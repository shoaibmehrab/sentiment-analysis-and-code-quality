id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
1999237329,"Thank you, copy that. 
I'll keep this PR open for a week or two to give you feedback when I get around running my experiments!",thank copy keep open week two give feedback get around running,issue,negative,neutral,neutral,neutral,neutral,neutral
1999207776,"Hi @CharlesGaydon, I'm working at Comet. We updated our FastAI integration and decided to include it on our SDK directly to help with the maintenance and benefits from our internal CI. You can find the up-to-date documentation how to use it here: https://www.comet.com/docs/v2/integrations/ml-frameworks/fastai/#start-logging. Please let me know if that works for you.

I also have a PR to update FastAI documentation with the same instructions that is currently pending review: https://github.com/fastai/fastai/pull/4009",hi working comet integration decided include directly help maintenance internal find documentation use please let know work also update documentation currently pending review,issue,positive,positive,neutral,neutral,positive,positive
1978018327,"The official tutorial can be run and will show the issue:
https://docs.fast.ai/tutorial.vision.html

![image](https://github.com/fastai/fastai/assets/4212742/f41291ba-3f47-4bdf-8449-2e701ca95f6f)
",official tutorial run show issue image,issue,negative,neutral,neutral,neutral,neutral,neutral
1976418188,Same behaviour seen on my setup with torch 2.2. Could the issue be related to the model being loaded having originally been generated with older library versions?,behaviour seen setup torch could issue related model loaded originally older library,issue,negative,positive,neutral,neutral,positive,positive
1975112581,Could you please add a reproducible code. I can help with this ,could please add reproducible code help,issue,positive,neutral,neutral,neutral,neutral,neutral
1975106490,"Thank you Jeremy! I missed that one and committed it accidentally.
I fixed sync and merge conflicts.",thank one accidentally fixed sync merge,issue,negative,positive,neutral,neutral,positive,positive
1974189904,"Looks good, except there's an extra nb change which changes the path - could you remove that please?",good except extra change path could remove please,issue,positive,positive,positive,positive,positive,positive
1972717593,"Hi @jph00
Could you please review this PR? Thanks",hi could please review thanks,issue,positive,positive,positive,positive,positive,positive
1969118836,"@jph00 Hi Jeremy, just wondering if this could be merged or if you need something else? Let me know if somethings missing!",hi wondering could need something else let know missing,issue,negative,negative,negative,negative,negative,negative
1967331450,any updates regarding this issue? I am facing same issue.,regarding issue facing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1967329657,"Hi, I am facing a same issue on Focal Loss, unable to pickle focal loss. am I missing out something, is there any solution to this problem. ",hi facing issue focal loss unable pickle focal loss missing something solution problem,issue,negative,negative,negative,negative,negative,negative
1967016745,"I wasn't sure exactly what to do with the current Callback in fastai repository (https://github.com/fastai/fastai/blob/master/fastai/callback/comet.py). Given that it's broken when you try to instantiate the callback:

```
File ~/.virtualenvs/comet3.9/lib/python3.9/site-packages/fastai/callback/comet.py:24, in CometCallback.__init__(self, project_name, log_model_weights)
     22 def __init__(self, project_name, log_model_weights=True):
     23     self.log_model_weights = log_model_weights
---> 24     self.keep_experiment_running = keep_experiment_running
     25     self.project_name = project_name
     26     self.experiment = None

NameError: name 'keep_experiment_running' is not defined
```

I think it's safe to delete the comet module. Alternatively, we can update the current callback to show a warning pointing to the new one maintained by Comet. Please let me know what do you prefer.",sure exactly current repository given broken try file self self none name defined think safe delete comet module alternatively update current show warning pointing new one comet please let know prefer,issue,negative,positive,positive,positive,positive,positive
1967001801,"Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/fastai/fastai/pull/4009""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 See visual diffs & provide feedback on Jupyter Notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>",check pull request see visual provide feedback powered,issue,negative,neutral,neutral,neutral,neutral,neutral
1961853465,"If people are still interested in having that function implemented, more than happy to take this on ",people still interested function happy take,issue,positive,positive,positive,positive,positive,positive
1948739245,while extracting the file a function called unrar was defined and it had a rename_extracted function it is not defined anywhere and it is showing Error cause its not defined. ,file function defined function defined anywhere showing error cause defined,issue,negative,neutral,neutral,neutral,neutral,neutral
1924506688,"I still get the same error. We figured out that by removing `Recorder()`, predict() works fine.",still get error figured removing recorder predict work fine,issue,negative,positive,positive,positive,positive,positive
1920596521,"@steve-estes fastai doesn't directly require cymem, so it must be from an upstream requirement. You can see [fastai's requirements here](https://github.com/fastai/fastai/blob/8e268e3b501ff27bc9efac1cfa7f4a746271c8bb/settings.ini#L17). If you could figure out which package is pinning to cymem-2.0.2, we can raise the issue with the maintainers or look into a workaround.

",directly require must upstream requirement see could figure package pinning raise issue look,issue,negative,positive,neutral,neutral,positive,positive
1917923424,"Try doing this

`pred,pred_idx,probs = learn.predict(Path(args.image_path))`
`prob = f'{probs[pred_idx]:.04f}`

`pred` is the prediction, `prob` is the probability.

Based on the FastAI code, you should save 3 variables like I showed above.
https://github.com/fastai/fastai/blob/43dbef38fe52b8b074d91ee1773e702a1401a486/fastai/learner.py#L319",try path prob prediction prob probability based code save like,issue,positive,neutral,neutral,neutral,neutral,neutral
1913294917,"@ismeh what should this link supposes to do?
bcoz either the link is incorrect or the file this link is trying to locate is corrupted.",link either link incorrect file link trying locate corrupted,issue,negative,neutral,neutral,neutral,neutral,neutral
1898456827,"The issue is the requirements peg to cymem==2.0.2.  I get the exact same as rupert above:

```ERROR: Some build dependencies for cymem==2.0.2 from https://files.pythonhosted.org/packages/8b/dc/0976e04cc46f86e0dd3ee3797ec68057eaafebf31daca9a076dc138b9920/cymem-2.0.2.tar.gz (from fastai) conflict with the backend dependencies: wheel==0.42.0 is incompatible with wheel>=0.32.0,<0.33.0.```

If we want to use fastai for some of its utils, even without PyTorch (e.g. we're fans of df_shrink), this prevents us from doing so on Python 3.12.  A simple fix would be to remove the version peg, instead just say `cymem>=2.0.2`.  cymem has (as of last Sept) released a version which fixes the wheel compatibility issue, all you need to do is allow people to use it.

Also, PyTorch supports Python 3.12 in its RC from a month ago (see: https://github.com/pytorch/pytorch/issues/110436 ), so we can expect a stable release that supports it shortly.  So testing fastai on 3.12, including for issues like this, is probably going to be an increasing priority - e.g. Homebrew now ships 3.12 by default on Mac, etc.
",issue peg get exact error build conflict incompatible wheel want use even without u python simple fix would remove version peg instead say last sept version wheel compatibility issue need allow people use also python month ago see expect stable release shortly testing like probably going increasing priority default mac,issue,negative,positive,neutral,neutral,positive,positive
1888706157,"Hi, just dropping in to confirm that I see the same behaviour @danielbellsa explains, i.e. learn.save adds a prefix `models/`. to the save path:

![image](https://github.com/fastai/fastai/assets/25931612/91e248a2-3430-46f1-b9c4-53b0bfe3acb3)


I have in `fastai==2.7.12` . I though this was intended behaviour somehow, but it would actually helpful to be able to override this.",hi dropping confirm see behaviour prefix save path image though intended behaviour somehow would actually helpful able override,issue,positive,positive,positive,positive,positive,positive
1879111866,"> Thank you very much! I have created a fresh environment and solved that problem.
Did you reinstall the virtual environment using pytorch1.7.1 , python3.6, cuda10.2, cudnn8.05, GeForce RTX 3090 environment?",thank much fresh environment problem reinstall virtual environment environment,issue,negative,positive,positive,positive,positive,positive
1875325444,"Hello, were you able to find a solution to this? I am unable to find a definition of rename_extracted().",hello able find solution unable find definition,issue,negative,neutral,neutral,neutral,neutral,neutral
1871488041,"If you are using any environment other than google colab, first install fastai library. 
use 
pip install fastai",environment first install library use pip install,issue,negative,positive,positive,positive,positive,positive
1857375243,"I have solved this issue with PR #3995. Now you can do the following and it will run successfully:
`dls = to.dataloaders(bs=20, dl_type=TabWeightedDL, wgts=[1.0] * len(df))`",issue following run successfully,issue,negative,positive,positive,positive,positive,positive
1857261959,"disregard this, retested it it was lacking ""()"" which failed to evaluate the code.  Making another PR, different branch.  I noticed I did not push on the right branch as well.",disregard evaluate code making another different branch push right branch well,issue,negative,positive,positive,positive,positive,positive
1836973441,"I am running into a similar problem where my model - trained on windows - is not running on colab showing the same error that. I have attached my code and error below (I tried using above mentioned solutions):

`# Load saved model`

`import pathlib`
`plt = platform.system()`
`if plt == 'Linux': pathlib.PosixPath = pathlib.WindowsPath`
`model_path = p + '/Liver_segmentation' #p is my path to the folder in my google drive`
`learn0 = load_learner(model_path)`

the error is:
`cannot instantiate 'WindowsPath' on your system`",running similar problem model trained running showing error attached code error tried load saved model import path folder drive learn error system,issue,negative,neutral,neutral,neutral,neutral,neutral
1834518435,"This is an nbdev project, so please make the change in the source notebook, add a brief test/example there too, and sync the lib. Thank you!",project please make change source notebook add brief sync thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1819610505,"@rohit27-2 , I think someone is also working on this problem here: #3977 ",think someone also working problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1814460236,"I merged the current master, but the problem with `_modidx.py` didn`t change, so I reset it manually. I hope it is ok not to merge ",current master problem change reset manually hope merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1813093557,"while running nbdev_prepare getting this error

AttributeError: 'FigureCanvasAgg' object has no attribute 'renderer'

<img width=""764"" alt=""image"" src=""https://github.com/fastai/fastai/assets/92698778/146bd73e-7562-4221-b422-803a487ea48d"">
<img width=""758"" alt=""image"" src=""https://github.com/fastai/fastai/assets/92698778/651eaf99-1160-48c4-bf48-956caa505351"">
",running getting error object attribute image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1789103137,"@jph00 In case you don't have a multi-GPU setup to test this, I recorded a couple minutes of my screen showing the behavior on master and the behavior after these commits.

- Here's the error on master related to the [example code](https://github.com/fastai/fastai/pull/3975/files#diff-16d51936d0e7b04d09e03912e2ce7816463a8f886e3bebf3c17d84daf06a9f20R656) in the notebook: https://drive.google.com/file/d/19CmlwqmRXJf2dZWDEu5Fis_WqEarZW1l/view
- Here's the error and fix related to [the data being on two different devices](https://github.com/fastai/fastai/pull/3975/files#diff-2d6d12070672525ed2f82d3f30899882f6392611a04899c9c7806c2188ea8634R157): https://drive.google.com/file/d/1dLiU7YYP3PAIBDwHu57ELdRiMw5gUlvK/view",case setup test couple screen showing behavior master behavior error master related example code notebook error fix related data two different,issue,negative,neutral,neutral,neutral,neutral,neutral
1783740145,"> Hi Sylvain, I faced the same error. This happened when we do not provide metrics to the learner, so self.learn.recorder.metrics is an empty list. Maybe should check whether metrics is empty first?

@tinhb92  how to pass custom metric for callback",hi faced error provide metric learner empty list maybe check whether metric empty first pas custom metric,issue,negative,positive,neutral,neutral,positive,positive
1781930641,Please let me know @eihli when it's ready for review and all seems to be working for you.,please let know ready review working,issue,positive,positive,positive,positive,positive,positive
1781929917,"After you've updated the nb, run `nbdev_prepare`, which will run the tests, sync the lib, and generate the docs/readme. If you request a review at that point I'll take a look to check it's all sorted.",run run sync generate request review point take look check sorted,issue,negative,neutral,neutral,neutral,neutral,neutral
1780434496,"> so I'm curious which one works. or do both?

Both do.

> Also, dl could be a PyTorch compatible DataLoader...

If that's the case, stick with the `self.dl.to(...)` solution?

Also:

> > I found this surprising since the [DataLoader does set](https://github.com/fastai/fastai/blob/nil/fastai/data/load.py#L102) device in its init, so I expect it to be hitting the setter that you added, and expect that second diff to resolve the issue.

Is it worth digging into this? I still expect `self.dl = DataLoader(device=dl.device, ...` should have also fixed it and I'm still really curious as to why it didn't. I think that's the solution that feels the best (if it would work).",curious one work also could compatible case stick solution also found surprising since set device expect setter added expect second resolve issue worth digging still expect also fixed still really curious think solution best would work,issue,positive,positive,positive,positive,positive,positive
1780421146,"@eihli I'm going to respond to [your post in #3976](https://github.com/fastai/fastai/pull/3976#issuecomment-1778212214) here, so the discussion on this issue/PR doesn't end up in too many places.

> Still getting the error from #3975 on this branch. (""RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!"")
> 
> Here's a bit of info that I hope you can use to track down the issue. I'm happy to jump on a screenshare if you want to collaborate on my environment as it experiences the issues.
> 
> This first diff fixes the error. The second diff doesn't.
> 
> ```
> diff --git a/fastai/distributed.py b/fastai/distributed.py
> index b8d71083..8b537dd5 100644
> --- a/fastai/distributed.py
> +++ b/fastai/distributed.py
> @@ -87,10 +87,11 @@ class DistributedDL(TfmdDL):
>                  pin_memory=dl.pin_memory, timeout=dl.timeout, shuffle=shuffle, drop_last=dl.drop_last, persistent_workers=dl.persistent_workers)
>          self.bs,self.device,self.drop_last,self.dataset,fake,self.num_workers,self.offs,self.pin_memory = \
>              attrgetter('bs','device','drop_last','dataset','fake_l','num_workers','offs','pin_memory')(self.dl)
> +        self.dl.device = self.dl.device
>          self.fake_l = _FakeLoader(self, fake.pin_memory, fake.num_workers, fake.timeout, 
>                                    persistent_workers=fake.persistent_workers, 
> -                                  pin_memory_device=fake.pin_memory_device)
> -        
> +u                                 pin_memory_device=fake.pin_memory_device)
> +
>      def _broadcast(self,t,rank):
>          ""Broadcasts t from rank `rank` to all other ranks. Returns t so t is same for all ranks after call.""
>          t = LongTensor(t).cuda() # nccl only works with cuda tensors
> ```
> 
> ```
> diff --git a/fastai/distributed.py b/fastai/distributed.py
> index b8d71083..cf7fa24e 100644
> --- a/fastai/distributed.py
> +++ b/fastai/distributed.py
> @@ -83,7 +83,7 @@ class DistributedDL(TfmdDL):
>          store_attr()
>          if type(dl) == torch.utils.data.DataLoader:
>              shuffle = True if eq(type(dl.sampler), torch.utils.data.RandomSampler) else False
> -            self.dl = DataLoader(dataset=dl.dataset, bs=dl.batch_size, num_workers=dl.num_workers, \
> +            self.dl = DataLoader(device=dl.device,dataset=dl.dataset, bs=dl.batch_size, num_workers=dl.num_workers, \
>                  pin_memory=dl.pin_memory, timeout=dl.timeout, shuffle=shuffle, drop_last=dl.drop_last, persistent_workers=dl.persistent_workers)
>          self.bs,self.device,self.drop_last,self.dataset,fake,self.num_workers,self.offs,self.pin_memory = \
>              attrgetter('bs','device','drop_last','dataset','fake_l','num_workers','offs','pin_memory')(self.dl)
> ```
> 
> I found this surprising since the [DataLoader does set](https://github.com/fastai/fastai/blob/nil/fastai/data/load.py#L102) `device` in its init, so I expect it to be hitting the setter that you added, and expect that second diff to resolve the issue.

The solution you mention in the quoted post:
```python
self.dl.device = self.dl.device
```

differs from this PR's current change of:
```python
self.dl.to(self.device)
```
so I'm curious which one works. or do both? (I don't have access to a multi-GPU machine, so cannot check myself.)

Also, `dl` could be a PyTorch compatible DataLoader due to `if type(dl) == torch.utils.data.DataLoader`, (as an aside should be an `isinstance` check), so it's not guaranteed to have a `device` attribute. So, you'll need to check if `device` exists first before trying to grab it from `dl` if that's the current working solution.",going respond post discussion end many still getting error branch device found least two bit hope use track issue happy jump want collaborate environment first error second git index class fake self self rank rank rank call work git index class type shuffle true type else false fake found surprising since set device expect setter added expect second resolve issue solution mention post python current change python curious one work access machine check also could compatible due type aside check device attribute need check device first trying grab current working solution,issue,positive,negative,neutral,neutral,negative,negative
1780321512,"Many thanks. This change actually needs to be made in index.ipynb, since the readme is auto-generated from that.",many thanks change actually need made since,issue,negative,positive,positive,positive,positive,positive
1780292573,"Run the same code on windows with intel cpu, with the same version of fastai, get expected result as the example shows
so the problem occur just on AMD cpu? but when i run the code with CUDA on AMD platform, still get train_loss NAN, valid_loss NAN",run code version get result example problem occur run code platform still get nan nan,issue,negative,neutral,neutral,neutral,neutral,neutral
1779506154,"Run the same code on colab with the same version of fastai, get expected result as the example shows
so the problem occur specifically on windows 11",run code version get result example problem occur specifically,issue,negative,neutral,neutral,neutral,neutral,neutral
1778212214,"Still getting the error from #3975 on this branch. (""RuntimeError: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cuda:1!"")

Here's a bit of info that I hope you can use to track down the issue. I'm happy to jump on a screenshare if you want to collaborate on my environment as it experiences the issues.

This first diff fixes the error. The second diff doesn't.

```
diff --git a/fastai/distributed.py b/fastai/distributed.py
index b8d71083..8b537dd5 100644
--- a/fastai/distributed.py
+++ b/fastai/distributed.py
@@ -87,10 +87,11 @@ class DistributedDL(TfmdDL):
                 pin_memory=dl.pin_memory, timeout=dl.timeout, shuffle=shuffle, drop_last=dl.drop_last, persistent_workers=dl.persistent_workers)
         self.bs,self.device,self.drop_last,self.dataset,fake,self.num_workers,self.offs,self.pin_memory = \
             attrgetter('bs','device','drop_last','dataset','fake_l','num_workers','offs','pin_memory')(self.dl)
+        self.dl.device = self.dl.device
         self.fake_l = _FakeLoader(self, fake.pin_memory, fake.num_workers, fake.timeout, 
                                   persistent_workers=fake.persistent_workers, 
-                                  pin_memory_device=fake.pin_memory_device)
-        
+u                                 pin_memory_device=fake.pin_memory_device)
+
     def _broadcast(self,t,rank):
         ""Broadcasts t from rank `rank` to all other ranks. Returns t so t is same for all ranks after call.""
         t = LongTensor(t).cuda() # nccl only works with cuda tensors
```

```
diff --git a/fastai/distributed.py b/fastai/distributed.py
index b8d71083..cf7fa24e 100644
--- a/fastai/distributed.py
+++ b/fastai/distributed.py
@@ -83,7 +83,7 @@ class DistributedDL(TfmdDL):
         store_attr()
         if type(dl) == torch.utils.data.DataLoader:
             shuffle = True if eq(type(dl.sampler), torch.utils.data.RandomSampler) else False
-            self.dl = DataLoader(dataset=dl.dataset, bs=dl.batch_size, num_workers=dl.num_workers, \
+            self.dl = DataLoader(device=dl.device,dataset=dl.dataset, bs=dl.batch_size, num_workers=dl.num_workers, \
                 pin_memory=dl.pin_memory, timeout=dl.timeout, shuffle=shuffle, drop_last=dl.drop_last, persistent_workers=dl.persistent_workers)
         self.bs,self.device,self.drop_last,self.dataset,fake,self.num_workers,self.offs,self.pin_memory = \
             attrgetter('bs','device','drop_last','dataset','fake_l','num_workers','offs','pin_memory')(self.dl)
```

I found this surprising since the [DataLoader does set](https://github.com/fastai/fastai/blob/nil/fastai/data/load.py#L102) `device` in its init, so I expect it to be hitting the setter that you added, and expect that second diff to resolve the issue.",still getting error branch device found least two bit hope use track issue happy jump want collaborate environment first error second git index class fake self self rank rank rank call work git index class type shuffle true type else false fake found surprising since set device expect setter added expect second resolve issue,issue,negative,negative,negative,negative,negative,negative
1776585352,"#3976 should fix the quoted issue from Discord.

> Per conversation on Discord: look at TfmdDL and see if it can/should be calling `to` on all of its Transforms.
> 
> > benjamin — Today at 1:23 PM
> > Maybe the distributed issue is related to different bug I encountered today. If you pass a device to a fastai DataLoader/TfmdDL on init, it doesn't move the transforms to that device.

",fix issue discord per conversation discord look see calling benjamin today maybe distributed issue related different bug today pas device move device,issue,negative,neutral,neutral,neutral,neutral,neutral
1776416421,"Per conversation on Discord: look at TfmdDL and see if it can/should be calling `to` on all of its Transforms.

> benjamin — Today at 1:23 PM
> Maybe the distributed issue is related to different bug I encountered today. If you pass a device to a fastai DataLoader/TfmdDL on init, it doesn't move the transforms to that device. ",per conversation discord look see calling benjamin today maybe distributed issue related different bug today pas device move device,issue,negative,neutral,neutral,neutral,neutral,neutral
1773992643,Just ran `accelerate launch nbs/examples/distrib.py` on the most up-to-date master (b273fbb32d075ef1d6fd372687b5f56564cead9) with 4 GPUs and didn't get any error. I think this can be closed. Maybe in the past 2 years since this was opened whatever was causing the issue was fixed.,ran accelerate launch master get error think closed maybe past since whatever causing issue fixed,issue,negative,negative,neutral,neutral,negative,negative
1767796611,"> That's odd - CI is being rather fussy, and complaining that your modidx file has a difference in line endings. Perhaps you modified it manually after syncing?

I saw that too. However, I didn't touched it and when I git-reset `_modidx.py` and run `nbdev_export`, eol is missing again (also on clean `upstream/master`), can you reproduce that? I'm using Codespace, so it shouldn't be a problem with my machine too",odd rather fussy file difference line perhaps manually saw however touched run missing also clean reproduce problem machine,issue,negative,neutral,neutral,neutral,neutral,neutral
1767336905,"That's odd - CI is being rather fussy, and complaining that your modidx file has a difference in line endings. Perhaps you modified it manually after syncing?",odd rather fussy file difference line perhaps manually,issue,negative,negative,negative,negative,negative,negative
1767333297,"> Thanks Jeremy (I should have read the CONTRIBUTION.md first)! I now executed `nbdev_export` (`_modidx.py` and `metrics.py` have changed as well as a consequence) and pushed again . What i still don't get, do I have to execute the `13a_learner.ipynb` notebooks as well in order to update the [`### Plotting tools`](https://docs.fast.ai/learner.html#recorder.plot_loss) section or is this done by the ci/cd pipline?

The docs are updated automatically for showing function signatures. The rest of the notebook is simply rendered as-is -- so if you have any new cell outputs, they will appear in the docs too.",thanks read first executed well consequence still get execute well order update plotting section done automatically showing function rest notebook simply new cell appear,issue,positive,positive,positive,positive,positive,positive
1765912885,"Thanks Jeremy (I should have read the CONTRIBUTION.md first)! I now executed `nbdev_export` (`_modidx.py` and `metrics.py` have changed as well as a consequence) and pushed again . What i still don't get, do I have to execute the `13a_learner.ipynb` notebooks as well in order to update the [`### Plotting tools`](https://docs.fast.ai/learner.html#recorder.plot_loss) section or is this done by the ci/cd pipline?",thanks read first executed well consequence still get execute well order update plotting section done,issue,positive,positive,positive,positive,positive,positive
1765271216,No apologies required! Thanks for putting it in the notebook. So now you need to run `nbdev_export` to sync your notebook with the library.,thanks notebook need run sync notebook library,issue,negative,positive,positive,positive,positive,positive
1764915283,"The latest release of PyTorch doesn't support Python 3.12, so fastai currently does not support it either.

Could you provide more details about the error? I am unable to replicate it on a new Python 3.11 environment. The fastai CI tests Python 3.8-3.10 and this error crop up either.",latest release support python currently support either could provide error unable replicate new python environment python error crop either,issue,negative,positive,neutral,neutral,positive,positive
1764856265,"> Many thanks! This is an nbdev project, so the changes need to be made in the source notebooks, and synced from there.

Thanks for pointing that out and I'm sorry I wasn't aware of it (it's my first post on fastai). I have moved it and hope everything is ok now. If not, please let me know",many thanks project need made source thanks pointing sorry aware first post hope everything please let know,issue,positive,positive,positive,positive,positive,positive
1763261697,"Many thanks! This is an nbdev project, so the changes need to be made in the source notebooks, and synced from there.",many thanks project need made source,issue,negative,positive,positive,positive,positive,positive
1762596165,"This should work now that #3973 was merged, fixing the bug which stopped the CI. I can't restart the CI though.",work fixing bug stopped ca restart though,issue,negative,neutral,neutral,neutral,neutral,neutral
1762306682,@jph00 Can you unmerge this? The error I missed needs to be fixed.,unmerge error need fixed,issue,negative,positive,neutral,neutral,positive,positive
1762300843,"Is it important that the order test failed? I wasn't expecting that error from this small change.

[edit] I think the answer is yes.",important order test error small change edit think answer yes,issue,negative,positive,neutral,neutral,positive,positive
1762259371,Can you please run sync in this one so the tests will run?,please run sync one run,issue,negative,neutral,neutral,neutral,neutral,neutral
1762258543,Fantastic - thanks for testing this. I'd been meaning to get around to it myself!,fantastic thanks testing meaning get around,issue,positive,positive,positive,positive,positive,positive
1752396808,"> I'm using Datablock what should I do

@XxMicrowavexX it works in my case

`dls = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    get_items=get_image_files,
    splitter=RandomSplitter(valid_pct=0.2, seed=42),
    get_y=parent_label,
    item_tfms=[Resize(192, method='squish')]
).dataloaders(path, bs=32, device='cpu')
`",work case resize path,issue,negative,neutral,neutral,neutral,neutral,neutral
1752153957,"We can't merge untested PRs, sorry. Once the new version is fully tested we can support it.",ca merge untested sorry new version fully tested support,issue,negative,negative,negative,negative,negative,negative
1752153648,"> Have you tested it works correctly with cuda?

no, I don't have nvidia card.
",tested work correctly card,issue,negative,neutral,neutral,neutral,neutral,neutral
1751722175,"> > 
> 
> For that i get this error `E:\Python>conda install -c nvidia fastai anaconda Retrieving notices: ...working... done Collecting package metadata (current_repodata.json): done Solving environment: failed with initial frozen solve. Retrying with flexible solve. Collecting package metadata (repodata.json): done Solving environment: failed with initial frozen solve. Retrying with flexible solve.
> 
> PackagesNotFoundError: The following packages are not available from current channels:
> 
> * fastai
> 
> Current channels:
> 
> * https://conda.anaconda.org/nvidia/win-64
> * https://conda.anaconda.org/nvidia/noarch
> * https://repo.anaconda.com/pkgs/main/win-64
> * https://repo.anaconda.com/pkgs/main/noarch
> * https://repo.anaconda.com/pkgs/r/win-64
> * https://repo.anaconda.com/pkgs/r/noarch
> * https://repo.anaconda.com/pkgs/msys2/win-64
> * https://repo.anaconda.com/pkgs/msys2/noarch
> 
> To search for alternate channels that may provide the conda package you're looking for, navigate to`

I'm having the same error running ""conda install -c nvidia fastai anaconda"". ",get error install anaconda working done package done environment initial frozen solve flexible solve package done environment initial frozen solve flexible solve following available current current search alternate may provide package looking navigate error running install anaconda,issue,negative,positive,neutral,neutral,positive,positive
1745470097,"I tried to reproduce. I get this output: 

![image](https://github.com/fastai/fastai/assets/61845660/92d48027-26da-47a5-bb17-d497d2c8cf53)

Running on Google Colab, T4 GPU
",tried reproduce get output image running,issue,negative,neutral,neutral,neutral,neutral,neutral
1729474058,"Is it correct to close this issue as completed @jph00  ? The issue is asking for better documentation of inputs, while they got help for their example, I can't see that it solves their actual problem:

>The documentation is huge but useless.
Please! please! add a specification of what each input to each class\function should be.
For 2 days I've just been trying to guess what each function expects. The code is ultra obscured in inheritance of obfuscated classes so it's incredibly hard to reverse engineer the input specifications as well.

>Numpy for example does an amazing job at this. I really suggest following their lead. Each function lists out each of the inputs and specify their type and a sentence or two of what they do. Check out [this](https://numpy.org/doc/stable/reference/generated/numpy.roll.html) for example.",correct close issue issue better documentation got help example ca see actual problem documentation huge useless please please add specification input day trying guess function code ultra inheritance class incredibly hard reverse engineer input well example amazing job really suggest following lead function specify type sentence two check example,issue,positive,positive,positive,positive,positive,positive
1729464931,"> We're not doing that, Jeremy will be working on the doc strings at some point. In the meantime just use nbdev if you're not satisfied with the vanilla. (Literally just do `pip install nbdev` and `doc()` will show the pretty doc)

Any progress on this? ",working doc point use satisfied vanilla literally pip install doc show pretty doc progress,issue,positive,positive,positive,positive,positive,positive
1717108206,"Hello Jeremy, the cell outputs have been restored and for the `clone` statements I believe keeping them will help with the understanding of the example test cases for learners looking into the documentation.",hello cell clone believe keeping help understanding example test looking documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
1706642031,"Oh of course, that makes sense. Just pushed the change.",oh course sense change,issue,negative,neutral,neutral,neutral,neutral,neutral
1703874598,"It is actually using num_workers, even although it isn't reporting it correctly. Nonetheless, I do agree it would be best if we reported it correctly!

Note that this is an nbdev project, so the change needs to be made in the source notebook, rather than just the py module.",actually even although correctly nonetheless agree would best correctly note project change need made source notebook rather module,issue,positive,positive,positive,positive,positive,positive
1703354939,"Sorry for that, I reverted these changes locally, but before I push I wanted to ask about the `clone` calls. Do you mean I change it from this:
```
x1a = torch.ones(20,1,1,1) 
x1b = torch.clone(x1a)*0.5
x1c = torch.clone(x1a)*0.3
x1 = torch.cat((x1a,x1b,x1c), dim=1) 
```
to this:
```
x1a = torch.ones(20,1,1,1)
x1 = torch.cat((x1a,x1b,x1c), dim=1) 
```",sorry locally push ask clone mean change,issue,negative,negative,negative,negative,negative,negative
1702791626,"> Thank you! Can you please place your new class in a separate cell, and add tests for it underneath?

You are most welcome, done Alhamdulillah (all praises are due to Allah) and ready for your review.",thank please place new class separate cell add underneath welcome done due ready review,issue,positive,positive,positive,positive,positive,positive
1702455085,"```
 ImageDataLoaders.from_folder (path, train='train', valid='valid',
                               valid_pct=None, seed=None, vocab=None,
                               item_tfms=None, batch_tfms=None,
                               img_cls=<class
                               'fastai.vision.core.PILImage'>, bs:int=64,
                               val_bs:int=None, shuffle:bool=True,
                               device=None)
```

in the from_folder function, you can set device= torch.device('cpu')",path class shuffle function set,issue,negative,neutral,neutral,neutral,neutral,neutral
1701617176,"Thank you! Can you please place your new class in a separate cell, and add tests for it underneath?",thank please place new class separate cell add underneath,issue,positive,positive,positive,positive,positive,positive
1671659588,fix it with conda install -c conda-forge platformdirs before you run the insall fastai command.,fix install run command,issue,negative,neutral,neutral,neutral,neutral,neutral
1668286368,"I ran a local test with slow and cuda flags. I am unable to test multicuda, so assuming the Accelerate bump works fine since there was no maximum version cap.",ran local test slow unable test assuming accelerate bump work fine since maximum version cap,issue,negative,negative,neutral,neutral,negative,negative
1659424801,"I've encountered this issue as well. My workaround was to simply change the loss function prior to exporting the model. Alternatively, you can use the Dill module instead of Pickle.",issue well simply change loss function prior model alternatively use dill module instead pickle,issue,negative,neutral,neutral,neutral,neutral,neutral
1655481658,Actually this is because it is not a number but a tensor so it is correct. Will report as an issue in the package that actually has the problem.,actually number tensor correct report issue package actually problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1652010081,"I have faced similar problem and had to dig into the fastai code to understand whats going on. Apparently if you save a model using `export` function, fastai will call pytorch's `save` model function which save the **PATH** to the model, not the model itself. So if you try to use it in a different location/device, it just breaks.
More details on how pytorch save models: https://pytorch.org/tutorials/beginner/saving_loading_models.html",faced similar problem dig code understand whats going apparently save model export function call save model function save path model model try use different save,issue,positive,positive,neutral,neutral,positive,positive
1650300570,"I am running this on colab. Data Munging topic has this to implement. But I am aslo getting the same error. 

> FileNotFoundError: [Errno 2] No such file or directory: '/root/.fastai/data/imdb_tok/counter.pkl'",running data topic implement getting error file directory,issue,negative,neutral,neutral,neutral,neutral,neutral
1647113190,This needs to be changed in the notebook too - this is an nbdev project so the notebooks are the actual source.,need notebook project actual source,issue,negative,neutral,neutral,neutral,neutral,neutral
1606213990,"Hi, have you checked the version of Pandas that is currently installed? Maybe upgrading the Pandas version can resolve the issue as it could be that the DatetimeProperties object is outdated or incompatible with the version of Fastai you are using.

Also, in current version 2.7.12 the import for add_datepart is with fastai.tabular.core or fastai.tabular.all
",hi checked version currently maybe version resolve issue could object outdated incompatible version also current version import,issue,negative,negative,negative,negative,negative,negative
1594495968,"I've ~hacked~ patched the file `learner.py` in my local installation to make the change described above, and the bug is now fixed for me.",file local installation make change bug fixed,issue,negative,positive,neutral,neutral,positive,positive
1585705311,"On windows 11 64 bit machine running out of visual code this worked for me.
Seems adding the dunder main check allows the loader to complete its process and learner to then run and tokenize (creating the missing files). I am by no means a python expert but have found I've needed to add this line in quite a few examples from the fastai book samples. Hopefully this helps others!

```
from fastai.text.all import *

path = untar_data(URLs.IMDB)
if __name__ == ""__main__"":
    dls = TextDataLoaders.from_folder(path, valid='test', bs=16)

    learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)
    learn.fine_tune(4, 1e-2)

    learn.predict(""I really liked that movie!"")
```",bit machine running visual code worked dunder main check loader complete process learner run missing python expert found add line quite book hopefully import path path learn really movie,issue,negative,positive,neutral,neutral,positive,positive
1580902239,"> In VS Code the issue is related to the jupyter extension. Reverting to version v2022.11.1003412109 fixed it. There was an issue filed and merged two days ago. Should see it in the next release. Not sure if that helps with PyCharm but figured I would share in case it helps anyone.

It truly saves lives. Thank you pounde!",code issue related extension version fixed issue two day ago see next release sure figured would share case anyone truly thank,issue,positive,positive,positive,positive,positive,positive
1564736345,"Just to keep information complete: I opened an issue in the pytorch project (https://github.com/pytorch/pytorch/issues/100717) and there seems to be a fix now (https://github.com/pytorch/pytorch/commit/b7bf953bbc864ae6182c36f892e1e61049647ea1), although not out yet.",keep information complete issue project fix although yet,issue,negative,positive,neutral,neutral,positive,positive
1563698478,That would break the notebook unfortunately. I've copied the image over now.,would break notebook unfortunately copied image,issue,negative,negative,negative,negative,negative,negative
1562924954,"> 

For that i get this error
`E:\Python>conda install -c nvidia fastai anaconda
Retrieving notices: ...working... done
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Collecting package metadata (repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.

PackagesNotFoundError: The following packages are not available from current channels:       

  - fastai

Current channels:

  - https://conda.anaconda.org/nvidia/win-64
  - https://conda.anaconda.org/nvidia/noarch
  - https://repo.anaconda.com/pkgs/main/win-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/r/win-64
  - https://repo.anaconda.com/pkgs/r/noarch
  - https://repo.anaconda.com/pkgs/msys2/win-64
  - https://repo.anaconda.com/pkgs/msys2/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to`",get error install anaconda working done package done environment initial frozen solve flexible solve package done environment initial frozen solve flexible solve following available current current search alternate may provide package looking navigate,issue,positive,positive,neutral,neutral,positive,positive
1559595552,"> 
try this

```bash
conda install -c nvidia fastai anaconda
```
",try bash install anaconda,issue,negative,neutral,neutral,neutral,neutral,neutral
1551327023,So strange that only I seem to be getting this error. Whenever I pass a string literal directly: `model.load('data/models/my_weights.pth')` FastAI still throws: `FileNotFoundError: [Errno 2] No such file or directory: 'models/data/models/my_weights.pth.pth'`,strange seem getting error whenever pas string literal directly still file directory,issue,negative,positive,neutral,neutral,positive,positive
1549138285,"Hey @danielbellsa I cannot reproduce the issue can you please provide more context? I have tested the following code on Colab:
```py

from fastai.vision.all import *
import torch

# Define your dataset
path = untar_data(URLs.PETS)/'images'
fnames = get_image_files(path)[:10] # use only first 10 images
def label_func(x): return x[0].isupper()
dls = ImageDataLoaders.from_name_func(
    path, fnames, label_func, item_tfms=Resize(224))

# Define your model
learn = cnn_learner(dls, resnet18, metrics=accuracy)

# Train your model
learn.fine_tune(1)

# Save your model
model_path = Path(""/content/test/my_model.pth"")
learn.export(model_path)

# Load your model
learn_loaded = load_learner(model_path)
```

It is working correctly for me and it is not adding any prefix or suffix to the model path.",hey reproduce issue please provide context tested following code import import torch define path path use first return path define model learn train model save model path load model working correctly prefix suffix model path,issue,positive,positive,positive,positive,positive,positive
1543777960,I've faced the same issue. @jph00 @sgugger Would you be interested in having the multilabel confusion matrix implementation in fastai? Can I work on this and raise a PR for the same?,faced issue would interested confusion matrix implementation work raise,issue,negative,positive,positive,positive,positive,positive
1538923704,"Sure, I will do a proper local setup and will do then the requested changes. Most probably over the coming weekend.",sure proper local setup probably coming weekend,issue,negative,positive,positive,positive,positive,positive
1537786439,"Thanks for the contribution! This is an nbdev project, so the actual source is in the notebooks, and the .py files are auto-generated. Could you please make your edit in the notebook too? Also, please add a comment above explaining why the extra casts are there?",thanks contribution project actual source could please make edit notebook also please add comment explaining extra,issue,positive,positive,neutral,neutral,positive,positive
1536219899,In VS Code the issue is related to the jupyter extension. Reverting to version v2022.11.1003412109 fixed it. There was an issue filed and merged two days ago. Should see it in the next release. Not sure if that helps with PyCharm but figured I would share in case it helps anyone.,code issue related extension version fixed issue two day ago see next release sure figured would share case anyone,issue,positive,positive,positive,positive,positive,positive
1532448108,"[PR 3910](https://github.com/fastai/fastai/pull/3910) adds these guards for current loss functions, I'd like to investigate why these loss functions can't be pickled with this issue but happy to open a new issue & PRs if you'd like to keep them separate.",current loss like investigate loss ca issue happy open new issue like keep separate,issue,positive,positive,positive,positive,positive,positive
1530551649,"I'm having the same issue with VS Code. Interestingly, I found this in the jupyter output:
`warn 16:22:37.484: Update display data message received, but no output found to update {
  data: {
    'text/plain': '<IPython.core.display.HTML object>',
    'text/html': '\n' +
      '    <div>\n' +
      ""      <progress value='0' class='' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n"" +
      '      0.00% [0/1 00:00&lt;?]\n' +
      '    </div>\n' +
      '    \n' +
      '<table border=""1"" class=""dataframe"">\n' +
      '  <thead>\n' +
      '    <tr style=""text-align: left;"">\n' +
      '      <th>epoch</th>\n' +
      '      <th>train_loss</th>\n' +
      '      <th>valid_loss</th>\n' +
      '      <th>error_rate</th>\n' +
      '      <th>time</th>\n' +
      '    </tr>\n' +
      '  </thead>\n' +
      '  <tbody>\n' +
      '  </tbody>\n' +
      '</table><p>\n' +
      '\n' +
      '    <div>\n' +
      ""      <progress value='26' class='' max='92' style='width:300px; height:20px; vertical-align: middle;'></progress>\n"" +
      '      28.26% [26/92 02:53&lt;07:21 0.5111]\n' +
      '    </div>\n' +
      '    '
  },
  metadata: {},
  transient: { display_id: 'c35929d719d7461747e318af11621b95' }
}
`",issue code interestingly found output warn update display data message received output found update data object div progress height middle table left th epoch th th th th time div progress height middle transient,issue,positive,positive,positive,positive,positive,positive
1528659822,"You might have resolved it by now, but I fixed similar error in `fastbook` by converting fastai tensors to standard PyTorch tensors:

```
x= x.as_subclass(torch.Tensor)
y = y.as_subclass(torch.Tensor)
```",might resolved fixed similar error converting standard,issue,negative,positive,neutral,neutral,positive,positive
1520795195,"@AdamZWinter It's been a while, but let me try. If I recall correctly, the issue was I was training something in a notebook, which always has the namespace `__main__`. I then saved the model into a pickle. Upon loading the model, it expects to have the model definition again in `__main__`, but I copied it to a module to be used in the API. The fix was to have both training and inference use the same model in the same module (i.e. `models.py` for example). ",let try recall correctly issue training something notebook always saved model pickle upon loading model model definition copied module used fix training inference use model module example,issue,negative,neutral,neutral,neutral,neutral,neutral
1519503045,Sorry @lanks I don't think I resolved this. I recall trying installing different versions of fastai but don't remember what got it working exactly.,sorry think resolved recall trying different remember got working exactly,issue,negative,negative,neutral,neutral,negative,negative
1518995222,Hmm getting this issue now as well with the Kaggle Notebook clone for lesson 1. @snewcomer @davidgilbertson did you guys manage to figure out what the issue is?,getting issue well notebook clone lesson manage figure issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1516836385,"I am having the same problem, but not sure I follow what you are saying to do.  Can you provide and example?  Thank you.",problem sure follow saying provide example thank,issue,negative,positive,positive,positive,positive,positive
1513708204,"Just ran into the same issue. I know this is pretty old, but still yields the same error. ",ran issue know pretty old still error,issue,negative,positive,positive,positive,positive,positive
1510402208,"Hi! Amazing project. I'm looking forward to using it. 

I'm new to Python and machine learning, so I apologise in advance if my question is naive. I have tried to install it with Conda and in jupyter notebook. I successfully installed Fastai. However, I can import Fastai, but I can't import fastsom. I changed the decoding, yet, it keeps raising the following error. So, I kindly ask you to show me my mistake, please. Thank you.

error: subprocess-exited-with-error
  
  Ã— python setup.py egg_info did not run successfully.
  â”‚ exit code: 1
  â•°â”€> [8 lines of output]
      Traceback (most recent call last):
        File ""<string>"", line 2, in <module>
        File ""<pip-setuptools-caller>"", line 34, in <module>
        File ""C:\Users\veron\AppData\Local\Temp\pip-install-efpuwbrv\sklearn_a3f614e103384df7a4b26a825228d5c3\setup.py"", line 10, in <module>
          LONG_DESCRIPTION = f.read()
        File ""C:\Users\veron\anaconda3\lib\encodings\cp1252.py"", line 23, in decode
          return codecs.charmap_decode(input,self.errors,decoding_table)[0]
      UnicodeDecodeError: 'charmap' codec can't decode byte 0x8f in position 7: character maps to <undefined>
      [end of output]
  
  note: This error originates from a subprocess, and is likely not a problem with pip.
error: metadata-generation-failed

Ã— Encountered error while generating package metadata.
â•°â”€> See above for output.

note: This is an issue with the package mentioned above, not pip.
hint: See above for details.
",hi amazing project looking forward new python machine learning advance question naive tried install notebook successfully however import ca import yet raising following error kindly ask show mistake please thank error python run successfully exit code output recent call last file string line module file line module file line module file line decode return input ca decode position character undefined end output note error likely problem pip error error generating package see output note issue package pip hint see,issue,negative,positive,positive,positive,positive,positive
1509485730,"@claforte 
AttributeError: 'RecordOnCPU' object has no attribute 'input' data？
AttributeError Traceback (most recent call last)
Cell In[53], line 1
----> 1 do_fit(‘v1.1’, slice(lr*10))

Cell In[52], line 4, in do_fit(save_name, lrs, pct_start)
2 learn.fit_one_cycle(1, lrs, pct_start=pct_start)
3 learn.save(save_name)
----> 4 learn.show_results()

File /fastai/basic_train.py:407, in Learner.show_results(self, ds_type, rows, **kwargs)
405 preds = self.pred_batch(ds_type)
406 *self.callbacks,rec_cpu = self.callbacks
→ 407 x,y = rec_cpu.input,rec_cpu.target
408 norm = getattr(self.data,‘norm’,False)
409 if norm:

AttributeError: ‘RecordOnCPU’ object has no attribute ‘input’

I get the above error using learn.show_results()",object attribute recent call last cell line slice cell line file self norm norm false norm object attribute input get error,issue,negative,negative,negative,negative,negative,negative
1509485056,"@tcapelle 
I am also converting unet in fastaiv1 to onnx, and the conversion is successful, but the data does not match and the output data is wrong. The following is part of my code and bugs. Can you help me?

 import onnxruntime
    model_name = model_path.split(""/"")[-1]
    model_dir = os.path.dirname(model_path)
    print(model_dir, model_name)

    onnx_name = model_name.split('.')[0] + "".onnx""
    onnx_file = os.path.join(model_dir, onnx_name)

    my_model = load_learner(model_dir, file=model_name)
    fastai_model = my_model.model.eval()  # gets the PyTorch model
    batch_size = 1  # 随机的取值，当设置dynamic_axes后影响不大
    dummy_input = torch.randn(batch_size, 3, 512, 512).cuda()
    # dummy_input = torch.randn(batch_size, 3, 512, 512, requires_grad=True).cuda()
    fastai_output= fastai_model(dummy_input)


    remove_all_spectral_norm(fastai_model)  # function posted above by 'jantic'
    torch.onnx.export(
        fastai_model,
        dummy_input,
        onnx_file,
        do_constant_folding=True,
        export_params=True,
        input_names=['input'],
        output_names=['output'],
        opset_version=10
    )
    onnx_session = onnxruntime.InferenceSession(onnx_file)
    example_input = dummy_input.detach().cpu().numpy()
    onnx_output = onnx_session.run(None, {""input"": example_input})[0]
    print(to_numpy(fastai_output).shape, to_numpy(fastai_output).dtype)
    print(type(onnx_output),onnx_output.shape,onnx_output.dtype)

    np.testing.assert_allclose(to_numpy(fastai_output), onnx_output, rtol=1e-03, atol=1e-05)

AssertionError: 
Not equal to tolerance rtol=0.001, atol=1e-05

Mismatched elements: 49028 / 786432 (6.23%)
Max absolute difference: 0.004484
Max relative difference: 1.745822
 x: array([[[[ 1.5412  ,  0.386021, -0.736858, -0.710856, ..., -0.672184,  2.365301,  5.091552,  7.694845],
         [ 0.774052,  0.454567, -0.108518, -1.029475, ..., -1.103212,  0.663   ,  4.146187,  7.466909],
         [-0.204205, -0.297791, -0.873678, -1.662844, ..., -2.052972, -0.762107,  3.904182,  6.5224  ],...
 y: array([[[[ 1.540189,  0.385563, -0.736872, -0.710747, ..., -0.672837,  2.363917,  5.08985 ,  7.691854],
         [ 0.773566,  0.454081, -0.108943, -1.029621, ..., -1.103786,  0.662059,  4.144192,  7.463364],
         [-0.204408, -0.298261, -0.874216, -1.662913, ..., -2.053382, -0.762767,  3.902846,  6.520339],...
",also converting conversion successful data match output data wrong following part code help import print model function posted none input print print type equal tolerance absolute difference relative difference array array,issue,positive,positive,neutral,neutral,positive,positive
1506150795,"Great, I'll have a look and put in a PR, thanks",great look put thanks,issue,positive,positive,positive,positive,positive,positive
1504733231,"Hey @warner-benjamin, let me know if this still needs picking up, I'll put in a PR if so.",hey let know still need put,issue,negative,neutral,neutral,neutral,neutral,neutral
1487558884,"@juwiragiye Since PyTorch 2.0 was released, the conda/mamba solver would occasionally get confused due to fastai support ending at 1.13.1.

Try again now with the new fastai 2.7.12 release which has PyTorch 2.0 support. If you are still having installation issues, please ask for help in the [forums](https://forums.fast.ai).",since solver would occasionally get confused due support ending try new release support still installation please ask help,issue,positive,negative,neutral,neutral,negative,negative
1483973984,Closing due to lack of activity - @bencoman feel free to reopen if you have a chance to get back to this.,due lack activity feel free reopen chance get back,issue,negative,positive,neutral,neutral,positive,positive
1483919404,"I've tried to run the example from the book. I've run pip install fastai and I still get this error:

`    from fastai.vision.all import *
  File ""C:\Python311\Lib\site-packages\fastai\vision\all.py"", line 1, in <module>
    from . import models
  File ""C:\Python311\Lib\site-packages\fastai\vision\models\__init__.py"", line 1, in <module>
    from . import xresnet
  File ""C:\Python311\Lib\site-packages\fastai\vision\models\xresnet.py"", line 13, in <module>
    from torchvision.models.utils import load_state_dict_from_url
ModuleNotFoundError: No module named 'torchvision.models.utils'`",tried run example book run pip install still get error import file line module import file line module import file line module import module,issue,negative,neutral,neutral,neutral,neutral,neutral
1483719890,"@depowered thank you!

For anyone else who's not super familiar with the whole google collab workflow, you can try the following:
- upload the files to your drive
- click on the folder icon in the left toolbar
- find the file in your google drive
- right-click and copy path
- 
That path can be used directly inside `learn.predict(""path/to/file"")`",thank anyone else super familiar whole try following drive click folder icon left find file drive copy path path used directly inside,issue,positive,positive,positive,positive,positive,positive
1483660852,"@Max1x1 PR #3884 resolves this issue, and the fix will be in the next release of fastai.",issue fix next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1483258881,"WOW! Thanks a lot, it works!!!!!!!!!",wow thanks lot work,issue,positive,positive,positive,positive,positive,positive
1482901950,"I ran into this problem as well. Both in fastbook chapter 1 notebook and the ""Is it a bird?"" notebook from the first lecture. This is due to a bug in the current release of the fastai library (v2.7.11).

This bug was identified in issue #3880 and fixed in PR #3884. The fix will be included in the next release of the library (ETA unknown).

In the meantime, I have had success with passing a file name/path string to `learn.predict`.

Is it a bird? Notebook Example:
```python
is_bird, _, probs = learn.predict('bird.jpg') # Works
is_bird, _, probs = learn.predict(PILImage.create('bird.jpg')) # Doesn't work in v2.7.11, should work in next release
```

Fastbook 01_intro Notebook Example:
```python
file = uploader.data[0] # File path string
is_cat, _, probs = learn.predict(file) # Works
is_cat, _, probs = learn.predict(PILImage.create(file)) # Doesn't work in v2.7.11, should work in next release
```",ran problem well chapter notebook bird notebook first lecture due bug current release library bug issue fixed fix included next release library eta unknown success passing file string bird notebook example python work work work next release notebook example python file file path string file work file work work next release,issue,negative,positive,neutral,neutral,positive,positive
1478044541,"@jaingranth You can't load `pth` files with the `load_learner` function. `pth` only contains the weights, and the optimizer state (optional). You need to redefine the model and load the weights in the following fashion.

```py
# define learner, transforms, and dls
dls = [...]
transforms = [...]
learn = Learner(....)
learn = learn.load('path-to-the-model-without-pth')
```",ca load function state optional need redefine model load following fashion define learner learn learner learn,issue,negative,neutral,neutral,neutral,neutral,neutral
1476342361,"Error has been resolved - see the discussion above
",error resolved see discussion,issue,negative,neutral,neutral,neutral,neutral,neutral
1474890422,"@kumuda0 Could you solve your issue?
Thank you.",could solve issue thank,issue,positive,neutral,neutral,neutral,neutral,neutral
1471007042,"I changed `TensorBase` to use `Tensor`'s `__reduce_ex__` and didn't notice any errors when running tests with the slow and cuda flags turned on. An Imagenette training and augmentation test also appears to work correctly.

I'm not sure why we have our own `__reduce_ex__` implementation for `TensorBase`, so I left it alone for PyTorch 1.x versions.",use tensor notice running slow turned training augmentation test also work correctly sure implementation left alone,issue,negative,positive,neutral,neutral,positive,positive
1468172690,"@wolever the new `_has_mps()` function now in fastai 2.7.11 causes an error on Intel Macs with OS < 12.3:
```python
RuntimeError: The MPS backend is supported on MacOS 12.3+.Current OS version can be queried using `sw_vers`
```

I think it is because `torch.backends.mps.is_available()` returns `False` (the correct value), but `torch.has_mps` is `True`. In this case `_has_mps()` returns `True` and the backend is set to mps. Using mps will cause the error above.

I suggest changing `_has_mps()` to return the value of `torch.backends.mps.is_available()` if it exists and only default to `torch.has_mps` if this function is not available

",new function error o python o version think false correct value true case true set cause error suggest return value default function available,issue,positive,positive,positive,positive,positive,positive
1462588402,"As a first-time user of the fastai library, I would like to share some observations that I have made. I am unsure if these issues have already been discussed in the forum or in any other issue threads.

I have noticed that when I execute the following code block and then pass it to learn.predict, it raises an `AttributeError: read`

```
dest = PILImage.create(image_cat())
dest.to_thumb(256,256)
```
However, when I execute the following code block and pass it to `learn.predict`, no error is raised:
```
dest = Image.open(image_cat())
dest.to_thumb(256,256)
```
Additionally, I have observed that the type of `dest` differs when I use the two different code blocks. Specifically, when I use the code block:
```
dest = PILImage.create(image_cat())
dest.to_thumb(256,256)
```
`type(dest)` returns `fastai.vision.core.PILImage`, while using the code block:
```
dest = Image.open(image_cat())
dest.to_thumb(256,256)
```
`type(dest)` returns `PIL.JpegImagePlugin.JpegImageFile`

It is worth noting that passing `dest` to `learn.predict` modifies its original type from `PIL.JpegImagePlugin.JpegImageFile` to `fastai.vision.core.PILImage`. 
```
is_cat,_,probs = learn.predict(dest)
print(f""Is this a cat?: {is_cat}."")
print(f""Probability it's a cat: {probs[1].item():.6f}"")
```
As a result, even when I execute the aforementioned block twice consecutively, an `AttributeError: read` is raised the second time.

",user library would like share made unsure already forum issue execute following code block pas read however execute following code block pas error raised additionally type use two different code specifically use code block type code block type worth passing original type print cat print probability cat result even execute block twice consecutively read raised second time,issue,negative,positive,positive,positive,positive,positive
1458652570,"I think this simple fix is the correct fix, as modifying [`infer_idx`](https://github.com/fastai/fastai/blob/4d1834cb0b6ac20b068de55cf57f40a0c2296cd4/fastai/data/core.py#L400-L409) and related code to perform a strict type check would probably cause more issues in the future.

We want to merge and release this soon @jph00, as there are a lot of questions as to why the tutorial notebooks on Kaggle are breaking and this will fix those issues.

",think simple fix correct fix related code perform strict type check would probably cause future want merge release soon lot tutorial breaking fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1449354800,"@csaroff `new_empty` is regularly called by PyTorch without setting `layout`, so `TensorBase.new_empty` needs to distinguish between 1.13 & 2.0 calling it expecting a `layout` default of `None` and 1.12 and earlier which expect a default of `strided`. Some form of PyTorch version hardcoding is required.",regularly without setting layout need distinguish calling layout default none expect default form version,issue,negative,neutral,neutral,neutral,neutral,neutral
1447060934,"That's still an issue as we want to support PyTorch 1.12. I thought I tested enough for #3882, but I clearly missed this. I don't think we want to set the default to `layout=torch.strided` though for PyTorch 1.13. I can look into this more later today.",still issue want support thought tested enough clearly think want set default though look later today,issue,positive,positive,neutral,neutral,positive,positive
1446952822,"Hey @warner-benjamin, I appreciate you taking a look.

I'm running pytorch version '1.12.1+cu102' and python version `3.10.5` and I'm on the latest fastai commit(4d1834cb0b6ac20b068de55cf57f40a0c2296cd4).

I copy-pasted your reproducible example and it fails for me with the following stack trace:

```python
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
Cell In [1], line 13
      3 imagenette = untar_data(URLs.IMAGENETTE_160)
      5 block = DataBlock(
      6     blocks=(ImageBlock, CategoryBlock),
      7     splitter=GrandparentSplitter(valid_name='val'),
   (...)
     11                 Normalize.from_stats(*imagenet_stats)],
     12 )
---> 13 dls = block.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)
     15 learn = Learner(dls, xresnext18(n_out=dls.c))
     16 learn.fit_one_cycle(5, 3e-4)

File ~/fastai/fastai/data/block.py:157, in DataBlock.dataloaders(self, source, path, verbose, **kwargs)
    155 dsets = self.datasets(source, verbose=verbose)
    156 kwargs = {**self.dls_kwargs, **kwargs, 'verbose': verbose}
--> 157 return dsets.dataloaders(path=path, after_item=self.item_tfms, after_batch=self.batch_tfms, **kwargs)

File ~/fastai/fastai/data/core.py:337, in FilteredBase.dataloaders(self, bs, shuffle_train, shuffle, val_shuffle, n, path, dl_type, dl_kwargs, device, drop_last, val_bs, **kwargs)
    335 dl = dl_type(self.subset(0), **merge(kwargs,def_kwargs, dl_kwargs[0]))
    336 def_kwargs = {'bs':bs if val_bs is None else val_bs,'shuffle':val_shuffle,'n':None,'drop_last':False}
--> 337 dls = [dl] + [dl.new(self.subset(i), **merge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))
    338               for i in range(1, self.n_subsets)]
    339 return self._dbunch_type(*dls, path=path, device=device)

File ~/fastai/fastai/data/core.py:337, in <listcomp>(.0)
    335 dl = dl_type(self.subset(0), **merge(kwargs,def_kwargs, dl_kwargs[0]))
    336 def_kwargs = {'bs':bs if val_bs is None else val_bs,'shuffle':val_shuffle,'n':None,'drop_last':False}
--> 337 dls = [dl] + [dl.new(self.subset(i), **merge(kwargs,def_kwargs,val_kwargs,dl_kwargs[i]))
    338               for i in range(1, self.n_subsets)]
    339 return self._dbunch_type(*dls, path=path, device=device)

File ~/fastai/fastai/data/core.py:97, in TfmdDL.new(self, dataset, cls, **kwargs)
     95 if not hasattr(self, '_n_inp') or not hasattr(self, '_types'):
     96     try:
---> 97         self._one_pass()
     98         res._n_inp,res._types = self._n_inp,self._types
     99     except Exception as e: 

File ~/fastai/fastai/data/core.py:80, in TfmdDL._one_pass(self)
     78 b = self.do_batch([self.do_item(None)])
     79 if self.device is not None: b = to_device(b, self.device)
---> 80 its = self.after_batch(b)
     81 self._n_inp = 1 if not isinstance(its, (list,tuple)) or len(its)==1 else len(its)-1
     82 self._types = explode_types(its)

File /opt/conda/lib/python3.10/site-packages/fastcore/transform.py:208, in Pipeline.__call__(self, o)
--> 208 def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)

File /opt/conda/lib/python3.10/site-packages/fastcore/transform.py:158, in compose_tfms(x, tfms, is_enc, reverse, **kwargs)
    156 for f in tfms:
    157     if not is_enc: f = f.decode
--> 158     x = f(x, **kwargs)
    159 return x

File ~/fastai/fastai/vision/augment.py:48, in RandTransform.__call__(self, b, split_idx, **kwargs)
     43 def __call__(self, 
     44     b, 
     45     split_idx:int=None, # Index of the train/valid dataset
     46     **kwargs
     47 ):
---> 48     self.before_call(b, split_idx=split_idx)
     49     return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b

File ~/fastai/fastai/vision/augment.py:479, in AffineCoordTfm.before_call(self, b, split_idx)
    477 while isinstance(b, tuple): b = b[0]
    478 self.split_idx = split_idx
--> 479 self.do,self.mat = True,self._get_affine_mat(b)
    480 for t in self.coord_fs: t.before_call(b)

File ~/fastai/fastai/vision/augment.py:492, in AffineCoordTfm._get_affine_mat(self, x)
    490 aff_m = _init_mat(x)
    491 if self.split_idx: return _prepare_mat(x, aff_m)
--> 492 ms = [f(x) for f in self.aff_fs]
    493 ms = [m for m in ms if m is not None]
    494 for m in ms: aff_m = aff_m @ m

File ~/fastai/fastai/vision/augment.py:492, in <listcomp>(.0)
    490 aff_m = _init_mat(x)
    491 if self.split_idx: return _prepare_mat(x, aff_m)
--> 492 ms = [f(x) for f in self.aff_fs]
    493 ms = [m for m in ms if m is not None]
    494 for m in ms: aff_m = aff_m @ m

File ~/fastai/fastai/vision/augment.py:722, in rotate_mat(x, max_deg, p, draw, batch)
    720 def _def_draw(x):   return x.new_empty(x.size(0)).uniform_(-max_deg, max_deg)
    721 def _def_draw_b(x): return x.new_zeros(x.size(0)) + random.uniform(-max_deg, max_deg)
--> 722 thetas = _draw_mask(x, _def_draw_b if batch else _def_draw, draw=draw, p=p, batch=batch) * math.pi/180
    723 return affine_mat(thetas.cos(), thetas.sin(), t0(thetas),
    724                  -thetas.sin(), thetas.cos(), t0(thetas))

File ~/fastai/fastai/vision/augment.py:568, in _draw_mask(x, def_draw, draw, p, neutral, batch)
    566 ""Creates mask_tensor based on `x` with `neutral` with probability `1-p`. ""
    567 if draw is None: draw=def_draw
--> 568 if callable(draw): res=draw(x)
    569 elif is_listy(draw):
    570     assert len(draw)>=x.size(0)

File ~/fastai/fastai/vision/augment.py:720, in rotate_mat.<locals>._def_draw(x)
--> 720 def _def_draw(x):   return x.new_empty(x.size(0)).uniform_(-max_deg, max_deg)

File ~/fastai/fastai/torch_core.py:406, in TensorBase.new_empty(self, dtype, layout, device, pin_memory, requires_grad, *size)
    404 def new_empty(self, *size, dtype=None, layout=None, device=None, pin_memory=False, requires_grad=False):
    405     cls = type(self)
--> 406     return self.as_subclass(Tensor).new_empty(*size, dtype=dtype, layout=layout, device=device, pin_memory=pin_memory, requires_grad=requires_grad).as_subclass(cls)

TypeError: new_empty(): argument 'layout' must be torch.layout, not NoneType
```",hey appreciate taking look running version python version latest commit reproducible example following stack trace python recent call last cell line block learn learner file self source path verbose source verbose return file self shuffle path device merge none else none false merge range return file merge none else none false merge range return file self self self try except exception file self none none list else file self self return file reverse return file self self index return super else file self true file self return none file return none file draw batch return return batch else return file draw neutral batch based neutral probability draw none callable draw draw assert draw file return file self layout device size self size type self return tensor size argument must,issue,positive,positive,neutral,neutral,positive,positive
1446863574,@tttiago the `TensorBase` deepcopy error should be resolved in the next fastai release with #3882.,error resolved next release,issue,negative,neutral,neutral,neutral,neutral,neutral
1446860806,"Hi @csaroff, since it looks like fastai batch augmentation is where the error came from, I just re-ran some tests with with them, but failed to reproduce this error with `TensorBase.new_empty` using the latest fastai commit. Can you provide a reproducible example? What version of PyTorch are you using?

You are correct, the 1.13.1 docs state the default in [`Tensor.new_empty`](https://pytorch.org/docs/stable/generated/torch.Tensor.new_empty.html) is `layout=torch.strided`. However, both the signatures and what I think is the [python definition](https://github.com/pytorch/pytorch/blob/49444c3e546bf240bed24a101e747422d1f8a0ee/torch/_refs/__init__.py#L3669) do not.

Here's the 1.13.1 signatures for both overloads (as reported by VSCode):
```python
def new_empty(
    size: Sequence[_int | SymInt],
    *,
    dtype: _dtype | None = None,
    layout: _layout | None = None,
    device: _device | str | None = None,
    pin_memory: _bool | None = False,
    requires_grad: _bool | None = False
) -> Tensor: ...

def new_empty(
    *size: _int,
    dtype: _dtype | None = None,
    layout: _layout | None = None,
    device: _device | str | None = None,
    pin_memory: _bool | None = False,
    requires_grad: _bool | None = False
) -> Tensor: ...
```
And here is my test code running on the latest fastai commit on 1.31.1 with Cuda 11.7:
```python
from fastai.vision.all import *

imagenette = untar_data(URLs.IMAGENETTE_160)

block = DataBlock(
    blocks=(ImageBlock, CategoryBlock),
    splitter=GrandparentSplitter(valid_name='val'),
    get_items=get_image_files, get_y=parent_label,
    item_tfms=Resize(128),
    batch_tfms=[*aug_transforms(flip_vert=True, max_rotate=45, max_warp=0.3, xtra_tfms=[Hue(), Saturation()]),
                Normalize.from_stats(*imagenet_stats)],
)
dls = block.dataloaders(imagenette, bs=128, num_workers=num_cpus(), pin_memory=True)

learn = Learner(dls, xresnext18(n_out=dls.c))
learn.fit_one_cycle(5, 3e-4)
```",hi since like batch augmentation error came reproduce error latest commit provide reproducible example version correct state default however think python definition python size sequence none none layout none none device none none none false none false tensor size none none layout none none device none none none false none false tensor test code running latest commit python import block hue saturation learn learner,issue,negative,negative,negative,negative,negative,negative
1445627083,Many thanks @warner-benjamin  -- great job getting this sorted out.,many thanks great job getting sorted,issue,positive,positive,positive,positive,positive,positive
1445234222,"So this is an issue with torchvision and the depeacated ""pretrained"" keyword and I suspect that create_body was updated to take this into account. The proper line for the function call should now be:

`encoder = create_body(resnet34(weights=""IMAGENET1K_V1""), cut=-2)`

 to make the siamese example work as expected with reasonable fine-tuning accuracy.

That said, some description to clarify how the create_body is adapted wouldn't go amiss, since it looks like you'll need to specify what pre-trained weights you're using from now on. I'm not sure if I'm understanding all of the changes to the functions, but I'd be happy to update the tutorial with a little explanation for this. ",issue suspect take account proper line function call make example work reasonable accuracy said description clarify would go amiss since like need specify sure understanding happy update tutorial little explanation,issue,positive,positive,positive,positive,positive,positive
1441137932,"ok cool, apologies to write 'class', I'm thinking of the notebook/module area and should take better care to use the right terminology, my mistake. Good to know tests within the vision_core section will suffice, thanks for your help 😄 ",cool write thinking area take better care use right terminology mistake good know within section suffice thanks help,issue,positive,positive,positive,positive,positive,positive
1441135139,"@nglillywhite [`vision_learner`](https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L209) isn't a class, but rather a method which returns a `Learner` instance.

Assuming the issue is with vision_core, then it would probably suffice to create a test like this current one, except passing a `PILImage` to `PILImage.create`

```python
timg = TensorImage(image2tensor(im))
tpil = PILImage.create(timg)
```
as `Learner.predict` will eventually call `PILImage.create` with whatever was passed to it. (Assuming a standard fastai ImageBlock setup).",class rather method learner instance assuming issue would probably suffice create test like current one except passing python eventually call whatever assuming standard setup,issue,positive,neutral,neutral,neutral,neutral,neutral
1441109903,"Hey @warner-benjamin,

I've managed to recreate the error, 2.7.10 works, and 2.7.11 creates this `AttributeError: read`

I'll dig into vision_core and make the changes and tests to cover this.

Is it appropriate to create a predict() test within the vision_learner class and replicate this circumstance despite changes being within the vision_core code? Seems like a cheap way to check/cover a vision learner taking in multiple types but I also don't want to break testing conventions if this isn't the fastai way to test and I should only be testing within the module I've made changes.",hey recreate error work read dig make cover appropriate create predict test within class replicate circumstance despite within code like cheap way vision learner taking multiple also want break testing way test testing within module made,issue,negative,positive,positive,positive,positive,positive
1439528953,"Happy to take this one up, will checkout the links and suggest a path forward 😀",happy take one link suggest path forward,issue,positive,positive,positive,positive,positive,positive
1432595086,"I'll take a look. Maybe i had some uncommited code so didn't see this failure locally

PS: the output on running locally doesn't match the curent cached outputs on unchanged cells. Is something an issue with my local setup?",take look maybe code see failure locally output running locally match unchanged something issue local setup,issue,negative,negative,neutral,neutral,negative,negative
1430663921,Hmmm yes the previous logic does seem a bit odd...,yes previous logic seem bit odd,issue,negative,negative,negative,negative,negative,negative
1430663446,"Many thanks for the great PR! We're actually moving away from having 3rd party integrations directly in fastai, to instead keeping them in separate projects. Would you be able to create a `fastai-galileo` project for this instead?",many thanks great actually moving away party directly instead keeping separate would able create project instead,issue,positive,positive,positive,positive,positive,positive
1430347312,"I missed that TabularPandas and tabular Batch Transforms set `to` as an object, so my followup commit should be compatible with TabularPandas.",tabular batch set object commit compatible,issue,negative,neutral,neutral,neutral,neutral,neutral
1424869705,Looks like there's a CI failure - do you want to take a look?,like failure want take look,issue,negative,negative,negative,negative,negative,negative
1422376663,"> This arises due to a documented limitation in the Pickle Library itself. Here is the list of supported items that can be pickled : [items](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled) The Splitter functions returns another local function called _inner() , which violates the condition that the function must be on the top level only.
> 
> Here is a potential fix [Very hacky, not recommended] : https://stackoverflow.com/a/61879723
> 
> Edit : Thought of a better solution: Instead of creating a closure, we can define a class of Spliiter and create a callable object (using **call** method) to avoid breaking any code based on current version. The direct advantage is that being an object it will help in pickling objects of all the splitter classes.
> 
> ```
> class RSClass():
>     def __init__(self,valid_pct=0.2, seed=None ):
>         self.valid_pct = valid_pct
>         self.seed = seed
>         
>     def __call__(self,o):
>         if self.seed is not None: torch.manual_seed(self.seed)
>         rand_idx = L(list(torch.randperm(len(o)).numpy()))
>         cut = int(self.valid_pct * len(o))
>         return rand_idx[cut:],rand_idx[:cut]
> ```
> 
> If this looks like a good enough solution I can shoot a PR, with a base class Splitter and all the splitter variations inheriting from it.

looks good to me!",due limitation pickle library list splitter another local function condition function must top level potential fix hacky edit thought better solution instead closure define class create callable object call method avoid breaking code based current version direct advantage object help splitter class class self seed self none list cut return cut cut like good enough solution shoot base class splitter splitter good,issue,positive,positive,positive,positive,positive,positive
1422375795,"Workaround copied from @zillionare kaggle notebook:

```python
class MyRandomSplitter:
    def __init__(self, valid_pct:float=0.2, seed:int=None):
        self.valid_pct = valid_pct
        self.seed = seed

    def __call__(self, o):
        if self.seed is not None: torch.manual_seed(self.seed)
        rand_idx = L(list(torch.randperm(len(o)).numpy()))
        cut = int(self.valid_pct * len(o))
        return rand_idx[cut:],rand_idx[:cut]
```",copied notebook python class self seed seed self none list cut return cut cut,issue,positive,neutral,neutral,neutral,neutral,neutral
1419221272,Could anyone help me to create a dataset for .dcm file in python?,could anyone help create file python,issue,positive,neutral,neutral,neutral,neutral,neutral
1408623413,"Thanks for taking the time, it seems like I'm a bit obsolete! Maybe this is a good excuse to finally look into nbdev a bit.",thanks taking time like bit obsolete maybe good excuse finally look bit,issue,positive,positive,positive,positive,positive,positive
1402387494,@jph00 If the image path was changed to `nbs/images/layered.png` in `index.ipynb` it will not work in the notebook but will work in the `README` file. I guess leaving it as it is now might be the best option.,image path work notebook work file guess leaving might best option,issue,positive,positive,positive,positive,positive,positive
1400968366,"This is an nbdev project so changes need to be made in the source notebook. Shall I do that, or would you like to? ",project need made source notebook shall would like,issue,negative,neutral,neutral,neutral,neutral,neutral
1399587621,"Correction, the icevision stuff seems to be working. I will use that for now.",correction stuff working use,issue,negative,neutral,neutral,neutral,neutral,neutral
1399097197,Can you make sure you are running the code in the correct environment?,make sure running code correct environment,issue,negative,positive,positive,positive,positive,positive
1398908834,"@HenryDashwood I've done so on Walk with fastai, see here: https://walkwithfastai.com/tab.export (sadly on the PR it got lost on time so it didn't quite get merged 😢 )",done walk see sadly got lost time quite get,issue,negative,negative,negative,negative,negative,negative
1398750866,"`np.int` has been [deprecated](https://numpy.org/doc/stable/release/1.20.0-notes.html#using-the-aliases-of-builtin-types-like-np-int-is-deprecated), so this bug seems valid.

Running `np.int = np.int32` before constructing the dataloader might work as a temporary workaround.

I'm not confident in suggesting a fix because I'm not sure I understand the logic of the crashing code. (Why should `sys.platform` matter?) Perhaps something like `if isinstance(x.dtype, np.integer): x = x.astype(np.int64, copy=False)`, relying on the [NumPy type hierarchy](https://numpy.org/doc/stable/reference/arrays.scalars.html#numpy.integer) and [`astype`](https://numpy.org/doc/stable/reference/generated/numpy.ndarray.astype.html#numpy.ndarray.astype)?
",bug valid running might work temporary confident suggesting fix sure understand logic code matter perhaps something like type hierarchy,issue,positive,positive,positive,positive,positive,positive
1398690204,I think this feature may have been deprecated or never merged. The `export` method isn't there in the master branch. Is this not a good way to reapply the TabularPandas processes on new data in e.g. production?,think feature may never export method master branch good way reapply new data production,issue,negative,positive,positive,positive,positive,positive
1377749577,"Thanks for the PR. Since this is an nbdev project, any changes need to be made in the source notebook, and then exported to the .py files.",thanks since project need made source notebook,issue,negative,positive,positive,positive,positive,positive
1374143180,Thanks for the PR. I think I'd rather just let people use plt.savefig directly themselves rather than add this to the method.,thanks think rather let people use directly rather add method,issue,negative,positive,positive,positive,positive,positive
1373703735,"It works! Thanks for your help. But there is one more question. The numbers in the first 5 lines of `train_loss` are '00:00', which seems to be listed in the column of `time`.",work thanks help one question first listed column time,issue,positive,positive,positive,positive,positive,positive
1371638467,"@amoghvaishampayan Also saw the same thing. I am not sure if this part of the Fastai doc but I was able to access the Colab notebooks through https://course.fast.ai/Resources/book.html.

Particularly on the homepage > Welcome to fastai section > ""[Using Colab](https://course.fast.ai/start_colab) for more information"" redirects to a 404 File Not Found error

Depending on what you are using Fastai for, I think the content itself may be a bit different. Another reference: https://forums.fast.ai/t/beginner-setup/95289/41

Edit: If you choose to use something separate from Google Colab, check out the following such as Kaggle Notebook: https://course.fast.ai/Lessons/lesson1.html
",also saw thing sure part doc able access particularly welcome section information file found error depending think content may bit different another reference edit choose use something separate check following notebook,issue,negative,positive,positive,positive,positive,positive
1370776927,"I hit the same issue and here's my version info:

```text
=== Software === 
python       : 3.9.15
fastai       : 2.7.10
fastcore     : 1.5.27
fastprogress : 1.0.3
torch        : 1.13.0
torch cuda   : None / is **Not available** 

=== Hardware === 
No GPUs available 

=== Environment === 
platform     : macOS-13.1-arm64-arm-64bit
conda env    : ml
python       : /opt/homebrew/anaconda3/envs/ml/bin/python
sys.path     : /Users/simon/Programs/ML
/opt/homebrew/anaconda3/envs/ml/lib/python39.zip
/opt/homebrew/anaconda3/envs/ml/lib/python3.9
/opt/homebrew/anaconda3/envs/ml/lib/python3.9/lib-dynload
/opt/homebrew/anaconda3/envs/ml/lib/python3.9/site-packages
no supported gpus found on this system

Please make sure to include opening/closing 
```

And here's my code
```
from fastai.vision.all import *
path = untar_data(URLs.PETS)/'images'

def is_cat(x): return x[0].isupper()
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224)
)
dls.device=torch.device('mps')
learn = vision_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(1)
```",hit issue version text python torch torch none available hardware available environment platform python found system please make sure include code import path return path path learn,issue,positive,positive,positive,positive,positive,positive
1367288998,"> > same problem here.
> > training and export of fastaiV2 model on windows. created App with Streamlit. on local Windows machine running smooth. Deployed on https://share.streamlit.io/ error ""NotImplementedError: cannot instantiate 'WindowsPath' on your system""
> > Any help appreciated ! thx
> 
> I found a solution for this adding the below to the code:
> 
> ```
> import pathlib
> plt = platform.system()
> if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath
> ```

thanks a lot <3",problem training export model local machine running smooth error system help found solution code import thanks lot,issue,negative,positive,positive,positive,positive,positive
1362579746,"Sounds good, my pleasure.  I am blown away by your intro course, just starting the videos, already life changing, so empowering, after years of reading ML books… ✨🙏✨",good pleasure blown away course starting already life reading,issue,positive,positive,positive,positive,positive,positive
1362233340,"Thanks! This is an nbdev project, so the source code lives in the notebooks, and the py modules are generated from there. Would you be able to modify the source notebook? (If not, just let me know, and I'll do it myself).",thanks project source code would able modify source notebook let know,issue,negative,positive,positive,positive,positive,positive
1360865753,"Many thanks for the PR. The README is actually built from a notebook, and making this change in the notebook would break the image there! I'll copy the image over to fix it.",many thanks actually built notebook making change notebook would break image copy image fix,issue,negative,positive,positive,positive,positive,positive
1356445849,"The Callback tries to index into the recorded loss-lists which might be empty for the skipped epochs, skipping them should fix the issue:
```python
@patch
def after_epoch(self:ShowGraphCallback):
        ""Plot validation loss in the pbar graph""
        if not self.nb_batches: return
        rec = self.learn.recorder
        iters = range_of(rec.losses)
        val_losses = [v[1] for v in rec.values if v!=[]] ## skip empty lists
        x_bounds = (0, (self.n_epoch - len(self.nb_batches)) * self.nb_batches[0] + len(rec.losses))
        y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(val_losses)))))
        self.progress.mbar.update_graph([(iters, rec.losses), (self.nb_batches, val_losses)], x_bounds, y_bounds)
```

This leaves a lot of empty space in the plot, since the Callback still takes the skipped train iterations into account:

![Screenshot from 2022-12-17 20-42-33](https://user-images.githubusercontent.com/64742466/208263662-bf737ddb-4313-4aa4-be3a-34451e6661f2.png)

Besides that the train loss and the validation loss count the training iterations differently which results in the curves not being aligned (if you look close enough):

![Screenshot from 2022-12-17 20-43-05](https://user-images.githubusercontent.com/64742466/208263702-ba9e4646-0d50-42b1-9fd7-09e6f35fe006.png)

If any of that bothers you, you can use this code:
```python
class ShowGraphCallback(Callback):
    ""Update a graph of training and validation loss""
    order,run_valid=65,False

    def before_fit(self):
        self.run = not hasattr(self.learn, 'lr_finder') and not hasattr(self, ""gather_preds"")
        if not(self.run): return
        self.nb_batches = []
        assert hasattr(self.learn, 'progress')
        skip_cbs = self.learn._grab_cbs(SkipToEpoch)
        self._skip_to = skip_cbs[0]._skip_to if skip_cbs else 0 ## grab number of skipped epochs
            
    def after_train(self): 
        self.nb_batches.append(self.train_iter)

    def after_epoch(self):
        ""Plot validation loss in the pbar graph""
        if not self.nb_batches: return
        rec = self.learn.recorder
        iters = range_of(rec.losses)
        val_losses = [v[1] for v in rec.values if v!=[]]
        x_bounds = (0, (self.n_epoch - self._skip_to - len(self.nb_batches)) * (self.nb_batches[0]) + len(rec.losses) - 1)
        y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(val_losses)))))
        self.progress.mbar.update_graph([(iters, rec.losses), (np.array(self.nb_batches)-1, val_losses)], x_bounds, y_bounds)
```
which creates this plot:

![Screenshot from 2022-12-17 20-54-02](https://user-images.githubusercontent.com/64742466/208263875-d8396ae7-140b-4ab9-95e2-21b3d820ae68.png)


I also made a [gist](https://gist.github.com/Ben-Karr/c0f7809808e0719590067d242b1bbc01) if someone wants to have a quick go at the code. Let me know if that works for you so I can make a PR.

",index might empty skipping fix issue python patch self plot validation loss graph return skip empty tensor tensor leaf lot empty space plot since still train account besides train loss validation loss count training differently look close enough use code python class update graph training validation loss order false self self return assert else grab number self self plot validation loss graph return tensor tensor plot also made gist someone quick go code let know work make,issue,negative,negative,neutral,neutral,negative,negative
1347603223,I'm replacing `list` in all types I can find with `MutableSequence` now FYI and will push shortly.,list find push shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
1347417009,"I have most of them done already, just need some clarification on the `Callback|list` change.",done already need clarification change,issue,negative,neutral,neutral,neutral,neutral,neutral
1347411431,"Let me know which would be easier/preferred - I can merge this PR as is, and make the type changes on my end, or I you can change them in this PR.",let know would merge make type end change,issue,negative,neutral,neutral,neutral,neutral,neutral
1344802977,Many thanks @warner-benjamin -- let me know if you have any outstanding questions.,many thanks let know outstanding,issue,positive,positive,positive,positive,positive,positive
1343751718,Will change any of the type hints to what you want. I tried to follow the convention set by #3639 and attempted to add some clarity. I added a few comments and questions on the code review.,change type want tried follow convention set add clarity added code review,issue,negative,neutral,neutral,neutral,neutral,neutral
1343331733,"@jph00 The CI failure appears to be random and due to a change made in the development branch of nbdev, which the fastai CI currently uses.

My updated passed the CI, but would have been safe to merge even if it did not, as I tested it with nbdev 2.3.9 and it passed every time.",failure random due change made development branch currently would safe merge even tested every time,issue,negative,negative,neutral,neutral,negative,negative
1340921825,"It seems like the previous courses had the ""Notebook servers"" section on their menu, and this year's course doesn't have it. As this year's course is now the only course on course.fast.ai and the 2020 course moved to course**20**.fast.ai, the link is dead. 

I suggest either directing the link to this page https://course20.fast.ai/start_colab or add the same section to the current course. Not sure what's better. ",like previous notebook section menu year course year course course course course link dead suggest either link page add section current course sure better,issue,negative,positive,positive,positive,positive,positive
1337000557,Simple summary: The code in the documentation is wrong.,simple summary code documentation wrong,issue,negative,negative,negative,negative,negative,negative
1336484047,"Hi @hengee , It's almost same implementation here, But difference is that giving the input for neural network. In first case , it's showing sentence encoder classification. in second case , they are using senentence encoder and poolinglinearclassifier as input of neural network in sequentinal format.  Both are classification model of text. ",hi almost implementation difference giving input neural network first case showing sentence classification second case input neural network format classification model text,issue,negative,positive,positive,positive,positive,positive
1336257197,"When I run the tests locally, CI error does not occur. I also did not change anything related to default callbacks. Investigating.",run locally error occur also change anything related default investigating,issue,negative,neutral,neutral,neutral,neutral,neutral
1336124601,"Hey @casmli169 , I am unable to find exact solution . But, I have alternative solution to use same attribute functionality.
`ImageDataLoaders.from_csv(path, 'train.csv', folder='train', valid_col='is_valid',splitter=RandomSplitter(0.2,seed=10))`
It might be help you.
Thanks!!",hey unable find exact solution alternative solution use attribute functionality path might help thanks,issue,positive,negative,neutral,neutral,negative,negative
1336111268,"> [https://course.fast.ai/start_colab](url) on https://docs.fast.ai/ gives 404


please clear your browser caches. it's help you.

",please clear browser help,issue,positive,positive,positive,positive,positive,positive
1332271227,"Any changes to this? facing same issue, unet_learner won't work in DataParallel. Doesnt work with DDP either.",facing issue wo work doesnt work either,issue,negative,neutral,neutral,neutral,neutral,neutral
1328316465,"Many thanks @bencoman . I think you need a blank line before your list to make it appear correctly. I suggest removing the name of each output, since they don't really have names (it's an unnamed tuple). Also you might want to add the `with_input` optional output to the list.
",many thanks think need blank line list make appear correctly suggest removing name output since really unnamed also might want add optional output list,issue,negative,positive,positive,positive,positive,positive
1328180374,"I'm not sure why this dff showed up. I didn't consciously make a change there.
![image](https://user-images.githubusercontent.com/1713447/204122163-25c643e2-a8ff-4f13-a648-2d0c1fbcb049.png)
",sure consciously make change image,issue,negative,positive,positive,positive,positive,positive
1317833766,"> > > > same problem here.
> > > > training and export of fastaiV2 model on windows. created App with Streamlit. on local Windows machine running smooth. Deployed on https://share.streamlit.io/ error ""NotImplementedError: cannot instantiate 'WindowsPath' on your system""
> > > > Any help appreciated ! thx
> > > 
> > > 
> > > I found a solution for this adding the below to the code:
> > > ```
> > > import pathlib
> > > plt = platform.system()
> > > if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath
> > > ```
> > 
> > 
> > Where should we add this? I tried adding this line of code but I got an error - `Name platform is not defined`
> 
> Same error here, what's your OS ?
> 
> #Edit 1, I just used this below from imports, with this change it does run only in Hugging Face (I'm using Windows)
> 
> ```python
> import pathlib
> plt = platform.system()
> if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath
> ```

I was using Linux! ",problem training export model local machine running smooth error system help found solution code import add tried line code got error name platform defined error o edit used change run hugging face python import,issue,negative,positive,positive,positive,positive,positive
1314376933,"@jph00 not sure where the diff is coming in, `nbdev_export` shows nothing new changing when building from 2.3.9 and 2.3.10 😕 ",sure coming nothing new building,issue,negative,positive,positive,positive,positive,positive
1313956923,@caleb-depotanalytics can you verify using `pip install git+https://github.com/muellerzr/fastai@fix-save` fixes this for you? Thanks!,verify pip install thanks,issue,negative,positive,positive,positive,positive,positive
1313909863,"@caleb-depotanalytics can you post the full trace for me? I received something like:
```python
Traceback (most recent call last):
  File ""/home/zach_mueller_huggingface_co/fastai_bug.py"", line 19, in <module>
    learn.fit_flat_cos(2, 1e-3, cbs=[SaveModelCallback()])
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/callback/schedule.py"", line 142, in fit_flat_cos
    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=0)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/learner.py"", line 256, in fit
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/learner.py"", line 195, in _with_events
    self(f'after_{event_type}');  final()
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/learner.py"", line 171, in __call__
    def __call__(self, event_name): L(event_name).map(self._call_one)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastcore/foundation.py"", line 156, in map
    def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastcore/basics.py"", line 840, in map_ex
    return list(res)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastcore/basics.py"", line 825, in __call__
    return self.func(*fargs, **kwargs)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/learner.py"", line 175, in _call_one
    for cb in self.cbs.sorted('order'): cb(event_name)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/callback/core.py"", line 62, in __call__
    except Exception as e: raise modify_exception(e, f'Exception occured in `{self.__class__.__name__}` when calling event `{event_name}`:\n\t{e.args[0]}', replace=True)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/callback/core.py"", line 60, in __call__
    try: res = getcallable(self, event_name)()
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/callback/tracker.py"", line 109, in after_fit
    elif not self.every_epoch: self.learn.load(f'{self.fname}', with_opt=self.with_opt)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/learner.py"", line 411, in load
    load_model(file, self.model, self.opt, device=device, **kwargs)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/fastai/learner.py"", line 50, in load_model
    state = torch.load(file, map_location=device, **torch_load_kwargs)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/torch/serialization.py"", line 712, in load
    return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/torch/serialization.py"", line 1049, in _load
    result = unpickler.load()
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/torch/serialization.py"", line 1019, in persistent_load
    load_tensor(dtype, nbytes, key, _maybe_decode_ascii(location))
  File ""/home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/lib/python3.9/site-packages/torch/serialization.py"", line 997, in load_tensor
    storage = zip_file.get_storage_from_record(name, numel, torch._UntypedStorage).storage()._untyped()
RuntimeError: Exception occured in `SaveModelCallback` when calling event `after_fit`:
        PytorchStreamReader failed reading file data/10: file read failed
ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 1) local_rank: 1 (pid: 77669) of binary: /home/zach_mueller_huggingface_co/miniconda3/envs/accelerate/bin/python
```
And I want to make sure you also got this",post full trace received something like python recent call last file line module file line file line fit file line self final file line self file line map map self return self file line return list file line return file line file line except exception raise calling event file line try self file line file line load file file line state file file line load return file line result file line key location file line storage name exception calling event reading file file read error binary want make sure also got,issue,positive,positive,positive,positive,positive,positive
1311444664,@Monk5088 I think its the `lambda x: x.y` that causes this. Try replacing that with a regularly defined function,monk think lambda try regularly defined function,issue,negative,neutral,neutral,neutral,neutral,neutral
1305055743,"Hello everyone, 
I am having an issue with the dataloader while exporting the pkl file, any idea? I am using icevision on googl
![Screenshot 2022-11-06 205628](https://user-images.githubusercontent.com/13992604/200224776-2c767683-29b2-4300-8a2e-ea9422105e64.png)
e colab 
",hello everyone issue file idea,issue,negative,neutral,neutral,neutral,neutral,neutral
1299110095,"Many thanks. The README is autogenerated from index.ipynb, so we need to fix it there too. Would you be able to make that change?",many thanks need fix would able make change,issue,negative,positive,positive,positive,positive,positive
1298497620,"Sounds like this is an underlying pytorch issue, is there an open bug or PR on pytorch anyone is aware of? I just picked up fastai the other day and ran face first into this.

The `learn.remove_cb(ProgressCallback)` allows learning to at least process thought I don't know what it's doing. But printing formatted outputs from tutorials also needs to be modified to just dump the tensor object instead of formatting it as well, so I'm just playing whack-a-mole to get output.",like underlying issue open bug anyone aware picked day ran face first learning least process thought know printing also need dump tensor object instead well get output,issue,negative,positive,neutral,neutral,positive,positive
1297957139,"Looks like this is a regression from the following pytorch commit:
pytorch/pytorch@3c2c2cc

`Tensor.__format__` previously handled formatting correctly for all non-meta 0-dimensional tensor instances:
```
if self.dim() == 0 and not self.is_meta:
            return self.item().__format__(format_spec)
```
However, an additional check was added, preventing this path from being exercised for instances of subclasses of `Tensor` (such as `fastai.torch_core.TensorBase`):
```
if self.dim() == 0 and not self.is_meta and type(self) is Tensor:
            return self.item().__format__(format_spec)
```",like regression following commit previously handled correctly tensor return however additional check added path tensor type self tensor return,issue,positive,negative,neutral,neutral,negative,negative
1297938317,Updated to use the [nbdev-ci workflow](https://github.com/fastai/workflows/tree/master/nbdev-ci) per feedback on the fastai discord,use per feedback discord,issue,negative,neutral,neutral,neutral,neutral,neutral
1297937040,The CI error here should be resolved when #3828 is merged into the master branch.,error resolved master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
1297867971,"Wait, I think you wanted me to have both changes. My bad! Will merge this branch into the other.",wait think bad merge branch,issue,negative,negative,negative,negative,negative,negative
1296507431,"Many thanks for your PR. fastai is an nbdev project, which means that the notebooks are the source files, and the .py files are generated from them. Could you please update the source notebooks with your changes?",many thanks project source could please update source,issue,positive,positive,positive,positive,positive,positive
1295988286,"I had the same problem with fastai 2.7.9, fastcore 1.5.27, PyTorch 1.13.0 on macOS Ventura 13.0. The problem is caused by this:
```
File ~/mambaforge/lib/python3.10/site-packages/fastai/callback/progress.py:33, in ProgressCallback.after_batch(self)
     31 def after_batch(self):
     32     self.pbar.update(self.iter+1)
---> 33     if hasattr(self, 'smooth_loss'): self.pbar.comment = f'{self.smooth_loss:.4f}'
```

The `smooth_loss` value cannot be converted properly in the format string (because it looks like [Tensor doesn't support format](https://discuss.pytorch.org/t/typeerror-unsupported-format-string-passed-to-tensor-format/62650)):
```
>>> learn.smooth_loss
TensorBase(0.0595)
>>> f'{learn.smooth_loss:.4f}'
...
TypeError: unsupported format string passed to TensorBase.__format__
```

It can be fixed by extracting the value of `smooth_loss` first with `item`:
```
>>> f'{learn.smooth_loss.item():.4f}'
'0.0595'
```

Hacking site-packages/fastai/callback/progress.py with this change fixed the problem.",problem problem file self self self value converted properly format string like tensor support format unsupported format string fixed value first item hacking change fixed problem,issue,negative,positive,positive,positive,positive,positive
1293609052,"I have the same issue. Also, in my case, the workaround does not work.",issue also case work,issue,negative,neutral,neutral,neutral,neutral,neutral
1287589053,"I think the problem occurs because when you export your Learner(Learner.export), in the notebook or the environment there is some function or class that used `spacy.lemmatizer`. When you try to load using `load_learner`, it looks for that object in the environment where you are trying to load it.

To solve that problem you just need to declare the functions that require `spacy.lemmatizer` before `load_learner`",think problem export learner notebook environment function class used try load object environment trying load solve problem need declare require,issue,negative,neutral,neutral,neutral,neutral,neutral
1286480790,"Modified the code to cover the edge case
```
t1 = _T([[1.,2.]], kw=1)
test_eq(t1.__dict__,{'kw': 1})
l1 = torch.unbind(t1)
test_eq(l1[0].__dict__,{'kw': 1})
```
",code cover edge case,issue,negative,neutral,neutral,neutral,neutral,neutral
1285013989,"OK cool I'll merge this now then, but feel free to do followup PRs if you have more ideas.",cool merge feel free,issue,positive,positive,positive,positive,positive,positive
1285003315,"It definitely is an improvement. I have created a new thread on the forum https://forums.fast.ai/t/add-check-to-add-norm-3820-pr/101344 as this whole normalisation business is definitely worth discussing. I will also run some experiments comparing norm using imagenet_stats vs actual stats from the dataset being used (particularly when they're different from imagined_stats like MNIST) vs no normalisation at all (with freezing/unfreezing of batch norm layers, which should be able to fix any issues with non normalised inputs...maybe).",definitely improvement new thread forum whole business definitely worth also run norm actual used particularly different like batch norm able fix non maybe,issue,positive,positive,positive,positive,positive,positive
1284985104,Actually on further consideration I think this PR as is can only be an improvement on the current situation. I wouldn't say I fully understand all the potential impacts though. What do you both think?,actually consideration think improvement current situation would say fully understand potential though think,issue,negative,neutral,neutral,neutral,neutral,neutral
1284659696,"Since it sounds like we're not really sure what the desired behavior is, perhaps I should close this PR, and we can discuss it on the forums or discord, if that's OK?

Generally it's best to use the same normalisation constants used when training the pretrained model, which is why we use that as the default.",since like really sure desired behavior perhaps close discus discord generally best use used training model use default,issue,positive,positive,positive,positive,positive,positive
1283645642,"> You get this error when you change the number of classes, maybe while retraining your U net model with different number of classes.
> I suggest you change the new model instance by using num_of_classes=99
> The model whose pretrained weights you are trying to load has 291 classes whilst yours has 99 only.

Yes; I needed an updated `.pkl` files that worked with the weights `.pth` file. Thanks

[Source](https://forums.fast.ai/t/runtimeerror-error-s-in-loading-state-dict-for-dynamicunet-missing-key-s-in-state-dict-layers-0-4-0-conv3-weight-size-mismatch-for-layers/101088/2?u=danielbell99)",get error change number class maybe net model different number class suggest change new model instance model whose trying load class whilst yes worked file thanks source,issue,positive,positive,neutral,neutral,positive,positive
1283465365,"Right, so I have successfully broken things when trying to fix things... 🤣

Will go with @warner-benjamin suggestion and add `n_in` to ` _add_norm` and `_timm_norm` (need to see if the latter is an issue to begin with or not).

What should be the behaviour in such a case though? Not applying normalization to the inputs of ImageNet pertained model goes against 'common practice' (for lack of better phrase) but not sure if it actually is a problem - the pixels are between 0 and 1 (so they don't take on crazy values like -1234), the networks have normalisation layers everywhere... 

On the other hand inserting a 1-channel normalisation transform with stats based on say the 1st batch might not be the worst idea. I mean, why are we normalizing with ImageNet stats to begin with? If a pertained model expects 0-mean 1-stdev inputs, then using ImageNet stats to normalize say x-ray images quite likely doesn't give you what you want. Although I suppose you at least don't have to calculate the stats for your dataset yourself.

So many questions! 🤯",right successfully broken trying fix go suggestion add need see latter issue begin behaviour case though normalization model go practice lack better phrase sure actually problem take crazy like everywhere hand transform based say st batch might worst idea mean begin model normalize say quite likely give want although suppose least calculate many,issue,negative,negative,neutral,neutral,negative,negative
1283417803,"Congrats on the first PR. Since we were discussing this issue on the fastai discord, I thought I would chime in after looking at the PR.

I think the CI error is due to the new code preventing the automatic conversion of single channel greyscale images to three channel images when the user doesn't specify `n_in=1` to `unet_learner` or `vision_learner`. With the default of `n_in=3`, we want this conversion from single to three channels to occur in the dataloader since the pretrained model will still be expecting three channel inputs.

I think the solution is to add `n_in` to '_add_norm' (and perhaps `_timm_norm`?) and then do a channel consistency check between n_in and the pretrained stats. And raise an error/warning if the two differ.",first since issue discord thought would chime looking think error due new code automatic conversion single channel three channel user specify default want conversion single three occur since model still three channel think solution add perhaps channel consistency check raise two differ,issue,negative,positive,neutral,neutral,positive,positive
1283384720,"I'm reasonably certain the CI error is not related to my PR and it needs to be reran later when the networking issues are resolved.

```
ERROR: Could not install packages due to an OSError: HTTPSConnectionPool(host='files.pythonhosted.org', port=443): Max retries exceeded with url:
```",reasonably certain error related need later resolved error could install due,issue,negative,positive,neutral,neutral,positive,positive
1283377652,"Looks like there's a CI failure - if you have a moment, perhaps you could try running the notebook with the failing test to see what the issue is?",like failure moment perhaps could try running notebook failing test see issue,issue,negative,negative,negative,negative,negative,negative
1283367354,"Congrats on your first PR! :D You didn't do anything silly at all -- or at least, not anything that I can see. Many thanks for your contribution.",first anything silly least anything see many thanks contribution,issue,negative,positive,neutral,neutral,positive,positive
1282917590,"BTW, my first PR *ever* so apologies if done something silly 😳",first ever done something silly,issue,negative,negative,negative,negative,negative,negative
1280643320,"> > same problem here.
> > training and export of fastaiV2 model on windows. created App with Streamlit. on local Windows machine running smooth. Deployed on https://share.streamlit.io/ error ""NotImplementedError: cannot instantiate 'WindowsPath' on your system""
> > Any help appreciated ! thx
> 
> I found a solution for this adding the below to the code:
> 
> ```
> import pathlib
> plt = platform.system()
> if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath
> ```

Where should we add this? I tried adding this line of code but I got an error - `Name platform is not defined`",problem training export model local machine running smooth error system help found solution code import add tried line code got error name platform defined,issue,negative,positive,positive,positive,positive,positive
1280250628,"There are two problem here:
1. You need to modify the way you used the API, according to docs arch need to be a class or callable creating a model (not the model itself as you gave). something like:
```python
from fastai.text.all import *
config = awd_lstm_clas_config.copy()
config.update(emb_sz=10, n_hid=10, n_layers=2)
get_text_classifier(arch=AWD_LSTM, n_class=2, vocab_sz=100, config=config)
```
2. The second problem is the API itself. I don't like the part that I created config `config = awd_lstm_clas_config.copy()` and the next line. I'm going to create PR to solve this issue, so you can use the API like:
```python
from fastai.text.all import *
config = dict(emb_sz=10, n_hid=10, n_layers=2)
get_text_classifier(arch=AWD_LSTM, n_class=2, vocab_sz=100, config=config)
```",two problem need modify way used according arch need class callable model model gave something like python import second problem like part next line going create solve issue use like python import,issue,positive,neutral,neutral,neutral,neutral,neutral
1274394206,"Previously I was not enabled to form dataloader (Fastai) for classification
of data in jupyter notebook now code is running. Can you tell me is there
any code of classification through fastai for test dataset?



On Sat, 7 May 2022, 06:08 Tanishq Abraham, ***@***.***> wrote:

> Please provide more details for us to be able to help you otherwise we'll
> close this issue...
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3555#issuecomment-1120097936>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ASSPV7WJ6P4WA5XSMTZEVNDVIW7ALANCNFSM5MGTGEEA>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",previously form classification data notebook code running tell code classification test sat may wrote please provide u able help otherwise close issue reply directly view id,issue,positive,positive,positive,positive,positive,positive
1272579729,"> Hi @Ben-Karr thanks for the response, yes it now imports so was indeed a typo in the article. However I run into other issues now after importing sucessfully and running the callback.
> 
> ```
> ---------------------------------------------------------------------------
> NameError                                 Traceback (most recent call last)
> Input In [5], in <cell line: 3>()
>       1 #from fastai.callback.comet import CometMLCallback
> ----> 3 comet_ml_callback = CometCallback('organic_palace_xxxx)  # specify project
>       5 learn = Learner(dls, resnet18,cbs=comet_ml_callback)
>       8 learn.fit_one_cycle(1)
> 
> File ~\Anaconda3\lib\site-packages\fastai\callback\comet.py:24, in CometCallback.__init__(self, project_name, log_model_weights)
>      22 def __init__(self, project_name, log_model_weights=True):
>      23     self.log_model_weights = log_model_weights
> ---> 24     self.keep_experiment_running = keep_experiment_running
>      25     self.project_name = project_name
>      26     self.experiment = None
> 
> NameError: name 'keep_experiment_running' is not defined
> ```
> 
> I expriment with commenting out `experiment_running` but creates more issues I think, let me know if I should open another Issue, thanks!

The `keep_experiment_running` is not defined in the function parameter while initializing the class I am not familiar with fast.ai's architecture but if you need `keep_experiment_running` you have to define it in initialization function like 

```
def __init__(self:CometCallback, project_name, log_model_weights=True, keep_experiment_running= #whatever value type is necessary):
        self.log_model_weights = log_model_weights
        self.keep_experiment_running = keep_experiment_running
        self.project_name = project_name
        self.experiment = None
```

and then
you will have to add a default value or add value when calling the function 

and while I was looking at the code I saw no use of `keep_experiment_running` so commenting it out or removing the whole line shouldn't be a problem",hi thanks response yes indeed typo article however run running recent call last input cell line import specify project learn learner file self self none name defined think let know open another issue thanks defined function parameter class familiar architecture need define function like self whatever value type necessary none add default value add value calling function looking code saw use removing whole line problem,issue,positive,positive,positive,positive,positive,positive
1270725041,"Thanks! BTW it looks like you need to install the hooks yourself, because there's some notebook metadata in your PR... :) ",thanks like need install notebook,issue,positive,positive,positive,positive,positive,positive
1269297232,"I haven't been able to replicate this issue.

I'm on the latest versions of fastai ( `2.7.10`)  and fastcore (` 1.5.28`)so I'm closing this issue.  ",able replicate issue latest issue,issue,negative,positive,positive,positive,positive,positive
1268991823,"NameError: name 'download_images' is not defined
https://colab.research.google.com/drive/1batgL9t9THRTyo03S8qMphnNtLLkG63x#scrollTo=GMQ99cMe8j37&line=2&uniqifier=1
did I do something wrong",name defined something wrong,issue,negative,negative,negative,negative,negative,negative
1266554675,"I don't see where `self.keep_experiment_running` is used in the callback (think it's a copy/paste error from the neptune callback), so I'm confused that commenting it out doesn't work for you.
```python
@patch
def __init__(self:CometCallback, project_name, log_model_weights=True):
        self.log_model_weights = log_model_weights
        #self.keep_experiment_running = keep_experiment_running
        self.project_name = project_name
        self.experiment = None
```
```python
CometCallback('Trying this out')
```
doesn't throw an error for me, but I'm also not familiar with comet_ml, maybe I'm missing something...",see used think error confused work python patch self none python throw error also familiar maybe missing something,issue,negative,negative,neutral,neutral,negative,negative
1262258345,"Hi @Ben-Karr thanks for the response, yes it now imports so was indeed a typo in the article. However I run into other issues now after importing sucessfully and running the callback.


```
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
Input In [5], in <cell line: 3>()
      1 #from fastai.callback.comet import CometMLCallback
----> 3 comet_ml_callback = CometCallback('organic_palace_xxxx)  # specify project
      5 learn = Learner(dls, resnet18,cbs=comet_ml_callback)
      8 learn.fit_one_cycle(1)

File ~\Anaconda3\lib\site-packages\fastai\callback\comet.py:24, in CometCallback.__init__(self, project_name, log_model_weights)
     22 def __init__(self, project_name, log_model_weights=True):
     23     self.log_model_weights = log_model_weights
---> 24     self.keep_experiment_running = keep_experiment_running
     25     self.project_name = project_name
     26     self.experiment = None

NameError: name 'keep_experiment_running' is not defined
```
I expriment with commenting out `experiment_running` but creates more issues I think, let me know if I should open another Issue, thanks!",hi thanks response yes indeed typo article however run running recent call last input cell line import specify project learn learner file self self none name defined think let know open another issue thanks,issue,positive,positive,neutral,neutral,positive,positive
1261762434,"Fixed by adding
`learn.remove_cb(ProgressCallback)`
before fine tuning. 
But can someone look into this bug?
Without the progress bar it is hard to figure out what is happening. ",fixed fine tuning someone look bug without progress bar hard figure happening,issue,negative,positive,neutral,neutral,positive,positive
1259901073,"No script, I ran `nbdev_migrate` against the notebooks and the callout migration worked without issue.

I did lightly modify `migrate_nb` before running because it was converting the markdown H1 titles and blockquote subtitles to frontmatter and was unsure if that's desired behavior.",script ran migration worked without issue lightly modify running converting markdown unsure desired behavior,issue,negative,positive,positive,positive,positive,positive
1259897183,"Great stuff! Did you use a script for this? If so, could you share a link to it since it's likely to be useful for others.",great stuff use script could share link since likely useful,issue,positive,positive,positive,positive,positive,positive
1257814691,"The error states that `CometMLCallback` doesn't exist in the `fastai.callback.comet` module. I think that there is a typo, since I can find `CometCallback`. Does `from fastai.callback.comet import CometCallback` do the trick for you? (Then the docs should be updated...)
",error exist module think typo since find import trick,issue,negative,neutral,neutral,neutral,neutral,neutral
1257230185,@Ben-Karr thanks for coming up with the solution. Would you be able to make a new Pull Request to implement this fix? ☺️,thanks coming solution would able make new pull request implement fix,issue,positive,positive,positive,positive,positive,positive
1257226728,"Normalize tries to calculate `mean` and `std` if they are not given,. This happens when creating the loader, but the `wgts` argument is not set at that moment, so it can not pull a batch to do so and produces the error.
```python
@delegates()
class WeightedDL(TfmdDL):
    ""Weighted dataloader where `wgts` is used for the training set only""
    def __init__(self, dataset=None, bs=None, wgts=None, **kwargs):
        super().__init__(dataset=dataset, bs=bs, **kwargs)
        wgts = array([1.]*len(dataset) if wgts is None else wgts)
        self.wgts = wgts/wgts.sum()
    …
    …
```
Swtiching the order gets rid of the error (for me):
```python
@delegates()
class WeightedDL(TfmdDL):
    ""Weighted dataloader where `wgts` is used for the training set only""
    def __init__(self, dataset=None, bs=None, wgts=None, **kwargs):
        wgts = array([1.]*len(dataset) if wgts is None else wgts)
        self.wgts = wgts/wgts.sum()
        super().__init__(dataset=dataset, bs=bs, **kwargs)


    def get_idxs(self):
        if self.n==0: return []
        if not self.shuffle: return super().get_idxs()
        return list(np.random.choice(self.n, self.n, p=self.wgts))
```",normalize calculate mean given loader argument set moment pull batch error python class weighted used training set self super array none else order rid error python class weighted used training set self array none else super self return return super return list,issue,positive,positive,positive,positive,positive,positive
1253312016,Thanks @TomPham97  I would start working on it then.,thanks would start working,issue,negative,positive,positive,positive,positive,positive
1253122410,"You're right, now it works flawlessly. It didn't though at the moment of submitting the issue.
Thank you!",right work flawlessly though moment issue thank,issue,positive,positive,positive,positive,positive,positive
1252994838,"I tried these codes from the [Fastai data transformation documentation](https://docs.fast.ai/data.transforms.html#normalize) and it ran without raising any error:
```python
mean,std = [0.5]*3,[0.5]*3
mean,std = broadcast_vec(1, 4, mean, std)

dls = dsets.weighted_dataloaders(wgts=wgts, bs=bs, after_item=[Resize(img_size), ToTensor()],
                        after_batch=[IntToFloatTensor(), Normalize.from_stats(mean, std)])
```

I'm not entirely sure why this is the case, but you're welcome to look at [`Normalize` source code](https://github.com/fastai/fastai/blob/master/fastai/data/transforms.py#L364) and see if there's an issue.",tried data transformation documentation ran without raising error python mean mean mean resize mean entirely sure case welcome look normalize source code see issue,issue,positive,positive,neutral,neutral,positive,positive
1252956921,"> @kevin-b1rd are you working on it? If not I would like to take this up.
> 
> Thanks, Ankit

No PR relating to this has been created yet, I think you're good to go @ankitmaurya001 ☺️",working would like take thanks yet think good go,issue,positive,positive,positive,positive,positive,positive
1252951639,"Apparently, [torch.device(""mps"") on M1 GPU is analogous to torch.device(""cuda"") on an Nvidia GPU](https://sebastianraschka.com/blog/2022/pytorch-m1-gpu.html#:~:text=Then%2C%20if%20you%20want%20to%20run%20PyTorch%20code%20on%20the%20GPU%2C%20use%20torch.device(%22mps%22)%20analogous%20to%20torch.device(%22cuda%22)%20on%20an%20Nvidia%20GPU.). I recommend running these codes from the [official Pytorch site](https://pytorch.org/docs/stable/notes/mps.html) first to see if it helps.
```python
# Check that MPS is available
if not torch.backends.mps.is_available():
    if not torch.backends.mps.is_built():
        print(""MPS not available because the current PyTorch install was not ""
              ""built with MPS enabled."")
    else:
        print(""MPS not available because the current MacOS version is not 12.3+ ""
              ""and/or you do not have an MPS-enabled device on this machine."")

else:
    mps_device = torch.device(""mps"")

    # Create a Tensor directly on the mps device
    x = torch.ones(5, device=mps_device)
    # Or
    x = torch.ones(5, device=""mps"")

    # Any operation happens on the GPU
    y = x * 2

    # Move your model to mps just like any other device
    model = YourFavoriteNet()
    model.to(mps_device)

    # Now every call runs on the GPU
    pred = model(x)
```

If not, I suggest the following alternatives:
```python
# Use GPU
dls = pets.dataloaders(path/'images', device = 'mps')

# Or use CPU
dls = pets.dataloaders(path/'images', device = 'cpu')
```",apparently analogous recommend running official site first see python check available print available current install built else print available current version device machine else create tensor directly device operation move model like device model every call model suggest following python use device use device,issue,positive,positive,positive,positive,positive,positive
1252910606,"> `dls = pets.dataloaders(path/'images')` << when run this line, the kernel down

Was there an error prompt at all before the kernel shut down? And why did you assume it was the memory limit?",run line kernel error prompt kernel shut assume memory limit,issue,negative,neutral,neutral,neutral,neutral,neutral
1252904607,The links you provided work perfectly fine for me. Could you check them again?,link provided work perfectly fine could check,issue,positive,positive,positive,positive,positive,positive
1251042842,Many thanks for your patience and encouragement to complete it 🙏🏾 .,many thanks patience encouragement complete,issue,positive,positive,positive,positive,positive,positive
1250188182,"Thanks for your suggestion Jeremy. Following your suggestion, I have opened a new PR with my changes in #3798 as it felt easier to do that way.

Closing #3718 ",thanks suggestion following suggestion new felt easier way,issue,positive,positive,positive,positive,positive,positive
1250075145,"@jph00 yeah your approach is far cleaner but your code doesn't work because `as_tensor()` doesn't accept `requires_grad` and `pin_memory` keyword arguments. I just erased them in `as_tensor()`'s arguments and it works correctly as we are already changing these attributes after that. I have also made the commit

Just changed this from your code:
```
t = torch.as_tensor(x, requires_grad=requires_grad, pin_memory=pin_memory, **kwargs)
```
to this:
```
t = torch.as_tensor(x, **kwargs)
```",yeah approach far cleaner code work accept erased work correctly already also made commit code,issue,positive,positive,neutral,neutral,positive,positive
1249963741,"We had some kinda folks from msft work with us for quite a few months to try to get things working smoothly on Windows. But they only managed to get it to a point that it kinda worked, and worked slowly.

It's not just a lack of testing - Windows just doesn't have the APIs that DL frameworks are using. So the frameworks would need to be rewritten with Windows APIs in mind, AFAICT, and few people are doing that. (There's some cool stuff like https://diffsharp.github.io/ , but few projects use that.)",work u quite try get working smoothly get point worked worked slowly lack testing would need mind people cool stuff like use,issue,negative,positive,positive,positive,positive,positive
1249887658,"I'd been hoping that Windows was a first-class citizen and I could avoid a layer of complexity (running inside WSL). But I see that generally in the deep learning world Python packages don't seem to get tested on Windows.

So I guess using WSL is the smart move, thanks for the guidance.",citizen could avoid layer complexity running inside see generally deep learning world python seem get tested guess smart move thanks guidance,issue,positive,positive,positive,positive,positive,positive
1249814216,"That's a clever approach. Would this work and be a bit cleaner?:

```python
def _array2tensor(x, requires_grad=False, pin_memory=False, **kwargs):
    if x.dtype==np.uint16: x = x.astype(np.float32)
    # windows default numpy int dtype is int32, while torch tensor default int dtype is int64
    # https://github.com/numpy/numpy/issues/9464
    if sys.platform == ""win32"" and x.dtype==np.int: x = x.astype(np.int64)
    t = torch.as_tensor(x, requires_grad=requires_grad, pin_memory=pin_memory, **kwargs)
    t.requires_grad_(requires_grad)
    if pin_memory: t.pin_memory()
    return t
```
",clever approach would work bit cleaner python default torch tensor default win return,issue,positive,positive,positive,positive,positive,positive
1249763826,"If it's easier to close this PR and open a new clean one with your changes, feel free to do that @kurianbenoy . Or I could paste them manually into the notebook at my end if you prefer.",easier close open new clean one feel free could paste manually notebook end prefer,issue,positive,positive,positive,positive,positive,positive
1249677636,Looks like I messed up with my latest changes to update description.,like latest update description,issue,negative,positive,positive,positive,positive,positive
1249317936,I just found out that you have you to build the notebooks too (I should read the nbdev stuff in more detail). So I'll open this once I have done that.,found build read stuff detail open done,issue,negative,neutral,neutral,neutral,neutral,neutral
1249231534,"Message ID: ***@***.***>I thought it used to happen automatically -- something may have gotten broken along the way. Windows doesn't get used much, frankly, since WSL works so much better. So we don't always see Windows issues very quickly.",message id thought used happen automatically something may gotten broken along way get used much frankly since work much better always see quickly,issue,negative,positive,positive,positive,positive,positive
1249000860,"Aha, good to know. Yep that works now.

It would be great if this happened automatically, or maybe it's mentioned in the docs and I should read the docs...",aha good know yep work would great automatically maybe read,issue,positive,positive,positive,positive,positive,positive
1248756111,You'll need to set `num_workers=0` on windows since we haven't found a way to make it work otherwise.,need set since found way make work otherwise,issue,negative,neutral,neutral,neutral,neutral,neutral
1248736544,"I'm getting this error, it seems to be triggered by `lr_find` in `fastai 2.7.9`

I have the very uncool setup of Windows 11 and vanilla Python 3.10 (just a script, no Jupyter)

```py
from fastai.callback.schedule import slide, valley
from fastai.metrics import error_rate
from fastai.vision.augment import aug_transforms, Resize
from fastai.vision.data import ImageDataLoaders
from fastai.vision.learner import vision_learner

if __name__ == ""__main__"":
    dls = ImageDataLoaders.from_folder(
        ""paddy-disease-classification/train_images/bacterial_leaf_blight"",
        valid_pct=0.2,
        item_tfms=Resize(480, method=""squish""),
        batch_tfms=aug_transforms(size=192, min_scale=0.75),
        bs=64,
    )

    learn = vision_learner(dls, ""resnet26d"", metrics=error_rate, path=""."").to_fp16()
    learn.lr_find(suggest_funcs=(valley, slide))
```

Full error:
```
Traceback (most recent call last):-------------------------------------| 0.00% [0/6 00:00<?]
  File ""C:\Users\david\py\libs\fastbook\tmp.py"", line 40, in <module>
    learn.lr_find(suggest_funcs=(valley, slide))
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\callback\schedule.py"", line 293, in lr_find
    with self.no_logging(): self.fit(n_epoch, cbs=cb)
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 256, in fit
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 193, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 245, in _do_fit
    self._with_events(self._do_epoch, 'epoch', CancelEpochException)
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 193, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 239, in _do_epoch
    self._do_epoch_train()
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 231, in _do_epoch_train
    self._with_events(self.all_batches, 'train', CancelTrainException)
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 193, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\learner.py"", line 199, in all_batches
    for o in enumerate(self.dl): self.one_batch(*o)
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\fastai\data\load.py"", line 129, in __iter__
    for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\torch\utils\data\dataloader.py"", line 1077, in __init__
    w.start()
  File ""C:\Program Files\Python310\lib\multiprocessing\process.py"", line 121, in start
    self._popen = self._Popen(self)
  File ""C:\Program Files\Python310\lib\multiprocessing\context.py"", line 224, in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
  File ""C:\Program Files\Python310\lib\multiprocessing\context.py"", line 327, in _Popen
    return Popen(process_obj)
  File ""C:\Program Files\Python310\lib\multiprocessing\popen_spawn_win32.py"", line 93, in __init__
    reduction.dump(process_obj, to_child)
  File ""C:\Program Files\Python310\lib\multiprocessing\reduction.py"", line 60, in dump
    ForkingPickler(file, protocol).dump(obj)
  File ""C:\Users\david\py\libs\fastbook\venv\lib\site-packages\torch\multiprocessing\reductions.py"", line 345, in reduce_storage
    raise RuntimeError(""Cannot pickle CUDA storage; try pickling a CUDA tensor instead"")
RuntimeError: Cannot pickle CUDA storage; try pickling a CUDA tensor instead
[W ..\torch\csrc\CudaIPCTypes.cpp:15] Producer process has been terminated before all shared CUDA tensors released. See Note [Sharing CUDA tensors]
```",getting error triggered setup vanilla python script import slide valley import import resize import import squish learn valley slide full error recent call last file line module valley slide file line file line fit file line try self file line file line try self file line file line file line try self file line enumerate file line file line file line start self file line return file line return file line file line dump file protocol file line raise pickle storage try tensor instead pickle storage try tensor instead producer process see note,issue,negative,positive,positive,positive,positive,positive
1248690584,"I see where you're coming from @SaadAhmedGit, and that potentially could be a useful feature to add though. I'm not sure it's necessarily the expected behaviour... pytorch's `tensor()` takes `(dtype=None, device=None, requires_grad=False, pin_memory=False)`. If we're going to have `requires_grad` work for numpy arrays, it seems odd to have the rest not work IMO.

I think if we could have all kwargs work in all situations, and keep things reasonably simple and fast, I'd be happy to make that change.",see coming potentially could useful feature add though sure necessarily behaviour tensor going work odd rest work think could work keep reasonably simple fast happy make change,issue,positive,positive,positive,positive,positive,positive
1248634144,"@jph00 Even after your commit https://github.com/fastai/fastai/commit/aa58b1316ad8e7a5fa2e434e15e5fe6df4f4db56, don't you think not being able to pass `**kwargs` to `_array2tensor()` essentially means that you **can't** set the `requires_grad` attribute of the returned tensor?

For example, in the following snippet:
```
should_req_grad = fastai.torch_core.tensor(np.array([3., 4., 5.]), requires_grad=True)

print(should_req_grad.requires_grad)
#Output: False
#Expected: True
```
The expected output is different from the original output when we are passing a numpy array to create a tensor out of.
I think the solution to this would be to allow `_array2tensor()` to accept `**kwargs` and use it to set the `requires_grad` attribute. What are your thoughts?",even commit think able pas essentially ca set attribute returned tensor example following snippet print output false true output different original output passing array create tensor think solution would allow accept use set attribute,issue,positive,positive,positive,positive,positive,positive
1248546502,"Sorry my bad I forgot to push it! here's the line:

https://github.com/fastai/fastai/blob/master/fastai/torch_core.py#L148
",sorry bad forgot push line,issue,negative,negative,negative,negative,negative,negative
1247965117,I looked up everywhere and couldn't find the commit that you are talking about. The function is still the same on the main branch and the issue is still open.,everywhere could find commit talking function still main branch issue still open,issue,negative,positive,neutral,neutral,positive,positive
1246286403,I actually committed a fix today you can look at ,actually fix today look,issue,negative,neutral,neutral,neutral,neutral,neutral
1246285849,"> This is actually an nbdev project so changes need to be made in the notebook.

Thanks @jph00 for educating me about fastai being an nbdev project. I will try to commit to the notebooks in the future.

> I'm also not sure the approach here is the best

Yes I too felt like there was something wrong with the previous solution. I have come up with another solution but I'll commit it in the notebook if you can have a quick look at it and tell me what's wrong with my approach so I can write something better and commit that instead if, that sounds ok.
```
def _array2tensor(x, **kwargs):
    if x.dtype==np.uint16: x = x.astype(np.float32)
    # windows default numpy int dytpe is int32, while torch tensor default int dtype is int64
    # https://github.com/numpy/numpy/issues/9464
    if sys.platform == ""win32"":
        if x.dtype==np.int: x = x.astype(np.int64)

    # removing and storing ""requires_grad"" from kwargs since torch.as_tensor() doesn't accept it
    req_grad_from_kwargs = kwargs.pop(""requires_grad"")
    t = torch.as_tensor(x, **kwargs)
    t.requires_grad_(req_grad_from_kwargs)
    return t
```",actually project need made notebook thanks project try commit future also sure approach best yes felt like something wrong previous solution come another solution commit notebook quick look tell wrong approach write something better commit instead default torch tensor default win removing since accept return,issue,positive,positive,positive,positive,positive,positive
1246014171,Many thanks @SaadAhmedGit . This is actually an nbdev project so changes need to be made in the notebook. I'm also not sure the approach here is the best -- I'll fix it at our end.,many thanks actually project need made notebook also sure approach best fix end,issue,positive,positive,positive,positive,positive,positive
1245817917,I would like to fix the conflicts and get with a ready to merge version pretty soon. I am hoping to complete it by this week sometime.,would like fix get ready merge version pretty soon complete week sometime,issue,positive,positive,positive,positive,positive,positive
1245718206,"Hi, I have linked a PR to this issue. I am still new to the repo but do you think this will resolve the issue that you are currently facing? I know you suggested a refactor of logic for testing arguments in torch_core.tensor() but I haven't touched that as I think there's more to it than I know.",hi linked issue still new think resolve issue currently facing know logic testing touched think know,issue,negative,positive,neutral,neutral,positive,positive
1245202120,"@kurianbenoy would you like to fix the conflicts and remove ""draft"" attribute when you feel this is ready to merge?",would like fix remove draft attribute feel ready merge,issue,positive,positive,positive,positive,positive,positive
1245030568,"@jph00 I see some [failures](https://github.com/fastai/fastai/actions/runs/3041062707/jobs/4899647574) but they seem unrelated. Let me know if you need me to check/change something.

> Yes, it is a big ugly! But looks like it does the job, and doesn't seem too hard to maintain. I hope you might consider adding __all__ in the future to make this kind of thing easier (and to support interactive use more generally).

I agree. I'll speak with the team to see if we can add a `models.backbones` or `models.classification` space. It's probably going to take multiple versions until you can use it (unless you pin fastai to the latest PyTorch version which I probably suspect you don't want to do). I'll let you know when we add something like this and follow up with more contributions. 

Looking forward working with you closer on the future!",see seem unrelated let know need something yes big ugly like job seem hard maintain hope might consider future make kind thing easier support interactive use generally agree speak team see add space probably going take multiple use unless pin latest version probably suspect want let know add something like follow looking forward working closer future,issue,positive,positive,neutral,neutral,positive,positive
1244818022,"Yes, it is a big ugly! But looks like it does the job, and doesn't seem too hard to maintain. I hope you might consider adding `__all__` in the future to make this kind of thing easier (and to support interactive use more generally).

Many thanks for the PR. Great to see all this terrific models in tvm nowadays.",yes big ugly like job seem hard maintain hope might consider future make kind thing easier support interactive use generally many thanks great see terrific nowadays,issue,positive,positive,positive,positive,positive,positive
1244649107,@jph00 I took a stab at option 2 at PR #3791. Let me know your thoughts.,took stab option let know,issue,negative,neutral,neutral,neutral,neutral,neutral
1240712545,"Thanks a lot for coming back to me @jph00.

> Might you be open to adding a submodule in torchvision which folks could import to just get the model builders with an import *? Or alternatively, define __all__ in torchvision.models to only include the model builders?

Currently we don't define an `__all__` in [`torchvision/models/__init__.py`](https://github.com/pytorch/vision/blob/main/torchvision/models/__init__.py) and so everything that is public is automatically exposed:
```python
# Import all backbone architecture methods + their weight enums:
from .alexnet import *
# ... more backbone imports go here...

# Import submodules:
from . import detection, optical_flow, quantization, segmentation, video  

# Import other non-model builder methods:
from ._api import get_model, get_model_weights, get_weight, list_models 
```

As you can see not all publicly exposed items are model builders. We include model classes (like `AlexNet`), weight enums (like `AlexNet_Weights`), model utility methods (like `interpolate_embeddings()` for ViT), other API methods (like `get_weight()`) and even submodules (like `detection`). This is one of the primary reasons we are introducing the registration API, so that one can easily get just the backbones with a single method call.

If you are not inclined to adopt the new API, then perhaps you would consider a workaround like the following? We can add tests on our side to ensure it will always return the expected results for you:
```python
from torchvision.models import *
for name in {""detection"", ""segmentation"", ""get_weight"", ""list_models"", ...}:
    globals().pop(name)
```

I'm happy to discuss alternatives. Just wanted to provide a few more details on the limitations and current situation on TorchVision.

> One thing to consider is how to handle transfer learning with the new models. So far we've been manually creating a metadata dict with info about where to cut the head to add a new transfer learning head, and what normalization statistics were used in training

That makes a lot of sense. I would love to get more details on exactly the type of meta-data you would like to store. Perhaps you could provide a few code references on how exactly you store this info? 

One potential option is to use the meta-data provided by the [Multi-weight support API](https://pytorch.org/blog/introducing-torchvision-new-multi-weight-support-api/). This was introduced in v0.13 and allows us to store things like meta-data and the preprocessing transforms along with the weights to facilitate transfer learning. I would like to understand more about your use-case to see if that is the right place to put this information. For reference [here](https://github.com/pytorch/vision/blob/main/torchvision/models/alexnet.py#L55-L74) is an example of the things we currently store.",thanks lot coming back might open could import get model import alternatively define include model currently define everything public automatically exposed python import backbone architecture weight import backbone go import import detection quantization segmentation video import builder import see publicly exposed model include model class like weight like model utility like like even like detection one primary registration one easily get single method call adopt new perhaps would consider like following add side ensure always return python import name detection segmentation name happy discus provide current situation one thing consider handle transfer learning new far manually cut head add new transfer learning head normalization statistic used training lot sense would love get exactly type would like store perhaps could provide code exactly store one potential option use provided support u store like along facilitate transfer learning would like understand see right place put information reference example currently store,issue,positive,positive,positive,positive,positive,positive
1239698224,"I think it's useful to have an easy way to import all models. Might you be open to adding a submodule in torchvision which folks could import to just get the model builders with an `import *`? Or alternatively, define `__all__` in `torchvision.models` to only include the model builders?

One thing to consider is how to handle transfer learning with the new models. So far we've been manually creating a metadata dict with info about where to cut the head to add a new transfer learning head, and what normalization statistics were used in training. However the timm library (which we also support in fastai) has these things available directly as part of the library for each model, so we can simply grab the info from there. That would make it easier for us to support all the new models. In addition, timm also has metadata which tell us which layers to use when creating a dynamic unet -- currently for torchvision models we have to figure this out for ourselves; that would be another nice thing to add to torchvision IMO.
",think useful easy way import might open could import get model import alternatively define include model one thing consider handle transfer learning new far manually cut head add new transfer learning head normalization statistic used training however library also support available directly part library model simply grab would make easier u support new addition also tell u use dynamic currently figure would another nice thing add,issue,positive,positive,positive,positive,positive,positive
1237541688,"I've noticed that too. But, seeing the project [Fastai docs](https://github.com/fastai/fastai-docs), I saw that the link is fixed.

Maybe the docs' website isn't in the latest version?

",seeing project saw link fixed maybe latest version,issue,negative,positive,positive,positive,positive,positive
1235255404,Is this issue available? I'd love to work on it!,issue available love work,issue,positive,positive,positive,positive,positive,positive
1229073730,"> > same problem here.
> > training and export of fastaiV2 model on windows. created App with Streamlit. on local Windows machine running smooth. Deployed on https://share.streamlit.io/ error ""NotImplementedError: cannot instantiate 'WindowsPath' on your system""
> > Any help appreciated ! thx
> 
> I found a solution for this adding the below to the code:
> 
> ```
> import pathlib
> plt = platform.system()
> if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath
> ```

Just had this exact problem and your code solved it. Thank you!",problem training export model local machine running smooth error system help found solution code import exact problem code thank,issue,negative,positive,positive,positive,positive,positive
1222559525,"I've resolved this problem with few @patch_to's
```python 
@patch_to(SkipToEpoch)
def before_fit(self):
    self.learn._skip_to = self._skip_to
```
```python
@patch_to(SkipToEpoch)
def after_fit(self):
    del self.learn._skip_to
```
```python 
@patch_to(TrackerCallback)
def after_epoch(self):
    def comp_last_value_to_best():
        val = self.recorder.values[-1][self.idx]
        if self.comp(val - self.min_delta, self.best): self.best,self.new_best = val,True
        else: self.new_best = False
    if hasattr(self.learn, '_skip_to'):
        if self.epoch >= self.learn._skip_to:
            comp_last_value_to_best()
        else:
            self.new_best = False
    else:
        comp_last_value_to_best()
```

```python 
#export
@patch_to(ShowGraphCallback)
def after_epoch(self):
    ""Plot validation loss in the pbar graph""
    def plot_pbar_graph(epochs_to_skip=0):
        if not self.nb_batches: return
        rec = self.learn.recorder
        iters = range_of(rec.losses)
        val_losses = [v[1] for v in rec.values[epochs_to_skip:]]
        x_bounds = (0, (self.n_epoch - len(self.nb_batches)) * self.nb_batches[0] + len(rec.losses))
        y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(val_losses)))))
        self.progress.mbar.update_graph([(iters, rec.losses), (self.nb_batches, val_losses)], x_bounds, y_bounds)
    if hasattr(self.learn, '_skip_to'):
        if self.epoch >= self.learn._skip_to:
            plot_pbar_graph(epochs_to_skip=self.learn._skip_to)
    else:
        plot_pbar_graph()
```

If you would like to I could make PR with the above changes. Below are the result of the code snippet
```python
from fastai.callback.all import *
from fastai.test_utils import synth_learner
learn = synth_learner()
learn.fit(10, start_epoch=2,cbs=[SaveModelCallback])
```
![image](https://user-images.githubusercontent.com/80767000/185965962-865897f0-ed6d-41d2-9424-dcc801b54a6a.png)
",resolved problem python self python self python self true else false else false else python export self plot validation loss graph return tensor tensor else would like could make result code snippet python import import learn image,issue,negative,negative,negative,negative,negative,negative
1221222486,"@YSaxon No, I apologise, I didn't see @hamelsmu's message last April that he'd fixed the CI issues so it was ready to review.

Have you taken a look at the various options here?: https://scikit-learn.org/stable/modules/classes.html#module-sklearn.model_selection . Is this PR doing something different to those classes?",see message last fixed ready review taken look various something different class,issue,negative,positive,neutral,neutral,positive,positive
1220968448,@jph00 I just came across this old pull request of mine. Did you ever have a chance to review it?,came across old pull request mine ever chance review,issue,negative,positive,neutral,neutral,positive,positive
1220396747,"I noticed the changes have been updated by someone nicely, so I don't think I need to do PR on it anymore",someone nicely think need,issue,negative,positive,positive,positive,positive,positive
1220391566,"I only saw this message now. How come I missed it, sorry for replying late.",saw message come sorry late,issue,negative,negative,negative,negative,negative,negative
1219791347,"From a look at the data I take that you want to do classification? Then `CrossEntropyLossFlatten()` would be your first choice as a loss function. (Not all loss functions are suitable for all problems/models.)
The error occours since the shape of the output of that model is `(64,10)` (batch_size, n_out) which gets flattened in the loss function and results in a tensor of size `640`, whereas the target has a size of `64` (batch_size). As the RuntimeError hints, MSELoss cannot compare tensors of different sizes. As you observed: for `n_out == 1` this is not a problem since `(64,1)` flattens to the required size of 64, but still most likely you want to use cross entropy for classification.",look data take want classification would first choice loss function loss suitable error since shape output model loss function tensor size whereas target size compare different size problem since size still likely want use cross entropy classification,issue,negative,positive,positive,positive,positive,positive
1219227646,"Hey,
what you are getting is actually not a newline but  the remainings of a progress bar. You can recreate this behaviour by calling `learn('before_validate')` (after training, before .predict) which shows you that progress bar. `learn('after_validate)` removes it, so calling both in succession leaves that empty space (and thats whats happening somewhere in .get_preds).
You can avoid this by removing the ProgressCallback from the list of callbacks but conveniently fastai offers a context manager that doesn't launch the progress bar. 
__So a solution would be to run your loop in the context of: `with learn.no_bar():`.__

Also this behaviour is not exclusive to the TabularLearner, at least the Learner from `vision_learner` does exactly the same...
Hope I could help.",hey getting actually progress bar recreate behaviour calling learn training progress bar learn calling succession leaf empty space thats whats happening somewhere avoid removing list conveniently context manager launch progress bar solution would run loop context also behaviour exclusive least learner exactly hope could help,issue,positive,negative,neutral,neutral,negative,negative
1218929639,Many thanks! It might be an nbdev issue - I'll merge and check locally.,many thanks might issue merge check locally,issue,negative,positive,positive,positive,positive,positive
1218787250,@jph00 Ready for review. Unsure of why test are failing. I successfully ran `nbdev_cean` locally with `nbdev==2.1.7` before opening the PR.,ready review unsure test failing successfully ran locally opening,issue,negative,positive,positive,positive,positive,positive
1211676344,"Thanks! BTW if you run `nbdev_readme` it'll also update the readme. You might want to do another PR after you've done that, so the README file will include your changes.",thanks run also update might want another done file include,issue,negative,positive,positive,positive,positive,positive
1211235437,"I took a look at this again and found a workaround.
Basically, we need to remove the lines where the callbacks or the learner look up the `len(dataset)` or `n` (see the lines commented out in the code snippet below)
Here's the code that fixes it:

```python
from fastcore.all import *

@patch
def after_batch(self: TrainEvalCallback):
    # self.n_iter = len(self.dl)
    # self.learn.pct_train += 1./(self.n_iter*self.n_epoch)
    self.learn.train_iter += 1

@patch
def all_batches(self: Learner):
    # self.n_iter = len(self.dl)
    for o in enumerate(self.dl): self.one_batch(*o)

learn.remove_cb(ProgressCallback)  # equivalently, with learn.no_bar():
learn.fit_one_cycle(3, lr_max=0.1)
learn.recorder.plot_loss()
```
@tcapelle do you think there is any interest to pursue a fix in this direction? I'd be happy to help.
(Some more thought would be necessary to handle the progress bar, but that's a bit of a different story)",took look found basically need remove learner look see code snippet code python import patch self patch self learner enumerate equivalently think interest pursue fix direction happy help thought would necessary handle progress bar bit different story,issue,positive,positive,positive,positive,positive,positive
1210932511,Oops! Thanks for the keen eye and the fix.,thanks keen eye fix,issue,positive,positive,positive,positive,positive,positive
1207662941,"I'm getting the error `name 'union2tuple' is not defined` in a Kaggle Notebook clone from the [Course notebook](https://www.kaggle.com/code/jhoward/is-it-a-bird-creating-a-model-from-your-own-data), is that related to this, or a different issue?

The notebook appears to be running `fastcore` version `1.3.29` and `fastai` version `2.7.9`",getting error name defined notebook clone course notebook related different issue notebook running version version,issue,negative,neutral,neutral,neutral,neutral,neutral
1207556051,"Okay, I have changed the code use `timm.create_model` `features_only=True`.
So far it seems to be training a `convnext_tiny`
<img width=""734"" alt=""Screen Shot 2022-08-08 at 11 36 37 am"" src=""https://user-images.githubusercontent.com/2882739/183321832-161daf0d-977a-4b8d-8459-b8f92222031c.png"">

",code use far training screen shot,issue,negative,positive,neutral,neutral,positive,positive
1207124472,"No, `doc` and `show_doc` are different. I guess we need to add `doc`.",doc different guess need add doc,issue,negative,neutral,neutral,neutral,neutral,neutral
1206940376,"> I actually meant the links in that section, like the following:

Understood - I'm fixing them too (they all need .html suffixes to work)",actually meant link section like following understood fixing need work,issue,negative,neutral,neutral,neutral,neutral,neutral
1206896306,"I actually meant the links in that section, like the following:
https://docs.fast.ai/migrating_pytorch
https://docs.fast.ai/migrating_ignite
https://docs.fast.ai/migrating_lightning
https://docs.fast.ai/migrating_catalyst

",actually meant link section like following,issue,negative,neutral,neutral,neutral,neutral,neutral
1206892935,"Looks like we're missing the .html suffix - this works: https://docs.fast.ai/#migrating-from-other-libraries.html

I'll fix the link now.",like missing suffix work fix link,issue,negative,negative,negative,negative,negative,negative
1204586891,Thanks for reporting @kevin-b1rd . Feel free to take a crack at a PR if you're interested! Otherwise I'll take a look at it later.,thanks feel free take crack interested otherwise take look later,issue,positive,positive,positive,positive,positive,positive
1204584967,You need to spend some time reading before you ask a question. That's what we wish to enforce.,need spend time reading ask question wish enforce,issue,negative,neutral,neutral,neutral,neutral,neutral
1204574280,Oops - thanks for pointing this out! The fix is actually to change the fmt string to remove the id. Done now.,thanks pointing fix actually change string remove id done,issue,negative,positive,neutral,neutral,positive,positive
1202045983,"Oh sorry my bad! Yes you're right this is that commit that I slid into the general nbdev2 fixes. You can use `git blame` to find the commit that fixed it if you're curious. 

https://github.com/fastai/fastai/blob/master/fastai/vision/learner.py#L240",oh sorry bad yes right commit slid general use git blame find commit fixed curious,issue,negative,negative,negative,negative,negative,negative
1202037548,"> It's fixed in #3746 . Please let me know if it doesn't work for you.
> 
> (We close issues when they're fixed in the repo, not when the release occurs.)

Sorry i was / am a littel confused. #3746 says it was closed with out merging, so just trying to see where the commit is",fixed please let know work close fixed release sorry confused closed trying see commit,issue,negative,negative,negative,negative,negative,negative
1201757914,"It's fixed in #3746 . Please let me know if it doesn't work for you.

(We close issues when they're fixed in the repo, not when the release occurs.)",fixed please let know work close fixed release,issue,negative,positive,neutral,neutral,positive,positive
1201731375,Thanks - this file is auto-generated so I'll fix the notebook.,thanks file fix notebook,issue,negative,positive,positive,positive,positive,positive
1201209125,Feel like we should keep this issue open until it is fixed and released?,feel like keep issue open fixed,issue,negative,positive,neutral,neutral,positive,positive
1196294322,For now I figured out I can visit `https://fastai.github.io/fastai-docs/<path-suffix>` to work around the missing links.,figured visit work around missing link,issue,negative,negative,negative,negative,negative,negative
1195051046,Message ID: ***@***.***>Thanks - we love it! :),message id thanks love,issue,positive,positive,positive,positive,positive,positive
1195049635,"> Thanks @peterdudfield -- I'm actually in the middle of updating fastai to work with nbdev2 and included your commit in that, so it'll be a while before it's visible! Your image looks like you figured it out though :)

Thanks, and good luck changing it to nddev2. Its the first time ive seen this setup with notebooks, and then testing the notebooks. Looks good.",thanks actually middle work included commit visible image like figured though thanks good luck first time seen setup testing good,issue,positive,positive,positive,positive,positive,positive
1194769683,"Thanks @peterdudfield  -- I'm actually in the middle of updating fastai to work with nbdev2 and included your commit in that, so it'll be a while before it's visible! Your image looks like you figured it out though :) ",thanks actually middle work included commit visible image like figured though,issue,positive,positive,neutral,neutral,positive,positive
1194663634,"Thanks @jph00 , please let me know the commit, I would be interested to see how it is done",thanks please let know commit would interested see done,issue,positive,positive,positive,positive,positive,positive
1194480030,Thanks @peterdudfield . This is an nbdev project so fixes need to be made in notebooks and then the lib built from there. I'll fix it at our end to save you the trouble.,thanks project need made built fix end save trouble,issue,positive,neutral,neutral,neutral,neutral,neutral
1187891459,"I think it's because of this line
```
    dblock = DataBlock(get_items=get_image_files(str(root), recurse=True),
```
`get_items` should be a function which takes root as an argument and returns items. Whereas, here it's a list.",think line root function root argument whereas list,issue,negative,neutral,neutral,neutral,neutral,neutral
1186625928,"Since Jeremy does not want to add this, this issue can be closed
@jph00 ",since want add issue closed,issue,negative,negative,neutral,neutral,negative,negative
1186625550,"Issue fixed today, @jph00 you can close",issue fixed today close,issue,negative,positive,neutral,neutral,positive,positive
1186625462,"This should have been an issue under https://github.com/fastai/fastcore but anyway this issue was resolved today. 

@jph00 you can close",issue anyway issue resolved today close,issue,negative,neutral,neutral,neutral,neutral,neutral
1186362496,"@jph00 Ready for review. I added support for splitting on a list of values, given the discord discussion with Benjamin. ",ready review added support splitting list given discord discussion benjamin,issue,negative,positive,positive,positive,positive,positive
1184418217,"#### Problem

Why I get that error is bc the `Tf()` function was used to train the `model.pkl` file, in the same **namespace** (because it was done in a notebook file).

This [article][1] states:

> `pickle` is lazy and does not serialize class definitions or function
> definitions. Instead it saves a reference of how to find the class
> (the module it lives in and its name)

#### Solution

There's an extension to pickle called dill, that does serialise Python objects and functions etc. (not references) [PyPI][2]


  [1]: https://python.tutorialink.com/attributeerror-when-reading-a-pickle-file/
  [2]: https://pypi.org/project/dill/#:~:text=About%20Dill,to%20a%20python%20object%20hierarchy.",problem get error function used train file done notebook file article pickle lazy serialize class function instead reference find class module name solution extension pickle dill python,issue,negative,negative,negative,negative,negative,negative
1181489756,@jph00 done! And tests pass in [fork's CI](https://github.com/seeM/fastai/runs/7297988501) + locally,done pas fork locally,issue,negative,neutral,neutral,neutral,neutral,neutral
1181399636,"@kevin-b1rd  are you working on it? If not I would like to take this up.

Thanks,
Ankit",working would like take thanks,issue,positive,positive,positive,positive,positive,positive
1181299593,"Oh @seeM two more things:

- All notebooks with `|` type annotations will need `from __future__ import annotations` at the top, if they don't already
- There's a CI failure; I'm not sure why. I'm guessing there's some type mismatch going on...
",oh seem two type need import top already failure sure guessing type mismatch going,issue,negative,positive,positive,positive,positive,positive
1179369006,Looks like this got fixed -- thanks!,like got fixed thanks,issue,positive,positive,positive,positive,positive,positive
1178376589,"@jph00 A question before this is ready for review: In https://github.com/fastai/fastai/pull/3711/commits/408c1060edf5d531e53b34c13ddbf114be0d681f I (1) fixed union annotations[^update-union-annots] and (2) reran all notebooks (using `execnb`, thanks to the Jupyter consistency updates). But that makes for a _huge_ diff. Would it be better to only fix the annotations?

[^update-union-annots]: I ended up doing this programmatically using `ast`, as you originally suggested, which I quite like! [Here's the notebook](https://wasimlorgat.com/tils/update-fastai-union-annotations-using-ast/). It uses `nbprocess` to export a tiny runnable package.",question ready review fixed union thanks consistency would better fix ended programmatically ast originally quite like notebook export tiny runnable package,issue,positive,positive,positive,positive,positive,positive
1178174102,Message ID: ***@***.***>Whatever is more convenient for you - I don't mind either way.,message id whatever convenient mind either way,issue,negative,neutral,neutral,neutral,neutral,neutral
1177631660,"```
from fastai.vision.all import *
```

```
conda create -n venv python==2.6.13
```

```
pip install -r requirements.txt
```

`requirements.txt`:
```
fastai==2.5.3
fastcore==1.3.27
python==3.6.13
```",import create pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1177148397,Thanks - this dead link is actually due to a different issue.,thanks dead link actually due different issue,issue,negative,negative,neutral,neutral,negative,negative
1176761748,"@manisnesan Interesting that I have a similar error, but without calling `fine_tune`. So, I call the finder as the very first method right after creating a `Learner` object. But I use _two_ suggesting functions.
```python
learner = Learner(dataloaders, model, loss_function).to_fp16()
learner.freeze()
learn.lr_find(suggest_funcs=[valley, slide])
```
My version is `2.7.4`. The version `2.6.0` worked without any problems.",interesting similar error without calling call finder first method right learner object use suggesting python learner learner model valley slide version version worked without,issue,negative,positive,positive,positive,positive,positive
1176472823,I would like to work on this issue ,would like work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1176077510,"Where is the **imports folder** to delete in **Miniconda3** on **Ubunutu**?

```
(base) daniel@ubuntu-pcs:~/miniconda3$ find . -type d -name ""imports""
./envs/pdl1lung/lib/python3.9/site-packages/fastai/imports
```
```
(base) daniel@ubuntu-pcs:~/miniconda3/lib/python3.9/site-packages$ grep -rl ""fastai""
dvclive-0.8.0.dist-info/RECORD
dvclive-0.8.0.dist-info/METADATA
tests/test_fastai.py
tests/__pycache__/test_fastai.cpython-39.pyc
__pycache__/MailChecker.cpython-39.pyc
dvclive/fastai.py
dvclive/__pycache__/fastai.cpython-39.pyc
MailChecker.py
```",folder delete base find base,issue,negative,negative,negative,negative,negative,negative
1175496142,Me and my group are going to work on this issue,group going work issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1173613411,"Hi,
Hopefully your question is still current,
you can take a look at TSAI: https://github.com/timeseriesAI/tsai,
which is an  open-source deep learning package built on top of Pytorch & fastai focused on state-of-the-art techniques for time series tasks like classification, regression, forecasting, imputation...",hi hopefully question still current take look deep learning package built top time series like classification regression forecasting imputation,issue,positive,positive,positive,positive,positive,positive
1173526567,"It's been fixed on v2.7.5. But there are still some warnings:

```
/home/jim/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and will be removed in 0.15. Please use keyword parameter(s) instead.
  warnings.warn(
/home/jim/.local/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
```",fixed still positional parameter since removed please use parameter instead weight none since removed current behavior equivalent passing also use get,issue,negative,positive,neutral,neutral,positive,positive
1173263139,"Met the same issue.
https://github.com/fastai/fastai/issues/3655#issuecomment-1170663578

### Software env:
| name | version |
| ------ | -------- |
| Ubuntu | 22.04 |
| Linux | Linux 5.15.0-40-generic |
| display driver | nvidia-smi 515.48.07 |
| cuda | 11.7 |
| torch | 1.12.0+cu116 |
| torchaudio | 0.12.0+cu116 |
| torchvision | 0.13.0+cu116 |
| fastai | 2.7.4 |

### Hardware env:
| name | version |
| ------ | -------- |
| CPU | 12th Gen Intel(R) Core(TM) i5-12400 |
| memory | 16GB |
| GPU |  NVIDIA Corporation GP108 [GeForce GT 1030] (rev a1) 2GB |
",met issue name version generic display driver torch hardware name version th gen core memory corporation rev,issue,negative,neutral,neutral,neutral,neutral,neutral
1173208061,"Message ID: ***@***.***>This PR is still important -- that sprint is finished now, and didn't complete docments for all functions. So we'd love to get more coverage!",message id still important sprint finished complete love get coverage,issue,positive,positive,positive,positive,positive,positive
1173207226,Thanks for the PR. Have a closer look at the source code to see how `dl` is used -- your current description isn't correct.,thanks closer look source code see used current description correct,issue,negative,positive,neutral,neutral,positive,positive
1173106023,"@jim-king-2000 This is not the same error. https://github.com/fastai/fastai/issues/3704 would be the correct place to post this.

Please post you hardware info there also (use the original post https://github.com/fastai/fastai/issues/3704 as an example for hardware overview). Ref: https://github.com/fastai/fastai/issues/3704#issuecomment-1168208897",error would correct place post please post hardware also use original post example hardware overview ref,issue,negative,positive,positive,positive,positive,positive
1173070931,"Just saw yesterday this youtube [W&B Fastbook Reading Group — Fastai Documentation Sprint w/ Zach Mueller](https://www.youtube.com/watch?v=6paEonqJz4Q) and realised that there had been a [huge docment PR in May](https://twitter.com/jeremyphoward/status/1524281237489487872) , which made this PR kind of nonessential. 
Nevertheless, thanks for pulling it. 
Yay, I contributed to fastai :)",saw yesterday reading group documentation sprint huge may made kind nonessential nevertheless thanks,issue,positive,positive,positive,positive,positive,positive
1172742704,"So, I tried training it just to make sure its still working.

I got this far before my paperspace machine shutdown:
<img width=""657"" alt=""Screen Shot 2022-07-02 at 7 56 00 am"" src=""https://user-images.githubusercontent.com/2882739/176972151-832a8e80-bae8-450e-8bf5-12cdbe1f9b71.png"">

So I guess its definitely training but extremely slowly. For comparison I can do the same dataset, resnet34 with batch size 4 and get epochs of about 6 minutes on that free paperspace gpu. So assuming the architecture was equally complex and the batch size was 4 times lower that should only take 24 minutes per epoch.

It seems like when the model is allocated theres only 7% gpu memory in use, and then once training with 1 batch starts it goes to 87+%
<img width=""530"" alt=""Screen Shot 2022-07-01 at 6 06 02 pm"" src=""https://user-images.githubusercontent.com/2882739/176972305-8e1bf547-0a34-456a-a977-9a9bcfd53eb0.png"">

I guess perhaps I don't understand the model cutting code and how to use it with `timm` models. Any advice on how to debug this?

",tried training make sure still working got far machine shutdown screen shot guess definitely training extremely slowly comparison batch size get free assuming architecture equally complex batch size time lower take per epoch like model there memory use training batch go screen shot guess perhaps understand model cutting code use advice,issue,positive,negative,neutral,neutral,negative,negative
1170723534,"It works when I switch to Pytorch@1.11.0+cu113.

Then a new error occurs:
```
RuntimeError: CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 1.95 GiB total capacity; 1.24 GiB already allocated; 4.38 MiB free; 1.26 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF
```

It is resolved when I change the batch size to 3. However, I think fastai should make the batch size adaptive.",work switch new error memory tried allocate mib gib total capacity gib already mib free gib reserved total reserved memory memory try setting avoid fragmentation see documentation memory management resolved change batch size however think make batch size adaptive,issue,negative,positive,positive,positive,positive,positive
1170666084,"And CUDA env:
```python
import torch
print(torch.__version__)
print(torch.version.cuda)
print(torch.backends.cudnn.version())
print(torch.cuda.is_available())
```

```
jim@ML0-CACHE-HIT:~/test$ python3 showcoda.py 
1.12.0+cu116
11.6
8302
True
```",python import torch print print print print python true,issue,negative,positive,positive,positive,positive,positive
1170664152,"And the env:
```
jim@ML0-CACHE-HIT:~/test$ pip3 show fastai
Name: fastai
Version: 2.7.4
Summary: fastai simplifies training fast and accurate neural nets using modern best practices
Home-page: https://github.com/fastai/fastai/tree/master/
Author: Jeremy Howard, Sylvain Gugger, and contributors
Author-email: info@fast.ai
License: Apache Software License 2.0
Location: /home/jim/.local/lib/python3.10/site-packages
Requires: fastcore, fastdownload, fastprogress, matplotlib, packaging, pandas, pillow, pip, pyyaml, requests, scikit-learn, scipy, spacy, torch, torchvision
Required-by: 
```

```
jim@ML0-CACHE-HIT:~/test$ pip3 list | grep -i torch
torch                   1.12.0+cu116
torchaudio              0.12.0+cu116
torchvision             0.13.0+cu116
```
",pip show name version summary training fast accurate neural modern best author license apache license location pillow pip spacy torch pip list torch torch,issue,positive,positive,positive,positive,positive,positive
1170663578,"This is the sample:

```python
from fastai.vision.all import *
path = untar_data(URLs.PETS)/'images'

def is_cat(x): return x[0].isupper()

dls = ImageDataLoaders.from_name_func(
        path, get_image_files(path), valid_pct=0.2, seed=42,
        label_func=is_cat, item_tfms=Resize(224))
learn = vision_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(1)
```

And this is the error code:
```
jim@ML0-CACHE-HIT:~/test$ python3 test.py 
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and will be removed in 0.15, please use 'weights' instead.
  warnings.warn(
/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and will be removed in 0.15. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.
  warnings.warn(msg)
epoch     train_loss  valid_loss  error_rate  time    
Traceback (most recent call last):-------------------------------------------------------------------------------| 0.00% [0/92 00:00<00:00]
  File ""/home/jim/test/test.py"", line 10, in <module>
    learn.fine_tune(1)
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/callback/schedule.py"", line 168, in fine_tune
    self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/callback/schedule.py"", line 122, in fit_one_cycle
    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd, start_epoch=start_epoch)
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 241, in fit
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 179, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 230, in _do_fit
    self._with_events(self._do_epoch, 'epoch', CancelEpochException)
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 179, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 224, in _do_epoch
    self._do_epoch_train()
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 216, in _do_epoch_train
    self._with_events(self.all_batches, 'train', CancelTrainException)
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 179, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/learner.py"", line 185, in all_batches
    for o in enumerate(self.dl): self.one_batch(*o)
  File ""/home/jim/.local/lib/python3.10/site-packages/fastai/data/load.py"", line 132, in __iter__
    for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
  File ""/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py"", line 1009, in __init__
    super(_MultiProcessingDataLoaderIter, self).__init__(loader)
  File ""/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py"", line 594, in __init__
    self._shared_seed = loader._get_shared_seed()
AttributeError: '_FakeLoader' object has no attribute '_get_shared_seed'
```",sample python import path return path path learn error code python parameter since removed please use instead weight none since removed current behavior equivalent passing also use get epoch time recent call last file line module file line slice file line file line fit file line try self file line file line try self file line file line file line try self file line enumerate file line file line super self loader file line object attribute,issue,positive,positive,positive,positive,positive,positive
1170662988,"@jim-king-2000 What is the error message/trace you are getting? can you provide a minimal example? Because it passed unit tests, so I would need to know what the scenario is that doesnt work.",error getting provide minimal example unit would need know scenario doesnt work,issue,negative,negative,neutral,neutral,negative,negative
1170660780,"still see the same error on fastai@2.7.4 with pytorch@1.12.0+cu116, any idea?",still see error idea,issue,negative,neutral,neutral,neutral,neutral,neutral
1168395617,I need the original code that made the model and exported the `.pkl`. Will keep posted,need original code made model keep posted,issue,negative,positive,positive,positive,positive,positive
1168365252,"> 

oh i see, good job man! hah",oh see good job man hah,issue,negative,positive,positive,positive,positive,positive
1168209880,Please use the forums to ask for help.,please use ask help,issue,positive,neutral,neutral,neutral,neutral,neutral
1168209706,There isn't enough info to repro your problem here - sounds like you got it sorted though,enough problem like got sorted though,issue,negative,neutral,neutral,neutral,neutral,neutral
1168207459,Accelerate is supported for distrib training now. Additional support will be in v3,accelerate training additional support,issue,negative,neutral,neutral,neutral,neutral,neutral
1168207091,Looks like this got fixed by another PR in the meantime,like got fixed another,issue,negative,positive,neutral,neutral,positive,positive
1168121718,"huggingface and fastai are awesome,whether the deep integration of the them can be done is very beneficial to developers.",awesome whether deep integration done beneficial,issue,positive,positive,positive,positive,positive,positive
1168030721,Not yet! I'll take it out of draft once it's ready. Sorry for the confusion,yet take draft ready sorry confusion,issue,negative,negative,negative,negative,negative,negative
1167965440,Looks like NBs need to be synced/cleaned. Also there's a CI error there - the output looks out since the two sides appear visually equal! Lemme know if you need a hand debugging it.,like need also error output since two side appear visually equal know need hand,issue,negative,neutral,neutral,neutral,neutral,neutral
1166836521,"Many thanks. Note that this is an *nbdev* project so the source code is in the notebooks, not the .py files - they're auto-synced when you run `nbdev_build_lib`. Would you mind update the nb file and building the lib? (No worries if not - I can do it at my end instead).",many thanks note project source code run would mind update file building end instead,issue,negative,positive,positive,positive,positive,positive
1166800070,"Ah, I thought I'd fixed nbdev export indexing but it still doesn't look right. I've made all of these draft PRs while I fix that...",ah thought fixed export indexing still look right made draft fix,issue,negative,positive,positive,positive,positive,positive
1166334779,"This also happens with non-TIMM models, i.e. by passing the _variable_ `resnet18`, rather than the string : 

```vision_learner(dls, resnet18, n_in=1, pretrained=True)```

And indeed, if we _do_ pass `n_in=3`, then it works, but it modifies the dataloaders such that they now return images with 3 channels, effectively overriding the `PILImageBW`

However, if we change `pretrained=False`, then it all works as expected, and it doesn't change the dataloaders.

---

Found the problem: when `pretrained=True`, then `vision_learner()` add a Normalization to the dataloaders (as documented). This normalization is 3-channel, so it makes your 1-channel dataloader return a 3-channel image, which is then no longer compatible with the 1-channel model. 

This can be seen in notebook https://github.com/fastai/fastai/blob/master/nbs/21_vision.learner.ipynb , section _`Learner` convenience functions_, function `_add_norm()`, which doesn't take `n_in` into account.  <small>(too bad we can't link to the notebook)</small>

I'm not sure what the solution could be here. Not do any normalization if `n_in != 3` ? Or adapts the `stats` of normalization accordingly? But this seems cumbersome",also passing rather string indeed pas work return effectively however change work change found problem add normalization normalization return image longer compatible model seen notebook section learner convenience function take account small bad ca link notebook sure solution could normalization normalization accordingly cumbersome,issue,negative,positive,neutral,neutral,positive,positive
1166215858,"something is really off!!! the old boilerplate codes doesnt seem to be working .... :( 
",something really old doesnt seem working,issue,negative,positive,neutral,neutral,positive,positive
1164969956,"@jakubLangr can you please share your notebook, I need to check how you were able to check the number of samples from the loading of data after doing aug transformations in fastai using tfms.
Also if you have done an evaluation of the object detection model using your thresholding over prediction boxes, I can take some help from that.
Thank you in advance.",please share notebook need check able check number loading data also done evaluation object detection model prediction take help thank advance,issue,positive,positive,positive,positive,positive,positive
1163371780,"(base) gerardogarcia@Gerardos-MacBook-Pro ~ % pip show fastai
Name: fastai
Version: 2.7.3
Summary: fastai simplifies training fast and accurate neural nets using modern best practices
Home-page: https://github.com/fastai/fastai/tree/master/
Author: Jeremy Howard, Sylvain Gugger, and contributors
Author-email: info@fast.ai
License: Apache Software License 2.0
Location: /Users/gerardogarcia/mambaforge/lib/python3.9/site-packages
Requires: fastcore, fastdownload, fastprogress, matplotlib, packaging, pandas, pillow, pip, pyyaml, requests, scikit-learn, scipy, spacy, torch, torchvision
Required-by: 
(base) gerardogarcia@Gerardos-MacBook-Pro ~ % pip show fastcore
Name: fastcore
Version: 1.4.5
Summary: Python supercharged for fastai development
Home-page: https://github.com/fastai/fastcore/tree/master/
Author: Jeremy Howard and Sylvain Gugger
Author-email: infos@fast.ai
License: Apache Software License 2.0
Location: /Users/gerardogarcia/mambaforge/lib/python3.9/site-packages
Requires: packaging, pip
Required-by: fastai, fastdownload
(base) gerardogarcia@Gerardos-MacBook-Pro ~ % 


",base pip show name version summary training fast accurate neural modern best author license apache license location pillow pip spacy torch base pip show name version summary python supercharged development author license apache license location pip base,issue,positive,negative,neutral,neutral,negative,negative
1163364085,"@geg00 what version of fastai do you have? I can't find that dataloader code anywhere.

Please do `pip show fastai` and report that version, `fastcore` as well

Though do note that fastai doesn't have mac support yet",version ca find code anywhere please pip show report version well though note mac support yet,issue,positive,neutral,neutral,neutral,neutral,neutral
1163357788,"You'd want the **distributed** training integration fastai has with Accelerate. 

- [The general docs are available here](https://docs.fast.ai/distributed.html)
- Tutorials with how to launch distributed training from a notebook [can be found here](https://docs.fast.ai/tutorial.distributed) that I personally recommend starting from. 
- Finally there's a number of examples with using the distributed training in a notebook [here](https://docs.fast.ai/distributed_app_examples) that follow the core examples from fastai. 

Just make sure you do `pip install accelerate` before starting!",want distributed training integration accelerate general available launch distributed training notebook found personally recommend starting finally number distributed training notebook follow core make sure pip install accelerate starting,issue,positive,positive,positive,positive,positive,positive
1160803401,"I modified the DataBlock to include all the unique Ids from the data frame and it resolve the problem.
The issue is that this is not very clear on the CategoryBlock class
I think it **should be implicit in the Class to include all unique values** from the identified source.

```
dls = DataBlock(
    blocks=(ImageBlock, CategoryBlock(vocab=list(df['Id'].unique()))),
    splitter=RandomSplitter(valid_pct = 0.2, seed=42),
    get_x=get_x,
    get_y=get_y,
    item_tfms=Resize((192, 288), method=ResizeMethod.Pad, pad_mode=PadMode.Zeros),
    batch_tfms=aug_transforms(size=(128, 192), min_scale=0.75)
).dataloaders(df)

```",include unique data frame resolve problem issue clear class think implicit class include unique source,issue,negative,positive,positive,positive,positive,positive
1159623798,Let's not add a dep - will break anyone using pillow-simd. I'll do a workaround. Thanks anyway!,let add break anyone thanks anyway,issue,negative,positive,positive,positive,positive,positive
1156802108,"Hello @muellerzr,

Thanks for the quick fix. It worked like a charm. I really appreciate the time you took to look into the issue. 

Thanks again. Cheers!",hello thanks quick fix worked like charm really appreciate time took look issue thanks,issue,positive,positive,positive,positive,positive,positive
1156784880,"@Outsiders17711 this pr will solve it: https://github.com/fastai/fastai/pull/3689

In the interim to try it out do:
```python
pip install git+https://github.com/muellerzr/fastai@distrib-fix
```",solve interim try python pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1156443828,Yeah yeah... I will try that. Thanks a lot.,yeah yeah try thanks lot,issue,positive,positive,positive,positive,positive,positive
1156442967,"In the interim until a solution is available of course :)

On Wed, Jun 15, 2022, 9:00 AM Zachary Mueller ***@***.***> wrote:

> Perhaps maybe compare the LR's used to see if they're similar as you scale?
>
> On Wed, Jun 15, 2022, 8:59 AM Oluwaleke Umar Yusuf <
> ***@***.***> wrote:
>
>> That sounds good.
>>
>> Thing is, my training setup has several rounds with increasing image
>> sizes. So I just call lr_find at the beginning of each round and use the
>> lrs.valley. This approach has given the best model accuracies till date.
>> It also makes the same code robust regardless of the dataset and image
>> sizes.
>>
>> Of course, if lr_find won't work, I will definitely have to use a
>> workaround. Unfortunately. 😓 Thanks for the suggestion.
>>
>> —
>> Reply to this email directly, view it on GitHub
>> <https://github.com/fastai/fastai/issues/3688#issuecomment-1156440937>,
>> or unsubscribe
>> <https://github.com/notifications/unsubscribe-auth/AB3YCV22XUSHWLCFJ5RHJ5LVPHHS7ANCNFSM5Y2SDIUQ>
>> .
>> You are receiving this because you were mentioned.Message ID:
>> ***@***.***>
>>
>
",interim solution available course wed wrote perhaps maybe compare used see similar scale wed wrote good thing training setup several increasing image size call beginning round use approach given best model till date also code robust regardless image size course wo work definitely use unfortunately thanks suggestion reply directly view id,issue,positive,positive,positive,positive,positive,positive
1156442356,"Perhaps maybe compare the LR's used to see if they're similar as you scale?

On Wed, Jun 15, 2022, 8:59 AM Oluwaleke Umar Yusuf ***@***.***>
wrote:

> That sounds good.
>
> Thing is, my training setup has several rounds with increasing image
> sizes. So I just call lr_find at the beginning of each round and use the
> lrs.valley. This approach has given the best model accuracies till date.
> It also makes the same code robust regardless of the dataset and image
> sizes.
>
> Of course, if lr_find won't work, I will definitely have to use a
> workaround. Unfortunately. 😓 Thanks for the suggestion.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3688#issuecomment-1156440937>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV22XUSHWLCFJ5RHJ5LVPHHS7ANCNFSM5Y2SDIUQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",perhaps maybe compare used see similar scale wed wrote good thing training setup several increasing image size call beginning round use approach given best model till date also code robust regardless image size course wo work definitely use unfortunately thanks suggestion reply directly view id,issue,positive,positive,positive,positive,positive,positive
1156440937,"That sounds good.

Thing is, my training setup has several rounds with increasing image sizes. So I just call `lr_find` at the beginning of each round and use the `lrs.valley`. This approach has given the best model accuracies till date. It also makes the same code robust regardless of the dataset and image sizes.

Of course, if `lr_find` won't work, I will definitely have to use a workaround. Unfortunately. 😓 Thanks for the suggestion.",good thing training setup several increasing image size call beginning round use approach given best model till date also code robust regardless image size course wo work definitely use unfortunately thanks suggestion,issue,positive,positive,positive,positive,positive,positive
1156432408,"I'd recommend finding an lr first, then just use the distributed setup for training :)

Or just use a close enough one. DS isn't an exact science after all

On Wed, Jun 15, 2022, 8:48 AM Oluwaleke Umar Yusuf ***@***.***>
wrote:

> Hello @muellerzr <https://github.com/muellerzr>,
>
> Done.
>
> I have been trying to switch my single GPU training code to a distributed
> one using Accelerate because my models are getting larger. I have gotten
> every other part of the code to work with Accelerate except LR Finder. Any
> help will be much appreciated.
>
> Thank you. Cheers.
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3688#issuecomment-1156429205>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV7T7GRMX5IEWSYVLDLVPHGIFANCNFSM5Y2SDIUQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",recommend finding first use distributed setup training use close enough one exact science wed wrote hello done trying switch single training code distributed one accelerate getting gotten every part code work accelerate except finder help much thank reply directly view id,issue,positive,positive,positive,positive,positive,positive
1156429205,"Hello @muellerzr,

Done. 

I have been trying to switch my single GPU training code to a distributed one using Accelerate because my models are getting larger. I have gotten every other part of the code to work with Accelerate except LR Finder.  Any help will be much appreciated. 

Thank you. Cheers.",hello done trying switch single training code distributed one accelerate getting gotten every part code work accelerate except finder help much thank,issue,positive,positive,neutral,neutral,positive,positive
1156422617,"Could we rename this to lr_find doesn't work in distributed setup then? 😄 I'll still try and work on it, but Accelerate isn't the root cause, it's a multiproc issue",could rename work distributed setup still try work accelerate root cause issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1156421006,"Hello @muellerzr,

I haven't used the distributed setup in fastai before. However, I just ran tests using the same code in `accelerate_lr_find_1.py` on the old setup. 

1. `python accelerate_lr_find_1.py` still works okay for `learn.lr_find` and `learn.fine_tune`. 
2. `accelerate launch accelerate_lr_find_1.py` worked okay for `learn.fine_tune`. 
3. With `accelerate launch accelerate_lr_find_1.py`, `learn.lr_find` **errored out** with the following stack trace:

```
(rhlu) oluwaleke@csep072172server1:~/outsiders17711/experiments$ accelerate launch accelerate_lr_find_1.py
Traceback (most recent call last):                                                                                                                   
  File ""accelerate_lr_find_1.py"", line 19, in <module>
    lrs = learn.lr_find(suggest_funcs=(valley, slide), show_plot=False)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/schedule.py"", line 285, in lr_find
    with self.no_logging(): self.fit(n_epoch, cbs=cb)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 221, in fit
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 165, in _with_events
    self(f'after_{event_type}');  final()
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 141, in __call__
    def __call__(self, event_name): L(event_name).map(self._call_one)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/foundation.py"", line 155, in map
    def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/basics.py"", line 698, in map_ex
    return list(res)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/basics.py"", line 683, in __call__
    return self.func(*fargs, **kwargs)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 145, in _call_one
    for cb in self.cbs.sorted('order'): cb(event_name)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/core.py"", line 45, in __call__
    if self.run and _run: res = getattr(self, event_name, noop)()
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/schedule.py"", line 196, in after_fit
    os.remove(tmp_f)
FileNotFoundError: [Errno 2] No such file or directory: '/home/oluwaleke/.fastai/data/oxford-iiit-pet/models/_tmp.pth'
Traceback (most recent call last):
  File ""accelerate_lr_find_1.py"", line 19, in <module>
    lrs = learn.lr_find(suggest_funcs=(valley, slide), show_plot=False)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/schedule.py"", line 285, in lr_find
lrs.valley = 5.248074739938602e-05 | lrs.slide = 9.999999747378752e-06
    with self.no_logging(): self.fit(n_epoch, cbs=cb)
Traceback (most recent call last):
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 221, in fit
  File ""accelerate_lr_find_1.py"", line 19, in <module>
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 165, in _with_events
    lrs = learn.lr_find(suggest_funcs=(valley, slide), show_plot=False)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/schedule.py"", line 285, in lr_find
    self(f'after_{event_type}');  final()
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 141, in __call__
    def __call__(self, event_name): L(event_name).map(self._call_one)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/foundation.py"", line 155, in map
    with self.no_logging(): self.fit(n_epoch, cbs=cb)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 221, in fit
    def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/basics.py"", line 698, in map_ex
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 165, in _with_events
    return list(res)
      File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/basics.py"", line 683, in __call__
self(f'after_{event_type}');  final()
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 141, in __call__
    def __call__(self, event_name): L(event_name).map(self._call_one)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/foundation.py"", line 155, in map
    return self.func(*fargs, **kwargs)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 145, in _call_one
    def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/basics.py"", line 698, in map_ex
    for cb in self.cbs.sorted('order'): cb(event_name)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/core.py"", line 45, in __call__
    if self.run and _run: res = getattr(self, event_name, noop)()
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/schedule.py"", line 196, in after_fit
    return list(res)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastcore/basics.py"", line 683, in __call__
    os.remove(tmp_f)
FileNotFoundError: [Errno 2] No such file or directory: '/home/oluwaleke/.fastai/data/oxford-iiit-pet/models/_tmp.pth'
    return self.func(*fargs, **kwargs)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/learner.py"", line 145, in _call_one
    for cb in self.cbs.sorted('order'): cb(event_name)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/core.py"", line 45, in __call__
    if self.run and _run: res = getattr(self, event_name, noop)()
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/fastai/callback/schedule.py"", line 196, in after_fit
    os.remove(tmp_f)
FileNotFoundError: [Errno 2] No such file or directory: '/home/oluwaleke/.fastai/data/oxford-iiit-pet/models/_tmp.pth'
Killing subprocess 17898
Killing subprocess 17899
Killing subprocess 17900
Killing subprocess 17901
Traceback (most recent call last):
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/runpy.py"", line 194, in _run_module_as_main
    return _run_code(code, main_globals, None,
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/runpy.py"", line 87, in _run_code
    exec(code, run_globals)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/torch/distributed/launch.py"", line 340, in <module>
    main()
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/torch/distributed/launch.py"", line 326, in main
    sigkill_handler(signal.SIGTERM, None)  # not coming back
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/torch/distributed/launch.py"", line 301, in sigkill_handler
    raise subprocess.CalledProcessError(returncode=last_return_code, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/oluwaleke/anaconda3/envs/rhlu/bin/python', '-u', 'accelerate_lr_find_1.py']' returned non-zero exit status 1.
Traceback (most recent call last):
  File ""/home/oluwaleke/anaconda3/envs/rhlu/bin/accelerate"", line 8, in <module>
    sys.exit(main())
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/accelerate/commands/accelerate_cli.py"", line 43, in main
    args.func(args)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/accelerate/commands/launch.py"", line 528, in launch_command
    multi_gpu_launcher(args)
  File ""/home/oluwaleke/anaconda3/envs/rhlu/lib/python3.8/site-packages/accelerate/commands/launch.py"", line 279, in multi_gpu_launcher
    raise subprocess.CalledProcessError(returncode=process.returncode, cmd=cmd)
subprocess.CalledProcessError: Command '['/home/oluwaleke/anaconda3/envs/rhlu/bin/python', '-m', 'torch.distributed.launch', '--use_env', '--nproc_per_node', '4', 'accelerate_lr_find_1.py']' returned non-zero exit status 1.
```

Looks like there's also an issue with LR Finder on the old setup. 

**My uninformed opinion:** 
From the stack trace, looks like all processes are trying to access the `_tmp.pth` file. The first process to access the file reads it (?), returns the lr_find results and then deletes the file, leaving the other processes hanging. I am not sure if something similar is happening with the new distributed setup since at least three lr_find results are returned.

Thanks.",hello used distributed setup however ran code old setup python still work accelerate launch worked accelerate launch following stack trace accelerate launch recent call last file line module valley slide file line file line fit file line self final file line self file line map map self return self file line return list file line return file line file line self noop file line file directory recent call last file line module valley slide file line recent call last file line fit file line module file line valley slide file line self final file line self file line map file line fit map self return self file line file line return list file line self final file line self file line map return file line map self return self file line file line self noop file line return list file line file directory return file line file line self noop file line file directory killing killing killing killing recent call last file line return code none file line code file line module main file line main none coming back file line raise command returned exit status recent call last file line module main file line main file line file line raise command returned exit status like also issue finder old setup uninformed opinion stack trace like trying access file first process access file file leaving hanging sure something similar happening new distributed setup since least three returned thanks,issue,negative,positive,neutral,neutral,positive,positive
1156389922,"So just to clarify, the old distributed setup in fastai would run lr_find just fine?

On Wed, Jun 15, 2022, 8:05 AM Oluwaleke Umar Yusuf ***@***.***>
wrote:

> Hello @muellerzr <https://github.com/muellerzr>,
>
> Thank you for your response.
>
> I created a new environment to test the Accelerate integration. I have no
> issues with learn.lr_find in my usual working environment.
>
> I also tried running the code in the gist I provided without Accelerate
> i.e. python accelerate_lr_find_1.py within the new environment. As
> expected, the training only occurred on GPU 0; learn.lr_find and
> learn.fine_tune worked okay; and the code terminated successfully.
>
> (d-rhlu) ***@***.***:~/outsiders17711/exps-distributed$ python accelerate_lr_find_1.py
> lrs.valley = 0.0010000000474974513 | lrs.slide = 0.003019951749593019559 3.0705]
> epoch     train_loss  valid_loss  error_rate  accuracy  time
> 0         0.413860    0.244745    0.108931    0.891069  02:13
> (d-rhlu) ***@***.***:~/outsiders17711/exps-distributed$
>
> —
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3688#issuecomment-1156387526>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV3UZJUAHYUAVQUFLYTVPHBKNANCNFSM5Y2SDIUQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",clarify old distributed setup would run fine wed wrote hello thank response new environment test accelerate integration usual working environment also tried running code gist provided without accelerate python within new environment training worked code successfully python epoch accuracy time reply directly view id,issue,positive,positive,positive,positive,positive,positive
1156387526,"Hello @muellerzr,

Thank you for your response. 

I created a new environment to test the Accelerate integration. I have no issues with `learn.lr_find` in my usual working environment. 

I also tried running the code in the gist I provided without Accelerate i.e.  `python accelerate_lr_find_1.py` within the new environment. As expected, the training only occurred on GPU 0; `learn.lr_find` and `learn.fine_tune` worked okay; and the code terminated successfully. 

```
(d-rhlu) oluwaleke@csep072172server1:~/outsiders17711/exps-distributed$ python accelerate_lr_find_1.py
lrs.valley = 0.0010000000474974513 | lrs.slide = 0.003019951749593019559 3.0705]
epoch     train_loss  valid_loss  error_rate  accuracy  time
0         0.413860    0.244745    0.108931    0.891069  02:13
(d-rhlu) oluwaleke@csep072172server1:~/outsiders17711/exps-distributed$
```
",hello thank response new environment test accelerate integration usual working environment also tried running code gist provided without accelerate python within new environment training worked code successfully python epoch accuracy time,issue,positive,positive,positive,positive,positive,positive
1156364320,Hi @Outsiders17711! Can you confirm if the LR finder worked before the integration?,hi confirm finder worked integration,issue,negative,neutral,neutral,neutral,neutral,neutral
1154536497,"> Thanks @naveensrinivasan . Can you explain how this is different to the dependabot stuff that runs by default?

The actions aren't getting updated. For example https://github.com/fastai/fastai/blob/ff215d4f853b206b7f6a85320f5efc77b4b28399/.github/workflows/main.yml#L29 is at `v2` where as there is `v3.1.0`

With this change Dependabot would open PR's to the actions.

HTH",thanks explain different stuff default getting example change would open,issue,negative,positive,neutral,neutral,positive,positive
1154526261,Thanks @naveensrinivasan . Can you explain how this is different to the dependabot stuff that runs by default?,thanks explain different stuff default,issue,negative,positive,neutral,neutral,positive,positive
1152062488,"I should have fixed the sync error, but if a nbdev `_all_` isn't on one line, it won't be added to the module's `__all__`.",fixed sync error one line wo added module,issue,negative,positive,neutral,neutral,positive,positive
1149992449,With recent Accelerate integration this is good now. cc @jph00 ,recent accelerate integration good,issue,negative,positive,positive,positive,positive,positive
1149991070,"You can now! The recent upgrade to the callback enables creating the CB outside the init.
@jph00  you can close this.",recent upgrade outside close,issue,negative,neutral,neutral,neutral,neutral,neutral
1148297442,"Turns out it was all down to my incompetence, after_item works as it should. In the example above the Resize transform simply doesn't know what to do with a tensor, pass a PILImage and all works as expected.",turn incompetence work example resize transform simply know tensor pas work,issue,negative,neutral,neutral,neutral,neutral,neutral
1145497003,"Closed due to fastai v2 no longer accepting major changes due to imminent development of fastai v3.

Metrics refactor can be used with fastai v2 via [fastxtend here](https://warner-benjamin.github.io/fastxtend/metrics.html).",closed due longer major due imminent development metric used via,issue,negative,negative,neutral,neutral,negative,negative
1145496432,Closed due to fastai v2 no longer accepting major changes due to imminent development of fastai v3.,closed due longer major due imminent development,issue,negative,negative,neutral,neutral,negative,negative
1144860180,"I've found a solution, but FYI @DanteOz, `df` needs to be on all processes so it's available to everyone all the time. You need to move that outside of the function and call it in a cell. 

A new `distributed_app_examples` notebook showing how all of this works is added in #3675 ",found solution need available everyone time need move outside function call cell new notebook showing work added,issue,negative,positive,positive,positive,positive,positive
1141427802,Nice - that's looking much better!,nice looking much better,issue,positive,positive,positive,positive,positive,positive
1140990957,"> Save `self.lengths` for the `df` mode as well.

To be honest, this solution can also be applied without any problems. Saving of lengths can be added to `Tokenizer.setups`. When these lengths are saved there, `if self.lengths is None: return None` will not be triggered in `get_lengths` if everything is initialized. Now `Tokenizer` with the `df` mode will have `self.lengths` that is not `None` as before. This solution is more ""general"" because it allows to call `self.lengths`.

I also encountered a bug when `tok_text_col` is different from the default name in `tokenize_df`. `'text_length'` is specified inside `get_lengths`, therefore, it will not be executed if you provide a different name.

Implemented this ""general"" solution. It works for every mode now. Please see the latest amended commit.

",save mode well honest solution also applied without saving added saved none return none triggered everything mode none solution general call also bug different default name inside therefore executed provide different name general solution work every mode please see latest commit,issue,positive,positive,positive,positive,positive,positive
1140534246,"> Many thanks for the PR. Note that fastai is an nbdev project, therefore edits need to be made in the notebooks, not the .py files -- the .py files are auto-generated. A walk-thru is here, if needed: https://docs.fast.ai/dev-setup.html

Got it. Only fixed it in `nbs/30_text.core.ipynb` and used `nbdev` to generate the .py files.

> Also, could you explain more about the reasoning for the first change you made, to reverse the check for `None`?

I think we don't need to reverse but the current version is incorrect anyway. Here is what I mean. There are two modes:
* `df`, it will save `text_length` into some DataFrame, however, it doesn't save these lengths into `self.lengths`.
* `folder`, it has `text_length` as `lengths.pkl`, moreover, it saves these lengths into `self.lengths`.

If `if self.lengths is None: return None` comes first, `if self.mode == 'df'` will never be executed because `self.lengths` is always `None` for this mode, these lengths are stored as a column in this DataFrame. Please note that `if self.mode == 'folder'` will work fine.

I see two solutions here:
* Save `self.lengths` for the `df` mode as well.
* Put `if self.lengths is None: return None` between `if self.mode == 'df'` and `if self.mode == 'folder'`. In this way, all the conditions above will be satisfied.

Sorry, that was my bad. I didn't check how the `folder` mode behaves. The changes were amended.",many thanks note project therefore need made got fixed used generate also could explain reasoning first change made reverse check none think need reverse current version incorrect anyway mean two save however save folder moreover none return none come first never executed always none mode column please note work fine see two save mode well put none return none way satisfied sorry bad check folder mode,issue,positive,positive,neutral,neutral,positive,positive
1140519502,"Many thanks for the PR. Note that fastai is an nbdev project, therefore edits need to be made in the notebooks, not the .py files -- the .py files are auto-generated. A walk-thru is here, if needed: https://docs.fast.ai/dev-setup.html

Also, could you explain more about the reasoning for the first change you made, to reverse the check for `None`?",many thanks note project therefore need made also could explain reasoning first change made reverse check none,issue,negative,positive,positive,positive,positive,positive
1139659484,@muellerzr Issue for bug reported on discord yesterday.,issue bug discord yesterday,issue,negative,neutral,neutral,neutral,neutral,neutral
1135318296,"> you need to add all required libs for running the notebooks to the dev requirements in `settings.ini`

Done. :-D",need add running dev done,issue,negative,neutral,neutral,neutral,neutral,neutral
1135295983,There's a CI failure -- that's because you need to add all required libs for running the notebooks to the dev requirements in `settings.ini`. Could you do that please?,failure need add running dev could please,issue,negative,negative,negative,negative,negative,negative
1133760482,"```python
    def __init__(self, dataset=None, bs=None, num_workers=0, pin_memory=False, timeout=0, batch_size=None,
                 shuffle=False, drop_last=False, indexed=None, n=None, device=None, persistent_workers=False,
                 pin_memory_device='', **kwargs):
....
        self.fake_l = _FakeLoader(self, pin_memory, num_workers, timeout, persistent_workers=persistent_workers,
                                  pin_memory_device=pin_memory_device)
```
Torch's default for `pin_memory_device` is a blank string.

I also updated the DistributedDL since that also does FakeLoader initialization.",python self self torch default blank string also since also,issue,negative,neutral,neutral,neutral,neutral,neutral
1133760144,"Solution was to convert the `__torch_function__` to a classmethod.

There was an issue during default_collate where if you call torch.stack, none of the `__dict__` values were passed along.
The original function, since it was `self`, would just use it's `__dict__`. since this is a class method, we select the `__dict__` from
the first `arg`. Whether or not this is the best way to do it I'm happy to debate, however I beleive this is functionally the same as how meta data was being propagated before.

```python
    @classmethod
    def __torch_function__(cls, func, types, args=(), kwargs=None):
        if cls.debug and func.__name__ not in ('__str__','__repr__'): print(func, types, args, kwargs)
        if is_listy(args[0]) and args[0]: dict_objs = [a for a in args[0] if hasattr(a,'__dict__')]
        else:                             dict_objs = [a for a in args if hasattr(a,'__dict__')]
        if _torch_handled(args, cls._opt, func): types = (torch.Tensor,)
        res = super().__torch_function__(func, types, args, ifnone(kwargs, {}))
        if issubclass(type(res),TensorBase) and dict_objs: res.set_meta(dict_objs[0],as_copy=True)
        return res
```
",solution convert issue call none along original function since self would use since class method select first whether best way happy debate however functionally meta data python print else super type return,issue,positive,positive,positive,positive,positive,positive
1133759574,@geg00 I'm making a pr tonight that fixes this along with some user warnings.,making tonight along user,issue,negative,neutral,neutral,neutral,neutral,neutral
1133179432,"@jph00 new release is now out, updated the tutorial w/ the new directions 😄 ",new release tutorial new,issue,negative,positive,positive,positive,positive,positive
1130418428,"Yes very welcome!

You'll need to `nbdev_build_lib` and also add it to `sidebar.json`.",yes welcome need also add,issue,positive,positive,positive,positive,positive,positive
1130414395,Got it @muellerzr -- I've made this a draft PR in the meantime. Let me know when it's ready to merge. (Which should wait until there's a pypi release of Accelerate.),got made draft let know ready merge wait release accelerate,issue,negative,positive,positive,positive,positive,positive
1130106479,We're moving `setup_accelerate` into it's on util in accelerate as it's more useful there. Will update this PR once that change has been made,moving accelerate useful update change made,issue,negative,positive,positive,positive,positive,positive
1127132575,"Looks great - thanks!

(Very minor formatting request - would be great to try to use a bit less vertical space in future PRs. e.g. assume terminal width >120 chars; put 1-line conditionals etc on same line)",great thanks minor request would great try use bit le vertical space future assume terminal width put line,issue,positive,positive,positive,positive,positive,positive
1126824922,Looks like it will be better to fix and open new PR,like better fix open new,issue,positive,positive,positive,positive,positive,positive
1126823824,"Oh, looks like I haven't pull the latest changes. Will update this tomorrow",oh like pull latest update tomorrow,issue,negative,positive,positive,positive,positive,positive
1125370726,"I wasn't sure what would be considered ""too much"" publicity/discussion on accelerate as a whole, let me know what you think about adding something like this  to the start of 20 distrib:

> When using multiple GPUs, you will most probably want to fit using distributed training. fastai utilizes [Accelerate](https://github.com/huggingface/accelerate) to make sure the process is as smooth as possible while keeping the code simplistic.  See [examples/distrib.py](https://github.com/fastai/fastai/blob/master/nbs/examples/distrib.py) for a complete example. To use distributed training, there are only two required steps:",sure would considered much accelerate whole let know think something like start multiple probably want fit distributed training accelerate make sure process smooth possible keeping code simplistic see complete example use distributed training two,issue,positive,positive,positive,positive,positive,positive
1124264130,"@warner-benjamin `after_backward` can be synonymous with `before_step`. But everyone should use `before_step` really, hence why it was left unmentioned.",synonymous everyone use really hence left unmentioned,issue,negative,positive,neutral,neutral,positive,positive
1124239038,"Could you update the Callback documentation to mention `after_backward` and what it is used for? Currently it reads:
```
- `before_backward`: called after the loss has been computed, but only in training mode (i.e. when the backward pass will be used)
- `before_step`: called after the backward pass, but before the update of the parameters. It can be used to do any change to the gradients before said update (gradient clipping for instance).
```",could update documentation mention used currently loss training mode backward pas used backward pas update used change said update gradient clipping instance,issue,negative,neutral,neutral,neutral,neutral,neutral
1123916929,I think the question of whether there is anything that should be fixed.  I am still unsure what the expected behavior is supposed to be since I am not using DistributedDL.  So I think the first thing to answer is what the expected behavior of fastai is in the scenario outlined above.  I think @marii-moe had the opinion that the current behavior is expected so there isn't really a bug.  I think at least it would need to be compared to see if it actually improves performance to change this or if there are times where one behavior is desired over the other.  ,think question whether anything fixed still unsure behavior supposed since think first thing answer behavior scenario outlined think opinion current behavior really bug think least would need see actually performance change time one behavior desired,issue,negative,positive,neutral,neutral,positive,positive
1122865660,"@jph00 you can close this...
no additional details are being provided and I am going to assume this is an error of trying to use fastai v1 code with fastai v2 (`get_transforms` is from fastai v1)",close additional provided going assume error trying use code,issue,negative,neutral,neutral,neutral,neutral,neutral
1121316590,"I am pasting this here. Have been running a bunch of sweeps comparing this  `timm` split vs the `default_split` method here:
https://wandb.ai/capecape/fine_tune_timm/sweeps . 

## (3 epoch finetune with 1/0 epoch fit) 
> A non-exhaustive exploration here shows that `default_split` works sometimes better for very short finetuning(3 epochs).

- `resnet34` 
<img width=""1072"" alt=""image"" src=""https://user-images.githubusercontent.com/18441985/167454931-cb00731b-aae7-4ebb-bc62-754978fe3295.png"">

-`regnetx_040`
<img width=""1063"" alt=""image"" src=""https://user-images.githubusercontent.com/18441985/167454823-96d9556a-01d9-406c-8060-d44fd71dd9ed.png"">

- `convnext_tiny`
> This model is insane!! 🚀
<img width=""1076"" alt=""image"" src=""https://user-images.githubusercontent.com/18441985/167455040-ac3927d2-4c17-46e2-b0cc-66fbe7a150b8.png"">
",pasting running bunch split method epoch epoch fit exploration work sometimes better short image image model insane rocket image,issue,positive,negative,neutral,neutral,negative,negative
1120806129,Hi @ahmedsamirio unfortunately nothing better than the forced garbage collection after every prediction as outlined in the issue,hi unfortunately nothing better forced garbage collection every prediction outlined issue,issue,negative,negative,negative,negative,negative,negative
1120202512,"Hey Robbie, did you find any solution to that problem? I'm currently encountering it during inference and have found no solution to it until now.",hey find solution problem currently inference found solution,issue,negative,neutral,neutral,neutral,neutral,neutral
1120115463,@kevinbird15 is this fixed yet? I don't think so since the test is the same and not updated... What needs to be fixed here?,fixed yet think since test need fixed,issue,negative,positive,neutral,neutral,positive,positive
1120112223,"Original poster has not responded and issue cannot be replicated
@jph00 this can be closed...",original poster issue replicated closed,issue,negative,positive,positive,positive,positive,positive
1120097936,Please provide more details for us to be able to help you otherwise we'll close this issue...,please provide u able help otherwise close issue,issue,positive,positive,positive,positive,positive,positive
1119977580,"Thanks for the great PR, @tcapelle ! I'll wait to hear back from @rwightman about a pypi release of the needed functionality before we merge this.",thanks great wait hear back release functionality merge,issue,positive,positive,positive,positive,positive,positive
1116356196,Thank you @jph00! Upgrading `nbdev` worked. Sorry for the earlier mismatch between the writing style of the fastai docs and my first commit. I made strong changes to be consistent with fastai.,thank worked sorry mismatch writing style first commit made strong consistent,issue,positive,positive,positive,positive,positive,positive
1113993081,"Any support for this issue is welcome.
Posting here as no support is available after posting in [forum.fastai](https://forums.fast.ai/)",support issue welcome posting support available posting,issue,positive,positive,positive,positive,positive,positive
1113958893,@jph00 thanks now it works when executing simultaneous inference calls! https://github.com/loretoparisi/tinypets,thanks work simultaneous inference,issue,negative,positive,positive,positive,positive,positive
1113903230,Message ID: ***@***.***>That's probably due to a bug I just fixed in nbdev a few minutes ago. Can you try upgrading to the latest nbdev and rebuild?,message id probably due bug fixed ago try latest rebuild,issue,negative,positive,positive,positive,positive,positive
1113899172,"Thank you for your kind guidance @jph00! I applied it accordingly. Just one question:
- The [fastai/huggingface.py](https://github.com/fastai/fastai/pull/3627/files#diff-5285402466cd6b3095c6e52eb0688f764b9a416c6b838fd2dc75a00c9a1658d8) file, although empty, is still being generated after running [`nbdev_build_lib`](https://nbdev.fast.ai/export2html.html#nbdev_build_lib). Shall I eliminate it?",thank kind guidance applied accordingly one question file although empty still running shall eliminate,issue,positive,positive,positive,positive,positive,positive
1112855814,"Thanks @omarespejel . A few requests:

- Remember this is fastai docs, not hf docs. Don't use words like ""us""
- Remove all marketing-oriented material, such as statistics about HF Hub
- Try to match fastai's prose style. We don't tend to use stuff like emojis. We try to focus on just imparting what the user needs to know
- Move the implementation code into HF's lib, rather than implementing it here. This should just be a tutorial
- Be sure to clean your NBs. `nbdev_install_git_hooks` will do that automatically. https://docs.fast.ai/dev-setup.html
- We're not too fussy about it, but try to follow at least the spirit of our coding style guide: https://docs.fast.ai/dev/style.html
",thanks remember use like u remove material statistic hub try match prose style tend use stuff like try focus user need know move implementation code rather tutorial sure clean automatically fussy try follow least spirit style guide,issue,positive,positive,positive,positive,positive,positive
1110716765,This issue remains open at least on my side. Any ideas how to fix it?,issue remains open least side fix,issue,negative,negative,negative,negative,negative,negative
1108353128,@rwightman I am also facing the same issue (DataParallel not working and showing a GPU missmatch) and unfortunately the link you provided is not working. Can you please guide us?,also facing issue working showing unfortunately link provided working please guide u,issue,negative,negative,negative,negative,negative,negative
1107899251,@rsomani95 It's on my todo list to add back a cached option,list add back option,issue,negative,neutral,neutral,neutral,neutral,neutral
1107832737,"@warner-benjamin With the changes made here, one would be re-running inference on each call of plotting the confusion matrix or fetching the `skm` classification report, right? If so, that could get very cumbersome esp. with larger test sets, and if you wanted to use the stored predictions for anything else.",made one would inference call plotting confusion matrix fetching classification report right could get cumbersome test use anything else,issue,negative,positive,positive,positive,positive,positive
1106716579,Please use forums.fast.ai for help with the course,please use help course,issue,positive,neutral,neutral,neutral,neutral,neutral
1102636815,"Oh i read it as you (Boris) were going to run the tests, my bad haha 😄. I'll quickly check the same and add a PR. ",oh read going run bad quickly check add,issue,negative,negative,negative,negative,negative,negative
1102628215,"Oh I thought you planned to make a PR?
I had just suggested to check there is no negative impact on non distributed mode first.",oh thought make check negative impact non distributed mode first,issue,negative,negative,neutral,neutral,negative,negative
1097496458,I have the same issue. I can't use fastai on Python 3.6 because of the annotations import which was available with Python 3.7 and onwards.,issue ca use python import available python onwards,issue,negative,positive,positive,positive,positive,positive
1090600321,Many thanks for letting us know - I've removed that from the sidebar now.,many thanks u know removed,issue,negative,positive,positive,positive,positive,positive
1090453549,Users reported having trouble installing fastai using the command pip install -e .[dev]. Specifically the issue was due to azureml module. See https://github.com/fastaidocsprint/fastai/pull/2#issuecomment-1039163535 ,trouble command pip install dev specifically issue due module see,issue,negative,negative,negative,negative,negative,negative
1090208808,I think the issue relates to [this commit](https://github.com/fastai/fastai/commit/ac905f74297296fd0d3a15282104bd33e978b4fc) from @jph00 which disabled the Azure ML callback (but did not remove the [link](https://github.com/fastai/fastai/blob/409a22a487a7807bb2d00bd688a1bfe7ccb8d01c/docs_src/sidebar.json#L122) from the navigation bar). However there seems to be no explanation as to why it was disabled...,think issue commit disabled azure remove link navigation bar however explanation disabled,issue,negative,negative,negative,negative,negative,negative
1086661571,"I don't remember why it was added but maybe it's not needed anymore.
I would check everything works well in non distributed mode to be sure (the tests from the notebook should be sufficient). If all is fine a PR would be awesome!",remember added maybe would check everything work well non distributed mode sure notebook sufficient fine would awesome,issue,positive,positive,positive,positive,positive,positive
1086567692,Yes removing the `to_detach()` calls in WandbCallback's `after_batch` did the job. Should I make a PR for this?,yes removing job make,issue,negative,neutral,neutral,neutral,neutral,neutral
1086277423,"The error seems to be when extracting the loss with:
```python
{
'train_loss': to_detach(self.smooth_loss.clone()),
'raw_loss': to_detach(self.loss.clone())
}
```

What about [this solution](https://github.com/fastai/fastai/issues/3291#issuecomment-812953720) from above?
Does it work for you?",error loss python solution work,issue,negative,neutral,neutral,neutral,neutral,neutral
1085056966,"I found if the `path` in e.g. 

`data.ImageDataLoaders.from_df(path=""/"", ...)`

then you will get a `learn.load` error like yours above as it uses `Path` to locate the model. It needs to be to be set in the `cnn_learner` before calling `learn.load`. e.g.

```python
learn = fastlib.cnn_learner(fastai_data, fastlib.resnet34, model_dir=/path/to/model/)
learn.load('model_name.pth')
```",found path get error like path locate model need set calling python learn,issue,negative,neutral,neutral,neutral,neutral,neutral
1085011929,@hamelsmu any fix for this? I am still facing this problem while training in DDP environment.,fix still facing problem training environment,issue,negative,neutral,neutral,neutral,neutral,neutral
1079810347,"@jph00 okay, that was an exploration and a half but we got callbacks working. One thing I did have to do though was move up where the exception classes were defined so they can be pulled into `Callback.__call__`. Since we already use `show_doc` for them all though, I think it would make sense to keep the documentation in the same spot",exploration half got working one thing though move exception class defined since already use though think would make sense keep documentation spot,issue,negative,negative,negative,negative,negative,negative
1079791715,@muellerzr can you take a look at this CI failure? Might just be a case of needing to merge lastest fastai changes - not sure.,take look failure might case needing merge sure,issue,negative,positive,neutral,neutral,positive,positive
1079791595,Aware there's a small bug with the tests in there I think. Will get to it in the next few days ,aware small bug think get next day,issue,negative,neutral,neutral,neutral,neutral,neutral
1077879972,"seems like there's no new release since the fix, so its still an issue.",like new release since fix still issue,issue,negative,positive,positive,positive,positive,positive
1073618387,Sorry for the late reply! I think 958fdcd285e0b28d7d2fa4d1e207eabc1722096f should fix the test.,sorry late reply think fix test,issue,negative,negative,negative,negative,negative,negative
1067182482,Many thanks for the PR. Could you please take a look at the CI test failure?,many thanks could please take look test failure,issue,negative,positive,positive,positive,positive,positive
1060966065,"Resolving this issue would require increasing fastai's minimum torch version from [1.7.0](https://pytorch.org/docs/1.7.0/generated/torch.div.html) to [1.8.0](https://pytorch.org/docs/1.8.0/generated/torch.div.html), which is the first version that deprecates [floor_divide](https://pytorch.org/docs/1.8.0/generated/torch.floor_divide.html).",issue would require increasing minimum torch version first version,issue,negative,positive,positive,positive,positive,positive
1059812444,ImageDataBunch is for fastai v1 so you will either need to download v1 or update your code to use something like [ImageDataLoaders](https://docs.fast.ai/vision.data.html#ImageDataLoaders.from_folder) instead,either need update code use something like instead,issue,negative,neutral,neutral,neutral,neutral,neutral
1058295621,"This would be a nice modification to the current callback.  I don't think there are any downsides to this since it will still check, but not before it actually needs it",would nice modification current think since still check actually need,issue,negative,positive,positive,positive,positive,positive
1058056391,"Thank you for chiming in 😊
Yes, I could initialize a run like that. Typically, when I am developing a function for creating a learner, there are many failures before I end up with something good. And if I kick off a run for every try, I end up with a bunch of runs in W&B that are not very useful (hence the question).",thank yes could initialize run like typically function learner many end something good kick run every try end bunch useful hence question,issue,positive,positive,positive,positive,positive,positive
1057866675,"After creating the learner, you could do:
```python
from fastai.callback.wandb import *

learn = Learner(...)

model_path = learn.save(""non_trained_model"")

with wandb.init():
  log_model(model_path, ""non_trained_model"")

learn.add_cbs([WandbCallback(...)])
```

I agree with you, the check for run could be delayed.
",learner could python import learn learner agree check run could,issue,negative,neutral,neutral,neutral,neutral,neutral
1055929849,"Just noticed the same thing.  I think it is because of this comma: 
```
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""# Dataloader"", <<<<<<<
   ]
  },
```",thing think comma markdown source,issue,negative,neutral,neutral,neutral,neutral,neutral
1055927197,This doesn't seem to be a correct PR - the resultant notebook doesn't work,seem correct resultant notebook work,issue,negative,neutral,neutral,neutral,neutral,neutral
1055310625,"> how did you solve this error? I have the same issue and its bothering me for days. Please help. Thanks in advance

help",solve error issue day please help thanks advance help,issue,positive,positive,positive,positive,positive,positive
1055308906,"how did you solve this error? I have the same issue and its bothering me for days. Please help. 
Thanks in advance",solve error issue day please help thanks advance,issue,positive,positive,positive,positive,positive,positive
1051079031,"2022_02_25

OK - 
get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])
dls_lm = DataBlock(
    blocks=TextBlock.from_folder(path, is_lm=True),
    get_items=get_imdb, splitter=RandomSplitter(0.1)
).dataloaders(path, path=path, bs=128, seq_len=80)

blows up because  the get_imdb statement is not finished and there is a delay, but the dls_lm block starts running.

Separate in the Jupyter Notebook

into
[1]  get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])

[2] dls_lm = DataBlock(
    blocks=TextBlock.from_folder(path, is_lm=True),
    get_items=get_imdb, splitter=RandomSplitter(0.1)
).dataloaders(path, path=path, bs=128, seq_len=80)

and it will run -IF you have already run it - delete imdb_tok directory - Then try the above

and the dls_lm block takes a while to run...
This worked for me in anaconda on Windows 10

",partial path path statement finished delay block running separate notebook partial path path run already run delete directory try block run worked anaconda,issue,negative,negative,neutral,neutral,negative,negative
1049475818,"Thanks, @eric-vanartsdalen. I upgraded the Pytorch version to '1.10.1+cu113'. Now the error becomes: 
`ModuleNotFoundError: No module named 'torchvision.models.utils'`

my torchvision version is:
`'0.11.2+cu113'`",thanks version error becomes module version,issue,negative,positive,positive,positive,positive,positive
1047023317,"Digging into this a little bit more, it looks like I am seeing the values for the specific functions in fs.  so for instance if I do:
```
tmp = Hue(max_hue=.5, batch=False)
tmp.fs[0].__stored_args__
```
I see the stored args for the function I want to.  So I'm wondering if I just misunderstand what the top level p=1 means",digging little bit like seeing specific instance hue see function want wondering misunderstand top level,issue,negative,positive,positive,positive,positive,positive
1046958049,"I just double-checked this and LightingTfm is working properly so it isn't affecting all tfms that inherit from SpaceTfm. Here is the list I have so far of Tfms affected: [Hue, Brightness, Contrast, Saturation, Warp, Zoom, Rotate, Dihedral]

",working properly affecting inherit list far affected hue brightness contrast saturation warp zoom rotate dihedral,issue,negative,positive,neutral,neutral,positive,positive
1046217373,"This error is coming from Pytorch itself. You may have to find a version of Pytorch which supports compute compatibility 8.6...
See:
https://pytorch.org/get-started/locally/
Note: fastai setup.ini indicates the version of pytorch>=1.7.0,<1.11

Also any possible issues in Pytorch forums itself might help guide you.
https://github.com/pytorch/pytorch/issues?q=is%3Aissue+is%3Aopen++%22RTX+3080%22",error coming may find version compute compatibility see note version also possible might help guide,issue,negative,neutral,neutral,neutral,neutral,neutral
1041157352,"Sorry, messed up the branching. Will create another PR with correct commit",sorry branching create another correct commit,issue,negative,negative,negative,negative,negative,negative
1039848469,"@kevinbird15  I did the following in my notebook:
```
import sys
!{sys.executable} -m pip install fastai
```",following notebook import pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1039597290,Nice and simple - good one!,nice simple good one,issue,positive,positive,positive,positive,positive,positive
1038812682,Great! I ran `nbdev_build_lib` and everything seems to be working (although I'll check the build again after it's finished). Let me know if there's anything else I need to do.,great ran everything working although check build finished let know anything else need,issue,positive,positive,positive,positive,positive,positive
1038617721,How did you install fastai?  I have had success using light-the-torch to install pytorch.  Not sure if this is something fastai can resolve,install success install sure something resolve,issue,positive,positive,positive,positive,positive,positive
1038615452,@jph00 This is good to be merged now I believe.  Thanks for the patience hopefully you didn't get too many notifications on this.  I will try coming with a more complete solution next time before I PR. :),good believe thanks patience hopefully get many try coming complete solution next time,issue,positive,positive,positive,positive,positive,positive
1038605758,"I would hold off.  I think @marii-moe brought up some good points and I am currently re-considering a lot of the changes I tried making to DataLoader.get_idxs.  I am going to move back a few commits and probably just leave it at making changes to get_preds and leave everything else how it is currently since it has such big implications. I will make the changes back now and let you know when it's done.  I do think there are a few core concepts that could use some discussion specifically what drop_last should and shouldn't do in regard to DataLoader, what drop_last should mean in a DistributedDL, and what the reorder argument in get_preds is doing and should be doing.  ",would hold think brought good currently lot tried making going move back probably leave making leave everything else currently since big make back let know done think core could use discussion specifically regard mean reorder argument,issue,negative,positive,neutral,neutral,positive,positive
1037825609,"If the other fix is right, this test would pass with `test_eq(list(dl1), [torch.arange(i*12, i*12+12)%50])`",fix right test would pas list,issue,negative,positive,positive,positive,positive,positive
1037560660,New fix also would close #3579 if it is a valid change,new fix also would close valid change,issue,negative,positive,positive,positive,positive,positive
1037393620,"Getting closer on this.  I found the reason that Tabular is failing.  It is because `reorder` in get_preds defaults to True and before since we were passing a list, it didn't have a get_idxs attribute so this wouldn't have executed, but since I am making it a proper DataLoader, it gets into this section of code. 
https://github.com/fastai/fastai/blob/681ae88211e0bd7d90259c65ce008fa227d02dfa/fastai/learner.py#L260

So far, what I've found is that text handles this properly and looks like the input is a tensor 
```
ipdb> (t_)
TensorText([[[2.1220e-02, 9.1441e-07, 7.8817e-03,  ..., 2.0213e-05,
          3.1001e-05, 3.1001e-05],
         [1.8548e-02, 5.8384e-08, 2.9509e-03,  ..., 7.1964e-06,
          4.1149e-06, 4.1149e-06],
         [2.3482e-02, 3.5561e-08, 5.9080e-04,  ..., 2.9862e-06,
          2.2433e-06, 2.2433e-06],
         [6.7106e-04, 1.3014e-08, 8.7557e-05,  ..., 8.7888e-07,
          7.7342e-07, 7.7342e-07],
         [8.5899e-04, 7.3736e-09, 4.2166e-05,  ..., 5.1746e-07,
          5.1974e-07, 5.1974e-07],
         [6.1429e-03, 6.5549e-09, 6.1269e-06,  ..., 1.1527e-06,
          5.2226e-07, 5.2226e-07]]])
ipdb> t_.shape
torch.Size([1, 6, 7080])
```

But for tabular, it seems to be missing a dimension

```
ipdb> (t_)
        [0.9484, 0.0516],
        [0.9642, 0.0358],
        [0.9744, 0.0256],
        [0.9719, 0.0281],
        [0.9803, 0.0197],
        [0.9605, 0.0395],
...
        [0.8389, 0.1611],
        [0.6571, 0.3429],
        [0.2968, 0.7032],
        [0.9422, 0.0578],
        [0.9649, 0.0351]])
ipdb> t_.shape
torch.Size([64, 2])
```

I can confirm this is missing by adding a [None] and getting the results we expect to see: 
```
ipdb> nested_reorder(t_[None], idxs)
tensor([[[0.9017, 0.0983],
         [0.6036, 0.3964],
         [0.1391, 0.8609],
         [0.6555, 0.3445],
         [0.6673, 0.3327],
         ...
```

`t` maps back in get_preds to res and following that back, I see cb.all_tensors() creates res.  When I step into that, I see self.preds is what populates that.  

Still looking into this, but at the moment I think it might have to do with how DataLoader.get_idxs is interacting with the the preds.  ",getting closer found reason tabular failing reorder true since passing list attribute would executed since making proper section code far found text properly like input tensor tabular missing dimension confirm missing none getting expect see none tensor back following back see step see still looking moment think might,issue,negative,positive,neutral,neutral,positive,positive
1037033290,Still a little more work to get this fully working. I notice that Tabular show_results seems to be giving some issues with the changes but will explore more tomorrow ,still little work get fully working notice tabular giving explore tomorrow,issue,negative,negative,negative,negative,negative,negative
1037017955,"Thankfully the tests caught an interesting use-case of Learner.get_preds that I hadn't considered.  

Currently the get_preds does the DataLoader check by checking for the existence of a `len`: 
https://github.com/fastai/fastai/blob/681ae88211e0bd7d90259c65ce008fa227d02dfa/fastai/learner.py#L243-L245
I'm wondering if this would be a better check: 
```
            if not isinstance(dl, DataLoader):
                raise TypeError(f""`dl` is {type(dl)} rather than a single `DataLoader` object"")
```
Because of this, the LMLearner uses this to pass a list to get_preds rather than a true DataLoader.  
https://github.com/fastai/fastai/blob/681ae88211e0bd7d90259c65ce008fa227d02dfa/fastai/text/learner.py#L158-L161

What I am trying to track down currently is why this works in get_preds?  
I *think* something must happen in self._do_epoch_validate that allows this behavior.
https://github.com/fastai/fastai/blob/681ae88211e0bd7d90259c65ce008fa227d02dfa/fastai/learner.py#L253
",thankfully caught interesting considered currently check existence wondering would better check raise type rather single object pas list rather true trying track currently work think something must happen behavior,issue,positive,positive,positive,positive,positive,positive
1036992174,"I looked into this and I think the *problem* is how you are creating your test_dl.  I think the preferred method of getting a test_dl to put into `preds, ground_truth = learn.get_preds(dl=test_dls.train)` would be https://docs.fast.ai/data.core.html#DataLoaders.test_dl and here is an example using your example: 

```python
test_dl = learn.dls.test_dl(test_df)
preds, ground_truth = learn.get_preds(dl=test_dl)
test_dl.drop_last #This now outputs False by default
```

I think this should still be considered a bug though because if I pass the training set in using ds_idx=0, it runs fine because get_preds specifically creates a new dl with drop_last=False: 
`if dl is None: dl = self.dls[ds_idx].new(shuffle=False, drop_last=False)`

I think the question is whether we want to change a dl that somebody specifically passes in to get_preds if somebody passes a dl that is *not* None.  I can think of a few different ways to handle it.  Probably the easiest would just be to do a dl check and say 

```
if dl.drop_last: dl = dl.new(shuffle=False, drop_last=False)
```

I've tested this and it does work so I'm adding it as a suggested fix in new incoming PR",think problem think preferred method getting put would example example python false default think still considered bug though pas training set fine specifically new none think question whether want change somebody specifically somebody none think different way handle probably easiest would check say tested work fix new incoming,issue,negative,positive,neutral,neutral,positive,positive
1036650625,"Thanks - this doesn't look like a good fit for our docs, but I appreciate your time to discuss it",thanks look like good fit appreciate time discus,issue,positive,positive,positive,positive,positive,positive
1035902065,"@jph00 Thanks, here is a colab notebook for fastai applications - quick start with minimal gradio demos added for each section https://colab.research.google.com/drive/1jMpV7q8Jly-M21YFovv-aTomtfyg1ZLL?usp=sharing

 the actual models for each task on the quick start page could be ""opened in Spaces"" (https://huggingface.co/spaces) so that people can start interactively using the models in their browser. This would really make this quick start guide accessible to an even wider audience, e.g. those starting out in ML

the badges currently are not linked to a Space

<img width=""832"" alt=""Screen Shot 2022-02-11 at 12 48 50 AM"" src=""https://user-images.githubusercontent.com/81195143/153543563-cf43f62a-9a81-48a2-ba90-3990bfa8e0c0.png"">

here is the example computer vision classification gradio demo

<img width=""611"" alt=""Screen Shot 2022-02-11 at 12 54 59 AM"" src=""https://user-images.githubusercontent.com/81195143/153544020-49bea04d-6336-43f5-bbed-91a696bb1646.png"">
",thanks notebook quick start minimal demo added section actual task quick start page could people start browser would really make quick start guide accessible even audience starting currently linked space screen shot example computer vision classification screen shot,issue,positive,positive,positive,positive,positive,positive
1034870105,"I found this issue, because I searched for a way to handle the orientation flag with JPG images in fastai/pytorch. So yes, I can confirm the problem, but don't have a solution, either.

cv2 handles the JPG orientation flag correctly, but I couldn't find a way to use cv2 instead of PIL as the image reading backend.
",found issue way handle orientation flag yes confirm problem solution either orientation flag correctly could find way use instead image reading,issue,negative,neutral,neutral,neutral,neutral,neutral
1034516417,"To do: Update all the references to and usage of existing functional metrics in tutorials, examples, etc.",update usage functional metric,issue,negative,neutral,neutral,neutral,neutral,neutral
1034493305,"Thanks @AK391 can you provide an example for one of fastai's notebooks, so I can see what it would look like?",thanks ak provide example one see would look like,issue,positive,positive,positive,positive,positive,positive
1034470542,"My concern that I had with this PR is that it would somehow hurt the automatic docs deployment so I was watching close for the next PR after this was merged.  #3573 was the next PR and it adds a `name` option to AccumMetric.  I just checked the docs and it shows up properly so I am pretty comfortable now saying this change is valid and could probably be replicated in the rest of the docker-compose.yml files.

![image](https://user-images.githubusercontent.com/7451178/153334481-c27988c2-7c37-426d-916b-c570d4b22c89.png)

The only other concern that I have is with this warning that I first noticed because I was looking very close at CI/CD pipeline after #3571.  `WARNING: Error loading config file: /root/.docker/config.json: open /root/.docker/config.json: permission denied`

But when I looked closer, I see this has been happening for quite some time so it appears to be unrelated and also doesn't seem to matter?  I will investigate separately, but closing this as resolved for the fastai repo
Dug into this warning a bit more and it definitely isn't an issue that I'm causing.  It seems to be something with the runner itself and the yml setting the HOME variable but since it doesn't seem like it causes issues, I would say ignoring it is fine",concern would somehow hurt automatic deployment watching close next next name option checked properly pretty comfortable saying change valid could probably replicated rest image concern warning first looking close pipeline warning error loading file open permission closer see happening quite time unrelated also seem matter investigate separately resolved dug warning bit definitely issue causing something runner setting home variable since seem like would say fine,issue,negative,positive,positive,positive,positive,positive
1034416210,"@muellerzr I think I have a reproducible example that passes a single `DataLoader` to `get_preds` and gets the same error.

I am often in a situation where I have to train and validate a model then save it, then later I'll need to load it and test it on a new set of data. I used `train_test_split` here instead of a `splitter` so it is a closer match to that scenario.
```
from fastai.tabular.all import *
from sklearn.model_selection import train_test_split

path = untar_data(URLs.ADULT_SAMPLE)
df = pd.read_csv(path/'adult.csv')
train_df, test_df = train_test_split(df, random_state=42)
dep_var = 'salary'
continuous_vars, categorical_vars = cont_cat_split(df, dep_var=dep_var)
categorical_vars.remove('native-country')
preprocessing = [Categorify, FillMissing, Normalize]
df_wrapper = TabularPandas(train_df, procs=preprocessing, cat_names=categorical_vars, cont_names=continuous_vars,
                   y_names=dep_var)
batch_size = 128
dls = df_wrapper.dataloaders(bs=batch_size)
learn = tabular_learner(dls, layers=[20,10])
learn.fit(1, 1e-2)
```
Now that the model is trained, I created a `TabularPandas` for my test data and try to `get_preds`

```
test_df_wrapper = TabularPandas(test_df, preprocessing, categorical_vars, continuous_vars, y_names=dep_var)
test_dls = test_df_wrapper.dataloaders(batch_size)#, drop_last=False)
preds, ground_truth = learn.get_preds(dl=test_dls.train)
```

This produces this error: `IndexError: index 8092 is out of bounds for dimension 0 with size 8064`

However, if I set `drop_last` to `False`, it works without an error.

This seems to match the experience of the users above and (I believe) correctly passes a `fastai.tabular.core.TabDataLoader`
object, but let me know if I missed something.
",think reproducible example single error often situation train validate model save later need load test new set data used instead splitter closer match scenario import import path normalize learn model trained test data try error index dimension size however set false work without error match experience believe correctly object let know something,issue,negative,negative,neutral,neutral,negative,negative
1034253403,OK I'll merge this now - but please keep an eye on CI for future commits to see if there's an issue,merge please keep eye future see issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1031797299,I was trying to publish a model on HuggingFace and it failed for the same reason. gbinnie's fix solved it.  Thanks! https://huggingface.co/spaces/GotAudio/Understanding-Women,trying publish model reason fix thanks,issue,negative,positive,positive,positive,positive,positive
1030757501,"I haven't seen any issues with this change locally and it seems to be fine in the ci pipeline.  I think if it is going to fail, it would be on the docs action which I don't think runs until merging to master.  I tried running that test on my end but wasn't able to get it running. ",seen change locally fine pipeline think going fail would action think master tried running test end able get running,issue,negative,positive,positive,positive,positive,positive
1029077841,"Unfortunately `doc()` is not the default way of getting docs in a notebook environment. I'm teaching my second class with fastai and I didn't know about it. It would be really helpful if the docstring gave some sort of hint about this, either to also include the docs link, or at least to say something like ""see docs(this_function) for more"". Perhaps this is something that the nbdev build step could add in.
",unfortunately doc default way getting notebook environment teaching second class know would really helpful gave sort hint either also include link least say something like see perhaps something build step could add,issue,negative,negative,negative,negative,negative,negative
1022657000,"it is not implemented yet
https://docs.fast.ai/losses.html#DiceLoss
class BaseLoss
class CrossEntropyLossFlat
class FocalLoss
class FocalLossFlat
class BCEWithLogitsLossFlat
BCELossFlat
MSELossFlat
L1LossFlat
class LabelSmoothingCrossEntropy
class LabelSmoothingCrossEntropyFlat
class DiceLoss",yet class class class class class class class class,issue,negative,neutral,neutral,neutral,neutral,neutral
1022656109,"great idea 
thanks
when it will be ready ?",great idea thanks ready,issue,positive,positive,positive,positive,positive,positive
1022028797,"cheers, I'm gonna rebase and run this, thanks.",gon na rebase run thanks,issue,negative,positive,positive,positive,positive,positive
1021716223,Apologies @tgalery I hadn't seen this. You need to run `nbdev_build_lib` as discussed in the developers guide: https://docs.fast.ai/dev-setup.html . Many thanks!,seen need run guide many thanks,issue,negative,positive,positive,positive,positive,positive
1020826715,@jph00 I tried to rebase the new commits earlier and I guess GH created a merge commit. I've removed those.,tried rebase new guess merge commit removed,issue,negative,positive,positive,positive,positive,positive
1020792236,I am having one issue with this for ClassificationInterpretation.  Working on a fix now and will detail in a new issue as well. ,one issue working fix detail new issue well,issue,negative,positive,positive,positive,positive,positive
1020745540,"@kwsp sorry it has taken me a while to get to this.

Could you please add the `ImageBlock` import to a non-exported cell? Otherwise it become part of the exported lib, resulting in circular references.

Also, would you be able to add a bit of Markdown prose explaining the code you added?",sorry taken get could please add import cell otherwise become part resulting circular also would able add bit markdown prose explaining code added,issue,negative,neutral,neutral,neutral,neutral,neutral
1015555881,"What I can understand is that the train_dl and valid_dl are created like that already when creating the dataloaders, e.g., when I do:
```
dblocks = DataBlock(
	blocks=(TextBlock.from_df('phrase'), CategoryBlock),
	get_x=ColReader('text'),
	get_y=ColReader('intent'), 
	splitter=ColSplitter(""is_valid"")
)
dls = dblocks.dataloaders(df, bs=batch_size)
```
`dblocks.datasets(df, verbose=True)` looks like:

```
Collecting items from                                                                                                                                                                                                                               phrase  \
0 [redacted]
...   
1199        [redacted]

                       intent  is_validation  
0                [redacted]              0  
...                       ...            ...  
1199          [redacted]              1  

[12003 rows x 3 columns]
Found 12003 items
2 datasets of sizes 10803,1200
Setting up Pipeline: ColReader -- {'cols': 'text', 'pref': '', 'suff': '', 'label_delim': None} -> Tokenizer -> Numericalize

/home/andres/anaconda3/envs/training/lib/python3.8/site-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray
  return array(a, dtype, copy=False, order=order)

Setting up Pipeline: ColReader -- {'cols': 'intent', 'pref': '', 'suff': '', 'label_delim': None} -> Categorize -- {'vocab': None, 'sort': True, 'add_na': False}
```",understand like already like phrase intent found size setting pipeline none ragged different meant must specify return array setting pipeline none categorize none true false,issue,positive,negative,neutral,neutral,negative,negative
1013742847,"Maybe update a small part in the 'welcome to fastai' documentation:

<i>""When installing with mamba or conda replace -c fastchan in the installation with -c pytorch -c nvidia -c fastai, since fastchan is not currently supported on Windows.

Due to python multiprocessing issues on Jupyter and Windows, num_workers of Dataloader is reset to 0 automatically to avoid Jupyter hanging. This makes tasks such as computer vision in Jupyter on Windows many times slower than on Linux. This limitation doesn't exist if you use fastai from a script.

See this example to fully leverage the fastai API on Windows.""</i>

I went through all the steps but I can only run it from a script when I add the argument num_worker = 0, otherwise I get the THCudaCheck FAIL error. Setting num_worker to 0 gives me the same speed as I would get running it through the jupyter notebook interface. 

So I am not sure about that sentence <i>'This limitation doesn't exist if you use fastai from a script'</i>. As I understand it after going through the docs and the forum, there is no support for doing GPU operations with Windows, only Linux. 

Another thing is that I installed fastai via this anaconda line > conda install -c fastchan fastai anaconda.

But this says; <i>'When installing with mamba or conda replace -c fastchan in the installation with -c pytorch -c nvidia -c fastai, since fastchan is not currently supported on Windows.'</i>

Not sure if this means I also needed to do that for anaconda or only for that miniconda version, since the original worked fine for anaconda.",maybe update small part documentation mamba replace installation since currently due python reset automatically avoid hanging computer vision many time limitation exist use script see example fully leverage went run script add argument otherwise get fail error setting speed would get running notebook interface sure sentence limitation exist use script understand going forum support another thing via anaconda line install anaconda mamba replace installation since currently sure also anaconda version since original worked fine anaconda,issue,negative,positive,positive,positive,positive,positive
1010108727,"I was getting this error in the quick_start notebook in the paperspace/fastai container in the TextDataLoaders.from_folder with the IMDB dataset with a 1070ti card (8GB). I changed the batchsize (bs=16) and it doesn't run out of memory, though it's a bit slow.

TextDataLoaders.from_folder(<all the other, previous args>, bs=16) ",getting error notebook container ti card run memory though bit slow previous,issue,negative,negative,negative,negative,negative,negative
1008911013,"I'm having the same issue, and the proposed solution doesn't actually work as it doesn't create the spm.model output so I suspect it removes some of the SubwordTokenizer properties",issue solution actually work create output suspect,issue,negative,neutral,neutral,neutral,neutral,neutral
1008346836,I think that would be right. I haven't been deployed though.,think would right though,issue,negative,positive,positive,positive,positive,positive
996837176,getting an error of  'TransformerTextClassLearner' object has no attribute 'recorder' on tensor flow 2.2.1,getting error object attribute tensor flow,issue,negative,neutral,neutral,neutral,neutral,neutral
991988320,Many thanks for your clear analysis @warner-benjamin ,many thanks clear analysis,issue,positive,positive,positive,positive,positive,positive
991737984,"Thanks for following up so quickly on this Benjamin. 
This issue only occurs to me on Python 3.6, even if I use the latest versions of fastai and fastcore.
But it works fine with higher versions of Python. I've upgraded to Python 3.7 so I don't have this issue anymore.",thanks following quickly benjamin issue python even use latest work fine higher python python issue,issue,positive,positive,positive,positive,positive,positive
991717076,"I investigated this and the fastai RSME appears to be working correctly.

The sklearn docs example below returns 0.6124
```python
from sklearn.metrics import mean_squared_error
y_true = [3, -0.5, 2, 7]
y_pred = [2.5, 0.0, 2, 8]
mean_squared_error(y_true, y_pred, squared=False)
```

The fastai metrics test for RSME also returns 0.6124
```python
from fastai.learner import Learner
from fastai.metrics import rmse
import torch

class TstLearner(Learner):
    def __init__(self,dls=None,model=None,**kwargs): self.pred,self.xb,self.yb = None,None,None

def compute_val(met, x1, x2):
    met.reset()
    vals = [0,6,15,20]
    learn = TstLearner()
    for i in range(3):
        learn.pred,learn.yb = x1[vals[i]:vals[i+1]],(x2[vals[i]:vals[i+1]],)
        met.accumulate(learn)
    return met.value
    
y_true = torch.tensor([3, -0.5, 2, 7])
y_pred = torch.tensor([2.5, 0.0, 2, 8])
compute_val(rmse, y_pred, y_true)
```

And if we construct a simple tabular training loop, the metric also returns 0.6124 for all batch sizes [1,4]:
```python
from fastai.tabular.all import *

# add zeros to be the training set
df = pd.DataFrame.from_dict({'preds': [0, 2.5, 0.0, 2, 8], 'true': [0, 3, -0.5, 2, 7]})

# create the datablock with 0s in training set, rest in valid set
tp = TabularPandas(df, cont_names='preds', y_names=['true'], splits=([0], [i for i in range(1,5)]))

# uncomment to verify the valid dataloader has all the rsme test values
# dls = tp.dataloaders(bs=2)
# dls.valid_ds

# dummy model which just passes input, __init__ is so the optimizer doesn't error out
class DummyModel(Module):
    def __init__(self): self.a = nn.Parameter(torch.randn(1))

    def forward(self, *x):
        return x[1]

# no matter the batch size (1,2,3,4), we expect the metric result to be #0.6124. Which it is
rmse_metrics = []
for bs in range(1,5):
    dls = tp.dataloaders(bs=bs)
    learn = Learner(dls, DummyModel(), loss_func=MSELossFlat(), metrics=rmse)
    rmse_metrics.append(learn.validate()[1])

print(rmse_metrics)
```",working correctly example python import metric test also python import learner import import torch class learner self none none none met learn range learn return construct simple tabular training loop metric also batch size python import add training set create training set rest valid set range verify valid test dummy model input error class module self forward self return matter batch size expect metric result range learn learner print,issue,negative,neutral,neutral,neutral,neutral,neutral
991349303,"You need to upgrade the fastai install from Colab's default of fastai v1 to fastai v2:

```
!pip install fastcore fastai --upgrade
```
upgrading fastcore wouldn't hurt either.",need upgrade install default pip install upgrade would hurt either,issue,negative,neutral,neutral,neutral,neutral,neutral
988152030,"I was unable to reproduce this issue. `Learner.export` worked without error running this code:
```python
from fastai.vision.all import *
path = untar_data(URLs.PETS)
pets = DataBlock(blocks = (ImageBlock, CategoryBlock),
                 get_items=get_image_files, 
                 splitter=RandomSplitter(seed=42),
                 get_y=using_attr(RegexLabeller(r'(.+)_\d+.jpg$'), 'name'),
                 item_tfms=Resize(460),
                 batch_tfms=aug_transforms(size=224, min_scale=0.75))
dls = pets.dataloaders(path/""images"")
learn = cnn_learner(dls, resnet34, loss_func=LabelSmoothingCrossEntropyFlat(), metrics=error_rate)
learn.export(""LabelSmoothingCrossEntropyFlat.pkl"")
```
on Windows with Python 3.7.11 & PyTorch 1.9.1 and Ubuntu with Python 3.9.7 & PyTorch 1.10.0. Both using the latest versions of fastai and fastcore.",unable reproduce issue worked without error running code python import path learn python python latest,issue,negative,neutral,neutral,neutral,neutral,neutral
982833754,"fastai was written to be used via import all
```python
from fastai.tabular.all import *
```
if you have more troubleshooting questions, please head to the [forums](https://forums.fast.ai).

Since the original reported issue is resolved, please close the github issue. Thanks!",written used via import python import please head since original issue resolved please close issue thanks,issue,positive,positive,positive,positive,positive,positive
982775111,"This solved the issue for me:
```
import threading
thread_lock = threading.Lock()  # thread locking is necessary to support multiple threads
thread_lock.acquire()
active_model = ...
dl = ...
probas     = active_model.get_preds(dl=dl)
thread_lock.release()
```",issue import thread locking necessary support multiple,issue,negative,neutral,neutral,neutral,neutral,neutral
982702547,"Just to complete the example with the use of `test_dl`, I got stuck by another piece of fastai, the **type dispatch**. Using my script from above I always ran into an error:

```python
import numpy as np
import pandas as pd

from fastai.tabular.core import Normalize
from fastai.tabular.core import FillMissing
from fastai.tabular.core import TabularPandas
from fastai.tabular.core import IndexSplitter

from fastcore.basics import store_attr
from fastcore.transform import Pipeline


N, M = 150, 15

def create_df(N:int, M:int, scaling_factor:float=30.0, prop_na:float=0.0, start_idx:int=0):   
    X = np.random.rand(N, M)

    if prop_na>0.0 and prop_na<1.0:
        mask = ~(X < prop_na)
        X = np.where(mask, X, np.nan)
    
    X *= scaling_factor
    
    X = pd.DataFrame(X,
                  index=[f'sample_{i:0{len(str(N))}}' for i in range(start_idx, start_idx+N)],
                  columns=(f'feat_{i:0{len(str(M))}}' for i in range(M)))
    return X



X = create_df(N, M)
X_test = create_df(int(N*0.1), M, prop_na=.1)


idx_val = X.sample(frac=0.2).index # RandomSplitter could be used, but used to show IndexSplitter usage with Tabular


splits = X.index.get_indexer(idx_val) # In Tabular iloc is used, not loc for splitting
splits = IndexSplitter(splits)(X) # splits is are to list of integer indicies (for iloc)


class FillMissingKeepAll(FillMissing):
    def setups(self, to):
        store_attr(but='to', na_dict={n:self.fill_strategy(to[n], self.fill_vals[n])
                            for n in to.conts.keys()})
        self.fill_strategy = self.fill_strategy.__name__



procs = [Normalize, FillMissingKeepAll] # FillMissing does not allow missing values in features only in validation data


to = TabularPandas(X, procs=procs, cont_names=X.columns.to_list(), splits=splits) # to = tabular object
print(""Tabular object:"", type(to))

dls = to.dataloaders()
dl_test = dls.test_dl(X_test)
dl_test.one_batch()
```
throws
```python
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-9-6a149e70c2e7> in <module>
     57 dls = to.dataloaders()
     58 dl_test = dls.test_dl(X_test)
---> 59 dl_test.one_batch()

~\Anaconda3\envs\vaep\lib\site-packages\fastai\data\load.py in one_batch(self)
    146     def one_batch(self):
    147         if self.n is not None and len(self)==0: raise ValueError(f'This DataLoader does not contain any batches')
--> 148         with self.fake_l.no_multiproc(): res = first(self)
    149         if hasattr(self, 'it'): delattr(self, 'it')
    150         return res

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\basics.py in first(x, f, negate, **kwargs)
    545     x = iter(x)
    546     if f: x = filter_ex(x, f=f, negate=negate, gen=True, **kwargs)
--> 547     return next(x, None)
    548 
    549 # Cell

~\Anaconda3\envs\vaep\lib\site-packages\fastai\data\load.py in __iter__(self)
    109         for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
    110             if self.device is not None: b = to_device(b, self.device)
--> 111             yield self.after_batch(b)
    112         self.after_iter()
    113         if hasattr(self, 'it'): del(self.it)

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\transform.py in __call__(self, o)
    198         self.fs = self.fs.sorted(key='order')
    199 
--> 200     def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)
    201     def __repr__(self): return f""Pipeline: {' -> '.join([f.name for f in self.fs if f.name != 'noop'])}""
    202     def __getitem__(self,i): return self.fs[i]

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\transform.py in compose_tfms(x, tfms, is_enc, reverse, **kwargs)
    148     for f in tfms:
    149         if not is_enc: f = f.decode
--> 150         x = f(x, **kwargs)
    151     return x
    152 

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\transform.py in __call__(self, x, **kwargs)
    111     ""A transform that always take tuples as items""
    112     _retain = True
--> 113     def __call__(self, x, **kwargs): return self._call1(x, '__call__', **kwargs)
    114     def decode(self, x, **kwargs):   return self._call1(x, 'decode', **kwargs)
    115     def _call1(self, x, name, **kwargs):

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\transform.py in _call1(self, x, name, **kwargs)
    114     def decode(self, x, **kwargs):   return self._call1(x, 'decode', **kwargs)
    115     def _call1(self, x, name, **kwargs):
--> 116         if not _is_tuple(x): return getattr(super(), name)(x, **kwargs)
    117         y = getattr(super(), name)(list(x), **kwargs)
    118         if not self._retain: return y

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\transform.py in __call__(self, x, **kwargs)
     71     @property
     72     def name(self): return getattr(self, '_name', _get_name(self))
---> 73     def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)
     74     def decode  (self, x, **kwargs): return self._call('decodes', x, **kwargs)
     75     def __repr__(self): return f'{self.name}:\nencodes: {self.encodes}decodes: {self.decodes}'

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\transform.py in _call(self, fn, x, split_idx, **kwargs)
     81     def _call(self, fn, x, split_idx=None, **kwargs):
     82         if split_idx!=self.split_idx and self.split_idx is not None: return x
---> 83         return self._do_call(getattr(self, fn), x, **kwargs)
     84 
     85     def _do_call(self, f, x, **kwargs):

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\transform.py in _do_call(self, f, x, **kwargs)
     87             if f is None: return x
     88             ret = f.returns(x) if hasattr(f,'returns') else None
---> 89             return retain_type(f(x, **kwargs), x, ret)
     90         res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)
     91         return retain_type(res, x)

~\Anaconda3\envs\vaep\lib\site-packages\fastcore\dispatch.py in __call__(self, *args, **kwargs)
    116         elif self.inst is not None: f = MethodType(f, self.inst)
    117         elif self.owner is not None: f = MethodType(f, self.owner)
--> 118         return f(*args, **kwargs)
    119 
    120     def __get__(self, inst, owner):

~\Anaconda3\envs\vaep\lib\site-packages\fastai\tabular\core.py in encodes(self, to)
    322 
    323     def encodes(self, to):
--> 324         if not to.with_cont: res = (tensor(to.cats).long(),)
    325         else: res = (tensor(to.cats).long(),tensor(to.conts).float())
    326         ys = [n for n in to.y_names if n in to.items.columns]

~\Anaconda3\envs\vaep\lib\site-packages\pandas\core\generic.py in __getattr__(self, name)
   5463             if self._info_axis._can_hold_identifiers_and_holds_name(name):
   5464                 return self[name]
-> 5465             return object.__getattribute__(self, name)
   5466 
   5467     def __setattr__(self, name: str, value) -> None:

AttributeError: 'DataFrame' object has no attribute 'with_cont'
```

If I use instead the recommended way of importing everything for `Tabular` data, i.e 

```python
from fastai.tabular.all import * 
```
the error went away and looking at what this imports 
> ```python
> # look at what this statement imports
> _globals = dict(globals())
> from fastai.tabular.all import * 
> print(""Imported into global scope:"")
> globals().keys() - _globals.keys()
> ```

reminded me of the fastai setup, finding the line 

https://github.com/fastai/fastai/blob/351f4b9314e2ea23684fb2e19235ee5c5ef8cbfd/fastai/tabular/data.py#L35

So best is to probably don't do manuel imports and use the `*`. Everything works though if this `DataLoader` for `Tabular` is imported into the script.

```python
# make DataLoaders.test_dl work for DataFrames as test_items:
from fastai.tabular.all import TabularDataLoaders
```

I uploaded the code to a notebook on colab [here](https://colab.research.google.com/drive/1hIyCRhZCeaLfeRLUfxRg5ibdMAsdJr4e?usp=sharing)",complete example use got stuck another piece type dispatch script always ran error python import import import normalize import import import import import pipeline mask mask range range return could used used show usage tabular tabular used splitting list integer class self normalize allow missing validation data tabular object print tabular object type python recent call last module self self none self raise contain first self self self return first negate iter return next none cell self none yield self self self return self return pipeline self return reverse return self transform always take true self return decode self return self name self name decode self return self name return super name super name list return self property name self return self self self return decode self return self return self self none return return self self self none return ret else none return ret return self none none return self owner self self tensor else tensor tensor self name name return self name return self name self name value none object attribute use instead way everything tabular data python import error went away looking python look statement import print global scope setup finding line best probably use everything work though tabular script python make work import code notebook,issue,positive,positive,positive,positive,positive,positive
982419334,"Hej @warner-benjamin,

thanks a lot.  So yesterday I ran

```
procs = [Normalize, FillMissing] # FillMissing does not allow missing values in features only in validation data

to = TabularPandas(X, procs=procs, cont_names=X.columns.to_list(), splits=splits) # to = tabular object
print(""Tabular object:"", type(to))
```

where the `Tabular` instance was transformed, but the `to.procs.fs` was an empty list. I tried to run your example on colab and it indeed works there. I'll try to setup my environment again and see if this will make a difference.

Thanks for the hint to `DataLoaders.test_dl(test_df)`! I wasn't aware of this helper function...
",thanks lot yesterday ran normalize allow missing validation data tabular object print tabular object type tabular instance empty list tried run example indeed work try setup environment see make difference thanks hint aware helper function,issue,positive,positive,neutral,neutral,positive,positive
982054374,"Hi @enryH, 

The example code is passing None to `procs`:

```python
to = TabularPandas(X, procs=None, cont_names=X.columns.to_list(), splits=splits)
```
so `to.procs.fs` being empty would be expected.

If you pass a pre-processor to `procs` when creating a `TabularPandas` object:

```python
to = TabularPandas(X, procs=Normalize, cont_names=X.columns.to_list(), splits=splits)
```
then calling `to.procs.fs` will show the pre-processor as expected:
```python
to.procs.fs
# (#1) [Normalize -- {'mean': None, 'std': None, 'axes': (0, 2, 3), 'means': {'feat_00': 15.122079, 'feat_01': 15.30869, 'feat_02': 15.738014, ...} }:
# encodes: (TensorImage,object) -> encodes
# (Tabular,object) -> encodes
# decodes: (TensorImage,object) -> decodes
# (Tabular,object) -> decodes
# ]
```
The fastai [tabular tutorial](https://docs.fast.ai/tutorial.tabular.html) shows how to use a TabularPandas dataloader on test data, which will apply the pre-processors to unseen data.",hi example code passing none python empty would pas object python calling show python normalize none none object tabular object object tabular object tabular tutorial use test data apply unseen data,issue,negative,negative,neutral,neutral,negative,negative
981833672,"This is cool, it's been on my TODO list for a while already!
My recommendation would be to only update the `wandb_process` functions but log using `Tables` instead. What do you think?",cool list already recommendation would update log table instead think,issue,negative,positive,positive,positive,positive,positive
981054763,"I still get this issue - fast ai version '2.5.2'
",still get issue fast ai version,issue,negative,positive,positive,positive,positive,positive
976819887,"@Daocuong-main please tell us your versions of:

```bash
pip show fastai fastcore fastbook
```
And your environment. Are you running in Colab?",please tell u bash pip show environment running,issue,negative,neutral,neutral,neutral,neutral,neutral
976768405,"> Further help for those who find this page... I just found this page after running, on Colab,
> 
> ```
> !pip install -Uqq fastbook
> import fastbook
> ```
> 
> ...as in the fastbook notebooks.
> 
> What you need to do is run
> 
> ```
> !pip install -Uqq fastai fastbook
> ```
> 
> THEN restart the runtime. Then you can run ""import fastbook"" and it will work.

it doesn't work for me",help find page found page running pip install import need run pip install restart run import work work,issue,negative,neutral,neutral,neutral,neutral,neutral
975155232,Okay please close the issue if the problem is resolved...,please close issue problem resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
975140798,"> Why are you trying to import fastai.core? The old version of fastai had a fastai.core module but not the current, v2 version.

Yes, I installed the version 1.0.51. The problem is solved now. ",trying import old version module current version yes version problem,issue,negative,positive,neutral,neutral,positive,positive
975081535,"Why are you trying to import fastai.core? The old version of fastai had a fastai.core module but not the current, v2 version.",trying import old version module current version,issue,negative,positive,neutral,neutral,positive,positive
975032834,"> > 
> 
> Thanks for your reply and could you please tell me how to install it?

Ok, I got it. But it is fastcore. That means I should turn the code ""import fastai.core"" to ""import fastcore""?",thanks reply could please tell install got turn code import import,issue,positive,positive,positive,positive,positive,positive
975030883,"> 

Thanks for your reply and could you please tell me how to install it?",thanks reply could please tell install,issue,positive,positive,positive,positive,positive,positive
974410009,There is a fastcore package. Could you try install that and try?,package could try install try,issue,negative,neutral,neutral,neutral,neutral,neutral
972668338,"Ok thanks that makes sense now! I assumed a ""get_preds"" call would only output predictions as i already have the target values from the df_test and that the second element of the tuple was the argmax() operation on the logits (fisrt element of the output tuple)",thanks sense assumed call would output already target second element operation element output,issue,negative,positive,neutral,neutral,positive,positive
972230550,"Hi @cconstantinou73,

[`Learner.get_preds`](https://docs.fast.ai/learner.html#Learner.get_preds) returns a tuple of predictions and targets. The example scores a perfect accuracy because the code here:
```python
# isolate predictions
y_preds_test_2 = y_preds_test_2[1].flatten().numpy()
```
uses the targets, not the predictions. Comparing the returned predictions from `Learner.get_preds` will result in the same accuracy as looping over `Learner.predict` to generate the predictions.
",hi example perfect accuracy code python isolate returned result accuracy looping generate,issue,negative,positive,positive,positive,positive,positive
968071214,"@kamalravi Could you provide the environment info and a reproducer?

I believe it infers from your data. So could not tell why it is not able to infer. May checking `data.show_batch()` might help.

loss_func could be CrossEntropyLossFlat .
`learn = text_classifier_learner(dbunch_clas, AWD_LSTM, drop_mult=0.5, metrics=accuracy, loss_func=CrossEntropyLossFlat()).to_fp16()`

Example : https://walkwithfastai.com/Pets#Time-to-make-and-train-a-model!
",could provide environment reproducer believe data could tell able infer may might help could learn example,issue,negative,positive,positive,positive,positive,positive
966094167,"@jph00 I think this can be closed. or maybe keep open until released?
It was reverted on the 29th Oct  
https://github.com/fastai/fastai/commit/841dd664ceb73b2dc5d246735acc3c720689b35c 

",think closed maybe keep open th,issue,negative,negative,neutral,neutral,negative,negative
965928235,"Well, finally figured this out with some help from Zach ...

Having a call to `dls.train.one_batch` in a callback will undo setting all the random seeds right before `fit` because the dataset is shuffled on each iteration, thereby changing the order of items when training starts.

Seems like a best practice for callback authors is to use `dls.valid.one_batch` should they need a batch to work with.",well finally figured help call undo setting random right fit iteration thereby order training like best practice use need batch work,issue,positive,positive,positive,positive,positive,positive
961538453,"Will do. Do you mind if I add that in a later PR?

-wg


On Thu, Nov 4, 2021 at 5:30 PM Jeremy Howard ***@***.***>
wrote:

> Many thanks. Do you want to also add a test for this so it doesn't break
> again in the future?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3520#issuecomment-961536370>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAADNMH6O3YW4H4BH7ZXHITUKMQR7ANCNFSM5HMWF75A>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
",mind add later wrote many thanks want also add test break future thread reply directly view triage go mobile android,issue,negative,positive,positive,positive,positive,positive
961536370,Many thanks. Do you want to also add a test for this so it doesn't break again in the future? ,many thanks want also add test break future,issue,negative,positive,positive,positive,positive,positive
960429587,@Theivaprakasham do you have a minimum code example to reproduce the issue? Thanks. I have been using top_k_accuracy recently and had no issues.,minimum code example reproduce issue thanks recently,issue,negative,positive,neutral,neutral,positive,positive
958124766,Both PRs fastai/fastcore#378 and #3518 resolve this issue. Thanks for catching it @Rebolforces.,resolve issue thanks catching,issue,positive,positive,positive,positive,positive,positive
956750228,Looks like it's all sorted! I'll update the fastcore version dep too.,like sorted update version,issue,negative,neutral,neutral,neutral,neutral,neutral
956013496,I think a function is a great idea ,think function great idea,issue,positive,positive,positive,positive,positive,positive
955931778,"Yeah. I can submit a PR for that. There's another incorrect version string comparison in [layers](https://github.com/fastai/fastai/blob/f8b74ef5b320512a2bb4a6c3cb17a5e917b7d6a3/fastai/layers.py#L598) which I copied for this PR.

Would it be preferred to add a get_torch_version method which returns a packaging.version.Version object in torch_core, or do the entire version check where needed?

There's also a PyTorch 0.4 check in [fp16_utils](https://github.com/fastai/fastai/blob/ab154927696338741e59e0ffc4774777c4a9781c/fastai/fp16_utils.py#L183) and a PyTorch 1.4 check in [examples/train_imdbclassifier.py](https://github.com/fastai/fastai/blob/ab154927696338741e59e0ffc4774777c4a9781c/nbs/examples/train_imdbclassifier.py#L36) which both can be removed.",yeah submit another incorrect version string comparison copied would preferred add method object entire version check also check check removed,issue,negative,neutral,neutral,neutral,neutral,neutral
955887733,"Yes good point. @Rebolforces @warner-benjamin perhaps one of you could fix it with a PR that does something like shown here:
https://stackoverflow.com/questions/11887762/how-do-i-compare-version-numbers-in-python/21065570 ",yes good point perhaps one could fix something like shown,issue,positive,positive,positive,positive,positive,positive
955644516,Just another thought: what if instead of `listify(flatten(self.pred))[0]` we did `next(flatten(self.pred))` ? That would avoid needlessly allocating extra memory.,another thought instead flatten next flatten would avoid needlessly extra memory,issue,negative,neutral,neutral,neutral,neutral,neutral
955644398,OK happy to leave it as-is then. Well spotted on the `concat` name clash - that's actually been there for ages but no-one had noticed before!,happy leave well spotted name clash actually,issue,positive,positive,positive,positive,positive,positive
955184134,"@jph00  we have a conflict with `torch_core.concat`
I did a quick fix but found another bug, try:
```python
retain_type([1,2,3], tuple([1]))
> [1,2,3]
```
it should be:
```
> (1,2,3)
```",conflict quick fix found another bug try python,issue,negative,positive,positive,positive,positive,positive
955099166,"@tcapelle can you please try changing `listify(flatten(...))` to `concat(...)`, since that's the same thing now",please try flatten since thing,issue,negative,neutral,neutral,neutral,neutral,neutral
954672187,"~~@jph00  do you know why the test is not passing?~~ my bad, it is missing the fastcore integration of `flatten` [PR](https://github.com/fastai/fastcore/pull/375)",know test passing bad missing integration flatten,issue,negative,negative,negative,negative,negative,negative
954561792,"I could do something like 
```python
def flatten(object):
    for item in object:
        if isinstance(item, (list, tuple, set)):
            yield from flatten(item)
        else:
            yield item
```",could something like python flatten object item object item list set yield flatten item else yield item,issue,negative,neutral,neutral,neutral,neutral,neutral
953293397,I'll merge this for now - but feel free to follow up with another PR if you guys feel there's a better approach.,merge feel free follow another feel better approach,issue,positive,positive,positive,positive,positive,positive
953291651,"No I don't think there's a chance of ""losing"" one batch from validation set, since the Learner creates a new iterator when it does validation, which will reset it.",think chance losing one batch validation set since learner new validation reset,issue,negative,positive,positive,positive,positive,positive
953261002,"Granted that we don't know why this is happening, but what are the risks
with this change? All the tests pass and it fixes a problem that exists at
least in my use case (perhaps others).

The risk isn't just losing a batch ... it is getting entirely different
model weights, metrics, and losses.  Its not just happening in the callback
as I can reproduce the issue by calling `Learner.dls.train.one_batch()`
just on its own AFTER unfreezing the learner (thats another weird thing,
this only happens after unfreezing).  Not sure how particular this is to me
using Blurr, or training transformers in general, or just certain kind of
transformers when the labels are included in the inputs, or if it might be
affecting other models unnoticed ... still trying to figure it out.

Anyways, yah, another option is to remove the code entirely if its not
essential ... up to you.  A last option is for me to patch the
`gather_args` method as I'm doing now and let folks using Blurr know to
watch out for this.

Lmk whatever you decide ... I can work with any of the options.

Thanks -wg

On Wed, Oct 27, 2021 at 11:43 AM Boris Dayma ***@***.***>
wrote:

> Hi,
>
> I'm not really sure why it happens but I'm scared of a fix where we don't
> understand why it works and the possible impacts.
>
> Would there be a risk of ""losing"" one batch from validation set, which
> would affect the reported validation metrics?
>
> Here this used just to infer inputs dimensions and report them to wandb.
> Since it's not essential maybe we just remove the ""input dimensions
> inference""?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3512#issuecomment-953210684>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAADNMELLG4BI6WNX7PP3FDUJBB55ANCNFSM5GZQ27TA>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
",know happening change pas problem least use case perhaps risk losing batch getting entirely different model metric happening reproduce issue calling unfreezing learner thats another weird thing unfreezing sure particular training general certain kind included might affecting unnoticed still trying figure anyways yah another option remove code entirely essential last option patch method let know watch whatever decide work thanks wed wrote hi really sure fix understand work possible would risk losing one batch validation set would affect validation metric used infer report since essential maybe remove input inference thread reply directly view triage go mobile android,issue,negative,positive,neutral,neutral,positive,positive
953210684,"Hi,

I'm not really sure why it happens but I'm scared of a fix where we don't understand why it works and the possible impacts.

Would there be a risk of ""losing"" one batch from validation set, which would affect the reported validation metrics?

Here this used just to infer inputs dimensions and report them to wandb. Since it's not essential maybe we just remove the ""input dimensions inference""?",hi really sure fix understand work possible would risk losing one batch validation set would affect validation metric used infer report since essential maybe remove input inference,issue,negative,positive,positive,positive,positive,positive
953144829,"Done.

On Wed, Oct 27, 2021 at 1:33 AM Jeremy Howard ***@***.***>
wrote:

> Can you please install the git hooks and clean the Nb?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3512#issuecomment-952669854>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAADNMFAALKJ6QKAU23Y2WTUI62PBANCNFSM5GZQ27TA>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
",done wed wrote please install git clean thread reply directly view triage go mobile android,issue,positive,positive,positive,positive,positive,positive
952830097,"This is not supported, as model hooks are not supported by the ONNX export.
I would recommend using a native torchvision segmentation model if your goal is to export to ONNX.
currently, the deeplabV3 models are pretty good.
```python
from torchvision.models.segmentation import deeplabv3_mobilenet_v3_large
```",model export would recommend native segmentation model goal export currently pretty good python import,issue,positive,positive,positive,positive,positive,positive
952669854,Can you please install the git hooks and clean the Nb? ,please install git clean,issue,positive,positive,positive,positive,positive,positive
951548139,"Personally I don't think there's anything to fix here - it's behaving as I'd expect it to behave. There is random state, and doing any training will change that state. Personally I don't see the point of having `restore_state`. If folks really need this functionality, it's easy enough to create a modified LR find class, or to just manually save and restore state.",personally think anything fix expect behave random state training change state personally see point really need functionality easy enough create find class manually save restore state,issue,positive,positive,neutral,neutral,positive,positive
951195240,"I'd be open to the `restore_state` option (or something along those lines), I think that's a good approach. What I'm not sure of is again, whether it should be true or false. Personally I'd leave it as `False`, maintaining original behavior but also putting in an explicit fix for those that want it.

@jph00 what are your thoughts here?",open option something along think good approach sure whether true false personally leave false original behavior also explicit fix want,issue,positive,positive,positive,positive,positive,positive
951194386,Resolved by #3508. Didn't use the correct verbiage for github to automatically close this issue when merging the PR. @jph00 ,resolved use correct verbiage automatically close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
951189628,"I investigated this issue and this does not appear to be related to #2892, as the optimizer is restored correctly after `lr_find`. This is a the same issue as #3013 though.

I have uploaded my investigation as a [gist here](https://gist.github.com/warner-benjamin/58149651371601757eceb93ef28ae519). I have annotated my examples with the notebook headings they were ran under.

# Restating the Issue
Liberally using `with no_random()` to maintain a reproducible state, I'd expect the following code (Trail 1):
```python
with no_random():
    dls = get_dls(192, False, 64)
    learn = Learner(dls, xresnet18(n_out=dls.c), metrics=accuracy)

with no_random():
    learn.lr_find()

with no_random():
    learn.fit_one_cycle(2, 3e-3)
```
![image](https://user-images.githubusercontent.com/51142400/138742725-7908980c-0734-4670-96eb-16b6abb7536b.png)
to have the same result as this code (Trial 2):
```python
with no_random():
    dls = get_dls(192, False, 64)
    learn = Learner(dls, xresnet18(n_out=dls.c), metrics=accuracy)

with no_random():
    learn.fit_one_cycle(2, 3e-3)
```
![image](https://user-images.githubusercontent.com/51142400/138743106-ac64fc5b-b701-4657-9326-70a6282363c0.png)
However, the results differ despite using `with no_random()`.

Recreating the dataloader does result in the same training output (Trial 3):
```python
with no_random():
    dls = get_dls(192, False, 64)
    learn = Learner(dls, xresnet18(n_out=dls.c), metrics=accuracy)

with no_random():
    learn.lr_find()

with no_random():
    dls = get_dls(192, False, 64)
    learn.dls = dls

with no_random():
    learn.fit_one_cycle(2, 3e-3)
```
![image](https://user-images.githubusercontent.com/51142400/138743713-ee64982d-ec0c-4e57-8a21-e7247c360a7f.png)
and so does Trial 4 (not shown here) with less use of `no_random`.
# Solution 1: Save and Restore Dataloader
Modify `LRFinder.before_fit` and `LRFinder.after_fit` to save and restore the dataloader:
```python
    def before_fit(self):
        super().before_fit()
        self.learn.save('_tmp')
        self.old_dls = deepcopy(self.learn.dls)
        self.best_loss = float('inf')

    def after_fit(self):
        self.learn.opt.zero_grad() # Needed before detaching the optimizer for future fits
        tmp_f = self.path/self.model_dir/'_tmp.pth'
        if tmp_f.exists():
            self.learn.load('_tmp', with_opt=True)
            os.remove(tmp_f)
        self.learn.dls = self.old_dls
```
This fixes the issue of Trial 1 resulting with different training then Trial 2. Trial 5 shown below:
```python
with no_random():
    dls = get_dls(192, False, 64)
    learn = Learner(dls, xresnet18(n_out=dls.c), metrics=accuracy)

with no_random():
    learn.lr_find()

with no_random():
    learn.fit_one_cycle(2, 3e-3)
```
![image](https://user-images.githubusercontent.com/51142400/138744755-1f5b21b6-b0ba-49cd-a274-9c82437220a9.png)
However, calling `lr_find` still changes the random state, so the following code results in different training output (Trial 7):
```python
with no_random():
    dls = get_dls(192, False, 64)
    learn = Learner(dls, xresnet18(n_out=dls.c), metrics=accuracy)

with no_random():
    learn.lr_find()
    learn.fit_one_cycle(2, 3e-3)
```
![image](https://user-images.githubusercontent.com/51142400/138745046-b78fed11-e71f-48df-b1b8-8985f1a1f32b.png)
This solution would require the user to call manually reset the random state in between `lr_find` and training.
# Solution 2: Save and Restore Both Dataloader & Random State
Which leads to the second possible solution, modifying `LRFinder.before_fit` and `LRFinder.after_fit` to save and restore the both the dataloader and random state:
```python
    def before_fit(self):
        super().before_fit()
        self.learn.save('_tmp')
        self.old_dls = deepcopy(self.learn.dls)
        self.states = get_random_states()
        self.best_loss = float('inf')

    def after_fit(self):
        self.learn.opt.zero_grad() # Needed before detaching the optimizer for future fits
        tmp_f = self.path/self.model_dir/'_tmp.pth'
        if tmp_f.exists():
            self.learn.load('_tmp', with_opt=True)
            os.remove(tmp_f)
        self.learn.dls = self.old_dls
        set_random_states(**self.states)
```
Then training the model directly after calling `lr_find` results in the same training output as training without `lr_find` (Trial 10):
```python
with no_random():
    dls = get_dls(192, False, 64)
    learn = Learner(dls, xresnet18(n_out=dls.c), metrics=accuracy)

with no_random():
    learn.lr_find()
    learn.fit_one_cycle(2, 3e-3)
```
![image](https://user-images.githubusercontent.com/51142400/138745539-146db526-4c60-4b37-8ca7-bf9b55b3474d.png)
# Potential Issue with Solution
While these changes will resolve the issue of `lr_find` effecting training, they will limit `lr_find` to the same images in the dataloader which will result in less variation in the results returned by `lr_find` when called multiple times without using `no_random`. Especially with restoring the random state, then the primary difference from calling `lr_find` multiple times appears to be from cuda not being set in deterministic mode.

Allowing users to control the restoring of dataloaders and random state by a `restore_state` option in `lr_find` would resolve this potential issue. Thoughts on whether it should default to true or false?
",issue appear related correctly issue though investigation gist notebook ran issue liberally maintain reproducible state expect following code trail python false learn learner image result code trial python false learn learner image however differ despite result training output trial python false learn learner false image trial shown le use solution save restore modify save restore python self super float self future issue trial resulting different training trial trial shown python false learn learner image however calling still random state following code different training output trial python false learn learner image solution would require user call manually reset random state training solution save restore random state second possible solution save restore random state python self super float self future training model directly calling training output training without trial python false learn learner image potential issue solution resolve issue training limit result le variation returned multiple time without especially random state primary difference calling multiple time set deterministic mode control random state option would resolve potential issue whether default true false,issue,positive,negative,negative,negative,negative,negative
950414059,Many thanks for letting us know,many thanks u know,issue,negative,positive,positive,positive,positive,positive
950407573,cc: @jph00 this issue can now be closed. fixed in #3502 .  in v2.53 release.,issue closed fixed release,issue,negative,neutral,neutral,neutral,neutral,neutral
950105570,I've updated the import now so no need for this PR - thanks anyway!,import need thanks anyway,issue,negative,positive,positive,positive,positive,positive
948990606,"You're trying to use fastai version 1, when fastai version 2 is installed. The last version of fastai1 was `fastai==1.0.61`",trying use version version last version,issue,negative,neutral,neutral,neutral,neutral,neutral
948099086,Many thanks for the clear explanation.,many thanks clear explanation,issue,positive,positive,positive,positive,positive,positive
940002635,"Hi, the problem seems to be still there at fastai 2.5.2, nvdev 1.1.22, fastcore 1.3.26 :)
Can anybody reproduce?",hi problem still anybody reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
937318977,"Further help for those who find this page... I just found this page after running, on Colab,

```
!pip install -Uqq fastbook
import fastbook
```
...as in the fastbook notebooks.   


What you need to do is run

```
!pip install -Uqq fastai fastbook
```
THEN restart the runtime.  Then you can run ""import fastbook"" and it will work. 
",help find page found page running pip install import need run pip install restart run import work,issue,negative,neutral,neutral,neutral,neutral,neutral
935596786,"You're welcome!

@jph00 Would you mind adding the `hacktoberfest-accepted` label to this PR (or the `hacktoberfest` topic to the repository) so that the PR counts towards [the event](https://hacktoberfest.digitalocean.com/)?",welcome would mind label topic repository towards event,issue,negative,positive,positive,positive,positive,positive
932719287,"This is the temporary fixed I've applied to the tsai library. 
It basically reverts the patch applied by fastai. 
It seems to fix the issue, but it won't prevent it if anybody imports  fastai.torch_core directly: 

```bash
import pandas as pd
pd_df__init__ = pd.DataFrame.__init__
from fastai.torch_core import *
pd.DataFrame.__init__ = pd_df__init__
```

",temporary fixed applied library basically patch applied fix issue wo prevent anybody directly bash import import,issue,negative,positive,neutral,neutral,positive,positive
928233838,"Many thanks. If either of you come up with a neater solution, please do let me know!",many thanks either come solution please let know,issue,positive,positive,positive,positive,positive,positive
927802890,the problems comes from the internal `reduce` parameter inside `FocalLoss` that is not picked up by the `loss_not_reduced` context manager on `get_preds`,come internal reduce parameter inside picked context manager,issue,negative,neutral,neutral,neutral,neutral,neutral
927801238,"Thanks for the PR! this solves the underlying issue it may be a little overkill.
The error comes from the new param defined inside the `FocalLossFlat` called `reduce` that acts as a switch to toggle reduction upon call.
The `loss_not_reduced` context manager is not able to switch to the `None` reduction as a results of this. There is maybe another solution that is more elegant @jph00 ",thanks underlying issue may little error come new param defined inside reduce switch toggle reduction upon call context manager able switch none reduction maybe another solution elegant,issue,positive,positive,positive,positive,positive,positive
926604148,"Problem seems to be that `learn.get_preds(with_loss=True)` doesn't work with `FocalLossFlat`. I have same problem (fastai 2.3.1, might be fixed in future versions?). 
",problem work problem might fixed future,issue,negative,positive,neutral,neutral,positive,positive
925400890,"I'm glad I searched the Github issues. I see that this PR was merged. Unfortunately, some other people from the forums and myself are still having this issue?  

https://forums.fast.ai/t/untar-data-unhashable-type-dict/90710/17

Can we reopen this? Going to attempt another PR to see if I can resolve this further maybe? Not sure why this is still happening ;-( ",glad see unfortunately people still issue reopen going attempt another see resolve maybe sure still happening,issue,positive,positive,positive,positive,positive,positive
923770075,"```
from fastai import *
from fastai.tabular import *
from fastai.tabular.all import *
import pandas as pd

# set seed for reproducibility
custom_set_seed(42)

df = pd.read_csv('credit_card_default.csv', index_col=0, na_values='')
df.head()

DEP_VAR = 'default_payment_next_month'

num_features = list(df.select_dtypes('number').columns)
num_features.remove(DEP_VAR)
cat_features = list(df.select_dtypes('object').columns)

preprocessing = [FillMissing, Categorify, Normalize]

data = (TabularList.from_df(df, cat_names=cat_features, cont_names=num_features, procs=preprocessing).split_by_rand_pct(valid_pct=0.2, seed=42).label_from_df(cols=DEP_VAR).databunch())
```

I'm running the above code. I encountered a problem when running the last line. It said `NameError: name 'TabularList' is not defined`. I tried `from fastai.tabular.data import TabularList` but encountered another problem `ImportError: cannot import name 'TabularList' from 'fastai.tabular.data' (D:\anaconda3\lib\site-packages\fastai\tabular\data.py)`. Does anyone meet the same problem? Could anyone help me? thank you very much in advance!",import import import import set seed reproducibility list list normalize data running code problem running last line said name defined tried import another problem import name anyone meet problem could anyone help thank much advance,issue,negative,positive,neutral,neutral,positive,positive
922420459,"I think simply looking for the current index of valid_loss column will make it work in both cases. e.g

```
def plot_loss(self, skip_start=5, with_valid=True):
  plt.plot(list(range(skip_start, len(self.losses))), self.losses[skip_start:], label='train')
  if with_valid:
    idx = (np.array(self.iters)<skip_start).sum()
    valid_col = self.metric_names.index('valid_loss') - 1 
    plt.plot(self.iters[idx:], L(self.values[idx:]).itemgot(valid_col), label='valid')
    plt.legend()
 ```  
 
    
",think simply looking current index column make work self list range,issue,negative,neutral,neutral,neutral,neutral,neutral
913091788,"Thank you sir. I did observed it, couldnt understand why that many additions and deletions are present. But some how I want to communicate the typo and experience how a pull request can be raised, so did that. Anyhow, thank you.",thank sir understand many present want communicate typo experience pull request raised anyhow thank,issue,positive,positive,positive,positive,positive,positive
913077320,"Thanks for the PR. Somehow your notebook has thousands of lines of changes. I'll just fix it locally, to save you the trouble of redoing it.",thanks somehow notebook fix locally save trouble,issue,positive,neutral,neutral,neutral,neutral,neutral
906836759,"Ah sorry. Forgot about that 2nd one

On Thu, Aug 26, 2021, 7:40 PM Tanishq Abraham ***@***.***>
wrote:

> @muellerzr <https://github.com/muellerzr> why was this closed when the
> second issue wasn't solved yet?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3455#issuecomment-906836194>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCVY57B7XUGRRG55G3RLT63NIDANCNFSM5CGVQCZQ>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&referrer=utm_campaign%3Dnotification-email%26utm_medium%3Demail%26utm_source%3Dgithub>.
>
>
",ah sorry forgot one wrote closed second issue yet reply directly view triage go mobile android,issue,negative,negative,negative,negative,negative,negative
906836194,@muellerzr why was this closed when the second issue wasn't solved yet?,closed second issue yet,issue,negative,negative,neutral,neutral,negative,negative
903564500,"This arises due to a documented limitation in the Pickle Library itself. 
Here is the list of supported items that can be pickled : [items](https://docs.python.org/3/library/pickle.html#what-can-be-pickled-and-unpickled)
The Splitter functions returns another local function called _inner() , which violates the condition that the function must be on the top level only.

Here is a potential fix [Very hacky, not recommended] : 
https://stackoverflow.com/a/61879723

Edit :
Thought of a better solution:
Instead of creating a closure, we can define a class of Spliiter and create a callable object (using __call__ method) to avoid breaking any code based on current version. The direct advantage is that being an object it will help in pickling objects of all the splitter classes.

```
class RSClass():
    def __init__(self,valid_pct=0.2, seed=None ):
        self.valid_pct = valid_pct
        self.seed = seed
        
    def __call__(self,o):
        if self.seed is not None: torch.manual_seed(self.seed)
        rand_idx = L(list(torch.randperm(len(o)).numpy()))
        cut = int(self.valid_pct * len(o))
        return rand_idx[cut:],rand_idx[:cut]
```
If this looks like a good enough solution I can shoot a PR, with a base class Splitter and all the splitter variations inheriting from it.",due limitation pickle library list splitter another local function condition function must top level potential fix hacky edit thought better solution instead closure define class create callable object method avoid breaking code based current version direct advantage object help splitter class class self seed self none list cut return cut cut like good enough solution shoot base class splitter splitter,issue,positive,positive,neutral,neutral,positive,positive
903199019,"This can be closed now, Jeremy fixed this. The entire documentation was down. 

cc @jph00 ",closed fixed entire documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
903198719,"I'd recommend something like this:

- Inference
  - Tabular

Given your tutorial is tabular specific ",recommend something like inference tabular given tutorial tabular specific,issue,positive,neutral,neutral,neutral,neutral,neutral
903193311,HI is this issue open  and can I start working on it ? ,hi issue open start working,issue,negative,neutral,neutral,neutral,neutral,neutral
903152697,"@jph00 made adjustments. Went with:

> Note: The source script for `X` is in the `examples` subdirectory of this folder if you checked out the `fastai` repo from git, or can be downloaded from [here](https://github.com/fastai/fastai/blob/master/nbs/examples/X.py) if you're using an online viewer such as Colab. ",made went note source script folder checked git viewer,issue,negative,neutral,neutral,neutral,neutral,neutral
903150504,"Yup! Sorry, life got busy unexpectedly. Will push some changes in an hour
or so.

On Sat, Aug 21, 2021, 12:33 PM Jeremy Howard ***@***.***>
wrote:

> Makes sense, will make that adjustment today
>
> Any news?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3456#issuecomment-903149620>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV2JOLHSJJPB5WR6QF3T57PNFANCNFSM5CGX5ZGQ>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>
> .
>
",sorry life got busy unexpectedly push hour sat wrote sense make adjustment today news thread reply directly view triage go mobile android,issue,negative,negative,neutral,neutral,negative,negative
903149620,"> Makes sense, will make that adjustment today

Any news?",sense make adjustment today news,issue,negative,neutral,neutral,neutral,neutral,neutral
901697341,"I had the same issue when running inference in fastpi server. 
In my case the problem was with concurrent executions of the model. 
That exactly matches behavior described by @nkrot  (error on 2nd call, no error with enough sleep time).

The issue can be resolved by simple threading.Lock around model inference. 
Or specially for fastapi: one can define the router function as async to avoid the ThreadPoolExecutor.",issue running inference server case problem concurrent model exactly behavior error call error enough sleep time issue resolved simple around model inference specially one define router function avoid,issue,negative,positive,positive,positive,positive,positive
901647255,"> Looks like you need to run `nbdev_build_lib`

Interesting, this was not required on my previous documentation edit. I just did these edits directly in github, without cloning the repo to my machine.",like need run interesting previous documentation edit directly without machine,issue,positive,positive,positive,positive,positive,positive
901518620,"Many thanks. I think this isn't quite the right fix, so I've just pushed a fix myself.",many thanks think quite right fix fix,issue,negative,positive,positive,positive,positive,positive
900866982,"I realise the thread is quite old but was anyone able to find a workaround? @rwightman, your link doesn't work anymore...",thread quite old anyone able find link work,issue,negative,positive,positive,positive,positive,positive
900832646,"Thanks @muellerzr I appreciate the feedback.

As the pr stands it adds a production tab with inference as a subsection.

![image](https://user-images.githubusercontent.com/4902386/129844779-945c614c-c053-4d6f-b364-ea5c19a3d68f.png)
",thanks appreciate feedback production tab inference subsection image,issue,positive,positive,positive,positive,positive,positive
899529256,"Marking it for review since, as Zachary mentioned, notebooks diffs are ""\r"" only and the notebook runs without errors on my local machine as well. Unsure how to proceed. ",marking review since notebook without local machine well unsure proceed,issue,negative,neutral,neutral,neutral,neutral,neutral
899499156,"@jph00 not 100% sure why the CI is failing here, as running the notebook myself in Colab worked top -> down (even with CUDA). 

It also looks like (annoyingly) much of the diff is /r from windows",sure failing running notebook worked top even also like annoyingly much,issue,negative,positive,positive,positive,positive,positive
899447453,"I love the idea of this! Great initiative! I'm thinking we make a subsection in the docs under tutorials for inference. I'll give your notebook a thorough review with some feedback later today, but it looks really good! Just a few touch ups I think and it'll be set. ",love idea great initiative thinking make subsection inference give notebook thorough review feedback later today really good touch think set,issue,positive,positive,positive,positive,positive,positive
899446802,"Makes sense, will make that adjustment today",sense make adjustment today,issue,negative,neutral,neutral,neutral,neutral,neutral
899239880,"The links are only needed for folks using Colab. So I'd suggest saying something like they're ""in the `examples` subdirectory of this folder, if you checked out the repo from git, or can be downloaded from [here](...) if you're using an online viewer such as Colab.""",link suggest saying something like folder checked git viewer,issue,negative,neutral,neutral,neutral,neutral,neutral
897592097,"I'm facing the same problem, and it seems like this is related to #3141.",facing problem like related,issue,negative,neutral,neutral,neutral,neutral,neutral
897358812,"This helped solve my problem. If anyone is still facing similar issues, modify the loss function accordingly

` inputs = cast(inputs, Tensor), 
  targets = cast(targets, Tensor)
 `

DiceBCELoss Function

```

class DiceBCELoss(nn.Module):
    def __init__(self, weight=None, size_average=True):
        super(DiceBCELoss, self).__init__()

    def forward(self, inputs, targets, smooth=1):
        
        inputs = cast(inputs, Tensor)
        targets = cast(targets, Tensor)
        
        #comment out if your model contains a sigmoid or equivalent activation layer
        inputs = F.sigmoid(inputs)       
        
        #flatten label and prediction tensors
        inputs = inputs.view(-1)
        targets = targets.view(-1)
        
        intersection = (inputs * targets).sum()                            
        dice_loss = 1 - (2.*intersection + smooth)/(inputs.sum() + targets.sum() + smooth)  
        
        BCE = F.binary_cross_entropy(inputs.float(), targets.float(), reduction='mean')
        Dice_BCE = BCE + dice_loss
        
        return Dice_BCE
```",solve problem anyone still facing similar modify loss function accordingly cast tensor cast tensor function class self super self forward self cast tensor cast tensor comment model sigmoid equivalent activation layer flatten label prediction intersection intersection smooth smooth return,issue,negative,positive,positive,positive,positive,positive
896623141,"Found an additional edge case which is definitely wrong:

```python
>>> from fastai.vision.all import *
>>> img = PILImageBW.create(np.random.random((100, 100)))
>>> img.crop_pad((20, 20), (-1, -1))
<PIL.Image.Image image mode=F size=101x101 at 0x7F785AB67130>
```",found additional edge case definitely wrong python import image,issue,negative,negative,negative,negative,negative,negative
895899696,"Beside the above, I still find the try/except of `download_url` odd

```python
try: download_url(url, dest/f""{name}{suffix}"", show_progress=False, timeout=timeout)
except Exception as e: f""Couldn't download {url}.""
```

the `except` leads to creating just a string...which it's not used :D
I assume there is a print missing?
Or re-raise the exception with the new message?

",beside still find odd python try name suffix except exception could except string used assume print missing exception new message,issue,negative,negative,neutral,neutral,negative,negative
895895557,"@kevinbird15 I noticed exactly the same

However, I think it's just code refactoring, and (I think) some glitches in the packaging

Looking at the code, `download_url` is not moved to `fastdownload` which is imported in the module 
https://github.com/fastai/fastai/blob/dfc4da0cac24df3b1fa0583d8bd8f9cba4ba874a/fastai/vision/utils.py

According to the track, @jph00 fixed it yesterday
https://github.com/fastai/fastai/commit/dfc4da0cac24df3b1fa0583d8bd8f9cba4ba874a

But I think the package is not available yet
Installing from the git itself it works for me
```
pip install git+https://github.com/fastai/fastai
```

@kevinbird15 your test seems downloading a file `00000000.jpg` not `00000001.jpg` so please double check your assert",exactly however think code think looking code module according track fixed yesterday think package available yet git work pip install test file please double check assert,issue,negative,positive,positive,positive,positive,positive
893762055,"Thanks! Sorry about that :)

On Thu, Aug 5, 2021, 3:44 PM Jeremy Howard ***@***.***> wrote:

> You forgot untar_data
>
> path = untar_data(URLs.IMDB)
> dls = TextDataLoaders.from_folder(path, valid='test')
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3444#issuecomment-893736449>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV5DCGM7W3KOULOBMDLT3LS2HANCNFSM5BQ77T5Q>
> .
> Triage notifications on the go with GitHub Mobile for iOS
> <https://apps.apple.com/app/apple-store/id1477376905?ct=notification-email&mt=8&pt=524675>
> or Android
> <https://play.google.com/store/apps/details?id=com.github.android&utm_campaign=notification-email>
> .
>
",thanks sorry wrote forgot path path thread reply directly view triage go mobile android,issue,negative,negative,neutral,neutral,negative,negative
891427916,@jph00 I think this issue can be closed thanks to your commit https://github.com/fastai/fastai/commit/f09e11907646d262f5161176045aa575891a244d,think issue closed thanks commit,issue,positive,positive,neutral,neutral,positive,positive
890589793,"@seppedl we use nbdev for development - see here for how to get set up: https://docs.fast.ai/dev-setup.html

I'm not able to replicate your issue. Please let us know the full details of your environment and how to replicate.",use development see get set able replicate issue please let u know full environment replicate,issue,negative,positive,positive,positive,positive,positive
889608576,I've just pushed that change - please test it when you have a moment.,change please test moment,issue,negative,neutral,neutral,neutral,neutral,neutral
889603659,Ouch that sure didn't work! I'll do it over here - thanks :) ,ouch sure work thanks,issue,positive,positive,positive,positive,positive,positive
889571281,"Oh okay, sure, if that's convenient for you then that would be great, otherwise I'm happy to follow your recommended steps. 

PS- I deleted the local fastai folder and rebuild from the updated NBs.",oh sure convenient would great otherwise happy follow local folder rebuild,issue,positive,positive,positive,positive,positive,positive
889569061,"Oh I think I know what's happening. Your notebooks have `nbdev_comment` lines added. Perhaps at some point you did `nbdev_update_lib` on all the nbs, with an old version of nbdev, so now all your NBs have been changed.

Would you prefer I just made the change manually on my end? Otherwise, might be easiest for you to just delete your local fastai folder and then make the change in the NB and build the lib.",oh think know happening added perhaps point old version would prefer made change manually end otherwise might easiest delete local folder make change build,issue,negative,positive,neutral,neutral,positive,positive
889565306,@jph00 Installed the latest NBDev and did a rebuild. Hopefully this is good now.,latest rebuild hopefully good,issue,positive,positive,positive,positive,positive,positive
889257796,"Hi
I tried reproducing your code in [Google Colab Notebook](https://colab.research.google.com/drive/19hLDbw8u_r9TN8z9NVog1KNbpe0UIop2?usp=sharing). It seems to be working fine. 
The CUDA version is different however. 

Is that a source of problem? ",hi tried code notebook working fine version different however source problem,issue,negative,positive,positive,positive,positive,positive
888530750,"Hi @tcapelle, thanks for your suggestions! I incorporated most of them, but I did not add the 'flatten_check_channel' method. 
Instead I added a casting to TensorBase and a shape-assert into the __call__ method. The code is simpler that way in my opionion (no transpose, contiguous, and view). Please have a look at the updated code and let me know what you think!

Regarding defaults: 
* Why would you want to sum over the channels but then take the mean over the batch? We can just sum over everything in this case, can't we?
* This paper here has the squares in the union: https://arxiv.org/abs/1606.04797 (it might even be the paper that introduced dice loss in deep learning). Also empirically with my dataset, my unet does not learn properly without the square. Did you try with and without square for your application? Did it make a difference?",hi thanks incorporated add method instead added casting method code simpler way transpose contiguous view please look code let know think regarding would want sum take mean batch sum everything case ca paper union might even paper dice loss deep learning also learn properly without square try without square application make difference,issue,negative,negative,neutral,neutral,negative,negative
888252335,"I would do some modifications:
- I would make method to check and flatten the vectors, it is important to check that the tensors have the same size and raise an error. Something like this:
```python
    def flatten_check_channel(self, p, t):
        ""keeps channels dim first""
        channels = p.shape[self.axis]
        def _flat(x): return TensorBase(x.transpose(0,self.axis).contiguous()).view(channels,-1)
        p,t = map(_flat, [p,t])
        assert p.shape == t.shape, 'input and target dimensions differ, DiceLoss expects non one-hot targs'
        return p, t
```
- I would make the defaults different, I did some testing today, and ideally you want the loss to have values that are not too small. So I would sum the dice coefficients over the channels and average over the batch.
- smooth should be around 1e-6 as default.
- square union should be off by default ( I would remove this altogether as for me it makes no sense), also square the target is not necessary, only the preds.
- You need to cast the tensors to `TensorBase` to avoid methods incompatibility between tensor subclasses.

Also a little of fastai style coding could be nice:
```python
union = (torch.sum(pred**2+targ, dim=sum_dims) if self.square_in_union
         else torch.sum(pred+targ, dim=sum_dims))
dice_score = (2. * inter + self.smooth)/(union + self.smooth).flatten()
return (1-dice_score).mean() if self.reduction == ""mean"" else (1-dice_score).sum()
```
We will have a pretty neat `DiceLoss` ...",would would make method check flatten important check size raise error something like python self dim first return map assert target differ non return would make different testing today ideally want loss small would sum dice average batch smooth around default square union default would remove altogether sense also square target necessary need cast avoid incompatibility tensor also little style could nice python union else inter union return mean else pretty neat,issue,positive,positive,positive,positive,positive,positive
887772164,@tcapelle : This is my latest version taking into account our discussion here and on discord. Please let me know what you think.,latest version taking account discussion discord please let know think,issue,negative,positive,positive,positive,positive,positive
887411623,"Hi all, 

@jph00: I removed the test case because the value it was asking for was wrong in my opinion (because I think that ""mean"" should be used instead of ""sum""). Also the example did not really have the form of an image, so I thought that it did not make much sense.

@tcapelle : You are right that ""mean"" vs ""sum"" only leads to a scale factor and hence will not affect the learning (I was wrong in this regard). Your suggestion with the 'reduction' argument sounds good. I would prefer to set 'reduction' to 'True' per default since it makes the interpretation of the loss a bit easier. 

I looked into my kaggle dataset again and found that the other change that I had made to the loss function is more important. I am squaring the terms in the denominator as I had learned in [this blog post](https://www.jeremyjordan.me/semantic-segmentation/).  If I do not square, then I get super bad performance on my dataset. Someone else seems to have experienced the same issue on another dataset with class imbalance (see [stackoverflow](https://stackoverflow.com/questions/66536963/dice-loss-working-only-when-probs-are-squared-at-denominator)). In the [monai library](https://docs.monai.io/en/latest/_modules/monai/losses/dice.html#DiceLoss) there is a toggle 'squared_pred' to switch on the squaring. I implemented such a toggle as well. Please let me know what you think of the newest version.

P.S. Just saw your message regarding fastai discord after I updated this PR. I will try to join the fastai discord now.

EDIT: @tcapelle just told me on discord that I had forgotten to apply the activation function in the loss computation. Will look into this and update here later. 
",hi removed test case value wrong opinion think mean used instead sum also example really form image thought make much sense right mean sum scale factor hence affect learning wrong regard suggestion argument good would prefer set per default since interpretation loss bit easier found change made loss function important squaring denominator learned post square get super bad performance someone else experienced issue another class imbalance see library toggle switch squaring toggle well please let know think version saw message regarding discord try join discord edit told discord forgotten apply activation function loss computation look update later,issue,negative,positive,neutral,neutral,positive,positive
887385983,"I am currently working on this, would you like to join the fastai discord and solve this together?",currently working would like join discord solve together,issue,negative,neutral,neutral,neutral,neutral,neutral
887025554,"let me check this tomorrow @jph00 
- we do a flatten check so the vector is 1d, so `sum(-1)` will sum over h and w.
- using mean or sum is equivalent, it is only a constant 1/n different. We could put a reduction arg for scale.
We could do something like:
```python
def __call__(self, pred, targ):
        targ = self._one_hot(targ, pred.shape[self.axis])
        pred, targ = flatten_check(self.activation(pred), targ)
        inter = (pred*targ).sum(axis=-1)
        union = (pred+targ).sum(axis=-1)
        dice = 2. * inter / (union + self.smooth)
        return (1 - dice).mean() if self.reduction=='mean' else (1 - dice).sum()
```",let check tomorrow flatten check vector sum sum mean sum equivalent constant different could put reduction scale could something like python self inter union dice inter union return dice else dice,issue,negative,negative,negative,negative,negative,negative
886975946,"> I am seeing some errors in the github actions regarding nbdev. It is complaining about
> 
> `__init__() missing 2 required positional arguments: 'cfg_path' and 'cfg_name'`
> 
> I had the same issue with my local install until I installed an older version of nbdev (1.1.11) in my conda environment. Maybe there is some issue with the current version of nbdev?

The latest nbdev also requires the latest fastcore. I've updated nbdev now to ensure that the correct fastcore is installed.",seeing regarding missing positional issue local install older version environment maybe issue current version latest also latest ensure correct,issue,negative,positive,positive,positive,positive,positive
886974656,"@thomasfermi this is looking great! Can you please explain why you needed to remove the test that was already there? Was it incorrect?

Apologies for the errors in CI - if you merge the latest changes from master that should fix them.",looking great please explain remove test already incorrect merge latest master fix,issue,positive,positive,positive,positive,positive,positive
886972185,"I am seeing some errors in the github actions regarding nbdev. It is complaining about

`__init__() missing 2 required positional arguments: 'cfg_path' and 'cfg_name'`

 I had the same issue with my local install until I installed an older version of nbdev (1.1.11) in my conda environment. Maybe there is some issue with the current version of nbdev?",seeing regarding missing positional issue local install older version environment maybe issue current version,issue,negative,negative,neutral,neutral,negative,negative
885907560,"
> @jph00 <https://github.com/jph00> did a pip upgrade and shows that I'm on the latest version. Should I build from source?
> 

That shouldn't be needed. I think somehow you have 2 versions installed or something. Or maybe you've got multiple environments.

I just released a new version which you could try, but the difference you're seeing is from code that was removed many months ago.",pip upgrade latest version build source think somehow something maybe got multiple new version could try difference seeing code removed many ago,issue,negative,positive,positive,positive,positive,positive
885251428,@jph00 did a pip upgrade and shows that I'm on the latest version. Should I build from source?,pip upgrade latest version build source,issue,negative,positive,positive,positive,positive,positive
884630658,@digantamisra98 looks like you may need to update your version of nbdev and rebuild,like may need update version rebuild,issue,negative,neutral,neutral,neutral,neutral,neutral
883920884,"Sure, that makes sense. I will submit a PR at the earliest, thanks!",sure sense submit thanks,issue,positive,positive,positive,positive,positive,positive
883908232,I believe that's fixed now. Thanks for the report.,believe fixed thanks report,issue,negative,positive,positive,positive,positive,positive
883907523,generally you can use the latest fastai with the latest released version of pytorch.,generally use latest latest version,issue,negative,positive,positive,positive,positive,positive
883907140,"Thanks @digantamisra98. In order to avoid changing the version dependency, how about having fastai delegate to the PyTorch version if it's 1.9 or greater, and use its internal implementation otherwise? If that sounds OK, I'd be happy to take a PR that does that.",thanks order avoid version dependency delegate version greater use internal implementation otherwise happy take,issue,positive,positive,positive,positive,positive,positive
882948970,"Since my modification of tabular_learner contains an embedding matrix, which is not associated to a class in to (TabularObject) I tried to set embed_szs as a list of tuples:
`emb_szs_list = [(10,6),(17,8),(8,5),(16,8),(7,5),(6,4),(4,4)]`

But when converting the list to a dict
`emb_szs_dict = {to.cat_names[i]:t[1] for i,t in enumerate(emb_szs_list)}`
it works, like intended.

So my fix just fixes a problem I had with a modification of tabular learner...",since modification matrix associated class tried set list converting list enumerate work like intended fix problem modification tabular learner,issue,negative,neutral,neutral,neutral,neutral,neutral
879838129,"how did you sorted this out,? my changes did not break the test, it was the pandas thingy....",sorted break test thingy,issue,negative,neutral,neutral,neutral,neutral,neutral
879569252,"Ah apologies - that `'base'` error isn't actually anything to do with your code, it's caused by the latest pandas. I've fixed that now.",ah error actually anything code latest fixed,issue,negative,positive,positive,positive,positive,positive
879478002,"@tcapelle this change impacts stuff other than just images, and breaks the tests (as you see from CI). Can you suggest an alternative that is more constrained?",change stuff see suggest alternative constrained,issue,negative,neutral,neutral,neutral,neutral,neutral
878834529,"How about changing it to `EndSplitter(..., valid_last=True)`? That way it can split at either end...",way split either end,issue,negative,neutral,neutral,neutral,neutral,neutral
877818446,"Updated the code to float() and reverted to https for movielens. I used two separate commit because these are two different issues.
Tests that failed above passed on my computer ` nbdev_test_nbs --flags '' --pause 1.0 --fname ""nbs/[0-2][0-2]*.ipynb""`
Hope all is good now",code float used two separate commit two different computer pause hope good,issue,positive,positive,positive,positive,positive,positive
876342456,Closing this PR so that I make a new one following the right process.,make new one following right process,issue,negative,positive,positive,positive,positive,positive
875470777,"Pillow v8.3.1 is out, however, we have still a bug as follows.

### Source code

```python
# fastai_sample.py

import urllib

from fastai.vision.all import accuracy
from fastai.vision.all import aug_transforms
from fastai.vision.all import ImageDataLoaders
from fastai.vision.all import Learner
from fastai.vision.all import SimpleCNN
from fastai.vision.all import untar_data
from fastai.vision.all import URLs


opener = urllib.request.build_opener()
opener.addheaders = [(""User-agent"", ""Mozilla/5.0"")]
urllib.request.install_opener(opener)


BATCHSIZE = 128
EPOCHS = 10


path = untar_data(URLs.MNIST_SAMPLE)


data = ImageDataLoaders.from_folder(
    path, bs=BATCHSIZE, batch_tfms=None
)

n_channels = [3, 100, 2]

model = SimpleCNN(n_channels)

learn = Learner(
    data,
    model,
    metrics=[accuracy],
)

learn.fit(EPOCHS)
```


### Error

```
python fastai_sample.py
Could not do one pass in your dataloader, there is something wrong in it
epoch     train_loss  valid_loss  accuracy  time
Traceback (most recent call last):---------------------------------------------------------------| 0.00% [0/96 00:00<00:00]
  File ""fastai_sample.py"", line 38, in <module>
    learn.fit(EPOCHS)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 221, in fit
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 163, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 212, in _do_fit
    self._with_events(self._do_epoch, 'epoch', CancelEpochException)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 163, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 206, in _do_epoch
    self._do_epoch_train()
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 198, in _do_epoch_train
    self._with_events(self.all_batches, 'train', CancelTrainException)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 163, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/Users/nzw/Documents/optuna/fastai/fastai/learner.py"", line 169, in all_batches
    for o in enumerate(self.dl): self.one_batch(*o)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/data/load.py"", line 109, in __iter__
    for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/torch/utils/data/dataloader.py"", line 521, in __next__
    data = self._next_data()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/torch/utils/data/dataloader.py"", line 1203, in _next_data
    return self._process_data(data)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/torch/utils/data/dataloader.py"", line 1229, in _process_data
    data.reraise()
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/torch/_utils.py"", line 425, in reraise
    raise self.exc_type(msg)
RuntimeError: Caught RuntimeError in DataLoader worker process 0.
Original Traceback (most recent call last):
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py"", line 287, in _worker_loop
    data = fetcher.fetch(index)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py"", line 34, in fetch
    data = next(self.dataset_iter)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/data/load.py"", line 118, in create_batches
    yield from map(self.do_batch, self.chunkify(res))
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/basics.py"", line 216, in chunked
    res = list(itertools.islice(it, chunk_sz))
  File ""/Users/nzw/Documents/optuna/fastai/fastai/data/load.py"", line 133, in do_item
    try: return self.after_item(self.create_item(s))
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/transform.py"", line 200, in __call__
    def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/transform.py"", line 150, in compose_tfms
    x = f(x, **kwargs)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/transform.py"", line 73, in __call__
    def __call__(self, x, **kwargs): return self._call('encodes', x, **kwargs)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/transform.py"", line 83, in _call
    return self._do_call(getattr(self, fn), x, **kwargs)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/transform.py"", line 90, in _do_call
    res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/transform.py"", line 90, in <genexpr>
    res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/transform.py"", line 89, in _do_call
    return retain_type(f(x, **kwargs), x, ret)
  File ""/opt/homebrew/Caskroom/miniconda/base/envs/optuna/lib/python3.8/site-packages/fastcore/dispatch.py"", line 118, in __call__
    return f(*args, **kwargs)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/vision/core.py"", line 223, in encodes
    def encodes(self, o:PILBase): return o._tensor_cls(image2tensor(o))
  File ""/Users/nzw/Documents/optuna/fastai/fastai/vision/core.py"", line 93, in image2tensor
    res = tensor(img)
  File ""/Users/nzw/Documents/optuna/fastai/fastai/torch_core.py"", line 134, in tensor
    else as_tensor(x, **kwargs) if hasattr(x, '__array__') or is_iter(x)
RuntimeError: Could not infer dtype of PILImage
```

### Installation 

```bash
pip install -U pillow # Pillow 8.3.1 is installed
git clone https://github.com/fastai/fastai
pip install -e ""fastai[dev]""
```

## important dependencies: 

```
# on the latest M1 mac book air
pip list | grep -i torch
pytorch-ignite                0.4.5
pytorch-lightning             1.3.8
torch                         1.9.0
torchaudio                    0.9.0
torchmetrics                  0.4.1
torchvision                   0.10.0
```

Sorry for not giving a more detailed investigation, but let me report the bug.",pillow however still bug source code python import import accuracy import import import learner import import import opener opener path data path model learn learner data model accuracy error python could one pas something wrong epoch accuracy time recent call last file line module file line fit file line try self file line file line try self file line file line file line try self file line enumerate file line file line data file line return data file line file line reraise raise caught worker process original recent call last file line data index file line fetch data next file line yield map file line list file line try return file line self return file line file line self return file line return self file line file line file line return ret file line return file line self return file line tensor file line tensor else could infer installation bash pip install pillow pillow git clone pip install dev important latest mac book air pip list torch torch sorry giving detailed investigation let report bug,issue,negative,positive,neutral,neutral,positive,positive
874395917,"this issue can be reproduced by the following code snippets:

```
from fastai.data.transforms import RandomSplitter
import pickle
pickle.dumps(RandomSplitter())

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-4-4260ef7da67d> in <module>
----> 1 pickle.dumps(RandomSplitter())

AttributeError: Can't pickle local object 'RandomSplitter.<locals>._inner'
```",issue following code import import pickle recent call last module ca pickle local object,issue,negative,neutral,neutral,neutral,neutral,neutral
874379125,@vtecftwy thanks for your PR. Please follow this guide to ensure your PR is nice and clean and passes all CI checks: https://docs.fast.ai/dev-setup.html ,thanks please follow guide ensure nice clean,issue,positive,positive,positive,positive,positive,positive
873689355,"Should I update the related notebook as well?
/nbs/14_callback.schedule.ipynb",update related notebook well,issue,negative,neutral,neutral,neutral,neutral,neutral
872747709,"sorry did not get that, I get it now, this extra argument is not present on pytorch Dataloader class.",sorry get get extra argument present class,issue,negative,negative,negative,negative,negative,negative
872538097,"Yes, that's exactly what I reported under ""Additional context"" already. But I don't see the point in having a compulsory argument that breaks the compatibility with pytorch and does in essence nothing useful.",yes exactly additional context already see point compulsory argument compatibility essence nothing useful,issue,negative,positive,positive,positive,positive,positive
872171965,@tcapelle I didn't know I had to change the corresponding .py file (though these would be auto generated somehow) but happy to push those changes if that's what you need. ,know change corresponding file though would auto somehow happy push need,issue,positive,positive,positive,positive,positive,positive
872129594,"Yes, that's the workaround I found too. It seems that it is only used for progressbar and stuff like that.
But:
1) That breaks compatibility with PyTorch Dataset/Dataloader
2) The documentation says (https://docs.fast.ai/data.load.html#DataLoader): 
`n (int): Defaults to len(dataset). If you are using iterable-style dataset, you can specify the size with n.`

which for me sounds like an optional parameter - but it's not
",yes found used stuff like compatibility documentation specify size like optional parameter,issue,positive,neutral,neutral,neutral,neutral,neutral
872123234,"Using delegates here is tricky. We want to delegate to `dl_type` which is passed as argument itself. Delegating to `TfmdDL` may be confusing if one uses other dataloader type.
The version proposed here allows to pass transforms as:
```
dls = DataLoaders.from_dsets(train_ds, valid_ds, 
                             after_item=[TrainOnlyTfm, ToTensor],
                             val_after_item=[ToTensor], 
                             after_batch=[IntToFloatTensor, Normalize.from_stats(*imagenet_stats)])
```
Keyword args starting with `val_` will be used for valid dataloader and if no `val_` argument provided, regular argument will be used for both train and valid dl. Knowing this one can finely control the behavior of `from_dsets`. This pattern is used in other places too, so it shouldn't be completely unfamiliar. But I agree this might be not ideal and possibly better solutions can be found.
Would you share examples where this is not expressive enough? We can try to improve solution based on that.

Also I remember Jeremy mentioned it's possible that v3 can possibly switch to using native pytorch `DataLoader`. If that's correct it will impact methods like `.from_dsets`. ",tricky want delegate argument may one type version pas starting used valid argument provided regular argument used train valid knowing one finely control behavior pattern used completely unfamiliar agree might ideal possibly better found would share expressive enough try improve solution based also remember possible possibly switch native correct impact like,issue,positive,positive,positive,positive,positive,positive
872092921,"We could put a big integer for non indexed datasets. `n` is mostly used to know where on the training loop we are, to do scheduling, etc...",could put big integer non indexed mostly used know training loop,issue,negative,positive,positive,positive,positive,positive
872055151,"The `from_dsets` method need reworking, maybe adding delegates also to replace the `**kwargs.`  Probably the `_batch_tfms = ('after_item','before_batch','after_batch' )` should also be explicit for train and valid. If we do so, this method would end up with like 15 arguments. Don't know what the right solution is, but the actual one is confusing and not expressive enough.",method need maybe also replace probably also explicit train valid method would end like know right solution actual one expressive enough,issue,positive,positive,positive,positive,positive,positive
870394650,"Most of fastai documentation is by examples, tutorials and courses. It is indeed not easy for someone that just want to try one functionality out of the box without reading the notebooks. The `DataBlock` is indeed pretty powerful.  I would recommend reading this tutorial: https://docs.fast.ai/tutorial.datablock.html
- `get_items` is how to grab an iterable of items from source. For vision, `get_image_files` is mostly used to do this. From a `Path` you get a list of image paths to iterate on.
- `get_x`: is how to get the `x` values from an iterable (pandas, list, dataset, etc..)
- `get_y`: is how to get the `y` labels from an iterable (pandas, list, dataset, etc..)

You will see that regularly `get_items` and `get_y` are passed, because `get_items` will already get you an interable that is ready to be passed through the block.

```
source -> iterable -> get_x, get_y -> blocks -> split -> tfms
```",documentation indeed easy someone want try one functionality box without reading indeed pretty powerful would recommend reading tutorial grab iterable source vision mostly used path get list image iterate get iterable list get iterable list see regularly already get ready block source iterable split,issue,positive,positive,positive,positive,positive,positive
869714178,I solve this issue by modifying source code;,solve issue source code,issue,negative,neutral,neutral,neutral,neutral,neutral
869617846,"Maybe `from_dsets` should not exist, and the user should be pushed towards creating explicitly their dataloaders with transforms using the `TfmDL` constructor. If you have plain datasets without transforms on the input, the needed `kwargs` on `from_dsets` can quickly become messy if you want to customize the full pipeline. With the actual change, we are forcing the same transforms pipelines (`after_item`, `after_batch`) on both train/valid datasets. Also, we are not letting the user disable shuffle or drop last.
I find myself always constructing the `TfmDL` independetly. My proposed change only fixes the issue with transforms, that was actually a bug.",maybe exist user towards explicitly constructor plain without input quickly become messy want full pipeline actual change forcing also user disable shuffle drop last find always change issue actually bug,issue,negative,positive,neutral,neutral,positive,positive
869608089,"@tcapelle, from previous message:
> The proposed version makes Dataloaders.from_dsets more consistent with Datasets.dataloaders. These two have similar purpose and structure. In my opinion this should make those easier to maintain.

I think this can help to avoid the kind of issues when we have an unexpected behavior in one method, while other method with similar functionality works fine. But that's just my opinion and it might be wrong. I can close the PR if proposed changes are not considered useful.",previous message version consistent two similar purpose structure opinion make easier maintain think help avoid kind unexpected behavior one method method similar functionality work fine opinion might wrong close considered useful,issue,positive,positive,positive,positive,positive,positive
869467787,"can you check on master if it is fixed now?
@jph00  you can close this.",check master fixed close,issue,negative,positive,neutral,neutral,positive,positive
869214992,"why not just do something like this:
```python
@classmethod
def from_dsets(cls, *ds, path='.',  bs=64, device=None, dl_type=TfmdDL, **kwargs):
    default = (True,) + (False,) * (len(ds)-1)
    defaults = {'shuffle': default, 'drop_last': default}
    tfms = {k:tuple(Pipeline(kwargs[k]) for i in range_of(ds)) for k in _batch_tfms if k in kwargs}
    kwargs = merge(defaults, {k: tuplify(v, match=ds) for k,v in kwargs.items() if k not in _batch_tfms}, tfms)
    kwargs = [{k: v[i] for k,v in kwargs.items()} for i in range_of(ds)]
    return cls(*[dl_type(d, bs=bs, **k) for d,k in zip(ds, kwargs)], path=path, device=device)
```",something like python default true false default default pipeline merge return zip,issue,positive,negative,neutral,neutral,negative,negative
867558655,"I think the issue could be renamed to ""old fastai functions being shown on autocomplete"", since the issue has changed scope a bit",think issue could old shown since issue scope bit,issue,negative,positive,neutral,neutral,positive,positive
867551197,"Ah! It is still there, I misunderstood the issue :) ",ah still misunderstood issue,issue,negative,neutral,neutral,neutral,neutral,neutral
867511638,"While the links aren’t there, autocomplete still is. Try looking at
get_transforms in the search bar, it’ll still show.

On Thu, Jun 24, 2021 at 6:03 AM Marii ***@***.***> wrote:

> I am unable to reproduce this, as it seems to be fixed now.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2960#issuecomment-867509939>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCVYJESSBLKWRWCTCJMLTUL7HRANCNFSM4TOO43YA>
> .
>
",link still try looking search bar still show wrote unable reproduce fixed reply directly view,issue,negative,negative,negative,negative,negative,negative
867505832,"Yup! This can be closed :)

On Thu, Jun 24, 2021 at 5:55 AM Marii ***@***.***> wrote:

> Think this one was completed in #2857
> <https://github.com/fastai/fastai/pull/2857>
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2826#issuecomment-867504219>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV32NY4TXXVVFSIE4TDTUL6ITANCNFSM4RVY52EQ>
> .
>
",closed wrote think one reply directly view,issue,negative,neutral,neutral,neutral,neutral,neutral
867021367,"I had this same error message, and was able to resolve it and get my `Learner` to fit properly by typecasting my dataset's original labels (which were integers) into `torch.float`s. Perhaps that might help?",error message able resolve get learner fit properly original perhaps might help,issue,positive,positive,positive,positive,positive,positive
866708433,"It is ready to review @jph00 (I initially solved the CI that was not passing by cleaning tutorial.text, but maybe was not a good idea).",ready review initially passing cleaning maybe good idea,issue,positive,positive,positive,positive,positive,positive
865409721,Well done you fixed it! Don't worry no one is keeping time ;) ,well done fixed worry one keeping time,issue,negative,positive,neutral,neutral,positive,positive
864942670,"I guess the model is loaded only once. It happens early, far before the requests are sent to the server. Can it be the case that the model is reloaded by some internal magic of fastai?

a) In the scenario when I am sending 2 images each with its own curl request one after the other:
1) prediction works for the 1st image, i see the response arriving
2) the error appears for the 2nd image

b) If i put some delay between curls (`sleep 0.2s`), the error does not happen.
",guess model loaded early far sent server case model internal magic scenario sending curl request one prediction work st image see response error image put delay sleep error happen,issue,negative,positive,positive,positive,positive,positive
864771747,"The following seems to have fixed it...

``
git pull

git checkout origin/master dev_nbs/course/lesson2-download.ipynb

git commit -m ""Removed lesson2-download.ipynb from pull request""

git push origin trim_url_querystring
``

Hopefully not a record for the slowest and smallest PR to the fast.ai library??!??!",following fixed git pull git git commit removed pull request git push origin hopefully record library,issue,positive,positive,neutral,neutral,positive,positive
864622546,Nope not good yet! You've committed a deletion of the whole notebook 😱 ,nope good yet deletion whole notebook,issue,negative,positive,positive,positive,positive,positive
863944211,"I would think this way: `get_preds` does validate on the `validation_dataloader` running `one_epoch`, so kind of makes sense to call `after_epoch`.",would think way validate running kind sense call,issue,positive,positive,positive,positive,positive,positive
862709038,"Nice! Sorry, i did not have time to test it. Thanks",nice sorry time test thanks,issue,positive,positive,neutral,neutral,positive,positive
862671213,"would you mind printing the `learn.path` and `learn.model_dir` please?
",would mind printing please,issue,negative,neutral,neutral,neutral,neutral,neutral
862664990,Can we close this? can you try if the recent fix helps?,close try recent fix,issue,negative,neutral,neutral,neutral,neutral,neutral
862664399,you should probably make sure to load the model once in your app. I also use flask and have never encountered such an issue.,probably make sure load model also use flask never issue,issue,negative,positive,positive,positive,positive,positive
862663070,"Would you mind checking if this fixes your issue:
```python
@typedispatch
def plot_top_losses(x:TensorImage, y:TensorMask, samples, outs, raws, losses, nrows=None, ncols=None, figsize=None, **kwargs):
    axes = get_grid(len(samples)*3, nrows=len(samples), ncols=3, add_vert=1, figsize=figsize, flatten=False, title=""Input | Target | Prediction"")
    if axes.ndim == 1: axes = (axes,)
    titles = [""input"", ""target"", ""pred""]
    for axs,s,o,l in zip(axes, samples, outs, losses):
        imgs = (s[0], s[1], o[0])
        for ax,im,title in zip(axs, imgs, titles):
            if title==""pred"": title += f""; loss = {l:.4f}""
            im.show(ctx=ax, **kwargs)
            ax.set_title(title)
```

it appears that the `kwargs` where missing. Anyway, the default value of `vmin` is zero, so I don't get why you need to put it to zero manually. I am pretty sure you are not in master. Would you mind doing:
```python
from fastai.test_utils import show_install
show_install()
```",would mind issue python ax input target prediction ax ax input target zip ax ax title zip title loss title missing anyway default value zero get need put zero manually pretty sure master would mind python import,issue,positive,positive,positive,positive,positive,positive
862629726,@Bunoviske looks like this was resolved in the latest version (2.4) :) cc @jph00 ,like resolved latest version,issue,negative,positive,positive,positive,positive,positive
862467412,"*Update:*

- Using a maximum value of 2 in the mask forces me to provide a list of `codes` with 3 entries, even if every mask only contains two values. Not doing so triggers `RuntimeError`s on training. The reason given for the error is mostly different, but providing three values in `codes` consistently fixes the issue.
- I tried using 1 and 2 as values in the mask instead of 0 and 1. This does not change the `RuntimeError`s being triggered when training as described above.",update maximum value mask provide list even every mask two training reason given error mostly different providing three consistently issue tried mask instead change triggered training,issue,negative,positive,positive,positive,positive,positive
862225860,"Using `deepcopy` was the first solution that came to both @riven314 and me and it fixes the issue :)

The solution proposed in this PR has advantage of handling kwargs specific to `valid` dataloader. Example use case when this can be useful - providing `val_res` for speeding up `SortedDL` creation. It is possible to modify current version of `.from_dsets` to take `val_*` keyword arguments as well. But that will also introduce substantial changes to review.
The proposed version makes `Dataloaders.from_dsets` more consistent with `Datasets.dataloaders`. These two have similar purpose and structure. In my opinion this should make those easier to maintain.

There is also an option to construct `Datasets` object from datasets passed to `Dataloaders.from_dsets` and use its `.dataloaders` method. But it might be unnecessary complication for the task. I can give it a try if you think it is a worthy idea.",first solution came riven issue solution advantage handling specific valid example use case useful providing speeding creation possible modify current version take well also introduce substantial review version consistent two similar purpose structure opinion make easier maintain also option construct object use method might unnecessary complication task give try think worthy idea,issue,positive,positive,neutral,neutral,positive,positive
861936030,"@mansimane fastai usually adds support for the latest version of pytorch soon after it's released. pytorch 1.9 release was just added

fastai v1 is no longer supported (except for bug fixes) and will likely not be compatible with the latest versions of pytorch",usually support latest version soon release added longer except bug likely compatible latest,issue,negative,positive,positive,positive,positive,positive
861920085,"Thanks this makes sense. Possibly it would be even better to have a param where the user passes the type they want to cast to, and have that default to `TensorBase`?",thanks sense possibly would even better param user type want cast default,issue,positive,positive,positive,positive,positive,positive
861916358,Why not just use `deepcopy`? A smaller change like that would be easier for me to review. Are there significant downsides?,use smaller change like would easier review significant,issue,positive,positive,positive,positive,positive,positive
861909700,@arampacha @borisdayma I'll leave this open until you two have resolved the above conversation,leave open two resolved conversation,issue,negative,neutral,neutral,neutral,neutral,neutral
861580499,"> Another (possibly better?) option to solve this is to register this function:
> 
> ```
> TensorMultiCategory.register_func(Tensor.__getitem__, TensorMultiCategory, TensorBBox)
> ```
> 
> (Thanks @riven314 for finding this solution)

I was facing a similar issue, but this did fix it. Thank you",another possibly better option solve register function thanks riven finding solution facing similar issue fix thank,issue,positive,positive,positive,positive,positive,positive
861033701,Thanks @andrewtruong . Can you please follow the steps here to clean your notebook and build the lib? https://docs.fast.ai/dev-setup.html ,thanks please follow clean notebook build,issue,positive,positive,positive,positive,positive,positive
861032786,"@Mjboothaus yes, you need to remove the changed notebook from the PR that has the metadata changes. Thanks!",yes need remove notebook thanks,issue,positive,positive,positive,positive,positive,positive
860632412,"No I didn't do that :) I did edit that notebook to try some test from memory but I didn't think it would get included - only the two files that I explicitly gIt add-ed. Maybe branches work differently and I need to do some more reading about Git?

Do I need to do anything else with this PR?￼￼

￼￼",edit notebook try test memory think would get included two explicitly git maybe work differently need reading git need anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
858933969,"> Sadly I have not, I could not make fastai to work fast (sorry for the joke) on windows. In the end I installed Ubuntu and whenever I need to run something locally I just change OS... It is a pain, but better than use 5% of my GPU when training with a single worker. :)

I am going that route as well. Thanks for the links.",sadly could make work fast sorry joke end whenever need run something locally change o pain better use training single worker going route well thanks link,issue,negative,negative,neutral,neutral,negative,negative
858526355,We managed to understand and re-purpose the fragment of code I was talking about when opening the ticked. The problem is solved for us know. However I would like to wish making this approach more user friendly. I expect to be able to pass an array of images and get back an array of predictions. ,understand fragment code talking opening ticked problem u know however would like wish making approach user friendly expect able pas array get back array,issue,negative,positive,positive,positive,positive,positive
856844555,"Sadly I have not, I could not make fastai to work fast (sorry for the joke) on windows. In the end I installed Ubuntu and whenever I need to run something locally I just change OS... It is a pain, but better than use 5% of my GPU when training with a single worker. :)",sadly could make work fast sorry joke end whenever need run something locally change o pain better use training single worker,issue,negative,negative,neutral,neutral,negative,negative
856814038,"Thanks for sharing. This is really helpful for me.

@muellerzr Would you have any advice for fastai on windows speedup? The sample code does not work for me.",thanks really helpful would advice sample code work,issue,positive,positive,positive,positive,positive,positive
855891143,"Also: Try installing the dev version of fastai and fastcore and try again too just to verify it's still an issue:
```python
pip install git+https://github.com/fastai/fastai
pip install git+https://github.com/fastai/fastcore
```",also try dev version try verify still issue python pip install pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
855889959,@Mjboothaus did you do `nbdev_clean_nbs` as well? (Just trying to think how that may have happened :) ),well trying think may,issue,negative,neutral,neutral,neutral,neutral,neutral
854888245,"Another (possibly better?) option to solve this is to register this function:

```
TensorMultiCategory.register_func(Tensor.__getitem__, TensorMultiCategory, TensorBBox)
```

(Thanks @riven314 for finding this solution)",another possibly better option solve register function thanks riven finding solution,issue,positive,positive,positive,positive,positive,positive
854773991,"Ran into the same issue in the [bounding box tutorial](https://docs.fast.ai/tutorial.datablock.html#Bounding-boxes). 
fastai==2.3.1
torch==1.8.1
",ran issue bounding box tutorial,issue,negative,neutral,neutral,neutral,neutral,neutral
853934935,"Of course. This is the code I used to train https://colab.research.google.com/drive/1gJ0sT5wCBbJRLRU9htfyKSIW73y4jtEn?usp=sharing
For some reason it won't work using jupyter so I had to save it as .py and run with 'python code.py'",course code used train reason wo work save run,issue,negative,neutral,neutral,neutral,neutral,neutral
853649944,"A tutorial / sample would be good. @coldfir3, can you elaborate on what you did with pytorch lightning? ",tutorial sample would good elaborate lightning,issue,negative,positive,positive,positive,positive,positive
853564210,"@Bunoviske 
Would you mind creating a minimal reproducible example in, lets say, a Colab notebook? 
I know there are some changes brought in fastai 2.3+ wrt adding normalization in validation set, which may be a cause for that. would be great if u have a notebook for me to verify that",would mind minimal reproducible example say notebook know brought normalization validation set may cause would great notebook verify,issue,positive,positive,positive,positive,positive,positive
853432603,"First image: no denorm
Second image: one denorm
Third image: two denorms

![noDenorm](https://user-images.githubusercontent.com/16785926/120561808-8890be80-c405-11eb-8375-5e40b7c3c960.png)
![oneDenorm](https://user-images.githubusercontent.com/16785926/120561811-89295500-c405-11eb-87e8-e696a26c8249.png)
![twoDenorms](https://user-images.githubusercontent.com/16785926/120561803-87f82800-c405-11eb-88cc-e4e7674eeb38.png)
",first image second image one third image two,issue,negative,positive,neutral,neutral,positive,positive
853286420,"Sounds good. And again, @riven314 @arampacha I appreciate the help!",good riven appreciate help,issue,positive,positive,positive,positive,positive,positive
853231974,"@backdoorbreaker 
I have opened a new issue to track and elaborate the bug
meanwhile @arampacha and I are working on a fix for this.
Instead of doing `deepcopy`, we plan to restructure `DataLoaders.from_dsets`",new issue track elaborate bug meanwhile working fix instead plan,issue,negative,positive,positive,positive,positive,positive
853227454,"I came here to ask the exact same thing. 

I can run FastAI locally just fine with num_workers = 0 on Windows, but that is painfully slow. The GPU load keeps fluctuating and the training times are 3~4x longer than what they should.

Is there any tutorial/guide/best practices to run FAST AI on windows? I am not saying about installation, cuda or anything like that. My only issue is with the dataloader.

On a side note, I managed to run almost the same pipeline using Pytorch Lightning by wrapping my call inside

```
if __name__ == '__main__':
    main_train_loop()
```
but this didn’t work with fastai for me. I keep getting pickling errors relating to my augmentation functions (not using any lambda func)

Thanks in advance, any tip would be helpful.",came ask exact thing run locally fine painfully slow load training time longer run fast ai saying installation anything like issue side note run almost pipeline lightning wrapping call inside work keep getting augmentation lambda thanks advance tip would helpful,issue,positive,positive,positive,positive,positive,positive
853011724,"Thank you for digging into this, Alex. Your findings were very insightful for me.

As an existing contributor, what is your opinion on me opening a PR to add this `deepcopy` to `from_dsets` and `TfmdDL`? ",thank digging insightful contributor opinion opening add,issue,negative,neutral,neutral,neutral,neutral,neutral
852839203,"@AndreyYashkin @hamelsmu 
I think its because of how `__exit__` is defined in `Learner`, i.e.:
```
# _after_epoch  = [event.after_epoch, event.after_fit]
def __exit__(self, exc_type, exc_value, tb): self(_after_epoch)
```

In addition to that, context manager is called in `self.get_preds`, so thats why 'Ping' appear twice.  

To verify this, I removed `event.after_fit` from `__exit__` and then `Ping` only appears once, as shown: 
![Screenshot from 2021-06-02 16-14-36](https://user-images.githubusercontent.com/21143399/120447954-a803f900-c3bd-11eb-9aa9-b4e834f5c850.png)
 
I think it involves a design decision here, not sure what I did here is desirable. Would like to hear more thoughts on that.",think defined learner self self addition context manager thats appear twice verify removed ping shown think design decision sure desirable would like hear,issue,positive,positive,positive,positive,positive,positive
852821826,"**Small Update**
The bug can be more simply reproduced by the following codes (`kw` should be identical for each print but strangely its not):  
```
kw = {'after_item': [ToTensor], 'before_batch': [ToTensor], 'shuffle': False}
for _nm in ('after_item', 'before_batch'):
  kw[_nm] = Pipeline(kw[_nm])
print(kw)
# >> {'after_item': Pipeline: ToTensor, 'before_batch': Pipeline: ToTensor, 'shuffle': False}
train_dl = TfmdDL(train_ds, bs=12, **kw)
print(kw)
# >> {'after_item': Pipeline: , 'before_batch': Pipeline: , 'shuffle': False}
valid_dl = TfmdDL(valid_ds, bs=12, **kw)
print(kw)
# >> {'after_item': Pipeline: , 'before_batch': Pipeline: , 'shuffle': False}
```

Something wrong when initializing train and valid `TfmdDL` with the same dict object as keyword arguments, particularly on values that are `Pipeline` (e.g. `after_item`)  

Simplest fix is to do `deepcopy` like this:
```
valid_dl = TfmdDL(valid_ds, bs=12, **deepcopy(kw))
```",small update bug simply following identical print strangely false pipeline print pipeline pipeline false print pipeline pipeline false print pipeline pipeline false something wrong train valid object particularly pipeline fix like,issue,negative,negative,negative,negative,negative,negative
852421466,"Hey sorry for the long radio silence, I got tangled up in some other work. I think we can package this MR together @tcapelle to add some more loss functions. But first we will have to figure out how to get rid off the notebook duplication and get it updated with master again.",hey sorry long radio silence got work think package together add loss first figure get rid notebook duplication get master,issue,negative,negative,negative,negative,negative,negative
851902119,"So maybe a nice solution would be to have __init__ with a 
```python 
FixedGANSwitcher(n_crit=1, n_gen=1) 
``` 
and have the case with n_crit=5 in 
```python 
def wgan():
```

Change:
https://github.com/fastai/fastai/blob/301016c5d3de2bdb5269121bd0716538d85f7409/fastai/vision/gan.py#L317-L320

To:
```python
def wgan(cls, dls, generator, critic, switcher=None, clip=0.01, switch_eval=False, **kwargs):
    ""Create a WGAN from `data`, `generator` and `critic`.""
    if switcher is None: switcher = FixedGANSwitcher(n_crit=5, n_gen=1)
    return cls(dls, generator, critic, _tk_mean, _tk_diff, switcher=switcher, clip=clip, switch_eval=switch_eval, **kwargs)
```",maybe nice solution would python case python change python generator critic create data generator critic switcher none switcher return generator critic,issue,negative,positive,positive,positive,positive,positive
851788021,"fastai v1 isn't supported anymore... please use the latest version of fastai if possible...
",please use latest version possible,issue,negative,positive,positive,positive,positive,positive
851678381,Yeah ok. This seems to be the case here but in the tutorial/[notebook](https://github.com/fastai/fastai/blob/master/dev_nbs/course/lesson7-wgan.ipynb) it states to use GANLearner.wgan(...) for WGAN. Wouldn't it be a better solution to have the class function wgan() of the GANLearner to handle the number of iterations in this special case?,yeah case notebook use would better solution class function handle number special case,issue,positive,positive,positive,positive,positive,positive
851670334,"The GAN module is not very well-documented but my understanding is that it is implementing a WGAN which is an improved version of a regular GAN. For WGANs, the critic is trained for 5 steps and then the generator is trained for 1 step.",gan module understanding version regular gan critic trained generator trained step,issue,negative,neutral,neutral,neutral,neutral,neutral
851644841,"Would be cool to do something like this: https://www.angioi.com/time-series-encoder-decoder-tensorflow/ using the new `GaussianLoss` in pytorch 1.8, basically, instead of doing a regression, you predict mean and std and fit a normal distribution that minimizes NLL. I can help you with this if you want.",would cool something like new basically instead regression predict mean fit normal distribution help want,issue,positive,positive,positive,positive,positive,positive
851392664,"I saw this some time ago, the indexing is not automatically inherited between tensor sublclasses. The quick fix is to cast the indexer to Tensor, but it is not very clean. Kinda of the same problem I tried to solve here: https://github.com/fastai/fastai/pull/3363",saw time ago indexing automatically tensor quick fix cast indexer tensor clean problem tried solve,issue,negative,positive,positive,positive,positive,positive
851008359,"The issue is gone when I tried to `deepcopy` the `kwargs` from train and valid set.  (as attached in the screenshot)
So I think probably its caused by a possibility that `kwargs['after_item']` for both train and valid are pointing to the same object. And during train's `DataLoader` is setup,  my suspect is that `kwargs['after_item']` is popped out which caused later on valid's `DataLoader` failed to access it. 
![Screenshot from 2021-05-30 22-20-18](https://user-images.githubusercontent.com/21143399/120107889-5547f880-c195-11eb-8aef-624a2af76ebb.png)

Thats what I found in prelim stage, needa further investigate.  
The above screenshot comes from this colab notebook which I copied from yours. 
https://colab.research.google.com/drive/1UhcEL5ykvNj4NJ4LU0BqH0qNGLRoQl0c?usp=sharing",issue gone tried train valid set attached think probably possibility train valid pointing object train setup suspect later valid access thats found prelim stage investigate come notebook copied,issue,negative,neutral,neutral,neutral,neutral,neutral
850896114,"They seem to be pretty similar, but not quite identical",seem pretty similar quite identical,issue,negative,positive,positive,positive,positive,positive
850895294,"Still trying to think through this, but I think we are running into this so maybe we need to somehow implement how some of this should work?  I'm not sure 

https://pytorch.org/docs/stable/notes/extending.html#extending-torch

Here are the old docs (https://pytorch.org/docs/1.7.1/notes/extending.html?highlight=extending#extending-torch)",still trying think think running maybe need somehow implement work sure old,issue,negative,positive,positive,positive,positive,positive
846582186,"This is the piece that it actually fails on: 
```
label[~empty]
```

Here's a slightly more minimal code to reproduce: 
```
label = TensorMultiCategory([[1,0,0]])
empty = TensorBBox([True])
label[~empty]
```",piece actually label slightly minimal code reproduce label empty true label,issue,negative,positive,neutral,neutral,positive,positive
846581634,"I believe the breaking example should actually be: 
```
from fastai.vision.all import *
bbox = TensorBBox.create([[10,10,20,20]])
label = TensorMultiCategory([[1,0,0]])
clip_remove_empty(bbox, label)
```

which works with fastai 2.1.8 and torch 1.7.0",believe breaking example actually import label label work torch,issue,negative,neutral,neutral,neutral,neutral,neutral
846456903,"Makes sense. Another option would be to remove `_fa_rebuild_*` functions to keep it consistent with what's done in pytorch if it's ok?

Upd: switched `__reduce_ex__` to use native pytorch `_rebuild*` funcs cause as mentioned by @riven314 `_fa_rebuild*` and call to `as_subclass` in `_rebuild_from_type` are redundant
If this is accepted `_fa_rebuild*` funcs can be removed as those are not used elsewhere",sense another option would remove keep consistent done switched use native cause riven call redundant accepted removed used elsewhere,issue,negative,positive,neutral,neutral,positive,positive
846438933,"I think the subclassing in this line is redundant:
```
ret = func(*args).as_subclass(type)
```

because unlike pytorch, the `func` in fastai is either `_fa_rebuild_tensor` or `_fa_rebuild_qtensor`, both of which returns subclass instead of torch.Tensor. 

So would it be better to make the change like this?
```
def _rebuild_from_type(func, args, dict):
    ret = func(*args)
    ret.__dict__ = dict
    return ret

# TensorBase
  def __reduce_ex__(self,proto):
      torch.utils.hooks.warn_if_has_hooks(self)
      args = (type(self), self.storage(), self.storage_offset(), tuple(self.size()), self.stride())
      if self.is_quantized: args = args + (self.q_scale(), self.q_zero_point())
      args = args + (self.requires_grad, OrderedDict())
      f = _fa_rebuild_qtensor if self.is_quantized else  _fa_rebuild_tensor
      return (_rebuild_from_type, (f, args, self.__dict__))
```",think line redundant ret type unlike either subclass instead would better make change like ret return ret self proto self type self else return,issue,positive,positive,positive,positive,positive,positive
846024958,"This is also an issue in fastaudio with an open issue over there as well.  

https://github.com/fastaudio/fastaudio/issues/95",also issue open issue well,issue,negative,neutral,neutral,neutral,neutral,neutral
844081268,"I think this might be better off in nbdev, where all the badges are handled.

cc @hamelsmu ",think might better handled,issue,negative,positive,positive,positive,positive,positive
842543481,"Please @jph00 make a release.

On Mon, May 17, 2021, 4:16 PM Alex Lau ***@***.***> wrote:

> @BobMcDear <https://github.com/BobMcDear>
> Thanks so much for the pointer!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3281#issuecomment-842361435>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEMWOAJXTHHT3BICP2L3AK3TOEQLHANCNFSM4ZZKIQZA>
> .
>
",please make release mon may wrote thanks much pointer thread reply directly view,issue,positive,positive,positive,positive,positive,positive
841844136,"@renato145 thanks for the verification, I believe this may have also been fixed in this latest version (the issue opened up on the forums). 

Also looks like notebooks and the lib aren't synced. Can you run `nbdev_build_lib` one more time?",thanks verification believe may also fixed latest version issue also like run one time,issue,positive,positive,positive,positive,positive,positive
841833487,@muellerzr I just tried and it was working fine. Can you share and example of that happening?,tried working fine share example happening,issue,negative,positive,positive,positive,positive,positive
841815103,"I’ve been made aware of that this only adds Normalize to the train, not the
validation. Can you confirm this Renato? And perhaps maybe we can fix that
here?

On Sun, May 16, 2021 at 6:38 AM Renato Hermoza Aragonés <
***@***.***> wrote:

> Ready to go @jph00 <https://github.com/jph00>, updated with your
> suggestions.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3371#issuecomment-841798925>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV6EKPBAMEY54CAM763TN6OARANCNFSM44YI2HVA>
> .
>
",made aware normalize train validation confirm perhaps maybe fix sun may wrote ready go reply directly view,issue,negative,positive,positive,positive,positive,positive
841787416,"I encountered the same issue when using fastai in kaggle kernel (2.2.7)
Would you mind pointing me to the PR that fixed the issue?
I would like to know what cause the issue, thanks!",issue kernel would mind pointing fixed issue would like know cause issue thanks,issue,positive,positive,positive,positive,positive,positive
841412433,My apologies for the late reply. I was too busy last weeks and could not find free time to update and check my patch.,late reply busy last could find free time update check patch,issue,positive,positive,neutral,neutral,positive,positive
840017336,"Is there a way to add TrackerCallback and make it monitor every metric?
Just trying to find a way to make it easily maintainable.",way add make monitor every metric trying find way make easily maintainable,issue,negative,positive,positive,positive,positive,positive
840015774,"@borisdayma If I understand it correctly `recorder.log` contains the metrics corresponding to the most recent epoch not the best one. And there is separate `TrackerCallback` [here](https://github.com/fastai/fastai/blob/d7779196359c8e497a80e2f7f85c327318777c1a/fastai/callback/tracker.py#L20) which monitors best value for early stopping and saving model. But it only monitors particular metric selected for monitoring, while all metrics might be interesting for analysis using W&B.",understand correctly metric corresponding recent epoch best one separate best value early stopping saving model particular metric selected metric might interesting analysis,issue,positive,positive,positive,positive,positive,positive
839996617,"Awesome!
I try to always reuse existing parameters from other callbacks. Don't we already have access to best metrics? Maybe [here](https://github.com/fastai/fastai/blob/30286a0ceb388b7f514a6f7066bfc3585312d548/fastai/callback/wandb.py#L129)",awesome try always reuse already access best metric maybe,issue,positive,positive,positive,positive,positive,positive
838523767,"That would be the progress bar. When doing predict try:

```python
with learn.no_bar(), learn.no_logging():
  learn.predict(...)
```",would progress bar predict try python,issue,negative,neutral,neutral,neutral,neutral,neutral
834127516,"> 
> 
> Quick Fix:
> 
> ```python
> def foreground_acc(inp, targ, bkg_idx=0, axis=1):
>     ""Computes non-background accuracy for multiclass segmentation""
>     targ = cast(targ.squeeze(1), TensorBase)
>     mask = targ != bkg_idx
>     return (inp.argmax(dim=axis)[mask]==targ[mask]).float().mean()
> ```


This fix works great for the time being. Than you for this quick solution.",quick fix python accuracy segmentation cast mask return mask mask fix work great time quick solution,issue,positive,positive,positive,positive,positive,positive
834108518,"Quick Fix:
```python
def foreground_acc(inp, targ, bkg_idx=0, axis=1):
    ""Computes non-background accuracy for multiclass segmentation""
    targ = cast(targ.squeeze(1), TensorBase)
    mask = targ != bkg_idx
    return (inp.argmax(dim=axis)[mask]==targ[mask]).float().mean()
```",quick fix python accuracy segmentation cast mask return mask mask,issue,negative,positive,positive,positive,positive,positive
833871908,Many thanks for the PR. Overall I agree with @tcapelle's view however - I don't think this is the right approach.,many thanks overall agree view however think right approach,issue,positive,positive,positive,positive,positive,positive
833829671,"As far as I am concerned the issue is that the installation instructions are wrong. It [says](https://docs.fast.ai/#Installing):

> If you install with pip, you should install PyTorch first by following the PyTorch [installation instructions](https://pytorch.org/get-started/locally/).

This extra step is what caused the problem, so the documentation should be fixed to not included that sentence. You can create a separate issue and close this one if you think it is more appropriate.",far concerned issue installation wrong install pip install first following installation extra step problem documentation fixed included sentence create separate issue close one think appropriate,issue,negative,positive,neutral,neutral,positive,positive
833515538,"The sampling you are proposing does not solve the distribution issue. It just flips a coin for each file it gets.
The distribution is something that it is no meant to be solved by this type of functions anyway. I think that this type of functionality should be available on the different `DataLoaders` that you want to construct afterwards.  ",sampling solve distribution issue coin file distribution something meant type anyway think type functionality available different want construct afterwards,issue,negative,positive,positive,positive,positive,positive
833467480,"> `get_files` returns a list, so one can easily call `sample` on it and obtain a smaller one.

Yes, but I also think that in that case, the relative distribution of categories would be uncertain. For example, if you sample a subset from a dataset that initially had an equal number of files among all categories, now it may or may not be the case. And to ensure that the distribution remains the same, you would have to write a whole block of code including if/else statements and for loops for each category. This would be a seriously long process, especially in the case of extremely large size/cardinal datasets. 

One thing that we can do is write a separate function that's meant just to get a subset of the dataset. Something like `get_subset_files`. And in turn leave this function as is.",list one easily call sample obtain smaller one yes also think case relative distribution would uncertain example sample subset initially equal number among may may case ensure distribution remains would write whole block code category would seriously long process especially case extremely large one thing write separate function meant get subset something like turn leave function,issue,positive,positive,neutral,neutral,positive,positive
833457903,"I am not a big fan of this, it complexify a very used and simple function. `get_files` returns a list, so one can easily call `sample` on it and obtain a smaller one.",big fan complexify used simple function list one easily call sample obtain smaller one,issue,positive,positive,positive,positive,positive,positive
833162769,Is this issue relevant anymore @HiPhish? Fastai just added support for the latest PyTorch packages...,issue relevant added support latest,issue,negative,positive,positive,positive,positive,positive
832470263,"You can set the learning rate in the `Learner`. Is there any reason for setting the `lr` in your optimizer? I'm asking this becase solving this issue makes library more complex!

```python
def get_learner(m):
    opt_func = partial(OptimWrapper, opt=torch.optim.SGD)
    return Learner(dls, m, loss_func=nn.CrossEntropyLoss(), metrics=accuracy, opt_func=opt_func, lr=0.002).to_fp16()
```",set learning rate learner reason setting issue library complex python partial return learner,issue,negative,negative,negative,negative,negative,negative
832203820,"Hi @jph00, I hoped to get around the complex notebook set up by editing the html directly, but I see that I did not manage that. If it's quick for you, I don't need credit for the PR and you're welcome to reject it and redo. Otherwise, I can plan to set up an environment and follow the prescribed steps to make the same change in the not-so-distant future. ",hi hoped get around complex notebook set directly see manage quick need credit welcome reject redo otherwise plan set environment follow make change future,issue,positive,positive,positive,positive,positive,positive
831470585,"1. fastai does not support torch 1.8+ yet, therefore torch 1.8 was uninstalled and 1.7 was installed.
2. torchaudio which was installed before running `pip install fastai` does not support torch 1.7.
3. That is a dependency conflict. 

This problem is not due to fastai install instructions. If you only had run `pip install torch` before `pip install fastai`, everything was fine. Do you need torchaudio really? If yes, you can install torchaudio 0.7.x.

`pip uninstall torchaudio`
`pip install torchaudio==0.7.2`",support torch yet therefore torch uninstalled running pip install support torch dependency conflict problem due install run pip install torch pip install everything fine need really yes install pip pip install,issue,positive,positive,positive,positive,positive,positive
831416007,@estaar we're working on this for the next release. There were a few bugs between the two torch versions,working next release two torch,issue,negative,neutral,neutral,neutral,neutral,neutral
831298531,Any new Update on this. tried to install fastai today and that error is very annoying and I have to recreate my environment again and just use normal Pytorch,new update tried install today error annoying recreate environment use normal,issue,negative,negative,negative,negative,negative,negative
830871879,"@andviane what Thomas has linked is correct, you should use a `test_dl` to perform batch inference. I have an example for semantic segmentation here: https://walkwithfastai.com/Segmentation#Inference

@jph00 think this can be closed, as my understanding is that `test_dl` coupled with `get_preds` should be the desired functionality they want",linked correct use perform batch inference example semantic segmentation think closed understanding coupled desired functionality want,issue,negative,negative,neutral,neutral,negative,negative
830766058,"Hi @muellerzr,

I have seen that the same issue happen on line 579:
https://github.com/fastai/fastai/blob/7fe5fcaab3c0b692a0be54ffe651f04f4cdd4a39/fastai/learner.py#L575-L579

Could you please also add this fix?
Thanks!",hi seen issue happen line could please also add fix thanks,issue,positive,positive,positive,positive,positive,positive
830697957,Yup can be - `get_idxs` is used to change sampling method,used change sampling method,issue,negative,neutral,neutral,neutral,neutral,neutral
830651763,"@tcapelle tutorials with all_slow flag won't run on github pushes (as it only runs `nbdev_test_nbs`.) I'd still say we want them running with the --slow flag, as this way we know if a tutorial broke :) ",flag wo run still say want running slow flag way know tutorial broke,issue,negative,negative,negative,negative,negative,negative
830626765,"Thanks Jeremy, It may be a good idea to move the tutorials notebooks out of nbs folder to not make them run on the tests.",thanks may good idea move folder make run,issue,positive,positive,positive,positive,positive,positive
830625932,"This is an issue, had the same problem last week on a fresh VM. You need to manually install pytorch 1.7.1 first, in the instruction it is expalined:
```
To install with pip, use: pip install fastai. If you install with pip, you should install PyTorch first by following the PyTorch installation instructions.
```",issue problem last week fresh need manually install first instruction install pip use pip install install pip install first following installation,issue,negative,positive,positive,positive,positive,positive
830475544,Sorry it took a while to merge this @tcapelle - it looks really great! :D ,sorry took merge really great,issue,positive,positive,positive,positive,positive,positive
830213212,"For anyone who still has this issue, this is the only thing that worked for me: 

`  def forward(self, x):`
 `       x = self.m(x)`
   `     x = torch.flatten(x, 1)`
`       x = torch.Tensor(x.cpu().float()).float().cuda()`
 `       return x`",anyone still issue thing worked forward self return,issue,negative,neutral,neutral,neutral,neutral,neutral
830039167,"Currently I do not have the fork prepared for contributing and not so much time. If at some point I have time to make the changes I will do as you mentioned. 

However, if someone wants to proceed with this small change then I would appreciate.",currently fork prepared much time point time make however someone proceed small change would appreciate,issue,positive,negative,neutral,neutral,negative,negative
829751991,"@jph00 not 100% sure why the medical imaging tutorial hates me, looks to be maybe device-side or something with how the metadata on the image is cleaned? (otherwise it *looks* fine on the diff viewer)",sure medical tutorial maybe something image otherwise fine viewer,issue,negative,positive,positive,positive,positive,positive
829724562,@jph00 this one looks ready to review without any conflicts :) ,one ready review without,issue,negative,positive,positive,positive,positive,positive
829715359,@trdvangraft please let me know when this is ready to review,please let know ready review,issue,positive,positive,positive,positive,positive,positive
829711671,Many thanks @KChalk ! Could you please run `make` or `nbdev_build_lib` so that the code is synced with the notebooks?,many thanks could please run make code,issue,positive,positive,positive,positive,positive,positive
829575870,"After interaction with @muellerzr on Discord fastai-help channel about this, he encouraged me to submit a PR.",interaction discord channel submit,issue,negative,neutral,neutral,neutral,neutral,neutral
829271361,"Just use a `test_dl` approach. You can create a dataloader easily and make inference on it using a batch size. Take a look here:
https://docs.fast.ai/tutorial.pets.html#Adding-a-test-dataloader-for-inference at the end.",use approach create easily make inference batch size take look end,issue,positive,positive,positive,positive,positive,positive
828987078,"@mszhanyi I've merged this PR, but it won't actually stick since the README is auto-generated from `nbs/index.ipynb`. So you need to edit that notebook, then run `nbdev_build_docs`. That will automatically update the docs too.

I also suggest you don't add a section saying ""windows is now supported"" since that is a message that is specific to a point in time. Instead, simply add a section called ""Windows support"" which says something like ""fastai runs on Windows, but please keep in mind the following issues:""... and then list the things people need to know. ",wo actually stick since need edit notebook run automatically update also suggest add section saying since message specific point time instead simply add section support something like please keep mind following list people need know,issue,positive,neutral,neutral,neutral,neutral,neutral
828984617,Thanks @rosbo . I'll take a look and see how much work it'll be to support spacy3.,thanks take look see much work support spacy,issue,positive,positive,positive,positive,positive,positive
828499013,"Hi guys! Do you have any update on this issue?
Is there any reason to not bump PyTorch's dependency?
Thanks a lot!",hi update issue reason bump dependency thanks lot,issue,negative,positive,positive,positive,positive,positive
827769841,"The testing comes from fastcore:

```python
from fastcore.test import *
```

https://fastcore.fast.ai/test.html",testing come python import,issue,negative,neutral,neutral,neutral,neutral,neutral
827530697,"Hi @muellerzr 

Sorry to bother but I spent ~20 minutes looking for some kind of guide on how to write tests for fastai and couldn't manage to find anything holistic.

I worked out that all the tests exist in the jupyter notebooks, but I can't find the testing library (e.g. where is the `test_close` function defined?) or a guide on how to write good tests.

Can you link me to a guide on good testing practices or a walkthrough on writing tests?",hi sorry bother spent looking kind guide write could manage find anything holistic worked exist ca find testing library function defined guide write good link guide good testing writing,issue,positive,positive,positive,positive,positive,positive
827276653,"Can you add your example in as a test in the notebook please? (Or write a different test if you so choose), so that we can catch this pre-emptively if something changes",add example test notebook please write different test choose catch something,issue,negative,neutral,neutral,neutral,neutral,neutral
825993684,@muellerzr  has a larger PR regarding LR find he is working on that includes this enhancement as a piece of it.  Closing this PR.  Will make a new PR after his if necessary. ,regarding find working enhancement piece make new necessary,issue,negative,positive,neutral,neutral,positive,positive
825259529,"Allow the validation set to be empty.

I have often needed to test whether a model is competent to learn a task at all, by seeing whether the training loss goes down. fastai makes me create a validation set and DataLoader anyway. What if we could write data=DataLoaders(trainDS, None) and have everything just work?",allow validation set empty often test whether model competent learn task seeing whether training loss go create validation set anyway could write none everything work,issue,negative,positive,positive,positive,positive,positive
824946849,"Tnx, will try that too

Em qui, 22 de abr de 2021 12:20, Zachary Mueller ***@***.***>
escreveu:

> @coldfir3 <https://github.com/coldfir3> you can also include a Flatten()
> layer to your model (which does the same thing)
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2769#issuecomment-824935815>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ADIYOYIPEXIALZ44AJ53ZLLTKA5C3ANCNFSM4Q6E553Q>
> .
>
",try em de de also include flatten layer model thing reply directly view,issue,negative,positive,neutral,neutral,positive,positive
824935815,@coldfir3 you can also include a `Flatten()` layer to your model (which does the same thing),also include flatten layer model thing,issue,negative,neutral,neutral,neutral,neutral,neutral
824932069,@hamelsmu can be closed due to my fix earlier today,closed due fix today,issue,negative,negative,negative,negative,negative,negative
824931825,"@hamelsmu link does no longer show up, but it looks like the autocompleter needs a refresher on what's valid? (Not sure if you know how to do this)",link longer show like need refresher valid sure know,issue,positive,positive,positive,positive,positive,positive
824930968,"@morganmcg1 did you ever wind up looking into this more? (I know, *really* old issue)",ever wind looking know really old issue,issue,negative,positive,neutral,neutral,positive,positive
824928348,"@hamelsmu can be closed, all migration doc links are working",closed migration doc link working,issue,negative,negative,neutral,neutral,negative,negative
824926426,"@hamelsmu let's rename this issue to ""Captum Integration"" broken (which we know this being due to captum currently not working)",let rename issue integration broken know due currently working,issue,negative,negative,negative,negative,negative,negative
824925828,"@hamelsmu this can be closed, Jeremy fixed this with a release a bit ago",closed fixed release bit ago,issue,negative,neutral,neutral,neutral,neutral,neutral
824925464,"@smart-patrol @fil82 are you still having issues? If so can you try installing the latest version and try again? (and give a bit more context on your systems being used, the version of fastai, etc?)",still try latest version try give bit context used version,issue,negative,positive,positive,positive,positive,positive
824919614,"@matveevai fastai version 1 has the import as `fastai.callbacks, but in fastai version 2 it's `fastai.callback` which you should also import with: `from fastai.callback.all import *`.

You'll know if you're using version 1 or two if `pip show fastai` (or `fastai.__version__`) shows fastai 1.0.x or fastai 2.x.x

@hamelsmu should be okay to close as this relates to the old version of the library",version import version also import import know version two pip show close old version library,issue,negative,positive,neutral,neutral,positive,positive
824918113,"@Saeed0Baba as @shIsmael said, `DatasetType` was fastai v1 specific, now we can simply pass in any `DataLoader` to get preds, and you can perform inference with the snippet shown there.

@hamelsmu should be good to close now. ",said specific simply pas get perform inference snippet shown good close,issue,negative,positive,positive,positive,positive,positive
824917224,"@Metal-joker we also need:

Your version of fastai
Your version of fastcore
Your version of torch.

Run:
```python
from fastai.test_utils import show_install
show_install()
```
And copy its output to here please!",also need version version version torch run python import copy output please,issue,negative,neutral,neutral,neutral,neutral,neutral
824910364,"@JWindy this repo is for the fastai library, you should open this in the fastbook repo: https://github.com/fastai/fastbook

cc: @hamelsmu this should be closed as it's not pertaining to the fastai library",library open closed pertaining library,issue,negative,negative,neutral,neutral,negative,negative
824186215,"I fixed this issue by creating a new module that casts the TensorImage to Tensor

```
class cast_to_tensor(Module):
  def forward(self, x): return cast(x, Tensor)
```

Then I added it as the last layer of my network

```
model = nn.Sequential(
  ...
  cast_to_tensor()
)
```
",fixed issue new module tensor class module forward self return cast tensor added last layer network model,issue,negative,positive,neutral,neutral,positive,positive
823969348,"> > > Does anybody know if I can run pytorch with CudaToolkit11.1 and fastai? I've been having issues trying to get them both to work together. I'm running a 3090 so I need cuda>=11, but I've been having issues getting a compatible version of torchvision installed.
> > > ERROR: Could not find a version that satisfies the requirement torchvision<0.9,>=0.8 (from fastai)
> > > ERROR: No matching distribution found for torchvision<0.9,>=0.8
> > 
> > 
> > Did you have any luck?
> > I am on a 3080 notebook GPU and get a warning: `Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.`
> > And if I try to still train I get a `RuntimeError: CUDA error: no kernel image is available for execution on the device`
> 
> I downgraded my FastAI version I believe, but now I have a plethora of other issues I'm running into. Still haven't been able to train a GAN with FastAI on a 3090. Got to the point I have stepped away to reset after the burnout and frustration.

So I entangled myself in python package dependency hell yesterday but then switched over to anaconda from miniconda. And after freshly installing fastai, etc. it seems that it works now for me. At least it does not break where it broke before when training a resnet. So I hope that can work for others.",anybody know run trying get work together running need getting compatible version error could find version requirement error matching distribution found luck notebook get warning capability compatible current try still train get error kernel image available execution device version believe plethora running still able train gan got point stepped away reset burnout frustration entangled python package dependency hell yesterday switched anaconda freshly work least break broke training hope work,issue,negative,positive,positive,positive,positive,positive
823672110,"> 
> 
> > Does anybody know if I can run pytorch with CudaToolkit11.1 and fastai? I've been having issues trying to get them both to work together. I'm running a 3090 so I need cuda>=11, but I've been having issues getting a compatible version of torchvision installed.
> > ERROR: Could not find a version that satisfies the requirement torchvision<0.9,>=0.8 (from fastai)
> > ERROR: No matching distribution found for torchvision<0.9,>=0.8
> 
> Did you have any luck?
> 
> I am on a 3080 notebook GPU and get a warning: `Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.`
> And if I try to still train I get a `RuntimeError: CUDA error: no kernel image is available for execution on the device`

I downgraded my FastAI version I believe, but now I have a plethora of other issues I'm running into. Still haven't been able to train a GAN with FastAI on a 3090. Got to the point I have stepped away to reset after the burnout and frustration.",anybody know run trying get work together running need getting compatible version error could find version requirement error matching distribution found luck notebook get warning capability compatible current try still train get error kernel image available execution device version believe plethora running still able train gan got point stepped away reset burnout frustration,issue,negative,positive,positive,positive,positive,positive
823629382,"The solution is likely to pin the version of `captum`, but I'm not sure we should do that as I vaguely remember that these third party libraries always cause issues so maybe we should approach this differently?  ",solution likely pin version sure vaguely remember third party always cause maybe approach differently,issue,positive,neutral,neutral,neutral,neutral,neutral
823092383,"> Does anybody know if I can run pytorch with CudaToolkit11.1 and fastai? I've been having issues trying to get them both to work together. I'm running a 3090 so I need cuda>=11, but I've been having issues getting a compatible version of torchvision installed.
> 
> ERROR: Could not find a version that satisfies the requirement torchvision<0.9,>=0.8 (from fastai)
> ERROR: No matching distribution found for torchvision<0.9,>=0.8

Did you have any luck? 

I am on a 3080 notebook GPU and get a warning: `Laptop GPU with CUDA capability sm_86 is not compatible with the current PyTorch installation.`
And if I try to still train I get a `RuntimeError: CUDA error: no kernel image is available for execution on the device`",anybody know run trying get work together running need getting compatible version error could find version requirement error matching distribution found luck notebook get warning capability compatible current try still train get error kernel image available execution device,issue,negative,positive,positive,positive,positive,positive
821963380,"My question was about exposing a non-existant param. Shouldn't calling a method/func with a non-existant kwargs raise an error?
Here we are calling `DataLoader.new` with a kwargs that does not exists, how can we make this fail.",question param calling raise error calling make fail,issue,negative,negative,negative,negative,negative,negative
821832164,"@Perseus14
Yes, if I remember correctly, you export the model to a .py, import that into your notebooks or wherever you are saving the model. Then, during inference you load from that same .py file, and it should work. The reference to the object then matches in both cases. ",yes remember correctly export model import wherever saving model inference load file work reference object,issue,negative,neutral,neutral,neutral,neutral,neutral
821782369,"@Baukebrenninkmeijer I am facing the same issue, were you able to fix it?",facing issue able fix,issue,negative,positive,positive,positive,positive,positive
821772399,"> Would you mind adding the spectral norm init also?
> […](#)
> On Thu, Apr 15, 2021, 8:50 AM pratX ***@***.***> wrote: Updated PixelShuffle_icnr unit test to check for both cases, weight_norm enabled and disabled. — You are receiving this because you are subscribed to this thread. Reply to this email directly, view it on GitHub <[#3322 (comment)](https://github.com/fastai/fastai/pull/3322#issuecomment-820164227)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AEMWOAK4ANPJKXU26YDGKX3TI2EDDANCNFSM42542OBA> .

Added unit test for PixelShuffle_icnr with sepctral_norm.",would mind spectral norm also wrote unit test check disabled thread reply directly view comment added unit test,issue,negative,negative,neutral,neutral,negative,negative
821570539,"Would you mind adding the spectral norm init also?

On Thu, Apr 15, 2021, 8:50 AM pratX ***@***.***> wrote:

> Updated PixelShuffle_icnr unit test to check for both cases, weight_norm
> enabled and disabled.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3322#issuecomment-820164227>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEMWOAK4ANPJKXU26YDGKX3TI2EDDANCNFSM42542OBA>
> .
>
",would mind spectral norm also wrote unit test check disabled thread reply directly view,issue,negative,negative,neutral,neutral,negative,negative
821549496,"cc @jph00 this looks fine to me. The reason this never popped up any tests is `shuffle` is set to `False` by default, so it was still generating a non-shuffled `DataLoader`. Just instead the wrong param was exposed. (Which is a non-existant one)",fine reason never shuffle set false default still generating instead wrong param exposed one,issue,negative,negative,negative,negative,negative,negative
821541484,"Looks good to me, I agree with the fix and change. cc @jph00 ",good agree fix change,issue,positive,positive,positive,positive,positive,positive
820990835,Then the install instructions are wrong. I have not installed fastai using just `pip install fastai` without manually installing PyTorch first and it seems to be working. Could have saved me a lot of frustration. Should I leave this issue open until the installation instructions are fixed?,install wrong pip install without manually first working could saved lot frustration leave issue open installation fixed,issue,negative,negative,neutral,neutral,negative,negative
820862170,Everything looks fine to me. fastai does not support torch 1.8+ yet. It seems you have successfully installed fastai though...,everything fine support torch yet successfully though,issue,positive,positive,positive,positive,positive,positive
820650950,"> but what I undertood from @jantic is that the best norm to use was spectral, so should not we init for this?

I'm just now getting caught up here after a return from vacation. My answer to that is in my limited set of image to image applications, this is indeed what I've found to work best. But that's qualified with ""your mileage may vary"" because I don't have the benchmarks to prove that this is true across the board. So it seems best to stick with the default of weight_norm here until that's proven otherwise.",best norm use spectral getting caught return vacation answer limited set image image indeed found work best qualified mileage may vary prove true across board best stick default proven otherwise,issue,positive,positive,positive,positive,positive,positive
820164227,"Updated PixelShuffle_icnr unit test to check for both cases, weight_norm enabled and disabled. Both the unit tests pass.",unit test check disabled unit pas,issue,negative,negative,negative,negative,negative,negative
820145096,"The PR is now ready. Updated the unit test for PixelShuffle_icnr as well.
https://github.com/fastai/fastai/pull/3322",ready unit test well,issue,positive,positive,positive,positive,positive,positive
820144021,"Updated the notebook with the fix and also the unit test. The unit test passes with weight_norm enabled (earlier weight_norm was explicitly disabled in the unit test, even though the description said that weight_norm is what worked best with super_resolution) which is the expected behavior.",notebook fix also unit test unit test explicitly disabled unit test even though description said worked best behavior,issue,positive,positive,positive,positive,positive,positive
820133096,Work in Progress. Checking out nbdev and following the development process used for fastai.,work progress following development process used,issue,negative,neutral,neutral,neutral,neutral,neutral
820100954,"> Yeap, but you need also to call nbdev_build_lib on it
> […](#)
> On Wed, Apr 14, 2021, 8:21 PM pratX ***@***.***> wrote: Submitted PR #3322 <#3322> I have directly edited the fastai/layers.py file; might need to change the corresponding notebook as well, I am not currently well versed with the development process followed here. — You are receiving this because you commented. Reply to this email directly, view it on GitHub <[#3315 (comment)](https://github.com/fastai/fastai/issues/3315#issuecomment-819734684)>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AEMWOALV3N6O4D6HTJ2BO7TTIXMMDANCNFSM42ZJKQSA> .

I'll checkout nbdev and follow the process.",need also call wed wrote directly file might need change corresponding notebook well currently well versed development process reply directly view comment follow process,issue,negative,positive,neutral,neutral,positive,positive
820016602,"> @matveevai I have a same problem. do you solve it ?

try this

![image](https://user-images.githubusercontent.com/54096137/114806555-8c29a100-9dd7-11eb-9ce9-83e27306c751.png)

but this version is old.",problem solve try image version old,issue,negative,positive,neutral,neutral,positive,positive
819738171,"Yeap, but you need also to call nbdev_build_lib on it

On Wed, Apr 14, 2021, 8:21 PM pratX ***@***.***> wrote:

> Submitted PR #3322 <https://github.com/fastai/fastai/pull/3322>
> I have directly edited the fastai/layers.py file; might need to change the
> corresponding notebook as well, I am not currently well versed with the
> development process followed here.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3315#issuecomment-819734684>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEMWOALV3N6O4D6HTJ2BO7TTIXMMDANCNFSM42ZJKQSA>
> .
>
",need also call wed wrote directly file might need change corresponding notebook well currently well versed development process reply directly view,issue,negative,positive,neutral,neutral,positive,positive
819734684,"Submitted PR https://github.com/fastai/fastai/pull/3322 
I have directly edited the fastai/layers.py file; might need to change the corresponding notebook as well, I am not currently well versed with the development process followed here.",directly file might need change corresponding notebook well currently well versed development process,issue,negative,positive,neutral,neutral,positive,positive
819465819,"Yes we can change the default behavior to Spectral maybe if there is solid empirical backing that it generally does better. But if the normType is WeightNorm, as in if someone using the library wants to use WeighNorm then this change has to go in for icnr_init to be effective.",yes change default behavior spectral maybe solid empirical backing generally better someone library use change go effective,issue,positive,positive,positive,positive,positive,positive
819462897,"but what I undertood from @jantic is that the best norm to use was spectral, so should not we init for this?",best norm use spectral,issue,positive,positive,positive,positive,positive,positive
819461502,"For my use_case I have have done as follows:

```
import fastai.layers as fastai_layers
class PixelShuffle_ICNR(torch.nn.Sequential):
    ""Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`.""
    def __init__(self, ni, nf=None, scale=2, blur=False, norm_type=fastai_layers.NormType.Weight, 
                 act_cls=fastai_layers.defaults.activation):
        super().__init__()
        nf = fastai_layers.ifnone(nf, ni)
        layers = [fastai_layers.ConvLayer(ni, nf*(scale**2), ks=1, norm_type=norm_type, act_cls=act_cls, bias_std=0),
                  torch.nn.PixelShuffle(scale)]
        if norm_type == fastai_layers.NormType.Weight:
            layers[0][0].weight_v.data.copy_(fastai_layers.icnr_init(layers[0][0].weight_v.data))
            layers[0][0].weight_g.data.copy_(((layers[0][0].weight_v.data**2).sum(dim=[1,2,3])**0.5)[:,None,None,None])
        else:
            layers[0][0].weight.data.copy_(fastai_layers.icnr_init(layers[0][0].weight.data))
        
        if blur: layers += [torch.nn.ReplicationPad2d((1,0,1,0)), torch.nn.AvgPool2d(2, stride=1)]
        super().__init__(*layers)
```

This doesn't break compatibility with other norm types.",done import class scale ni default ni self ni super ni ni scale scale none none else blur super break compatibility norm,issue,positive,positive,positive,positive,positive,positive
818855190,"Something like this, can you try?
```python
def icnr_init(x, scale=2, init=nn.init.kaiming_normal_):
    ""ICNR init of `x`, with `scale` and `init` function""
    ni,nf,h,w = x.shape
    ni2 = int(ni/(scale**2))
    k = init(x.new_zeros([ni2,nf,h,w])).transpose(0, 1)
    k = k.contiguous().view(ni2, nf, -1)
    k = k.repeat(1, 1, scale**2)
    weigth_v = k.contiguous().view([nf,ni,h,w]).transpose(0, 1)
    weight_g = torch.norm(weight_v, dim=[1,2]).unsqueeze_(-1).unsqueeze_(-1)
    return weight_v, weight_g


class PixelShuffle_ICNR(nn.Sequential):
    ""Upsample by `scale` from `ni` filters to `nf` (default `ni`), using `nn.PixelShuffle`.""
    def __init__(self, ni, nf=None, scale=2, blur=False, norm_type=NormType.Weight, act_cls=defaults.activation):
        super().__init__()
        nf = ifnone(nf, ni)
        layers = [ConvLayer(ni, nf*(scale**2), ks=1, norm_type=norm_type, act_cls=act_cls, bias_std=0),
                  nn.PixelShuffle(scale)]
        weight_v, weight_g = icnr_init(layers[0][0].weight.data
        layers[0][0].weight_v.data.copy_(weight_v.data)
        layers[0][0].weight_g.data.copy_(weight_g.data)
        if blur: layers += [nn.ReplicationPad2d((1,0,1,0)), nn.AvgPool2d(2, stride=1)]
        super().__init__(*layers)    
```

Something like this would break the compatibilty with no norm and spectral norm, I would love the input from @jantic  on this.",something like try python scale function ni ni scale ni ni scale ni return class scale ni default ni self ni super ni ni scale scale blur super something like would break norm spectral norm would love input,issue,positive,positive,positive,positive,positive,positive
818825871,"How heavy this impacts the perf of the layer? I am currently using a lot of Unet and get lot's of artifacts. May this be related?
Aren't we using `spectral_norm` more often on Segmentation?",heavy layer currently lot get lot may related often segmentation,issue,negative,negative,neutral,neutral,negative,negative
817838053,We can initialize **weight_v** exactly the same way the derived **weight** is currently being initialized. **weight_g** would then be initialized to the per channel magnitude of **weight_v**.,initialize exactly way derived weight currently would per channel magnitude,issue,negative,positive,positive,positive,positive,positive
817826256,"I see 2 possible solutions, we change the `init_icnr` func to modify the leaf params or we init the `wieght_g` and `_d` params directly.",see possible change modify leaf directly,issue,negative,positive,neutral,neutral,positive,positive
817783820,"Hi @tmabraham  thank you for your help, I thin sobased on it working on the kaggle notebook. But I will check today pulling on the master just in case.",hi thank help thin working notebook check today master case,issue,positive,negative,negative,negative,negative,negative
817192715,Are the LR finder curves vastly different? This could be just due to randomness from one machine to another...,finder vastly different could due randomness one machine another,issue,negative,negative,neutral,neutral,negative,negative
816937197,"@bojnin-basile 

```python
pip install fastai==2.0.19 fastcore==1.3.2
```

@hamelsmu this should be closable :) ",python pip install closable,issue,negative,neutral,neutral,neutral,neutral,neutral
816416204,"@jph00 I fixed the sync issues in this PR as well, it is ready for review.",fixed sync well ready review,issue,positive,positive,positive,positive,positive,positive
816284837,"Does anybody know if I can run pytorch with CudaToolkit11.1 and fastai? I've been having issues trying to get them both to work together. I'm running a 3090 so I need cuda>=11, but I've been having issues getting a compatible version of torchvision installed.

ERROR: Could not find a version that satisfies the requirement torchvision<0.9,>=0.8 (from fastai)
ERROR: No matching distribution found for torchvision<0.9,>=0.8",anybody know run trying get work together running need getting compatible version error could find version requirement error matching distribution found,issue,negative,neutral,neutral,neutral,neutral,neutral
816061513,"
You can review now ~~Not yet, let me add one example of the new transformer archs that have been recently invented (TimesFormer, ViVit, etc)~~",review yet let add one example new transformer recently,issue,negative,positive,neutral,neutral,positive,positive
816001096,@tcapelle is this PR ready to review?  I see that it is still marked as draft,ready review see still marked draft,issue,negative,positive,positive,positive,positive,positive
815995972,@jph00 I fixed this PR (sync issues) - ready for review,fixed sync ready review,issue,negative,positive,positive,positive,positive,positive
815995202,@muellerzr would you like to resolve conflicts please,would like resolve please,issue,positive,neutral,neutral,neutral,neutral,neutral
815986682,"I can actually merge this.  Thanks,  this I just minor documentation change",actually merge thanks minor documentation change,issue,negative,positive,neutral,neutral,positive,positive
815981661,"@jph00 I fixed this PR (the notebooks were out of sync with the lib), and I also fixed the CI.  It's ready for review.",fixed sync also fixed ready review,issue,negative,positive,positive,positive,positive,positive
815529344,"Thanks @hamelsmu for the reply, I was pretty sure the CI was down. It is crazy these attacks to mine crypto!",thanks reply pretty sure crazy mine,issue,positive,positive,neutral,neutral,positive,positive
815450764,@ReinierKoops I converted this to a draft PR while you sort the conflicts (and also b/c the PR title says WIP),converted draft sort also title,issue,negative,neutral,neutral,neutral,neutral,neutral
815437866,I followed your new method and it works very well!  Thanks again! @BobMcDear ,new method work well thanks,issue,positive,positive,positive,positive,positive,positive
815413117,"@fredguth This seems to be working for me. Any chance you could post some screenshots? 

![image](https://user-images.githubusercontent.com/41290559/113962862-e7094880-986b-11eb-95a8-39219585cf8a.png)
![image](https://user-images.githubusercontent.com/41290559/113962880-ed97c000-986b-11eb-98f8-fdfc2bee511f.png)
",working chance could post image image,issue,negative,neutral,neutral,neutral,neutral,neutral
815372484,Many thanks for the report - fixed now,many thanks report fixed,issue,negative,positive,positive,positive,positive,positive
815039419,Thanks for the clarification! That's what I thought. I was reading a paper published in 2019 and looked at their code to construct the collab learner and I have checked the tutorials of the updated fastai and sorted it out. Thanks again.,thanks clarification thought reading paper code construct learner checked sorted thanks,issue,positive,positive,positive,positive,positive,positive
814916202,"You're trying to use extremely outdated code. It would help to know the source of the article or the rough time period in which it came out. As it clearly isn't using fastai v2, nor fastai v1.0.0",trying use extremely outdated code would help know source article rough time period came clearly,issue,positive,negative,negative,negative,negative,negative
814601081,reverting this PR.  for some reason didn't render correctly on GitHub pages.   Will investigate.,reason render correctly investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
813953574,"I don't know why, but in Linux this last cell on 
![image](https://user-images.githubusercontent.com/18441985/113685735-d66b9d80-96c6-11eb-80c8-2e71b1e3e7fb.png)
data.load` fails.",know last cell image,issue,negative,neutral,neutral,neutral,neutral,neutral
813887073,"Found a similiar issue today after updating, where my tuple images where not moved to GPU correctly, and broken my forward pass.
Indeed @oguiza fix the issue.  I will make a PR.",found issue today correctly broken forward pas indeed fix issue make,issue,negative,negative,negative,negative,negative,negative
813300161,From what I saw fastai version 2.3.0 still requires PyTorch 1.7.1. PyTorch 1.8.1 has since been released. ,saw version still since,issue,negative,neutral,neutral,neutral,neutral,neutral
813177240,"Thank @oguiza for the quick fix. For anyone who uses Google Colab and wants to avoid editing the source code every runtime as I do, I suggest adding this monkey patch:
```
@patch
def one_batch(self: Learner, i, b):
    self.iter = i
    b_on_device = to_device(b, device=self.dls.device) if self.dls.device is not None else b
    self._split(b_on_device)
    self._with_events(self._do_one_batch, 'batch', CancelBatchException)
```",thank quick fix anyone avoid source code every suggest monkey patch patch self learner none else,issue,negative,positive,positive,positive,positive,positive
813059274,"Its me again, Unfortunately the above method doesn't always work
So is there any way to solve it permanently?",unfortunately method always work way solve permanently,issue,negative,negative,negative,negative,negative,negative
813047251,"Hi Again, I found a solution to this issue myself, so I am posting it here incase anyone gets stuck with the same issue, you will probably get this issue if you are on GPU, so after you construct your dataset in pytorch make sure to add the data to device in the same class that is within the Dataset class instead of training class like its usually done in Pytorch Training loops. Here is the example code.

```
class JSONnew(Dataset):
  def __init__(self,filename,transform=None):
    self.filename=filename
    self.transform=transform
    with open(self.filename) as f:
            self.data = json.load(f)


  def proc(self,band_1,band_2):
        band_3=band_1 / band_2
        r = (band_1 + abs(band_1.min())) / torch.max((band_1 + abs(band_1.min())))
        g = (band_2 + abs(band_2.min())) / torch.max((band_2 + abs(band_2.min())))
        b = (band_3 + abs(band_3.min())) / torch.max((band_3 + abs(band_3.min())))

        image = torch.stack([r, g, b],dim=0)
        return image

  def __getitem__(self,idx):
    id=self.data[idx][""id""]
    H=75
    band_1=torch.tensor(self.data[idx][""band_1""]).reshape(H,H)
    band_2=(torch.tensor(self.data[idx][""band_2""])).reshape(H,H)
    band_3 = band_1 / band_2
    image=self.proc(band_1,band_2)
    is_iceberg=self.data[idx][""is_iceberg""]
    label=torch.tensor(is_iceberg)
    label=label.type(torch.LongTensor)
    if self.transform:
        image=self.transform(image)
    image=image.to(device) #This is what i meant by putting in the dataset class
    label=label.to(device)
    return image,label
  
  def __len__(self):
    return len(self.data)
```
In case you dont know how to declare device, this is the code for that 
```device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")```

Cheers!
",hi found solution issue posting incase anyone stuck issue probably get issue construct make sure add data device class within class instead training class like usually done training example code class self open self image return image self id image device meant class device return image label self return case dont know declare device code device else,issue,positive,positive,neutral,neutral,positive,positive
813046261,"Hi, I have created a Dataset and DataLoader using pure pytorch, after which i imported fastai, however I am getting the following error when i am trying to put them in a DataBunch in fastai. I am new to fast.ai so can you tell me what should I amend, Thanks!

from fastai.vision import *
from fastai import *
data = DataBunch(train_loader, val_loader)

 '''AttributeError                            Traceback (most recent call last)
<ipython-input-47-7a37c0dca017> in <module>()
----> 1 data = DataBunch(train_loader, val_loader)

2 frames
/usr/local/lib/python3.7/dist-packages/fastai/basic_data.py in DataLoader___getattr__(dl, k)
     18 torch.utils.data.DataLoader.__init__ = intercept_args
     19 
---> 20 def DataLoader___getattr__(dl, k:str)->Any: return getattr(dl.dataset, k)
     21 DataLoader.__getattr__ = DataLoader___getattr__
     22 

AttributeError: 'Subset' object has no attribute 'init_kwargs' '''

Machine : Google Colab, GPU Enabled.

",hi pure however getting following error trying put new tell amend thanks import import data recent call last module data return object attribute machine,issue,negative,positive,neutral,neutral,positive,positive
812933399,where would I find source code of is_string_dtype()?,would find source code,issue,negative,neutral,neutral,neutral,neutral,neutral
812920907,"Yah, this has broken blurr as well :(

In the case of blurr, `xb` is a dictionary that looks like this:
```
{'input_ids': tensor([[   0, 4833, 3009,  ..., 1916,    6,    2],
        [   0, 1941, 4584,  ..., 2792,   11,    2],
        [   0,   38, 3996,  ...,  393,  956,    2],
        [   0,   38,  218,  ...,    8, 5930,    2]], device='cuda:1'), 'attention_mask': tensor([[1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1],
        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:1')}
```
... the updated code above where it attempts to move elements to the correct device:
```
b_on_device = tuple(e.to(device=self.dls.device) for e in b if hasattr(e, ""to"")) if self.dls.device is not None else b
```
returns just my `yb `as such:
```
(TensorCategory([0, 1, 1, 0], device='cuda:1'),)
```
and that of course doesn't bode well for anything there on out working.  I can verify that the fix proposed above by @oguiza above fixes the issue.

",yah broken well case dictionary like tensor tensor code move correct device none else course bode well anything working verify fix issue,issue,negative,negative,negative,negative,negative,negative
812087052,@jph00 this one is fine when you are ready to get to it (It's just minor cleanup/consistency) ,one fine ready get minor,issue,positive,positive,positive,positive,positive,positive
810327980,"Ah, now I see. The whole library had to be rebuild because of the addition of your one feature.",ah see whole library rebuild addition one feature,issue,negative,positive,positive,positive,positive,positive
809858924,"> I opened the notebook in colab and ran all. I did not get an error in colab on fastai 2.2.7 and was not able to replicate.

I use KVM CPU and Tesla T4 GPU with cuda 10.2. What information do you need to reproduce this, please let me know.",notebook ran get error able replicate use information need reproduce please let know,issue,negative,positive,positive,positive,positive,positive
809782447,"For anyone having this issue, please make sure you've installed the latest version of fastai via Github, not pip. [This](https://github.com/fastai/fastai/issues/3281), which also causes this bug, is only present in the pip version of fastai.",anyone issue please make sure latest version via pip also bug present pip version,issue,positive,positive,positive,positive,positive,positive
809781595,"This is completely my mistake. I assumed the latest version of fastai is on pip, and this issue goes away if fastai is installed via Github.",completely mistake assumed latest version pip issue go away via,issue,negative,positive,positive,positive,positive,positive
809678699,I opened the notebook in colab and ran all.  I did not get an error in colab on fastai 2.2.7 and was not able to replicate.,notebook ran get error able replicate,issue,negative,positive,positive,positive,positive,positive
809408772,"@yang20085936 Please take a look at [this](https://github.com/fastai/fastai/issues/3281). The correct way to fix it (for now) is to normalize your data through your DataBlock (```batch_tfms=Normalize.from_stats(*imagenet_stats)```) rather than the Learner. 

The method I proposed is flawed given that it causes your data not to get normalized if your DataBlock isn't normalizing the data.",yang please take look correct way fix normalize data rather learner method flawed given data get data,issue,negative,negative,negative,negative,negative,negative
809002750,"I have the same question and it can be fixed as @BobMcDear  said. Thanks!

> A couple of notes:
> 
>     1. It can be fixed by reinitializing (recreating) the DataLoaders object after creating the Learner and reassigning it (`Learner.dls = new_dls`).
> 
>     2. This only happens for the validation set, not the training set.

",question fixed said thanks couple fixed object learner validation set training set,issue,negative,positive,positive,positive,positive,positive
808783851,"Every file seems to have been edited, maybe a new pull request with only the actual feature change?",every file maybe new pull request actual feature change,issue,negative,positive,neutral,neutral,positive,positive
808610195,Apologies @marii-moe I didn't realize it was ready to merge now. Thanks so much for the code and the ping.,realize ready merge thanks much code ping,issue,positive,positive,positive,positive,positive,positive
807276442,I suspect this is related to a [bug](https://github.com/fastai/fastai/issues/3281) where fastai only normalizes the training set.,suspect related bug training set,issue,negative,neutral,neutral,neutral,neutral,neutral
806989614,"A hacky fix to the problem:

```
def layer_info(learn, *xb):
    ""Return layer infos of `model` on `xb` (only support batch first inputs)""
    def _track(m, i, o):
        if isinstance(i, tuple):
            # assume whenever i is a tuple, the first element is the actual input
            i = i[0]
        if isinstance(o, tuple):
            # assume whenever o is a tuple, the first element is the actual input
            o = o[0]
        params, trainable, shape = '', '', ''
        same = any((x[0].shape == x[1].shape for x in zip(i, o)))
        params, trainable = total_params(m)
        shape = apply(lambda x: x.shape, o)
        return (type(m).__name__, params, trainable, shape, same)

    with Hooks(flatten_model(learn.model), _track) as h:
        batch = apply(lambda o:o[:1], xb)
        train_only_cbs = [cb for cb in learn.cbs if hasattr(cb, '_only_train_loop')]
        with learn.removed_cbs(train_only_cbs), learn.no_logging(), learn as l:
            r = l.get_preds(dl=[batch], inner=True, reorder=False)
        return h.stored
```

revealed more problems in the summary method. In particular, most layers do not have a `weights` attribute for which there is a check. The above version works nicely with our ULMFit-based models.

Btw: In order to get appealing output from the `summary` method, we also had to overwrite nn.Module.children in the AWD_LSTM module to achieve proper ordering of the layers and look into EmbeddingDropout, which registers its child, the Embedding layer, but never really delegates to its forward method. Thus, the tracking callback is registered for the Embedding layer but never called. 

However, I guess that should better be a separate issue and tackled once there is a better and less hacky fix for this issue and when it can be reproduced without running into this issue on the way.
",hacky fix problem learn return layer model support batch first assume whenever first element actual input assume whenever first element actual input trainable shape zip trainable shape apply lambda return type trainable shape batch apply lambda learn batch return revealed summary method particular attribute check version work nicely order get appealing output summary method also overwrite module achieve proper look child layer never really forward method thus registered layer never however guess better separate issue tackled better le hacky fix issue without running issue way,issue,negative,positive,positive,positive,positive,positive
804651385,"@jph00 Don't mean to bother you too much, but currently cnn_learner's valid loss and accuracy are incorrect due to this issue.",mean bother much currently valid loss accuracy incorrect due issue,issue,negative,negative,negative,negative,negative,negative
803809469,I'm also getting this same error using Gradient with the latest pull.,also getting error gradient latest pull,issue,negative,positive,positive,positive,positive,positive
803439726,"I actually got this problem and for the rest of the dumb coders like me if a standard
 
`download_images(Path('.'), urls=urls)`  doesnt work then try adding the following parameter:
 
`download_images(Path('.'), urls=urls, n_workers = 0)`",actually got problem rest dumb like standard path doesnt work try following parameter path,issue,negative,negative,neutral,neutral,negative,negative
802964841,"I'm having the same issue on multiple machines. 

A couple of notes:
1. It can be fixed by reinitializing (recreating) the DataLoaders object after creating the Learner and reassigning it (```Learner.dls = new_dls```).
2. This only happens for the validation set, not the training set.

**Edit**

The method I proposed is flawed given that it causes your data not to get normalized if your DataBlock isn't normalizing the data.",issue multiple couple fixed object learner validation set training set edit method flawed given data get data,issue,negative,negative,negative,negative,negative,negative
802715717,"After this I will take a look at `Pipeline.add`. I think it needs to be updated to allow adding a list and we should also look at handling order when adding transforms. I think that logic should be reserved for the pipeline itself. Wanted to get this in first, as currently validation loss does not work with cnn_learner, and the pipeline change might take a bit longer. ",take look think need allow list also look handling order think logic reserved pipeline get first currently validation loss work pipeline change might take bit longer,issue,negative,positive,positive,positive,positive,positive
802509465,"Yes, I am also having the same issue! Look at the below image. All the leafs are originally green. 

![image](https://user-images.githubusercontent.com/14893062/111725997-10970b80-888e-11eb-912f-0dcda2718c25.png)
",yes also issue look image originally green image,issue,negative,negative,negative,negative,negative,negative
802489250,"course-v3 is the fastai1 version of the nbs, and dev_nbs contains the fastai2 version. We'd like to keep both.",version version like keep,issue,negative,neutral,neutral,neutral,neutral,neutral
801736895,"@gbinnie : Awesome ! It works now with your code!

big thanks from Bali !
",awesome work code big thanks bali,issue,positive,positive,positive,positive,positive,positive
801508416,I am reviewing the code with @muellerzr s suggestions. I had forgotten about order and I do agree the code could be better. ,code forgotten order agree code could better,issue,positive,positive,positive,positive,positive,positive
801498184,"So I think we can rewrite and simplify this a bit more:

```python
@patch
def _add_tfm(self:DataLoaders, tfms, event, ds_idx):
    ""Adds `tfms` to `event` on `dl`""
    dl_tfms = getattr(self[ds_idx], event)
    apply(dl_tfms.add, tfms)
    dl_tfms.fs = L(dl_tfms.fs).sorted(key='order')
```

```python
@patch
def add_tfms(self:DataLoaders, tfms, event, ds_idxs=None):
    if ds_idxs is None: ds_idxs = range(len(self.loaders))
    if not is_listy(ds_idxs): ds_idxs = listify(ds_idxs)
    for idx in ds_idxs:
        apply(self._add_tfm, tfms, event, idx)
```

`ds_idxs` is more a preference thing, and I'd leave that up to @jph00: should we use just indexing? Similar to what we already do? Or include support for `dls.train` and `dls.valid` and just do both. It adds a few lines of code but could be nice.

Also we should likely check that `event` is valid. In a perfect world both `item_tfms` and `after_item` can work, but I think just checking that `event` is either `after_item` or `after_batch` would be enough.

Re: my adjustments here, we need that last little line in `_add_tfms` in order to make sure the order gets properly readjusted. The only thing this doesn't do is if I pass in 3 `Resize` functions for instance it will add in all three. Should we not allow that since item transforms are all composed? How should that behavior work. (Question for you Jeremy)",think rewrite simplify bit python patch self event event self event apply python patch self event none range apply event preference thing leave use indexing similar already include support code could nice also likely check event valid perfect world work think event either would enough need last little line order make sure order properly thing pas resize instance add three allow since item composed behavior work question,issue,positive,positive,positive,positive,positive,positive
801290900,"> @glitt13 It's because `log_args` was removed in fastcore 1.3.5, so if you are using `fastai==2.0.19`, you need to also force `fastcore==1.3.2`.

Yes, thank you. How do you do that?",removed need also force yes thank,issue,positive,neutral,neutral,neutral,neutral,neutral
800864578,"I think you can't use a single confusion matrix if one image has multiple labels. The confusion matrix is only valid if there is one label per image.  Let's say, you have an image with a *dog* and the model predicts *cat*, then it has confused the two. However, if you have an image with a *dog* and a *bird* but the model predicted *cat* and *horse* you can't really tell what it did confuse (*dog* with *cat* or *dog* with *bird*) and it is not possible to plot the matrix. 
However, you could break down the results into multiple matrices. Check out the [multilabel_confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.multilabel_confusion_matrix.html) from sklearn, maybe this is what you want?
",think ca use single confusion matrix one image multiple confusion matrix valid one label per image let say image dog model cat confused two however image dog bird model cat horse ca really tell confuse dog cat dog bird possible plot matrix however could break multiple matrix check maybe want,issue,negative,negative,neutral,neutral,negative,negative
800713569,"Getting this as well. Going to try to downgrade to a previous version.

Edit: this did not work.

wonder if this is related to #3090  ?",getting well going try downgrade previous version edit work wonder related,issue,negative,negative,neutral,neutral,negative,negative
800498708,@hamelsmu Could you maybe give your input on this? This is currently preventing me from updating to the latest PyTorch for the new Notebook images I built that will be included with Kubeflow 1.3. ,could maybe give input currently latest new notebook built included,issue,negative,positive,positive,positive,positive,positive
800496019,Also an issue when using colab (see [this post](https://forums.fast.ai/t/fastai-install-fail-on-colab-version-mismatch-in-pytorch/86655)).,also issue see post,issue,negative,neutral,neutral,neutral,neutral,neutral
799995649,"> Many thanks!
> 
> I see that some of the output cells are now missing - could you please re-run the full notebook so that the outputs are included? Otherwise the documentation will be missing the outputs.

Sorry for my late reply.. and sorry again as  didn't pay attention to cell outputs.
I've made a commit after running all cells in the notebook.",many thanks see output missing could please full notebook included otherwise documentation missing sorry late reply sorry pay attention cell made commit running notebook,issue,negative,negative,neutral,neutral,negative,negative
799578059,"It seems fixed to me, it definitely showed other results before. However I think this would only be 100% fixed if `get_transforms` would not appear anymore as an autocomplete suggestion as there are no exact matches for this anymore.",fixed definitely however think would fixed would appear suggestion exact,issue,negative,positive,positive,positive,positive,positive
799408566,"I totally agree, it would be very cool to be able to install `fastai` with `torch` 1.8.0 / `torchvision` 0.9.0 from PyPI, since the Windows wheels for `torchvision` only started to be pushed to PyPI again (starting with 0.9.0).

Any updates on this? :)",totally agree would cool able install torch since starting,issue,positive,positive,positive,positive,positive,positive
799030278,"Hello,

I would like to help but I cannot reproduce the error. 

- When typing ""get_transf"" into the search bar, it prints two results but none of them are exact matches and there is no redirection to non-existent pages.

- When I select the autocomplete version ""get_transforms"", there are six links. None of them are exact matches and again there is no redirection to non-existent pages.

Has the problem been fixed, since then? If yes, we can close this issue.",hello would like help reproduce error search bar two none exact redirection select version six link none exact redirection problem fixed since yes close issue,issue,positive,positive,positive,positive,positive,positive
798790974,"> same problem here.
> training and export of fastaiV2 model on windows. created App with Streamlit. on local Windows machine running smooth. Deployed on https://share.streamlit.io/ error ""NotImplementedError: cannot instantiate 'WindowsPath' on your system""
> Any help appreciated ! thx

I found a solution for this adding the below to the code:

```
import pathlib
plt = platform.system()
if plt == 'Linux': pathlib.WindowsPath = pathlib.PosixPath
```",problem training export model local machine running smooth error system help found solution code import,issue,negative,positive,positive,positive,positive,positive
798169497,"@jph00 now (hopefully) updated the PR branch.
This was my first time trying to update a PR branch and tried to rebase it into a single commit and cooked it...
So sorry about the force push and extra commit.
Feel free to squash the commits before merging.
Besides updating, I am also now hiding a new test cell and ""fixed"" a weird indentation in a different cell. (only 2 space width)",hopefully branch first time trying update branch tried rebase single commit sorry force push extra commit feel free squash besides also new test cell fixed weird indentation different cell space width,issue,positive,negative,neutral,neutral,negative,negative
797902100,"same problem here.
training and export of fastaiV2 model on windows. created App with Streamlit. on local Windows machine running smooth. Deployed on https://share.streamlit.io/ error ""NotImplementedError: cannot instantiate 'WindowsPath' on your system""
Any help appreciated ! thx",problem training export model local machine running smooth error system help,issue,negative,positive,positive,positive,positive,positive
797859158,"Sadly the problem still persists :'( in fastai 2.2.7 & fastcore 1.3.19
![image](https://user-images.githubusercontent.com/13318820/111017714-24002d80-83db-11eb-876f-630a571b56a8.png)
",sadly problem still image,issue,negative,negative,negative,negative,negative,negative
797807585,Just re-opened and ran the notebook.  The warning still exist.,ran notebook warning still exist,issue,negative,neutral,neutral,neutral,neutral,neutral
797800481,Many thanks - this looks good. Could you please resolve the conflicts and at-mention me when it's ready to merge?,many thanks good could please resolve ready merge,issue,positive,positive,positive,positive,positive,positive
797791712,Many thanks. I suspect this cast is no longer required due to the auto-casting we added to TensorBase.,many thanks suspect cast longer due added,issue,negative,positive,positive,positive,positive,positive
797030629,"I'm having similar issue when trying to load_learner on colab a learner that was exported from a Windows machine. The problem seems to be that the learner.path is serialized as pathlib.WindowsPath and when we try to deserialize the system cannot instantiate. Is there a way I can change the learner.path to a string and then export? I tried to force this, but it fails to export. Any ideas?",similar issue trying learner machine problem try system way change string export tried force export,issue,negative,neutral,neutral,neutral,neutral,neutral
796840883,"This PR fixes some errors while using a custom tokenizer with the `TextDataloaders` class via 
the parameter `tok_tfm`. See this[ short post ](https://forums.fast.ai/t/changing-the-tokenizer-default-language-in-text-data/86316) for details.",custom class via parameter see short post,issue,negative,neutral,neutral,neutral,neutral,neutral
795521941,"@jph00 , Could you please take a look when you're free.",could please take look free,issue,positive,positive,positive,positive,positive,positive
794470677,"I faced the same problem, working on implementing the solution that you gave!",faced problem working solution gave,issue,negative,neutral,neutral,neutral,neutral,neutral
792994416,"@muellerzr It seems like there is a difference between the `settings.ini` and the `environment.yml` files in regards to PyTorch 1.8 and TorchVision 0.9. 

https://github.com/fastai/fastai/blob/00d88637cd7f804da55473b7c3c31aba4fecba1c/settings.ini#L16
https://github.com/fastai/fastai/blob/00d88637cd7f804da55473b7c3c31aba4fecba1c/settings.ini#L17

https://github.com/fastai/fastai/blob/00d88637cd7f804da55473b7c3c31aba4fecba1c/environment.yml#L8
https://github.com/fastai/fastai/blob/00d88637cd7f804da55473b7c3c31aba4fecba1c/environment.yml#L18

Should I create a PR to extend the pinning in the `settings.ini` file?

I'm wanting to add FastAI to some of the new docker images provided with Kubeflow in the upcoming release, but as we are wanting to only include the latest version of frameworks it would be nice if FastAI could be installed with PyTorch 1.8 (through pip). ",like difference create extend pinning file wanting add new docker provided upcoming release wanting include latest version would nice could pip,issue,positive,positive,positive,positive,positive,positive
792713552,"@jph00 , one more interesting thing. 

https://github.com/fastai/fastai/blob/00d88637cd7f804da55473b7c3c31aba4fecba1c/fastai/data/core.py#L218-L221

if we change the fastai\data\core.py as below, and run the sample script.
```
# no exception
dl = dl_type(self.subset(0), **merge(kwargs,def_kwargs, dl_kwargs[0]))
dls = [dl]
return self._dbunch_type(*dls, path=path, device=device)
```


```
# has exception of Cannot pickle CUDA storage
dl = dl_type(self.subset(0), **merge(kwargs,def_kwargs, dl_kwargs[0]))
dl2 = dl.new(self.subset(0), **merge(kwargs,def_kwargs, dl_kwargs[0]))
dls = [dl2]
return self._dbunch_type(*dls, path=path, device=device)
```

",one interesting thing change run sample script exception merge return exception pickle storage merge merge return,issue,negative,positive,positive,positive,positive,positive
792451226,"@jph00 
I find a good post about cuda and multiple workers in Dataloader.
https://discuss.pytorch.org/t/cuda-initialization-error-when-dataloader-with-cuda-tensor/43390/2",find good post multiple,issue,negative,positive,positive,positive,positive,positive
792435729,"NO，`Flip` isn't the only transform that's causing this problem. 
Any transform causes this problem.
![image](https://user-images.githubusercontent.com/16190118/110270358-98645680-8000-11eb-9eee-b7b6abb08666.png)

The sample code is below, the issue can be reproduced both on Windows and Linux if the process start method is spawn
```
from fastai.torch_basics import *
from fastai.data.load import *
from fastai.vision.all import *
from fastai.data.all import *
        
def proc_info(dls):
    import os
    print(os.getpid())
    print(""dls -------"")
    print(dls)
    print(""/dls ------"")

if __name__ == ""__main__"":
    multiprocessing.set_start_method('spawn')
    print(""start main ..."")

    path = untar_data(URLs.IMAGENETTE_160)
    dls = ImageDataLoaders.from_folder(path, valid='val', 
        item_tfms=RandomResizedCrop(128, min_scale=0.35), batch_tfms=aug_transforms(min_scale=0.5, size=128))

    proc_info(dls)

    p = Process(target=proc_info, args=(dls,))
    p.start()
    p.join()
```

",flip transform causing problem transform problem image sample code issue process start method spawn import import import import import o print print print print print start main path path process,issue,negative,positive,positive,positive,positive,positive
792069050,@muellerzr Cool. Should I create a PR to change the dependency listing to include PyTorch 1.8? ,cool create change dependency listing include,issue,positive,positive,positive,positive,positive,positive
792043508,"@DavidSpek someone already tested this the day of release and confirmed it worked without error, so this can be closed. 

(For TorchAudio I'd recommend looking at the fastaudio library and ask them, as fastai doesn't have any native audio support, but they do)",someone already tested day release confirmed worked without error closed recommend looking library ask native audio support,issue,negative,positive,positive,positive,positive,positive
792037897,"I was using the 1.8 nightly with fastai very briefly as I needed to for RTX3090 support. I didn't notice anything that broke, but my use was very limited. ",nightly briefly support notice anything broke use limited,issue,negative,negative,neutral,neutral,negative,negative
792037166,"Do you know specifically if anything breaks when using torchvision and torch that we need to fix? It would be very helpful if you could find any areas which are breaking, as if there are none then nothing is needed :) ",know specifically anything torch need fix would helpful could find breaking none nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
791920885,"Tried to fix problem when github is waiting for testing stages that no longer exist. 

The problem was still present though https://github.com/fastai/fastai/pull/3242",tried fix problem waiting testing longer exist problem still present though,issue,negative,neutral,neutral,neutral,neutral,neutral
791920232,"On further investigation, I can see that the cell in question was added ([commit](https://github.com/fastai/fastai/commit/89770a495b500f585210845e195c5c9a7996f2f4)) by @jph00 couple months ago.

I don't understand why it did not fail for other PRs",investigation see cell question added commit couple ago understand fail,issue,negative,negative,negative,negative,negative,negative
791917873,"Hmmm, not sure what the problem is.

The tests fail for nbs/04_data.external.ipynb saying that file is not found, full traceback below.

The CALTECH url is reachable at the moment. https://s3.amazonaws.com/fast-ai-imageclas/caltech_101.tgz

Reading from the notebook, I get a feeling that maybe this cell should not be present anyway?
![image](https://user-images.githubusercontent.com/29500178/110204999-2d434480-7e87-11eb-9a3d-27ff8290fe1a.png)


```
Error in /__w/fastai/fastai/nbs/04_data.external.ipynb:
An error occurred while executing the following cell:
------------------
url = URLs.CALTECH_101
untar_data(url)
_add_check(url, URLs.path(url))
------------------

rror in /__w/fastai/fastai/nbs/04_data.external.ipynb:
An error occurred while executing the following cell:
------------------
url = URLs.CALTECH_101
untar_data(url)
_add_check(url, URLs.path(url))
------------------

---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
/__w/fastai/fastai/fastai/data/external.py in <module>
      1 url = URLs.CALTECH_101
      2 untar_data(url)
----> 3 _add_check(url, URLs.path(url))

/__w/fastai/fastai/fastai/data/external.py in _add_check(url, fname)
      3     ""Internal function to update the internal check file with `url` and check on `fname`.""
      4     checks = json.load(open(Path(__file__).parent/'checks.txt', 'r'))
----> 5     checks[url] = _check_file(fname)
      6     json.dump(checks, open(Path(__file__).parent/'checks.txt', 'w'), indent=2)

/__w/fastai/fastai/fastai/data/external.py in _check_file(fname)
      7 def _check_file(fname):
      8     ""internal function to get the hash of the local file at `fname`.""
----> 9     size = os.path.getsize(fname)
     10     with open(fname, ""rb"") as f: hash_nb = hashlib.md5(f.read(2**20)).hexdigest()
     11     return [size,hash_nb]

/usr/lib/python3.8/genericpath.py in getsize(filename)
     48 def getsize(filename):
     49     """"""Return the size of a file, reported by os.stat().""""""
---> 50     return os.stat(filename).st_size
     51 
     52 

FileNotFoundError: [Errno 2] No such file or directory: '/github/home/.fastai/archive/caltech_101.tgz'
```

",sure problem fail saying file found full reachable moment reading notebook get feeling maybe cell present anyway image error error following cell error following cell recent call last module internal function update internal check file check open path open path internal function get hash local file size open return size return size file return file directory,issue,negative,positive,neutral,neutral,positive,positive
791889181,@jph00 fixed! surprised this wasn't an issue before but one of the cells was not marked slow...,fixed issue one marked slow,issue,negative,negative,neutral,neutral,negative,negative
791878871,@tmabraham any chance you could look to see why one notebook is timing out in tests in CI?,chance could look see one notebook timing,issue,negative,neutral,neutral,neutral,neutral,neutral
791871015,"@mszhanyi many thanks for the debugging - sorry for the slow response, we've been moving to Australia so a bit overwhelmed by that!

Is `Flip` the only transform that's causing this problem? Have you tried including everything except `Flip` to see if it works?

Regarding ""we should copy data from cpu to gpu in each workers"": how are you thinking we might implement that? Any sample code you could show?",many thanks sorry slow response moving bit flip transform causing problem tried everything except flip see work regarding copy data thinking might implement sample code could show,issue,negative,negative,neutral,neutral,negative,negative
791870955,"@jph00 I made changes based on your suggestions, and also added the doc changes from #3226 ",made based also added doc,issue,negative,neutral,neutral,neutral,neutral,neutral
791742052,I'm having the same issue with a similar code. Any ideas on how to fix it?,issue similar code fix,issue,negative,neutral,neutral,neutral,neutral,neutral
791405086,"this could be cool btw, I may work on implementing this.",could cool may work,issue,negative,positive,positive,positive,positive,positive
791385420,"Hi Thomas you can close for now .
If I get more issue I will open a new one

On Fri, 5 Mar 2021, 16:32 Thomas Capelle, <notifications@github.com> wrote:

> did you solve this issue? Could you get a clearer picture of what is
> happening?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3236#issuecomment-791347723>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJDFNZAO3JV4AR6IXSAUONTTCC257ANCNFSM4YEUVWYQ>
> .
>
",hi close get issue open new one mar wrote solve issue could get clearer picture happening thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
791347723,did you solve this issue? Could you get a clearer picture of what is happening?,solve issue could get clearer picture happening,issue,negative,neutral,neutral,neutral,neutral,neutral
791242856,"I just realized that by switching the arguments of `OptimWrapper`, I can make it even easier to use:
`opt_func = partial(OptimWrapper, opt=torch.optim.SGD)`

I have added this change as a commit, but @jph00 please let me know if you are fine with this. If you think it's too much change to the `OptimWrapper` usage, I will revert back to the previously agreed upon changes... 
",switching make even easier use partial added change commit please let know fine think much change usage revert back previously agreed upon,issue,positive,positive,neutral,neutral,positive,positive
790628452,As of March 2021 installation on Win10 is solved by adding `-c conda-forge` to original command. [Solution from forum](https://forums.fast.ai/t/install-fail-with-anaconda-because-of-gh/84710/2?u=kasianenko),march installation win original command solution forum,issue,positive,positive,positive,positive,positive,positive
790514650,"```
/opt/conda/lib/python3.7/site-packages/fastai/learner.py:54: UserWarning: Saved filed doesn't contain an optimizer state.
  elif with_opt: warn(""Saved filed doesn't contain an optimizer state."")
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    153     def _with_events(self, f, event_type, ex, final=noop):
--> 154         try:       self(f'before_{event_type}')       ;f()
    155         except ex: self(f'after_cancel_{event_type}')
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in __call__(self, event_name)
    131 
--> 132     def __call__(self, event_name): L(event_name).map(self._call_one)
    133 
/opt/conda/lib/python3.7/site-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    178 
--> 179     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    180     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))
/opt/conda/lib/python3.7/site-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs)
    606     if gen: return res
--> 607     return list(res)
    608 
/opt/conda/lib/python3.7/site-packages/fastcore/basics.py in __call__(self, *args, **kwargs)
    596         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 597         return self.func(*fargs, **kwargs)
    598 
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in _call_one(self, event_name)
    135         assert hasattr(event, event_name), event_name
--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]
    137 
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in <listcomp>(.0)
    135         assert hasattr(event, event_name), event_name
--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]
    137 
/opt/conda/lib/python3.7/site-packages/fastai/callback/core.py in __call__(self, event_name)
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit
/opt/conda/lib/python3.7/site-packages/fastai/callback/fp16.py in before_fit(self)
     84     def before_fit(self):
---> 85         assert self.dls.device.type == 'cuda', ""Mixed-precision training requires a GPU, remove the call `to_fp16`""
     86         if self.learn.opt is None: self.learn.create_opt()
AssertionError: Mixed-precision training requires a GPU, remove the call `to_fp16`
During handling of the above exception, another exception occurred:
FileNotFoundError                         Traceback (most recent call last)
<ipython-input-60-ff4d58f0ddc0> in <module>
      8                                  #MixUp1(),
      9                                  ReduceLROnPlateau(monitor='accuracy_multi',factor=5,patience=2)
---> 10                                 ,SaveModelCallback(monitor='accuracy_multi',fname=f'best_model_dense_ext_{fold}')  ] )
/opt/conda/lib/python3.7/site-packages/fastai/callback/schedule.py in fit_sgdr(self, n_cycles, cycle_len, lr_max, cycle_mult, cbs, reset_opt, wd)
    146     scheds = [SchedCos(lr_max, 0) for _ in range(n_cycles)]
    147     scheds = {'lr': combine_scheds(pcts, scheds)}
--> 148     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)
    149 
    150 # Cell
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
    203             self.opt.set_hypers(lr=self.lr if lr is None else lr)
    204             self.n_epoch = n_epoch
--> 205             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
    206 
    207     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    154         try:       self(f'before_{event_type}')       ;f()
    155         except ex: self(f'after_cancel_{event_type}')
--> 156         finally:   self(f'after_{event_type}')        ;final()
    157 
    158     def all_batches(self):
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in __call__(self, event_name)
    130     def ordered_cbs(self, event): return [cb for cb in sort_by_run(self.cbs) if hasattr(cb, event)]
    131 
--> 132     def __call__(self, event_name): L(event_name).map(self._call_one)
    133 
    134     def _call_one(self, event_name):
/opt/conda/lib/python3.7/site-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    177     def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step))
    178 
--> 179     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    180     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))
    181     def filter(self, f=noop, negate=False, gen=False, **kwargs):
/opt/conda/lib/python3.7/site-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs)
    605     res = map(g, iterable)
    606     if gen: return res
--> 607     return list(res)
    608 
    609 # Cell
/opt/conda/lib/python3.7/site-packages/fastcore/basics.py in __call__(self, *args, **kwargs)
    595             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)
    596         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 597         return self.func(*fargs, **kwargs)
    598 
    599 # Cell
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in _call_one(self, event_name)
    134     def _call_one(self, event_name):
    135         assert hasattr(event, event_name), event_name
--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]
    137 
    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in <listcomp>(.0)
    134     def _call_one(self, event_name):
    135         assert hasattr(event, event_name), event_name
--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]
    137 
    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)
/opt/conda/lib/python3.7/site-packages/fastai/callback/core.py in __call__(self, event_name)
     42                (self.run_valid and not getattr(self, 'training', False)))
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit
     46         return res
/opt/conda/lib/python3.7/site-packages/fastai/callback/tracker.py in after_fit(self, **kwargs)
     85     def after_fit(self, **kwargs):
     86         ""Load the best model.""
---> 87         if not self.every_epoch: self.learn.load(f'{self.fname}', with_opt=self.with_opt)
     88 
     89 # Cell
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in load(self, file, with_opt, device, **kwargs)
    291         if self.opt is None: self.create_opt()
    292         file = join_path_file(file, self.path/self.model_dir, ext='.pth')
--> 293         load_model(file, self.model, self.opt, with_opt=with_opt, device=device, **kwargs)
    294         return self
    295 
/opt/conda/lib/python3.7/site-packages/fastai/learner.py in load_model(file, model, opt, with_opt, device, strict)
     44     if isinstance(device, int): device = torch.device('cuda', device)
     45     elif device is None: device = 'cpu'
---> 46     state = torch.load(file, map_location=device)
     47     hasopt = set(state)=={'model', 'opt'}
     48     model_state = state['model'] if hasopt else state
/opt/conda/lib/python3.7/site-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)
    579         pickle_load_args['encoding'] = 'utf-8'
    580 
--> 581     with _open_file_like(f, 'rb') as opened_file:
    582         if _is_zipfile(opened_file):
    583             # The zipfile reader is going to advance the current file position.
/opt/conda/lib/python3.7/site-packages/torch/serialization.py in _open_file_like(name_or_buffer, mode)
    228 def _open_file_like(name_or_buffer, mode):
    229     if _is_path(name_or_buffer):
--> 230         return _open_file(name_or_buffer, mode)
    231     else:
    232         if 'w' in mode:
/opt/conda/lib/python3.7/site-packages/torch/serialization.py in __init__(self, name, mode)
    209 class _open_file(_opener):
    210     def __init__(self, name, mode):
--> 211         super(_open_file, self).__init__(open(name, mode))
    212 
    213     def __exit__(self, *args):
FileNotFoundError: [Errno 2] No such file or directory: 'models/best_model_dense_ext_3.pth'
```",saved contain state warn saved contain state recent call last self ex final self ex try self except ex self self self map self gen map self return self self return self negate iterable gen gen return return list self else return self assert event assert event self none self noop reset true end fit self self assert training remove call none training remove call handling exception another exception recent call last module fold self range cell fit self none else self none none none none none self ex final try self except ex self finally self final self self self event return event self self map self gen range return map self return self self return self negate filter self iterable gen map iterable gen return return list cell self else return cell self self assert event self return self assert event self return self self false none self noop reset true end fit return self self load best model cell load self file device none file file file return self file model opt device strict device device device device none device state file set state state else state load reader going advance current file position mode mode return mode else mode self name mode class self name mode super self open name mode self file directory,issue,positive,positive,positive,positive,positive,positive
789783328,"Should be fixed with #3184

You can install the latest version of fastai with:

```sh
git clone https://github.com/fastai/fastai
pip install -e ""fastai[dev]""
```
",fixed install latest version sh git clone pip install dev,issue,negative,positive,positive,positive,positive,positive
789670638,"For spawn, I think we should copy data from cpu to gpu in each workers.",spawn think copy data,issue,negative,neutral,neutral,neutral,neutral,neutral
789666881,"For fastai, it could be reproduced with the below snippet.

```
from fastai.data.load import *
from fastai.vision.all import *
from fastai.data.all import *

def proc_info(dls):
    import os
    print(os.getpid())
    print(""dls -------"")
    print(dls)
    print(""/dls ------"")

if __name__ == ""__main__"":
    multiprocessing.set_start_method('spawn')
    print(""start main ..."")

    path = untar_data(URLs.IMAGENETTE_160)
    tkw = {'size': None, 'mode': 'bilinear', 'pad_mode': 'reflection', 'batch': False, 'align_corners': True}
    flip_1 = Flip(p=0.5, **tkw)

    dls = ImageDataLoaders.from_folder(path, valid='val', 
        item_tfms=RandomResizedCrop(128, min_scale=0.35), batch_tfms=flip_1)

    proc_info(dls)

    p = Process(target=proc_info, args=(dls,))
    p.start()
    p.join()
```

x is always a cuda variable in a GPU machine.
https://github.com/fastai/fastai/blob/87827a10c946ea024fb09ecaf00073395e4d950d/fastai/vision/augment.py#L464
And it should be caused by 
https://github.com/fastai/fastai/blob/45376f13df04ddf72749be25ae8a6dff35859f68/fastai/data/core.py#L212

the call stack for training should be like the below image
![image](https://user-images.githubusercontent.com/16190118/109803150-a9f1db00-7c5b-11eb-85cf-045b04fe5180.png)
@jph00 

",could snippet import import import import o print print print print print start main path none false true flip path process always variable machine call stack training like image image,issue,negative,positive,neutral,neutral,positive,positive
789657409,"The root cause should be that pickle doesn't support serialize cuda variable.
Let's start with a very simple script, the exception could be reproduced easily on **Windows and Linux**.

```
import torch
from multiprocessing import Process

my_tensor = torch.tensor([1.0]).cuda()
def proc_info(my_obj):
    import os
    print(os.getpid())
    print(obj.__dict__)

if __name__ == ""__main__"":
   multiprocessing.set_start_method('spawn')
   p = Process(target=proc_info, args=(my_tensor,))
   p.start()
   p.join()
```
",root cause pickle support serialize variable let start simple script exception could easily import torch import process import o print print process,issue,positive,positive,positive,positive,positive,positive
787897478,"Sorry, It has nothing with dereference.  Append() returns None.
It has something with the function aug_transforms.
same exception occurs with `batch_tfms=aug_transforms(min_scale=0.5, size=128)`
As long as the batch_tfms is the class of Transform, there's the exception.

It can be reproduced in Linux by setting start_method as spawn.",sorry nothing append none something function exception long class transform exception setting spawn,issue,negative,negative,negative,negative,negative,negative
787132601,"I believe this is the intended behavior as the library is currently written. Looking at the default proc_rules applied to the strings prior to being passed to the tokenizer, it appears that the fastai.text.core.lowercase function has a default value of add_eos=False.

We can override this behavior by using a Python Partial Function and passing those into the TextBlock rules parameter. 


```
custom_proc_rules = defaults.text_proc_rules.copy()
custom_proc_rules[-1] = partial(lowercase,add_bos=True,add_eos=True)

texts_s2s = DataBlock(
    
    # blocks specify what type of data we are going to be loading.
    # In this case both are text files contained in the same df
    #blocks=(TextBlock.from_df('from_txt',is_lm=False),TextBlock.from_df('to_txt',is_lm=False)),
    
    # You can specify a tokenizer by passing in a tok variable. Comment the line above and ucomment the onces below.
    blocks=(
        TextBlock.from_df('from_txt', is_lm=False, tok=SubwordTokenizer(vocab_sz=200),rules=custom_proc_rules),
        TextBlock.from_df('to_txt'  , is_lm=False, tok=SubwordTokenizer(vocab_sz=200),rules=custom_proc_rules)),
    

    # The TestBlock tokenization process puts tokenized inputs into a column called text. 
    # The ColReader for get_x will always reference text, even if the original text inputs 
    # were in a column with another name in the dataframe.
    get_x=ColReader('text'),
    get_y=ColReader('text'),
    
    # The dataframe needs to have a is_valid column for this to work.
    splitter=ColSplitter()

)

Here is a Jupyter notebook containing the end-to-end example https://github.com/goralpl/learning_fastai/blob/master/seq2seq_fastai_datablocks.ipynb


```",believe intended behavior library currently written looking default applied prior function default value override behavior python partial function passing parameter partial specify type data going loading case text specify passing variable comment line process column text always reference text even original text column another name need column work notebook example,issue,positive,positive,neutral,neutral,positive,positive
786648238,"fastai does, not me.
https://docs.fast.ai/tutorial.albumentations.html

On Fri, Feb 26, 2021 at 3:14 AM Thomas Capelle <notifications@github.com>
wrote:

> tyr putting your transform on this block with MNIST. I think @muellerzr
> <https://github.com/muellerzr> has a tutorial on interating
> albumentations on fastai on his walkwithfastai repo.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3236#issuecomment-786515441>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV7NXGFXSFY7NEMCSXDTA5Q67ANCNFSM4YEUVWYQ>
> .
>
",wrote transform block think tutorial reply directly view,issue,negative,positive,neutral,neutral,positive,positive
786515441,tyr putting your transform on this block with MNIST.  I think @muellerzr  has a tutorial on integrating albumentations with fastai on his walkwithfastai repo.,transform block think tutorial,issue,negative,neutral,neutral,neutral,neutral,neutral
786507283,"Which block summary do you look for

On Fri, 26 Feb 2021, 14:19 Thomas Capelle, <notifications@github.com> wrote:

> Please at least print a block summary.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3236#issuecomment-786502693>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJDFNZDGG64DYHIOBSARVN3TA5OCZANCNFSM4YEUVWYQ>
> .
>
",block summary look wrote please least print block summary thread reply directly view,issue,negative,negative,neutral,neutral,negative,negative
786502693,Please at least print a block summary.,please least print block summary,issue,negative,negative,negative,negative,negative,negative
786394476,"Problem happens if image sizes are different ... to make them uniform i
would use crop and resize func in item tfms

On Fri, 26 Feb 2021, 00:25 Thomas Capelle, <notifications@github.com> wrote:

> would you mind refactoring your code, with a fastai dataset an reproduce
> the error, so I can test from my side?
> something like this:
> [image: image]
> <https://user-images.githubusercontent.com/18441985/109202532-60107d00-77a3-11eb-8a8e-27db46d194e4.png>
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3236#issuecomment-786126002>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AJDFNZCOJHU5JZIGXY2ZC2LTA2MKFANCNFSM4YEUVWYQ>
> .
>
",problem image size different make uniform would use crop resize item wrote would mind code reproduce error test side something like image image thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
786126002,"would you mind refactoring your code, with a fastai dataset an reproduce the error, so I can test from my side?
something like this:
![image](https://user-images.githubusercontent.com/18441985/109202532-60107d00-77a3-11eb-8a8e-27db46d194e4.png)
it is a good exercise anyway.",would mind code reproduce error test side something like image good exercise anyway,issue,negative,positive,positive,positive,positive,positive
786075722,please post a minimal reproductible example.,please post minimal example,issue,negative,negative,neutral,neutral,negative,negative
785603839,Huh that's odd - I have no idea why that is! Great find,huh odd idea great find,issue,negative,positive,positive,positive,positive,positive
785603266,"I got it.
it works by changing
`batch_tfms=[*aug_transforms(min_scale=0.5, size=128), Normalize.from_stats(*imagenet_stats)]`
to 
`batch_tfms=aug_transforms(min_scale=0.5, size=128).append(Normalize.from_stats(*imagenet_stats))`

`*` dereference looks incompatible with pickle serialization",got work incompatible pickle serialization,issue,negative,neutral,neutral,neutral,neutral,neutral
785312653,"One script to reproduce similar issue.
It should be related to DataBlocks and process start method.
@jph00 
```
from fastai.vision.all import *
from fastai.data.all import *

 
if __name__ == ""__main__"":
    # uncomment it to reproduce in Linux
    #torch.multiprocessing.set_start_method('spawn') 
    
   path = untar_data(URLs.IMAGENETTE_160)
    # the imagedataloders works
    #dls = ImageDataLoaders.from_folder(path, valid='val', 
    #    item_tfms=RandomResizedCrop(128, min_scale=0.35), batch_tfms=Normalize.from_stats(*imagenet_stats))
    
    # throws exception `Cannot pickle CUDA Storage`
    dls = DataBlock(
        blocks=(ImageBlock, CategoryBlock), get_items=get_image_files, 
        splitter=GrandparentSplitter(valid_name='val'),
        get_y=parent_label, item_tfms=Resize(160),
        batch_tfms=[*aug_transforms(min_scale=0.5, size=128),
                    Normalize.from_stats(*imagenet_stats)],
    ).dataloaders(path, bs=128)

    print(L(dls.train))
```",one script reproduce similar issue related process start method import import reproduce path work path exception pickle storage path print,issue,negative,neutral,neutral,neutral,neutral,neutral
784614172,Thanks for noting this - turns out the conda release had an error. Fixed now.,thanks turn release error fixed,issue,negative,positive,positive,positive,positive,positive
784044605,"@jph00 @aberres Ah, I hadn't seen that - thanks for the fix.  Yes, this resolves the problem.  (The only small thing, probably of negligible significance, is that if times are given with millisecond accuracy, this will be lost by the integer division.  Changing `// 10 ** 9` into `/ 1e9` would address this, too.)",ah seen thanks fix yes problem small thing probably negligible significance time given millisecond accuracy lost integer division would address,issue,negative,negative,neutral,neutral,negative,negative
783965980,"We have two possible resolutions, but it's your choice which to apply to the code base: either the suggestion to add the extra line
```python
    df[prefix + 'Elapsed'] = df[prefix + 'Elapsed'].astype('Int64')
```
after the assignment (which requires a relatively recent Pandas, I think >= 0.25), which keeps it an integer type, or replace the assignment with
```python
    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) / 1e9,np.nan)
```
which makes the Elapsed column a float64 instead.",two possible choice apply code base either suggestion add extra line python prefix prefix assignment relatively recent think integer type replace assignment python prefix mask column float instead,issue,negative,negative,negative,negative,negative,negative
783804563,"@jph00 Hey sorry, I couldn't figure out why the third check was failing. It should be ready now? I couldn't find anything wrong with nb 18.",hey sorry could figure third check failing ready could find anything wrong,issue,negative,negative,negative,negative,negative,negative
783708188,"Please let me know when it's ready to review, and at-mention me. (It's marked as a draft at the moment)",please let know ready review marked draft moment,issue,positive,positive,positive,positive,positive,positive
783683990,"Ok I was wrong looks like I do, in fact, need to clean the notebooks. ",wrong like fact need clean,issue,negative,negative,neutral,neutral,negative,negative
783199665,"Ah, if we're changing to a float dtype, then the solution is even simpler: just change the 'Elapsed' definition line to read:
```python
    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) / 1e9,np.nan)
```
The `np.nan` is a `float` type, so this ends up with the whole column having dtype `float64`.  (And we can replace `// 10 ** 9` with `/ 1e9` because it's going to be converted into a float anyway.)",ah float solution even simpler change definition line read python prefix mask float type whole column float replace going converted float anyway,issue,negative,positive,positive,positive,positive,positive
782914127,"I stumbled upon the same problem.

The other solution might be to switch to a float dtype - as this is a continuous variable this is the correct thing to do IMO. I proposed this MR: https://github.com/fastai/fastai/pull/3230

@jph00 needs to decide, I guess.",upon problem solution might switch float continuous variable correct thing need decide guess,issue,negative,neutral,neutral,neutral,neutral,neutral
782882854,"Ah, no, it turns out there are errors in both `09_tabular.ipynb` and in `fastai`.  So reopening this with the diagnosis and a patch for the `fastai` library part.

In https://github.com/fastai/fastai/blob/master/nbs/40_tabular.core.ipynb, we have the definition of `add_datepart`:
```python
#export
def add_datepart(df, field_name, prefix=None, drop=True, time=False):
    ""Helper function that adds columns relevant to a date in the column `field_name` of `df`.""
    make_date(df, field_name)
    field = df[field_name]
    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))
    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',
            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']
    if time: attr = attr + ['Hour', 'Minute', 'Second']
    # Pandas removed `dt.week` in v1.1.10
    week = field.dt.isocalendar().week.astype(field.dt.day.dtype) if hasattr(field.dt, 'isocalendar') else field.dt.week
    for n in attr: df[prefix + n] = getattr(field.dt, n.lower()) if n != 'Week' else week
    mask = ~field.isna()
    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,None)
    if drop: df.drop(field_name, axis=1, inplace=True)
    return df
```

Now, the intention of the `df[prefix + 'Elapsed']` is to add an `int64` column with the elapsed time (time since long ago or whatever).  Unfortunately, though, the `np.where` function returns an `ndarray` whose `dtype` is the smallest that can accommodate both arguments, in this case an array of type `int64` and `None`, and that is `O` (""object"").  So the resulting Elapsed column has type ""object"", which is not particularly useful.

Easy fix: add an extra line after this assignment:
```python
    df[prefix + 'Elapsed'] = df[prefix + 'Elapsed'].astype('Int64')
```

(This cannot be combined into a single line, as `np.where` returns a NumPy `ndarray`, but `Int64` is a Pandas type, so can only be applied to a Pandas Series or DataFrame.  Therefore the assignment into `df` needs to happen before the change of dtype.)",ah turn diagnosis patch library part definition python export helper function relevant date column field prefix prefix ate time removed week else prefix else week mask prefix mask none drop return intention prefix add column time time since long ago whatever unfortunately though function whose accommodate case array type none object resulting column type object particularly useful easy fix add extra line assignment python prefix prefix combined single line type applied series therefore assignment need happen change,issue,positive,positive,neutral,neutral,positive,positive
782829295,"@jph00 Thanks Jeremy, that does fix the `cont_cat_split` issues.  I guess this report can now be closed, then, taking care that the next release is version 2.2.7 or later.",thanks fix guess report closed taking care next release version later,issue,positive,positive,neutral,neutral,positive,positive
782797003,@jph00 I updated to the latest and the `fastai.__version__` still says 2.2.5 but confirmed that it does have the fix for `con_cat_split` so I think it is the latest and fixes the issue I was seeing. Thanks for your help; and for the lessons!,latest still confirmed fix think latest issue seeing thanks help,issue,positive,positive,positive,positive,positive,positive
782793643,"Many thanks for the reports - I've just released 2.2.6, which hopefully actually contains the fixes from 2.2.5. Please take a look and let me know if this resolves the issues.",many thanks hopefully actually please take look let know,issue,positive,positive,positive,positive,positive,positive
782772598,"yes, i've been pulling my hair out for hours now trying to figure out why fastbook 09_tabular.ipynb was giving me wrong results, only to update fastai and then find it no longer ran. specifically `cont_cat_split` was turning YearMade and other columns into category fields causing my results to differ greatly from the results in the lessons. 

once I nailed it down to an issue with `cont_cat_split` I updated my fastai dependency to the latest (2.2.5) only to find that `cont_cat_split` no longer worked at all. I found https://github.com/fastai/fastai/pull/3157 and confirmed that I had a version that had supposedly had that fix, but after no luck getting the code to run and digging through the module dependencies on disk i realized it doesn't really have that fix. i've patched my local version and now things are working again, but right now 09_tabular.ipynb is broken for anyone running the latest published version of fastai.

i tried to include as many keywords as i could in here so hopefully anyone running into the same issue can find this with a google search; i wasn't finding anything myself.",yes hair trying figure giving wrong update find longer ran specifically turning category causing differ greatly issue dependency latest find longer worked found confirmed version supposedly fix luck getting code run digging module disk really fix local version working right broken anyone running latest version tried include many could hopefully anyone running issue find search finding anything,issue,positive,positive,positive,positive,positive,positive
781837630,"It will be nice to know the pytorch commit that caused this, I guess pytorch is 1.7.0 but has been since some time?. So I guess the different behaviour was introduced from 1.6 to current 1.7 isn't? or we can't be sure about that?


As a side note from what I know from the TPU thing, there are some tiny diffs very internal to optimizers from fastai and pytorch so perhaps could be a good time to test in deep compatibility between the two?",nice know commit guess since time guess different behaviour current ca sure side note know thing tiny internal perhaps could good time test deep compatibility two,issue,positive,positive,positive,positive,positive,positive
781409725,"Yeps, I can confirm this. 

Just wondered why the Pandas dtype fix for `cont_cat_split` was not around.

Seems as if Jeremy is doing the releases himself, hence a friendly ping @jph00
",confirm fix around hence friendly ping,issue,negative,positive,positive,positive,positive,positive
780935289,"@jph00 - I think you may have introduced this regression in this commit:
https://github.com/fastai/fastai/commit/8ba759d1563e3858fd7b4b9fc77a96167decaf8e
Could you take a look?",think may regression commit could take look,issue,negative,neutral,neutral,neutral,neutral,neutral
780489008,"Would it make sense to print the full Input shape on the first line?

```
DynamicUnet (Input shape: 8)                                                                                               
============================================================================
Layer (type)         Output Shape         Param #    Trainable 
============================================================================
                     8 x 64 x 48 x 64 
```

Within the table; the first Output Shape that is printed is the first ""changed"" shape; so having `DynamicUnet (Input shape: 8) ` list the full shape would be useful to see the original image size if that info isn't available in some other part of the summary I have not understood yet.",would make sense print full input shape first line input shape layer type output shape param trainable within table first output shape printed first shape input shape list full shape would useful see original image size available part summary understood yet,issue,positive,positive,positive,positive,positive,positive
780270032,"There are two problems when it comes to the compose approach. This is what I am trying:

```
opt_func = compose(partial(torch.optim.Adam, eps=1e-6), OptimWrapper)
```

(I had also tried something similar earlier with AdaBelief)

If I try passing this `opt_func` into `Learner` like this:
```
learn_ = Learner(dls, resnet34(), opt_func=opt_func, metrics=error_rate)
learn_.fit(1)
```
I get this error:
```
TypeError: __init__() got an unexpected keyword argument 'lr'
```
I believe this is a limitation of fastcore's `compose` function. `compose` passes the same `kwargs` into all of the composed functions, but `OptimWrapper` doesn't expect `lr` and other related arguments, hence the error.

If I try with `cnn_learner` like this:
```
path = untar_data(URLs.PETS)/'images'

def is_cat(x): return x[0].isupper()
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224))

learn = cnn_learner(dls, resnet34, opt_func=opt_func, metrics=error_rate)
learn.fit(1)
```

I get the following error:
```
TypeError: optimizer can only optimize Tensors, but one of the params is list
```
I am not sure why I get this error, but it may have something to do with the `param_lists`/the splitting of the model.

For these reasons, the `compose` approach does not currently work...
",two come compose approach trying compose partial also tried something similar try passing learner like learner get error got unexpected argument believe limitation compose function compose composed expect related hence error try like path return path path learn get following error optimize one list sure get error may something splitting model compose approach currently work,issue,negative,positive,neutral,neutral,positive,positive
780269356,"I don't understand this line of code: `losses = -log_preds.sum(dim=-1) * self.eps/c`

Isn't `log_preds.sum(dim=-1)` always gonna be 1 since you're summing a softmax? 

@PiotrCzapla @sgugger ",understand line code always gon na since,issue,negative,neutral,neutral,neutral,neutral,neutral
780251154,"@jph00 I sadly don't particularly know what exactly is causing the issue. (I also don't know what version fixed this, as I didn't really use this functionality much). 

For some reason it looks like it's trying to do something like `AdamW()()` (IE call the class instance) rather then `.step` I believe? But I also don't know what the old behavior exactly did.

@tmabraham used it much more, so he may have an idea?",sadly particularly know exactly causing issue also know version fixed really use functionality much reason like trying something like ie call class instance rather believe also know old behavior exactly used much may idea,issue,negative,positive,positive,positive,positive,positive
780201873,Do we know what's changed that's caused the `compose()`/inline approach to not work any more? cc @muellerzr ,know compose approach work,issue,negative,neutral,neutral,neutral,neutral,neutral
779378476,"@tyoc213 that used to be able to work, but now we need to actually write a basic `opt_func` to wrap it in",used able work need actually write basic wrap,issue,negative,positive,positive,positive,positive,positive
778848156,"I think you can also pass directly to the fit method IIRC just as parameter... barely remember something like `fit(optim= OptimWrapper(optim.SGD(params, lr=0.001)))`",think also pas directly fit method parameter barely remember something like fit,issue,positive,positive,positive,positive,positive,positive
778837348,"It does indeed, however it needs to be defined as such:
```python
def opt_func(params, **kwargs): return OptimWrapper(optim.SGD(params, lr=0.001))
```
The docs should be updated (and this closed once they are)",indeed however need defined python return closed,issue,negative,negative,neutral,neutral,negative,negative
777037579,"Hi Zachary. I ran into an issue when using 5d tensors where there was not enough room in the size field to show the size fully. See
https://forums.fast.ai/t/learn-summary-output-shape-field-is-fixed-and-too-small/83745/3

Also, I wonder if summary() could provide a more useful diagnosis of model errors, rather than just crashing. Size mismatches are a persistent issue posted on the forums. Something like, ""The layer [layer string] needed shape 1x3x50x50 but the previous layer sent 1x2x50x50. You might fix this by ...."" It could help people diagnose their own models.

Thanks for your good work.
Malcolm (Pomo)",hi ran issue enough room size field show size fully see also wonder summary could provide useful diagnosis model rather size persistent issue posted something like layer layer string shape previous layer sent might fix could help people diagnose thanks good work,issue,positive,positive,positive,positive,positive,positive
776267528,"Not sure why ""nbs are not synched"". Is it because of this?

```
-# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/nbs/08_vision.data.ipynb (unless otherwise specified).
+# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/08_vision.data.ipynb (unless otherwise specified).
```

I rand  `nbdev_build_lib --fname nbs/08_vision.data.ipynb ` to create the Python file.",sure edit file edit unless otherwise edit file edit unless otherwise rand create python file,issue,positive,positive,positive,positive,positive,positive
776257462,"Right, sorry I was a bit too quick with this one. Let me open an new PR.",right sorry bit quick one let open new,issue,negative,positive,neutral,neutral,positive,positive
776154090,Good job - thanks for taking the time to figure it out! :) ,good job thanks taking time figure,issue,positive,positive,positive,positive,positive,positive
775635913,"A clean edit of the jupyter notebook with a multioutput example is done [here](https://github.com/fastai/fastai/pull/3217).

Will close this pull request",clean edit notebook example done close pull request,issue,negative,positive,positive,positive,positive,positive
775459011,@tcapelle this actually shouldn't work and is more a feature request. Currently `show_results` is only geared towards labelled dataloaders. ,actually work feature request currently geared towards,issue,negative,neutral,neutral,neutral,neutral,neutral
775148825,"> Hi!
> 
> you create a DataBlock and you pass a GrandparentSplitter, something like this:
> 
> ```
>     dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),
>                    get_items = get_image_files,
>                    splitter = GrandparentSplitter(train_name = 'train', 
>                                                   valid_name = 'val'),
>                    get_y = parent_label)
> ```
> 
> GrandparentSplitter will get as train and validation sets the names of the folder you specify, and in this case, you'll get the labels from the parent folders (NORMAL or PNEUMONIA, i think).
> 
> then you create the dataloader from that datablock: `dls = dblock.dataloaders(data)`

**Fastai-v2.2.5**
Thanks a lot :+1:  It works for me.

",hi create pas something like splitter get train validation folder specify case get parent normal pneumonia think create data thanks lot work,issue,positive,positive,positive,positive,positive,positive
775130973,"Hi!

you create a DataBlock and you pass a GrandparentSplitter, something like this:

```
    dblock = DataBlock(blocks = (ImageBlock, CategoryBlock),
                   get_items = get_image_files,
                   splitter = GrandparentSplitter(train_name = 'train', 
                                                  valid_name = 'val'),
                   get_y = parent_label)
```

GrandparentSplitter will get as train and validation sets the names of the folder you specify, and in this case, you'll get the labels from the parent folders (NORMAL or PNEUMONIA, i think).

then you create the dataloader from that datablock: ` dls = dblock.dataloaders(data) `
",hi create pas something like splitter get train validation folder specify case get parent normal pneumonia think create data,issue,positive,positive,positive,positive,positive,positive
775030029,"In the callback/fp16.py, .dtype is called on self.preds
However, when the model has two or more outputs, self.preds is a tuple of tensors not tensor
This results in an assertion error when self.preds.dtype is called.

To reproduce, train a model with two or more outputs with mixed precision.
""""""
/usr/local/lib/python3.6/dist-packages/fastai/callback/fp16.py in after_pred(self)
20 def before_batch(self): self.autocast.enter()
21 def after_pred(self):
---> 22 if self.pred.dtype==torch.float16: self.learn.pred = to_float(self.pred)
23 def after_loss(self): self.autocast.exit()
24 def before_backward(self): self.learn.loss_grad = self.scaler.scale(self.loss_grad)

AttributeError: 'tuple' object has no attribute 'dtype'
""""""

Expected Behavior:
The dtype check should be done on one of the outputs, regardless the number of outputs of a model.
Checking all outputs for dtype should not be necessary, because outputs should be of the same dtype.

Fix:
Using listify(self.preds)[0].dtype instead of self.preds[0] in callback/fp16.py
should resolve this issue.",however model two tensor assertion error reproduce train model two mixed self self self self self object attribute behavior check done one regardless number model necessary fix instead resolve issue,issue,negative,neutral,neutral,neutral,neutral,neutral
774892948,"> I have a similar issue with my package [UPIT](https://github.com/tmabraham/UPIT), great to see you already have a fix.
> 
> Have you tried following [this guide](https://docs.fast.ai/dev-setup.html) to make your changes and submit a PR?

Thanks, I followed those steps to request a merge [Here](https://github.com/fastai/fastai/pull/3212)",similar issue package great see already fix tried following guide make submit thanks request merge,issue,positive,positive,positive,positive,positive,positive
774778380,`#export` is already present at the top of the cell where the class `MCDropoutCallback` is defined ([link to source](https://github.com/fastai/fastai/blob/master/nbs/18b_callback.preds.ipynb)). The only thing missing is the entry in the `fastai/callback/all.py` file for the generated `preds.py` file.,export already present top cell class defined link source thing missing entry file file,issue,negative,positive,neutral,neutral,positive,positive
774774396,"It needs a `#export` at the top of its cell, if it doesn't already have one. Also there's some info here
https://docs.fast.ai/dev-setup.html 

(And the nbdev tutorial of course.)",need export top cell already one also tutorial course,issue,negative,positive,positive,positive,positive,positive
774556194,"I have a similar issue with my package [UPIT](https://github.com/tmabraham/UPIT), great to see you already have a fix.

Have you tried following [this guide](https://docs.fast.ai/dev-setup.html) to make your changes and submit a PR?",similar issue package great see already fix tried following guide make submit,issue,positive,positive,positive,positive,positive,positive
774555130,This is already implemented with the [CSVLogger](https://docs.fast.ai/callback.progress.html#CSVLogger) callback. Is there a reason this callback does not fulfill your needs?,already reason fulfill need,issue,negative,neutral,neutral,neutral,neutral,neutral
774539370,"@jph00 I updated this PR as requested.  Also, I checked in the new hashes that correspond to the updated tar files.  

@tmabraham to test, check out this branch and install it: from the root of this repo run `pip install -e .`

",also checked new correspond tar test check branch install root run pip install,issue,negative,positive,positive,positive,positive,positive
774526494,"Got the same error:

**TypeError: no implementation found for 'torch.nn.functional.nll_loss' on types that implement __torch_function__: [<class 'fastai.torch_core.TensorImage'>, <class 'fastai.torch_core.TensorMask'>]**

```
def myfunc(outputs, targets):
    print(type(outputs)) # <class 'fastai.torch_core.TensorImage'>
    print(type(targets)) # <class 'fastai.torch_core.TensorMask'>
    softmax = torch.nn.functional.log_softmax(outputs, dim=1)
    loss = torch.nn.functional.nll_loss(softmax, targets)  <--- exception here
    return loss
```
",got error implementation found implement class class print type class print type class loss exception return loss,issue,negative,neutral,neutral,neutral,neutral,neutral
774237651,"@jph00 made adjustments. The test will fail based on the previous commit we're fixing (since IMDB_Sample names it's text column as `text`, it's an easy situation to miss)",made test fail based previous commit fixing since text column text easy situation miss,issue,negative,negative,neutral,neutral,negative,negative
774226893,Sure. Will also add a brief test as well,sure also add brief test well,issue,positive,positive,positive,positive,positive,positive
774209996,Sorry @muellerzr looks like a conflict has appeared - any chance you could resolve that so I can merge this?,sorry like conflict chance could resolve merge,issue,positive,negative,negative,negative,negative,negative
773934401,"Purely from an end user point of view, another look at how distributed training is implemented. 

Consider the situation in which we have a training script `train.py` which trains a model using a single GPU. Whilst it is currently possible to use DDP for training, it requires modifying this script to include a context manager which wraps `Learner` and then, instead of calling `python train.py args .. ` , we must call `python -m fastai.launch train.py args`. 

Whilst this isn't a _huge_ amount of effort, it would be even better if I didn't have to change my process at all, except for an argument for the number of GPUs I would like to use; I think this is something that PyTorch-Lightning does very well, in a way that is completely abstracted from the user. Additionally, it can be problematic if the script is being called as part of a pipeline when using a tool such as Azure Machine Learning, in which it is difficult to modify the command line call to include `-m fastai.launch` - in this case, you would be forced to create an additional python script to act as a wrapper.  ",purely end user point view another look distributed training consider situation training script model single whilst currently possible use training script include context manager learner instead calling python must call python whilst amount effort would even better change process except argument number would like use think something well way completely abstracted user additionally problematic script part pipeline tool azure machine learning difficult modify command line call include case would forced create additional python script act wrapper,issue,negative,negative,neutral,neutral,negative,negative
773884917,"I don't think that tracing has this limitation.
![image](https://user-images.githubusercontent.com/18441985/107010130-382a8c80-6796-11eb-81eb-d3717b65b765.png)
I agree that  Every `fastai` layer should be scriptable anyway.",think tracing limitation image agree every layer anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
773868090,"In my opinion, there is another important limitation with tracing. You need to use the same batch size that you used when you traced your module. So, it's difficult to use a traced model in a production server that support batching request. For example torchserve, cortex or BentoML support this. 

I don't generally find difficult to script a model. Most of them works out of the box or with small tweaks (I scripted several classification and segmentation models, yolov5 and some custom models). With small tweaks I mean annotating code with Python annotation (mostly constants in the __init__) + avoid to use functions/methods with **kwargs. ",opinion another important limitation tracing need use batch size used module difficult use model production server support request example cortex support generally find difficult script model work box small several classification segmentation custom small mean code python annotation mostly avoid use,issue,negative,negative,neutral,neutral,negative,negative
773835523,"@jph00 , Thank your help, no need to extend tests timeout.",thank help need extend,issue,positive,neutral,neutral,neutral,neutral,neutral
773567600,"it has, this solves the issue:
```python
@patch
def requires_grad_(self:TensorBase, requires_grad=True):
    # Workaround https://github.com/pytorch/pytorch/issues/50219
    self.requires_grad = requires_grad
    return self
```
Anyway, you should trace vision models that are without control-flow. It is important to cast to `TensorBase` to be able to show results.",issue python patch self return self anyway trace vision without important cast able show,issue,negative,positive,positive,positive,positive,positive
773463080,"If you just mark slow cells with `#slow` then they will be skipped. For details, see:
https://nbdev.fast.ai/test ",mark slow slow see,issue,negative,negative,negative,negative,negative,negative
773403454,"I think that TensorBase call in `Flatten` is the culprit that Flatten can't be scripted.

```python
@module(full=False)
def myFlatten(self, x):
    ""Flatten `x` to a single dimension, e.g. at end of a model. `full` for rank-1 tensor""
    # return TensorBase(x.view(-1) if self.full else x.view(x.size(0), -1)) <- Fastai implementation.
    return x.view(-1) if self.full else x.view(x.size(0), -1)

path = untar_data(URLs.PETS)/'images'
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2,
    label_func=lambda x: x[0].isupper(), item_tfms=Resize(224))
learn = cnn_learner(dls, resnet18)

assert isinstance(model[1][1], Flatten)
model[1][1] = myFlatten()

ts_model = torch.jit.script(learn.model)
```

This can be scripted.",think call flatten culprit flatten ca python module self flatten single dimension end model full tensor return else implementation return else path path path learn assert model flatten model,issue,negative,positive,positive,positive,positive,positive
772987600,"
> @jph00 <https://github.com/jph00> I did. sorry, I added the snapshot in fastai/nbdev#412 <https://github.com/fastai/nbdev/pull/412>, not in this PR


Ah OK - looks like you didn't at-mention me, so I missed those. Sorry about that.",sorry added snapshot ah like sorry,issue,negative,negative,negative,negative,negative,negative
772984454,"> > @jph00

> Did you try running this notebook manually to see where/why it's so slow? Is that the only one causing the speed issue?

@jph00 I did.  sorry, I added the snapshot in https://github.com/fastai/nbdev/pull/412, not in this PR",try running notebook manually see slow one causing speed issue sorry added snapshot,issue,negative,negative,negative,negative,negative,negative
772729275,"> @jph00
> ![image](https://user-images.githubusercontent.com/16190118/106707553-612f0e00-662c-11eb-8c63-796bfa46f460.png)
> ![image](https://user-images.githubusercontent.com/16190118/106707709-a6534000-662c-11eb-98bc-1b41169f755a.png)

Did you try running this notebook manually to see where/why it's so slow? Is that the only one causing the speed issue?",image image try running notebook manually see slow one causing speed issue,issue,negative,negative,negative,negative,negative,negative
772722375,"Thanks for the PR. This is an nbdev project, so edits need to be made in the appropriate notebook, along with a test to exercise the new behavior, and prose to explain it.

I'll close this PR - please open a new one, or reopen this one, if you're interested in moving ahead.",thanks project need made appropriate notebook along test exercise new behavior prose explain close please open new one reopen one interested moving ahead,issue,positive,positive,positive,positive,positive,positive
771714405,I just try to reproduce the error to post here but now the notebook is working perfectly and not giving an error.,try reproduce error post notebook working perfectly giving error,issue,negative,positive,positive,positive,positive,positive
771711949,I got the same error when i tried to run the 01_intro.ipynb from fastai/fastbook in colab. It happens at the first cell in import fastbook line. Notebook only gives an error when i change the runtime type and try to use a GPU. Everything seems to work fine when i dont use a GPU.,got error tried run first cell import line notebook error change type try use everything work fine dont use,issue,negative,positive,positive,positive,positive,positive
771418846,"Thank you @sgugger it solved my problem as well

from fastai.text import *
import numpy as np
from sklearn.model_selection import train_test_split
import pickle
import sentencepiece as spm
import re
import pdb
defaults.cpus=1",thank problem well import import import import pickle import import import,issue,negative,neutral,neutral,neutral,neutral,neutral
771181137,Ok!  This should be resolved with #3197 please let us know if this fixes things for you!,resolved please let u know,issue,negative,neutral,neutral,neutral,neutral,neutral
771164271,"This appears to be fixed in #3194.  This should be fixed on windows, but if by any chance it is not, please let us know and we will reopen this issue. 

I have tested this in Colab: [see notebook](https://colab.research.google.com/drive/16nqqa7xmuL5zGQrI5qoWJf3jVzT1Uzzw?usp=sharing)

I have also tested that this works locally on my mac.  ",fixed fixed chance please let u know reopen issue tested see notebook also tested work locally mac,issue,positive,positive,neutral,neutral,positive,positive
771037607,"This was an issue for fastai v1. If there's still an issue with v2 or fastbook, please create a new issue and at-mention me (or create a PR with the `threadpool=True` workaround). Many thanks!",issue still issue please create new issue create many thanks,issue,positive,positive,positive,positive,positive,positive
771017842,"> Closing this since the option apparently works to fix the bug.

Would be nice if it was working out of the box, though. Is it really needed to download the images using multiprocessing, rather than multithreading? If not, passing `threadpool=True` in https://github.com/fastai/fastai/blob/0e01131/fastai/vision/utils.py#L37 should make it work for all platforms.",since option apparently work fix bug would nice working box though really rather passing make work,issue,negative,positive,positive,positive,positive,positive
770082402,"Hey @muellerzr , I think this can be closed now. Thanks for the guidance and help with my first PR and contribution to fastai, the experience was really positive (thanks jeremy as well for feedback).",hey think closed thanks guidance help first contribution experience really positive thanks well feedback,issue,positive,positive,positive,positive,positive,positive
769901420,"> The os.remove call should be restricted to the master GPU.

I cannot do this without creating a deadlock in distributed mode. Any ideas to properly fix this?",call restricted master without deadlock distributed mode properly fix,issue,negative,neutral,neutral,neutral,neutral,neutral
769773161,"Thanks mate. Worked like a charm (though I did my homework before posting here, could not find a clear and concise explanation)
Yep, The project is predicting storm speed from satellite imagery. Nothing new really :) It has been out for a couple of years already.

I suppose I should close this thread.
Appreciated your help

Cheers",thanks mate worked like charm though homework posting could find clear concise explanation yep project storm speed satellite imagery nothing new really couple already suppose close thread help,issue,positive,positive,positive,positive,positive,positive
769757597,Thank you very much!  I have created a fresh environment and solved that problem.,thank much fresh environment problem,issue,negative,positive,positive,positive,positive,positive
769738531,"This is cimpletely normal.
your `xresnet` does not know how many outputs your data has. (when you call xresnet18 directly, you are using the default imagenet 1000 classes).
Use the `create_cnn` method and explicitely say `n_out=1`, replace  your model by this:
```python
model = create_cnn_model(xresnet18, n_out=1)
```
A good practice, is to pass one input on the model manually, and check the output.
```python
x,y = dls.one_batch()
out = model(x)
assert test_eq(out.shape, y.shape)
```
Cool project, what are you regressing, the wind speed from the image of the storm?",normal know many data call directly default class use method say replace model python model good practice pas one input model manually check output python model assert cool project wind speed image storm,issue,positive,positive,positive,positive,positive,positive
769693932,"please run:
```python
from fastai.test_utils import show_install
show_install()
```
and post the output (this is probably related with how you installed pytorch/cuda).
Try creating a fresh environment and install pytorch using conda.",please run python import post output probably related try fresh environment install,issue,positive,positive,positive,positive,positive,positive
769635607,"Sure, the details are as follows:
Traceback (most recent call last):
  File ""/home/zm/anaconda3/bin/nnUNet_predict"", line 33, in <module>
    sys.exit(load_entry_point('nnunet', 'console_scripts', 'nnUNet_predict')())
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/inference/predict_simple.py"", line 221, in main
    step_size=step_size, checkpoint_name=args.chk)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/inference/predict.py"", line 636, in predict_from_folder
    segmentation_export_kwargs=segmentation_export_kwargs)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/inference/predict.py"", line 220, in predict_cases
    mixed_precision=mixed_precision)[1][None])
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/training/network_training/nnUNetTrainerV2.py"", line 219, in predict_preprocessed_data_return_seg_and_softmax
    mixed_precision=mixed_precision)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/training/network_training/nnUNetTrainer.py"", line 521, in predict_preprocessed_data_return_seg_and_softmax
    mixed_precision=mixed_precision)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/network_architecture/neural_network.py"", line 150, in predict_3D
    verbose=verbose)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/network_architecture/neural_network.py"", line 385, in _internal_predict_3D_3Dconv_tiled
    gaussian_importance_map)[0]
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/network_architecture/neural_network.py"", line 522, in _internal_maybe_mirror_and_pred_3D
    pred = self.inference_apply_nonlin(self(x))
  File ""/home/zm/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/network_architecture/generic_UNet.py"", line 391, in forward
    x = self.conv_blocks_context[d](x)
  File ""/home/zm/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/network_architecture/generic_UNet.py"", line 142, in forward
    return self.blocks(x)
  File ""/home/zm/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/home/zm/anaconda3/lib/python3.6/site-packages/torch/nn/modules/container.py"", line 117, in forward
    input = module(input)
  File ""/home/zm/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/home/zm/nnUNetFrame/nnUNet/nnunet/network_architecture/generic_UNet.py"", line 65, in forward
    x = self.conv(x)
  File ""/home/zm/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py"", line 727, in _call_impl
    result = self.forward(*input, **kwargs)
  File ""/home/zm/anaconda3/lib/python3.6/site-packages/torch/nn/modules/conv.py"", line 573, in forward
    self.padding, self.dilation, self.groups)
RuntimeError: no valid convolution algorithms available in CuDNN

pytorch 1.7.1 , python3.6, cuda10.2, cudnn8.05, GeForce RTX 3090 .
I am wondering if I have chosen the wrong version of cuDdnn or cuda?
Thanks in advance!",sure recent call last file line module file line main file line file line none file line file line file line file line file line self file line result input file line forward file line result input file line forward return file line result input file line forward input module input file line result input file line forward file line result input file line forward valid convolution available wondering chosen wrong version thanks advance,issue,negative,positive,positive,positive,positive,positive
769615990,"Would you mind posting the detailed error?

On Fri, Jan 29, 2021, 4:05 AM xzming1998 <notifications@github.com> wrote:

> I have met the same problem, have you solved it?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3031#issuecomment-769542805>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEMWOAKW5P3OFBHY2MNIILLS4IQYNANCNFSM4UB7QSNQ>
> .
>
",would mind posting detailed error wrote met problem thread reply directly view,issue,negative,positive,positive,positive,positive,positive
768513781,Have you find a way to solve this issue. I also faced same issue. ,find way solve issue also faced issue,issue,negative,neutral,neutral,neutral,neutral,neutral
767726670,"No I don't think this is a solution - we need to be able to get >0 workers running on Windows. It's OK if it doesn't work in notebooks, but it should at least be made to work in scripts. I'll close this PR since I don't think this is the right approach. With 0 workers, performance isn't acceptable for nearly any practical vision task, for instance.",think solution need able get running work least made work close since think right approach performance acceptable nearly practical vision task instance,issue,positive,positive,positive,positive,positive,positive
767552919,Because I think the `imports` folder comes from a previous version. The corch and torch modules are imported in another file,think folder come previous version torch another file,issue,negative,negative,negative,negative,negative,negative
767543896,I have the same problem. Why do you need to delete the `imports` folder?,problem need delete folder,issue,negative,neutral,neutral,neutral,neutral,neutral
766196993,"Looks as though I missed a recent commit/fix. Will adjust accordingly

On Fri, Jan 22, 2021 at 8:14 PM review-notebook-app[bot] <
notifications@github.com> wrote:

> Check out this pull request on  [image: ReviewNB]
> <https://app.reviewnb.com/fastai/fastai/pull/3186>
>
> See visual diffs & provide feedback on Jupyter Notebooks.
> ------------------------------
>
> *Powered by ReviewNB <https://www.reviewnb.com/?utm_source=gh>*
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3186#issuecomment-765817744>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV7WSAAMMKKZARBPAVLS3IWH7ANCNFSM4WPJNXGA>
> .
>
",though recent adjust accordingly bot wrote check pull request image see visual provide feedback powered thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
765813977,"@jph00 here is a minimal reproducer of the exact cause of this issue. It seems as though despite the callback being `run_valid`, some aspects of the Callback that can affect input/output are still being called:
```python
from fastai.vision.all import *
set_seed(99, True)
path = untar_data(URLs.PETS)/'images'
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2,
    label_func=lambda x: x[0].isupper(), item_tfms=Resize(224))

learn = cnn_learner(dls, resnet18, cbs=MixUp())
b = dls[1].one_batch()
p = learn.get_preds(dl=[b], with_decoded=True)
x,y,its = dls.show_batch(b, 9, show=False)
b_out = type(b)(b[:dls.n_inp] + (tuple(p[2]) if is_listy(p[2]) else (p[2],)))

learn.cbs = learn.cbs[:-1]
p = learn.get_preds(dl=[b], with_decoded=True)
x,y,its = dls.show_batch(b, 9, show=False)
b_out_a = type(b)(b[:dls.n_inp] + (tuple(p[2]) if is_listy(p[2]) else (p[2],)))

test_eq(b_out, b_out_a)
```
(also this was present in the old MixUp implementation too, checked that)",minimal reproducer exact cause issue though despite affect still python import true path path path learn type else type else also present old implementation checked,issue,negative,positive,positive,positive,positive,positive
765774491,"> @jph00 <https://github.com/jph00> let me know if you would like me to make an adjustment to instances of `requires_grad_()` in the framework to expose the `requires_grad` param inside of it or not.
> What places did you find that might require that?

jit's `clone_input` (which is called during `trace`) will call a tensor like so:
```python
    148                 a.detach()
    149                 .clone(memory_format=torch.preserve_format)
--> 150                 .requires_grad_(a.requires_grad)
    151             )
```
(this is from https://github.com/fastai/fastai/issues/3182)

You can also see it here in their source: https://github.com/pytorch/pytorch/blob/master/torch/jit/_trace.py#L150",let know would like make adjustment framework expose param inside find might require trace call tensor like python also see source,issue,positive,neutral,neutral,neutral,neutral,neutral
765771046,"
> @jph00 <https://github.com/jph00> let me know if you would like me to make an adjustment to instances of `requires_grad_()` in the framework to expose the `requires_grad` param inside of it or not.


What places did you find that might require that?",let know would like make adjustment framework expose param inside find might require,issue,negative,neutral,neutral,neutral,neutral,neutral
765440520,close this issue. I figured it out. y_int=True was missing,close issue figured missing,issue,negative,negative,negative,negative,negative,negative
765170042,"Hi - faced same error when training an Image Regression from scratch using RegressionBlock and MSELossFlat (but using the same code with CategoryBlock and CrossEntropyLossFlat work well for Classification)

```
def get_dls(r, bs, size):
  dblock = DataBlock(blocks=(ImageBlock, RegressionBlock),
                    get_x=get_x,
                    get_y=get_y,
                    splitter=splitter,
                    batch_tfms=[*aug_transforms(size=size, min_scale=0.75),
                                Normalize()])
  return dblock.dataloaders(r, bs=bs)

dls = get_dls(df, 64, 224) 

model = xresnet18()
learn = Learner(dls, model, loss_func=MSELossFlat(), metrics=rmse)
learn.fit_one_cycle(5, 3e-3)

RuntimeError                              Traceback (most recent call last)
<ipython-input-10-d6b32cc82696> in <module>()
      1 model = xresnet18()
      2 learn = Learner(dls, model, loss_func=MSELossFlat(), metrics=rmse)
----> 3 learn.fit_one_cycle(5, 3e-3)

20 frames
/usr/local/lib/python3.6/dist-packages/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)
    110     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),
    111               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}
--> 112     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)
    113 
    114 # Cell

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
    209             self.opt.set_hypers(lr=self.lr if lr is None else lr)
    210             self.n_epoch = n_epoch
--> 211             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
    212 
    213     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    158 
    159     def _with_events(self, f, event_type, ex, final=noop):
--> 160         try: self(f'before_{event_type}');  f()
    161         except ex: self(f'after_cancel_{event_type}')
    162         self(f'after_{event_type}');  final()

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_fit(self)
    200         for epoch in range(self.n_epoch):
    201             self.epoch=epoch
--> 202             self._with_events(self._do_epoch, 'epoch', CancelEpochException)
    203 
    204     def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    158 
    159     def _with_events(self, f, event_type, ex, final=noop):
--> 160         try: self(f'before_{event_type}');  f()
    161         except ex: self(f'after_cancel_{event_type}')
    162         self(f'after_{event_type}');  final()

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_epoch(self)
    194 
    195     def _do_epoch(self):
--> 196         self._do_epoch_train()
    197         self._do_epoch_validate()
    198 

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_epoch_train(self)
    186     def _do_epoch_train(self):
    187         self.dl = self.dls.train
--> 188         self._with_events(self.all_batches, 'train', CancelTrainException)
    189 
    190     def _do_epoch_validate(self, ds_idx=1, dl=None):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    158 
    159     def _with_events(self, f, event_type, ex, final=noop):
--> 160         try: self(f'before_{event_type}');  f()
    161         except ex: self(f'after_cancel_{event_type}')
    162         self(f'after_{event_type}');  final()

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in all_batches(self)
    164     def all_batches(self):
    165         self.n_iter = len(self.dl)
--> 166         for o in enumerate(self.dl): self.one_batch(*o)
    167 
    168     def _do_one_batch(self):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in one_batch(self, i, b)
    182         self.iter = i
    183         self._split(b)
--> 184         self._with_events(self._do_one_batch, 'batch', CancelBatchException)
    185 
    186     def _do_epoch_train(self):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    158 
    159     def _with_events(self, f, event_type, ex, final=noop):
--> 160         try: self(f'before_{event_type}');  f()
    161         except ex: self(f'after_cancel_{event_type}')
    162         self(f'after_{event_type}');  final()

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_one_batch(self)
    170         self('after_pred')
    171         if len(self.yb):
--> 172             self.loss_grad = self.loss_func(self.pred, *self.yb)
    173             self.loss = self.loss_grad.clone()
    174         self('after_loss')

/usr/local/lib/python3.6/dist-packages/fastai/losses.py in __call__(self, inp, targ, **kwargs)
     33         if targ.dtype in [torch.int8, torch.int16, torch.int32]: targ = targ.long()
     34         if self.flatten: inp = inp.view(-1,inp.shape[-1]) if self.is_2d else inp.view(-1)
---> 35         return self.func.__call__(inp, targ.view(-1) if self.flatten else targ, **kwargs)
     36 
     37 # Cell

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in _call_impl(self, *input, **kwargs)
    725             result = self._slow_forward(*input, **kwargs)
    726         else:
--> 727             result = self.forward(*input, **kwargs)
    728         for hook in itertools.chain(
    729                 _global_forward_hooks.values(),

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py in forward(self, input, target)
    444 
    445     def forward(self, input: Tensor, target: Tensor) -> Tensor:
--> 446         return F.mse_loss(input, target, reduction=self.reduction)
    447 
    448 

/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py in mse_loss(input, target, size_average, reduce, reduction)
   2648             return handle_torch_function(
   2649                 mse_loss, tens_ops, input, target, size_average=size_average, reduce=reduce,
-> 2650                 reduction=reduction)
   2651     if not (target.size() == input.size()):
   2652         warnings.warn(""Using a target size ({}) that is different to the input size ({}). ""

/usr/local/lib/python3.6/dist-packages/torch/overrides.py in handle_torch_function(public_api, relevant_args, *args, **kwargs)
   1061         # Use `public_api` instead of `implementation` so __torch_function__
   1062         # implementations can do equality/identity comparisons.
-> 1063         result = overloaded_arg.__torch_function__(public_api, types, args, kwargs)
   1064 
   1065         if result is not NotImplemented:

/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs)
    323         convert=False
    324         if _torch_handled(args, self._opt, func): convert,types = type(self),(torch.Tensor,)
--> 325         res = super().__torch_function__(func, types, args=args, kwargs=kwargs)
    326         if convert: res = convert(res)
    327         if isinstance(res, TensorBase): res.set_meta(self, as_copy=True)

/usr/local/lib/python3.6/dist-packages/torch/tensor.py in __torch_function__(cls, func, types, args, kwargs)
    993 
    994         with _C.DisableTorchFunction():
--> 995             ret = func(*args, **kwargs)
    996             return _convert(ret, cls)
    997 

/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py in mse_loss(input, target, size_average, reduce, reduction)
   2657         reduction = _Reduction.legacy_get_string(size_average, reduce)
   2658 
-> 2659     expanded_input, expanded_target = torch.broadcast_tensors(input, target)
   2660     return torch._C._nn.mse_loss(expanded_input, expanded_target, _Reduction.get_enum(reduction))
   2661 

/usr/local/lib/python3.6/dist-packages/torch/functional.py in broadcast_tensors(*tensors)
     69         if any(type(t) is not Tensor for t in tensors) and has_torch_function(tensors):
     70             return handle_torch_function(broadcast_tensors, tensors, *tensors)
---> 71     return _VF.broadcast_tensors(tensors)  # type: ignore
     72 
     73 

RuntimeError: The size of tensor a (64000) must match the size of tensor b (64) at non-singleton dimension 0
```


checking the size of tensors:

```
x,y = dls.one_batch()
x.size()
out: (64, 3, 224, 224)
y.size()
out: torch.Size([64])
```

for CategoryBlock would be:

```
x,y = dls.one_batch()
x.size()
out: (64, 3, 224, 224)
y.size()
out: (64,)
```

P.S.: the same lines of code for a transfer learning regression work with no error as well. ",hi faced error training image regression scratch code work well classification size normalize return model learn learner model recent call last module model learn learner model self div none else cell fit self none else self none none none none none self ex final self ex try self except ex self self final self epoch range fit self self ex final self ex try self except ex self self final self self self self self self ex final self ex try self except ex self self final self self enumerate self self self self ex final self ex try self except ex self self final self self self self else return else cell self input result input else result input hook forward self input target forward self input tensor target tensor tensor return input target input target reduce reduction return input target target size different input size use instead implementation result result self convert type self super convert convert self ret return ret input target reduce reduction reduction reduce input target return reduction type tensor return return type ignore size tensor must match size tensor dimension size would code transfer learning regression work error well,issue,negative,positive,neutral,neutral,positive,positive
765072481,"I added a couple examples to the tutorials. I went out of my way to make the diffs as small as possible, but the base64 encoded imagery from `.show_batch()` is a diff. I also tried to rebase my commits and squash them to 1 but because I pulled from origin in between the first commit from the other day and today, I couldn't rebase as I'd like so I apologize for the multiple commits.",added couple went way make small possible base imagery also tried rebase squash origin first commit day today could rebase like apologize multiple,issue,positive,negative,negative,negative,negative,negative
764999434,"This is really an implementation-specific issue, and not something I'd want to document for long-term support. Maybe add something to the fastai vnext issue requesting we add an official way to provide this?",really issue something want document support maybe add something issue add official way provide,issue,positive,positive,positive,positive,positive,positive
763819694,"I think people would be surprised that setting the seed would make it slower, hence it's False by default.",think people would setting seed would make hence false default,issue,negative,negative,negative,negative,negative,negative
763273342,"Ability to create tabular dataloaders that pull batches from out of memory.  Currently, if you dataset is too large for memory you must do something outside of fastai.

**Why Tabular:** A very large percentage of companies are not leveraging machine learning (or at least not in a super meaningful way).  For many of these companies the natural place to start would be tabular.  Most companies have a lot of data already stored in a SQL database (customer transactions, billing information, complaints, sales, contracts, competitor data, account information, firmographics, etc.) and so starting to leverage that would be the ideal place to start.  Partially because it's what is available but partially it's data that the business already has some understanding of.  

**What's the issue currently:** The problem is that often these datasets are too large to just fit in memory.  If there was an easy way to create a dataloader that wasn't dependent on storing the full dataframe in memory it would make using fastai much more approachable for a lot of businesses.  Currently in order for these users to start using fastai for tabular - they have to create some custom implementation of fastai dataloaders to be able to do this using all their data.

**Example of Tabular OOM with fastai using rapids:**  Here is a link to the example on rossman for OOM datasets using parquet files, on the navigation bar you can also see how it fits into training with fastai. 
 ""providing the Dataset class, which breaks a set of parquet or csv files into into a collection of cudf.DataFrame chunks that can fit in device memory.""  https://nvidia.github.io/NVTabular/v0.2.0/examples/rossmann.html#Datasets ",ability create tabular pull memory currently large memory must something outside tabular large percentage machine learning least super meaningful way many natural place start would tabular lot data already customer billing information competitor data account information starting leverage would ideal place start partially available partially data business already understanding issue currently problem often large fit memory easy way create dependent full memory would make much approachable lot currently order start tabular create custom implementation able data example tabular link example parquet navigation bar also see training providing class set parquet collection fit device memory,issue,positive,positive,positive,positive,positive,positive
762887795,"I’d agree the docs need to be improved in that part. I’ll add it to the to
do list :)

On Tue, Jan 19, 2021 at 8:01 AM Alexander Kluber <notifications@github.com>
wrote:

> Awesome, that works, thanks!
>
> I guess I could've dug deeper into get_emb_szs to understand the logic.
> The top-level docs were a little scant regarding the proper types for
> tabular_learner.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3155#issuecomment-762856790>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV64JOCX6R5WSPJIDCDS2WGCXANCNFSM4WBMZDMQ>
> .
>
",agree need part add list tue wrote awesome work thanks guess could dug understand logic little scant regarding proper reply directly view,issue,positive,positive,positive,positive,positive,positive
762856790,"Awesome, that works, thanks! 

I guess I could've dug deeper into `get_emb_szs` to understand the logic. The top-level docs were a little scant regarding the proper types for `tabular_learner`.",awesome work thanks guess could dug understand logic little scant regarding proper,issue,positive,positive,positive,positive,positive,positive
762526158,@jph00 I'd say this is ready for your review :) This would close https://github.com/fastai/fastai/issues/3125,say ready review would close,issue,negative,positive,positive,positive,positive,positive
762473623,"@muellerzr , you're right on the pillow version syntax. I updated the example to the latest available versions.

I'm on windows so I couldn't verify the path examples already provided in the other snippets but the rest of the installation commands worked pending having the prerequisites installed. Happy to spin up a VM and work through them if thats needed to get the PR through.",right pillow version syntax example latest available could verify path already provided rest installation worked pending happy spin work thats get,issue,positive,positive,positive,positive,positive,positive
762460973,"You could ask people to execute:
```python
from fastai.test_utils import show_install
show_install()
```
![image](https://user-images.githubusercontent.com/18441985/104960929-948b5f00-59d5-11eb-9f51-4a93cc5afb4f.png)
",could ask people execute python import image,issue,negative,neutral,neutral,neutral,neutral,neutral
762441850,"I have a meeting tomorrow morning with Nvidia, I can try to ask.
The truth is I don't understand a lot of what is happening with
`torch.script` in general, I know it serializes, but the host device can be
changed at loading, so...
I would be favorable to remove the module decorator, it does not save a
lot of space, we already have the fastai `Module`.
Anyway, we should be able to `trace` the vision models anyway, as they are completely deterministic.
I really think that we should move forward to making all fastai models compatible with `torch serve`

",meeting tomorrow morning try ask truth understand lot happening general know host device loading would favorable remove module decorator save lot space already module anyway able trace vision anyway completely deterministic really think move forward making compatible torch serve,issue,positive,positive,positive,positive,positive,positive
762345918,"Yes, removing the Flatten layer lets the model work (I did this via a custom head). Looks like having the `@module` doesn't matter, as I rewrote `Flatten` as 
```python
class myFlatten(Module):
    def __init__(self, full=False): self.full = full
    def forward(self, x): return TensorBase(x.view(-1) if self.full else x.view(x.size(0), -1))
```
So it can't be scripted on CUDA, but it can on CPU. @tcapelle do you know if this limits anything? Also closing since this isn't entirely a bug anymore",yes removing flatten layer model work via custom head like module matter flatten python class module self full forward self return else ca know anything also since entirely bug,issue,positive,positive,positive,positive,positive,positive
762199453,"the `@module` decorator does not seems to be used extensively on fastai code. Did you tried replacing only the flatten layer to see if it works?
For reference, your gist works on CPU.
![image](https://user-images.githubusercontent.com/18441985/104911989-faeb8f80-598b-11eb-8976-4b0d8209fa12.png)

",module decorator used extensively code tried flatten layer see work reference gist work image,issue,negative,neutral,neutral,neutral,neutral,neutral
762142062,"> you can then add a test dataset (without labels).

If you pass `with_labels=True` to your `dls.test_dl`, you can attach labels to them if you happen to have them.

This would be better as a forum question asked on https://forums.fast.ai rather than in a github issue",add test without pas attach happen would better forum question rather issue,issue,negative,positive,positive,positive,positive,positive
762140267,"Your embeddings sizes should be a dictionary of `var:size`

So in your case you only need to do:
```python
first_embed_size = {
    var: int(np.floor(float(len(to.classes[var])) ** 0.25))
    for var in to.cats.columns
}

learn = tabular_learner(dls, [200,100], emb_szs = first_embed_size)
```",size dictionary size case need python float learn,issue,negative,neutral,neutral,neutral,neutral,neutral
762080828,"@sayanbanerjee32 hi, as dataloader.show_batch changes the order of dataset, and does not have export functionality, could you please let me know how you compared original data frame with dataloader. thanks",hi order export functionality could please let know original data frame thanks,issue,positive,positive,positive,positive,positive,positive
761879442,"@zineanteoh Your error and solution seem to be unrelated, the solution points to an undefined symbol error - there is no method `downlod_url`.

@theptrk No, I did not solve this myself. It turned out that the resource at the URL I was querying was unavailable due to SSL issue at the server's end. It got resolved in some time on its own, and I did not face this problem since then. I have always tried this on Paperspace. You could try setting and passing the `verify` argument in `download_images()` definition.",error solution seem unrelated solution undefined symbol error method solve turned resource querying unavailable due issue server end got resolved time face problem since always tried could try setting passing verify argument definition,issue,negative,negative,negative,negative,negative,negative
761849190,"@theptrk I am using Colab. 
I am not sure what the source of the problem is, but I managed to get the code to run without errors by: 

Changing: 
downlod_url(ims[0], dest) 
To: 
download_url(ims[1], dest) 

",sure source problem get code run without,issue,negative,positive,positive,positive,positive,positive
761764451,"I also have the same error. How did you manage to fix it? 
Any help is appreciated",also error manage fix help,issue,negative,neutral,neutral,neutral,neutral,neutral
761723862,"Thats a good point, let me verify all the commands and work through the doc. I read it for legibility and checked hyperlinks but didn't run the commands myself. I'll check them all and update accordingly, thanks!",thats good point let verify work doc read legibility checked run check update accordingly thanks,issue,positive,positive,positive,positive,positive,positive
761723333,"@nglillywhite have you verified that all of it works? `fastai` no longer has a `pillow_version` function. You could do something like:

```python
import PIL
print(PIL.__version__)
```

(for instance right now, it will either say 7.0.0 or 7.0.0.post3, with the latter being simd)",work longer function could something like python import print instance right either say post latter,issue,negative,positive,positive,positive,positive,positive
761722333,"@jph00 you may be better at suggesting this. Ideally if you wanted to bring it over, it would reside in the same place that we already have the `show_install`? 

The actual func in v1 is here: https://github.com/fastai/fastai1/blob/master/fastai/utils/collect_env.py#L156",may better suggesting ideally bring would reside place already actual,issue,positive,positive,positive,positive,positive,positive
761721762,"I noticed that check_perf() wasn't migrated into the new repo and so I removed that from the previous performance doc, was this intentional or this function didn't make the cut to the new version of the library?",new removed previous performance doc intentional function make cut new version library,issue,negative,positive,neutral,neutral,positive,positive
761702532,"Happy to tackle this, @muellerzr thanks for the suggestion and guidance. I'll put together a PR and post back here if that's the best way forward. Let me know if there's anything else.",happy tackle thanks suggestion guidance put together post back best way forward let know anything else,issue,positive,positive,positive,positive,positive,positive
761654001,"I'm happy to make any changes, documentation or otherwise, but I'll wait for Jeremy to opine so I only have to make them once. ",happy make documentation otherwise wait opine make,issue,positive,positive,positive,positive,positive,positive
761463700,I am submitting a PR to visually enhance the LR find graph to add red dots where the recommendation are.  The proposed code is used in this article where you can see 2 examples of LR find plots with the visual dots:  https://walkwithfastai.com/lr_finder#Learner.lr_find,visually enhance find graph add red recommendation code used article see find visual,issue,negative,neutral,neutral,neutral,neutral,neutral
760985175,"Ah great, thanks for confirming, that's helpful.

I found that line and made a similar fix (I used `.astype(` but not sure if better). I also noticed that the other types were dependent on if all date values are present (`int64` as in the above example) vs if the column contained None (becomes `float64`)

This didn't solve the issue for Category and other Pandas types though:
```python
# Example with pandas types and generated columns
df = pd.DataFrame({'cat1': pd.Series(['l','xs','xl','s'], dtype='category'),
                    'ui32': pd.Series([1, 2, 3, 4], dtype='UInt32'),
                    'i64': pd.Series([1, 2, 3, 4], dtype='Int64'),
                    'f16': pd.Series([1, 2, 3, 4], dtype='Float64'),
                    'd1_date': ['2021-02-09', None, '2020-05-12', '2020-08-14'],
                    })
df = add_datepart(df, 'd1_date', drop=False)
df['cat1'].cat.set_categories(['xl','l','m','s','xs'], ordered=True, inplace=True)
cont_names, cat_names = cont_cat_split(df, max_card=0)
```
I found that changing `cont_cat_split` to use `pd.api.types.is_integer_dtype` over `np.issubtype` seems to be more reliable.

I created a PR (https://github.com/fastai/fastai/pull/3157) incorporating the two fixes above and would welcome your thoughts. 

Thanks",ah great thanks confirming helpful found line made similar fix used sure better also dependent date present example column none becomes float solve issue category though python example none found use reliable two would welcome thanks,issue,positive,positive,positive,positive,positive,positive
760969854,"Ah, it works in pandas version 1.0.5 but not the next version up (1.1.0) and I was on an old version of pandas (sorry!).

There is a comment in add_datepart (    # Pandas removed `dt.week` in v1.1.10).  The fix in add_datepart works but makes the week field a dtype not compatible with cont_cat_split (particularly the np.issubdtype line).

The easiest fix is to cast that field as an int.  I will put in a pr for this issue this evening.  In the meantime, you can modify the function and it should work.  This is the only line that changes:
    `week = int(field.dt.isocalendar().week) if hasattr(field.dt, 'isocalendar') else int(field.dt.week)`


### Fixed function
```python
def add_datepart(df, field_name, prefix=None, drop=True, time=False):
    ""Helper function that adds columns relevant to a date in the column `field_name` of `df`.""
    make_date(df, field_name)
    field = df[field_name]
    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))
    attr = ['Year', 'Month', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',
            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']
    if time: attr = attr + ['Hour', 'Minute', 'Second']
    for n in attr: df[prefix + n] = getattr(field.dt, n.lower())
    # Pandas removed `dt.week` in v1.1.10
    week = int(field.dt.isocalendar().week) if hasattr(field.dt, 'isocalendar') else int(field.dt.week)
    df.insert(3, prefix+'Week', week)
    mask = ~field.isna()
    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,None)
    if drop: df.drop(field_name, axis=1, inplace=True)
    return df
```

",ah work version next version old version sorry comment removed fix work week field compatible particularly line easiest fix cast field put issue evening modify function work line week else fixed function python helper function relevant date column field prefix prefix ate time prefix removed week else week mask prefix mask none drop return,issue,positive,positive,neutral,neutral,positive,positive
760757092,"Thanks @Isaac-Flath - As of this morning, I'm still able to repro on both gradient and colab.

Could you send over your versions and dtypes please?

<img width=""416"" alt=""Screenshot 2021-01-15 at 08 39 47"" src=""https://user-images.githubusercontent.com/637130/104701973-45aba400-570d-11eb-9c32-895f3eac4012.png"">

<img width=""557"" alt=""Screenshot 2021-01-15 at 08 33 48"" src=""https://user-images.githubusercontent.com/637130/104700979-e5b4fd80-570c-11eb-870a-e82362bfaa90.png"">",thanks morning still able gradient could send please,issue,positive,positive,positive,positive,positive,positive
760751208,"Nice!
Probably make the dosctring one liner, and put the rest on a markdown cell above.",nice probably make one liner put rest markdown cell,issue,negative,positive,positive,positive,positive,positive
760655410,"I think it was just my addled mind...  I forgot to star the aug_tfms ... (result of too long a coding session)

 ",think mind forgot star result long session,issue,negative,negative,neutral,neutral,negative,negative
760614329,"Try this instead!  Please respond if this addresses your issue.
 
DATA2 = DATA.new(batch_tfms=[Normalize.from_stats(*imagenet_stats), *aug_transforms()])

![MNIST dataloader issue](https://user-images.githubusercontent.com/6256508/104675860-e5d0e100-56ab-11eb-9724-a290f3c661ca.png)
",try instead please respond issue data issue,issue,negative,neutral,neutral,neutral,neutral,neutral
760496334,By default the dataloader will have train/val datasets. you can then add a test dataset (without labels).,default add test without,issue,negative,neutral,neutral,neutral,neutral,neutral
760316839,Thanks a lot. This is of great help,thanks lot great help,issue,positive,positive,positive,positive,positive,positive
760300783,"As you are no using the text learner, pass the `ModelResetter` Callback first.  Would you mind sharing a link to the nb? (don't want to re write all that to try)
Another solution is to call reset on the model, after sending it to cuda.
![image](https://user-images.githubusercontent.com/18441985/104618998-ae533c00-568d-11eb-8db5-ce98ec9fdf7a.png)
The hidden state is not a parameter of the model (no gradient). So when you do `.cuda()` on the model, it doe snot find the hidden state in the registered params, so it stays on the CPU.
Normally, when you use the pre-built `text_learner` you automatically get the `ModelResetter` callback, that will do `reset` before start the training. (and after each epoch.",text learner pas first would mind link want write try another solution call reset model sending image hidden state parameter model gradient model doe snot find hidden state registered stay normally use automatically get reset start training epoch,issue,negative,positive,neutral,neutral,positive,positive
760283933,"Many thanks for your response. I tried it using a dls also but facing same error

![bug](https://user-images.githubusercontent.com/39881731/104614486-4eb95880-56ae-11eb-929f-bcfe3d51314c.jpg)
",many thanks response tried also facing error bug,issue,negative,positive,positive,positive,positive,positive
760261753,"I think this is tricky. Try with an actual `dls` on the gpu before calling the forward method.
I think the Learner is initalizing the hidden state on the device of the dataloader, as there is `None`, it is putting the tensors on the CPU.",think tricky try actual calling forward method think learner hidden state device none,issue,negative,negative,neutral,neutral,negative,negative
759340860,"I think it would be nice if calling `validate` would log the correct results (rather fix the logging through `validate`, instead of deactivating it).",think would nice calling validate would log correct rather fix logging validate instead,issue,positive,positive,positive,positive,positive,positive
759338400,"I'm thinking there's an issue in one of these 2 lines:
* [metrics at `after_batch`](https://github.com/fastai/fastai/blob/c3408c273b8a5bf7d90f17c04f3149e0e578e20f/fastai/callback/wandb.py#L91)
* [metrics at `after_epoch`](https://github.com/fastai/fastai/blob/c3408c273b8a5bf7d90f17c04f3149e0e578e20f/fastai/callback/wandb.py#L112)

My guess is that some of these metrics are either not calculated (and set to 0) or are named differently (maybe `loss` instead of `valid_loss`).

Based on the issue we can either tackle it in the logger or in the `validate` function.",thinking issue one metric metric guess metric either calculated set differently maybe loss instead based issue either tackle logger validate function,issue,negative,neutral,neutral,neutral,neutral,neutral
759171481,"What a pity, due to IP reason I can't open-sourcing the project. I can confirm that W&B callback works well on other lesson notebooks. Closing this now since it's not a common issue, debugging it on my own. I will share any insights that might have caused me the problem.",pity due reason ca project confirm work well lesson since common issue share might problem,issue,negative,negative,negative,negative,negative,negative
759101481,"Thank you so much for addressing both questions, this is very helpful. I will try this out!",thank much helpful try,issue,positive,positive,positive,positive,positive,positive
758905090,"@jph00 would you be so kind as to release a new version? Would be super helpful for us, because we're depending on the above changes :) Thanks a lot!",would kind release new version would super helpful u depending thanks lot,issue,positive,positive,positive,positive,positive,positive
758861639,"> For this one I think it might be good to assume keyword arguments apply to train, and can be overridden for the validation set by starting with 'val_'.

I like it. Let's leave `shuffle_train` as well for now, but have it raise a deprecation warning if not `None`, and have it just set `shuffle`. How does that sound?",one think might good assume apply train validation set starting like let leave well raise deprecation warning none set shuffle sound,issue,positive,positive,positive,positive,positive,positive
758861039,"Ahhhh. I wasn’t sure on that one. Thanks for catching! Good to know for in
the future

On Tue, Jan 12, 2021 at 1:44 PM Jeremy Howard <notifications@github.com>
wrote:

> (BTW a PR with a label appears in the changelog, regardless of whether
> there's an issue too)
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3137#issuecomment-758860240>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV4TEH2LOMV4J42K7WTSZSKB3ANCNFSM4VZWPGSA>
> .
>
",sure one thanks catching good know future tue wrote label regardless whether issue thread reply directly view,issue,positive,positive,positive,positive,positive,positive
758860240,"(BTW a PR with a label appears in the changelog, regardless of whether there's an issue too)",label regardless whether issue,issue,negative,neutral,neutral,neutral,neutral,neutral
758860086,We don't normally have docs changes in the changelog - and I'd rather not have stuff in issues that aren't actionable.,normally rather stuff actionable,issue,negative,positive,positive,positive,positive,positive
758849876,"Thanks. I'm going to rename `wks` back to what it was, since there's no reason for this breaking change AFAICT.",thanks going rename back since reason breaking change,issue,negative,positive,neutral,neutral,positive,positive
758778469,"Sure, let's go with the subclassing option. At this stage, It's probably easiest to just start a new PR fresh. I will close this one and re-open tonight. Let me know if any concerns with that strategy.",sure let go option stage probably easiest start new fresh close one tonight let know strategy,issue,positive,positive,positive,positive,positive,positive
758613394,"> @juliangilbey Just to help with writing this, why are you trying to shuffle the validation set? I wouldn't think we would want to drop the last batch on the validation set so making sure.

Hi @marii-moe I wanted to run `dls.valid.show_batch()` to check that things looked OK in the validation set. Unfortunately, the original data is very nicely ordered, so I only see data instances from one class.  Being able to shuffle the validation set would help for this.",help writing trying shuffle validation set would think would want drop last batch validation set making sure hi run check validation set unfortunately original data nicely ordered see data one class able shuffle validation set would help,issue,positive,positive,positive,positive,positive,positive
758572708,"@ViswanathRavindran your version is outdated, you need to update to the latest fastai, fastcore, wwf and timm. (the bug I reported is fixed, potentially you have a different one)",version outdated need update latest bug fixed potentially different one,issue,negative,positive,neutral,neutral,positive,positive
758571480,"The issue still persists as of today while installing 2.2.0, could you please look into it. For now I have installed 2.1.8",issue still today could please look,issue,negative,neutral,neutral,neutral,neutral,neutral
758526612,"Try this:
```python
class Jitter(Transform):
    def __init__(self, magnitude=0.4): 
        self.magnitude = magnitude
        
    def encodes(self, img: TensorImage):
        return img + ((torch.rand_like(img)-0.5)*self.magnitude*2)
```

I would recommend checking the [vision notebook](https://github.com/fastai/fastai/blob/master/nbs/09_vision.augment.ipynb) to do it.
For your second question: https://gist.github.com/tcapelle/25adfa75eb99a5e249f7d78f5131b967",try python class jitter transform self magnitude self return would recommend vision notebook second question,issue,positive,neutral,neutral,neutral,neutral,neutral
758522170,"Awesome, focal loss is so useful, didn't we had them at some point on V1?",awesome focal loss useful point,issue,positive,positive,positive,positive,positive,positive
758362300,"That looks pretty good! What do you think Patrick?


On Mon, Jan 11, 2021, at 6:24 PM, Patrick Ford wrote:
> 

> Subclassing is certainly possible. The best way I can think to include is like so:

> `class FocalLossFlat(CrossEntropyLossFlat):
    """"""
    Same as CrossEntropyLossFlat but with focal paramter, `gamma`. From  Lin et al. in this paper
    Focal loss is introduced by Lin et al. in https://arxiv.org/pdf/1708.02002.pdf. Note the class
    weighting factor in that paper, alpha, can be implemented through pytorch `weight` argument.
    """"""
    y_int = True
    @use_kwargs_dict(keep=True, weight=None, ignore_index=-100, reduction='mean')
    def __init__(self, *args, gamma=2, axis=-1, **kwargs):
        self.gamma = gamma
        if 'reduction' in kwargs: self.reduce = kwargs.pop('reduction')
        super().__init__(*args, reduction='none', axis=axis, **kwargs)
    def __call__(self, inp, targ, **kwargs):
        ce_loss = super().__call__(inp, targ, **kwargs)
        pt = torch.exp(-ce_loss)
        fl_loss = (1-pt)**self.gamma * ce_loss
        return fl_loss.mean() if self.reduce == 'mean' else fl_loss.sum() if self.reduce == 'sum' else fl_loss
`

> —
> You are receiving this because your review was requested.
> Reply to this email directly, view it on GitHub <https://github.com/fastai/fastai/pull/3144#issuecomment-758351118>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AACUW54HW2NTHTKIWKYILSLSZOXGXANCNFSM4V4XQ6RQ>.

",pretty good think mon ford wrote certainly possible best way think include like class focal gamma lin al paper focal loss lin al note class weighting factor paper alpha weight true self gamma super self super return else else review reply directly view,issue,positive,positive,positive,positive,positive,positive
758352030,"@jph00 For this one I think it might be good to assume keyword arguments apply to train, and can be overridden for the validation set by starting with 'val_'. The key idea below: 
```
default_kwargs = {'bs':bs,'n':None}
def create_dl(): #place holder for creating dataloaders
val_kwargs={k[4:]:v for k,v in kwargs.items() if k.startswith('val_')} #implmenting this is the key idea
#below validation set only
dls = [ create_dl(**merge(kwargs,default_kwargs,val_kwargs,dl_kwargs[i]) ) for i in range(num_dls) ]
```

Here is a more complete gist for my idea: https://gist.github.com/marii-moe/7374ee9d59400f85b17dc54b7a2c4af0

Here is the original: https://github.com/fastai/fastai/blob/dded7854017ecfebe8b70e0674915e7b50f134c5/fastai/data/core.py#L207

This would mean removing 'shuffle_train' which has been part of the api as far back as I could track in fastai_dev/fastai2. `kwargs` was originally included in creating the validation dataloader, but more recently was removed, so less sure about including that one as part of the merge. Unable to find info on why kwargs is not included as part of creating validation dataloaders, but it could have been to simplfy things. Here is the commit that changed it though: https://github.com/fastai/fastai/commit/a4e2456420832f9507924d69e73a62a0ac0c4571#diff-b881fa2851a7d60fe30b52d6cd1bc25cd510f0b9ac30de516cd01c3de05af1cbL166

It is important to put all in a `merge`, as this was we don't end up passing two of the same keyword argument.",one think might good assume apply train validation set starting key idea none place holder key idea validation set merge range complete gist idea original would mean removing part far back could track originally included validation recently removed le sure one part merge unable find included part validation could commit though important put merge end passing two argument,issue,positive,positive,positive,positive,positive,positive
758351118,"Subclassing is certainly possible. The best way I can think to include is like so:

```
class FocalLossFlat(CrossEntropyLossFlat):
    """"""
    Same as CrossEntropyLossFlat but with focal paramter, `gamma`. Focal loss is introduced by Lin et al. in 
    https://arxiv.org/pdf/1708.02002.pdf. Note the class weighting factor in the paper, alpha, can be implemented 
    through pytorch `weight` argument.
    """"""
    y_int = True
    @use_kwargs_dict(keep=True, weight=None, ignore_index=-100, reduction='mean')
    def __init__(self, *args, gamma=2, axis=-1, **kwargs):
        self.gamma = gamma
        if 'reduction' in kwargs: self.reduce = kwargs.pop('reduction')
        super().__init__(*args, reduction='none', axis=axis, **kwargs)
    def __call__(self, inp, targ, **kwargs):
        ce_loss = super().__call__(inp, targ, **kwargs)
        pt = torch.exp(-ce_loss)
        fl_loss = (1-pt)**self.gamma * ce_loss
        return fl_loss.mean() if self.reduce == 'mean' else fl_loss.sum() if self.reduce == 'sum' else fl_loss
```",certainly possible best way think include like class focal gamma focal loss lin al note class weighting factor paper alpha weight true self gamma super self super return else else,issue,positive,positive,positive,positive,positive,positive
758328608,"@juliangilbey Just to help with writing this, why are you trying to shuffle the validation set? I wouldn't think we would want to drop the last batch on the validation set so making sure. ",help writing trying shuffle validation set would think would want drop last batch validation set making sure,issue,negative,positive,positive,positive,positive,positive
758015624,"Improved visualization:

```
import wandb
from fastai.callback.wandb import WandbCallback
from fastai.vision.all import *


def label_func(f):
    return f[0].isupper()


path = untar_data(URLs.PETS)
files = get_image_files(path / ""images"")
dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))
wandb.init()
learn = cnn_learner(dls, resnet34, metrics=[accuracy, error_rate], cbs=[
    WandbCallback(log_model=False)])

learn.fit_one_cycle(3, slice(0.001, 0.03))

val_res = dict(zip([""valid_loss"", ""accuracy"", ""error_rate""], learn.validate()))
print(val_res)
wandb.log(val_res, commit=True)
```

![image](https://user-images.githubusercontent.com/31695/104199758-24566980-5428-11eb-860d-67235c5ae352.png)

run ID: er30qr43/hearty-violet-26",visualization import import import return path path path learn accuracy slice zip accuracy print image run id,issue,negative,neutral,neutral,neutral,neutral,neutral
758005411,"@borisdayma 

Here you go:

```
import wandb
from fastai.callback.wandb import WandbCallback
from fastai.vision.all import *


def label_func(f):
    return f[0].isupper()


path = untar_data(URLs.PETS)
files = get_image_files(path / ""images"")
dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))
wandb.init()
learn = cnn_learner(dls, resnet34, metrics=[accuracy, error_rate], cbs=[
    WandbCallback(log_model=False)])

learn.fit_one_cycle(3, slice(0.001, 0.03))

learn.validate()
```

The issue here is also `learn.validate()`. This is logging bogus values to wandb. ",go import import import return path path path learn accuracy slice issue also logging bogus,issue,negative,neutral,neutral,neutral,neutral,neutral
757962045,"@tumbleintoyourheart I can't confirm this, wandb is working for me. If you provide an example that I can run (with all imports, variables etc.), I can give it a try here, to see if there's a problem specific to your code. ",ca confirm working provide example run give try see problem specific code,issue,negative,neutral,neutral,neutral,neutral,neutral
757771432,"I would separate them with a partial or a sub class.
I would also add tests for different cases. (multi label, etc), adding a ref to the paper to the docs is also nice. The math formula in LaTeX would be an extra =)",would separate partial sub class would also add different label ref paper also nice math formula latex would extra,issue,negative,positive,positive,positive,positive,positive
757571349,"Yes, thank you! I was using a lagged forked version unbeknownst. 

I've fiddled around with trying to combine focal loss and cross entropy loss and I think this will work.. The challenge is with the `reduction` argument. If focal loss is desired, I believe it has to be cached in another parameter which I've called `self.reduce` because `nn.CrossEntropyLoss` needs to be called with `reduction = 'none'` first so a tensor is returned that be operated on elementwise. 

```
@delegates()
class CrossEntropyLossFlat(BaseLoss):
    """"""
    Same as `nn.CrossEntropyLoss`, but flattens input and target. If `gamma` is > 0 then this loss function
    is (unweighted) focal loss
    """"""
    y_int = True
    @use_kwargs_dict(keep=True, weight=None, ignore_index=-100, reduction='mean')
    def __init__(self, *args, gamma=0, axis=-1, **kwargs):
        self.gamma = gamma
        if 'reduction' in kwargs: self.reduce = kwargs.pop('reduction')
        super().__init__(nn.CrossEntropyLoss, *args, reduction='none', axis=axis, **kwargs)
    def __call__(self, inp, targ, **kwargs):
        ce_loss = super().__call__(inp, targ, **kwargs)
        pt = torch.exp(-ce_loss)
        fl_loss = (1-pt)**self.gamma * ce_loss
        return fl_loss.mean() if self.reduce== 'mean' else fl_loss.sum() if self.reduce== 'sum' else fl_loss

    def decodes(self, x):    return x.argmax(dim=self.axis)
    def activation(self, x): return F.softmax(x, dim=self.axis)
```

If you could opine on whether this is preferred to having a separate class, or if you think there's a better way, that would be most appreciated.",yes thank lagged forked version unbeknownst around trying combine focal loss cross entropy loss think work challenge reduction argument focal loss desired believe another parameter need reduction first tensor returned class input target gamma loss function unweighted focal loss true self gamma super self super return else else self return activation self return could opine whether preferred separate class think better way would,issue,positive,positive,positive,positive,positive,positive
757551555,"Sounds like you might be working from an old version of fastai? log_args isn't used in the current version.

The line you showed doesn't look too long to me - feel free to rename things if you like though.

I know the current flatten CE loss function doesn't have focal loss - I'm wondering, however, if it should be added as a parameter, rather than creating a new loss function (since cross entropy loss is a special case of focal loss).",like might working old version used current version line look long feel free rename like though know current flatten ce loss function focal loss wondering however added parameter rather new loss function since cross entropy loss special case focal loss,issue,negative,positive,positive,positive,positive,positive
757551075,"I do not need `log_args` but the notebook that I was updating has `log_args` in many cells and it is not in my environment which has fastcore 1.3.19. So the notebook is not runnable in the environment which I thought might be needed for the diffs. But I was able to handle the diffs using the github.com UI (VSC doesn't seem to allow me to edit jupyter notebook as json anymore).

I can elongate lines and use ternary operator but it seems excessively long in my IDE:
```
return focal_loss.mean() if self.reduction == 'mean' else focal_loss.sum() if self.reduction == 'sum' else focal_loss
```
I suppose I could use an abbreviation for `focal_loss` to shorten if you'd prefer.

`CrossEntropyLossFlat` doesn't currently support focal loss. Here's what it looks like. 
```
class CrossEntropyLossFlat(BaseLoss):
    ""Same as `nn.CrossEntropyLoss`, but flattens input and target.""
    y_int = True
    @use_kwargs_dict(keep=True, weight=None, ignore_index=-100, reduction='mean')
    def __init__(self, *args, axis=-1, **kwargs): super().__init__(nn.CrossEntropyLoss, *args, axis=axis, **kwargs)
    def decodes(self, x):    return x.argmax(dim=self.axis)
    def activation(self, x): return F.softmax(x, dim=self.axis)
```







",need notebook many environment notebook runnable environment thought might able handle seem allow edit notebook elongate use ternary operator excessively long ide return else else suppose could use abbreviation shorten prefer currently support focal loss like class input target true self super self return activation self return,issue,positive,positive,positive,positive,positive,positive
757549247,"Why do you need `log_args`? Do you have the latest versions of nbdev and fastcore?

Could you please try to reduce the vertical space your code is using, e.g. by using the ternary operator for the return, and using a wider line width?

I haven't looked closely, but is there an option to include focal loss in the flattened cross entropy loss directly?",need latest could please try reduce vertical space code ternary operator return line width closely option include focal loss cross entropy loss directly,issue,negative,positive,positive,positive,positive,positive
757101466,"I made the change and I also changed

`dicom_dataframe.head(2).T.head(8)`

to

`dicom_dataframe.head(2).T.tail(5)`

so you can see how the window choice affects the `img_pct_window`",made change also see window choice,issue,negative,neutral,neutral,neutral,neutral,neutral
756832847,"Not really... It fixes your particular issue: `ti == tm` but it misses others. I am pretty noob on all this subclassing issues. I am figuring out.
![image](https://user-images.githubusercontent.com/18441985/104035695-bc5b1580-51d2-11eb-8315-ef3e745fafd6.png)
",really particular issue ti pretty image,issue,negative,positive,positive,positive,positive,positive
756822754,"Thanks @tcapelle for the suggestion. I saw the most recent commit to Main branch (that you made) added this. So, is it safe to assume that this is resolved if pulling from Main branch?",thanks suggestion saw recent commit main branch made added safe assume resolved main branch,issue,positive,positive,positive,positive,positive,positive
756732850,"I am trying to solve this issue, but it is pretty hard. Debugging `state_dict'`s is not very practical....
I really don't get why this is happening.
You can put some save/load in between and does not work either.
```python
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224),shuffle_train= False)
learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.save('before_fit')
learn.fit(1)

learn.load('before_fit')
learn.fit(1)
```
I don't think is the `lr_find`.
![image](https://user-images.githubusercontent.com/18441985/104021192-aa6f7780-51be-11eb-9a02-6d67f52f0c28.png)

",trying solve issue pretty hard practical really get happening put work either python path path false learn think image,issue,positive,negative,neutral,neutral,negative,negative
756732041,"I’ve already done so

On Fri, Jan 8, 2021 at 2:57 AM Marcel Ackermann <notifications@github.com>
wrote:

> @muellerzr <https://github.com/muellerzr> Sorry for not providing more
> details! I believe it's the same error, because it's with a model from
> timm_learner, so I am closing this as well. Thank you for the fast fix!
> Could you also submit a new version to pypi?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3134#issuecomment-756609193>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV4Q4ZR4YUNBXJCBGXTSY23G3ANCNFSM4VZJJVFA>
> .
>
",already done marcel wrote sorry providing believe error model well thank fast fix could also submit new version reply directly view,issue,negative,negative,neutral,neutral,negative,negative
756705667,"I was trying to shuffle the validation set (I had a good reason to), but realised that even if the `shuffle` argument did as it said, it would still not shuffle the validation set, only the training set. So I found a different (perhaps clunky) way to do what I wanted to do. But if someone didn't want to shuffle the training set for some reason, `shuffle=False` would not work either, so the bug definitely remains, though it's a pretty small one.",trying shuffle validation set good reason even shuffle argument said would still shuffle validation set training set found different perhaps way someone want shuffle training set reason would work either bug definitely remains though pretty small one,issue,positive,positive,positive,positive,positive,positive
756670229,"try this:
```
import numpy as np
from fastai.vision.all import *
from fastai.torch_core import TensorImage
from fastai.torch_core import TensorMask

for o in Tensor.__eq__,:
    TensorBase.register_func(o, TensorMask, TensorImageBase)
    TensorBase.register_func(o, TensorImageBase, TensorMask)


size = (3, 10, 10)
ti = TensorImage(np.random.uniform(size=size))
tm = TensorMask(np.random.choice([0,1], size=size))

ti == tm
```",try import import import import size ti ti,issue,negative,neutral,neutral,neutral,neutral,neutral
756609193,"@muellerzr Sorry for not providing more details! I believe it's the same error, because it's with a model from `timm_learner`, so I am closing this as well. Thank you for the fast fix! Could you also submit a new version to pypi?  ",sorry providing believe error model well thank fast fix could also submit new version,issue,negative,negative,neutral,neutral,negative,negative
756573940,"> Hi,
> 
> I think this issue is known based on [Zachary's response on this thread](https://forums.fast.ai/t/chapter-13-learner-error/83114), but I didn't see a github issue for it explicitly
> 
> Versions:
> fastai : 2.2.1
> torch: 1.7.1
> fastcore: 1.3.16
> 
> Reproducible example:
> 
> ```
> import numpy as np
> from fastai.torch_core import TensorImage
> from fastai.torch_core import TensorMask
> 
> size = (3, 10, 10)
> ti = TensorImage(np.random.uniform(size=size))
> tm = TensorMask(np.random.choice([0,1], size=size))
> 
> ti == tm
> ```
> 
> Error:
> 
> ```
> TypeError                                 Traceback (most recent call last)
> <ipython-input-27-f607939df9b1> in <module>
>       6 tm = TensorMask(np.random.choice([0,1], size=size))
>       7 
> ----> 8 ti == tm
> 
> ~/.local/share/virtualenvs/fastai_modeling-wXHhCDlU/lib64/python3.7/site-packages/torch/tensor.py in wrapped(*args, **kwargs)
>      23         from torch.overrides import has_torch_function, handle_torch_function
>      24         if not all(type(t) is Tensor for t in args) and has_torch_function(args):
> ---> 25             return handle_torch_function(wrapped, args, *args, **kwargs)
>      26         try:
>      27             return f(*args, **kwargs)
> 
> ~/.local/share/virtualenvs/fastai_modeling-wXHhCDlU/lib64/python3.7/site-packages/torch/overrides.py in handle_torch_function(public_api, relevant_args, *args, **kwargs)
>    1066     raise TypeError(""no implementation found for '{}' on types that implement ""
>    1067                     '__torch_function__: {}'
> -> 1068                     .format(func_name, list(map(type, overloaded_args))))
>    1069 
>    1070 def has_torch_function(relevant_args: Iterable[Any]) -> bool:
> 
> TypeError: no implementation found for 'torch.tensor.eq' on types that implement __torch_function__: [<class 'fastai.torch_core.TensorImage'>, <class 'fastai.torch_core.TensorMask'>]
> ```
np.array(ti.cpu()) == np.array(tm.cpu())",hi think issue known based response thread see issue explicitly torch reproducible example import import import size ti ti error recent call last module ti wrapped import type tensor return wrapped try return raise implementation found implement list map type iterable bool implementation found implement class class,issue,negative,neutral,neutral,neutral,neutral,neutral
756533809,Was able to reproduce this and taking a look at it now. ,able reproduce taking look,issue,negative,positive,positive,positive,positive,positive
756485460,"@dreamflasher we need much more in order to be able to reproduce your issue, as what you've shown is simply not enough. This was a minor miss on the changelog, so the fix to the fastai head change has been added on there. Please provide us with how you are generating your model, etc. Are you using `cnn_learner`? `create_head` manually?",need much order able reproduce issue shown simply enough minor miss fix head change added please provide u generating model manually,issue,negative,positive,positive,positive,positive,positive
756482987,"@craine that's a breaking issue on my end based on how I wrote `timm_learner` at the time, so I would say unrelated to this :) (Related in the fact that cnn_learner changing broke it, but unrelated as this is something I need to fix over there) Can you open the issue here and I can get to it tommorow? https://github.com/walkwithfastai/walkwithfastai.github.io",breaking issue end based wrote time would say unrelated related fact broke unrelated something need fix open issue get,issue,negative,neutral,neutral,neutral,neutral,neutral
756481758,"I'm seeing the same exact issue all of the sudden:
RuntimeError: running_mean should contain 1024 elements not 2048.
https://colab.research.google.com/drive/1kY_qH-GCG9IiUhQmH0Gk3-IU338bD0Ea?usp=sharing

",seeing exact issue sudden contain,issue,negative,positive,positive,positive,positive,positive
756457230,"Can you show us how you're building your model? There were some minor breaking changes into how create_head works, so if you're trying to do the concat pooling, you no longer need to pass in 2x the amount of input features, it will do so automatically",show u building model minor breaking work trying longer need pas amount input automatically,issue,negative,negative,neutral,neutral,negative,negative
756427878,"Updated to the latest version, hopefully all good now. Thanks",latest version hopefully good thanks,issue,positive,positive,positive,positive,positive,positive
756396027,Can you please run `nbdev_build_lib` with the latest nbdev version?,please run latest version,issue,negative,positive,positive,positive,positive,positive
756316140,"I have the same issue when using the `foreground_acc` metric on a segmentation data loader.
`dataloaders = SegmentationDataLoaders.from_label_func(
    SEGMENTATION_IMAGE_DIR, 
    fnames = train_val_images,
    label_func = get_lung_mask,
    valid_pct=train_val_split,
    seed=42,
    codes=codes,
    batch_tfms=batch_transformations,
    item_tfms=item_transformations,
    bs=4)`

`learn = unet_learner(dataloaders, models.resnet34, metrics=[foreground_acc])`

Error:
`no implementation found for 'torch.tensor.eq' on types that implement __torch_function__: [<class 'fastai.torch_core.TensorImage'>, <class 'fastai.torch_core.TensorMask'>]`

",issue metric segmentation data loader learn error implementation found implement class class,issue,negative,neutral,neutral,neutral,neutral,neutral
756293237,"Let me do a test.
I'm scared of a side effect which will be that last step is uncommitted in colab until people call `wandb.finish()` (which is typically never done). This is not needed in scripts as it will be automatically called when it finishes.",let test side effect last step uncommitted people call typically never done automatically,issue,negative,positive,neutral,neutral,positive,positive
756276525,"@jph00 I can't reopen, would you be so kind? This fixes two issues – thanks for fixing one, I'd like to adjust this PR so that it fixes the other issue I linked to, thanks!",ca reopen would kind two thanks fixing one like adjust issue linked thanks,issue,positive,positive,positive,positive,positive,positive
756274890,"Actually, I see the same issue appears on lines 215-216 as well, if `shuffle` appears in `dl_kwargs[i]`.",actually see issue well shuffle,issue,negative,neutral,neutral,neutral,neutral,neutral
756268390,I fixed the smooth_loss issue this morning by setting the callback order. Feel free to reopen this or open a new PR if there's still an unresolved issue.,fixed issue morning setting order feel free reopen open new still unresolved issue,issue,positive,positive,positive,positive,positive,positive
756264809,Sorry just saw this - I fixed that this morning.,sorry saw fixed morning,issue,negative,negative,negative,negative,negative,negative
756190038,"This is the problem that I could not solve, and I described [here](https://github.com/fastai/fastai/pull/3043).

If I have to guess, I would say that this is not a problem with fastai nor captum, but with PyTorch and tensor subclasses. One solution is to override the in-place operation `.requires_grad_()` like so:

```python
class FooTensor(Tensor):
    def requires_grad_(self):
        self.requires_grad = True
        return self
```

What do you think @jph00?",problem could solve guess would say problem tensor one solution override operation like python class tensor self true return self think,issue,negative,positive,positive,positive,positive,positive
756184065,My english is not excellent but it is a first version. It may be better to put this notebooks elsewhere (examples??). Maybe move all tutorials there also? I would not mind if the professor zach could take a look and make comments. haven't yet decided what model to show on the ImageSeq 2 ImageSeq task. I don't want to make it to heavy.,excellent first version may better put elsewhere maybe move also would mind professor could take look make yet decided model show task want make heavy,issue,positive,positive,positive,positive,positive,positive
756149907,"@borisdayma How about this: https://github.com/fastai/fastai/pull/3129 – we can do the last empty log, but keeping the step_count – this solves it on our side too, and shouldn't change anything in your tests? I also included a fix for the above error. Do you approve?",last empty log keeping side change anything also included fix error approve,issue,negative,negative,neutral,neutral,negative,negative
756131006,"Just pulled the last fastai version and now I am getting this error with the above example:

```
Traceback (most recent call last):
  File ""wandbtest.py"", line 16, in <module>
    learn.fit_one_cycle(3, slice(0.001, 0.03))
  File ""/home/ubuntu/git/fastai/fastai/callback/schedule.py"", line 112, in fit_one_cycle
    self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 211, in fit
    self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 160, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 202, in _do_fit
    self._with_events(self._do_epoch, 'epoch', CancelEpochException)
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 160, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 196, in _do_epoch
    self._do_epoch_train()
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 188, in _do_epoch_train
    self._with_events(self.all_batches, 'train', CancelTrainException)
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 160, in _with_events
    try: self(f'before_{event_type}');  f()
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 166, in all_batches
    for o in enumerate(self.dl): self.one_batch(*o)
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 184, in one_batch
    self._with_events(self._do_one_batch, 'batch', CancelBatchException)
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 162, in _with_events
    self(f'after_{event_type}');  final()
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 141, in __call__
    def __call__(self, event_name): L(event_name).map(self._call_one)
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/fastcore/foundation.py"", line 154, in map
    def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/fastcore/basics.py"", line 641, in map_ex
    return list(res)
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/fastcore/basics.py"", line 631, in __call__
    return self.func(*fargs, **kwargs)
  File ""/home/ubuntu/git/fastai/fastai/learner.py"", line 145, in _call_one
    for cb in self.cbs.sorted('order'): cb(event_name)
  File ""/home/ubuntu/git/fastai/fastai/callback/core.py"", line 44, in __call__
    if self.run and _run: res = getattr(self, event_name, noop)()
  File ""/home/ubuntu/git/fastai/fastai/callback/wandb.py"", line 92, in after_batch
    wandb.log({'epoch': self._wandb_epoch, 'train_loss': to_detach(self.smooth_loss.clone()), 'raw_loss': to_detach(self.loss.clone()), **hypers}, step=s
elf._wandb_step)
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/fastcore/basics.py"", line 378, in __getattr__
    if attr is not None: return getattr(attr,k)
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/fastcore/basics.py"", line 378, in __getattr__
    if attr is not None: return getattr(attr,k)
  File ""/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py"", line 778, in __getattr__
    raise ModuleAttributeError(""'{}' object has no attribute '{}'"".format(
torch.nn.modules.module.ModuleAttributeError: 'Sequential' object has no attribute 'smooth_loss'
```

cc @jph00 was there a recent change that could explain this new error?",last version getting error example recent call last file line module slice file line file line fit file line try self file line file line try self file line file line file line try self file line enumerate file line file line self final file line self file line map map self return self file line return list file line return file line file line self noop file line file line none return file line none return file line raise object attribute object attribute recent change could explain new error,issue,negative,positive,neutral,neutral,positive,positive
755940644,"@glitt13 It's because `log_args` was removed in fastcore 1.3.5, so if you are using `fastai==2.0.19`, you need to also force `fastcore==1.3.2`.",removed need also force,issue,negative,neutral,neutral,neutral,neutral,neutral
755732204,"It looks like this solves the issue on our end, did you run it through your test suite? Shall I create a PR?",like issue end run test suite shall create,issue,positive,neutral,neutral,neutral,neutral,neutral
755618698,what do you think about moving all tutorials to one folder? So users can submit more tutorials.,think moving one folder submit,issue,negative,neutral,neutral,neutral,neutral,neutral
755613017,"Got it, thanks!
![image](https://user-images.githubusercontent.com/18441985/103815004-f60d0e80-5062-11eb-96a2-0fe438eb4534.png)
It is nice for us using jupyter, but for the regular folk using VSCode it may be more complicated.",got thanks image nice u regular folk may complicated,issue,positive,positive,neutral,neutral,positive,positive
755605678,"We're not doing that, Jeremy will be working on the doc strings at some point. In the meantime just use nbdev if you're not satisfied with the vanilla. (Literally just do `pip install nbdev` and `doc()` will show the pretty doc)",working doc point use satisfied vanilla literally pip install doc show pretty doc,issue,positive,positive,positive,positive,positive,positive
755581677,"> > Fastai's docstring are minimal, one liners. The documentation is on the website or the notebooks where the function is defined. This is intended:
> > https://docs.fast.ai/learner.html#Learner.validate
> 
> @tcapelle , in this case, wouldn't it make sense to put links (URLs) to the documentation in docstrings?

This is already possible. fastai promotes installing `nbdev`, and doing `doc(myfunc)` in nbdev will pull up the documentation, a link to the source code, and a link to it's documentation",minimal one documentation function defined intended case would make sense put link documentation already possible doc pull documentation link source code link documentation,issue,negative,negative,neutral,neutral,negative,negative
755530838,@jph00 this is good to go now. It seems to also have picked up some other notebooks needing to be cleaned with the \r from nbdev,good go also picked needing,issue,negative,positive,positive,positive,positive,positive
755482920,"Have you tried the latest master version of fastai? Do you know if this problem is a captum problem or a fastai problem? Maybe you could ask the captum folks to take a look, since we're not captum experts here!",tried latest master version know problem problem problem maybe could ask take look since,issue,negative,positive,positive,positive,positive,positive
755479607,"I'll close this since it's largely resolved, but feel free to open a new issue or PR if you have suggestions for making custom loss functions more convenient",close since largely resolved feel free open new issue making custom loss convenient,issue,negative,positive,positive,positive,positive,positive
755474552,@tcapelle I'll wait until you've done the tutorial notebook so I can see which bits of that we might want to merge into this nb.,wait done tutorial notebook see might want merge,issue,negative,neutral,neutral,neutral,neutral,neutral
754932369,"> Maybe do the `if self.training:` guard also in `def after_epoch(self):`?

I don't think it would work because we want to log validation metrics there, for which `self.training=False`.

I believe the solution may be to remove [this line](https://github.com/fastai/fastai/blob/870409f78df41e04a2be378197e41f8c2e1ab371/fastai/callback/wandb.py#L123).
Its purpose is to force commit the last data at the end of training (happens automatically in a script but not necessarily in notebooks), which also auto-increment wandb internal step.

I think we would want to log the validation data (though it may overwrite previous validation data logged for this step, which should be the same unless the data changed).",maybe guard also self think would work want log validation metric believe solution may remove line purpose force commit last data end training automatically script necessarily also internal step think would want log validation data though may overwrite previous validation data logged step unless data,issue,positive,negative,neutral,neutral,negative,negative
754644260,"We use `learn.validate()` for two reasons

1) To get the results of the best run and log this to wandb (wandb shows the last result, but as we are keeping the best model for future use, we want to see the best numbers in wandb (according to validation metric)).
2) We do multiple training runs and want to average metrics across runs (monte-carlo cross-validation), and at the end report those average metrics (wandb doesn't support two levels of grouping so far, we need one for MCCV runs and the other for multiple active learning runs)

In the example above we don't do any logging so far, and the error already occurs. But yes, likely the next issue will be to do the logging without screwing up wandb. But let's start with fixing `learn.validate()` – it looks to me that during this no logging to wandb should be the default? 

Currently 
```
def after_batch(self):
        ""Log hyper-parameters and training loss""
        if self.training:
```

Maybe do the `if self.training:` guard also in `def after_epoch(self):`?",use two get best run log last result keeping best model future use want see best according validation metric multiple training want average metric across end report average metric support two grouping far need one multiple active learning example logging far error already yes likely next issue logging without screwing let start fixing logging default currently self log training loss maybe guard also self,issue,positive,positive,positive,positive,positive,positive
754520583,I am currently making a tutorial notebook.,currently making tutorial notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
754210279,"Thanks a lot for this @dreamflasher 

I actually never used this function.
I'll need to take a look to understand the difference between `validate` and validation from the `fit` loop.
I imagine you would expect to log validation metrics, though it's tricky to know what should be done here as you could have the same metrics already associated to the last step from your `fit` loop.",thanks lot actually never used function need take look understand difference validate validation fit loop imagine would expect log validation metric though tricky know done could metric already associated last step fit loop,issue,positive,positive,positive,positive,positive,positive
754174274,"Pointed out by Zachary Mueller that this is already fixed in master. Rerunning the code using master fixes the issue:

!pip install git+https://github.com/fastai/fastai
!pip install git+https://github.com/fastai/fastcore",pointed already fixed master code master issue pip install pip install,issue,negative,positive,neutral,neutral,positive,positive
754162531,"@jph00 Please reopen

@borisdayma Here's a reproducible example of what's failing:

```
import wandb
from fastai.callback.wandb import WandbCallback
from fastai.vision.all import *


def label_func(f):
    return f[0].isupper()


path = untar_data(URLs.PETS)
files = get_image_files(path / ""images"")
dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))
wandb.init()
learn = cnn_learner(dls, resnet34, metrics=error_rate, cbs=[WandbCallback(log_model=False)])

learn.fit_one_cycle(3, slice(0.001, 0.03))

learn.validate()
```

The problem is with `learn.validate()` – took me a while to extract this.",please reopen reproducible example failing import import import return path path path learn slice problem took extract,issue,negative,neutral,neutral,neutral,neutral,neutral
754139944,"Peiyi Hong made an compelling analysis and provides a workaround on the forums.

```
It seems that == operation between <class 'fastai.torch_core.TensorImageBW'> and <class 'fastai.torch_core.TensorCategory'> is broken or missing.

Metric accuracy use == for element-wise comparison, so you can replace accuracy with a metric without using == to let your learner compute accuracy.

For example, like this:

def my_accuracy(y_pred, y_true):
    y_pred = torch.argmax(y_pred, axis=1).float()
    equ = [1 if i == t else 0 for i, t in zip(y_pred, y_true)]
    return np.mean(equ)

learn = Learner(dls, simple_cnn, loss_func=CrossEntropyLossFlat(), metrics=my_accuracy)


```",hong made compelling analysis operation class class broken missing metric accuracy use comparison replace accuracy metric without let learner compute accuracy example like else zip return learn learner,issue,negative,negative,negative,negative,negative,negative
753425788,I'm closing this due to lack of activity - feel free to reopen if needed.,due lack activity feel free reopen,issue,negative,positive,positive,positive,positive,positive
753216596,"ref: https://github.com/fastai/fastai/issues/2583

In the meantime, you can always do something like this:

```python
cols = df.columns.drop('date') # or any columns you know are not continuous
df[cols] = df[cols].apply(lambda row: row.astype(float))
```",ref always something like python know continuous lambda row float,issue,negative,neutral,neutral,neutral,neutral,neutral
753215289,"Thanks for making this issue, @NouamaneTazi.  I also am experiencing this issue. Thought I was going crazy.",thanks making issue also issue thought going crazy,issue,negative,negative,negative,negative,negative,negative
752976788,"Hi, 
just tested the lines of code below on Colab GPU. 
fastai (2.1.10)
nbdev (1.1.15) 
fastcore (1.3.13)

```
!pip install -U fastbook
import fastbook
fastbook.setup_book()

from fastbook import *
from fastai.basics import *
from fastai.vision.all import *
from fastai.vision.core import *
from fastai.vision.data import *
from fastai.data.all import *

path = untar_data(URLs.CAMVID_TINY)
dls = SegmentationDataLoaders.from_label_func(
    path, bs=8, fnames = get_image_files(path/""images""),
    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}', 
    codes = np.loadtxt(path/'codes.txt', dtype=str)
)
learn = unet_learner(dls, resnet34, metrics=Dice())
learn.fine_tune(8)
```
This issue is not fixed. The output is exactly the same (20 frames), same errors. 

Only noticed difference:
```
/usr/local/lib/python3.6/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
    204             self.opt.set_hypers(lr=self.lr if lr is None else lr)
    205             self.n_epoch = n_epoch
--> 206             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
```
where line is **206** against prior **205**. ",hi tested code pip install import import import import import import import path path lambda learn issue fixed output exactly difference fit self none else line prior,issue,negative,positive,positive,positive,positive,positive
752657439,"Thanks @muellerzr . One of the best things about the fast.ai community is the positive and supportive tone with which you folks respond to questions / problems on here and on the forum, even if an issue is incorrectly classified :) On behalf of all users, we appreciate it. 

I was able to get a working version of Focal Loss by digging into the source a bit and seeing how fast.ai builds loss classes. I'll leave the solution below in case anyone has a similar problem in the future. 

I haven't been able to get a version working using binary cross entropy / BCE with logits, which I think would be more appropriate for my problem. I think I'll try and start a discussion over on the forum, and hopefully facilitate some conversation around workflows for building / debugging loss functions in V2. It seems to be a bit trickier than with V1 given the PyTorch changes, etc.

```
class FocalLoss(Module):
    def __init__(self, alpha=1, gamma=2, axis=1, reduction='mean'):
        self.alpha = alpha 
        self.gamma = gamma 
        self.axis = axis
        self.reduction = reduction 
    
    def forward(self, output, target):
        ce_loss = CrossEntropyLossFlat(axis=self.axis, reduction='none')(output, target)
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss
        
        if self.reduction == 'mean': return focal_loss.mean()
        elif self.reduction == 'sum': return focal_loss.sum()
        else: return focal_loss
        
    def decodes(self, x):    return x.argmax(dim=self.axis)
    def activation(self, x): return F.softmax(x, dim=self.axis)
```",thanks one best community positive supportive tone respond forum even issue incorrectly classified behalf appreciate able get working version focal loss digging source bit seeing loss class leave solution case anyone similar problem future able get version working binary cross entropy think would appropriate problem think try start discussion forum hopefully facilitate conversation around building loss bit given class module self alpha gamma axis reduction forward self output target output target return return else return self return activation self return,issue,positive,positive,positive,positive,positive,positive
752201964,"I saw many notebooks are using `num_features_model` to get `nf` and then multiplying it by 2. But it would be better, if this is done automatically, inside `create_head` function. ",saw many get multiplying would better done automatically inside function,issue,negative,positive,positive,positive,positive,positive
751909867,Issue was caused by a breaking change in `unet_learner` that was fixed in `cnn_learner` in regards to `store_attr`,issue breaking change fixed,issue,negative,positive,neutral,neutral,positive,positive
751891045,What is your version of fastcore and fastai? We can't do much without knowing this. It seems you may have an old version,version ca much without knowing may old version,issue,negative,positive,positive,positive,positive,positive
751890878,"Thanks to the new PyTorch version everything needs to be dispatched to a same ""Tensor Class"" for us to work with it (not fun!). Try inheriting `BaseLoss` rather than `nn.Module` in your loss function",thanks new version everything need tensor class u work fun try rather loss function,issue,positive,positive,positive,positive,positive,positive
751123909,"FYI @muellerzr if you look at the commit here something is adding a bunch of empty tags, which is going to make conflicts more likely, so you might want to remove whatever that is.",look commit something bunch empty going make likely might want remove whatever,issue,negative,negative,neutral,neutral,negative,negative
750947612,"> Im using fastai version 2.1.2

You're using an outdated fastai version @knightz33. 2.1.2 is from October, and I believe this issue was tackled around then.

It was, specifically here: https://github.com/fastai/fastai/blob/master/CHANGELOG.md#breaking-changes-1

@jph00 this can be closed",version outdated version believe issue tackled around specifically closed,issue,negative,negative,negative,negative,negative,negative
750606899,A better solution would be to use register_func to register whatever InvisibleTensor needs.,better solution would use register whatever need,issue,positive,positive,positive,positive,positive,positive
750469198,"The small change shouldn't break or slow working scripts at all as it would be a no-op on non-Windows platforms. Scripts on non-Windows platforms would not break, slow, or be affected in any way. 

That said, it may surprise Windows users who run code that forcibly set `num_workers` to non-zero or those who let fastai set the value. I think a printed warning and a do-what-i-mean-to-really-do-even-if-its-slower-than-linux-just-get-running-on-windows-fast corrective action is probably better than not working at all with the mysterious message in this issue. 

This might be easier to explain if I just sent in the PR. ",small change break slow working would would break slow affected way said may surprise run code forcibly set let set value think printed warning corrective action probably better working mysterious message issue might easier explain sent,issue,positive,positive,neutral,neutral,positive,positive
750459356,"Rather than allowing every subclass for every op, let's find a way to be more specific about letting particular combinations of classes opt in to allowing particular operations. ",rather every subclass every let find way specific particular class opt particular,issue,negative,positive,positive,positive,positive,positive
750458452,"This only impacts notebooks, I believe, and I wouldn't want to break (or slow) working scripts.",believe would want break slow working,issue,negative,negative,negative,negative,negative,negative
750430343,"@jph00 Would you take a PR to set and force `num_workers=0` on Windows with a warning printed that it was overridden if it was set? 

The `num_workers=0` thing isn't a terrible blocker and it would mean being able to run the tutorial notebooks out of the box on Windows without having to modify the notebooks. Reducing onboarding friction is always desirable.

As for maintenance burden drawback, would it be acceptable to have the removal milestone for this small piece of code be when WSL2 with CUDA/GPU access is released on stable Windows?",would take set force warning printed set thing terrible blocker would mean able run tutorial box without modify reducing friction always desirable maintenance burden drawback would acceptable removal milestone small piece code access stable,issue,negative,negative,negative,negative,negative,negative
750240676,"Problem solved!
The issue was that I had a folder in `C:\Users\Nouamane\Anaconda3\Lib\site-packages\fastai` called like this:
``` 
└───imports
        core.py
        torch.py
        __init__.py
``` 
I just deleted the `imports` folder and it resolved the problem. (Apparently uninstalling fastai and reinstalling it using pip or anaconda didn't delete it before)",problem issue folder like folder resolved problem apparently pip anaconda delete,issue,negative,positive,neutral,neutral,positive,positive
750035727,"Ok, so right now it is not possible to install specific version of fastai, only latests. (at least with pip).
For me the simplest solution is to pin fastcore in fastai `settings.ini`. Most of the broken dependencies comes from `fastcore`  peace of change. 
We should at least keep a version with pytorch 1.6 avilable on pip/conda.",right possible install specific version least pip solution pin broken come peace change least keep version,issue,negative,negative,negative,negative,negative,negative
749893727,"> @Kouin what are the exact fastai and fastcore versions you used for torch 1.6.0?


I could not exactly remmember the thorough information about my attempts
but I remember I used the instruction `conda install fastai -c fastai` to install fastai after installing torch by `conda install -c pytorch pytorch=1.6`

Now, I'm using torch1.7 with fastai2.1.8, fastcore 1.3.10. 
I temporarily solved by setting 'num_workers=0' to my dataloader",exact used torch could exactly thorough information remember used instruction install install torch install torch temporarily setting,issue,negative,positive,positive,positive,positive,positive
749888441,"> The versions in the Kaggle Kernel are:
> torch - 1.6.0
> fastcore - 1.3.2
> fastai - 2.0.19
> 
> Have you tried locally with these versions?

yes，i've tried torch 1.6 and 1.7 with corresponding fastai version",kernel torch tried locally tried torch corresponding version,issue,negative,neutral,neutral,neutral,neutral,neutral
749887400,"The versions in the Kaggle Kernel are:
torch - 1.6.0
fastcore - 1.3.2
fastai - 2.0.19

Have you tried locally with these versions?",kernel torch tried locally,issue,negative,neutral,neutral,neutral,neutral,neutral
749822707,"Since fastai uses fastrelease, Jeremy and I discussed putting this option in there, and when calling `make release` (how fastai pushes new releases) we can create the versions.txt file (or something similar). Thanks @tyoc213 for the suggestion",since option calling make release new create file something similar thanks suggestion,issue,positive,positive,positive,positive,positive,positive
749817723,"Proper docker containers for fastai and fastcore that are updated daily are available here: https://hub.docker.com/r/fastdotai/fastai

See here for more information: https://github.com/fastai/docker-containers#fastai",proper docker daily available see information,issue,negative,positive,positive,positive,positive,positive
749815705,"When running `from fastcore.all import *`, the function `delegates` is imported correctly. But it seems the way it's imported in fastai/torch_core.py doesnt work for me.
When I added that import to fastai/torch_core.py:
``` 
# Cell
from .imports import *
from .torch_imports import *
from fastcore.all import *
```

I get a different error:
```
    from fastai.vision.all import *
  File ""C:\Users\Nouamane\Anaconda3\lib\site-packages\fastai\vision\all.py"", line 1, in <module>
    from . import models
  File ""C:\Users\Nouamane\Anaconda3\lib\site-packages\fastai\vision\models\__init__.py"", line 1, in <module>
    from . import xresnet
  File ""C:\Users\Nouamane\Anaconda3\lib\site-packages\fastai\vision\models\xresnet.py"", line 12, in <module>
    from ...torch_basics import *
  File ""C:\Users\Nouamane\Anaconda3\lib\site-packages\fastai\torch_basics.py"", line 11, in <module>
    from .torch_core import *
  File ""C:\Users\Nouamane\Anaconda3\lib\site-packages\fastai\torch_core.py"", line 82, in <module>
    class ArrayBase(ndarray):
NameError: name 'ndarray' is not defined
```",running import function correctly way doesnt work added import cell import import import get different error import file line module import file line module import file line module import file line module import file line module class name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
749812504,"We include it as what that allows is partial sizes to be used, for instance we can do:
```python
emb_szs = {'workclass':100}
learn = tabular_learner(dls, layers=[200,100], emb_szs=emb_szs)
```
And it will still generate embeddings for the other variables, whereas yours would fail (it's a helpful guard)

@jph00 can close",include partial size used instance python learn still generate whereas would fail helpful guard close,issue,negative,negative,negative,negative,negative,negative
749810468,I tried updating and reinstalling all the packages. I still get the same error. Where is `delegates` supposed to be imported from?,tried still get error supposed,issue,negative,neutral,neutral,neutral,neutral,neutral
749807951,Can you update and try again? I can't recreate this,update try ca recreate,issue,negative,neutral,neutral,neutral,neutral,neutral
749803166,"I responded in your forum post as well: https://forums.fast.ai/t/classes-list-of-textlearner/83777/2

But it lives in `learn.dls.categorize.vocab`. It's not in `learn.dls.vocab` (as it would be for other applications using `CategoryBlock` or `MultiCategoryBlock`) as text has its own vocab. As a result we need to go to the direct transform

@jph00 can be closed",forum post well would text result need go direct transform closed,issue,negative,neutral,neutral,neutral,neutral,neutral
749280667,Sorry this took a while! Done now :) Looking forward to the tutorial...,sorry took done looking forward tutorial,issue,negative,negative,negative,negative,negative,negative
749273391,"This is super neat, but I think it's a bit to complex for this foundational function.

I like the changes to `create_head`, so let's keep those. But could you remove the changes in `create_cnn_model` so this becomes just a flag people pass in manually?",super neat think bit complex foundational function like let keep could remove becomes flag people pas manually,issue,positive,positive,neutral,neutral,positive,positive
749030698,I also get this error message following `from fastai.vision.all import *` despite having fastai `2.0.19`. I tried installing in my anaconda as follows:  `conda install -c fastai -c pytorch -c anaconda fastai gh anaconda`,also get error message following import despite tried anaconda install anaconda anaconda,issue,negative,neutral,neutral,neutral,neutral,neutral
748723686,Did you fix this issue? I am using Paperspace and still have the same error.,fix issue still error,issue,negative,neutral,neutral,neutral,neutral,neutral
748552365,"I would guess it happens when logging your validation data. If you have a call to `wandb.log`, make sure to use `commit=False`.

Feel free to share your code privately if you want me to take a closer look.
It's not always uploaded depending on your settings.",would guess logging validation data call make sure use feel free share code privately want take closer look always depending,issue,positive,positive,positive,positive,positive,positive
748288045,"It does run if I set the batch size to 4.  Perplexity was lower with that setting and fit_one_cycle than with a batch size of 8.  New to this so don't really understand that metric that well. 
Would a batch size of 4 be a better default so it runs on GPUs that don't have an immense amount of memory ?",run set batch size perplexity lower setting batch size new really understand metric well would batch size better default immense amount memory,issue,negative,positive,positive,positive,positive,positive
748196836,Has any solution to this been found yet? I am getting the same error as well.,solution found yet getting error well,issue,negative,neutral,neutral,neutral,neutral,neutral
748042126,"Sometimes it happens after the first epoch, no previous runs before, only one init call:

```
epoch     train_loss  valid_loss  accuracy  brier_score  ece       nll       err  time
0         7.291822    6.423790    0.891155  0.022018     0.056384  6.423790  0.122854           05:20     wandb: WARNING Step must only increase in log calls.  Step 232 < 233; dropping {'epoch': 1}.
```

I restored the original fastai code, removed all our custom wandb.log calls, and now the problem occurs after the first run. 
The 5th epoch finishes and then I get `wandb: WARNING Step must only increase in log calls.  Step 1164 < 1165; dropping {'epoch': 5}.`.
Also in this run we have multiple consecutive wandb.init calls – but it already happens in the first run (I can turn the multiple runs off, if that helps debugging).
Thank you so much for your continued help! Yes, the wandb run is: `imachines/mitl-regression-tests/90xkcy38`.
The code should be uploaded by default right?",sometimes first epoch previous one call epoch accuracy err time warning step must increase log step dropping original code removed custom problem first run th epoch get warning step must increase log step dropping also run multiple consecutive already first run turn multiple thank much continued help yes run code default right,issue,positive,positive,positive,positive,positive,positive
747648273,I've made this a draft until it's confirmed whether there's a bug.,made draft confirmed whether bug,issue,negative,positive,positive,positive,positive,positive
747601577,"I could take a closer look if you can share any code.
Can you share your W&B run? When you look at each of the metrics logged on your panel, is there any that is not logged through `fastai` callback?

Otherwise for debugging, you could try to print `wandb.run.step` and `WandbCallback._wandb_step`.",could take closer look share code share run look metric logged panel logged otherwise could try print,issue,positive,neutral,neutral,neutral,neutral,neutral
747598536,"It happens after the first epoch, no previous runs before, only one init call:

```
epoch     train_loss  valid_loss  accuracy  brier_score  ece       nll       err  time
0         7.291822    6.423790    0.891155  0.022018     0.056384  6.423790  0.122854           05:20     wandb: WARNING Step must only increase in log calls.  Step 232 < 233; dropping {'epoch': 1}.
```",first epoch previous one call epoch accuracy err time warning step must increase log step dropping,issue,negative,positive,neutral,neutral,positive,positive
747589317,"I did have a look at the PR. I also performed a few small tests to check `commit` and `step` worked as expected.
Basically you're not supposed to provide both `step` and `commit`.

When `step` is provided, typically `commit` is at its default which is `None`.
Setting it to `False` will actually call the exact same functions.
`commit` is forced to `True` only when `step` is `None` (also default value)

That is why I don't understand why it would change the behavior in your code.

Relevant code section is [here](https://github.com/wandb/client/blob/52f31e00a83e887d94cd46a08b2fe2652670f5c9/wandb/sdk/wandb_run.py#L794-L813).

`after_batch` increases the step to get it ready for current logging (it is initially set at `-1`).
I'm not sure I understand where we increase the counter at `after_epoch` as the `step` is manually given.

Here are other interesting links:
* my test checking internal behavior of wandb depending on `commit`: [colab](https://colab.research.google.com/drive/1q-Lcrm9GzIPHRKn1mkK_45WFyLxQ_kjk?usp=sharing)
* tests in fastai library, 2 training loops are performed and there is no output warning: [see end of notebook](https://github.com/fastai/fastai/blob/master/nbs/70_callback.wandb.ipynb)

Is the issue happening at your first `fit` loop or are you having additional training loops within a same run?
For debugging, you could try to print `wandb.run.step` and `WandbCallback._wandb_step`.",look also small check commit step worked basically supposed provide step commit step provided typically commit default none setting false actually call exact commit forced true step none also default value understand would change behavior code relevant code section step get ready current logging initially set sure understand increase counter step manually given interesting link test internal behavior depending commit library training output warning see end notebook issue happening first fit loop additional training within run could try print,issue,positive,positive,positive,positive,positive,positive
747578676,"Thanks a lot for your feedback. I removed all custom logging and still getting the error described above. So the root cause is very likely the WandbCallback (I ran all our tests and with the proposed changes it's working). Did you  have a look at the PR? You increase the step count twice at the end of the epoch, is that intentional? At the end of an epoch first `after_batch` and then `after_epoch` are being called. You don't increase the callback counter, but you do increase (implicitly) the wandb counter by calling wandb.log without commit, which defaults to True, and thus increases the count, right?

It looks to me like the auto increment with wandb.log() is detrimental, because now it's not possible anymore to submit but not to increase the count?",thanks lot feedback removed custom logging still getting error root cause likely ran working look increase step count twice end epoch intentional end epoch first increase counter increase implicitly counter calling without commit true thus count right like auto increment detrimental possible submit increase count,issue,positive,positive,positive,positive,positive,positive
747571492,"I'm still surprised it would solve your problem:
* `commit=True` submits metrics as well as previously uncommitted metrics (for example when using `commit=False` or `step`), then increments the wandb step. When `False` it just adds the metrics to dict of uncommitted values for future commit.
* `step` gives direct access to wandb step and prevents from logging at a previous step. When logging at a future step, it will commit all previous steps, and not commit only the current step.

I'm thinking that there is a mismatch between the logging from the callback and your custom logging.

You could:
* Option 1 (recommended unless impossible): log data mainly using `wandb_process` and let the callback handle the proper step, taking advantage of `type_dispatch`
* Option 2: use `commit=False` and don't provide any step in your custom logging, this will automatically match the last step logged by the callback
* Option 3: if you have to provide a step (maybe you log something before the callback), you can access it through `wandb.run.step`. You need to be careful here because `WandbCallback` keeps its own internal counter `self._wandb_step` which it increases at `after_batch`, right before logging.",still would solve problem metric well previously uncommitted metric example step step false metric uncommitted future commit step direct access step logging previous step logging future step commit previous commit current step thinking mismatch logging custom logging could option unless impossible log data mainly let handle proper step taking advantage option use provide step custom logging automatically match last step logged option provide step maybe log something access need careful internal counter right logging,issue,positive,negative,neutral,neutral,negative,negative
747411293,"@borisdayma I wasn't able to create a concise example, but I believe I found the root cause – actually what I already wrote in the initial message – that you changed the wandb.log api (always increase), but at four places in the code it shouldn't be increased.

Here's the PR: https://github.com/fastai/fastai/pull/3080

Does this make sense to you and is this the expected behaviour?

On my end this fixes the error.",able create concise example believe found root cause actually already wrote initial message always increase four code make sense behaviour end error,issue,negative,positive,positive,positive,positive,positive
747177781,"> Same exception with your env and a different model/dataloader.
> Any solutions?
> EDIT: I temporarily solved adding `num_workers=0` to my dataloader.
> 
> ```python
>  dls = DataLoaders.from_dsets(ds_train, ds_val, bs=4, num_workers=0)
> ```

thx bro, it works!!!",exception different edit temporarily python work,issue,negative,neutral,neutral,neutral,neutral,neutral
746947336,"DataBlock is a separate issue. DataLoader already lets you use custom samplers.

--
  Jeremy Howard
  j@howard.fm


On Mon, Dec 14, 2020, at 10:38 AM, Abner Ayala-Acevedo wrote:
> 

> Has this been addressed?

> By far the most wanted feature for FastAI for me is to be able to simply use pytorch samplers. It will make the DataBlock API complete, DataBlock support splitter, labeling function it should also support sampler function or pytorch sampler class. That will open up many unique sampling techniques for problems that require triplet loss, self-learning problems, etc...


> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub <https://github.com/fastai/fastai/issues/2638#issuecomment-744631548>, or unsubscribe <https://github.com/notifications/unsubscribe-auth/AACUW53XAYBE3HFFLYWLVIDSUZLSBANCNFSM4QEVNQIQ>.
",separate issue already use custom mon wrote far feature able simply use make complete support splitter function also support sampler function sampler class open many unique sampling require triplet loss reply directly view,issue,negative,positive,positive,positive,positive,positive
746900121,Thanks. I'm not even sure why we have an env file actually!...,thanks even sure file actually,issue,positive,positive,positive,positive,positive,positive
746810846,"I encountered a similar error (albeit mine is fatal) and it looks like in the current fastai release the Image and the Tensor get passed to CropPad in item_tfms separately which means they encounter a problem when trying to get orig_size from Points or BBoxes.

I have a small test I wrote when trying to understand what is going on:

```python
def _process_sz(size):
    if isinstance(size,int): size=(size,size)
    return fastuple(size[1],size[0])

def _get_sz(x):
    if isinstance(x, tuple): x = x[0]
    if not isinstance(x, Tensor): return fastuple(x.size)
    return fastuple(getattr(x, 'img_size', getattr(x, 'sz', (x.shape[-1], x.shape[-2]))))

class MyCropPad(DisplayedTransform):
    ""Center crop or pad an image to `size`""
    order = 0
    def __init__(self, size, pad_mode=PadMode.Zeros, **kwargs):
        size = _process_sz(size)
        store_attr()
        super().__init__(**kwargs)
        
    def encodes(self, x:(Image.Image,TensorBBox,TensorPoint)):
        orig_sz = _get_sz(x)
        tl = (orig_sz-self.size)//2
        print(type(x), self.size, orig_sz, tl)
        return x.crop_pad(self.size, tl, orig_sz=orig_sz, pad_mode=self.pad_mode)

dblock = DataBlock(blocks=(ImageBlock, PointBlock),
                   splitter=RandomSplitter(0.2),
                   get_y=get_points,
                   item_tfms=[MyCropPad((1042, 1042), pad_mode=PadMode.Border)],
                   batch_tfms=[*aug_transforms(do_flip=False, max_rotate=180, min_zoom=.3, max_zoom=1, pad_mode=PadMode.Border)],
                  )
```

Aftrwards I do `dls = dblock.dataloaders(imgs, bs=16)` and get (+ an exception):
```
<class 'fastai.vision.core.PILImage'> (1042, 1042) (1042, 542) (0, -250)
<class 'fastai.vision.core.TensorPoint'> (1042, 1042) () ()
```

The PILImage gets proper parameters. The TensorPoint gets nothing.

How is this supposed to work? I tried to follow the flow through the transform code but it is not straightforward at all.",similar error albeit mine fatal like current release image tensor get separately encounter problem trying get small test wrote trying understand going python size size size size return size size tensor return return class center crop pad image size order self size size size super self print type return get exception class class proper nothing supposed work tried follow flow transform code straightforward,issue,negative,positive,neutral,neutral,positive,positive
745507648,"By the way @renato145 when I was taking a look at this, it seemed that some calls before it was a tuple, `Torch.Size` inside `_convert` was there with all the components, to mee it seems that it just doesnt stop there and continue transforming maybe by the recursive nature.

@butchland found this https://github.com/pytorch/pytorch/issues/46826",way taking look inside doesnt stop continue transforming maybe recursive nature found,issue,negative,neutral,neutral,neutral,neutral,neutral
744901167,"

I've found a workaround to the PyTorch 1.7 version + FastAI 2.1 version. ([see release notes ](https://github.com/fastai/fastai/blob/2.1.0/CHANGELOG.md))
While the issue is addressed and the problem is completely solved, I will opt for installing a older version 
PyTorch 1.6+FastAI 2.0.19. 
```!pip uninstall torch -y
!pip uninstall torch -y
 CUDA 10.1
!pip install torch==1.6.0+cu101 torchvision==0.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html
!pip install fastai==2.0.19
!pip install fastcore==1.3.1 
```
https://forums.fast.ai/t/a-walk-with-fastai2-vision-study-group-and-online-lectures-megathread/59929/1383

Hope this helps, thank you to all the contributors. ",found version version see release issue problem completely opt older version pip torch pip torch pip install pip install pip install hope thank,issue,negative,positive,positive,positive,positive,positive
744637058,"Ok, good to know that's automated. I created the PR because the current 2.1.9 release prints 2.1.8 as version. 

Thanks!",good know current release version thanks,issue,positive,positive,positive,positive,positive,positive
744631548,"Has this been addressed?

By far the most wanted feature for FastAI for me is to be able to simply use pytorch samplers. It will make the DataBlock API complete, DataBlock support splitter, labeling function it should also support sampler function or pytorch sampler class. That will open up many unique sampling techniques for problems that require triplet loss, self-learning problems, etc...",far feature able simply use make complete support splitter function also support sampler function sampler class open many unique sampling require triplet loss,issue,negative,positive,positive,positive,positive,positive
744586999,"Thanks for the PR. This is touching on too many files for my liking, so I'd rather not go with this solution.",thanks touching many liking rather go solution,issue,positive,positive,positive,positive,positive,positive
744584801,"We use nbdev, so this needs to be updated in the notebook. Feel free open reopen this PR or open a new one if you have a chance to do this.",use need notebook feel free open reopen open new one chance,issue,positive,positive,positive,positive,positive,positive
744383245,"I am using something similar here @bwbelljr . But I was trying to create something that could see the IoU (jaccard) by class, does anyone have any suggestions? Currently, I'm returning a dict to be in place of a value, but it looks ugly 

...
And we need to create a PR to fix these metrics or at least the name of the variable, this union is not the union... it would be the sum of the predicted area + ground truth area, but remember that the Dice does not use the union but the total area:
`c_totalArea = (p+t).float().sum().item()`

And to save memory (as it is already done today), the union is given by removing the intersection of this total area:
`c_union = c_totalArea - c_inter # Better to calculate this part only in the jaccard, to not occupy memory`

I imagine that the wrong name in the metrics can confuse people who are trying to figure out how everything works. At first, I even thought the calculation of Dice was wrong because they were using Union, but I saw that it was the name of the variable that was wrong.",something similar trying create something could see class anyone currently place value ugly need create fix metric least name variable union union would sum area ground truth area remember dice use union total area save memory already done today union given removing intersection total area better calculate part occupy memory imagine wrong name metric confuse people trying figure everything work first even thought calculation dice wrong union saw name variable wrong,issue,negative,negative,negative,negative,negative,negative
744096385,"Thanks everyone for posting your code. I have a similar issue with the Jaccard metric. I am providing my code for Jaccard (which sub-classes from Dice, as provided by @johnnv1) and a new ""JaccardCoeffMulti"" (which sub-classes from DiceMulti, as provided by @NadyaStrogankova). If there are any problems with this code, feel free to respond.

```python
class JaccardCoeff(Dice):
    ""Implementation of the Jaccard coefficient that is lighter in RAM""
    @property
    def value(self): return self.inter/(self.union-self.inter) if self.union > 0 else None

class JaccardCoeffMulti(DiceMulti):
    ""Averaged Jaccard coefficient for multiclass target in segmentation""
    @property
    def value(self):
      binary_jaccard_scores = np.array([])
      for c in self.inter:
        binary_jaccard_scores = np.append(binary_jaccard_scores, self.inter[c]/(self.union[c] - self.inter[c]) if self.union[c] > 0 else np.nan)
      return np.nanmean(binary_jaccard_scores)
```",thanks everyone posting code similar issue metric providing code dice provided new provided code feel free respond python class dice implementation coefficient lighter ram property value self return else none class coefficient target segmentation property value self else return,issue,positive,positive,positive,positive,positive,positive
744031006,"> I agree that there is no easy way to go from the code to the doc. I would also like better docstrings, but don't know how ti could be done without impacting the notebooks and code style.
> From someone coming from scikit-learn or pandas/numpy used to read docstring with shift+tab it is very painful to find what you are looking for.
> https://forums.fast.ai/t/better-docstrings/82904

I agree !, even coming from pytorch, where the doc strings have standard style, its gets difficult for me here with single ling strings, when working with something like vscode/pycharm",agree easy way go code doc would also like better know ti could done without code style someone coming used read painful find looking agree even coming doc standard style difficult single ling working something like,issue,positive,negative,neutral,neutral,negative,negative
743849731,"> path = untar_data(URLs.PETS)
> fnames = get_image_files(path/""images"")
> pat = r'^(.*)_\d+.jpg$'
> dls = ImageDataLoaders.from_name_re(path, fnames, pat, item_tfms=Resize(224))
> learn = cnn_learner(dls, models.resnet34, loss_func=CrossEntropyLossFlat(), ps=0.25)
> learn.save('restnet34')
> img_size = 224
> trace_input = torch.ones(1,3,img_size,img_size).cuda()
> learn.model.eval()
> jit_model = torch.jit.trace(learn.model.float(), trace_input)

I tried your example and got this `RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same`

I just moved the model to cuda and it doesnt throw error

```
dede = torch.device('cuda')
path = untar_data(URLs.PETS)
fnames = get_image_files(path/""images"")
pat = r'^(.*)_\d+.jpg$'
dls = ImageDataLoaders.from_name_re(path, fnames, pat, item_tfms=Resize(224))
learn = cnn_learner(dls, models.resnet34, loss_func=CrossEntropyLossFlat(), ps=0.25)
learn.save('restnet34')
img_size = 224
trace_input = torch.ones(1,3,img_size,img_size).cuda()
learn.model.eval()
learn.model = learn.model.to(dede)
jit_model = torch.jit.trace(learn.model.float(), trace_input)
```

I used fastai.tests_utils.show_install to get this

```text
=== Software === 
python        : 3.8.5
fastai        : 2.1.8
fastprogress  : 0.2.7
torch         : 1.7.0
nvidia driver : 450.80
torch cuda    : 11.0 / is available
torch cudnn   : 8003 / is enabled

=== Hardware === 
nvidia gpus   : 1
torch devices : 1
  - gpu0      : GeForce RTX 2080

=== Environment === 
platform      : Linux-5.4.0-56-generic-x86_64-with-glibc2.10
distro        : #62-Ubuntu SMP Mon Nov 23 19:20:19 UTC 2020
conda env     : fastai
python        : /home/tyoc213/miniconda3/envs/fastai/bin/python
sys.path      : /home/tyoc213/Documents/github/fastai_xla_extensions/nbs
/home/tyoc213/miniconda3/envs/fastai/lib/python38.zip
/home/tyoc213/miniconda3/envs/fastai/lib/python3.8
/home/tyoc213/miniconda3/envs/fastai/lib/python3.8/lib-dynload

/home/tyoc213/miniconda3/envs/fastai/lib/python3.8/site-packages
/home/tyoc213/Documents/github/fastai_xla_extensions
/home/tyoc213/Documents/github/nbdev
/home/tyoc213/Documents/github/fastcore
/home/tyoc213/Documents/github/fastai
/home/tyoc213/miniconda3/envs/fastai/lib/python3.8/site-packages/IPython/extensions
/home/tyoc213/.ipython
```",path pat path pat learn tried example got input type weight type model doesnt throw error path pat path pat learn used get text python torch driver torch available torch hardware torch environment platform mon python,issue,negative,positive,positive,positive,positive,positive
743802804,"Thes best way right now I can think of, is each time fastcore or fastai is released, in some place log the versions, like on a separate repo that pulls the libs and install them on clean environment, then outputs a log that commits the versions, maybe `test_utils.show_version` would help too and something like `pip freeze` or `conda list --export`... dont know if that will help in the future to ""track correct versions""",best way right think time place log like separate install clean environment log maybe would help something like pip freeze list export dont know help future track correct,issue,positive,positive,positive,positive,positive,positive
743791290,"@jph00 done, interesting that github allows direct commit of suggestions, the bad is that it doesn't run `nbdev_update_lib` in this case or compose more the commit to delete the other line...

![image](https://user-images.githubusercontent.com/506234/101991052-c7706380-3c6f-11eb-8541-af8a3197f0da.png)
",done interesting direct commit bad run case compose commit delete line image,issue,negative,negative,neutral,neutral,negative,negative
743746907,has anyone found a solution to this yet? ,anyone found solution yet,issue,negative,neutral,neutral,neutral,neutral,neutral
743422196,"@letrongan nbdev is the current pip release, so 1.1.15. You are using the old version of fastai. You should do `pip install fastai --upgrade` on whatever platform you have so it shows fastai `2.x.x`",current pip release old version pip install upgrade whatever platform,issue,negative,positive,neutral,neutral,positive,positive
743319893,"Wow that's cool that it works already - I'm really surprised!

I'm going to merge this PR because it's a useful test, but I do agree it's too heavy. If you can find a way to simplify it, or split it into multiple smaller tests, even if it makes the test a little less perfect, I think that would be useful. (But if not possible, that's fine too)",wow cool work already really going merge useful test agree heavy find way simplify split multiple smaller even test little le perfect think would useful possible fine,issue,positive,positive,positive,positive,positive,positive
742787858,"Thanks a lot! This is happening in a bigger integrated project, I'll try to distill a simpler piece of code for reproduction. In my code I always call wandb.log with `commit=False`.",thanks lot happening bigger project try distill simpler piece code reproduction code always call,issue,negative,positive,neutral,neutral,positive,positive
742735445,Can you share your W&B run and some reproducible code?,share run reproducible code,issue,negative,neutral,neutral,neutral,neutral,neutral
742718815,"Hi @dreamflasher ,

Do you have any reproducible code you could share so that we can see the issue?
Providing the step explicitly ensures we associate validation and training data to the correct step.

With the proposed PR, `wandb.step` would increase after the end of each training batch. It means that validation metrics would be associated with the next step.

If you log custom data, the recommended way is to create `wandb_process` with the new `@typedispatch` as shown in the notebook (maybe we can better document it).

Otherwise you would just use `commit=False` in your own calls to `wandb.log`.

Let me know if it works for you.",hi reproducible code could share see issue providing step explicitly associate validation training data correct step would increase end training batch validation metric would associated next step log custom data way create new shown notebook maybe better document otherwise would use let know work,issue,positive,positive,positive,positive,positive,positive
742704049,I don't think current behavior should be changed but let's discuss it in the issue #3066 ,think current behavior let discus issue,issue,negative,neutral,neutral,neutral,neutral,neutral
742529061,"Same exception with your env and a different model/dataloader.
Any solutions?
EDIT: I temporarily solved adding ```num_workers=0``` to my dataloader.
```python
 dls = DataLoaders.from_dsets(ds_train, ds_val, bs=4, num_workers=0)
```",exception different edit temporarily python,issue,negative,neutral,neutral,neutral,neutral,neutral
742007242,"Same problem with DiceMulti. 
Similar fix:
```
class DiceMulti(Metric):
    ""Averaged Dice metric (Macro F1) for multiclass target in segmentation""
    def __init__(self, axis=1): self.axis = axis
    def reset(self): self.inter,self.union = {},{}
    def accumulate(self, learn):
        pred,targ = flatten_check(learn.pred.argmax(dim=self.axis), learn.y)
        for c in range(learn.pred.shape[self.axis]):
            p = torch.where(pred == c, 1, 0)
            t = torch.where(targ == c, 1, 0)
            p, t = TensorBase(p), TensorBase(t)
            c_inter = (p*t).float().sum().item()
            c_union = (p+t).float().sum().item()
            if c in self.inter:
                self.inter[c] += c_inter
                self.union[c] += c_union
            else:
                self.inter[c] = c_inter
                self.union[c] = c_union
    @property
    def value(self):
        binary_dice_scores = np.array([])
        for c in self.inter:
            binary_dice_scores = np.append(binary_dice_scores, 2.*self.inter[c]/self.union[c] if self.union[c] > 0 else np.nan)
        return np.nanmean(binary_dice_scores)

```",problem similar fix class metric dice metric macro target segmentation self axis reset self accumulate self learn range else property value self else return,issue,negative,neutral,neutral,neutral,neutral,neutral
741889784,I am getting the same `AttributeError: 'Learner' object has no attribute 'lr_find'`  error with version `2.1.5`. ,getting object attribute error version,issue,negative,neutral,neutral,neutral,neutral,neutral
741713644,"> 
> 
> Oh, thanks, this seems work

The parenthesis helps to instantiate the metric. ",oh thanks work parenthesis metric,issue,negative,positive,positive,positive,positive,positive
741709174,"it should be `learn = unet_learner(dls, resnet34, metrics=[Dice()],pretrained=True)`. You forgot the parenthesis, happened to me the first time too! 😊 ",learn dice forgot parenthesis first time,issue,negative,positive,positive,positive,positive,positive
741704174,"I'm just trying to run without many parameters, with just this Dice

```
from fastai.vision.all import unet_learner
from fastai.vision.models import resnet34
from fastai.metrics import Metric

class Dice(Metric):
    ""Dice coefficient metric for binary target in segmentation""
    def __init__(self, axis=1): self.axis = axis
    def reset(self): self.inter,self.union = 0,0
    def accumulate(self, learn):
        pred,targ = flatten_check(learn.pred.argmax(dim=self.axis), learn.y)
        pred, targ = TensorBase(pred), TensorBase(targ)
        self.inter += (pred*targ).float().sum().item()
        self.union += (pred+targ).float().sum().item()

    @property
    def value(self): return 2. * self.inter/self.union if self.union > 0 else None

learn = unet_learner(dls, resnet34, metrics=[Dice],pretrained=True)
```

`learn.fit_one_cycle(1,lr_max=1e-02)`",trying run without many dice import import import metric class dice metric dice coefficient metric binary target segmentation self axis reset self accumulate self learn property value self return else none learn dice,issue,negative,positive,positive,positive,positive,positive
741583341,"> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in accumulate(self, learn)
>     377     def accumulate(self, learn):
>     378         bs = find_bs(learn.yb)
> --> 379         self.total += learn.to_detach(self.func(learn.pred, *learn.yb))*bs
>     380         self.count += bs
>     381     @property
> 
> TypeError: __init__() takes from 1 to 2 positional arguments but 3 were given
> ```

Hello, João. I believe that the error you are getting comes from another metric because the accumulate function in the error message is different.  My workaround is only for Dice. Which metrics are you using? And regarding the union, I just copied fastai's current implementation of Dice and added this line: `pred, targ = TensorBase(pred), TensorBase(targ)`",accumulate self learn accumulate self learn property positional given hello believe error getting come another metric accumulate function error message different dice metric regarding union copied current implementation dice added line,issue,negative,neutral,neutral,neutral,neutral,neutral
741567692,This is strange for me. It was working fine just last week and suddenly it decided to quit on me. Im using fastai version 2.1.2 ,strange working fine last week suddenly decided quit version,issue,negative,positive,neutral,neutral,positive,positive
741168500,"> For anyone having the same issue with Dice metric, a workaround would be to just rewrite fastai's Dice class with a slight modification:
> 
> ```
> class Dice(Metric):
>     ""Dice coefficient metric for binary target in segmentation""
>     def __init__(self, axis=1): self.axis = axis
>     def reset(self): self.inter,self.union = 0,0
>     def accumulate(self, learn):
>         pred,targ = flatten_check(learn.pred.argmax(dim=self.axis), learn.y)
>         pred, targ = TensorBase(pred), TensorBase(targ)
>         self.inter += (pred*targ).float().sum().item()
>         self.union += (pred+targ).float().sum().item()
> 
>     @property
>     def value(self): return 2. * self.inter/self.union if self.union > 0 else None
> ```

i was having the same problem as @eduguiu, but in the function ""fit"" (fit_one_cycle or fit_flat_cos)...
With this workaround, I get another error...
Oh, and I think the dice is given by 2*intersection / (sum of the areas) and not over the union

```
---------------------------------------------------------------------------

TypeError                                 Traceback (most recent call last)

<ipython-input-49-c09caa37e1a9> in <module>()
----> 1 learn.fit_one_cycle(2,lr_max=1e-02)

19 frames

/usr/local/lib/python3.6/dist-packages/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)
    110     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),
    111               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}
--> 112     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)
    113 
    114 # Cell

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
    203             self.opt.set_hypers(lr=self.lr if lr is None else lr)
    204             self.n_epoch = n_epoch
--> 205             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
    206 
    207     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    152 
    153     def _with_events(self, f, event_type, ex, final=noop):
--> 154         try:       self(f'before_{event_type}')       ;f()
    155         except ex: self(f'after_cancel_{event_type}')
    156         finally:   self(f'after_{event_type}')        ;final()

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_fit(self)
    194         for epoch in range(self.n_epoch):
    195             self.epoch=epoch
--> 196             self._with_events(self._do_epoch, 'epoch', CancelEpochException)
    197 
    198     def fit(self, n_epoch, lr=None, wd=None, cbs=None, reset_opt=False):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    152 
    153     def _with_events(self, f, event_type, ex, final=noop):
--> 154         try:       self(f'before_{event_type}')       ;f()
    155         except ex: self(f'after_cancel_{event_type}')
    156         finally:   self(f'after_{event_type}')        ;final()

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_epoch(self)
    189     def _do_epoch(self):
    190         self._do_epoch_train()
--> 191         self._do_epoch_validate()
    192 
    193     def _do_fit(self):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_epoch_validate(self, ds_idx, dl)
    185         if dl is None: dl = self.dls[ds_idx]
    186         self.dl = dl
--> 187         with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)
    188 
    189     def _do_epoch(self):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    152 
    153     def _with_events(self, f, event_type, ex, final=noop):
--> 154         try:       self(f'before_{event_type}')       ;f()
    155         except ex: self(f'after_cancel_{event_type}')
    156         finally:   self(f'after_{event_type}')        ;final()

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in all_batches(self)
    158     def all_batches(self):
    159         self.n_iter = len(self.dl)
--> 160         for o in enumerate(self.dl): self.one_batch(*o)
    161 
    162     def _do_one_batch(self):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in one_batch(self, i, b)
    176         self.iter = i
    177         self._split(b)
--> 178         self._with_events(self._do_one_batch, 'batch', CancelBatchException)
    179 
    180     def _do_epoch_train(self):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    154         try:       self(f'before_{event_type}')       ;f()
    155         except ex: self(f'after_cancel_{event_type}')
--> 156         finally:   self(f'after_{event_type}')        ;final()
    157 
    158     def all_batches(self):

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in __call__(self, event_name)
    130     def ordered_cbs(self, event): return [cb for cb in sort_by_run(self.cbs) if hasattr(cb, event)]
    131 
--> 132     def __call__(self, event_name): L(event_name).map(self._call_one)
    133 
    134     def _call_one(self, event_name):

/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    177     def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step))
    178 
--> 179     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    180     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))
    181     def filter(self, f=noop, negate=False, gen=False, **kwargs):

/usr/local/lib/python3.6/dist-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs)
    605     res = map(g, iterable)
    606     if gen: return res
--> 607     return list(res)
    608 
    609 # Cell

/usr/local/lib/python3.6/dist-packages/fastcore/basics.py in __call__(self, *args, **kwargs)
    595             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)
    596         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 597         return self.func(*fargs, **kwargs)
    598 
    599 # Cell

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in _call_one(self, event_name)
    134     def _call_one(self, event_name):
    135         assert hasattr(event, event_name), event_name
--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]
    137 
    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in <listcomp>(.0)
    134     def _call_one(self, event_name):
    135         assert hasattr(event, event_name), event_name
--> 136         [cb(event_name) for cb in sort_by_run(self.cbs)]
    137 
    138     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

/usr/local/lib/python3.6/dist-packages/fastai/callback/core.py in __call__(self, event_name)
     42                (self.run_valid and not getattr(self, 'training', False)))
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit
     46         return res

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in after_batch(self)
    455         if len(self.yb) == 0: return
    456         mets = self._train_mets if self.training else self._valid_mets
--> 457         for met in mets: met.accumulate(self.learn)
    458         if not self.training: return
    459         self.lrs.append(self.opt.hypers[-1]['lr'])

/usr/local/lib/python3.6/dist-packages/fastai/learner.py in accumulate(self, learn)
    377     def accumulate(self, learn):
    378         bs = find_bs(learn.yb)
--> 379         self.total += learn.to_detach(self.func(learn.pred, *learn.yb))*bs
    380         self.count += bs
    381     @property

TypeError: __init__() takes from 1 to 2 positional arguments but 3 were given
```

",anyone issue dice metric would rewrite dice class slight modification class dice metric dice coefficient metric binary target segmentation self axis reset self accumulate self learn property value self return else none problem function fit get another error oh think dice given intersection sum union recent call last module self div none else cell fit self none else self none none none none none self ex final self ex try self except ex self finally self final self epoch range fit self self ex final self ex try self except ex self finally self final self self self self none self self ex final self ex try self except ex self finally self final self self enumerate self self self self ex final try self except ex self finally self final self self self event return event self self map self gen range return map self return self self return self negate filter self iterable gen map iterable gen return return list cell self else return cell self self assert event self return self assert event self return self self false none self noop reset true end fit return self return else met return accumulate self learn accumulate self learn property positional given,issue,negative,positive,neutral,neutral,positive,positive
740702724,"Ok, I tracked my issue, pillow was to old.
We should put min version on the `settings.ini` to avoid this.
But fastai 2.0.19 pulls` fastcore 1.3.10` that already removed the `log_args`, so doing
```
pip install ""fastai<2.1""
pip install ""fastcore==1.3.2""
```
solves the issue.",tracked issue pillow old put min version avoid already removed pip install pip install issue,issue,negative,positive,neutral,neutral,positive,positive
739668417,"`fastai2` is heavily outdated, as it was merged into `fastai` a few months back (hence why its an archived project). I would recommend using the latest `fastai`, otherwise you would need to try and find the suitable `fastcore` version to install, which looks to be `0.1.34`. ",heavily outdated back hence project would recommend latest otherwise would need try find suitable version install,issue,negative,positive,positive,positive,positive,positive
739663133,"@jph00 okay changes have been pushed. Here's what Ignacio suggested:

Regarding CutMix: 
> I went back through the original CutMix paper and lambda can take any value between 0 and 1, not .5 and 1, so I've changed the logic for that. 
> Also if the input shape is [batch size x channels x height x width], then x (which corresponds to w) needs to be applied to the 3rd dimension, and y (H) to the 2nd dimension. This doesn't make any difference with sqaured images, but it'd break with non-squared images.

Regarding my most recent changes:
In order to not have to worry about too much magic and make this adaptable for Mix that use custom losses, I changed up how `MixHandler` can act. We have a `mixup_criterion` which is for `MixUp` and `CutMix`, and if other loss functions are needed then they can directly pass in their custom ones as `loss_func`",regarding went back original paper lambda take value logic also input shape batch size height width need applied dimension dimension make difference break regarding recent order worry much magic make adaptable mix use custom act loss directly pas custom,issue,negative,positive,positive,positive,positive,positive
739514504,"Yes, definitely there is a deeper underlying problem ",yes definitely underlying problem,issue,negative,neutral,neutral,neutral,neutral,neutral
739514182,"```
> Class Dice(Metric):
>     ""Dice coefficient metric for binary target in segmentation""
>     def __init__(self, axis=1): self.axis = axis
>     def reset(self): self.inter,self.union = 0,0
>     def accumulate(self, learn):
>         pred,targ = flatten_check(learn.pred.argmax(dim=self.axis), learn.y)
>         pred, targ = TensorBase(pred), TensorBase(targ)
>         self.inter += (pred*targ).float().sum().item()
>         self.union += (pred+targ).float().sum().item()
> 
>     @property
>     def value(self): return 2. * self.inter/self.union if self.union > 0 else None
```

Reynaldo, the workaround does the job. 
The issue could close, but I suspect there is a deeper problem going on (including learn.summary(), learn.model() or even trying to add a Dice loss function)",class dice metric dice coefficient metric binary target segmentation self axis reset self accumulate self learn property value self return else none job issue could close suspect problem going even trying add dice loss function,issue,negative,neutral,neutral,neutral,neutral,neutral
739498806,"For anyone having the same issue with Dice metric, a workaround would be to just rewrite fastai's Dice class with a slight modification:

```
class Dice(Metric):
    ""Dice coefficient metric for binary target in segmentation""
    def __init__(self, axis=1): self.axis = axis
    def reset(self): self.inter,self.union = 0,0
    def accumulate(self, learn):
        pred,targ = flatten_check(learn.pred.argmax(dim=self.axis), learn.y)
        pred, targ = TensorBase(pred), TensorBase(targ)
        self.inter += (pred*targ).float().sum().item()
        self.union += (pred+targ).float().sum().item()

    @property
    def value(self): return 2. * self.inter/self.union if self.union > 0 else None
```",anyone issue dice metric would rewrite dice class slight modification class dice metric dice coefficient metric binary target segmentation self axis reset self accumulate self learn property value self return else none,issue,negative,negative,negative,negative,negative,negative
738921929,"Not quite yet, sorry! Final projects. I’ll be able to look at this over the
weekend.

On Fri, Dec 4, 2020 at 12:35 PM Jeremy Howard <notifications@github.com>
wrote:

> @muellerzr <https://github.com/muellerzr> any news on this?
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/3037#issuecomment-738915748>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV7KZCNSVCYKZSTJDUDSTEMVLANCNFSM4UDEUCEQ>
> .
>
",quite yet sorry final able look weekend wrote news reply directly view,issue,negative,positive,neutral,neutral,positive,positive
738555279,"I am having this same issue and followed the above running into further errorswhcih directed me to update the versions to this:
!pip install fastai==2.1.8
!pip install fastai2==0.0.30
!pip install fastcore==1.3.8.

which worked after I restarted the runtime. I am not sure how to dynamically update this but it would be nice particularly in the how to for using notebooks",issue running directed update pip install pip install pip install worked sure dynamically update would nice particularly,issue,positive,positive,positive,positive,positive,positive
737271550,"I agree that there is no easy way to go from the code to the doc. I would also like better docstrings, but don't know how ti could be done without impacting the notebooks and code style.
From someone coming from scikit-learn or pandas/numpy used to read docstring with shift+tab it is very painful to find what you are looking for.
https://forums.fast.ai/t/better-docstrings/82904
",agree easy way go code doc would also like better know ti could done without code style someone coming used read painful find looking,issue,positive,positive,neutral,neutral,positive,positive
737216207,"@muellerz can you provide a snippet on how to deserialize a bugged model and re-serialize it with the correct size?
I have a lot of models affected by this issue that I can't retrain.
Thanks in advance.",provide snippet model correct size lot affected issue ca retrain thanks advance,issue,negative,positive,positive,positive,positive,positive
737163899,"> Fastai's docstring are minimal, one liners. The documentation is on the website or the notebooks where the function is defined. This is intended:
> https://docs.fast.ai/learner.html#Learner.validate

@tcapelle , in this case, wouldn't it make sense to put links (URLs) to the documentation in docstrings?",minimal one documentation function defined intended case would make sense put link documentation,issue,negative,negative,neutral,neutral,negative,negative
736868308,"I have just checked with a fresh environment, and it worked without installing flask manually. We don't need that change.",checked fresh environment worked without flask manually need change,issue,negative,positive,positive,positive,positive,positive
736861327,"Now CI passed. 

I also had to install flask, but I have some issues with my conda env, so I am not sure if it was just me. Maybe this would be handled automatically by conda/pip at the moment of installation. It might be necessary to add it to the settings too.",also install flask sure maybe would handled automatically moment installation might necessary add,issue,negative,positive,positive,positive,positive,positive
736832101,"Oh also, could you please modify `settings.ini` to update the dev requirements for `captum` to the correct version range?",oh also could please modify update dev correct version range,issue,negative,neutral,neutral,neutral,neutral,neutral
736569451,Your pytorch is too old. Suggest you ask on the forums for help.,old suggest ask help,issue,negative,positive,neutral,neutral,positive,positive
736502674,"Unfortunately , from fastai.tabular import * is not working .Is there alternative thing ? ",unfortunately import working alternative thing,issue,negative,negative,negative,negative,negative,negative
736197626,"> @BishalLakha have you tried updating fastcore?
> 
> `conda update fastcore`

I had previously installed it with pip, recently did with miniconda, updated fastcore too but still no luck 
![image](https://user-images.githubusercontent.com/9823258/100694486-4f748480-33b7-11eb-83dd-ca3ca7121299.png)
",tried update previously pip recently still luck image,issue,negative,negative,neutral,neutral,negative,negative
735731271,"I get the same error in https://github.com/fastai/fastai/blob/master/dev_nbs/course/lesson7-wgan.ipynb

@jph00 Changing the parent Class to TensorImageBase as discussed on Discord didn't help.

```
class InvisibleTensor(TensorImageBase): def show(self, ctx=None, **kwargs): return ctx
```",get error parent class discord help class show self return,issue,negative,neutral,neutral,neutral,neutral,neutral
735631580,"thanks,i also solve the question in LMF model.",thanks also solve question model,issue,positive,positive,positive,positive,positive,positive
735234734,"the learn.summary() returns an error.
Even though the execution of learn (eg, learn.finetune() etc...) finishes without problem if no metrics is added. 

**Error with full stack trace**
```
TypeError                                 Traceback (most recent call last)

<ipython-input-22-bc39e9e85f86> in <module>()
----> 1 learn.summary()

6 frames

/usr/local/lib/python3.6/dist-packages/fastai/callback/hook.py in summary(self)
    189     ""Print a summary of the model, optimizer and loss function.""
    190     xb = self.dls.train.one_batch()[:self.dls.train.n_inp]
--> 191     res = module_summary(self, *xb)
    192     res += f""Optimizer used: {self.opt_func}\nLoss function: {self.loss_func}\n\n""
    193     if self.opt is not None:

/usr/local/lib/python3.6/dist-packages/fastai/callback/hook.py in module_summary(learn, *xb)
    166     infos = layer_info(learn, *xb)
    167     n,bs = 64,find_bs(xb)
--> 168     inp_sz = _print_shapes(apply(lambda x:x.shape, xb), bs)
    169     res = f""{learn.model.__class__.__name__} (Input shape: {inp_sz})\n""
    170     res += ""="" * n + ""\n""

/usr/local/lib/python3.6/dist-packages/fastai/callback/hook.py in _print_shapes(o, bs)
    156 def _print_shapes(o, bs):
    157     if isinstance(o, torch.Size): return ' x '.join([str(bs)] + [str(t) for t in o[1:]])
--> 158     else: return str([_print_shapes(x, bs) for x in o])
    159 
    160 # Cell

/usr/local/lib/python3.6/dist-packages/fastai/callback/hook.py in <listcomp>(.0)
    156 def _print_shapes(o, bs):
    157     if isinstance(o, torch.Size): return ' x '.join([str(bs)] + [str(t) for t in o[1:]])
--> 158     else: return str([_print_shapes(x, bs) for x in o])
    159 
    160 # Cell

/usr/local/lib/python3.6/dist-packages/fastai/callback/hook.py in _print_shapes(o, bs)
    156 def _print_shapes(o, bs):
    157     if isinstance(o, torch.Size): return ' x '.join([str(bs)] + [str(t) for t in o[1:]])
--> 158     else: return str([_print_shapes(x, bs) for x in o])
    159 
    160 # Cell

/usr/local/lib/python3.6/dist-packages/fastai/callback/hook.py in <listcomp>(.0)
    156 def _print_shapes(o, bs):
    157     if isinstance(o, torch.Size): return ' x '.join([str(bs)] + [str(t) for t in o[1:]])
--> 158     else: return str([_print_shapes(x, bs) for x in o])
    159 
    160 # Cell

/usr/local/lib/python3.6/dist-packages/fastai/callback/hook.py in _print_shapes(o, bs)
    156 def _print_shapes(o, bs):
    157     if isinstance(o, torch.Size): return ' x '.join([str(bs)] + [str(t) for t in o[1:]])
--> 158     else: return str([_print_shapes(x, bs) for x in o])
    159 
    160 # Cell

TypeError: 'int' object is not iterable
```",error even though execution learn without problem metric added error full stack trace recent call last module summary self print summary model loss function self used function none learn learn apply lambda input shape return else return cell return else return cell return else return cell return else return cell return else return cell object iterable,issue,negative,positive,positive,positive,positive,positive
735037441,"I'd like to put this on pause just for a few days, Ignacio Oguiza (from the forums) had a chance to look over the code as well and made some recommendations but I won't be able to reflect them in my code for a little bit. ",like put pause day chance look code well made wo able reflect code little bit,issue,positive,positive,positive,positive,positive,positive
734557915,"> 
> 
> I know this is fixed and merged now, but I'm hesitant to use it. I was seeing better results with the old implementation of the high LR and got worse results here. Do you have any advice @marii-moe as to how I should adapt my old LR to work with this new adjustment?

I am not familiar with your particular example, but you should get approximately the same results if you set your learning rate like so: 
new_lr = old_lr*n_acc/bs",know fixed hesitant use seeing better old implementation high got worse advice adapt old work new adjustment familiar particular example get approximately set learning rate like,issue,negative,positive,neutral,neutral,positive,positive
734436328,"I know this is fixed and merged now, but I'm hesitant to use it. I was seeing better results with the old implementation of the high LR and got worse results here. Do you have any advice @marii-moe as to how I should adapt my old LR to work with this new adjustment?",know fixed hesitant use seeing better old implementation high got worse advice adapt old work new adjustment,issue,negative,positive,neutral,neutral,positive,positive
734433188,"Fastai's docstring are minimal, one liners. The documentation is on the website or the notebooks where the function is defined. This is intended:
https://docs.fast.ai/learner.html#Learner.validate
",minimal one documentation function defined intended,issue,negative,negative,neutral,neutral,negative,negative
734367742,Yes please open a new issue.,yes please open new issue,issue,positive,positive,neutral,neutral,positive,positive
734357489,"Sure let me know how I can help.
Gradients are added and not averaged but it makes sense to change it to make it easier to use. My recommendation here would be just to keep track of how many samples are added and divide at the end.
Also the documentation will need to be updated as it mentions that the learning rate needs to be decreased.

I was not aware of potential issues with batch norm so it's great you noticed it!",sure let know help added sense change make easier use recommendation would keep track many added divide end also documentation need learning rate need aware potential batch norm great,issue,positive,positive,positive,positive,positive,positive
734257835,"Hi Jeremy,  
running the same code with the ""metrics=Dice()"" included (ie, learn = unet_learner(dls, resnet34, metrics=Dice()) returns an error message. 

TypeError: unsupported operand type(s) for *: 'TensorImage' and 'TensorMask' 

Stumbled upon this, when researching how to solve an issue appeared on a notebook (image segmentation) that 20 days ago, used to work without any problem. I have the new version 2.1.7 

Shall I open a new issue? ",hi running code included ie learn error message unsupported operand type upon solve issue notebook image segmentation day ago used work without problem new version shall open new issue,issue,negative,positive,neutral,neutral,positive,positive
734066827,Great! Will definitely make a PR post this then :),great definitely make post,issue,positive,positive,positive,positive,positive,positive
734062952,"@jph00 can also confirm other Mix variants can be adapted easily, just did `Ricap` a moment ago and it trains as I would expect :) (would Ricap also be a good idea to include in this ""mix"" module? I can do that as a separate PR later)",also confirm mix easily moment ago would expect would also good idea include mix module separate later,issue,positive,positive,positive,positive,positive,positive
734059326,"Yup, I have been using this in a kaggle competition and they are just as accurate, only breaking changes are the imports (which we've fixed to a degree with a warning in the pr :) )",competition accurate breaking fixed degree warning,issue,negative,positive,positive,positive,positive,positive
734057799,"Are there any breaking changes as far as you know?

Have you trained some models before and after this change and confirmed they're at least as accurate as previously? (If not, please do so! :) )",breaking far know trained change confirmed least accurate previously please,issue,negative,positive,neutral,neutral,positive,positive
734043076,"Was about to say, the imports would be the major shift/break. Sounds good",say would major good,issue,negative,positive,positive,positive,positive,positive
734042922,Let's change the module name back to `mixup` from `mixups` so that's one less breaking change,let change module name back one le breaking change,issue,negative,neutral,neutral,neutral,neutral,neutral
733473530,"@rsomani95 tracking this one in a different pull request, so closing this one. 

https://github.com/fastai/fastai/pull/3030",one different pull request one,issue,negative,neutral,neutral,neutral,neutral,neutral
733473245,"This is the offending code in `TrainEvalCallback` that made this not work: 
```
def before_train(self):
        ""Set the model in training mode""
        self.learn.pct_train=self.epoch/self.n_epoch
        self.model.train()
        self.learn.training=True
```",code made work self set model training mode,issue,negative,neutral,neutral,neutral,neutral,neutral
732725533,"hi are there are fixes for this? I'm running into this issue as well. This is my code: 

```
img_size = 128
trace_input = torch.ones(1,3,img_size,img_size).cuda()
learn.model.eval()
jit_model = torch.jit.trace(learn.model.float(), trace_input)
```
This is my error: 
```
---------------------------------------------------------------------------
UnsupportedNodeError                      Traceback (most recent call last)
<ipython-input-64-8261d07310ef> in <module>
      2 trace_input = torch.ones(1,3,img_size,img_size).cuda()
      3 learn.model.eval()
----> 4 jit_model = torch.jit.trace(learn.model.float(), trace_input)
      5 #jit_model

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in trace(func, example_inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)
    740             strict,
    741             _force_outplace,
--> 742             _module_class,
    743         )
    744 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in trace_module(mod, inputs, optimize, check_trace, check_inputs, check_tolerance, strict, _force_outplace, _module_class, _compilation_unit)
    926         register_submods(mod, ""__module"")
    927 
--> 928         module = make_module(mod, _module_class, _compilation_unit)
    929 
    930         for method_name, example_inputs in inputs.items():

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in make_module(mod, _module_class, _compilation_unit)
    558         if _module_class is None:
    559             _module_class = TopLevelTracedModule
--> 560         return _module_class(mod, _compilation_unit=_compilation_unit)
    561 
    562 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in __init__(self, orig, id_set, _compilation_unit)
   1038         for name, submodule in orig._modules.items():
   1039             tmp_module._modules[name] = make_module(
-> 1040                 submodule, TracedModule, _compilation_unit=None
   1041             )
   1042 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in make_module(mod, _module_class, _compilation_unit)
    558         if _module_class is None:
    559             _module_class = TopLevelTracedModule
--> 560         return _module_class(mod, _compilation_unit=_compilation_unit)
    561 
    562 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in __init__(self, orig, id_set, _compilation_unit)
   1038         for name, submodule in orig._modules.items():
   1039             tmp_module._modules[name] = make_module(
-> 1040                 submodule, TracedModule, _compilation_unit=None
   1041             )
   1042 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in make_module(mod, _module_class, _compilation_unit)
    558         if _module_class is None:
    559             _module_class = TopLevelTracedModule
--> 560         return _module_class(mod, _compilation_unit=_compilation_unit)
    561 
    562 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in __init__(self, orig, id_set, _compilation_unit)
   1038         for name, submodule in orig._modules.items():
   1039             tmp_module._modules[name] = make_module(
-> 1040                 submodule, TracedModule, _compilation_unit=None
   1041             )
   1042 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in make_module(mod, _module_class, _compilation_unit)
    558         if _module_class is None:
    559             _module_class = TopLevelTracedModule
--> 560         return _module_class(mod, _compilation_unit=_compilation_unit)
    561 
    562 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_trace.py in __init__(self, orig, id_set, _compilation_unit)
   1042 
   1043         script_module = torch.jit._recursive.create_script_module(
-> 1044             tmp_module, lambda module: (), share_types=False
   1045         )
   1046 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_recursive.py in create_script_module(nn_module, stubs_fn, share_types)
    350     check_module_initialized(nn_module)
    351     concrete_type = get_module_concrete_type(nn_module, share_types)
--> 352     return create_script_module_impl(nn_module, concrete_type, stubs_fn)
    353 
    354 def create_script_module_impl(nn_module, concrete_type, stubs_fn):

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_recursive.py in create_script_module_impl(nn_module, concrete_type, stubs_fn)
    363     cpp_module = torch._C._create_module_with_type(concrete_type.jit_type)
    364     method_stubs = stubs_fn(nn_module)
--> 365     property_stubs = get_property_stubs(nn_module)
    366 
    367     def init_fn(script_module):

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/_recursive.py in get_property_stubs(nn_module)
    599     """"""
    600     module_ty = type(nn_module)
--> 601     properties_asts = get_class_properties(module_ty, self_name=""RecursiveScriptModule"")
    602     rcbs = {}
    603 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/frontend.py in get_class_properties(cls, self_name)
    149     for prop in props:
    150         if prop[0] not in unused_properties and not should_drop(prop[1].fget):
--> 151             getter = get_jit_def(prop[1].fget, f""__{prop[0]}_getter"", self_name=self_name)
    152             setter = get_jit_def(prop[1].fset, f""__{prop[0]}_setter"", self_name=self_name) if prop[1].fset else None
    153             properties.append(Property(getter.range(), Ident(getter.range(), prop[0]), getter, setter))

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/frontend.py in get_jit_def(fn, def_name, self_name)
    219             arg.annotation = unused_def.args.args[0].annotation
    220 
--> 221     return build_def(ctx, fn_def, type_line, def_name, self_name=self_name)
    222 
    223 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/frontend.py in build_def(ctx, py_def, type_line, def_name, self_name)
    253     return Def(Ident(r, def_name),
    254                decl,
--> 255                build_stmts(ctx, body))
    256 
    257 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/frontend.py in build_stmts(ctx, stmts)
    125 
    126 def build_stmts(ctx, stmts):
--> 127     stmts = [build_stmt(ctx, s) for s in stmts]
    128     return list(filter(None, stmts))
    129 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/frontend.py in <listcomp>(.0)
    125 
    126 def build_stmts(ctx, stmts):
--> 127     stmts = [build_stmt(ctx, s) for s in stmts]
    128     return list(filter(None, stmts))
    129 

~/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/torch/jit/frontend.py in __call__(self, ctx, node)
    226         method = getattr(self, 'build_' + node.__class__.__name__, None)
    227         if method is None:
--> 228             raise UnsupportedNodeError(ctx, node)
    229         return method(ctx, node)
    230 

UnsupportedNodeError: try blocks aren't supported:
  File ""/home/ec2-user/anaconda3/envs/pytorch_latest_p36/lib/python3.6/site-packages/fastai/layers.py"", line 572
def _has_children(m:nn.Module):
    try: next(m.children())
    ~~~ <--- HERE
    except StopIteration: return False
    return True

```",hi running issue well code error recent call last module trace optimize strict strict optimize strict module none return self name name none return self name name none return self name name none return self lambda module return type prop prop prop prop getter prop prop setter prop prop prop else none property prop getter setter return return body return list filter none return list filter none self node method self none method none raise node return method node try file line try next except return false return true,issue,positive,negative,neutral,neutral,negative,negative
732670224,"@rsomani95 I was fixing a different issue and ended up debugging this one in the process, I wasn't aware you were working on this one, sorry about that. This callback seems to be inter-playing with the TrainEvalCallback. This is how I was able to get it working for me: 
```
class BnFreeze(Callback):
    run_after=TrainEvalCallback
    ""Freeze moving average statistics in all non-trainable batchnorm layers.""
    def before_train(self):
        set_bn_eval(self.model)
```
I am not very familiar with the `BnFreeze` code myself. This should be the offending code in `TrainEvalCallback` that makes this not work: 
```
def before_train(self):
        ""Set the model in training mode""
        self.learn.pct_train=self.epoch/self.n_epoch
        self.model.train()
        self.learn.training=True
```
Wanted to go ahead and contribute this as you are the one leading and most familiar with this one. ",fixing different issue ended one process aware working one sorry able get working class freeze moving average statistic self familiar code code work self set model training mode go ahead contribute one leading familiar one,issue,negative,positive,positive,positive,positive,positive
732653654,"Noticed that `BnFreeze` also seems to not be working in the same notebook. Its only test is slow, so it probably wasn't caught when something else changed. Taking a look now. ",also working notebook test slow probably caught something else taking look,issue,negative,negative,negative,negative,negative,negative
732515696,"@jph00 Thanks for the speedy help, and will do, was my first time submitting an issue!",thanks speedy help first time issue,issue,positive,positive,positive,positive,positive,positive
732412725,"Setting `num_workers` to zero worked. Thanks!
`dls = bears.dataloaders(path, num_workers=0) `",setting zero worked thanks path,issue,negative,positive,positive,positive,positive,positive
732412081,"Hi Jeremy, Thanks for fixing!

On Mon, Nov 23, 2020 at 11:46 AM Jeremy Howard <notifications@github.com>
wrote:

> Hi - you'd already created an issue for this bug. Creating 2 issues makes
> more administrative overhead for us, and slows us down, making it take
> longer to fix bugs. In this case, I'd just fixed the bug, and now I have to
> mark two issues closed instead of one. So please don't do this.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/3017#issuecomment-732320018>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AIIXO3CJIMM3CDQXIAJO55TSRKNXXANCNFSM4T34YCDQ>
> .
>
",hi thanks fixing mon wrote hi already issue bug administrative overhead u slows u making take longer fix case fixed bug mark two closed instead one please thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
732374817,"I also don't know why 09b is disliking me, looks like somehow a nb build mismatch that made it through the testing API? I don't know",also know disliking like somehow build mismatch made testing know,issue,negative,neutral,neutral,neutral,neutral,neutral
732357769,@jph00 just did a heavy refactor and threw out the extra stuff for this pr. Let me know if you have any thoughts. ,heavy threw extra stuff let know,issue,negative,negative,neutral,neutral,negative,negative
732351136,"@evan-tan should be fixed now. FYI it's best to create new issues for new problems, since adding to a closed issue often gets lost.",fixed best create new new since closed issue often lost,issue,positive,positive,positive,positive,positive,positive
732343911,Sure. I only included it as it was requested a few times in the forums and looked like a thing that should be added in. Can definitely separate into another PR,sure included time like thing added definitely separate another,issue,positive,positive,positive,positive,positive,positive
732342410,"Oh I see - sorry I didn't know there were two things in this PR. Could we separate these issues, and tackle the layer groups issue later (if we decide to do it)? Let's keep each step simple. :) ",oh see sorry know two could separate tackle layer issue later decide let keep step simple,issue,negative,negative,negative,negative,negative,negative
732320018,"Hi - you'd already created an issue for this bug. Creating 2 issues makes more administrative overhead for us, and slows us down, making it take longer to fix bugs. In this case, I'd just fixed the bug, and now I have to mark two issues closed instead of one. So please don't do this.",hi already issue bug administrative overhead u slows u making take longer fix case fixed bug mark two closed instead one please,issue,negative,neutral,neutral,neutral,neutral,neutral
732304578,Many thanks for this very clear bug report!,many thanks clear bug report,issue,positive,positive,positive,positive,positive,positive
732302737,I have an additional example of this bug at the top of my post on the forums: https://forums.fast.ai/t/tensorcategory-and-tensortext-when-using-awd-lstm-for-text-classification/82428,additional example bug top post,issue,negative,positive,positive,positive,positive,positive
732275177,"No problem, feel free to reach back if you have any issue",problem feel free reach back issue,issue,negative,positive,positive,positive,positive,positive
732172986,Maybe just a `!pip install -U fastai --upgrade` will do the job.,maybe pip install upgrade job,issue,negative,neutral,neutral,neutral,neutral,neutral
732066669,"Sorry, this was a silly oversight on my part. I was running 3.1.5 and just realised this was fixed in 3.1.6",sorry silly oversight part running fixed,issue,negative,negative,negative,negative,negative,negative
731886102,"Hey, I'm getting the error **TypeError: no implementation found for 'torch.nn.functional.cross_entropy' on types that implement __torch_function__: [<class 'fastai.torch_core.TensorImage'>, <class 'fastai.torch_core.TensorMask'>]** when running the following code in 01_intro.ipynb, running on the Datacrunch FastAI image
```
path = untar_data(URLs.CAMVID_TINY)
dls = SegmentationDataLoaders.from_label_func(
    path, bs=8, fnames = get_image_files(path/""images""),
    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',
    codes = np.loadtxt(path/'codes.txt', dtype=str)
)

learn = unet_learner(dls, resnet34)
learn.fine_tune(8)
```",hey getting error implementation found implement class class running following code running image path path lambda learn,issue,negative,neutral,neutral,neutral,neutral,neutral
731770652,Thanks @wfwiggins .  That change caught my eye but I was overwhelmed by all the padding changes.  ,thanks change caught eye padding,issue,negative,positive,positive,positive,positive,positive
731689066,"@dalupus you are correct. I had overlooked the fact that I had also pinned `fastai==2.1.4` in order to fix this issue.

It appears that reverting the change to `tokenize_df` made in `fastai.text.core` from `2.1.4 -> 2.1.5` fixes this issue. The change was apparently made in response to a numpy warning. The change was made on line 224 of `fastai/text/core.py`.

```
# fastai==2.1.4
224    res[tok_text_col] = outputs

# fastai==2.1.5
224    res[tok_text_col] = pd.Series(outputs, dtype=object)
```

I will submit a PR reverting this change shortly, assuming this is desirable.",correct fact also pinned order fix issue change made issue change apparently made response warning change made line submit change shortly assuming desirable,issue,negative,positive,neutral,neutral,positive,positive
731651657,"I can recreate with the following code and the attached csv
```
from fastai.text.all import *
df = pd.read_csv('reviewSpamData.csv')
df_new = df[(df.domain.str.contains('hotel')) & (df.type.str.contains('expert')==False)]
dls_lm = TextDataLoaders.from_df(df_new, valid_pct = 0.1, text_col='text', 
                                 label_col='spam', bs=256, seq_len=80, is_lm=True)
```

[reviewSpamData.zip](https://github.com/fastai/fastai/files/5578636/reviewSpamData.zip)
",recreate following code attached import,issue,negative,neutral,neutral,neutral,neutral,neutral
731650381,"Probably you have an old version of fastai2 https://github.com/fastai/fastai/issues/2954.

Mmm if possible, try to install latest in a new env and try again.",probably old version possible try install latest new try,issue,negative,positive,positive,positive,positive,positive
731639107,"This issue is indeed in fastai and not fastcore
Simply downgrading to `fastcore==1.3.1` does not resolve the issue.  You must downgrade to `fastai==2.1.4` ",issue indeed simply resolve issue must downgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
731606175,"To solve number 2, this patch works well
```python
@patch
def requires_grad_(self:TensorBase, requires_grad=True):
    self.requires_grad = requires_grad
    return self
```",solve number patch work well python patch self return self,issue,negative,neutral,neutral,neutral,neutral,neutral
730242076,"The problem is that now `TensorBase.shape` is returning a tuple instead of `torch.Size`.
Not sure whats the best way to solve this, a change on `TensorBase.__torch_function__` is now using `torch.tensor._convert` which is turning the result into a tuple:

https://github.com/pytorch/pytorch/blob/v1.7.0/torch/tensor.py#L1009",problem instead sure whats best way solve change turning result,issue,positive,positive,positive,positive,positive,positive
730043170,"> The fix is just getting rid of our first batch norm layer in create_head

I don't think that works. I'm not entirely sure this is automatable. Perhaps the best we can hope for is a bool param that can be set via `model_meta`?",fix getting rid first batch norm layer think work entirely sure perhaps best hope bool param set via,issue,positive,positive,positive,positive,positive,positive
730042242,"I'll also note that some tests had to be changed as well. These needed to be adjusted as ReLU is no longer perceived as ""trainable"" (since it has no parameters) and a second value of `same` is returned as well, which dictates whether or not the input and output shapes remained the same",also note well longer trainable since second value returned well whether input output,issue,positive,neutral,neutral,neutral,neutral,neutral
730039486,The utils update/change was due to a mismatch that got overlooked it seems (I made a new fork just before doing this < 1hr ago),due mismatch got made new fork ago,issue,negative,positive,neutral,neutral,positive,positive
729962703,A better solution would be to check for a batch norm layer at the end of the encoder,better solution would check batch norm layer end,issue,positive,positive,positive,positive,positive,positive
729246481,The other option is to fix the bug in fastai itself and cast it to a proper fastai custom tensor instead (which is what they are doing),option fix bug cast proper custom tensor instead,issue,negative,neutral,neutral,neutral,neutral,neutral
729245773,"yes, it actually needs to be of Pyotrch tensor type instead of fastai's cutom tensors. My fix does this, removes the type to the output of the model. You can apply this fix, by passing this cb to the learner.",yes actually need tensor type instead fix type output model apply fix passing learner,issue,negative,neutral,neutral,neutral,neutral,neutral
729234358,"I I have similar issue and am using the lastest version v2.1.5.
If I insert a lr_find in front of the fit, it will change the training result. Please see screenshot below
![image](https://user-images.githubusercontent.com/26617297/99454500-5e0c7600-298b-11eb-9da2-392fb989e3a4.png)
reproducible code:
```
from fastai.vision.all import *
def is_cat(x): return x[0].isupper()
path = untar_data(URLs.PETS)/'images'
set_seed(42,True)
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224),shuffle_train= False)
learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fit(1)
```

```
set_seed(42,True)
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224),shuffle_train= False)
learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.lr_find()

learn.fit(1)
```
",similar issue version insert front fit change training result please see image reproducible code import return path true path path false learn true path path false learn,issue,positive,positive,neutral,neutral,positive,positive
729204087,"The issue is it needs to be a proper tensor type. Jeremy and Marii are
currently working on a fix.

On Tue, Nov 17, 2020 at 3:02 PM Scott Butters <notifications@github.com>
wrote:

> Hi @tcapelle <https://github.com/tcapelle> , I've been seeing this issue
> as well.
>
> For your proposed fix above, where would that be implemented to get this
> code working? Or do you have plans to integrate it into this tutorial
> notebook?
>
> And as long as we're here, I'm also seeing the below error in response to
> the last line in this notebook. Possibly related?
>
> ---------------------------------------------------------------------------
> RuntimeError                              Traceback (most recent call last)
> <ipython-input-85-97c83ebb6f57> in <module>()
> ----> 1 res = learn.siampredict(siamtest)
>
> 1 frames
> <ipython-input-78-c877b0c06524> in siampredict(self, item, rm_type_tfms, with_input)
>       2 def siampredict(self:Learner, item, rm_type_tfms=None, with_input=False):
>       3     res = self.predict(item, rm_type_tfms=None, with_input=False)
> ----> 4     if res[0] == tensor(0):
>       5         SiameseImage(item[0], item[1], 'Prediction: Not similar').show()
>       6     else:
>
> /usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs)
>     315
>     316     def __torch_function__(self, func, types, args=(), kwargs=None):
> --> 317         with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__)
>     318         if isinstance(ret, TensorBase): ret.set_meta(self, as_copy=True)
>     319         return ret
>
> RuntimeError: Boolean value of Tensor with more than one value is ambiguous
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2973#issuecomment-729169313>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV2X5FWKOAAMWELB6S3SQLJFJANCNFSM4TSDLLHQ>
> .
>
",issue need proper tensor type currently working fix tue wrote hi seeing issue well fix would get code working integrate tutorial notebook long also seeing error response last line notebook possibly related recent call last module self item self learner item item tensor item item similar else self self ret ret self return ret value tensor one value ambiguous thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
729169313,"Hi @tcapelle , I've been seeing this issue as well.

For your proposed fix above, where would that be implemented to get this code working? Or do you have plans to integrate it into this tutorial notebook?

And as long as we're here, I'm also seeing the below error in response to the last line in this notebook. Possibly related?

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-85-97c83ebb6f57> in <module>()
----> 1 res = learn.siampredict(siamtest)

1 frames
<ipython-input-78-c877b0c06524> in siampredict(self, item, rm_type_tfms, with_input)
      2 def siampredict(self:Learner, item, rm_type_tfms=None, with_input=False):
      3     res = self.predict(item, rm_type_tfms=None, with_input=False)
----> 4     if res[0] == tensor(0):
      5         SiameseImage(item[0], item[1], 'Prediction: Not similar').show()
      6     else:

/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in __torch_function__(self, func, types, args, kwargs)
    315 
    316     def __torch_function__(self, func, types, args=(), kwargs=None):
--> 317         with torch._C.DisableTorchFunction(): ret = _convert(func(*args, **(kwargs or {})), self.__class__)
    318         if isinstance(ret, TensorBase): ret.set_meta(self, as_copy=True)
    319         return ret

RuntimeError: Boolean value of Tensor with more than one value is ambiguous
```",hi seeing issue well fix would get code working integrate tutorial notebook long also seeing error response last line notebook possibly related recent call last module self item self learner item item tensor item item similar else self self ret ret self return ret value tensor one value ambiguous,issue,negative,negative,neutral,neutral,negative,negative
729013707,"Hey! I would like to add improve the docstrings.
Can you help me out with specifics? :-)",hey would like add improve help,issue,positive,neutral,neutral,neutral,neutral,neutral
728548702,"I see what you mean.
Trouble is - I am led here by installation instructions for students of the course.
",see mean trouble led installation course,issue,negative,negative,negative,negative,negative,negative
728248279,"@twosatnams  facing the same issue, any idea how you resolved this issue",facing issue idea resolved issue,issue,negative,neutral,neutral,neutral,neutral,neutral
727648255,"@jph00 sure, I will go ahead and add the suggested change",sure go ahead add change,issue,negative,positive,positive,positive,positive,positive
727269905,"I'd be happy to accept this PR, but it needs to check if the file already exists, and if so, should add an incrementing number to the end of the filename (before the suffix of course), until it finds a filename that doesn't exist. Otherwise we'll end up overwriting files.

If you're not interested in doing this, no problem, just let me know and I'll close the PR.",happy accept need check file already add number end suffix course exist otherwise end interested problem let know close,issue,positive,positive,positive,positive,positive,positive
726933524,Hopefully this isn't needed now. Please feel free to reopen if I'm wrong!,hopefully please feel free reopen wrong,issue,positive,negative,neutral,neutral,negative,negative
726833368,"Also, do you like the dual usage of groupkey (if `items` is a list, then groupkey should be a callable, if `items` is a dataframe then it should be a column name)? In any other language I would overload the function instead, like so, but it's not clear to me if that's even possible in python, let alone the pythonic way.

def GroupedSplitter(Callable item2group,valid_pct=0.2,seed=None,n_tries=3):
  def _inner(o):
    assert not isinstance(o,pd.DataFrame)

def GroupedSplitter(str group_col,valid_pct=0.2,seed=None,n_tries=3):
  def _inner(o):
    assert isinstance(o,pd.DataFrame)
",also like dual usage list callable column name language would overload function instead like clear even possible python let alone pythonic way callable assert assert,issue,negative,positive,neutral,neutral,positive,positive
726827049,"In general, is this the sort of documentation you wanted? Or is it too verbose? If so, is there anywhere else better suited to a more verbose explanation and example? Maybe in the tutorial section?",general sort documentation verbose anywhere else better verbose explanation example maybe tutorial section,issue,negative,positive,positive,positive,positive,positive
726826317,"More generally, I thought it might be a good idea to demonstrate the use of this splitter with a real dataset, but I also realize that it might slow down tests. Is there any way to mark those cells so they are no automatically run?",generally thought might good idea demonstrate use splitter real also realize might slow way mark automatically run,issue,negative,positive,positive,positive,positive,positive
726826279,I'm not sure I understand the error message this is failing with.,sure understand error message failing,issue,negative,positive,positive,positive,positive,positive
726638365,"The problem is that `ProgressCallback` is not deleting its `pbar` attribute after the fit. I modified @muellerzr gist showing how to solve the problem.
https://gist.github.com/ababino/2a2c67ac264e2ed8c95144377b9be2b4

",problem attribute fit gist showing solve problem,issue,negative,positive,positive,positive,positive,positive
726585731,"Does this mean the `WandbCallback` is currently not usable?
Just want to make sure I understand what exactly breaks. ",mean currently usable want make sure understand exactly,issue,negative,positive,positive,positive,positive,positive
726405135,"# Potential Solutions

1. Use smaller text files :D

**or**

2. After a quick chat with Jeremy on the discord, a temporary work around would be do to the numericalization alongside the tokenization during `.setups`, and then keep these numericalized arrays in memory. Reading these in Tokenizer.encodes should then be pretty quick (hopefully)

Will give this a go now",potential use smaller text quick chat discord temporary work around would alongside keep memory reading pretty quick hopefully give go,issue,negative,positive,positive,positive,positive,positive
726369692,The issue appears to pertain to a change in `fastcore` and was temporarily fixed by pinning `fastcore==1.3.1`. Will move this to the `fastcore` Issues.,issue pertain change temporarily fixed pinning move,issue,negative,positive,neutral,neutral,positive,positive
726357042,"I spoke too soon, moving `Numericalize` to 'item_tfms' **does** speed things up when using a dataframe with large chunks of text in each row. 

But another issue with @radekosmulski 's example is that because its reading from files, and his files are quite huge.  `Tokenizer.encodes` reads every tokenized file and runs `.split(' ')`, like so:

```
    def encodes(self, o:Path):
        if self.mode=='folder' and str(o).startswith(str(self.path)):
            tok = self.output_dir/o.relative_to(self.path)
            return L(tok.read_text().split(' '))
        else: return self._tokenize1(o.read_text())
```

`snakeviz` profiler shows me it takes ~5s for .split and 2.3s for read_text for a simple `dls.show_batch(max_n=2)`",spoke soon moving speed large text row another issue example reading quite huge every file like self path return else return profiler simple,issue,positive,positive,positive,positive,positive,positive
726355400,Another user posted on this issue in the forums [see post here](https://forums.fast.ai/t/getting-error-typeerror-float-object-is-not-iterable-when-creating-dataloaders/81881/2).,another user posted issue see post,issue,negative,neutral,neutral,neutral,neutral,neutral
726297920,"Many thanks. Please fix the CI issues, then I'll merge. You may also want to point people to some of the developer pages in the docs, such as https://docs.fast.ai/dev-setup .",many thanks please fix merge may also want point people developer,issue,positive,positive,positive,positive,positive,positive
726153145,"Here's a minimal reproducer showing that there is a duplicate validation dataframe being added after fit:

https://gist.github.com/muellerzr/df3fc4a12b021be85639afddab3c5d32

@jph00 we should reopen this issue",minimal reproducer showing duplicate validation added fit reopen issue,issue,negative,positive,positive,positive,positive,positive
726096742,"@claudiobottari I've found the issue. It's after we *fit* the model
",found issue fit model,issue,negative,positive,positive,positive,positive,positive
726027150,"This fixes the issue:
```python
def apply_wo_type(func, x, *args, **kwargs):
    ""Apply `func` recursively to `x`, passing on args""
    if is_listy(x): return type(x)([apply_wo_type(func, o, *args, **kwargs) for o in x])
    if isinstance(x,dict):  return {k: apply_wo_type(func, v, *args, **kwargs) for k,v in x.items()}
    res = func(x, *args, **kwargs)
    return res

def remove_tensor_type(b):
    ""Recursively map lists of int tensors in `b ` to float.""
    return apply_wo_type(lambda x: cast(x,typ=Tensor), b)

class RemoveTypeCB(Callback):
    def after_pred(self):
        self.learn.pred = remove_tensor_type(self.pred)
```

or a  last `Transform` that removes types before feeding the model.",issue python apply passing return type return return map float return lambda cast class self last transform feeding model,issue,negative,neutral,neutral,neutral,neutral,neutral
725997851,"I've done the same (after upgrading to 2.1.5) and I also experienced the same issue:
Model trained with adult.csv, exported to a 161K file.
Model trained with the same dataset, but containing 500K rows, exported to a 8Mb file.

https://colab.research.google.com/drive/1zhSKeJCB5CvTiQKgYWubey9w1VzbNiG2?usp=sharing
",done also experienced issue model trained file model trained file,issue,negative,positive,positive,positive,positive,positive
725989583,"Hi, I upgraded Fastai to the lastest version (2.1.5) and I'm still experiencing the same issue.

I created a notebook on Colab to reproduce the problem: 
[https://colab.research.google.com/drive/1yvQwIrC9zfI0jq5xZq_h4JVkoXWszcHC?usp=sharing](https://colab.research.google.com/drive/1yvQwIrC9zfI0jq5xZq_h4JVkoXWszcHC?usp=sharing)",hi version still issue notebook reproduce problem,issue,negative,neutral,neutral,neutral,neutral,neutral
725555819,"this is pretty weird indeed... if we run `%debug` just after this, the `x`  is correct, butt the `y` vector is wrong.
```
y[2].shape
>> (1,3,64,1)
```

The problem comes from `get_preds`, the output of the model is of type `TensorImage`. This shouldn't be the case, it is probably linked to the new typed-Tensors, even if you do:
```
b  = dls.one_batch()
out = learn.model(b[0], b[1])
type(out)
>> TensorImage
```

so `TensorImage` propagates all through the model, images in, images out...
",pretty weird indeed run correct butt vector wrong problem come output model type case probably linked new even type model,issue,negative,negative,negative,negative,negative,negative
725204789,"
> Didn't try this yet, does a transform like `Numericalize` fit into the philosophy of what a Dataloader should do?


No not really - it wouldn't be a great approach.
",try yet transform like fit philosophy really would great approach,issue,positive,positive,positive,positive,positive,positive
725189618,"> Please provide a complete reproducer. A colab link would be most helpful. The reproducer needs to use a publicly available dataset - preferably a small one that's provided in fastai's `URLs` class.

https://colab.research.google.com/drive/19WzwYTzs78DNvQ7VTw_37hbXq3l5ozsk?usp=sharing
Please check this colab",please provide complete reproducer link would helpful reproducer need use publicly available preferably small one provided class please check,issue,positive,positive,neutral,neutral,positive,positive
725140119,"Tried a few things based on what you said, but first here is a minimal repro:

## Repro
```
import fastai
from fastai.text.all import *
from fastcore.basics import *

path = untar_data(URLs.IMDB_SAMPLE)
df = pd.read_csv(path/'texts.csv')

# Increase amount of text in each row
n = 5000
df['text'] = df['text'] * n
df = df.iloc[:15,:].copy()

# Dataloader
imdb_lm = DataBlock(blocks=TextBlock.from_df('text', is_lm=True),
                    get_x=ColReader('text'),
                    splitter=ColSplitter())
dls = imdb_lm.dataloaders(df, bs=4, n_workers=0)

# Show batch time
%%time
dls.show_batch(max_n=2)

# Time
%%time
for b in dls.train: 
    print(b[0].size())
```
## Tried

### Moving Numericalize to `batch_tfms` in the init of TextBlock
Didn't work so well, had to modify a few functions that expected to receive a tensor but were now receiving tokenized text. Eventually hit a wall when it came to the `fa_collate` which again expects an array or tensor. When it didn't get either it turned a batch item into a list of tuples like so:

`[('xxbos',),('this',),('doesn't,),('work',)...]`

I think getting `batch_tfms` to work might end up being too hacky/fragile 

### Moving Numericalize to `item_tfms` in the init of TextBlock
Appears work work nicely, a quick test shows that timing is back down to **100-200ms** for `.show_batch`. I still have to test more thoroughly, including test that `reverse_text` works as expected

#### Modifications
1. Move `Numericalize` to item_tfms in `TextBlock`:

class TextBlock(TransformBlock):
    ""A `TransformBlock` for texts""

    @delegates(Numericalize.__init__)
    def __init__(self, tok_tfm, vocab=None, is_lm=False, seq_len=72, backwards=False, **kwargs):
        type_tfms = [tok_tfm]
        if backwards: type_tfms += [reverse_text]
        item_tfms = [Numericalize(vocab, **kwargs)]      # <---- Moved here
        return super().__init__(type_tfms=type_tfms,
                                item_tfms=item_tfms,
                                dl_type=LMDataLoader if is_lm else SortedDL,
                                dls_kwargs={'seq_len': seq_len} if is_lm else {'before_batch': Pad_Chunk(seq_len=seq_len)})

    @classmethod
    @delegates(Tokenizer.from_df, keep=True)
    def from_df(cls, text_cols, vocab=None, is_lm=False, seq_len=72, backwards=False, min_freq=3, max_vocab=60000, **kwargs):
        ""Build a `TextBlock` from a dataframe using `text_cols`""
        return cls(Tokenizer.from_df(text_cols, **kwargs), vocab=vocab, is_lm=is_lm, seq_len=seq_len,
                   backwards=backwards, min_freq=min_freq, max_vocab=max_vocab)

    @classmethod
    @delegates(Tokenizer.from_folder, keep=True)
    def from_folder(cls, path, vocab=None, is_lm=False, seq_len=72, backwards=False, min_freq=3, max_vocab=60000, **kwargs):
        ""Build a `TextBlock` from a `path`""
        return cls(Tokenizer.from_folder(path, **kwargs), vocab=vocab, is_lm=is_lm, seq_len=seq_len,
                   backwards=backwards, min_freq=min_freq, max_vocab=max_vocab)

2. Had to modify 1 line of `create_item` in `LMDataLoader`:

```
def create_item(self:LMDataLoader, seq):
    #pdb.set_trace()
    if seq>=self.n: raise IndexError
    sl = self.last_len if seq//self.bs==self.n_batches-1 else self.seq_len
    st = (seq%self.bs)*self.bl + (seq//self.bs)*self.seq_len
    txt = self.chunks[st : st+sl+1]
    return (txt[:-1],txt[1:])     # <- New version
    #return LMTensorText(txt[:-1]),txt[1:]   # <- Old version
```

### Add to dataloader
Didn't try this yet, does a transform like `Numericalize` fit into the philosophy of what a Dataloader should do?
",tried based said first minimal import import import path increase amount text row show batch time time time time print tried moving work well modify receive tensor text eventually hit wall came array tensor get either turned batch item list like think getting work might end moving work work nicely quick test timing back still test thoroughly test work move class self backwards return super else else build return path build path return path modify line self raise else st st return new version return old version add try yet transform like fit philosophy,issue,positive,positive,positive,positive,positive,positive
725053246,Please provide a complete reproducer. A colab link would be most helpful. The reproducer needs to use a publicly available dataset - preferably a small one that's provided in fastai's `URLs` class.,please provide complete reproducer link would helpful reproducer need use publicly available preferably small one provided class,issue,positive,positive,neutral,neutral,positive,positive
725025294,Feel free to ask if you have trouble getting nbdev working OK. Many thanks for the PR.,feel free ask trouble getting working many thanks,issue,positive,positive,positive,positive,positive,positive
725019454,@jph00 Thanks a lot for your input. I made the according changes.,thanks lot input made according,issue,negative,positive,positive,positive,positive,positive
724953254,Yeah was having trouble setting it up for some reason. I thought I could get away with it. ,yeah trouble setting reason thought could get away,issue,negative,negative,negative,negative,negative,negative
724952929,"Yeah sorry I should have replied earlier - I see the problem. Numericalize is being called on the whole dataset each time. It should probably be a batch transform, or maybe part of the DataLoader. Or a preprocessing step.",yeah sorry see problem whole time probably batch transform maybe part step,issue,negative,negative,negative,negative,negative,negative
724934791,"Just taking another peak at this, the slowness seems to come from the amount of data in the datasets, e.g. `dls.train_ds`

Here is the size of the items in `train_ds` with the IMDB example (`.show_batch(max_n=2)` takes **191 ms** on my machine):

<img width=""194"" alt=""Screenshot 2020-11-10 at 13 56 40"" src=""https://user-images.githubusercontent.com/20516801/98726838-a361ef80-235c-11eb-8eba-8a0503bd1435.png"">


And here is the size of the items in @radekosmulski 's `train_ds` (`.show_batch(max_n=2)` takes **19.5 s** on my machine):

<img width=""310"" alt=""Screenshot 2020-11-10 at 13 58 43"" src=""https://user-images.githubusercontent.com/20516801/98727054-f3d94d00-235c-11eb-93cf-91087282b364.png"">


(maybe this is obvious to folks, sharing just in case)",taking another peak come amount data size example machine size machine maybe obvious case,issue,negative,neutral,neutral,neutral,neutral,neutral
724744513,@moritzschwyzer please at-mention me here when you've got an update you'd like me to take a look at.,please got update like take look,issue,positive,neutral,neutral,neutral,neutral,neutral
724429168,"Ok solved 

```
learn = cnn_learner(dls, resnet50, metrics=[accuracy, error_rate, Precision(average='micro'),
               Recall(average='micro')]) # resnet 34 or 18, also 50 works better
learn.fine_tune(4)
```",learn accuracy precision recall also work better,issue,negative,positive,positive,positive,positive,positive
724428067,"I am also confused, how can we calculate Precision and Recall in fastai?!

when I run  

```
learn = cnn_learner(dls, resnet50, metrics=[accuracy, error_rate, Recall(), Precision()]) # resnet 34 or 18, also 50 works better
learn.fine_tune(4)
```

I got this


```
ValueError                                Traceback (most recent call last)
<ipython-input-18-c0eb68e0d858> in <module>
      1 learn = cnn_learner(dls, resnet50, metrics=[accuracy, error_rate, Recall(), Precision()]) # resnet 34 or 18, also 50 works better
----> 2 learn.fine_tune(4)

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/logargs.py in _f(*args, **kwargs)
     54         init_args.update(log)
     55         setattr(inst, 'init_args', init_args)
---> 56         return inst if to_return else f(*args, **kwargs)
     57     return _f

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/callback/schedule.py in fine_tune(self, epochs, base_lr, freeze_epochs, lr_mult, pct_start, div, **kwargs)
    159     ""Fine tune with `freeze` for `freeze_epochs` then with `unfreeze` from `epochs` using discriminative LR""
    160     self.freeze()
--> 161     self.fit_one_cycle(freeze_epochs, slice(base_lr), pct_start=0.99, **kwargs)
    162     base_lr /= 2
    163     self.unfreeze()

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/logargs.py in _f(*args, **kwargs)
     54         init_args.update(log)
     55         setattr(inst, 'init_args', init_args)
---> 56         return inst if to_return else f(*args, **kwargs)
     57     return _f

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)
    111     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),
    112               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}
--> 113     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)
    114 
    115 # Cell

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/logargs.py in _f(*args, **kwargs)
     54         init_args.update(log)
     55         setattr(inst, 'init_args', init_args)
---> 56         return inst if to_return else f(*args, **kwargs)
     57     return _f

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
    205             self.opt.set_hypers(lr=self.lr if lr is None else lr)
    206             self.n_epoch = n_epoch
--> 207             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
    208 
    209     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    153 
    154     def _with_events(self, f, event_type, ex, final=noop):
--> 155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')
    157         finally:   self(f'after_{event_type}')        ;final()

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _do_fit(self)
    195         for epoch in range(self.n_epoch):
    196             self.epoch=epoch
--> 197             self._with_events(self._do_epoch, 'epoch', CancelEpochException)
    198 
    199     @log_args(but='cbs')

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    153 
    154     def _with_events(self, f, event_type, ex, final=noop):
--> 155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')
    157         finally:   self(f'after_{event_type}')        ;final()

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _do_epoch(self)
    190     def _do_epoch(self):
    191         self._do_epoch_train()
--> 192         self._do_epoch_validate()
    193 
    194     def _do_fit(self):

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _do_epoch_validate(self, ds_idx, dl)
    186         if dl is None: dl = self.dls[ds_idx]
    187         self.dl = dl
--> 188         with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)
    189 
    190     def _do_epoch(self):

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')
--> 157         finally:   self(f'after_{event_type}')        ;final()
    158 
    159     def all_batches(self):

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in __call__(self, event_name)
    131     def ordered_cbs(self, event): return [cb for cb in sort_by_run(self.cbs) if hasattr(cb, event)]
    132 
--> 133     def __call__(self, event_name): L(event_name).map(self._call_one)
    134 
    135     def _call_one(self, event_name):

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    224     def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step))
    225 
--> 226     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    227     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))
    228     def filter(self, f=noop, negate=False, gen=False, **kwargs):

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs)
    549     res = map(g, iterable)
    550     if gen: return res
--> 551     return list(res)
    552 
    553 # Cell

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/basics.py in __call__(self, *args, **kwargs)
    539             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)
    540         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 541         return self.func(*fargs, **kwargs)
    542 
    543 # Cell

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _call_one(self, event_name)
    135     def _call_one(self, event_name):
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 
    139     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in <listcomp>(.0)
    135     def _call_one(self, event_name):
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 
    139     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/callback/core.py in __call__(self, event_name)
     42                (self.run_valid and not getattr(self, 'training', False)))
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit
     46         return res

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in after_validate(self)
    470     def before_validate(self): self._valid_mets.map(Self.reset())
    471     def after_train   (self): self.log += self._train_mets.map(_maybe_item)
--> 472     def after_validate(self): self.log += self._valid_mets.map(_maybe_item)
    473     def after_cancel_train(self):    self.cancel_train = True
    474     def after_cancel_validate(self): self.cancel_valid = True

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    224     def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step))
    225 
--> 226     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    227     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))
    228     def filter(self, f=noop, negate=False, gen=False, **kwargs):

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/basics.py in map_ex(iterable, f, gen, *args, **kwargs)
    549     res = map(g, iterable)
    550     if gen: return res
--> 551     return list(res)
    552 
    553 # Cell

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastcore/basics.py in __call__(self, *args, **kwargs)
    539             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)
    540         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 541         return self.func(*fargs, **kwargs)
    542 
    543 # Cell

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/learner.py in _maybe_item(t)
    426 # Cell
    427 def _maybe_item(t):
--> 428     t = t.value
    429     return t.item() if isinstance(t, Tensor) and t.numel()==1 else t
    430 

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/fastai/metrics.py in value(self)
     67         preds,targs = torch.cat(self.preds),torch.cat(self.targs)
     68         if self.to_np: preds,targs = preds.numpy(),targs.numpy()
---> 69         return self.func(targs, preds, **self.kwargs) if self.invert_args else self.func(preds, targs, **self.kwargs)
     70 
     71     @property

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs)
     70                           FutureWarning)
     71         kwargs.update({k: arg for k, arg in zip(sig.parameters, args)})
---> 72         return f(**kwargs)
     73     return inner_f
     74 

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/sklearn/metrics/_classification.py in recall_score(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)
   1733     ``zero_division``.
   1734     """"""
-> 1735     _, r, _, _ = precision_recall_fscore_support(y_true, y_pred,
   1736                                                  labels=labels,
   1737                                                  pos_label=pos_label,

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/sklearn/utils/validation.py in inner_f(*args, **kwargs)
     70                           FutureWarning)
     71         kwargs.update({k: arg for k, arg in zip(sig.parameters, args)})
---> 72         return f(**kwargs)
     73     return inner_f
     74 

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/sklearn/metrics/_classification.py in precision_recall_fscore_support(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)
   1431     if beta < 0:
   1432         raise ValueError(""beta should be >=0 in the F-beta score"")
-> 1433     labels = _check_set_wise_labels(y_true, y_pred, average, labels,
   1434                                     pos_label)
   1435 

~/anaconda3/envs/pytorch3d/lib/python3.8/site-packages/sklearn/metrics/_classification.py in _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)
   1261             if y_type == 'multiclass':
   1262                 average_options.remove('samples')
-> 1263             raise ValueError(""Target is %s but average='binary'. Please ""
   1264                              ""choose another average setting, one of %r.""
   1265                              % (y_type, average_options))

ValueError: Target is multiclass but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted'].
```
",also confused calculate precision recall run learn accuracy recall precision also work better got recent call last module learn accuracy recall precision also work better log return else return self div fine tune freeze unfreeze discriminative slice log return else return self div none else cell log return else return fit self none else self none none none none none self ex final self ex try self except ex self finally self final self epoch range self ex final self ex try self except ex self finally self final self self self self none self self ex final try self except ex self finally self final self self self event return event self self map self gen range return map self return self self return self negate filter self iterable gen map iterable gen return return list cell self else return cell self self assert event self return self assert event self return self self false none self noop reset true end fit return self self self self self true self true map self gen range return map self return self self return self negate filter self iterable gen map iterable gen return return list cell self else return cell cell return tensor else value self return else property zip return return average zip return return beta average beta raise beta score average average raise target please choose another average setting one target please choose another average setting one none,issue,positive,positive,neutral,neutral,positive,positive
724350771,"Now I'm getting more params logged than before!

The next step will be to figure out how to log params from `learn.fit`, `learn.fit_one_cycle`, etc… (included method name).",getting logged next step figure log included method name,issue,negative,neutral,neutral,neutral,neutral,neutral
724328118,"> @kessido looks like you need to run `nbdev_clean_nbs`.

done, is it ok now?",like need run done,issue,negative,neutral,neutral,neutral,neutral,neutral
723941959,Oh no. Was playing with `gh` and accidentally used the link for this issue.,oh accidentally used link issue,issue,negative,neutral,neutral,neutral,neutral,neutral
723709202,@KushajveerSingh why did you close this? I don't believe it's resolved yet.,close believe resolved yet,issue,negative,neutral,neutral,neutral,neutral,neutral
723575154,@ecatkins Going ahead and closing this one pretty sure it is all fixed now. ,going ahead one pretty sure fixed,issue,positive,positive,positive,positive,positive,positive
723521834,"https://forums.fast.ai/t/attributeerror-tensorpoint-object-has-no-attribute-img-size/81431

To reproduce, run the 06_multicat.ipynb in colab from fast.ai.

```Exception in user code:
------------------------------------------------------------
Traceback (most recent call last):
  File ""<ipython-input-91-9e15da96f703>"", line 6, in <module>
    dls.show_results(b, preds, max_n=9)
  File ""/usr/local/lib/python3.6/dist-packages/fastai/data/core.py"", line 108, in show_results
    x1,y1,outs = self.show_batch(b_out, max_n=max_n, show=False)
  File ""/usr/local/lib/python3.6/dist-packages/fastai/data/core.py"", line 101, in show_batch
    if not show: return self._pre_show_batch(b, max_n=max_n)
  File ""/usr/local/lib/python3.6/dist-packages/fastai/data/core.py"", line 92, in _pre_show_batch
    its = self._decode_batch(b, max_n, full=False)
  File ""/usr/local/lib/python3.6/dist-packages/fastai/data/core.py"", line 86, in _decode_batch
    return L(batch_to_samples(b, max_n=max_n)).map(f)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py"", line 226, in map
    def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/basics.py"", line 543, in map_ex
    return list(res)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/basics.py"", line 533, in __call__
    return self.func(*fargs, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/basics.py"", line 553, in _inner
    for f in funcs: x = f(x, *args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/transform.py"", line 206, in decode
    if full: return compose_tfms(o, tfms=self.fs, is_enc=False, reverse=True, split_idx=self.split_idx)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/transform.py"", line 150, in compose_tfms
    x = f(x, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/transform.py"", line 74, in decode
    def decode  (self, x, **kwargs): return self._call('decodes', x, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/transform.py"", line 83, in _call
    return self._do_call(getattr(self, fn), x, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/transform.py"", line 90, in _do_call
    res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/transform.py"", line 90, in <genexpr>
    res = tuple(self._do_call(f, x_, **kwargs) for x_ in x)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/transform.py"", line 89, in _do_call
    return retain_type(f(x, **kwargs), x, ret)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/dispatch.py"", line 129, in __call__
    return f(*args, **kwargs)
  File ""/usr/local/lib/python3.6/dist-packages/fastai/vision/core.py"", line 258, in decodes
    def decodes(self, x:TensorPoint): return _unscale_pnts(x.view(-1, 2), self._get_sz(x))
  File ""/usr/local/lib/python3.6/dist-packages/fastai/vision/core.py"", line 245, in _get_sz
    sz = x.img_size
AttributeError: 'TensorPoint' object has no attribute 'img_size'
------------------------------------------------------------```",reproduce run exception user code recent call last file line module file line file line show return file line file line return file line map map self return self file line return list file line return file line file line decode full return file line file line decode decode self return file line return self file line file line file line return ret file line return file line self return file line object attribute,issue,negative,positive,positive,positive,positive,positive
723514886,"@jph00 I'm happy with it!

Note that the subclassing of Pytorch tensors will be handled directly in wandb repo: https://github.com/wandb/client/pull/1474",happy note handled directly,issue,positive,positive,positive,positive,positive,positive
723503879,"Nice. Turns out it wasn't the `permute` that's slow, but `iter` and cast tensor->int. Just pushed a different approach to solving the same problem, which takes the same time as `choice`. Note that when timing stuff like this you should run `gc.collect()` before each timing, otherwise gc overhead will make results highly variable.",nice turn permute slow iter cast different approach problem time choice note timing stuff like run timing otherwise overhead make highly variable,issue,negative,positive,positive,positive,positive,positive
723499562,When reporting issues please try to provide the full stack trace for us to look at as well as a (minimal) reproducer. ,please try provide full stack trace u look well minimal reproducer,issue,positive,positive,positive,positive,positive,positive
723494459,"I decided to use `np.random.choice` because it's faster. (for 10 million items it reduces it from 1.78 seconds -> 1.21 seconds)

Edit: wasn't fully convinced, just keeping it as permute. If others find it works better or something more efficient we can use that",decided use faster million edit fully convinced keeping permute find work better something efficient use,issue,positive,positive,positive,positive,positive,positive
723488841,It was gradual (about after every 15th epoch).,gradual every th epoch,issue,negative,neutral,neutral,neutral,neutral,neutral
723487915,Was the increase gradual or was it sudden? After the first epoch this could be expected as we unfreeze the model,increase gradual sudden first epoch could unfreeze model,issue,negative,positive,positive,positive,positive,positive
723483606,"@borisdayma just in case you didn't see on Discord yet, I've had to remove `log_args` due to a memory leak. Let's discuss how to fix up any missing functionality as soon as you have a moment.",case see discord yet remove due memory leak let discus fix missing functionality soon moment,issue,negative,negative,negative,negative,negative,negative
723433481,"@driesvr  Here is a gist of what I am proposing, does it look good to you? https://gist.github.com/marii-moe/0dbab6a5b18824988ee66f878823ac79

You would have to define your own `show_batch`, or do something similar to the Siamere Tutorial. I included my own version of `show_batch` to show the gist of it

This is not finalized yet. ",gist look good would define something similar tutorial included version show gist yet,issue,negative,positive,positive,positive,positive,positive
723355959,"@goerlitz Do you have any news regarding this? I'm working on a multi-label classifier and struggle to understand why my `accuracy_multi` metric (I'm using FastAI2) is always greater than 99% no matter what. Since I'm working with more than 200 different labels, I highly doubt this is that accurate. Or I am missing the purpose of this metric.",news regarding working classifier struggle understand metric always greater matter since working different highly doubt accurate missing purpose metric,issue,negative,positive,positive,positive,positive,positive
723327266,"I've narrowed down the issue to the `ReadTabBatch` transform, we're always storing a copy of the dataframe into memory through this",issue transform always copy memory,issue,negative,neutral,neutral,neutral,neutral,neutral
723218941,"Many thanks for this. Please run `nbdev_build_libs` to fix the CI fail.

Also, the current test isn't very useful or clear for readers - it just reimplements the implementation, and requires a lot of code. Instead, pick some small simple examples that have obvious answers (e.g. no overlap, all overlap, and 50% overlap) and test the results are as expected.

Finally, `sum/len` with a python list seems like a slow way to calc the mean. Maybe you can use `np.mean`, ideally passing it a numpy array? Or use a torch tensor and call `mean` on it?",many thanks please run fix fail also current test useful clear implementation lot code instead pick small simple obvious overlap overlap overlap test finally python list like slow way mean maybe use ideally passing array use torch tensor call mean,issue,positive,positive,neutral,neutral,positive,positive
722776959,"Got `show_batch` returning with results. Formatting of the output is off with this first example(multi) provided so attempting to figure that out. Formatting does work with the second example(single). Other examples in the notebooks are formatted correctly.

This is because show_batch is getting a tuple(obect) of TensorText, instead of a single TensorText for x. Going to see if I can figure out a way to add multi-text display for show_batch. 
",got output first example provided figure work second example single correctly getting instead single going see figure way add display,issue,negative,positive,neutral,neutral,positive,positive
722462703,"The documentation should go along with your code in data.transforms. You
can see other splitter’s documentation for inspiration.

On Thu, Nov 5, 2020 at 10:47 AM Yaakov Saxon <notifications@github.com>
wrote:

> Should that documentation go in 05_data.transforms.ipynb? Or somewhere
> else?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/2809#issuecomment-722461275>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCV4OWZR7YC4LIDMVZ3LSOLCKDANCNFSM4RPPOOJQ>
> .
>
",documentation go along code see splitter documentation inspiration wrote documentation go somewhere else thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
722461275,Should that documentation go in 05_data.transforms.ipynb? Or somewhere else?,documentation go somewhere else,issue,negative,neutral,neutral,neutral,neutral,neutral
722235694,"Thanks! I'll change it to DataLoaders. I will update the siim_small dataset with labels and then I'll create the tests and docs. Additionally, I'm planning to create a tutorial similar to the X-ray classification tutorial.",thanks change update create additionally create tutorial similar classification tutorial,issue,positive,positive,neutral,neutral,positive,positive
722069840,"Please before accepting the modifications of this PR check the Notebook I created explaining how to make full sense of this PR. Right now everything works, but the code can be further cleaned. 

Here is the notebook: [encoder and encoder_dp are redundant](https://github.com/arnaujc91/experiments/blob/main/encoder_and_encoder_dp_are_redundant.ipynb)

Thanks a lot! ",please check notebook explaining make full sense right everything work code notebook redundant thanks lot,issue,positive,positive,positive,positive,positive,positive
722010070,"The current version of fastai does not have `start_epoch`. Feel free to create an issue requested support for restarting training, with details about how you'd like to see it work.",current version feel free create issue support training like see work,issue,positive,positive,positive,positive,positive,positive
722008170,Many thanks for the clear reporter and repro!,many thanks clear reporter,issue,positive,positive,positive,positive,positive,positive
722002006,Many thanks for the report. This is due to a problem in PyTorch 1.7 that's already fixed in their master. I'm adding a workaround now.,many thanks report due problem already fixed master,issue,negative,positive,positive,positive,positive,positive
721981072,"@YSaxon, are you still planning to handle to remaining issues? Or would you prefer I closed this PR?",still handle would prefer closed,issue,negative,negative,neutral,neutral,negative,negative
721979859,"Thanks @moritzschwyzer - passing now! I see the class suffix is `DataLoader` instead of `DataLoaders` - is this intentional? If not, could you change it? Also, could you please add docs and tests?",thanks passing see class suffix instead intentional could change also could please add,issue,positive,positive,positive,positive,positive,positive
721971156,"On it. I actually came across this issue on a custom dataset, so i guess my colab notebook won't run on your system(because the data comes from my Google drive). So I'll try to reproduce this error on a generic tensor dataset, or another data, and open a new issue when i do. Thanks for replying!",actually came across issue custom guess notebook wo run system data come drive try reproduce error generic tensor another data open new issue thanks,issue,negative,positive,neutral,neutral,positive,positive
721930876,Thanks @Isaac-Flath! Could you please run `nbdev_clean_nbs`? (this is what the failing test is),thanks could please run failing test,issue,negative,positive,positive,positive,positive,positive
721856245,"@hamelsmu can reproduce:
```python
!pip install fastai --upgrade
!pip install nbdev

from fastai.vision.all import *
doc(show_images)
```
Clicking the `Show in docs` url points to https://docs.fast.ai/torch.core#show_images

Same with anything in `torch_core` I think, as `show_image` did it too.",reproduce python pip install upgrade pip install import doc show anything think,issue,negative,neutral,neutral,neutral,neutral,neutral
721847835,"Thanks for letting me know. Can you please provide a full reproducible example (e.g. a colab notebook, or a standalone script) so we can see the problem? Then we should be able to fix it reasonably quickly.",thanks know please provide full reproducible example notebook script see problem able fix reasonably quickly,issue,negative,positive,positive,positive,positive,positive
721847064,@marii-moe where are you finding this link?  I'm seeing this link https://docs.fast.ai/torch_core#show_images show properly.  ,finding link seeing link show properly,issue,negative,neutral,neutral,neutral,neutral,neutral
721676608,"Currently seeing if I can pull the padding logic into its own transform. This would allow us to remove 'padding removal' from numerizalize.decodes as well as handle tuples of tuples in a cleaner way, of course taking advantage of typedispatch. ",currently seeing pull padding logic transform would allow u remove removal well handle cleaner way course taking advantage,issue,positive,neutral,neutral,neutral,neutral,neutral
721623271,"It always is. The issue had nothing to do with the DataLoader itself moreso
the fact they were passing in both DataLoaders to get_preds. If you can
create a reproducible example of test_dl dropping the last batch please
open an issue however all test_dl’s should not drop the last batch since
they’re generated based on the validation DataLoader.

On Wed, Nov 4, 2020 at 3:09 AM Marcel Ackermann <notifications@github.com>
wrote:

> @jph00 <https://github.com/jph00> @muellerzr
> <https://github.com/muellerzr> Why is the drop_last necessary, though?
> Shouldn't that default to false for a test_dl?
>
> —
> You are receiving this because you were mentioned.
>
>
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2874#issuecomment-721577894>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AB3YCVZXCIZWTOADYYGBI5LSOED2VANCNFSM4SKJRHZQ>
> .
>
",always issue nothing fact passing create reproducible example dropping last batch please open issue however drop last batch since based validation wed marcel wrote necessary though default false reply directly view,issue,negative,negative,neutral,neutral,negative,negative
721577894,"@jph00 @muellerzr Why is the drop_last necessary, though? Shouldn't that default to false for a test_dl?",necessary though default false,issue,negative,negative,negative,negative,negative,negative
721576412,"> 
> 
> I'm not seeing this - perhaps you're running on some OS other than Linux? If you can repro this on Linux with no other libs imported, please reopen with the details.

I am running on Linux, with no other libs.",seeing perhaps running o please reopen running,issue,negative,neutral,neutral,neutral,neutral,neutral
721477655,"Yeah, it seems `pad_input_chunk` only works on the first input, while the second one gets no padding. Currently trying to determine how to handle this issue. Therefore leading to a collate issue because the second one is variable length. ",yeah work first input second one padding currently trying determine handle issue therefore leading collate issue second one variable length,issue,negative,positive,neutral,neutral,positive,positive
721461624,"@jph00 I can reproduce this issue. It looks to stem from the ConvLayer inside of SequentialEx

(minimal reproducer):
```python
path = untar_data(URLs.CAMVID_TINY)
codes = np.loadtxt(path/'codes.txt', dtype=str)
fnames = get_image_files(path/""images"")
def label_func(fn): return path/""labels""/f""{fn.stem}_P{fn.suffix}""
dls = SegmentationDataLoaders.from_label_func(
    path, bs=8, fnames = fnames, label_func = label_func, codes = codes
)
learn = unet_learner(dls, resnet34)
learn.fine_tune(8)
```",reproduce issue stem inside minimal reproducer python path return path learn,issue,negative,negative,neutral,neutral,negative,negative
721429963,"Not 100% sure why it's trying to do the last pr too, let me investigate quickly",sure trying last let investigate quickly,issue,negative,positive,positive,positive,positive,positive
721417614,"@PalaashAgrawal to be able to help we need a the code necessary to reproduce the problem, or a link to your colab notebook.",able help need code necessary reproduce problem link notebook,issue,negative,positive,positive,positive,positive,positive
721414935,"Please use forums.fast.ai for help. GitHub issues is for reporting confirmed bugs. If you're not sure if what you're seeing is a bug, or are not sure how to confirm it, ask for help on the forums. When posting on the forums, we have some suggestions to help you get your problem resolved:

https://forums.fast.ai/t/how-to-ask-for-help/10421",please use help confirmed sure seeing bug sure confirm ask help posting help get problem resolved,issue,positive,positive,positive,positive,positive,positive
721414053,"@adamfarquhar FYI in the future, in the ""To reproduce"" section please provide complete code to reproduce the problem from scratch, rather than just a general description.",future reproduce section please provide complete code reproduce problem scratch rather general description,issue,negative,positive,neutral,neutral,positive,positive
721410164,"@dreamflasher @adamfarquhar the issue is you're trying to pass in a *set* of `DataLoaders`, where `get_preds` can only get inference on **one** `DataLoader` at a time. @dreamflasher solution is correct because it is the proper way to use the inference API. ",issue trying pas set get inference one time solution correct proper way use inference,issue,negative,neutral,neutral,neutral,neutral,neutral
721403300,"@sidwa I copied and pasted that into a notebook, and it worked for me. So maybe a data problem or you're not on Linux. I'd suggest asking on the forums. If you can find a sequence of steps that reliably reproduces the issue on a fresh install, please reopen this issue.",copied pasted notebook worked maybe data problem suggest find sequence reliably issue fresh install please reopen issue,issue,negative,positive,positive,positive,positive,positive
721400510,Sorry we're not able to provide help thru gh issues,sorry able provide help,issue,negative,neutral,neutral,neutral,neutral,neutral
721399917,I feel like that would be a bit too overloaded for my liking - but thanks for the suggestion! :) ,feel like would bit liking thanks suggestion,issue,positive,positive,positive,positive,positive,positive
721388911,That's true. I'd be happy to take a PR if you're interested in fixing this in a similar way to the earlier example.,true happy take interested fixing similar way example,issue,positive,positive,positive,positive,positive,positive
721387885,"You didn't provide a repro so I don't actually know if I fixed it - but I made a change to load back the orig `opt` after `lr_find`, so hopefully it's fixed now. I couldn't repro the fp16 issue at all. Here's what I did

```
from fastai.vision.all import *

path = untar_data(URLs.PETS)
files = get_image_files(path/""images"")
def label_func(f): return f[0].isupper()
dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224), n_workers=8)
learn = cnn_learner(dls, resnet34, metrics=error_rate).to_fp16()
learn.lr_find()
```

Please reopen if there's still a problem and you can provide a minimal repro.",provide actually know fixed made change load back opt hopefully fixed could issue import path return path learn please reopen still problem provide minimal,issue,negative,positive,neutral,neutral,positive,positive
721333934,"Ignore this, accidently went to the wrong branch!",ignore accidently went wrong branch,issue,negative,negative,negative,negative,negative,negative
721325137,"Oh OK great - yeah stuff like `setups` certainly doesn't need to be in the docs or part of `__all__`, so that's fine. As long as the transform classes themselves are exported.
",oh great yeah stuff like certainly need part fine long transform class,issue,positive,positive,positive,positive,positive,positive
721324517,"This should be able to be closed now. I've posted in the documentation in both tabular.core as well as tabular.tutorial this explanation: 

> Note: Since machine learning models can't magically understand categories it was never trained on, the data should reflect this. If there are different missing values in your test data you should address this before training",able closed posted documentation well explanation note since machine learning ca magically understand never trained data reflect different missing test data address training,issue,negative,positive,positive,positive,positive,positive
721322212,"@jph00 it's meant to clean up sections like so:
https://docs.fast.ai/tabular.core#setups

Aka places where `@Categorize` and `@Normalize` are. They don't display well in the documentation, and results in a very awkward looking placeholder where we might not necessarily *want* to show `encodes`, `decodes`, etc but rather say `Normalize`

One compromise I can think of is a `show_doc` or manual doc (since `show_doc` won't show this new behavior) to describe that the `proc` is available and modified. I'm open to your ideas though",meant clean like aka categorize normalize display well documentation awkward looking might necessarily want show rather say normalize one compromise think manual doc since wo show new behavior describe available open though,issue,positive,positive,neutral,neutral,positive,positive
721318732,"This looks great! I didn't see where you added `exporti`, but note that iirc this removes from `__all__`, which is possibly not what you meant to do? If not, perhaps undo that with a followup PR? Let me know what cleanup you were trying to achieve with it. Note that you can always put `show_doc` for a symbol somewhere else in an nb, to stop it from displaying in the default place",great see added note possibly meant perhaps undo let know cleanup trying achieve note always put symbol somewhere else stop default place,issue,negative,positive,positive,positive,positive,positive
721282999,Yes please do go ahead and modify the tests. Many thanks!,yes please go ahead modify many thanks,issue,positive,positive,positive,positive,positive,positive
721243040,@jph00 let me know if there are any other improvements you can think of or better ways to rephrase that ,let know think better way rephrase,issue,negative,positive,positive,positive,positive,positive
721185065,"Yes, with ```fastai==2.1.3``` it started working, again. However, for ```camvid``` notebook I get:

```
epoch	train_loss	valid_loss	acc_camvid	time
0	None	None	00:00
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-32-bc39e9e85f86> in <module>()
----> 1 learn.summary()

25 frames
/usr/local/lib/python3.6/dist-packages/torch/tensor.py in __deepcopy__(self, memo)
     75                         self._backward_hooks)
     76                 else:
---> 77                     new_tensor = self.new()
     78                     new_tensor.set_(new_storage, self.storage_offset(), self.size(), self.stride())
     79                     new_tensor.requires_grad = self.requires_grad

TypeError: new() missing 1 required positional argument: 'x'
```

Notebook is here: https://colab.research.google.com/drive/1SeSDhItCTldlLGZIzfS0QFQCha5_RvP4?usp=sharing",yes working however notebook get epoch time none none recent call last module self memo else new missing positional argument notebook,issue,negative,negative,neutral,neutral,negative,negative
721082391,"I modified the PR to pass the previous test, but now is failing in another test:

```
      1 enc = nn.Embedding(10, 7, padding_idx=1)
----> 2 enc_dp = EmbeddingDropout(enc, 0.5)
      3 tst_inp = torch.randint(0,10,(8,))
      4 tst_out = enc_dp(tst_inp)
      5 for i in range(8):
```
This is because the class `EmbeddingDropout` expects that you pass it an instance of `nn.Embedding` to the constructor but precisely the point of my PR is that the new `EmbeddingDropout` does *not* need an instance of `nn.Embedding`. So either I can change this test or the tests are too rigid for this PR to make sense.  

As I explained in the previous [Notebook](https://github.com/arnaujc91/experiments/blob/main/EmbeddingDropout_new.ipynb) there are two possibilities to fix the ActivationStats problem:

1. Modify flatten_model
2. Modify EmbeddingDropout

I decided to modify EmbeddingDropout. The reason was twofold: it simplified the code and it solved the issue with the hooks.  My current modification just affects `EmbeddingDropout`; `AWD_LST` stays the same. Do you really need that `EmbeddingDropout` requires an instance of `nn.Embedding` in other parts of the library?

If the tests can't be modified then I will need to close this PR and maybe check if i can modify flatten_model instead. 

Can you or me modify the tests for the layer EmbeddingDropout?

Thanks a lot Jeremy.  ",pas previous test failing another test range class pas instance constructor precisely point new need instance either change test rigid make sense previous notebook two fix problem modify modify decided modify reason twofold simplified code issue current modification stay really need instance library ca need close maybe check modify instead modify layer thanks lot,issue,negative,positive,neutral,neutral,positive,positive
720941582,"VisibleDeprecationWarning I am still looking into, but that may be out of scope of this fix. Please tell me if you would like that fixed before accepting this pull request. 

Below is an example of what it looks like with the fix in place, as well as showing that the first one is much longer than the following examples as you guessed. 

https://gist.github.com/marii-moe/cdec63f28299af106d09c68595a95fff

Converting this back to a pull request. I found some behavior I found odd, though I think the effect it has will be minimal. It might just be that I am not as familiar with NLP data. 

""i believe the problem is a data problem
i think it's just that the first row is really long""
Yes the first row is very long, actually it is always the longest item! Though previous versions of the tutorial also had the exact same element as the first item. More analysis in the gist. Check here: https://docs.fast.ai/tutorial.text

""so there's lots of paddin
would be good to confirm that, and if it's true, figure out why it's started happening recently (in the last couple of months IIRC) and how best to fix it""

Hard for me to go back into history, but I believe this was always mostly random(analysis in gist). We just previously filtered out padding when doing `show_batch`.",still looking may scope fix please tell would like fixed pull request example like fix place well showing first one much longer following converting back pull request found behavior found odd though think effect minimal might familiar data believe problem data problem think first row really long yes first row long actually always item though previous tutorial also exact element first item analysis gist check lot would good confirm true figure happening recently last couple best fix hard go back history believe always mostly random analysis gist previously padding,issue,positive,positive,positive,positive,positive,positive
720933629,"I found the link by typing 'callbacks' into the search bar, and searching by Relevance. It was the second search result.",found link search bar searching relevance second search result,issue,negative,neutral,neutral,neutral,neutral,neutral
720886305,"I see the same issue.
I'm using google colab, and mostly all fastai defaults.
the problem arises during learn.fit()

> 
> `/usr/local/lib/python3.6/dist-packages/fastcore/logargs.py in _f(*args, **kwargs)
>      54         init_args.update(log)
>      55         setattr(inst, 'init_args', init_args)
> ---> 56         return inst if to_return else f(*args, **kwargs)
>      57     return _f
> 
> /usr/local/lib/python3.6/dist-packages/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)
>     111     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),
>     112               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}
> --> 113     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)
>     114 
>     115 # Cell
> 
> /usr/local/lib/python3.6/dist-packages/fastcore/logargs.py in _f(*args, **kwargs)
>      54         init_args.update(log)
>      55         setattr(inst, 'init_args', init_args)
> ---> 56         return inst if to_return else f(*args, **kwargs)
>      57     return _f
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
>     205             self.opt.set_hypers(lr=self.lr if lr is None else lr)
>     206             self.n_epoch = n_epoch
> --> 207             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
>     208 
>     209     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
>     153 
>     154     def _with_events(self, f, event_type, ex, final=noop):
> --> 155         try:       self(f'before_{event_type}')       ;f()
>     156         except ex: self(f'after_cancel_{event_type}')
>     157         finally:   self(f'after_{event_type}')        ;final()
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_fit(self)
>     195         for epoch in range(self.n_epoch):
>     196             self.epoch=epoch
> --> 197             self._with_events(self._do_epoch, 'epoch', CancelEpochException)
>     198 
>     199     @log_args(but='cbs')
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
>     153 
>     154     def _with_events(self, f, event_type, ex, final=noop):
> --> 155         try:       self(f'before_{event_type}')       ;f()
>     156         except ex: self(f'after_cancel_{event_type}')
>     157         finally:   self(f'after_{event_type}')        ;final()
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_epoch(self)
>     189 
>     190     def _do_epoch(self):
> --> 191         self._do_epoch_train()
>     192         self._do_epoch_validate()
>     193 
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in _do_epoch_train(self)
>     181     def _do_epoch_train(self):
>     182         self.dl = self.dls.train
> --> 183         self._with_events(self.all_batches, 'train', CancelTrainException)
>     184 
>     185     def _do_epoch_validate(self, ds_idx=1, dl=None):
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
>     153 
>     154     def _with_events(self, f, event_type, ex, final=noop):
> --> 155         try:       self(f'before_{event_type}')       ;f()
>     156         except ex: self(f'after_cancel_{event_type}')
>     157         finally:   self(f'after_{event_type}')        ;final()
> 
> /usr/local/lib/python3.6/dist-packages/fastai/learner.py in all_batches(self)
>     159     def all_batches(self):
>     160         self.n_iter = len(self.dl)
> --> 161         for o in enumerate(self.dl): self.one_batch(*o)
>     162 
>     163     def _do_one_batch(self):
> 
> /usr/local/lib/python3.6/dist-packages/fastai/data/load.py in __iter__(self)
>     100         self.before_iter()
>     101         self.__idxs=self.get_idxs() # called in context of main process (not workers/subprocesses)
> --> 102         for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
>     103             if self.device is not None: b = to_device(b, self.device)
>     104             yield self.after_batch(b)
> 
> /usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py in __init__(self, loader)
>     735             #     before it starts, and __del__ tries to join but will get:
>     736             #     AssertionError: can only join a started process.
> --> 737             w.start()
>     738             self._index_queues.append(index_queue)
>     739             self._workers.append(w)
> 
> /usr/lib/python3.6/multiprocessing/process.py in start(self)
>     103                'daemonic processes are not allowed to have children'
>     104         _cleanup()
> --> 105         self._popen = self._Popen(self)
>     106         self._sentinel = self._popen.sentinel
>     107         # Avoid a refcycle if the target function holds an indirect
> 
> /usr/lib/python3.6/multiprocessing/context.py in _Popen(process_obj)
>     221     @staticmethod
>     222     def _Popen(process_obj):
> --> 223         return _default_context.get_context().Process._Popen(process_obj)
>     224 
>     225 class DefaultContext(BaseContext):
> 
> /usr/lib/python3.6/multiprocessing/context.py in _Popen(process_obj)
>     282         def _Popen(process_obj):
>     283             from .popen_spawn_posix import Popen
> --> 284             return Popen(process_obj)
>     285 
>     286     class ForkServerProcess(process.BaseProcess):
> 
> /usr/lib/python3.6/multiprocessing/popen_spawn_posix.py in __init__(self, process_obj)
>      30     def __init__(self, process_obj):
>      31         self._fds = []
> ---> 32         super().__init__(process_obj)
>      33 
>      34     def duplicate_for_child(self, fd):
> 
> /usr/lib/python3.6/multiprocessing/popen_fork.py in __init__(self, process_obj)
>      17         util._flush_std_streams()
>      18         self.returncode = None
> ---> 19         self._launch(process_obj)
>      20 
>      21     def duplicate_for_child(self, fd):
> 
> /usr/lib/python3.6/multiprocessing/popen_spawn_posix.py in _launch(self, process_obj)
>      45         try:
>      46             reduction.dump(prep_data, fp)
> ---> 47             reduction.dump(process_obj, fp)
>      48         finally:
>      49             set_spawning_popen(None)
> 
> /usr/lib/python3.6/multiprocessing/reduction.py in dump(obj, file, protocol)
>      58 def dump(obj, file, protocol=None):
>      59     '''Replacement for pickle.dump() using ForkingPickler.'''
> ---> 60     ForkingPickler(file, protocol).dump(obj)
>      61 
>      62 #
> 
> /usr/local/lib/python3.6/dist-packages/torch/multiprocessing/reductions.py in reduce_storage(storage)
>     308     from . import get_sharing_strategy
>     309     if storage.is_cuda:
> --> 310         raise RuntimeError(""Cannot pickle CUDA storage; try pickling a CUDA tensor instead"")
>     311     elif get_sharing_strategy() == 'file_system':
>     312         metadata = storage._share_filename_()
> 
> RuntimeError: Cannot pickle CUDA storage; try pickling a CUDA tensor instead`",see issue mostly problem log return else return self div none else cell log return else return fit self none else self none none none none none self ex final self ex try self except ex self finally self final self epoch range self ex final self ex try self except ex self finally self final self self self self self self ex final self ex try self except ex self finally self final self self enumerate self self context main process none yield self loader join get join process start self self avoid target function indirect return class import return class self self super self self none self self try finally none dump file protocol dump file file protocol storage import raise pickle storage try tensor instead pickle storage try tensor instead,issue,positive,positive,neutral,neutral,positive,positive
720870598,I am able to reproduce this issue in my local environment. ,able reproduce issue local environment,issue,negative,positive,positive,positive,positive,positive
720863639,I'd be most happy to see your more verbose thinking :) ,happy see verbose thinking,issue,positive,positive,positive,positive,positive,positive
720844038,"@jph00 I don't think the solution to this has to be more than simply a note saying that it will do so, as adding ""blank"" NaN's would lead to bad results. If you agree with this thinking I can be a bit more verbose",think solution simply note saying blank nan would lead bad agree thinking bit verbose,issue,negative,negative,negative,negative,negative,negative
720812959,Thanks @arnaujc91  - I'm still seeing the test failure however. Would you be able to fix that?,thanks still seeing test failure however would able fix,issue,negative,positive,positive,positive,positive,positive
720812417,Many thanks for the fix! Apologies for the CI fail - wasn't anything to do with you.,many thanks fix fail anything,issue,negative,positive,neutral,neutral,positive,positive
720812078,Thanks @Isaac-Flath - we're rewriting nbdev from scratch so this problem will fix itself. So I'll close this now. cc @hamelsmu ,thanks scratch problem fix close,issue,negative,positive,positive,positive,positive,positive
720808850,"I'm not seeing this - perhaps you're running on some OS other than Linux? If you can repro this on Linux with no other libs imported, please reopen with the details.",seeing perhaps running o please reopen,issue,negative,neutral,neutral,neutral,neutral,neutral
720808262,@muellerzr would you be open to taking a look at this? Do you already have a notebook that might be suitable?,would open taking look already notebook might suitable,issue,negative,positive,positive,positive,positive,positive
720807996,"Thanks for filing the issue. In general, please show how to repro with data supported by `URLs`, since otherwise we have to figure out what dataset you're using, how to download, set it up, etc. Using `URLs.PETS` works for me, so I'm guessing this might be a data or code issue at your end. If you can reproduce this problem with a fastai dataset, feel free to reopen this. Here's what worked for me:

```
from fastai.vision.all import *

fnames = get_image_files(untar_data(URLs.PETS))
dls = ImageDataLoaders.from_name_re(
    path, fnames, pat=r'(.+)_\d+.(?:png|jpg)$', item_tfms=Resize(460), bs=12,
    batch_tfms=[*aug_transforms(size=224, min_scale=0.75), Normalize.from_stats(*imagenet_stats)])

learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.summary()
```
",thanks filing issue general please show data since otherwise figure set work guessing might data code issue end reproduce problem feel free reopen worked import path learn,issue,positive,positive,positive,positive,positive,positive
720804541,"This isn't enough info for us to reproduce the problem, however there's been some recent bug fixes so try the latest version, and if you're still having problems, please ask for help on forums.fast.ai.",enough u reproduce problem however recent bug try latest version still please ask help,issue,negative,positive,positive,positive,positive,positive
720794180,"I haven't taken a look at this myself, but this may be related to RandomResizeCrop being a batch transform, instead of applying the transform differently to each item in a batch. ",taken look may related batch transform instead transform differently item batch,issue,negative,neutral,neutral,neutral,neutral,neutral
720782222,@actcod01  I notice you are using fastai version 1. I think that code is now found here: https://github.com/fastai/fastai1,notice version think code found,issue,negative,neutral,neutral,neutral,neutral,neutral
720713398,"Yeah sorry what I said was wrong - anyhoo I've patched the PyTorch bug now so `new` works again :)
",yeah sorry said wrong bug new work,issue,negative,negative,negative,negative,negative,negative
720532838,"I tried to update line 172 of fastai.text.learner in the LMLearner.predict() method to:
```
idxs.new_tensor([idx])
```
And it throws the following error:
```
new_tensor() missing 1 required positional arguments: ""data""
```
The issue is that this works with pytorch 1.7
```
t = torch.Tensor([1.,2,3])
idx = 4
t.new_tensor([idx])
```
But this doesn't:
```
tt = TensorText([1.,2,3])
idx = 4
tt.new_tensor([idx])
```",tried update line method following error missing positional data issue work,issue,negative,negative,neutral,neutral,negative,negative
720418968,"Just update your Fast AI.
for pip:
pip install --upgrade fastai
",update fast ai pip pip install upgrade,issue,negative,positive,positive,positive,positive,positive
720218053,"My bad - I actually knew about this issue already, but forgot to rigorously check for it. It's actually a change in the PyTorch behavior of `Tensor.new`. We need to replace *all* uses of `new` with `new_empty` for any kind of tensor.

I'll work on fixing this myself tomorrow, time permitting - although a PR in the meantime if you happen to have the time and inclination would be most welcome.

It also sounds like we're missing tests to cover some functionality, since we clearly have bugs which aren't being picked up by tests! :(
",bad actually knew issue already forgot rigorously check actually change behavior need replace new kind tensor work fixing tomorrow time although happen time inclination would welcome also like missing cover functionality since clearly picked,issue,positive,positive,neutral,neutral,positive,positive
720209711,"Hi, 

Despite #2927 fixing one instance of this issue, I'm afraid that this incompatibility is more pervasive. Another case is in line 172 of fastai.text.learner in the `LMLearner.predict()` method. Calling `idxs.new([idx])` is returning an empty `TensorText`.

I'm happy to do what I can to try to spot other instances with a broad find and replace but I worry that I won't always know when the tensor is `TensorText` and whether this issue extends to other subclasses of `torch.Tensor`.
",hi despite fixing one instance issue afraid incompatibility pervasive another case line method calling empty happy try spot broad find replace worry wo always know tensor whether issue,issue,negative,positive,neutral,neutral,positive,positive
720209204,"Hi Jeremy,

I'm afraid that this incompatibility is more pervasive than just this instance (I was afraid of that!). Another case is in line 172 of fastai.text.learner in the `LMLearner.predict()` method. Again, calling `idxs.new([idx])` is returning an empty TensorText. 

I'm happy to do what I can to try to spot other instances with a broad find and replace but I worry that I won't always know when the tensor is `TensorText` and whether this issue extends to other sublasses of `torch.Tensor`. ",hi afraid incompatibility pervasive instance afraid another case line method calling empty happy try spot broad find replace worry wo always know tensor whether issue,issue,negative,negative,neutral,neutral,negative,negative
720169391,"This can be closed, as the solution was posted in that thread. We have `RandomSubsetSplitter` for this.

(cc @jph00)",closed solution posted thread,issue,negative,negative,neutral,neutral,negative,negative
720168526,A PR would be most welcome :) . Thanks for noting the problem and the fix. I agree your suggested fix looks right.,would welcome thanks problem fix agree fix right,issue,positive,positive,positive,positive,positive,positive
720165930,"OK I've just made a `2.0.19` release which is compatible with fastcore 1.3, so hopefully this will make the problem go away, even although I'm still mystified as to what actually happened! :D ",made release compatible hopefully make problem go away even although still actually,issue,negative,neutral,neutral,neutral,neutral,neutral
720165550,"I don't know if this helps @muellerzr but I build the docker containers with fastai daily and they are tagged with a version number https://hub.docker.com/repository/docker/fastdotai/fastai/tags?page=1

You can search for any version number and then run the associated container to find the version of fastcore.  That might save you some trouble in the future.  (I had anticipated this and that is why I'm taking snapshots of each fastai version).

HTH",know build docker daily tagged version number search version number run associated container find version might save trouble future taking version,issue,negative,negative,neutral,neutral,negative,negative
720165032,"Sorry about these troubles folks! I'm confused though - there is no fastcore 1.2.6 on pypi, conda, or github. The last 1.2 release was 1.2.5, which I just tested and is compatible with the last 2.0 fastai release, and was auto-installed correctly when I installed that through pip.",sorry confused though last release tested compatible last release correctly pip,issue,negative,negative,negative,negative,negative,negative
720159883,"I've described the solution and reason in this thread but essentially here is what is happening:

Fastai doesn’t pin the fastcore version each one uses. As a result it will install the most recent version all the time. The fix (until Jeremy can find a better way) is to look at the release of fastai you are working on, and the releases of fastcore (through the pypi website) and find the version to install through the date.

For example if my fastai version was 2.0.16, I would look for the fastcore version released around October 8th, which would be 1.1.0. (This is a MVP for the versioning, there could be compatible fastcore versions above that, but this is guaranteed to get your version working)

pypi [fastai](https://pypi.org/project/fastai/#history) and [fastcore](https://pypi.org/project/fastcore/#history)",solution reason thread essentially happening pin version one result install recent version time fix find better way look release working find version install date example version would look version around th would could compatible get version working,issue,positive,positive,positive,positive,positive,positive
719996086,"Having the same issue. Installed pytorch 1.6.0 although did not want to and then ended up with the following error:

```
---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
<ipython-input-2-02dd30090e2f> in <module>
     22 
     23 # import torch
---> 24 from fastai.tabular.all import *
     25 from fastai.data.all import *

F:\Anaconda3\envs\gemo\lib\site-packages\fastai\tabular\all.py in <module>
----> 1 from ..basics import *
      2 from ..callback.all import *
      3 from .core import *
      4 from .data import *
      5 from .model import *

F:\Anaconda3\envs\gemo\lib\site-packages\fastai\basics.py in <module>
----> 1 from .data.all import *
      2 from .optimizer import *
      3 from .callback.core import *
      4 from .learner import *
      5 from .metrics import *

F:\Anaconda3\envs\gemo\lib\site-packages\fastai\data\all.py in <module>
----> 1 from ..torch_basics import *
      2 from .core import *
      3 from .load import *
      4 from .external import *
      5 from .transforms import *

F:\Anaconda3\envs\gemo\lib\site-packages\fastai\torch_basics.py in <module>
----> 1 from torch import multiprocessing
      2 import platform,os
      3 if platform.system()=='Darwin':
      4     # Python 3.8 changed to 'spawn' but that doesn't work with PyTorch DataLoader w n_workers>0
      5     multiprocessing.set_start_method('fork', force=True)

F:\Anaconda3\envs\gemo\lib\site-packages\torch\__init__.py in <module>
    114                 err = ctypes.WinError(last_error)
    115                 err.strerror += ' Error loading ""{}"" or one of its dependencies.'.format(dll)
--> 116                 raise err
    117             elif res is not None:
    118                 is_loaded = True

OSError: [WinError 127] The specified procedure could not be found. Error loading ""F:\Anaconda3\envs\gemo\lib\site-packages\torch\lib\caffe2_detectron_ops_gpu.dll"" or one of its dependencies.
```",issue although want ended following error recent call last module import torch import import module import import import import import module import import import import import module import import import import import module torch import import platform o python work module err error loading one raise err none true procedure could found error loading one,issue,negative,positive,neutral,neutral,positive,positive
719981033,Very cool. Can you please resolve the conflicts and at-mention me so I can merge when ready?,cool please resolve merge ready,issue,positive,positive,positive,positive,positive,positive
719947079,I got the same error as I was going through fastai's intro_1 notebook,got error going notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
719930381,Thanks a lot oguiza . Your suggestion worked .,thanks lot suggestion worked,issue,negative,positive,positive,positive,positive,positive
719916150,I noticed on reviewnb the augmentation notebook ended up being formatted weirdly around the warp transform. It looks fine in my local and here: https://github.com/fastai/fastai/blob/bae078f9a18ee392c78d762471b55a240c7ef675/nbs/09_vision.augment.ipynb,augmentation notebook ended weirdly around warp transform fine local,issue,negative,negative,neutral,neutral,negative,negative
719907556,For some reason my local environment is broken with the newest version. Going to close this for now. ,reason local environment broken version going close,issue,negative,negative,negative,negative,negative,negative
719901223,"Hi, 
I've now updated to the most recent versions or fastai and fastcore, as well as torch 1.7:
fastai     : 2.1.2
fastcore: 1.3.1
torch     : 1.7.0

and have noticed the issue doesn't occur again. 
However, I've left this open as anyone using torch 1.6 and fastai <2.1 may have the same issue. 
A workaround that worked for me is to install fastcore=1.2.5 -and fastai=2.0.18.",hi recent well torch torch issue occur however left open anyone torch may issue worked install,issue,negative,neutral,neutral,neutral,neutral,neutral
719879429,"I came across the same issue, while running **load_learner(path)**
Here's the full stack trace...

```

----> 1 learn=load_learner(path_sgt/'sgmt_halfsz.pkl')

9 frames
/usr/local/lib/python3.6/dist-packages/fastai/learner.py in load_learner(fname, cpu)
    547     ""Load a `Learner` object in `fname`, optionally putting it on the `cpu`""
    548     distrib_barrier()
--> 549     res = torch.load(fname, map_location='cpu' if cpu else None)
    550     if hasattr(res, 'to_fp32'): res = res.to_fp32()
    551     if cpu: res.dls.cpu()

/usr/local/lib/python3.6/dist-packages/torch/serialization.py in load(f, map_location, pickle_module, **pickle_load_args)
    582                     opened_file.seek(orig_position)
    583                     return torch.jit.load(opened_file)
--> 584                 return _load(opened_zipfile, map_location, pickle_module, **pickle_load_args)
    585         return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
    586 

/usr/local/lib/python3.6/dist-packages/torch/serialization.py in _load(zip_file, map_location, pickle_module, **pickle_load_args)
    840     unpickler = pickle_module.Unpickler(data_file, **pickle_load_args)
    841     unpickler.persistent_load = persistent_load
--> 842     result = unpickler.load()
    843 
    844     return result

/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in _fa_rebuild_tensor(cls, *args, **kwargs)
    188 
    189 # Cell
--> 190 def _fa_rebuild_tensor (cls, *args, **kwargs): return cls(torch._utils._rebuild_tensor_v2(*args, **kwargs))
    191 def _fa_rebuild_qtensor(cls, *args, **kwargs): return cls(torch._utils._rebuild_qtensor  (*args, **kwargs))
    192 

/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in __new__(cls, x, **kwargs)
    300 class TensorBase(Tensor):
    301     def __new__(cls, x, **kwargs):
--> 302         res = cast(tensor(x), cls)
    303         if kwargs: res._meta = kwargs
    304         return res

/usr/local/lib/python3.6/dist-packages/fastcore/dispatch.py in __call__(self, *args, **kwargs)
    127         elif self.inst is not None: f = MethodType(f, self.inst)
    128         elif self.owner is not None: f = MethodType(f, self.owner)
--> 129         return f(*args, **kwargs)
    130 
    131     def __get__(self, inst, owner):

/usr/local/lib/python3.6/dist-packages/fastcore/dispatch.py in cast(x, typ)
    188     res = typ._before_cast(x) if hasattr(typ, '_before_cast') else x
    189     if isinstance_str(res, 'ndarray'): res = res.view(typ)
--> 190     elif hasattr(res, 'as_subclass'): res = res.as_subclass(typ)
    191     else:
    192         try: res.__class__ = typ

/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in as_subclass(self, typ)
    295 def as_subclass(self:Tensor, typ):
    296     ""Cast to `typ` and include `__dict__` and meta""
--> 297     return retain_meta(self, torch.as_subclass(self, typ))
    298 
    299 # Cell

/usr/local/lib/python3.6/dist-packages/fastcore/dispatch.py in retain_meta(x, res, as_copy)
    170 def retain_meta(x, res, as_copy=False):
    171     ""Call `res.set_meta(x)`, if it exists""
--> 172     if hasattr(res,'set_meta'): res.set_meta(x, as_copy=as_copy)
    173     return res
    174 

/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py in _f(self, *args, **kwargs)
    329         def _f(self, *args, **kwargs):
    330             cls = self.__class__
--> 331             res = getattr(super(TensorBase, self), fn)(*args, **kwargs)
    332             return retain_type(res, self, copy_meta=True)
    333         return _f

TypeError: set_meta() got an unexpected keyword argument 'as_copy'
```",came across issue running path full stack trace load learner object optionally else none load return return return result return result cell return return class tensor cast tensor return self none none return self owner cast else else try self self tensor cast include meta return self self cell call return self self super self return self return got unexpected argument,issue,negative,positive,positive,positive,positive,positive
719793373,"Everything should be working now. If anyone finds something not working for them, please open an issue with full details.",everything working anyone something working please open issue full,issue,negative,positive,positive,positive,positive,positive
719735171,Actually I've just finished updating fastai for pytorch 1.7. I added full support for `persistent_workers`.,actually finished added full support,issue,negative,positive,positive,positive,positive,positive
719722329,"> Also, it looks like you forgot to `nbdev_build_lib`.

I assume you meant `ndbev_update_lib` (`nbdev_build_lib` overwrote the lib changes in favor of what was in the nbs). When I run update_lib, it changes many of the nbs aside from just the ones relevant to my changes. For example: 
``` 
""_all_ = ['progress_bar','master_bar']""
```
changes to:
```
""#nbdev_comment _all_ = ['progress_bar','master_bar']""
```
From looking at nbdev, this appears to be intentional behavior. I hesitate to include those changes because they're unrelated to the changes I'm aiming for in this PR. Should I include those nbdev changes anyway?",also like forgot assume meant favor run many aside relevant example looking intentional behavior hesitate include unrelated aiming include anyway,issue,negative,positive,positive,positive,positive,positive
718923750,For some reason 3 tests failed and I didn't know why. I'd be happy have this pull request merged.,reason know happy pull request,issue,positive,positive,positive,positive,positive,positive
718902287,Why did you close this @moritzschwyzer ? Are you doing another version? Or have you decided you don't want to contribute this?,close another version decided want contribute,issue,negative,neutral,neutral,neutral,neutral,neutral
718553164,"> Any solution to this? I encountered the same problem and could not even finish the first course. Thanks much!

I have the same problem too.. frustrating. I know use Paperspace untill there is a solution",solution problem could even finish first course thanks much problem know use untill solution,issue,negative,positive,positive,positive,positive,positive
718330316,I am wondering whether there is any update on this. I encountered the same issue and cannot finish course 1..Thanks much!,wondering whether update issue finish course thanks much,issue,negative,positive,positive,positive,positive,positive
718329968,Any solution to this? I encountered the same problem and could not even finish the first course. Thanks much!,solution problem could even finish first course thanks much,issue,negative,positive,positive,positive,positive,positive
717466105,Thanks for letting me know - I better get on to this then! :) ,thanks know better get,issue,positive,positive,positive,positive,positive,positive
717415959,I just have seen that they released torch's & torchvision's next release on PyPI.,seen torch next release,issue,negative,neutral,neutral,neutral,neutral,neutral
716925542,Actually just noticed that everything BUT the exact docs haven't been updated here. Will get to that momentarily. ,actually everything exact get momentarily,issue,negative,positive,positive,positive,positive,positive
716815470,"Ok, I have created a notebook where I tried to explain as good as possible why I am doing this PR and what are the possible solutions that I see to the problem. 

See the following notebook: [EmbeddingDropout](https://github.com/arnaujc91/experiments/blob/main/EmbeddingDropout_new.ipynb)

P.S. I updated again the notebook. Let me know what you think. Thanks a lot!
",notebook tried explain good possible possible see problem see following notebook notebook let know think thanks lot,issue,negative,positive,positive,positive,positive,positive
716761502,"I am seeing the same issue on the newer version.

fastai : 2.0.16
fastcore : 1.2.3

```python
from fastai.vision.all import *
path = untar_data(URLs.PETS)/'images'


def is_cat(x): return x[0].isupper()
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224))

# TypeError: TypeError: unsupported operand type(s) for -: 'NoneType' and 'float'
learn = cnn_learner(dls, resnet34, metrics=error_rate, cbs = [SaveModelCallback()])

# IndexError: list index out of range
# learn = cnn_learner(dls, resnet34, metrics=error_rate, cbs = [ShowGraphCallback()])
learn.summary()
```


",seeing issue version python import path return path path unsupported operand type learn list index range learn,issue,negative,neutral,neutral,neutral,neutral,neutral
716535903,"Thanks @arnaujc91 . Can you please fix the test failure shown here in CI? It's saying `ModuleAttributeError: 'AWD_LSTM' object has no attribute 'encoder_dp'`. Also, could you add to the notebook some basic docs and a test or example for `EmbeddingDropout` so that I can understand the new code you've added?",thanks please fix test failure shown saying object attribute also could add notebook basic test example understand new code added,issue,negative,positive,neutral,neutral,positive,positive
716203607,"Hey @sutt !

encoder_dp is just used if `from_embeds=False`, which it is by default. In case `from_embeds=True` basically we are skipping the `self.encoder` layer from AWD_LSTM because we are using an external encoder/embedding. So this does not affect the changes I did, my changes just take place for `from_embeds=False` which is by default.

Yes I saw that the test failed because there must be a `self.encoder` layer. I am thinking about just renaming the current `self.encoder_dp` to `self.encoder`. Do you know if `self.encoder_dp` must be also in the class? Do you know where I can check the tests to make my changes such that they will pass them?

Thanks a lot Will, I have learned a lot doing this! Thank you for your time and patience! ",hey used default case basically skipping layer external affect take place default yes saw test must layer thinking current know must also class know check make pas thanks lot learned lot thank time patience,issue,positive,positive,neutral,neutral,positive,positive
716191270,"@arnaujc91
I think you need to leave in the `AWD_LSTM.encoder` object. This will also get the test to pass for your PR. Or maybe just change the test, I think you are correct encoder never gets used on its own.
The forward method might use bypass encoder_dp when using the with_embeds argument.
```
def forward(self, inp, from_embeds=False):
        bs,sl = inp.shape[:2] if from_embeds else inp.shape
        if bs!=self.bs: self._change_hidden(bs)

        output = self.input_dp(inp if from_embeds else self.encoder_dp(inp))
```
I've searched the repository for an example of using `from_embeds=True` but there are no examples of how this should work.
As to *why* this exists, I can't say for certain, but I'd check out Jeremy's paper on ULMFiT (https://arxiv.org/abs/1801.06146) where he uses an AWD_LSTM. I think what happens is you're fitting a model on say Wikipedia to create a pretrained model, then you get ""expanded"" embeddings when fine tuning on a specific domain (e.g. IMDB) where certain vocabulary might be more/less common. 

Nice work!",think need leave object also get test pas maybe change test think correct never used forward method might use bypass argument forward self else output else repository example work ca say certain check paper think fitting model say create model get expanded fine tuning specific domain certain vocabulary might common nice work,issue,positive,positive,positive,positive,positive,positive
716069605,"Found a solution! Just wrote a new `EmbeddingDropout` class, and modified a couple of line from the original code of `AWD_LSTM`. Now the hooks work good and besides there is no duplication of layers while using `flatten_model`. 

```
class EmbeddingDropout(nn.Embedding):
    ""Apply dropout with probability `embed_p` to an embedding layer `emb`.""
    def __init__(self, *args, embed_p, **kwargs):
        super().__init__(*args, **kwargs)
        self.embed_p = embed_p

    def forward(self, words, scale=None):
        if self.training and self.embed_p != 0:
            size = (self.weight.size(0),1)
            mask = dropout_mask(self.weight.data, size, self.embed_p)
            masked_embed = self.weight * mask
        else: masked_embed = self.weight
        if scale: masked_embed.mul_(scale)
        return F.embedding(words, masked_embed, ifnone(self.padding_idx, -1), self.max_norm,
                       self.norm_type, self.scale_grad_by_freq, self.sparse)
        
class AWD_LSTM(Module):
    ""AWD-LSTM inspired by https://arxiv.org/abs/1708.02182""
    initrange=0.1

    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token=1, hidden_p=0.2, input_p=0.6, embed_p=0.1,
                 weight_p=0.5, bidir=False):
        store_attr('emb_sz,n_hid,n_layers,pad_token')
        self.bs = 1
        self.n_dir = 2 if bidir else 1
        self.encoder_dp = EmbeddingDropout(vocab_sz, emb_sz, embed_p=embed_p, padding_idx=pad_token)
        self.encoder_dp.weight.data.uniform_(-self.initrange, self.initrange)
        # self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)
        # self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)
        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir,
                                                 bidir, weight_p, l) for l in range(n_layers)])
        # self.encoder.weight.data.uniform_(-self.initrange, self.initrange)
        self.input_dp = RNNDropout(input_p)
        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])
        self.reset()

    def forward(self, inp, from_embeds=False):
        bs,sl = inp.shape[:2] if from_embeds else inp.shape
        if bs!=self.bs: self._change_hidden(bs)

        output = self.input_dp(inp if from_embeds else self.encoder_dp(inp))
        new_hidden = []
        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):
            output, new_h = rnn(output, self.hidden[l])
            new_hidden.append(new_h)
            if l != self.n_layers - 1: output = hid_dp(output)
        self.hidden = to_detach(new_hidden, cpu=False, gather=False)
        return output

    def _change_hidden(self, bs):
        self.hidden = [self._change_one_hidden(l, bs) for l in range(self.n_layers)]
        self.bs = bs

    def _one_rnn(self, n_in, n_out, bidir, weight_p, l):
        ""Return one of the inner rnn""
        rnn = nn.LSTM(n_in, n_out, 1, batch_first=True, bidirectional=bidir)
        return WeightDropout(rnn, weight_p)

    def _one_hidden(self, l):
        ""Return one hidden state""
        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir
        return (one_param(self).new_zeros(self.n_dir, self.bs, nh), one_param(self).new_zeros(self.n_dir, self.bs, nh))

    def _change_one_hidden(self, l, bs):
        if self.bs < bs:
            nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir
            return tuple(torch.cat([h, h.new_zeros(self.n_dir, bs-self.bs, nh)], dim=1) for h in self.hidden[l])
        if self.bs > bs: return (self.hidden[l][0][:,:bs].contiguous(), self.hidden[l][1][:,:bs].contiguous())
        return self.hidden[l]

    def reset(self):
        ""Reset the hidden states""
        [r.reset() for r in self.rnns if hasattr(r, 'reset')]
        self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]
```

As you can see I just slightly modified the class `EmbeddingDropout`. Here you have an image where you can compare:

![image](https://user-images.githubusercontent.com/38285979/97095711-3adbf880-1663-11eb-98b5-7658f9a26d3e.png)



Besides I think is also a more clean solution: instead of using two layers `self.encoder` and `self.encoder_dp` now we just have one layer `self.encoder_dp`. Pay attention to the fact that previously the layer `self.encoder` was just used to create the layer `self.encoder_dp`, it had no other use besides this. So I think now it is even easier!

On the other hand I do not know if `EmbeddingDropout` had other uses, so my modification would change any other use of this class in other parts of the code. Still I think now is cleaner. 

Let me know what you think! :)",found solution wrote new class couple line original code work good besides duplication class apply dropout probability layer self super forward self size mask size mask else scale scale return class module inspired self else else else range range forward self else output else enumerate zip output output output output return output self range self return one inner return self return one hidden state else return self self self else return return return reset self reset hidden range see slightly class image compare image besides think also clean solution instead two one layer pay attention fact previously layer used create layer use besides think even easier hand know modification would change use class code still think cleaner let know think,issue,positive,positive,positive,positive,positive,positive
715925149,"@arnaujc91 Thanks for these great examples. 
Let me take a look this weekend to study your ideas and see if we can finish this issue off with another PR.
Best,",thanks great let take look weekend study see finish issue another best,issue,positive,positive,positive,positive,positive,positive
715918105,"Hey @sutt ! 

I saw your pull request. I wanted to ask you what about the Embedding layer? I have spotted the problem: basically [EmbeddingDropout](https://github.com/fastai/fastai/blob/master/fastai/text/models/awdlstm.py#L81) is not captured by `flatten_model`because `flatten_model`captures just the children, as you can see:


![image](https://user-images.githubusercontent.com/38285979/97083307-587f7280-160f-11eb-8e1d-b0cc6ce9e36d.png)


The hooks are actually working but the method `forward` is just called for the layer `EmbeddingDropout` as it is shown in the following screenshot:


![image](https://user-images.githubusercontent.com/38285979/97083419-34706100-1610-11eb-9209-96614538e706.png)

Therefore there are just two options, either modify `flatten_model` or modify `EmbeddingDropout`. Right now `flatten_model` produces duplicates as you have seen. Also it does not capture the layer `EmbeddingDropout` because this last one has children.
 
Any ideas?? I have been thinking about it but i do not consider myself experienced enough to perform a decent PR.

Thanks a lot @sutt !





",hey saw pull request ask layer spotted problem basically see image actually working method forward layer shown following image therefore two either modify modify right seen also capture layer last one thinking consider experienced enough perform decent thanks lot,issue,negative,positive,positive,positive,positive,positive
715530462,Many thanks @pford221 . Can you please resolve the conflicts and at-mention me when ready to merge?,many thanks please resolve ready merge,issue,positive,positive,positive,positive,positive,positive
714989825,"Solved by setting `set_start_method('fork', force=True)` – which is already set in the fastai library (maybe it's changed by a library that I import). But now the issue is that I don't see the progress bar anymore.",setting already set library maybe library import issue see progress bar,issue,negative,neutral,neutral,neutral,neutral,neutral
714271762,"Probably needs to be more documentation as well, but wanted to commit what I have right now because I am kind of stuck on how to head forward. ",probably need documentation well commit right kind stuck head forward,issue,positive,positive,positive,positive,positive,positive
713772141,Apologies for the delay in getting to this. Family emergency came up. I'll aim to work on this more either later this week or this weekend. ,delay getting family emergency came aim work either later week weekend,issue,negative,neutral,neutral,neutral,neutral,neutral
713369452,"I have the same issue here.
Also maybe related, some models with fp16 diverge if I do a `lr_find` before calling `fit`. So I do `lr_find`, then recreate the learner and call fit afterwards.",issue also maybe related diverge calling fit recreate learner call fit afterwards,issue,positive,positive,positive,positive,positive,positive
713268747,"Currently it doesn't seem to work with mixed precision, here is the stack trace:
```python

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-20-979fb3ad48c2> in <module>
      6     load_model(file, self.model, self.opt, device=device, **kwargs)
      7     return self
----> 8 learn.lr_find()

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/callback/schedule.py in lr_find(self, start_lr, end_lr, num_it, stop_div, show_plot, suggestions)
    226     n_epoch = num_it//len(self.dls.train) + 1
    227     cb=LRFinder(start_lr=start_lr, end_lr=end_lr, num_it=num_it, stop_div=stop_div)
--> 228     with self.no_logging(): self.fit(n_epoch, cbs=cb)
    229     if show_plot: self.recorder.plot_lr_find()
    230     if suggestions:

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastcore/logargs.py in _f(*args, **kwargs)
     54         init_args.update(log)
     55         setattr(inst, 'init_args', init_args)
---> 56         return inst if to_return else f(*args, **kwargs)
     57     return _f

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
    205             self.opt.set_hypers(lr=self.lr if lr is None else lr)
    206             self.n_epoch = n_epoch
--> 207             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
    208 
    209     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')
--> 157         finally:   self(f'after_{event_type}')        ;final()
    158 
    159     def all_batches(self):

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in __call__(self, event_name)
    131     def ordered_cbs(self, event): return [cb for cb in sort_by_run(self.cbs) if hasattr(cb, event)]
    132 
--> 133     def __call__(self, event_name): L(event_name).map(self._call_one)
    134 
    135     def _call_one(self, event_name):

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in map(self, f, *args, **kwargs)
    270              else f.format if isinstance(f,str)
    271              else f.__getitem__)
--> 272         return self._new(map(g, self))
    273 
    274     def filter(self, f, negate=False, **kwargs):

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in _new(self, items, *args, **kwargs)
    216     @property
    217     def _xtra(self): return None
--> 218     def _new(self, items, *args, **kwargs): return type(self)(items, *args, use_list=None, **kwargs)
    219     def __getitem__(self, idx): return self._get(idx) if is_indexer(idx) else L(self._get(idx), use_list=None)
    220     def copy(self): return self._new(self.items.copy())

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in __call__(cls, x, *args, **kwargs)
    197     def __call__(cls, x=None, *args, **kwargs):
    198         if not args and not kwargs and x is not None and isinstance(x,cls): return x
--> 199         return super().__call__(x, *args, **kwargs)
    200 
    201 # Cell

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in __init__(self, items, use_list, match, *rest)
    207         if items is None: items = []
    208         if (use_list is not None) or not _is_array(items):
--> 209             items = list(items) if use_list else _listify(items)
    210         if match is not None:
    211             if is_coll(match): match = len(match)

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in _listify(o)
    114     if isinstance(o, list): return o
    115     if isinstance(o, str) or _is_array(o): return [o]
--> 116     if is_iter(o): return list(o)
    117     return [o]
    118 

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in __call__(self, *args, **kwargs)
    177             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)
    178         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 179         return self.fn(*fargs, **kwargs)
    180 
    181 # Cell

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in _call_one(self, event_name)
    135     def _call_one(self, event_name):
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 
    139     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/learner.py in <listcomp>(.0)
    135     def _call_one(self, event_name):
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 
    139     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/callback/core.py in __call__(self, event_name)
     42                (self.run_valid and not getattr(self, 'training', False)))
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit
     46         return res

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/callback/fp16.py in after_fit(self)
    123     def after_fit(self):
    124         if not hasattr(self,'master_pgs'): return
--> 125         _copy_state(self.learn.opt, self.master_pgs, self.model_pgs)
    126         self.learn.opt.param_lists  = self.old_pgs
    127         delattr(self, ""master_pgs"")

~/anaconda3/envs/fastai/lib/python3.8/site-packages/fastai/callback/fp16.py in _copy_state(opt, pgs1, pgs2)
     58 # Cell
     59 def _copy_state(opt, pgs1, pgs2):
---> 60     opt.param_lists = pgs2
     61     for pg1,pg2 in zip(pgs1, pgs2):
     62         for p1,p2 in zip(pg1, pg2): opt.state[p2] = copy_clone(opt.state.pop(p1, {}))

AttributeError: 'NoneType' object has no attribute 'param_lists'
```
I don't know enough about fp16 to know where to start debugging or the obvious red flags",currently seem work mixed precision stack trace python recent call last module file return self self log return else return fit self none else self none none none none none self ex final try self except ex self finally self final self self self event return event self self map self else else return map self filter self self property self return none self return type self self return else copy self return none return return super cell self match rest none none list else match none match match match list return return return list return self else return cell self self assert event self return self assert event self return self self false none self noop reset true end fit return self self self return self opt cell opt zip zip object attribute know enough know start obvious red,issue,positive,positive,neutral,neutral,positive,positive
712822427,"The solution is to make predictions in the following way:
```
probs, _ = learn.get_preds(dl=learn.dls.test_dl(files, drop_last=False))
```
Somewhere drop_last defaults to True, which should be changed. ",solution make following way somewhere true,issue,positive,positive,positive,positive,positive,positive
712296503,I can reproduce the bug and would appreciate a fix.,reproduce bug would appreciate fix,issue,negative,neutral,neutral,neutral,neutral,neutral
711412186,"I think basically all the `None` should have some statistics right? I do not know how the people who coded that expected it to work but in the code there is a function named [has_params](https://github.com/fastai/fastai/blob/master/fastai/callback/hook.py#L100) to choose the layers from which we will collect statistics. So my guess is that all the `None` should disappear. For example in my code from my previous post I get the hooks activated for the Embeddings as well, here in the code you showed, the first two elements of the list are `None` and they correspond to the Embedding layers. I have checked  with your modified code and the hooks are not fired for the Embedding layers so far. 

Last issue is that I do not really know what the layers [ParameterModule](https://github.com/fastai/fastai/blob/master/fastai/layers.py) are. 

Summary: For sure the first two layers should collect statistics of the weights of the Embeddings, and my bet would be that no element of the list should be `None`.

Can we maybe ask this to the people who implemented this functionality?",think basically none statistic right know people work code function choose collect statistic guess none disappear example code previous post get well code first two list none correspond checked code fired far last issue really know summary sure first two collect statistic bet would element list none maybe ask people functionality,issue,negative,positive,positive,positive,positive,positive
711347237,The docs for FastAI v1 have been moved to https://fastai1.fast.ai/. So if you want to access the fit_one_cycle docs you need to navigate to https://fastai1.fast.ai/train.html#fit_one_cycle,want access need navigate,issue,negative,neutral,neutral,neutral,neutral,neutral
711287691,"> how to fix the error ""NameError: name 'CallbackHandler' is not defined"" on ubuntu 20.04?

Hello,
Could you please elaborate on the issue so that I can reproduce this on my end?
Much thanks in advance :)

Srikar
",fix error name defined hello could please elaborate issue reproduce end much thanks advance,issue,negative,positive,positive,positive,positive,positive
711037814,"I've found the problem. There are two lines of code you need to edit.

 First, the main problem comes from `WeightDropout` class as you suspected. By ""calling"" this module, instead of calling its forward argument, we allow the registered hooks a chance to fire (as handled by pytorch's `Module._call_impl()` )

 Second we need to handle the tuple types as output for LSTM layers. So alter the `hook` function on ActivationStats.
```
diff --git a/fastai/callback/hook.py b/fastai/callback/hook.py
index 1146d35..d2c715f 100644
--- a/fastai/callback/hook.py
+++ b/fastai/callback/hook.py
@@ -208,6 +208,7 @@ class ActivationStats(HookCallback):
         self.stats = L()

     def hook(self, m, i, o):
+        if isinstance(o, tuple): o = o[0]
         o = o.float()
         res = {'mean': o.mean().item(), 'std': o.std().item(),
                'near_zero': (o<=0.05).long().sum().item()/o.numel()}
diff --git a/fastai/text/models/awdlstm.py b/fastai/text/models/awdlstm.py
index 546dd8a..3dd154b 100644
--- a/fastai/text/models/awdlstm.py
+++ b/fastai/text/models/awdlstm.py
@@ -50,7 +50,8 @@ class WeightDropout(Module):
         with warnings.catch_warnings():
             # To avoid the warning that comes because the weights aren't flattened.
             warnings.simplefilter(""ignore"", category=UserWarning)
-            return self.module.forward(*args)
+            return self.module(*args)
+            # return self.module.forward(*args)

```

This gives you largely what you're looking for.
![image](https://user-images.githubusercontent.com/2819112/96347705-83971e80-1071-11eb-954f-1daf82780dd9.png)
I'd like to put this functionality into the library, @arnaujc91 - could you show me essentially what is the structure of activation stats that we should see with this model type?
",found problem two code need edit first main problem come class suspected calling module instead calling forward argument allow registered chance fire handled second need handle output alter hook function git index class hook self git index class module avoid warning come ignore return return return largely looking image like put functionality library could show essentially structure activation see model type,issue,negative,positive,positive,positive,positive,positive
710762780,"Another observation:

After commenting out `_patch_tb()` [here](https://github.com/fastai/fastai/blob/8f8c629bd2da69a5d4b0d2dbb053ce5c0aa29180/fastai/torch_core.py#L324), I ran into an issue with WandbCallback with a long traceback that looks like it's related to this quick fix?
<details>
  <summary>Long WandbCallback `TypeError`</summary>
  

```python
~/git/fastai/fastai/learner.py in _do_epoch(self)
    190     def _do_epoch(self):
--> 191         self._do_epoch_train()
    192         self._do_epoch_validate()

~/git/fastai/fastai/learner.py in _do_epoch_train(self)
    182         self.dl = self.dls.train
--> 183         self._with_events(self.all_batches, 'train', CancelTrainException)
    184 

~/git/fastai/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    154     def _with_events(self, f, event_type, ex, final=noop):
--> 155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')

~/git/fastai/fastai/learner.py in all_batches(self)
    160         self.n_iter = len(self.dl)
--> 161         for o in enumerate(self.dl): self.one_batch(*o)
    162 

~/git/fastai/fastai/learner.py in one_batch(self, i, b)
    178         self._split(b)
--> 179         self._with_events(self._do_one_batch, 'batch', CancelBatchException)
    180 

~/git/fastai/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    156         except ex: self(f'after_cancel_{event_type}')
--> 157         finally:   self(f'after_{event_type}')        ;final()
    158 

~/git/fastai/fastai/learner.py in __call__(self, event_name)
    132 
--> 133     def __call__(self, event_name): L(event_name).map(self._call_one)
    134 

~/git/fastcore/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    341 
--> 342     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    343     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))

~/git/fastcore/fastcore/foundation.py in map_ex(iterable, f, gen, *args, **kwargs)
    201     if gen: return res
--> 202     return list(res)
    203 

~/git/fastcore/fastcore/foundation.py in __call__(self, *args, **kwargs)
    184         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 185         return self.fn(*fargs, **kwargs)
    186 

~/git/fastai/fastai/learner.py in _call_one(self, event_name)
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 

~/git/fastai/fastai/learner.py in <listcomp>(.0)
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 

~/git/fastai/fastai/callback/core.py in __call__(self, event_name)
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit

~/git/fastai/fastai/callback/wandb.py in after_batch(self)
     91             hypers = {f'{k}_{i}':v for i,h in enumerate(self.opt.hypers) for k,v in h.items()}
---> 92             wandb.log({'epoch': self._wandb_epoch, 'train_loss': to_detach(self.smooth_loss.clone()), 'raw_loss': to_detach(self.loss.clone()), **hypers}, step=self._wandb_step)
     93 

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/sdk/wandb_run.py in log(self, data, step, commit, sync)
    840             elif step > self.history._step:
--> 841                 self.history._flush()
    842                 self.history._step = step

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/sdk/wandb_history.py in _flush(self)
     48             if self._callback:
---> 49                 self._callback(row=self._data, step=self._step)
     50             self._data = dict()

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/sdk/wandb_run.py in _history_callback(self, row, step)
    634 
--> 635         self._backend.interface.publish_history(row, step)
    636 

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/interface/interface.py in publish_history(self, data, step, run)
    170             item.key = k
--> 171             item.value_json = json_dumps_safer_history(v)
    172         self._publish_history(history)

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/util.py in json_dumps_safer_history(obj, **kwargs)
    532     """"""Convert obj to json, with some extra encodable types, including histograms""""""
--> 533     return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
    534 

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/__init__.py in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)
    237         separators=separators, default=default, sort_keys=sort_keys,
--> 238         **kw).encode(obj)
    239 

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/encoder.py in encode(self, o)
    198         # equivalent to the PySequence_Fast that ''.join() would do.
--> 199         chunks = self.iterencode(o, _one_shot=True)
    200         if not isinstance(chunks, (list, tuple)):

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/encoder.py in iterencode(self, o, _one_shot)
    256                 self.skipkeys, _one_shot)
--> 257         return _iterencode(o, 0)
    258 

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/util.py in default(self, obj)
    503             return obj
--> 504         return json.JSONEncoder.default(self, obj)
    505 

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/encoder.py in default(self, o)
    178         """"""
--> 179         raise TypeError(f'Object of type {o.__class__.__name__} '
    180                         f'is not JSON serializable')

TypeError: Object of type TensorCategory is not JSON serializable

During handling of the above exception, another exception occurred:

IndexError                                Traceback (most recent call last)
~/git/fastai/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    154     def _with_events(self, f, event_type, ex, final=noop):
--> 155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')

~/git/fastai/fastai/learner.py in _do_fit(self)
    196             self.epoch=epoch
--> 197             self._with_events(self._do_epoch, 'epoch', CancelEpochException)
    198 

~/git/fastai/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    156         except ex: self(f'after_cancel_{event_type}')
--> 157         finally:   self(f'after_{event_type}')        ;final()
    158 

~/git/fastai/fastai/learner.py in __call__(self, event_name)
    132 
--> 133     def __call__(self, event_name): L(event_name).map(self._call_one)
    134 

~/git/fastcore/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    341 
--> 342     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    343     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))

~/git/fastcore/fastcore/foundation.py in map_ex(iterable, f, gen, *args, **kwargs)
    201     if gen: return res
--> 202     return list(res)
    203 

~/git/fastcore/fastcore/foundation.py in __call__(self, *args, **kwargs)
    184         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 185         return self.fn(*fargs, **kwargs)
    186 

~/git/fastai/fastai/learner.py in _call_one(self, event_name)
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 

~/git/fastai/fastai/learner.py in <listcomp>(.0)
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 

~/git/fastai/fastai/callback/core.py in __call__(self, event_name)
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit

~/git/fastai/fastai/callback/tracker.py in after_epoch(self)
     80         else: #every improvement
---> 81             super().after_epoch()
     82             if self.new_best:

~/git/fastai/fastai/callback/tracker.py in after_epoch(self)
     38         ""Compare the last value to the best up to now""
---> 39         val = self.recorder.values[-1][self.idx]
     40         if self.comp(val - self.min_delta, self.best): self.best,self.new_best = val,True

~/git/fastcore/fastcore/foundation.py in __getitem__(self, idx)
    300     def _new(self, items, *args, **kwargs): return type(self)(items, *args, use_list=None, **kwargs)
--> 301     def __getitem__(self, idx): return self._get(idx) if is_indexer(idx) else L(self._get(idx), use_list=None)
    302     def copy(self): return self._new(self.items.copy())

~/git/fastcore/fastcore/foundation.py in _get(self, i)
    304     def _get(self, i):
--> 305         if is_indexer(i) or isinstance(i,slice): return getattr(self.items,'iloc',self.items)[i]
    306         i = mask2idxs(i)

IndexError: list index out of range

During handling of the above exception, another exception occurred:

TypeError                                 Traceback (most recent call last)
<ipython-input-27-e99b098e6de9> in <module>
      1 learn.fit_one_cycle(20, 3e-3, cbs=[WandbCallback(),
----> 2                                    SaveModelCallback(fname=fname)])

~/git/fastcore/fastcore/logargs.py in _f(*args, **kwargs)
     54         init_args.update(log)
     55         setattr(inst, 'init_args', init_args)
---> 56         return inst if to_return else f(*args, **kwargs)
     57     return _f

~/git/fastai/fastai/callback/schedule.py in fit_one_cycle(self, n_epoch, lr_max, div, div_final, pct_start, wd, moms, cbs, reset_opt)
    111     scheds = {'lr': combined_cos(pct_start, lr_max/div, lr_max, lr_max/div_final),
    112               'mom': combined_cos(pct_start, *(self.moms if moms is None else moms))}
--> 113     self.fit(n_epoch, cbs=ParamScheduler(scheds)+L(cbs), reset_opt=reset_opt, wd=wd)
    114 
    115 # Cell

~/git/fastcore/fastcore/logargs.py in _f(*args, **kwargs)
     54         init_args.update(log)
     55         setattr(inst, 'init_args', init_args)
---> 56         return inst if to_return else f(*args, **kwargs)
     57     return _f

~/git/fastai/fastai/learner.py in fit(self, n_epoch, lr, wd, cbs, reset_opt)
    205             self.opt.set_hypers(lr=self.lr if lr is None else lr)
    206             self.n_epoch = n_epoch
--> 207             self._with_events(self._do_fit, 'fit', CancelFitException, self._end_cleanup)
    208 
    209     def _end_cleanup(self): self.dl,self.xb,self.yb,self.pred,self.loss = None,(None,),(None,),None,None

~/git/fastai/fastai/learner.py in _with_events(self, f, event_type, ex, final)
    155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')
--> 157         finally:   self(f'after_{event_type}')        ;final()
    158 
    159     def all_batches(self):

~/git/fastai/fastai/learner.py in __call__(self, event_name)
    131     def ordered_cbs(self, event): return [cb for cb in sort_by_run(self.cbs) if hasattr(cb, event)]
    132 
--> 133     def __call__(self, event_name): L(event_name).map(self._call_one)
    134 
    135     def _call_one(self, event_name):

~/git/fastcore/fastcore/foundation.py in map(self, f, gen, *args, **kwargs)
    340     def range(cls, a, b=None, step=None): return cls(range_of(a, b=b, step=step))
    341 
--> 342     def map(self, f, *args, gen=False, **kwargs): return self._new(map_ex(self, f, *args, gen=gen, **kwargs))
    343     def argwhere(self, f, negate=False, **kwargs): return self._new(argwhere(self, f, negate, **kwargs))
    344     def filter(self, f=noop, negate=False, gen=False, **kwargs):

~/git/fastcore/fastcore/foundation.py in map_ex(iterable, f, gen, *args, **kwargs)
    200     res = map(g, iterable)
    201     if gen: return res
--> 202     return list(res)
    203 
    204 # Cell

~/git/fastcore/fastcore/foundation.py in __call__(self, *args, **kwargs)
    183             if isinstance(v,_Arg): kwargs[k] = args.pop(v.i)
    184         fargs = [args[x.i] if isinstance(x, _Arg) else x for x in self.pargs] + args[self.maxi+1:]
--> 185         return self.fn(*fargs, **kwargs)
    186 
    187 # Cell

~/git/fastai/fastai/learner.py in _call_one(self, event_name)
    135     def _call_one(self, event_name):
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 
    139     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

~/git/fastai/fastai/learner.py in <listcomp>(.0)
    135     def _call_one(self, event_name):
    136         assert hasattr(event, event_name), event_name
--> 137         [cb(event_name) for cb in sort_by_run(self.cbs)]
    138 
    139     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)

~/git/fastai/fastai/callback/core.py in __call__(self, event_name)
     42                (self.run_valid and not getattr(self, 'training', False)))
     43         res = None
---> 44         if self.run and _run: res = getattr(self, event_name, noop)()
     45         if event_name=='after_fit': self.run=True #Reset self.run to True at each end of fit
     46         return res

~/git/fastai/fastai/callback/wandb.py in after_fit(self)
    121         self.run = True
    122         if self.log_preds: self.remove_cb(FetchPredsCallback)
--> 123         wandb.log({}) # ensure sync of last step
    124 
    125 # Cell

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/sdk/wandb_run.py in log(self, data, step, commit, sync)
    844             commit = True
    845         if commit:
--> 846             self.history._row_add(data)
    847         else:
    848             self.history._row_update(data)

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/sdk/wandb_history.py in _row_add(self, row)
     32     def _row_add(self, row):
     33         self._data.update(row)
---> 34         self._flush()
     35         self._step += 1
     36 

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/sdk/wandb_history.py in _flush(self)
     47             self._data[""_timestamp""] = int(self._data.get(""_timestamp"", time.time()))
     48             if self._callback:
---> 49                 self._callback(row=self._data, step=self._step)
     50             self._data = dict()
     51 

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/sdk/wandb_run.py in _history_callback(self, row, step)
    633             self._config_callback(data=self._config._as_dict())
    634 
--> 635         self._backend.interface.publish_history(row, step)
    636 
    637     def _console_callback(self, name, data):

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/interface/interface.py in publish_history(self, data, step, run)
    169             item = history.item.add()
    170             item.key = k
--> 171             item.value_json = json_dumps_safer_history(v)
    172         self._publish_history(history)
    173 

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/util.py in json_dumps_safer_history(obj, **kwargs)
    531 def json_dumps_safer_history(obj, **kwargs):
    532     """"""Convert obj to json, with some extra encodable types, including histograms""""""
--> 533     return json.dumps(obj, cls=WandBHistoryJSONEncoder, **kwargs)
    534 
    535 

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/__init__.py in dumps(obj, skipkeys, ensure_ascii, check_circular, allow_nan, cls, indent, separators, default, sort_keys, **kw)
    236         check_circular=check_circular, allow_nan=allow_nan, indent=indent,
    237         separators=separators, default=default, sort_keys=sort_keys,
--> 238         **kw).encode(obj)
    239 
    240 

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/encoder.py in encode(self, o)
    197         # exceptions aren't as detailed.  The list call should be roughly
    198         # equivalent to the PySequence_Fast that ''.join() would do.
--> 199         chunks = self.iterencode(o, _one_shot=True)
    200         if not isinstance(chunks, (list, tuple)):
    201             chunks = list(chunks)

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/encoder.py in iterencode(self, o, _one_shot)
    255                 self.key_separator, self.item_separator, self.sort_keys,
    256                 self.skipkeys, _one_shot)
--> 257         return _iterencode(o, 0)
    258 
    259 def _make_iterencode(markers, _default, _encoder, _indent, _floatstr,

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/wandb/util.py in default(self, obj)
    502         if converted:
    503             return obj
--> 504         return json.JSONEncoder.default(self, obj)
    505 
    506 

~/miniconda3/envs/bleeding-edge/lib/python3.7/json/encoder.py in default(self, o)
    177 
    178         """"""
--> 179         raise TypeError(f'Object of type {o.__class__.__name__} '
    180                         f'is not JSON serializable')
    181 

TypeError: Object of type TensorCategory is not JSON serializable
```
</details>

On investigating, I found this can be fixed by tweaking `wandb` itself rather than `WandbCallback`. More info here: https://github.com/wandb/client/issues/1378


",another observation ran issue long like related quick fix summary long python self self self self ex final self ex try self except ex self self enumerate self self ex final except ex self finally self final self self map self gen map self return self self return self negate iterable gen gen return return list self else return self assert event assert event self none self noop reset true end fit self enumerate log self data step commit sync step step self self row step row step self data step run history convert extra return indent default encode self equivalent would list self return default self return return self default self raise type object type handling exception another exception recent call last self ex final self ex try self except ex self self self ex final except ex self finally self final self self map self gen map self return self self return self negate iterable gen gen return return list self else return self assert event assert event self none self noop reset true end fit self else every improvement super self compare last value best true self self return type self self return else copy self return self self slice return list index range handling exception another exception recent call last module log return else return self div none else cell log return else return fit self none else self none none none none none self ex final try self except ex self finally self final self self self event return event self self map self gen range return map self return self self return self negate filter self iterable gen map iterable gen return return list cell self else return cell self self assert event self return self assert event self return self self false none self noop reset true end fit return self true ensure sync last step cell log self data step commit sync commit true commit data else data self row self row row self self row step row step self name data self data step run item history convert extra return indent default encode self detailed list call roughly equivalent would list list self return default self converted return return self default self raise type object type investigating found fixed rather,issue,positive,positive,positive,positive,positive,positive
710753579,"@rsomani95 You're right. The error came from `*aug_transforms`, similar to your comment in #2769. Error I mentioned was unrelated to this.",right error came similar comment error unrelated,issue,negative,positive,positive,positive,positive,positive
710749534,"Upon trying this fix, I was able to train a regular classification model, but only if NOT using `*aug_transforms(...)` in the `batch_tfms` when constructing the DataLoader. 

When using `*aug_transforms(...)`, I ran into the following error:
```python
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-18-90634fcc3c9e> in <module>
----> 1 dls.show_batch()

~/git/fastai/fastai/data/core.py in show_batch(self, b, max_n, ctxs, show, unique, **kwargs)
     98             old_get_idxs = self.get_idxs
     99             self.get_idxs = lambda: Inf.zeros
--> 100         if b is None: b = self.one_batch()
    101         if not show: return self._pre_show_batch(b, max_n=max_n)
    102         show_batch(*self._pre_show_batch(b, max_n=max_n), ctxs=ctxs, max_n=max_n, **kwargs)

~/git/fastai/fastai/data/load.py in one_batch(self)
    134     def one_batch(self):
    135         if self.n is not None and len(self)==0: raise ValueError(f'This DataLoader does not contain any batches')
--> 136         with self.fake_l.no_multiproc(): res = first(self)
    137         if hasattr(self, 'it'): delattr(self, 'it')
    138         return res

~/git/fastcore/fastcore/foundation.py in first(x)
    236 def first(x):
    237     ""First element of `x`, or None if missing""
--> 238     try: return next(iter(x))
    239     except StopIteration: return None
    240 

~/git/fastai/fastai/data/load.py in __iter__(self)
    102         for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
    103             if self.device is not None: b = to_device(b, self.device)
--> 104             yield self.after_batch(b)
    105         self.after_iter()
    106         if hasattr(self, 'it'): del(self.it)

~/git/fastcore/fastcore/transform.py in __call__(self, o)
    196         self.fs.append(t)
    197 
--> 198     def __call__(self, o): return compose_tfms(o, tfms=self.fs, split_idx=self.split_idx)
    199     def __repr__(self): return f""Pipeline: {' -> '.join([f.name for f in self.fs if f.name != 'noop'])}""
    200     def __getitem__(self,i): return self.fs[i]

~/git/fastcore/fastcore/transform.py in compose_tfms(x, tfms, is_enc, reverse, **kwargs)
    148     for f in tfms:
    149         if not is_enc: f = f.decode
--> 150         x = f(x, **kwargs)
    151     return x
    152 

~/git/fastai/fastai/vision/augment.py in __call__(self, b, split_idx, **kwargs)
     32 
     33     def __call__(self, b, split_idx=None, **kwargs):
---> 34         self.before_call(b, split_idx=split_idx)
     35         return super().__call__(b, split_idx=split_idx, **kwargs) if self.do else b
     36 

~/git/fastai/fastai/vision/augment.py in before_call(self, b, split_idx)
    379         while isinstance(b, tuple): b = b[0]
    380         self.split_idx = split_idx
--> 381         self.do,self.mat = True,self._get_affine_mat(b)
    382         for t in self.coord_fs: t.before_call(b)
    383 

~/git/fastai/fastai/vision/augment.py in _get_affine_mat(self, x)
    394         ms = [f(x) for f in self.aff_fs]
    395         ms = [m for m in ms if m is not None]
--> 396         for m in ms: aff_m = aff_m @ m
    397         return _prepare_mat(x, aff_m)
    398 

~/miniconda3/envs/bleeding-edge/lib/python3.7/site-packages/torch/tensor.py in __torch_function__(cls, func, types, args, kwargs)
    999 
   1000         with _C.DisableTorchFunction():
-> 1001             ret = func(*args, **kwargs)
   1002             return _convert(ret, cls)
   1003 

RuntimeError: The size of tensor a (128) must match the size of tensor b (0) at non-singleton dimension 0
```",upon trying fix able train regular classification model ran following error python recent call last module self show unique lambda none show return self self none self raise contain first self self self return first first first element none missing try return next iter except return none self none yield self self self return self return pipeline self return reverse return self self return super else self true self none return ret return ret size tensor must match size tensor dimension,issue,positive,positive,positive,positive,positive,positive
710734724,"@paulclou I think that might have to do with the code in the notebook rather than a bug in fastai. I tried `dls.show_batch()` on the same dataset in the tutorial notebook and the dataloader works fine. I also inspected `dls.one_batch()` to double check.

PS: the notebook you tried was last updated 2 months ago whereas the one I mentioned was last updated just 7 days ago.


However, I run into a different error when calling `learn.fine_tune(1)`, one that's discussed [here](https://github.com/fastai/fastai/issues/2757) and [here](https://github.com/fastai/fastai/issues/2769)",think might code notebook rather bug tried tutorial notebook work fine also double check notebook tried last ago whereas one last day ago however run different error calling one,issue,negative,positive,neutral,neutral,positive,positive
710675379,"Thanks for this! Let me take a look at it.
I've changed ActivationStats to print anytime a hook gets fired like you did, and stopped fastai from removing the hooks after_fit:
```
class ActivationStats(HookCallback):
    ""Callback that record the mean and std of activations.""
    run_before=TrainEvalCallback
    def __init__(self, with_hist=False, **kwargs):
        # super().__init__(**kwargs)
        super().__init__(remove_end=False)
        self.with_hist = with_hist

    def before_fit(self):
        ""Initialize stats.""
        super().before_fit()
        self.stats = L()

    def hook(self, m, i, o):
        o = o.float()
        print(f'hooked a {m}')
        res = {'mean': o.mean().item(), 'std': o.std().item(),
               'near_zero': (o<=0.05).long().sum().item()/o.numel()}
```

- This shows only the LinearDecoder layer is getting properly hitting hooks. 
- By changing remove_end=False in the callback, the hooks should stay on the torch Sequential object on the learner's model. So we take that object out, and call forward on directly:
- As you can see model[0] the (AWS_LTSD modules) don't fire any hooks
- but model[1] the Linear decoder module does fire it's hook.
-Finally, we examine the layer and their respective `._forward_hooks` attr's: it looks like all layers do have hooks registered here, they just don't fire for some reason?

![image](https://user-images.githubusercontent.com/2819112/96312642-010f5000-0fda-11eb-8d90-b3c4eb003381.png)
",thanks let take look print hook fired like stopped removing class record mean self super super self initialize super hook self print layer getting properly stay torch sequential object learner model take object call forward directly see model fire model linear module fire hook examine layer respective like registered fire reason image,issue,positive,positive,positive,positive,positive,positive
710643767,"Ok Let's try the following. 

First: I modify the [AWD_LSTM](https://github.com/fastai/fastai/blob/master/fastai/text/models/awdlstm.py) class in the following way:

```
class AWD_LSTM_M(Module):
    ""AWD-LSTM inspired by https://arxiv.org/abs/1708.02182""
    initrange=0.1

    def __init__(self, vocab_sz, emb_sz, n_hid, n_layers, pad_token=1, hidden_p=0.2, input_p=0.6, embed_p=0.1,
                 weight_p=0.5, bidir=False):
        store_attr('emb_sz,n_hid,n_layers,pad_token')
        self.bs = 1
        self.n_dir = 2 if bidir else 1
        self.encoder = nn.Embedding(vocab_sz, emb_sz, padding_idx=pad_token)
#         self.encoder_dp = EmbeddingDropout(self.encoder, embed_p)
        self.encoder_dp = self.encoder
        self.rnns = nn.ModuleList([self._one_rnn(emb_sz if l == 0 else n_hid, (n_hid if l != n_layers - 1 else emb_sz)//self.n_dir,
                                                 bidir, weight_p, l) for l in range(n_layers)])
        self.encoder.weight.data.uniform_(-self.initrange, self.initrange)
        self.input_dp = RNNDropout(input_p)
        self.hidden_dps = nn.ModuleList([RNNDropout(hidden_p) for l in range(n_layers)])
        self.reset()

    def forward(self, inp, from_embeds=False):
        bs,sl = inp.shape[:2] if from_embeds else inp.shape
        if bs!=self.bs: self._change_hidden(bs)

        output = self.input_dp(inp if from_embeds else self.encoder_dp(inp))
        new_hidden = []
        for l, (rnn,hid_dp) in enumerate(zip(self.rnns, self.hidden_dps)):
            output, new_h = rnn(output, self.hidden[l])
            new_hidden.append(new_h)
            if l != self.n_layers - 1: output = hid_dp(output)
        self.hidden = to_detach(new_hidden, cpu=False, gather=False)
        return output

    def _change_hidden(self, bs):
        self.hidden = [self._change_one_hidden(l, bs) for l in range(self.n_layers)]
        self.bs = bs

    def _one_rnn(self, n_in, n_out, bidir, weight_p, l):
        ""Return one of the inner rnn""
        rnn = nn.LSTM(n_in, n_out, 1, batch_first=True, bidirectional=bidir)
#         return WeightDropout(rnn, weight_p)
        return rnn

    def _one_hidden(self, l):
        ""Return one hidden state""
        nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir
        return (one_param(self).new_zeros(self.n_dir, self.bs, nh), one_param(self).new_zeros(self.n_dir, self.bs, nh))

    def _change_one_hidden(self, l, bs):
        if self.bs < bs:
            nh = (self.n_hid if l != self.n_layers - 1 else self.emb_sz) // self.n_dir
            return tuple(torch.cat([h, h.new_zeros(self.n_dir, bs-self.bs, nh)], dim=1) for h in self.hidden[l])
        if self.bs > bs: return (self.hidden[l][0][:,:bs].contiguous(), self.hidden[l][1][:,:bs].contiguous())
        return self.hidden[l]

    def reset(self):
        ""Reset the hidden states""
        [r.reset() for r in self.rnns if hasattr(r, 'reset')]
        self.hidden = [self._one_hidden(l) for l in range(self.n_layers)]
`
```

As you can see I have just modified 2 lines from the original code. Now lets make the following experiment:





````
def hook_fn(m, i, o):
  print(f""Working for layer: -- {m._get_name()} --"")

awd_lstm_modified =  AWD_LSTM_M(vocab_sz=3,
                  emb_sz=5,
                  n_hid=6,
                  n_layers=2)

awd_lstm_original =  AWD_LSTM(vocab_sz=3,
                  emb_sz=5,
                  n_hid=6,
                  n_layers=2)

for model in [awd_lstm_modified, awd_lstm_original]:
    print('-------')
    for m in flatten_model(model):
        if has_params(m):
            print(m._get_name())
            m.register_forward_hook(hook_fn)

#Check this output
awd_lstm_modified(torch.randint(3, (1,4)))

# Check this output
awd_lstm_original(torch.randint(3, (1,4)))
````

You will see how the modified `AWD_LSTM_M` prints the forward hooks, so it is clear that the problem comes from these two layers that I have commented in my modified `AWD_LSTM_M` class. 

Check if this also happens for you. Then we would have to see why these two Dropouts do not retain the hooks, could be from PyTorch maybe? I do not know at this point i just stopped it. Would be really could if we could figure it out! :)",let try following first modify class following way class module inspired self else else else range range forward self else output else enumerate zip output output output output return output self range self return one inner return return self return one hidden state else return self self self else return return return reset self reset hidden range see original code make following experiment print working layer model print model print check output check output see forward clear problem come two class check also would see two retain could maybe know point stopped would really could could figure,issue,positive,positive,neutral,neutral,positive,positive
710632964,Yeah - so if you do the Tokenization on a smaller dataset it works out fine - but you have to do it outside of the DataBlock - otherwise you hit `Unhashable type: L`.,yeah smaller work fine outside otherwise hit type,issue,negative,positive,positive,positive,positive,positive
710516535,"I am not able to reproduce your steps above.

My initial testing is showing that although:
 *Good:* `ActivationStats.before_fit()` registers a hook on all layers within the model,
 *Bad:*    only the LinearDecoder layer is getting called for `ActivationStats.hook()`",able reproduce initial testing showing although good hook within model bad layer getting,issue,negative,positive,positive,positive,positive,positive
710210940,"Well the expected behaviour is that you get the statistics of the activations for each of the layers. So instead of a  `None` I would expect to find something of the form: `{'mean': 0.5, 'std':  0.99, 'near_zero': 0.12}`. Apparently in this Language Model there are 9 layers. Just the last layer gets the statistics of the activations, why do `None` appear for the first 8 layers? All these `None`s are because the Hooks are not working. 

I kind of went deep into the Language model and realized that this happens because of the following two layers in [AWD_LSTM](https://github.com/fastai/fastai/blob/master/fastai/text/models/awdlstm.py):

- WeightDropout(rnn, weight_p) => This you will find inside the method `_one_rnn`. Just substitute this for `rnn`
- RNNDropout(input_p) => This you will find it inside the `__init__`. Just substitute it for `input_p`, i.e., do nothing.

If you remove these dropouts the forward hooks work fine for the AWD_LSTM architecture. Please let me know how can we fix this. Thanks a lot for your time, it is really appreciated!


",well behaviour get statistic instead none would expect find something form apparently language model last layer statistic none appear first none working kind went deep language model following two find inside method substitute find inside substitute nothing remove forward work fine architecture please let know fix thanks lot time really,issue,positive,positive,positive,positive,positive,positive
710141345,"These are excellent examples. I am reproducing your results exactly.
Could you suggest expected behavior? 

In fastai.callback.hook.py, this caught my eye:
```
def module_summary(learn, *xb):
    ""Print a summary of `model` using `xb`""
    #Individual parameters wrapped in ParameterModule aren't called through the hooks in `layer_info`,
    #  thus are not counted inside the summary
    #TODO: find a way to have them counted in param number somehow
    infos = layer_info(learn, *xb)
```",excellent exactly could suggest behavior caught eye learn print summary model individual wrapped thus inside summary find way param number somehow learn,issue,positive,positive,positive,positive,positive,positive
710082711,"But the implementation of fastai does not do it that way. Please try to run the following code:
```
from fastai.text.all import *

path = untar_data(URLs.IMDB_SAMPLE)
imdb = pd.read_csv(path/'texts.csv')
imdb_lm = TextDataLoaders.from_df(imdb, text_col='text', is_lm=True)
learn = language_model_learner(imdb_lm, AWD_LSTM, cbs = [ActivationStats],  metrics=[accuracy])

learn.fit(1)

learn.activation_stats.stats[0]
```

The result to me is:
```
(#9) [None,None,None,None,None,None,None,None,{'mean': 0.13280442357063293, 'std': 2.111562967300415, 'near_zero': 0.5319848539272031}]
```

Basically the forward hooks do not work for almost all the layers in the fastai implementation of ActivationStats. That was my main motivation of this post, because from the beginning this piece of code was not working (as expected). 

 Please, in case I am doing something wrong tell me (or is this a mistake?).

Thanks!",implementation way please try run following code import path learn accuracy result none none none none none none none none basically forward work almost implementation main motivation post beginning piece code working please case something wrong tell mistake thanks,issue,negative,negative,neutral,neutral,negative,negative
709810567,"And then the kernel dies.

![Screen Shot 2020-10-15 at 10 51 08 PM](https://user-images.githubusercontent.com/2433203/96218140-fa7ccc00-0f38-11eb-9c7d-632172b82ad6.png)

So I'm assuming maybe the tokenization loop starts to take up a load of memory.",kernel screen shot assuming maybe loop take load memory,issue,negative,neutral,neutral,neutral,neutral,neutral
709808394,"And interestingly it goes from processing 200 items per second to doing around 3 (instant decline, no gradual slowdown), at around the 40% mark, for what seems to be no reason.

![Screen Shot 2020-10-15 at 10 47 18 PM](https://user-images.githubusercontent.com/2433203/96217890-6ad71d80-0f38-11eb-8fea-7d2e5a4256c4.png)
",interestingly go per second around instant decline gradual slowdown around mark reason screen shot,issue,negative,positive,positive,positive,positive,positive
709671045,"I think also this may just be a Paperspace thing where it's running out of memory, but I'm not getting a `cuda out of memory` style error for this one.",think also may thing running memory getting memory style error one,issue,negative,neutral,neutral,neutral,neutral,neutral
709656709,"But registering the hook on a layer and feeding that layer input does work.
Your hook modifying the layer objects in `model` which is an `fastai.text.models.awdlstm.AWD_LSTM` object.
![image](https://user-images.githubusercontent.com/2819112/96198816-d95db080-0f23-11eb-8de4-f12a0be24202.png)
",hook layer feeding layer input work hook layer model object image,issue,negative,neutral,neutral,neutral,neutral,neutral
709282272,"Many thanks. Have you confirmed that persistent workers do work correctly after this patch?

Also, it looks like you forgot to `nbdev_build_lib`.",many thanks confirmed persistent work correctly patch also like forgot,issue,positive,positive,positive,positive,positive,positive
708848510,"Try to install the dev version of fast AI. It sorted out the problem  in my
case.

On Wed, Oct 14, 2020, 18:54 LinoSun <notifications@github.com> wrote:

> [image: image]
> <https://user-images.githubusercontent.com/44741345/95995045-94724500-0e63-11eb-81ad-d56fe311309c.png>
> [image: image]
> <https://user-images.githubusercontent.com/44741345/95995077-9dfbad00-0e63-11eb-888e-01fc09cd90cf.png>
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2147#issuecomment-708399469>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AQWVYAHICFL3WPIEFDDY5EDSKWRBPANCNFSM4HU4BUEA>
> .
>
",try install dev version fast ai sorted problem case wed wrote image image image image reply directly view,issue,negative,positive,positive,positive,positive,positive
708398842,"> I am having a similar configurations and facing the similar issue, can you plz suggest how you managed to sort out.
> 
> ![Screenshot 2020-09-25 161740](https://user-images.githubusercontent.com/70081536/94260822-72fdf780-ff4e-11ea-8196-c4b0d7971483.jpg)

You can do like this to fix this problem:
python -m ipykernel install --user --name my_pt --display-name my_pt",similar facing similar issue suggest sort like fix problem python install user name,issue,negative,neutral,neutral,neutral,neutral,neutral
706742840,What version of fastai are you running? I believe that `DataBunch` is [a part of `fastai1`](https://github.com/fastai/fastai1/blob/bcef12e95405655481bb309761f8c552b51b2bd2/fastai/basic_data.py#L84) but no longer part of the current version of `fastai`.,version running believe part longer part current version,issue,negative,neutral,neutral,neutral,neutral,neutral
705377481,"hey ,how van we calculate f_score just like we calculated Precison and recall. Do we have any class for that to be instantiated?",hey van calculate like calculated recall class,issue,negative,neutral,neutral,neutral,neutral,neutral
705243691,"> 
> 
> I'll second this idea...it threw me for a loop a while back as wrote up here: https://forums.fast.ai/t/identical-loaded-model-not-reproducible/68890/9
> 
> @marii-moe are you sure this can affect the RNG state in dataloaders/learners which are designed to purposefully not share state?

I include in the docs that this will not affect those RNGs, it seems to be a semi-common problem people run into. If you did want to control those random number generators you could probably control the initialization seed like so:
```with no_random: ImageDataLoaders(...) ```
but you would need to recreate the dataloader every time. 
The way you did it in your forum thread is how I usually control the RNGs. 

Your problem is difficult for me to solve, without requiring people to have an understanding of how dataloaders work. 

My only idea would be to keep a list of [weakrefs](https://docs.python.org/3/library/weakref.html), and patch the RNG initializers to require them to be added to this list. Simply iterate through this list to store/reload RNG state. This is a harder problem though, and I don't feel confident about solving it now, but I will think on it. 

Here is what I mentioned in the notebook: 
> Note: It is important to remember that classes like Dataloader have internal random number generators, and no_random will have no effect on those random number generators.


",second idea threw loop back wrote sure affect state designed purposefully share state include affect problem people run want control random number could probably control seed like would need recreate every time way forum thread usually control problem difficult solve without people understanding work idea would keep list patch require added list simply iterate list state harder problem though feel confident think notebook note important remember class like internal random number effect random number,issue,positive,negative,neutral,neutral,negative,negative
705195173,"Those are in `callback`, (ie `from fastai.callback.all import *` however when importing from the library generally you should do `from fastai.tabular.all import *`",ie import however library generally import,issue,negative,positive,neutral,neutral,positive,positive
705194284,"those are all the fastai library I imports:
from fastai.tabular import *
from fastai.tabular.core import *
from fastai.tabular.data import TabularDataLoaders
from fastai.tabular.learner import tabular_learner
from fastai.data.transforms import *
from fastai.data.block import TransformBlock, CategoryBlock
from fastai.losses import CrossEntropyLossFlat
from fastai.metrics import *
from fastcore.utils import *",library import import import import import import import import import,issue,negative,neutral,neutral,neutral,neutral,neutral
704990613,"I'll second this idea...it threw me for a loop a while back as wrote up here: https://forums.fast.ai/t/identical-loaded-model-not-reproducible/68890/9

@marii-moe  are you sure this can affect the RNG state in dataloaders/learners which are designed to purposefully not share state?",second idea threw loop back wrote sure affect state designed purposefully share state,issue,positive,positive,positive,positive,positive,positive
704599243,"I don't agree we should create them like this - we have ways to show scaled images, so I think the stored array should be the plain values.",agree create like way show scaled think array plain,issue,positive,negative,negative,negative,negative,negative
704556864,"I've added feat['vec'].squeeze() to support unflattend layers for image models (e.g. pooling layers). Changed docs and tests to show the different options how to pass the callback (fit_one_cycle(5, cbs=cbs), get_preds(dl=dl, cbs=cbs)).",added feat support image show different pas,issue,negative,neutral,neutral,neutral,neutral,neutral
704119555,"> > So, any update or workaround for this?
> 
> @alexgalkin1994 don't do that. Not in this project, not in any open source project.

Hey, I didn't mean to offend, I only wanted to know if someone has a way to work around this issue in the meantime since I have to work with PyTorch 1.7.0. ",update project open source project hey mean offend know someone way work around issue since work,issue,negative,negative,negative,negative,negative,negative
703992479,"@jph00 from what I understand, there are multiple issues. That's a fix for one of them - https://github.com/pytorch/pytorch/pull/45870 @mengxr can comment here better ",understand multiple fix one comment better,issue,negative,positive,positive,positive,positive,positive
703932763,"Ha sweet! It looks like I spoke too soon though, going through the first notebook of the course and the following piece of code triggers the same error, even with that line commented. Will look into it more.

path = untar_data(URLs.CAMVID_TINY)
dls = SegmentationDataLoaders.from_label_func(
    path, bs=8, fnames = get_image_files(path/""images""),
    label_func = lambda o: path/'labels'/f'{o.stem}_P{o.suffix}',
    codes = np.loadtxt(path/'codes.txt', dtype=str)
)

learn = unet_learner(dls, resnet34)
learn.fine_tune(8)",ha sweet like spoke soon though going first notebook course following piece code error even line look path path lambda learn,issue,positive,positive,positive,positive,positive,positive
703924625,"I think I'll just leave that issue for another day, one simple pr function at a time :) ",think leave issue another day one simple function time,issue,negative,neutral,neutral,neutral,neutral,neutral
703907167,"Currently there is a failing test as a result of that, but I don't want to change anything without your thoughts first of course. The issue with this is the urls used by google drive look something like: `https://drive.google.com/uc?export=download&id=1cI2ZIhY2nbc-azOtY1VXr2xfBh21ry` so it will store in a weirdly named `uc?export=download&id=1cI2ZIhY2nbc-azOtY1VXr2xfBh21ry` folder",currently failing test result want change anything without first course issue used drive look something like store weirdly folder,issue,negative,negative,neutral,neutral,negative,negative
703904611,@jph00 my solution was to change the `.name` being used to save when passing in a custom `dest`. the prior did not quite make sense because if I pass in a `dest` I would expect my data to be saved to `dest` not `dest/mnist` (for example). Let me know any other thoughts in regards to that. ,solution change used save passing custom prior quite make sense pas would expect data saved example let know,issue,positive,neutral,neutral,neutral,neutral,neutral
703900343,"I am currently partial to this solution, as it solves half the problem. `untar_data` has issues if the URL is not poised exactly with the filename, leading to storage issues. Let me work on that as well",currently partial solution half problem poised exactly leading storage let work well,issue,negative,negative,neutral,neutral,negative,negative
703868306,Thanks for checking - that's exactly the fix I was planning to test! :D I'll try to make that change soon.,thanks exactly fix test try make change soon,issue,negative,positive,positive,positive,positive,positive
703848951,"Just in case anyone else runs across this, commenting out line 314 (_patch_tb()) in torch_core.py appears to work as a quick fix.",case anyone else across line work quick fix,issue,negative,positive,positive,positive,positive,positive
703719601,"Some more context: when all strings are the same size, the dual-text dataloader works, again pointing to the padding as the likely culprit. ",context size work pointing padding likely culprit,issue,negative,neutral,neutral,neutral,neutral,neutral
703692145,"Had a couple minutes so I fixed the conflict

Still need to do the rest",couple fixed conflict still need rest,issue,negative,positive,neutral,neutral,positive,positive
703429942,"> So, any update or workaround for this?

@alexgalkin1994 don't do that. Not in this project, not in any open source project.",update project open source project,issue,negative,neutral,neutral,neutral,neutral,neutral
703278098,"> `load_learner` expects an output from `learn.export`. Not `learn.save`

Thanks for that - I guess it was an understanding gap on my part when reading the tutorial materials then (I didn't see an attempt to load the learner again in that page of the tutorials, and haven't looked at subsequent pages to see if they do).

Will close.",output thanks guess understanding gap part reading tutorial see attempt load learner page subsequent see close,issue,negative,positive,neutral,neutral,positive,positive
703177760,"I just made a pull request adding a couple of sentences to the tutorial about this behavior.

https://github.com/fastai/fastai/pull/2860
",made pull request couple tutorial behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
703137256,Also I removed the `rm_type_tfms` here as it seemed much more centralized. I'll update the other tabular PR once this one has been merged (since this one and the prior PR are much more minor),also removed much update tabular one since one prior much minor,issue,negative,positive,neutral,neutral,positive,positive
703118477,"I wound up putting the test under `#slow`, if there's a better way for testing the creation/loading back in of the file let me know. I didn't see one for `Learner.export`",wound test slow better way testing back file let know see one,issue,negative,positive,neutral,neutral,positive,positive
702709497,"Had some time over lunch, so I have submitted a [PR](https://github.com/fastai/fastai/pull/2851) for this, using @ucohen's code, slightly modifying the test, and also adding some text to the notebook to explain.",time lunch code slightly test also text notebook explain,issue,negative,negative,negative,negative,negative,negative
702451065,"well, I spoke to soon... but still, at least it's a different error on `dls = TextDataLoaders.from_folder(source, valid='test', bs=32)`, so progress, right? Anything I can do differently to get around this error?

---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-46-936ee9207a80> in <module>
      2 source = untar_data(URLs.IMDB)
      3 source
----> 4 dls = TextDataLoaders.from_folder(source, valid='test', bs=32)
      5 ###
      6 #get_imdb = partial(get_text_files, folders=['train', 'test', 'unsup'])

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/text/data.py in from_folder(cls, path, train, valid, valid_pct, seed, vocab, text_vocab, is_lm, tok_tfm, seq_len, backwards, **kwargs)
    229                            splitter=splitter,
    230                            get_y=None if is_lm else parent_label)
--> 231         return cls.from_dblock(dblock, path, path=path, seq_len=seq_len, **kwargs)
    232 
    233     @classmethod

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py in from_dblock(cls, dblock, source, path, bs, val_bs, shuffle_train, device, **kwargs)
    178     @classmethod
    179     def from_dblock(cls, dblock, source, path='.',  bs=64, val_bs=None, shuffle_train=True, device=None, **kwargs):
--> 180         return dblock.dataloaders(source, path=path, bs=bs, val_bs=val_bs, shuffle_train=shuffle_train, device=device, **kwargs)
    181 
    182     _docs=dict(__getitem__=""Retrieve `DataLoader` at `i` (`0` is training, `1` is validation)"",

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/block.py in dataloaders(self, source, path, verbose, **kwargs)
    111 
    112     def dataloaders(self, source, path='.', verbose=False, **kwargs):
--> 113         dsets = self.datasets(source)
    114         kwargs = {**self.dls_kwargs, **kwargs, 'verbose': verbose}
    115         return dsets.dataloaders(path=path, after_item=self.item_tfms, after_batch=self.batch_tfms, **kwargs)

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/block.py in datasets(self, source, verbose)
    108         splits = (self.splitter or RandomSplitter())(items)
    109         pv(f""{len(splits)} datasets of sizes {','.join([str(len(s)) for s in splits])}"", verbose)
--> 110         return Datasets(items, tfms=self._combine_type_tfms(), splits=splits, dl_type=self.dl_type, n_inp=self.n_inp, verbose=verbose)
    111 
    112     def dataloaders(self, source, path='.', verbose=False, **kwargs):

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py in __init__(self, items, tfms, tls, n_inp, dl_type, **kwargs)
    308     def __init__(self, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, **kwargs):
    309         super().__init__(dl_type=dl_type)
--> 310         self.tls = L(tls if tls else [TfmdLists(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])
    311         self.n_inp = ifnone(n_inp, max(1, len(self.tls)-1))
    312 

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py in <listcomp>(.0)
    308     def __init__(self, items=None, tfms=None, tls=None, n_inp=None, dl_type=None, **kwargs):
    309         super().__init__(dl_type=dl_type)
--> 310         self.tls = L(tls if tls else [TfmdLists(items, t, **kwargs) for t in L(ifnone(tfms,[None]))])
    311         self.n_inp = ifnone(n_inp, max(1, len(self.tls)-1))
    312 

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in __call__(cls, x, *args, **kwargs)
    197     def __call__(cls, x=None, *args, **kwargs):
    198         if not args and not kwargs and x is not None and isinstance(x,cls): return x
--> 199         return super().__call__(x, *args, **kwargs)
    200 
    201 # Cell

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py in __init__(self, items, tfms, use_list, do_setup, split_idx, train_setup, splits, types, verbose, dl_type)
    234         if do_setup:
    235             pv(f""Setting up {self.tfms}"", verbose)
--> 236             self.setup(train_setup=train_setup)
    237 
    238     def _new(self, items, split_idx=None, **kwargs):

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/data/core.py in setup(self, train_setup)
    252         self.tfms.setup(self, train_setup)
    253         if len(self) != 0:
--> 254             x = super().__getitem__(0) if self.splits is None else super().__getitem__(self.splits[0])[0]
    255             self.types = []
    256             for f in self.tfms.fs:

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in __getitem__(self, idx)
    217     def _xtra(self): return None
    218     def _new(self, items, *args, **kwargs): return type(self)(items, *args, use_list=None, **kwargs)
--> 219     def __getitem__(self, idx): return self._get(idx) if is_indexer(idx) else L(self._get(idx), use_list=None)
    220     def copy(self): return self._new(self.items.copy())
    221 

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/foundation.py in _get(self, i)
    221 
    222     def _get(self, i):
--> 223         if is_indexer(i) or isinstance(i,slice): return getattr(self.items,'iloc',self.items)[i]
    224         i = mask2idxs(i)
    225         return (self.items.iloc[list(i)] if hasattr(self.items,'iloc')

IndexError: list index out of range

",well spoke soon still least different error source progress right anything differently get around error recent call last module source source source partial path train valid seed backwards else return path source path device source return source retrieve training validation self source path verbose self source source verbose return self source verbose size verbose return self source self self super else none self super else none none return return super cell self verbose setting verbose self setup self self self super none else super self self return none self return type self self return else copy self return self self slice return return list list index range,issue,positive,positive,positive,positive,positive,positive
702393666,@kevinbird15 Did the splitter function work for you in all the cases? There are some tests failing in my case. In `vision.learner` I cannot do `learn.fit` with the new splitter.,splitter function work failing case new splitter,issue,negative,positive,positive,positive,positive,positive
702242675,"> Maybe a more general util.py file and add all the things xtra that are on the imports,py and torch_core.py?

Yeah maybe. I'll merge this and take a look. Thanks so much for the PR! :) ",maybe general file add yeah maybe merge take look thanks much,issue,positive,positive,positive,positive,positive,positive
702160655,"Hey Jeremy, I am not sure if you want this methods to be on the `test_util` file, but I did not wanted to create a new file without your blessing. The `show_install` was pretty useful for issues.
Yesterday I was playing with `torch_core` and realized that there are many functions that maybe should be elsewhere.
Maybe a more general `util.py` file and add all the things xtra that are on the `imports,py` and `torch_core.py`?",hey sure want file create new file without blessing pretty useful yesterday many maybe elsewhere maybe general file add,issue,negative,positive,positive,positive,positive,positive
702137442,"Having talked with @muellerzr about the scenario where this was relevant for the project I was working on, I think this pull request might be irrelevant.  Closing for now!",scenario relevant project working think pull request might irrelevant,issue,negative,negative,neutral,neutral,negative,negative
701736170,"I'm also getting a file-not-found, because it's storing URLs.IMDB as `/storage/data/imdb_tok/counter.pkl`, when apparently it needs to be` /storage/data/imdb/counter.pkl`

I tried `untar_data(URLs.IMDB, dest='/storage/data/imdb_tok/counter.pkl')`, but it just tacks the directory on the end like /storage`/data/imdb_tok/counter.pkl/imdb`

Deleting the dir is what worked for me, like you said @tyoc213, but I used ""os"", idk what module ""p"" is you used there:
`os.remove('/storage/data/imdb')`

Anyway, thanks so much!

",also getting apparently need tried directory end like worked like said used o module used anyway thanks much,issue,positive,positive,positive,positive,positive,positive
701724246,"@ecatkins Code should be updated now to work with a list. I am currently updating the documentation, which is probably harder than the code fix itself. Using a function is actually ""difficult"" and a more advanced use case given the code I see though. I will be explaining how to use that as well. ",code work list currently documentation probably harder code fix function actually difficult advanced use case given code see though explaining use well,issue,negative,negative,neutral,neutral,negative,negative
701659445,"Is there any update on this issue? I came across the below error :
```
Traceback (most recent call last):
  File ""05_pet_breeds.py"", line 84, in <module>
    x,y = dls1.valid.one_batch()
  File ""/root/fastai/fastai/data/load.py"", line 136, in one_batch
    with self.fake_l.no_multiproc(): res = first(self)
  File ""/usr/local/lib/python3.6/dist-packages/fastcore/foundation.py"", line 187, in first
    try: return next(iter(x))
  File ""/root/fastai/fastai/data/load.py"", line 102, in __iter__
    for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
  File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 466, in __init__
    super(_SingleProcessDataLoaderIter, self).__init__(loader)
  File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 415, in __init__
    self._persistent_workers = loader.persistent_workers
AttributeError: '_FakeLoader' object has no attribute 'persistent_workers'

```",update issue came across error recent call last file line module file line first self file line first try return next iter file line file line super self loader file line object attribute,issue,negative,positive,positive,positive,positive,positive
701509804,Figured out... I need the file https://github.com/fastai/fastai/blob/master/nbs/examples/migrating_lightning.py in the current directory or to copy it to a cell in the notebook. ,figured need file current directory copy cell notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
701501049,"Just to put some numbers on this, the decrease in speed is really disproportionate to the increase in dataset size...

## Numbers

### Data sizes, train/val split (lines in .txt file)

- Mini: 75,055/155 

- Bigger Mini: 375,275 / 310

### Datablock creation timing

- Mini: 23min 15s

- Bigger Mini: 23min 

### 11 item dataloader loop timing

- Mini: 2.38s per loop

- Bigger Mini: 47.3s per loop

### dls.show_batch() timings

- Mini: 0.042s

- Bigger Mini: 4.3s

### Learner train time (1 batch)

- Mini:  0h 8m

- Bigger Mini: 3h 15m (estimate)
",put decrease speed really disproportionate increase size data size split file bigger creation timing min bigger min item loop timing per loop bigger per loop bigger learner train time batch bigger estimate,issue,positive,positive,neutral,neutral,positive,positive
701366977,"Awesome! Thanks so much for the great explanation :) If you have a chance to document this in the nb, that would be really helpful. ",awesome thanks much great explanation chance document would really helpful,issue,positive,positive,positive,positive,positive,positive
701361844,"@jph00 
I'll reuse actual test cases if that is okay. All the above assumes p=1 which is the probability that the transform is applied. 
1.
`
test_eq(_draw_mask(x, def_draw, 1, p=1), tensor([1.,1,1,1,1]))`
Since the above's third argument is 1, 1 is the ""draw"" 1 is the mask for every element of the batch. In Rotate this could be set to 30, and would mean every image was rotated 30 degrees. 
2.
`test_eq(_draw_mask(x, def_draw, [0,1,2,3,4], p=1), tensor([0.,1,2,3,4]))`
This provides a list of values for ""draw"", so each of these are applied to an element of the batch. This patch is trying to allow this already existing functionality to be used in a dataloader. If we take the rotate example this would be the same as providing [30,90,120,150,180] degree rotations. 
3.
`test_eq(_draw_mask(x[0:3], def_draw, [0,1,2,3,4], p=1), tensor([0.,1,2]))`
This is new functionality I am proposing, where you can have a variable batch size(`x[0:3]`) as long as it is less than the len(draw).  In my rotate example this would be like providing [30,90,120,150,180], but it would only use the first three[30,90,120] if your batch_size=3. The idea here was mostly to help with different batch sizes for valid and train. 

This functionality in 3 is not needed, but support for bs=1 has to exist for dls._one_pass to work, and therefore decoding of a batch in the dataloader. Alternative way to allow functionality in 2 is to instead have a special exception for batch size of 1, which I think would also be fine. I was planning on documenting the behavior in 3 if you thought it was okay, but if it seems more confusing than useful I can instead add a special exception for batch size of 1. ",reuse actual test probability transform applied tensor since third argument draw mask every element batch rotate could set would mean every image rotated tensor list draw applied element batch patch trying allow already functionality used take rotate example would providing degree tensor new functionality variable batch size long le draw rotate example would like providing would use first three idea mostly help different batch size valid train functionality support exist work therefore batch alternative way allow functionality instead special exception batch size think would also fine behavior thought useful instead add special exception batch size,issue,positive,positive,positive,positive,positive,positive
701204482,"I notice that in UNetBlock normType is passed as None in call to PixelShuffle_ICNR.
So, closing this issue.",notice none call issue,issue,negative,neutral,neutral,neutral,neutral,neutral
701129436,"Awesome thanks

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: Jeremy Howard <notifications@github.com>
Sent: Tuesday, September 29, 2020 1:56:10 PM
To: fastai/fastai <fastai@noreply.github.com>
Cc: Roland Fernandez <rfernand@microsoft.com>; Mention <mention@noreply.github.com>
Subject: Re: [fastai/fastai] Problems running vision tutorial in colab (#2762)


I've added a pip upgrade cell to the top of every notebook now, which should resolve this.

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Ffastai%2Ffastai%2Fissues%2F2762%23issuecomment-700981263&data=02%7C01%7Crfernand%40microsoft.com%7C85dcdaf089434cda20f008d864ba183b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637370097714369265&sdata=PVESoqKA1evsRqYOHd5sIUbvi2XJnGvfcWk2%2FYYlhQw%3D&reserved=0>, or unsubscribe<https://nam06.safelinks.protection.outlook.com/?url=https%3A%2F%2Fgithub.com%2Fnotifications%2Funsubscribe-auth%2FABAY3XU2LNHKLB5P6YNAQIDSIJCWVANCNFSM4Q3JMU5Q&data=02%7C01%7Crfernand%40microsoft.com%7C85dcdaf089434cda20f008d864ba183b%7C72f988bf86f141af91ab2d7cd011db47%7C1%7C0%7C637370097714379260&sdata=oqTCu%2BQJ8%2FV4Itf91EX6LpKDna3lykxDeyLCJgYs%2BuA%3D&reserved=0>.
",awesome thanks get outlook sent mention mention subject running vision tutorial added pip upgrade cell top every notebook resolve reply directly view,issue,positive,positive,positive,positive,positive,positive
701103842,Thanks @YSaxon  - I look forward to seeing it. :) No hurry though!,thanks look forward seeing hurry though,issue,negative,positive,positive,positive,positive,positive
701099887,"I did also already write a slightly more complicated version which will pick the most accurate (compared to requested split percentage) split out of _n_ tries (default to 5), and also warn if the final returned split is off by +- 5 from the percent requested. I'll have to push or otherwise link that to this pull request.",also already write slightly complicated version pick accurate split percentage split default also warn final returned split percent push otherwise link pull request,issue,negative,negative,neutral,neutral,negative,negative
701099087,"I'll add docs and fix the merge conflicts when I get a chance. It might be a little bit, as I'm pretty busy with a few projects at the moment.",add fix merge get chance might little bit pretty busy moment,issue,positive,positive,neutral,neutral,positive,positive
701098708,"The whole idea of GroupedSplitter is to allow fastai to automatically ensure that the pictures of the same people, same boats etc, end up wholly in either the training set or the validation set, and not split between sets.",whole idea allow automatically ensure people end wholly either training set validation set split,issue,positive,positive,positive,positive,positive,positive
701098103,"@racheltho 's blog post https://www.fast.ai/2017/11/13/validation-sets/, subheading **New people, new boats, new…** is another good example.",post subheading new people new another good example,issue,negative,positive,positive,positive,positive,positive
701097192,"My [first post](https://forums.fast.ai/t/developer-chat/22363/1013?u=ysaxon) on the dev forum, which this pull request was based off of, giving my justification and an example:

Idea, which I already implemented for myself inside a notebook, but I wonder if it might have broader appeal:

A split_with_grouping(group_from_filepath_re, pct, seed) function that would allow you to split a dataset randomly by percentage, like split_by_rand_pct, but without splitting up groups as defined by a regex.

For example, I’m using the 50States10k dataset of US Google StreetView images(https://arxiv.org/pdf/1810.03077.pdf, smaller dataset here). This has folders for each State, and then files for each cardinal direction for each of many randomly selected points labeled by some kind of hash, so for instance:

50States10k/Alabama/2007_-NPWPMrYipeYcLsiZqKRyw_0.jpg
50States10k/Alabama/2007_-NPWPMrYipeYcLsiZqKRyw_180.jpg
…
50States10k/Alabama/2009_3BS7oprV5tjwg-M4dA1nLA_270.jpg
…
50States10k/South Dakota/2011_iloPUAZx7Vw59X-qJB2OQw_90.jpg
…
Now if you simply use split_by_rand_pct, you will wind up with an unfair validation set, as for each validation image, in most cases you were training with images from other cardinal directions of the same point,. You want to instead validate it with examples of streetviews from locations it has never seen at all.

You could make a csv file and split the images manually but that sounds like a major pain.

So instead why not just have a function that can take an regex which can identify that, for instance, the top two examples (and two others) are all part of the same group and need to be collectively assigned to either the training or validation set.

(in this case, what I used was:
re.match(r'\d{4}_([\w-]+)_\d+',Path(x).stem).group(1) which for example above spits out -NPWPMrYipeYcLsiZqKRyw)

-----

My [second post](https://forums.fast.ai/t/developer-chat/22363/1020?u=ysaxon):

Hi, just wanted to follow up about this idea. I suspect it got lost amidst the upgrade to v2.

To generalize a bit (and update for v2), you could have a splitter function in the new datablock api (GroupPreservingSplitter? SegregatedSplitter?) which takes a function (item->groupidentifier) and a percentage, and splits into training and validation sets without splitting up groups (as identified by the function).

Edit: I went looking for an implementation of the underlying algorithm (to avoid reinventing the wheel), and this 1 is the only one I could find. It’s definitely more polished than what I had written for myself but not substantially different.",first post dev forum pull request based giving justification example idea already inside notebook wonder might appeal seed function would allow split randomly percentage like without splitting defined example u smaller state cardinal direction many randomly selected kind hash instance simply use wind unfair validation set validation image training cardinal point want instead validate never seen could make file split manually like major pain instead function take identify instance top two two part group need collectively assigned either training validation set case used path example second post hi follow idea suspect got lost amidst upgrade generalize bit update could splitter function new function percentage training validation without splitting function edit went looking implementation underlying algorithm avoid wheel one could find definitely polished written substantially different,issue,positive,positive,neutral,neutral,positive,positive
700981324,"I've added a pip upgrade cell to the top of every notebook now, which should resolve this.",added pip upgrade cell top every notebook resolve,issue,positive,positive,positive,positive,positive,positive
700924976,"@SoulEvill thanks for letting us know. 
We hope we can fix this in the next release - MLR 7.4 so wouldn't need num_workers=0 then. ",thanks u know hope fix next release would need,issue,positive,positive,neutral,neutral,positive,positive
700869751,"@jph00 I think that last commit should have things working how you'd like them with the `defaultdict`, let me know if otherwise.",think last commit working like let know otherwise,issue,positive,neutral,neutral,neutral,neutral,neutral
700470266,"Thanks for sharing! I was using the databricks for fastai course too and had the same issues, I was able to run it fine after set num_workers = 0. 
",thanks course able run fine set,issue,positive,positive,positive,positive,positive,positive
700430150,"After looking into this a bit, an array will not work for batch_tfms, which I believe is where this code is being used, and where I was able to reproduce the issues listed here. I do think this points out that the documentation here needs to be updated. I will probably try to do that. 

Here are some examples of how this works with batch transforms. 
```
def my_rotate_different(x): 
    return torch.arange(0,x.size(0)*15,15,device=x.device)

tfm_list = [Rotate(p=1.0, draw=my_rotate_different)]
my_tfms_different = setup_aug_tfms(tfm_list)

tfm_list = [Rotate(p=1.0, draw=10.5)]
my_tfms_constant = setup_aug_tfms(tfm_list)

#Example 1
set_seed(42,True)
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, bs=4, seed=42,
    label_func=is_cat, item_tfms=Resize(224),batch_tfms=my_tfms_different)
dls.show_batch()
#Example 2
set_seed(42,True)
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, bs=4, seed=42,
    label_func=is_cat, item_tfms=Resize(224),batch_tfms=my_tfms_constant)
dls.show_batch()
```

In the first example, this is how I found to be able to use draw using a function. As you found the output of the function must be a tensor, or it will not have the 'cos' function. 

In the second example, you can see that it is possible to use a single constant for a rotation transform. 

Finally, the reason for the weird behavior with your code is that dataloaders have to be able to handle **variable** batch size, or at least a batch size of 1, this is needed to due things like dls._one_pass(). Behind the scenes fastai calls this _one_pass to make sure it has the correct types when it is decoding the tensors back into images. Since you provided a list this call fails because _one_pass operates on a batch of size 1 instead of an entire batch. 

@ecatkins does that solve your issue? I can provide a gist if this is not clear enough. 

I will look at this a bit more, to see what can be done about the documenting this further, thank you for reporting this issue!   

Edit: Actually I will take a shot at updating this to work with a list. It should only be ~1-2 lines of code to get this working(what to do in case of batch_size==1). ",looking bit array work believe code used able reproduce listed think documentation need probably try work batch return rotate rotate example true path path example true path path first example found able use draw function found output function must tensor function second example see possible use single constant rotation transform finally reason weird behavior code able handle variable batch size least batch size due like behind make sure correct back since provided list call batch size instead entire batch solve issue provide gist clear enough look bit see done thank issue edit actually take shot work list code get working case,issue,positive,positive,neutral,neutral,positive,positive
700260254,"I have unsubscribed from this account 3 times, and yet I still continue to
keep receiving emails from many many people in this unforsaken group. I
want ALL OF THESE DARN EMAILS TO STOP NOW!!!!! I don't want to hear any
excuses either. I believe I have been extremely patient, considering all
the aggravating multitude of emails that I have had to delete every single
day.
If this is not taken care of, I will be forced to take more drastic
measures that you and your group/company will really not appreciate. So
please take me off your list and have EVERYONE STOP sending me anymore
emails.

Thank you,

ntr.lvin.wiccan.witch@gmail.com

On Mon, Sep 28, 2020, 12:25 PM Jeremy Howard <notifications@github.com>
wrote:

> *@jph00* requested changes on this pull request.
>
> Thanks! Just some little questions to look at
> ------------------------------
>
> In fastai/data/transforms.py
> <https://github.com/fastai/fastai/pull/2837#discussion_r496076284>:
>
> > @@ -345,10 +345,10 @@ def broadcast_vec(dim, ndim, *t, cuda=True):
>  class Normalize(DisplayedTransform):
>      ""Normalize/denorm batch of `TensorImage`""
>      parameters,order = L('mean', 'std'),99
> -    def __init__(self, mean=None, std=None, axes=(0,2,3)): store_attr()
> +    def __init__(self, mean=None, std=None, axes=(0,2,3), **kwargs): store_attr(**kwargs)
>
> What are the kwargs for? Can we list them explicitly, or use delegates?
> ------------------------------
>
> In fastai/tabular/core.py
> <https://github.com/fastai/fastai/pull/2837#discussion_r496076472>:
>
> >      def setups(self, to):
> -        store_attr(classes={n:CategoryMap(to.iloc[:,n].items, add_na=(n in to.cat_names)) for n in to.cat_names})
> +        if self.classes is None:
> +            classes={n:CategoryMap(to.iloc[:,n].items, add_na=(n in to.cat_names)) for n in to.cat_names}
> +        else:
> +            classes = {}
>
> Would defaultdict allow us to simplify this?
> ------------------------------
>
> In fastai/tabular/data.py
> <https://github.com/fastai/fastai/pull/2837#discussion_r496077576>:
>
> > @@ -27,7 +27,7 @@ def from_csv(cls, csv, skipinitialspace=True, **kwargs):
>          return cls.from_df(pd.read_csv(csv, skipinitialspace=skipinitialspace), **kwargs)
>
>      @delegates(TabDataLoader.__init__)
> -    def test_dl(self, test_items, rm_type_tfms=None, process=True, **kwargs):
>
> Why is this removed?
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/2837#pullrequestreview-497694506>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ANXWOF63DB5KRQD72UJG4VLSIC2GTANCNFSM4R2RBCPQ>
> .
>
",unsubscribed account time yet still continue keep many many people unforsaken group want darn stop want hear either believe extremely patient considering aggravating multitude delete every single day taken care forced take drastic really appreciate please take list everyone stop sending thank mon wrote pull request thanks little look dim class normalize batch order self self list explicitly use self none else class would allow u simplify return self removed thread reply directly view,issue,positive,positive,neutral,neutral,positive,positive
700208040,"So I can't quite seem to get the `defaultdict` working how it should, my attempt was:

```python
class Categorify(TabularProc):
    ""Transform the categorical variables to something similar to `pd.Categorical`""
    order = 1
    def __init__(self, classes=defaultdict(L)): 
        store_attr()
        super().__init__()
    def setups(self, to):
        for n in to.cat_names:
            if n not in self.classes or is_categorical_dtype(to[n]):
                self.classes[n] = CategoryMap(to.iloc[:,n].items, add_na=n)

    def encodes(self, to): to.transform(to.cat_names, partial(_apply_cats, self.classes, 1))
    def decodes(self, to): to.transform(to.cat_names, partial(_decode_cats, self.classes))
    def __getitem__(self,k): return self.classes[k]
```

<s>Do you see anything wrong with this implementation I may have missed? The issue is it passes all the base tests but not the TabularPandas `Pipeline` tests</s>

Answer: I fell for the mutable type gotcha: https://docs.python-guide.org/writing/gotchas/

",ca quite seem get working attempt python class transform categorical something similar order self super self self partial self partial self return see anything wrong implementation may issue base pipeline answer fell mutable type,issue,negative,negative,negative,negative,negative,negative
700153896,"> OK thanks. In the future, please try to keep separate fixes in separate PRs, with a description of what each is doing. Makes life much easier! :)

Can do! Tried to do this for this time around (I have 3-ish tabular PR's including this one) but will keep this in mind better

",thanks future please try keep separate separate description life much easier tried time around tabular one keep mind better,issue,positive,positive,positive,positive,positive,positive
700153372," 
> We don't ever pass in `rm_type_tfms` for anything and it doesn't serve a purpose for tabular. (Unless you can think of a scenario we can keep it).


OK thanks. In the future, please try to keep separate fixes in separate PRs, with a description of what each is doing. Makes life much easier! :)
",ever pas anything serve purpose tabular unless think scenario keep thanks future please try keep separate separate description life much easier,issue,positive,positive,positive,positive,positive,positive
700153013,"On Mon, Sep 28, 2020, at 9:45 AM, Zachary Mueller wrote:
> If we did go that route I would just get rid of `Normalize.from_tab` entirely most likely since it's just redundancy


Sounds like that would simplify the API, so that seems like an improvement?",mon wrote go route would get rid entirely likely since redundancy like would simplify like improvement,issue,positive,neutral,neutral,neutral,neutral,neutral
700152315,If we did go that route I would just get rid of `Normalize.from_tab` entirely most likely since it's just redundancy,go route would get rid entirely likely since redundancy,issue,negative,neutral,neutral,neutral,neutral,neutral
700150640,"So you're saying we have `Normalize` be:

```python
def __init__(self, mean=None, std=None, axes=(0,2,3), means=None, stds=None)
```
? 

Because I can explicitly say it in `Normalize.from_tab`, but just want to make sure we want it explicit here as well. (by passing it as a kwarg)",saying normalize python self explicitly say want make sure want explicit well passing,issue,positive,positive,positive,positive,positive,positive
700148826,"Just write out the param names and defaults explicitly, I guess",write param explicitly guess,issue,negative,neutral,neutral,neutral,neutral,neutral
700143839,"Many thanks. Sorry it took me a while to review.

It's a little hard for me to review it right now, and will also be hard for people to use it, because it has no docs, and the tests are quite long and complex. Could you please write some explanations and simple examples, along with motivation for the feature, in the notebook? The extra details you included above in the PR could also be added to the notebook. In general, try to provide all the information that someone might want in order to understand what this does, whether they might want to use it, and how to use it.

Also, please resolve the conflict that's been introduced since you submitted this.",many thanks sorry took review little hard review right also hard people use quite long complex could please write simple along motivation feature notebook extra included could also added notebook general try provide information someone might want order understand whether might want use use also please resolve conflict since,issue,positive,negative,neutral,neutral,negative,negative
700018203,"Thank you, @marii-moe. It does not break anything, and I added the edge case tests. I'll submit the PR then.",thank break anything added edge case submit,issue,negative,neutral,neutral,neutral,neutral,neutral
699549892,"That is not a bug. `TextBlock` has a `res_col_name` parameter, and this is where your tokenized text lives. Your `get_x` should just return `text`, as you saw.

https://forums.fast.ai/t/issue-with-textblock-from-df-dataloaders-only-accepting-one-column-name/77467/2",bug parameter text return text saw,issue,negative,neutral,neutral,neutral,neutral,neutral
699524056,"@marii-moe I was going just to copy paste the proposed solution and send the PR... but wanted maybe that OP tried to do it, guess if not answer in say 5 days, will do it.

Except if you think is not the correct solution :).",going copy paste solution send maybe tried guess answer say day except think correct solution,issue,positive,neutral,neutral,neutral,neutral,neutral
699290110,"@marii-moe I have successfully trained models with this, and am certain it works. I'll do that once more just to be 100% certain, as it was ~3 weeks back. The reason I hadn't submitted a PR is, IIRC, because `flatten` was not exposed in the loss function's init. It's odd, I see that it is now in the latest version that it is, so I'll put in a PR. Thanks.",successfully trained certain work certain back reason flatten exposed loss function odd see latest version put thanks,issue,positive,positive,positive,positive,positive,positive
699266313,"I think this was an old link from fastai v1, but I think this feature was moved into the library development package [nbdev](https://github.com/fastai/nbdev) over [here](https://nbdev.fast.ai/showdoc).",think old link think feature library development package,issue,negative,positive,neutral,neutral,positive,positive
699232681,"@ rsomani95 just wanted to make sure, are you actively working on this? have you tested the fix? If you want to submit a pull request yourself I think making sure it is passing the test suite would be good. Then make a pull request and get Jeremy's opinion there, he actively reviews pull requests. ",make sure actively working tested fix want submit pull request think making sure passing test suite would good make pull request get opinion actively pull,issue,positive,positive,positive,positive,positive,positive
699192900,"@ababino I have not dug into this one, but have you run tests against this change? If it does not break anything, and you make sure to test edge cases such as lists of length 0,1,2 then I think it is probably good to make a pull request. ",dug one run change break anything make sure test edge length think probably good make pull request,issue,positive,positive,positive,positive,positive,positive
699121900,"Thanks - feel free to submit a PR to fix it, but it's probably not worth leaving an issue open.",thanks feel free submit fix probably worth leaving issue open,issue,positive,positive,positive,positive,positive,positive
699120003,"@jph00 not sure if ""dev_nbs"" bugs are being actively worked on, if not then this can be closed. @TannerGilbert has pointed out a solution that will will help @miramar-labs get around the issue

(Description on Discord for what `dev_nbs` is for: ""It's some useful nbs that aren't part of docs or part of the lib, mainly background info and examples"")",sure actively worked closed pointed solution help get around issue description discord useful part part mainly background,issue,positive,positive,positive,positive,positive,positive
699113710,"@jph00 I think this has been answered, either by downgrading to v0.7 or modifying the script being used to follow the v2 example linked above",think either script used follow example linked,issue,negative,neutral,neutral,neutral,neutral,neutral
699112359,"Tested this and the fastai docs links that I get in Google link to pages that work

@jph00 I think these doc's link issues look like they are fixed",tested link get link work think doc link look like fixed,issue,negative,positive,neutral,neutral,positive,positive
699111594,"Just tested a few searches for fastai (""fastai callback"" etc) and all the links appear to work correctly now

@jph00 I think this can be closed",tested link appear work correctly think closed,issue,negative,negative,neutral,neutral,negative,negative
699107978,"@jph00 I can see `fastcore>=1.0.5` is now in `settings.ini` which should address this dependency issue, this can probably be closed",see address dependency issue probably closed,issue,negative,negative,neutral,neutral,negative,negative
699105348,"@morganmcg1 no, that is a typo (though I don't believe it should affect anything except may check that it's installed)",typo though believe affect anything except may check,issue,negative,neutral,neutral,neutral,neutral,neutral
699104559,"@jph00 @muellerzr is there a need to list `pandas` twice in `settings.ini`?

`requirements = fastcore>=1.0.5 torchvision>=0.7 matplotlib pandas requests pyyaml fastprogress>=0.2.4 pillow scikit-learn scipy spacy pandas`

in https://github.com/fastai/fastai/blob/master/settings.ini",need list twice pillow spacy,issue,negative,neutral,neutral,neutral,neutral,neutral
699098105,"Multiple searches (including for ""basic_data"") return links that all work for me

 @jph00 I think this is fixed",multiple return link work think fixed,issue,negative,positive,neutral,neutral,positive,positive
699094739,Ah understood now...hmmm...I wonder what is going on,ah understood wonder going,issue,negative,neutral,neutral,neutral,neutral,neutral
699003053,"Thanks @marii-moe! I was able to get consistent results between runs as well.

<img width=""461"" alt=""Screen Shot 2020-09-25 at 8 38 26 AM"" src=""https://user-images.githubusercontent.com/28925987/94287415-1f1def00-ff0b-11ea-9e3e-59e908c0999e.png"">
",thanks able get consistent well screen shot,issue,positive,positive,positive,positive,positive,positive
698977212,Thank you so much for your help! Problem solved!,thank much help problem,issue,negative,positive,positive,positive,positive,positive
698964504,"The problem is that training is extremely slow. If I understand correctly, at that point everything has been tokenized, but batch creation time unfortunately scales with the amount of data to the point where the model is untrainable. ",problem training extremely slow understand correctly point everything batch creation time unfortunately scale amount data point model untrainable,issue,negative,negative,negative,negative,negative,negative
698897844,"I fixed all styling, sorry about that.

My main use case for this change is when using a large tabular dataset in memory (2gb in memory).  The model is a tabular variational autoencoder where I try to reconstruct both continuous and categorical variables.  I want to use the compressed representation just like the [Porto Seguro Winning Solution](https://forums.fast.ai/t/porto-seguro-winning-solution-representation-learning/8499).  Some of the categorial variables in my dataset have large cardinality, so the output of the model is quite large since I have several categorical variables all outputting softmaxed one hot encoded vectors, plus all the continuous variables.

I don't care about the reconstructed values, I only care about the compressed representation.  So I use a HookCallback to get those in get_preds:

```
class GetBottleNeckCallback(HookCallback):
    def __init__(self, path, **kwargs):
        super().__init__(**kwargs)
        self.path = path
        
    def hook(self, m, i, o):
        (self.path/str(self.iter)).save_array(self.learn.to_detach(i[0]))

hook = GetBottleNeckCallback(path=Path('saved/compressed'), modules=[learn.model.decoder[0][0]])
learn.add_cbs(hook)
dl = learn.dls.test_dl(df)
learn.get_preds(dl=dl, save_preds=False, save_targs=False)
```

I don't care about the prediction and the targets because I already have them in my dataframe.  I just want the data produced by the GetBottleNeckCallback.

This is the main reason for this change.  A variational auto-encoder returns a tuple, the reconstructed input, the mu and logvar of the distribution.  So I tried saving that with pickle before, but it resulted in 300+megs files for each batch.  If I let the prediction accumulate in memory I get an out of memory on my 64gb ram in about 10s.

So that's why I added the option not to save anything both in memory and on disk for scenarios where a callback is doing the job in the background.  I hope this clarifies!

Thanks,",fixed styling sorry main use case change large tabular memory memory model tabular variational try reconstruct continuous categorical want use compressed representation like porto winning solution categorial large output model quite large since several categorical one hot plus continuous care reconstructed care compressed representation use get class self path super path hook self hook hook care prediction already want data produced main reason change variational reconstructed input mu distribution tried saving pickle batch let prediction accumulate memory get memory ram added option save anything memory disk job background hope thanks,issue,positive,positive,positive,positive,positive,positive
698871576,"I am having a similar configurations and facing the similar issue, can you plz suggest how you managed to sort out.


![Screenshot 2020-09-25 161740](https://user-images.githubusercontent.com/70081536/94260822-72fdf780-ff4e-11ea-8196-c4b0d7971483.jpg)
",similar facing similar issue suggest sort,issue,negative,neutral,neutral,neutral,neutral,neutral
698860231,"@radekosmulski After a quick look it seems like its the parallel tokenization that really slows down for some reason. In your colab example for me the progress bar flies for the first half (up to step 24 of 48), however then it really seems to hit a brick wall.

This is where things slow down:

```
def parallel_tokenize(items, tok=None, rules=None, n_workers=defaults.cpus, **kwargs):
    ""Calls optional `setup` on `tok` before launching `TokenizeWithRules` using `parallel_gen""
    if tok is None: tok = WordTokenizer()
    if hasattr(tok, 'setup'): tok.setup(items, rules)
    return parallel_gen(TokenizeWithRules, items, tok=tok, rules=rules, n_workers=n_workers, **kwargs)
```

I passed `tok=SubwordTokenizer()` to the TextBlock and that also was slow, but faster than the default WordTokenizer (Spacy)

I think like you said its just a function of data size and the creation of the vocab. I guess it should be faster on a second pass when everything is cached",quick look like parallel really slows reason example progress bar first half step however really hit brick wall slow optional setup none return also slow faster default spacy think like said function data size creation guess faster second pas everything,issue,positive,positive,neutral,neutral,positive,positive
698855707,"@sky1ove in future please be more descriptive when describing your issue, for example in the example that is given when you open an issue

If you look closely you can see you can see there is a named module called `layers` that you have to call

`learn.model[-1]`

```
PoolingLinearClassifier(
  (layers): Sequential(
    (0): LinBnDrop(
      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): Dropout(p=0.2, inplace=False)
      (2): Linear(in_features=1200, out_features=50, bias=False)
      (3): ReLU(inplace=True)
    )
    (1): LinBnDrop(
      (0): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (1): Dropout(p=0.1, inplace=False)
      (2): Linear(in_features=50, out_features=2, bias=False)
    )
  )
)
```

 `learn.model[-1].layers[-1]` should get you what you need

Feel free to close this issue if this solves your problem",future please descriptive issue example example given open issue look closely see see module call sequential dropout linear dropout linear get need feel free close issue problem,issue,negative,positive,positive,positive,positive,positive
698759541,"Just looked at this a bit more, and I think I determined how this is supposed to be used actually. This gives different results than previously, but is consistent between runs. The trick here is you have to set the seed, and recreate the dataloader. 
```
from fastai.vision.all import *
def is_cat(x): return x[0].isupper()
path = untar_data(URLs.PETS)/'images'
set_seed(42,True)
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224))
learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fit(1)
set_seed(42,True)
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224))
learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fit(1)
```
```

epoch | train_loss | valid_loss | error_rate | time
-- | -- | -- | -- | --
0 | 0.080560 | 0.007115 | 0.002706 | 00:25


epoch | train_loss | valid_loss | error_rate | time
-- | -- | -- | -- | --
0 | 0.080560 | 0.007115 | 0.002706 | 00:25

```

This is how the original set_seed was supposed to work, so after a little more investigation this does not seem to be a regression. I will add this result to the forum post. ",bit think determined supposed used actually different previously consistent trick set seed recreate import return path true path path learn true path path learn epoch time epoch time original supposed work little investigation seem regression add result forum post,issue,positive,positive,positive,positive,positive,positive
698751573,"If you want to do this without all the extra code, you can use fastai's builin set_seed
```
set_seed(42,True)
dls.rng.seed(42)
```
It also does not set dls.rng, which is probably a bug. I'll take a look at it, because I know where it is now. I think this needs a test case so it doesn't regress in the future. 

I will go ahead and work on this, I will try to make it reproducable so that you only have to call ```set_seed```. 

Results with this method is the same: 
```
epoch | train_loss | valid_loss | error_rate | time
-- | -- | -- | -- | --
0 | 0.069872 | 0.012277 | 0.004060 | 00:24


epoch | train_loss | valid_loss | error_rate | time
-- | -- | -- | -- | --
0 | 0.069872 | 0.012277 | 0.004060 | 00:24
```",want without extra code use true also set probably bug take look know think need test case regress future go ahead work try make call method epoch time epoch time,issue,negative,positive,positive,positive,positive,positive
698727559,"@marii-moe Yes, I think it can be closed. Thank you for your participation.",yes think closed thank participation,issue,positive,negative,neutral,neutral,negative,negative
698718683,"Awesome that works for me! Thanks @marii-moe 

@baidut I've updated the colab if you want to see it: https://colab.research.google.com/drive/13XJ_u_HsgLemi4TvWVswKoeO3In9lNCl?usp=sharing",awesome work thanks want see,issue,positive,positive,positive,positive,positive,positive
698716520,"I took a quick look at this and came up with this which seems to fix your issue: 

```
def set_seed(dls,x=42): #must have dls, as it has an internal random.Random
    random.seed(x)
    dls.rng.seed(x) #added this line
    np.random.seed(x)
    torch.manual_seed(x)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    if torch.cuda.is_available(): torch.cuda.manual_seed_all(x)
```

These were the results I got with seed 42:
```
epoch | train_loss | valid_loss | error_rate | time
-- | -- | -- | -- | --
0 | 0.069872 | 0.012277 | 0.004060 | 00:24


epoch | train_loss | valid_loss | error_rate | time
-- | -- | -- | -- | --
0 | 0.069872 | 0.012277 | 0.004060 | 00:24
```",took quick look came fix issue must internal added line true false got seed epoch time epoch time,issue,negative,positive,neutral,neutral,positive,positive
698526540,"I'm getting the same results when using the `MNIST_SAMPLE` dataset ([here's a colab](https://colab.research.google.com/drive/13XJ_u_HsgLemi4TvWVswKoeO3In9lNCl?usp=sharing)). However, when I downgrade to `fastai==1.0.61` I am able to use the same approach to reproduce the error rate ([here's a colab showing that](https://colab.research.google.com/drive/1_qXO91NzPrzoxOj9k1-qHqsErN_xPtTx?usp=sharing)).",getting however downgrade able use approach reproduce error rate showing,issue,negative,positive,positive,positive,positive,positive
697957202,"Closing the PR for now, as there's more hidden away with issues pertaining to the problem:

Such as [here](https://discuss.pytorch.org/t/need-some-help-on-using-the-new-keypointrcnn/47051)",hidden away pertaining problem,issue,negative,negative,negative,negative,negative,negative
697864243,"I think it makes more sense to maintain consistency between pytorch and fastai (as it might help in the long run).  For the implementation we can use this:

```python
def l2d(ps): return L(dict(params=p) for p in ps)

def splitter(m): return l2d(L(m[0][:3], m[0][3:], m[1:]).map(params))
```
With this we only need to add `l2d` and then wrap previous splitters with this function.",think sense maintain consistency might help long run implementation use python return splitter return need add wrap previous function,issue,negative,negative,negative,negative,negative,negative
697356795,"Many thanks.

So I guess there might be two possible solutions: try to make fastai's optimizers have the same structure as PyTorch's, or else try to make OptimWrapper or something similar change the splitter, right?",many thanks guess might two possible try make structure else try make something similar change splitter right,issue,negative,positive,positive,positive,positive,positive
697144209,"Here is another option, but it doesn't always work: 
```
@delegates(torch.optim.AdamW)
def AdamW_opt(params, **kwargs): 
    param_list = []
    for p in params: param_list.append(dict(params=p))
    return OptimWrapper(torch.optim.AdamW(param_list, **kwargs))
```

This works fine when passed here: 

```
path = untar_data(URLs.PETS)/'images'

def is_cat(x): return x[0].isupper()
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224))

learn = cnn_learner(dls, resnet34, metrics=error_rate, opt_func=AdamW_opt)
```

But when I tried the same thing for a second optimizer from pytorch:
```
@delegates(torch.optim.LBFGS)
def LBFGS_opt(params, **kwargs): 
    param_list = []
    for p in params: param_list.append(dict(params=p))
    return OptimWrapper(torch.optim.LBFGS(param_list, **kwargs))

path = untar_data(URLs.PETS)/'images'

def is_cat(x): return x[0].isupper()
dls = ImageDataLoaders.from_name_func(
    path, get_image_files(path), valid_pct=0.2, seed=42,
    label_func=is_cat, item_tfms=Resize(224))

learn = cnn_learner(dls, resnet34, metrics=error_rate, opt_func=LBFGS_opt)
learn._step = partial(_step_LBFGS,learn)
```

I get the following error: 

```
---------------------------------------------------------------------------
ValueError                                Traceback (most recent call last)
<ipython-input-44-c2be8a648cb1> in <module>
      6     label_func=is_cat, item_tfms=Resize(224))
      7 
----> 8 learn = cnn_learner(dls, resnet34, metrics=error_rate, opt_func=LBFGS_opt)
      9 learn._step = partial(_step_LBFGS,learn)

~/Environment_personal/development/fastcore/fastcore/logargs.py in _f(*args, **kwargs)
     50         log_dict = {**func_args.arguments, **{f'{k} (not in signature)':v for k,v in xtra_kwargs.items()}}
     51         log = {f'{f.__qualname__}.{k}':v for k,v in log_dict.items() if k not in but}
---> 52         inst = f(*args, **kwargs) if to_return else args[0]
     53         init_args = getattr(inst, 'init_args', {})
     54         init_args.update(log)

~/Environment_personal/development/fastai/fastai/vision/learner.py in cnn_learner(dls, arch, loss_func, pretrained, cut, splitter, y_range, config, n_out, normalize, **kwargs)
    175     model = create_cnn_model(arch, n_out, ifnone(cut, meta['cut']), pretrained, y_range=y_range, **config)
    176     learn = Learner(dls, model, loss_func=loss_func, splitter=ifnone(splitter, meta['split']), **kwargs)
--> 177     if pretrained: learn.freeze()
    178     return learn
    179 

~/Environment_personal/development/fastai/fastai/learner.py in freeze(self)
    513 
    514 @patch
--> 515 def freeze(self:Learner): self.freeze_to(-1)
    516 
    517 @patch

~/Environment_personal/development/fastai/fastai/learner.py in freeze_to(self, n)
    508 @patch
    509 def freeze_to(self:Learner, n):
--> 510     if self.opt is None: self.create_opt()
    511     self.opt.freeze_to(n)
    512     self.opt.clear_state()

~/Environment_personal/development/fastai/fastai/learner.py in create_opt(self)
    139     def _bn_bias_state(self, with_bias): return norm_bias_params(self.model, with_bias).map(self.opt.state)
    140     def create_opt(self):
--> 141         self.opt = self.opt_func(self.splitter(self.model), lr=self.lr)
    142         if not self.wd_bn_bias:
    143             for p in self._bn_bias_state(True ): p['do_wd'] = False

<ipython-input-34-dc56115c5594> in LBFGS_opt(params, **kwargs)
      3     param_list = []
      4     for p in params: param_list.append(dict(params=p))
----> 5     return OptimWrapper(torch.optim.LBFGS(param_list, **kwargs))

~/anaconda3/envs/fastai_dev/lib/python3.8/site-packages/torch/optim/lbfgs.py in __init__(self, params, lr, max_iter, max_eval, tolerance_grad, tolerance_change, history_size, line_search_fn)
    234 
    235         if len(self.param_groups) != 1:
--> 236             raise ValueError(""LBFGS doesn't support per-parameter options ""
    237                              ""(parameter groups)"")
    238 

ValueError: LBFGS doesn't support per-parameter options (parameter groups)
```

But using the splitter method that has no issues.  ",another option always work return work fine path return path path learn tried thing second return path return path path learn partial learn get following error recent call last module learn partial learn signature log else log arch cut splitter normalize model arch cut meta learn learner model splitter meta return learn freeze self patch freeze self learner patch self patch self learner none self self return self true false return self raise support parameter support parameter splitter method,issue,positive,positive,neutral,neutral,positive,positive
696775468,"@jph00 this'll be something I want to pick up and implement, as I could easily see its value when folks want to use fastai tabular for preprocessing and then use it for other libraries and move into production. In my head I view it as something like `to.export()`, and follows the same protocol that `learn.export` would do, just isolated to the `TabularPandas` level.",something want pick implement could easily see value want use tabular use move production head view something like protocol would isolated level,issue,positive,positive,positive,positive,positive,positive
696599174,The use of `verify_images` changed with the newest version. You can find an example in [02_production](https://github.com/fastai/fastbook/blob/master/clean/02_production.ipynb).,use version find example,issue,negative,neutral,neutral,neutral,neutral,neutral
696308555,I've created a BaseCallback and inherited from that. Made the code clearer. Also tried to implement all your suggestions.,made code clearer also tried implement,issue,negative,neutral,neutral,neutral,neutral,neutral
696191624,"@ucohen I think you can write the PR with the code you provided, if you can't say me and I will write the PR.",think write code provided ca say write,issue,negative,neutral,neutral,neutral,neutral,neutral
696185788,"@yrzhanov try checking paths with https://docs.fast.ai/data.external#Config

```
config = Config()
config.d
```

Check that you have write access and can create a directory inside `/storage/data/` from a cell `p.mkdir('/storage/data/or_something_like_this')`.",try check write access create directory inside cell,issue,negative,neutral,neutral,neutral,neutral,neutral
696053065,"If I understand code correctly the above would read all dicoms and attempt a split.

Given that fastai already provides a convenient (and paralellized pd.DataFrame.from_dicoms(...) ) method, I suggest instead to create a generic (i.e. not dicom-specific) splitter:

```
def ColGroupKFoldSplitter(col,n_folds:int=5,fold:int=0):
    ""Split `items` (supposed to be a dataframe) by GroupKFold in`col`""
    def _inner(o):
        assert isinstance(o, pd.DataFrame), ""ColSplitter only works when your items are a pandas DataFrame""
        # TODO
    return _inner
```

and then assuming you're instanciating the DataBlock on df_mel, you'd just do: `ColGroupKFoldSplitter('PatientID')`

",understand code correctly would read attempt split given already convenient method suggest instead create generic splitter col fold split supposed col assert work return assuming,issue,negative,neutral,neutral,neutral,neutral,neutral
695878303,"currently it only display 2 results 

![image](https://user-images.githubusercontent.com/506234/93729577-c8bb5400-fb8a-11ea-8a2c-5258a5ecbe92.png)

which the first is 404 https://docs.fast.ai/callbacks.mem.html",currently display image first,issue,negative,positive,positive,positive,positive,positive
695871863,so my suguestion would be to use `!pip install --upgrade fastai`,would use pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
695871373,"Is there some runable code that can be used to test for error?? just did the instructions in the OP and got fastai installed


![image](https://user-images.githubusercontent.com/506234/93728190-652e2800-fb84-11ea-8609-f95b90f39e4d.png)

If on the other case you can the latest for the moment doing `!pip install --upgrade pandas` before importing pandas (or restart colab env).",code used test error got image case latest moment pip install upgrade restart,issue,negative,positive,positive,positive,positive,positive
695733029,"I didn't update fastai. 
After the bug occurred, I left it alone.
Then I tried examples related to transformers. It worked correctly.
Now I rerun the former IMDB code, and it doesn't raise an error.",update bug left alone tried related worked correctly rerun former code raise error,issue,negative,neutral,neutral,neutral,neutral,neutral
695723845,"yeah, for the moment there is no dependence in versions for fastai and fastcore... so you need to upgrade to make sure you have the latest, the best you can do is to save in some place your fastai and fasctore versions so you know which versions you installed... but think of this, if you install fastai with version == 2, most likely you will get the latest fastcore version, not say v 1 of fastcore.",yeah moment dependence need upgrade make sure latest best save place know think install version likely get latest version say,issue,positive,positive,positive,positive,positive,positive
695697774,"![image](https://user-images.githubusercontent.com/506234/93694134-dc54b500-facd-11ea-9e5e-71281b8540b1.png)


Try this https://buomsoo-kim.github.io/colab/2018/04/27/Using-External-fonts-in-colab.md/ or better https://github.com/tensorflow/tensorflow/issues/42780#issuecomment-617267129

In collab it seems that is a know issue for the font they use. (Dont know which one is)

Tried and got this (because locally also doesnt show)

![image](https://user-images.githubusercontent.com/506234/93694306-a0baea80-facf-11ea-80ac-e1b377c881fe.png)


I installed locally `sudo apt-get install fonts-nanum`",image try better know issue font use dont know one tried got locally also doesnt show image locally install,issue,negative,positive,positive,positive,positive,positive
695649611,"Actually did you updated your fastai or fastcore versions??? maybe got solved in the way, recently been some changes here and there and things are moving so maybe you get in the middle of something.",actually maybe got way recently moving maybe get middle something,issue,negative,neutral,neutral,neutral,neutral,neutral
695645822,"Hi, I rerun the code and it can run correctly. Don't know the reason why it work now 😅 ",hi rerun code run correctly know reason work,issue,negative,neutral,neutral,neutral,neutral,neutral
695577497,I also link https://github.com/fastai/fastai/issues/2787 as related to this one,also link related one,issue,negative,neutral,neutral,neutral,neutral,neutral
695140350,"To know where your data is stored, look at this `Config().config_path` -> `Path('/home/tyoc213/.fastai')`

![image](https://user-images.githubusercontent.com/506234/93655256-f74cf980-f9e7-11ea-8621-5540396885b5.png)

See that the _tok dir is created when `from_folder` is called...


I could run it locally like this


```
from fastai.text.all import *

path = untar_data(URLs.IMDB)
dls = TextDataLoaders.from_folder(path, valid='test', bs=16)
learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)
learn.fine_tune(4, 1e-2)
```

See I only reduced batch size to 16.... mmm.

On a new conda env installing from source fastcore and fastai. Havent tried with pip install.",know data look path image see could run locally like import path path learn see reduced batch size new source havent tried pip install,issue,negative,positive,neutral,neutral,positive,positive
695139802,"@HeroadZ I could run locally this with 

```
from fastai.text.all import *

path = untar_data(URLs.IMDB)
dls = TextDataLoaders.from_folder(path, valid='test', bs=16)
learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)
learn.fine_tune(4, 1e-2)
```

See I only reduced batch size to 16.... mmm.

On a new conda env installing from source fastcore and fastai. Havent tried with pip install.",could run locally import path path learn see reduced batch size new source havent tried pip install,issue,negative,positive,neutral,neutral,positive,positive
695081278,"
> IE the current test here checks for combinations of out of scope negatives and positives (`-2,.5`), etc, which I can all easily reproduce by adding transforms like `aug_transforms` to my `DataBlock`. Does this help some? I can also run this with the headpose dataset too if that would be beneficial.


Yes this certainly helps some, although just as important is to train some models and do inference to see it looks right.",ie current test scope easily reproduce like help also run would beneficial yes certainly although important train inference see right,issue,positive,positive,positive,positive,positive,positive
695080946,"
> Shows that it winds up coming in as a `list`, unless you are suggesting something like:

> return L(samples).starmap(_f)

Yes that.
",coming list unless suggesting something like return yes,issue,positive,neutral,neutral,neutral,neutral,neutral
695080755,"Sounds reasonable, although I don't recall all the code fully ATM. So still needs plenty of testing!",reasonable although recall code fully still need plenty testing,issue,negative,positive,positive,positive,positive,positive
695039225,"The fact that this did not do as it was supposed to also causes some concern over doing the same thing in practice with the bounding boxes. Which is indeed the case, leading to a larger issue. Tested the following with coco:

```python
item_tfms = [Resize(64),]
batch_tfms = [*aug_transforms(), Normalize.from_stats(*imagenet_stats)]
```
Grabbing a batch of data leads to an out of scope y:
```python
[-0.7330, -1.0998, -0.0408, -0.5673],
```
My solution for the keypoints was to do a `Transform` that instead performs this as an order of `50`:
```python
class ClampPoints(Transform):
    order = 50
    def encodes(self, x:TensorPoint): return torch.clamp(x, -1,1)
```
Which would run this just before Lighting Transforms, which I believe should be the solution here too. As any batch transforms looks to mess with it. Does this sound reasonable @jph00 ? (we could also give this an order of 100, similar to what `RandomErasing` will do

I'd instead try to adjust bbox too while I'm at it to have this truly work, so it would need a decent redo ground up (and we can keep this as a draft instead)",fact supposed also concern thing practice bounding indeed case leading issue tested following coco python resize batch data scope python solution transform instead order python class transform order self return would run lighting believe solution batch mess sound reasonable could also give order similar instead try adjust truly work would need decent redo ground keep draft instead,issue,positive,positive,neutral,neutral,positive,positive
695034782,"I see now. While I did test it, I didn't test it thoroughly enough on the dataset, as it winds up not really doing what it should be doing on the points (outliers still are > 1.) I'm going to attempt to restructure this as a Transform instead that runs before IntToFloat and Normalize",see test test thoroughly enough really still going attempt transform instead normalize,issue,negative,positive,neutral,neutral,positive,positive
695020787,"Sorry to clarify, I'm not asking about the general approach, but the testing of this specific code.",sorry clarify general approach testing specific code,issue,negative,negative,negative,negative,negative,negative
695018064,"It's extremely well tested (by others doing keypoint datasets), and provides a much more stable training. Along with this, in any article I've read involving data augmentation with points, this is being done, as well as in papers. What most libraries do when they instead opt for a conv-approach (heatmap) is they have a third variable they keep track of that checks if a point went off-screen (it's called vis), however this is a major API change to how keypoints work, so simply doing this approach allows for more stable training while enabling transforms to be done. 

I had to modify my Walk with fastai notebook to include a ClampBatch transform because it was leading to instability during training thanks to out-of-boundary transforms. As you may recall many moons ago we had a discussion over trying to figure out why the results of my cat keypoint model was centering rather than giving the points, and it was due to them going off-screen. While this was initially a data issue (as some of the datapoints were already going off-picture), after applying the common transforms the pattern came back. Clamping fixed this issue. 

Otherwise, without clamping you can't really remove outliers well, and your model will train for ""ghost points"", which during inference can be hard to weed out and narrow down (IE the model winds up guessing where an arm joint could be, even though that's not an option or what it should be looking for). Instead we look for extremes on the boundaries. 

What winds up happening is the model is overfitting based on the labels rather than the actual data, as say if I'm cropping my image now the point is off screen and is relying on that

(Will be providing a visual example in a moment)",extremely well tested much stable training along article read data augmentation done well instead opt third variable keep track point went vi however major change work simply approach stable training done modify walk notebook include transform leading instability training thanks may recall many ago discussion trying figure cat model centering rather giving due going initially data issue already going common pattern came back fixed issue otherwise without ca really remove well model train ghost inference hard weed narrow ie model guessing arm joint could even though option looking instead look happening model based rather actual data say image point screen providing visual example moment,issue,positive,positive,neutral,neutral,positive,positive
694973404,"fastai Version: 2.0.13
fastprogress Version: 0.2.7
torchvision: 0.7.0+cu101
torch version: 1.6.0+cu101

Cuda: True
cuda Version: 10.1
GPU: Tesla P100-PCIE-16GB

I've tried to restart before i posted the issue, but now when I restarted it, everything is working fine...(less than 50 secs)
This might be related to something in Google Colab, temporary or not. Closing this issue for now.",version version torch version true version tried restart posted issue everything working fine le might related something temporary issue,issue,positive,positive,positive,positive,positive,positive
694966274,"I tried this just now and no issues.

![time](https://user-images.githubusercontent.com/25020209/93621658-bfff2e00-f990-11ea-9da3-41fea0f75b60.PNG)

Can you confirm that the GPU is active?  run this code(bit more flamboyant than needed but it will do the trick)
```
BLUE = '\033[94m'; BOLD = '\033[1m'; ITALIC = '\033[3m'; RESET = '\033[0m'

import fastai; print(BOLD + BLUE + ""fastai Version: "" + RESET + ITALIC + str(fastai.__version__))
import fastcore; print(BOLD + BLUE + ""fastcore Version: "" + RESET + ITALIC + str(fastcore.__version__))
import torchvision; print(BOLD + BLUE + ""torchvision: "" + RESET + ITALIC + str(torchvision.__version__))
import torch; print(BOLD + BLUE + ""torch version: "" + RESET + ITALIC + str(torch.__version__))
print(BOLD + BLUE + ""\nCuda: "" + RESET + ITALIC + str(torch.cuda.is_available()))
print(BOLD + BLUE + ""cuda Version: "" + RESET + ITALIC + str(torch.version.cuda))
print(BOLD + BLUE + ""GPU: "" + RESET + ITALIC + str(torch.cuda.get_device_name(0)))
```

![gpu2](https://user-images.githubusercontent.com/25020209/93622626-4ec07a80-f992-11ea-9def-3674eca4f86a.PNG)
",tried time confirm active run code bit flamboyant trick blue bold reset import print bold blue version reset import print bold blue version reset import print bold blue reset import torch print bold blue torch version reset print bold blue reset print bold blue version reset print bold blue reset,issue,positive,positive,positive,positive,positive,positive
694932339,"Note that it is guaranteed to always return a validation set. But in various edge cases, like where there is only a single group, or if the validation fraction is set abnormally high (ie .80 with two groups of equal size), it is possible that it will mark _all_ items to be part of the validation set. If you'd like, I could set it to raise an error in that case.

It is *not* guaranteed to always return the very best possible validation set (ie closest possible count to the fraction requested). This seems to be an NP-hard problem. [Wikipedia](https://en.wikipedia.org/wiki/Subset_sum_problem) [Stack Overflow](https://stackoverflow.com/questions/4632322/finding-all-possible-combinations-of-numbers-to-reach-a-given-sum?rq=1). Not to mention, what you'd really want would be a random pick from among the various possible sets that are reasonably close to the best set you could possibly make, which would probably involve several NP-hard problems plus a judgement call.

In practice, what we could maybe do is raise an alert if the size of the returned set deviates significantly (maybe +/- .05?) from the size requested. Let me know if that's something you'd like me to implement.",note always return validation set various edge like single group validation fraction set abnormally high ie two equal size possible mark part validation set like could set raise error case always return best possible validation set ie possible count fraction problem stack overflow mention really want would random pick among various possible reasonably close best set could possibly make would probably involve several plus call practice could maybe raise alert size returned set significantly maybe size let know something like implement,issue,positive,positive,positive,positive,positive,positive
694921903,See [here](https://colab.research.google.com/drive/1L9zs-NH_iG8XM9zlRityAjv-uft7y5Bp?usp=sharing) for a notebook with the basic steps broken down.,see notebook basic broken,issue,negative,negative,negative,negative,negative,negative
694890729,"I tried to troubleshoot this further. The example I tried from the docs (imdb) work okay. 

I was able to narrow down the issue to the quantity of the data. Batch generation time depends on the amount of total data. 

Below results of generating batches, first image with the entire wiki en dump. The 2nd example with 1/24th of the data.

The behavior I see in `htop` is a single core being maxed out.

![image](https://user-images.githubusercontent.com/2444926/93607160-3fa8ef00-f9c9-11ea-9e71-367a6d420a7c.png)",tried example tried work able narrow issue quantity data batch generation time amount total data generating first image entire en dump example data behavior see single core image,issue,negative,positive,neutral,neutral,positive,positive
694569499,Can confirm this is working. Also fixes any issues with `aug_transforms` along with it. Nice work guys :) ,confirm working also along nice work,issue,negative,positive,positive,positive,positive,positive
694415732,"Thanks for looking at this - sorry I should have assigned myself, since I've started on it myself. I actually need to add something to 'nbdev' to ensure this doesn't break tests.",thanks looking sorry assigned since actually need add something ensure break,issue,positive,negative,neutral,neutral,negative,negative
694414996,"Do let us know if you figure out the solution, in case we see similar reports in the future.",let u know figure solution case see similar future,issue,negative,neutral,neutral,neutral,neutral,neutral
694407931,"Hey @jph00,

I created a script that recursively adds the `pip upgrade` cell to every notebook. My assumption is that whenever the first cell is having `'default_exp'` inside it, the new cell should be the second cell otherwise first. Is that correct?

It works fine when I am trying to insert a new cell at index 1 but adding it to index 0 deforms the format of the notebook and brings everything on line 1. Is there any formatted in `nbdev` or tool I can use to reformat it?

See the screenshot below to get a better sense of the problem I am facing.
![Screenshot from 2020-09-17 23-37-04](https://user-images.githubusercontent.com/46084304/93510459-da102080-f93e-11ea-84d8-f3d692e30a82.png)
",hey script pip upgrade cell every notebook assumption whenever first cell inside new cell second cell otherwise first correct work fine trying insert new cell index index format notebook everything line tool use see get better sense problem facing,issue,negative,positive,positive,positive,positive,positive
694407303,"Thanks to you both! I'll just go ahead and merge this then, but I don't actually know if it's the right fix, so I'd love it if you folks could take a look at some image augmentation outputs and confirm visually that it all looks ok to you! :)",thanks go ahead merge actually know right fix love could take look image augmentation confirm visually,issue,positive,positive,positive,positive,positive,positive
694398606,"@jph00 I wonder this 2 are phrased exactly the same... both of them should be ""Replace tokens in Sentence Case""?

![image](https://user-images.githubusercontent.com/506234/93508699-545f8700-f8e4-11ea-8740-4d804d40bd00.png)

And

![image](https://user-images.githubusercontent.com/506234/93508945-aa342f00-f8e4-11ea-8e39-fd3ace4d2f12.png)

Just to confirm the change.
",wonder exactly replace sentence case image image confirm change,issue,negative,positive,positive,positive,positive,positive
694183506,Same issue happening here. Downgrading to `fastcore==1.0.0` worked as well.,issue happening worked well,issue,negative,neutral,neutral,neutral,neutral,neutral
694034282,"I think I was the one who originally stated that a previous version existed that did not have the issue. I tried to track down the issue, but didn't get to the bottom of it yet. This notebook shows the behavior I found that was suspicious: https://gist.github.com/marii-moe/a8e7a330fbd4d9b0dc326e396ef17e36

commit that this is from is 94e1568f9d9f7718a8c925436fc4b25452f626b9, though I have no idea what version actually broke it yet. 

I was moving my last project off of the old environment when I noticed the discrepancy between the old and new fastai. 

Just noticed gist has display issues with displaying the results from the previous version of fastai, leaving this here as I am having trouble getting its formatting correct in the notebook gist: 

```
Pipeline: BBoxLabeler -> PointScaler -> Resize -> ToTensor
{'img_size': None}
<function <lambda> at 0x7f6d1da1a2f0>
{'img_size': None}
<function <lambda> at 0x7f6d1da1a268>
{'img_size': None}
Pipeline: IntToFloatTensor
{'img_size': None}
Pipeline: IntToFloatTensor
{'img_size': None}
<function <lambda> at 0x7f6d1da1a268>
{'img_size': None}
<bound method DataLoader.create_batch of <fastai2.data.core.TfmdDL object at 0x7f6d28af1320>>
{'img_size': None}
Pipeline: bb_pad
{'img_size': None}
<function <lambda> at 0x7f6d1da1a2f0>
{'img_size': None}
Pipeline: BBoxLabeler -> PointScaler -> Resize -> ToTensor
{'img_size': [256, 256]}
```

NotE: this was found in a debugger, I am just trying to make it more obvious what is happening by breaking open the dataloader. 

All of the 'Nones' is what makes me suspect that the previous version of fastai had something that was broken, but a new version fixed something else, that actually ended up breaking bounding boxes, by making img_size not null. Which is why I think IRailean's fix may work.  This logic is a bit convoluted though. ",think one originally stated previous version issue tried track issue get bottom yet notebook behavior found suspicious commit though idea version actually broke yet moving last project old environment discrepancy old new gist display previous version leaving trouble getting correct notebook gist pipeline resize none function lambda none function lambda none pipeline none pipeline none function lambda none bound method object none pipeline none function lambda none pipeline resize note found trying make obvious happening breaking open suspect previous version something broken new version fixed something else actually ended breaking bounding making null think fix may work logic bit convoluted though,issue,negative,negative,neutral,neutral,negative,negative
693848038,"The issue is on Databricks side and is related to multiprocessing. 
The workaround is to set num_workers=0 in DataLoaders.from_name_func. 
We will have a look how to solve this.
Thank you for everyone's help. 
",issue side related set look solve thank everyone help,issue,positive,neutral,neutral,neutral,neutral,neutral
693818385,"Sorry, I guess I misunderstood the real issue. Thanks for taking the time to look anyway :)",sorry guess misunderstood real issue thanks taking time look anyway,issue,negative,negative,neutral,neutral,negative,negative
693804863,This is working around the underlying bug rather than fixing it. I've fixed the real issue now :) ,working around underlying bug rather fixing fixed real issue,issue,negative,positive,positive,positive,positive,positive
693802372,I suspect my fix to #2764 should fix this too. Feel free to reopen if it's not fixed.,suspect fix fix feel free reopen fixed,issue,negative,positive,positive,positive,positive,positive
693798671,Many thanks for the clear issue and repro! :) Should be fixed now - was just missing an initializer for `learn.epoch`.,many thanks clear issue fixed missing,issue,positive,positive,positive,positive,positive,positive
693785292,"@ai-padawan , as mentioned in the issue template, we need full details on how to repro the bug, in order to fix it.

Can you please provide a complete code example which triggers this error?",issue template need full bug order fix please provide complete code example error,issue,negative,positive,positive,positive,positive,positive
693758814,"Don't merge yet, I know it's failing on the imports from layers. Let me do some digging/refactoring some",merge yet know failing let,issue,negative,neutral,neutral,neutral,neutral,neutral
693561250,"> With the old implementation everything works fine if run only this notebook. If run after installing fastai (pip | from git | using local setup.py), bboxes are not shown correctly.

Oh interesting - can you tell me more about this? Is it a fastcore change or fastai change which broke things? Do you know what version the breakage occurred from?",old implementation everything work fine run notebook run pip git local shown correctly oh interesting tell change change broke know version breakage,issue,negative,positive,positive,positive,positive,positive
693511851,"Try installing from source... if you have time and can create a new env... you just clone fastcore and fastai repo then in your new env, just do `pip install -e .`
",try source time create new clone new pip install,issue,negative,positive,positive,positive,positive,positive
693351082,"I have updated the last test from 09_vision.augment.ipynb with a new transform Resize(256) - it is clearly seen that previously bboxes are not covering the objects. 
Note: With the old implementation everything works fine if run only this notebook. If run after installing fastai (pip | from git | using local setup.py), bboxes are not shown correctly.",last test new transform resize clearly seen previously covering note old implementation everything work fine run notebook run pip git local shown correctly,issue,positive,positive,neutral,neutral,positive,positive
693323477,"Actually I can fine tune transformers but cannot run this demo code correctly. That's confusing. 
What can I do to help you?",actually fine tune run code correctly help,issue,positive,positive,positive,positive,positive,positive
693219468,"I think I can write a little test inside `summary` if one of the elements in the split is 0 show an extra print that says something like ""check your splitter parameters or change to RandomSplitter""",think write little test inside summary one split show extra print something like check splitter change,issue,negative,negative,neutral,neutral,negative,negative
693218980,"This is not an issue. The problem was that in the DataBlock I had not specified the training and testing folder names. It should have been like this

```
mnist = DataBlock(blocks = (ImageBlock(cls=PILImageBW),CategoryBlock),
                  get_items = get_image_files,
                  **splitter = GrandparentSplitter(train_name='training', valid_name='testing'),**
                  get_y = parent_label) 
```",issue problem training testing folder like splitter,issue,negative,neutral,neutral,neutral,neutral,neutral
693208766,"This https://github.com/fastai/fastai/pull/2804 fixed the issue related to ```n_workers```, Thanks, Zachary!",fixed issue related thanks,issue,negative,positive,positive,positive,positive,positive
693002151,"ok, let's just close this issue then. Thanks.",let close issue thanks,issue,negative,positive,positive,positive,positive,positive
692997132,"Tried your example and instead got this

```

 Download of https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz has failed after 5 retries
 Fix the download manually:
$ mkdir -p /home/tyoc213/.fastai/archive
$ cd /home/tyoc213/.fastai/archive
$ wget -c https://s3.amazonaws.com/fast-ai-modelzoo/wt103-fwd.tgz
$ tar xf wt103-fwd.tgz
 And re-run your code once the download is successful

---------------------------------------------------------------------------
EOFError                                  Traceback (most recent call last)
<ipython-input-1-25bb0d73c882> in <module>
      3 path = untar_data(URLs.IMDB)
      4 dls = TextDataLoaders.from_folder(path, valid='test')
----> 5 learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)
      6 learn.fine_tune(4, 1e-2)

~/Documents/github/fastcore/fastcore/logargs.py in _f(*args, **kwargs)
     50         log_dict = {**func_args.arguments, **{f'{k} (not in signature)':v for k,v in xtra_kwargs.items()}}
     51         log = {f'{f.__qualname__}.{k}':v for k,v in log_dict.items() if k not in but}
---> 52         inst = f(*args, **kwargs) if to_return else args[0]
     53         init_args = getattr(inst, 'init_args', {})
     54         init_args.update(log)

~/Documents/github/fastai/fastai/text/learner.py in text_classifier_learner(dls, arch, seq_len, config, backwards, pretrained, drop_mult, n_out, lin_ftrs, ps, max_len, y_range, **kwargs)
    230             warn(""There are no pretrained weights for that architecture yet!"")
    231             return learn
--> 232         model_path = untar_data(meta[url], c_key='model')
    233         fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]
    234         learn = learn.load_pretrained(*fnames, model=learn.model[0])

~/Documents/github/fastai/fastai/data/external.py in untar_data(url, fname, dest, c_key, force_download, extract_func)
    257         if _get_check(url) and _check_file(fname) != _get_check(url):
    258             print(f""File downloaded is broken. Remove {fname} and try again."")
--> 259         extract_func(fname, dest.parent)
    260         rename_extracted(dest)
    261     return dest

~/Documents/github/fastai/fastai/data/external.py in file_extract(fname, dest)
    217     if dest is None: dest = Path(fname).parent
    218     fname = str(fname)
--> 219     if   fname.endswith('gz'):  tarfile.open(fname, 'r:gz').extractall(dest)
    220     elif fname.endswith('zip'): zipfile.ZipFile(fname     ).extractall(dest)
    221     else: raise Exception(f'Unrecognized archive: {fname}')

~/miniconda3/envs/fastai/lib/python3.8/tarfile.py in extractall(self, path, members, numeric_owner)
   2024                 tarinfo.mode = 0o700
   2025             # Do not set_attrs directories, as we will do that further down
-> 2026             self.extract(tarinfo, path, set_attrs=not tarinfo.isdir(),
   2027                          numeric_owner=numeric_owner)
   2028 

~/miniconda3/envs/fastai/lib/python3.8/tarfile.py in extract(self, member, path, set_attrs, numeric_owner)
   2065 
   2066         try:
-> 2067             self._extract_member(tarinfo, os.path.join(path, tarinfo.name),
   2068                                  set_attrs=set_attrs,
   2069                                  numeric_owner=numeric_owner)

~/miniconda3/envs/fastai/lib/python3.8/tarfile.py in _extract_member(self, tarinfo, targetpath, set_attrs, numeric_owner)
   2137 
   2138         if tarinfo.isreg():
-> 2139             self.makefile(tarinfo, targetpath)
   2140         elif tarinfo.isdir():
   2141             self.makedir(tarinfo, targetpath)

~/miniconda3/envs/fastai/lib/python3.8/tarfile.py in makefile(self, tarinfo, targetpath)
   2186                 target.truncate()
   2187             else:
-> 2188                 copyfileobj(source, target, tarinfo.size, ReadError, bufsize)
   2189 
   2190     def makeunknown(self, tarinfo, targetpath):

~/miniconda3/envs/fastai/lib/python3.8/tarfile.py in copyfileobj(src, dst, length, exception, bufsize)
    245     blocks, remainder = divmod(length, bufsize)
    246     for b in range(blocks):
--> 247         buf = src.read(bufsize)
    248         if len(buf) < bufsize:
    249             raise exception(""unexpected end of data"")

~/miniconda3/envs/fastai/lib/python3.8/gzip.py in read(self, size)
    290             import errno
    291             raise OSError(errno.EBADF, ""read() on write-only GzipFile object"")
--> 292         return self._buffer.read(size)
    293 
    294     def read1(self, size=-1):

~/miniconda3/envs/fastai/lib/python3.8/_compression.py in readinto(self, b)
     66     def readinto(self, b):
     67         with memoryview(b) as view, view.cast(""B"") as byte_view:
---> 68             data = self.read(len(byte_view))
     69             byte_view[:len(data)] = data
     70         return len(data)

~/miniconda3/envs/fastai/lib/python3.8/gzip.py in read(self, size)
    496                 break
    497             if buf == b"""":
--> 498                 raise EOFError(""Compressed file ended before the ""
    499                                ""end-of-stream marker was reached"")
    500 

EOFError: Compressed file ended before the end-of-stream marker was reached


```

And if I try to run again I get this

```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-5-c993adf43077> in <module>
----> 1 learn = text_classifier_learner(dls, AWD_LSTM, drop_mult=0.5, metrics=accuracy)
      2 learn.fine_tune(4, 1e-2)

~/Documents/github/fastcore/fastcore/logargs.py in _f(*args, **kwargs)
     50         log_dict = {**func_args.arguments, **{f'{k} (not in signature)':v for k,v in xtra_kwargs.items()}}
     51         log = {f'{f.__qualname__}.{k}':v for k,v in log_dict.items() if k not in but}
---> 52         inst = f(*args, **kwargs) if to_return else args[0]
     53         init_args = getattr(inst, 'init_args', {})
     54         init_args.update(log)

~/Documents/github/fastai/fastai/text/learner.py in text_classifier_learner(dls, arch, seq_len, config, backwards, pretrained, drop_mult, n_out, lin_ftrs, ps, max_len, y_range, **kwargs)
    231             return learn
    232         model_path = untar_data(meta[url], c_key='model')
--> 233         fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]
    234         learn = learn.load_pretrained(*fnames, model=learn.model[0])
    235         learn.freeze()

~/Documents/github/fastai/fastai/text/learner.py in <listcomp>(.0)
    231             return learn
    232         model_path = untar_data(meta[url], c_key='model')
--> 233         fnames = [list(model_path.glob(f'*.{ext}'))[0] for ext in ['pth', 'pkl']]
    234         learn = learn.load_pretrained(*fnames, model=learn.model[0])
    235         learn.freeze()

IndexError: list index out of range
```

Will see if I can replicate original bug... and check the space on my HD just in case...",tried example instead got fix manually tar code successful recent call last module path path learn signature log else log arch backwards warn architecture yet return learn meta list learn print file broken remove try return none path else raise exception archive self path path extract self member path try path self self else source target self length exception remainder length range raise exception unexpected end data read self size import raise read object return size read self self self view data data data return data read self size break raise compressed file ended marker compressed file ended marker try run get recent call last module learn signature log else log arch backwards return learn meta list learn return learn meta list learn list index range see replicate original bug check space case,issue,negative,positive,positive,positive,positive,positive
692923977,This is the first time that this issue has been reported. There's no known compatibility issues. The only way I think we can debug it is by following the steps I requested in my previous reply.,first time issue known compatibility way think following previous reply,issue,negative,positive,neutral,neutral,positive,positive
692915719,"The conda environment is not broken per se. I tried many times and it consistently fails with this exception. Many of those versions come standard on that particular version of Databricks runtime - [Machine Learning Runtime (MLR) 7.3 for GPU](https://docs.databricks.com/release-notes/runtime/7.3ml.html#python-on-gpu-clusters). I tried different MLR versions and none of them work. Are there some known compatibility issues in fastai? Any of the above package versions are much newer / much older than what you would expect to see or what you normally test `fastai` against? 

Response I got from PyTorch developers @mariosasko @albanD in pytorch/pytorch#44628 
fastai doesn't use pytorch library in that case correctly as `fit` as `input` has `[0]` (single-element list with just 0 in it) while it has to have a tensor. 
",environment broken per se tried many time consistently exception many come standard particular version machine learning tried different none work known compatibility package much much older would expect see normally test response got use library case correctly fit input list tensor,issue,negative,positive,positive,positive,positive,positive
692889043,The search uses google to find the results. It will take some time until google search notices that some pages no longer exist.,search find take time search longer exist,issue,negative,neutral,neutral,neutral,neutral,neutral
692882462,"It would be great to fix, I agree.

Could you try creating a new conda env, and see if you still have the problem? If not, could you try installing a few of the extra libs or different versions you have in the broken env, to track down where the issue is coming from?
",would great fix agree could try new see still problem could try extra different broken track issue coming,issue,negative,positive,positive,positive,positive,positive
692877524,"Thanks for the info.

The old page is still linked to from the search results, so that should probably be fixed. (See screenshot.)
![fastai-docs-screenshot](https://user-images.githubusercontent.com/286890/93246602-debbb580-f741-11ea-9b5f-37e52aff068a.png)
",thanks old page still linked search probably fixed see,issue,negative,positive,positive,positive,positive,positive
692861211,"@jph00 thanks for trying to reproduce this. 

It looks like the issue may be in some versions or other dependencies that cause this.. 

I was using Databricks Machine Learning Runtime 7.3 as a baseline - here's conda spec 
https://docs.databricks.com/release-notes/runtime/7.3ml.html#python-on-gpu-clusters

On top of that had following for fastai components to work - 
```
%conda install -c fastai -c pytorch fastai fastbook powerai::""sentencepiece<0.1.90"" 
%sh pip install azure-cognitiveservices-search-imagesearch
```

We have a number of folks in Databricks and Databricks customers who are trying to use fastai and running into this issue so it would be nice to understand root cause of this issue. 

<details>
<summary>
PS. here's complete list of the conda environment in Databricks where this issue consistently happens - </summary>

```
# Name                    Version                   Build  Channel
_libgcc_mutex             0.1                        main  
_tflow_select             2.3.0                       mkl  
absl-py                   0.9.0                    py37_0  
adal                      1.2.4                    pypi_0    pypi
argon2-cffi               20.1.0           py37h7b6447c_1  
asn1crypto                1.3.0                    py37_1  
astor                     0.8.0                    py37_0  
astunparse                1.6.3                      py_0  
attrs                     20.1.0                     py_0  
azure-cognitiveservices-search-imagesearch 2.0.0                    pypi_0    pypi
azure-common              1.1.25                   pypi_0    pypi
azure-core                1.8.0                    pypi_0    pypi
azure-storage-blob        12.4.0                   pypi_0    pypi
backcall                  0.1.0                    py37_0  
backports                 1.0                        py_2  
bcrypt                    3.2.0            py37h7b6447c_0  
blas                      1.0                         mkl  
bleach                    3.1.5                      py_0  
blinker                   1.4                      py37_0  
boto3                     1.12.0                     py_0  
botocore                  1.15.0                     py_0  
c-ares                    1.15.0            h7b6447c_1001  
ca-certificates           2020.7.22                     0  
cachetools                4.1.1                      py_0  
cairo                     1.14.12              h8948797_3  
catalogue                 1.0.0                    py37_1  
certifi                   2020.6.20                py37_0  
cffi                      1.14.0           py37h2e261b9_0  
chardet                   3.0.4                 py37_1003  
click                     7.0                      py37_0  
cloudpickle               1.3.0                      py_0  
configparser              3.7.4                    py37_0  
cryptography              2.8              py37h1ba5d50_0  
cudatoolkit               10.1.243             h6bb024c_0  
cycler                    0.10.0                   py37_0  
cymem                     2.0.3            py37he6710b0_0  
cython                    0.29.15          py37he6710b0_0  
cython-blis               0.4.1            py37h7b6447c_1  
databricks-cli            0.11.0                   pypi_0    pypi
dbus                      1.13.16              hb2f20db_0  
decorator                 4.4.1                      py_0  
defusedxml                0.6.0                      py_0  
dill                      0.3.1.1                  py37_1  
diskcache                 5.0.2                    pypi_0    pypi
docker                    4.3.1                    pypi_0    pypi
docutils                  0.15.2                   py37_0  
entrypoints               0.3                      py37_0  
expat                     2.2.9                he6710b0_2  
fastai                    2.0.11                     py_0    fastai
fastbook                  0.0.11             pyh39e3cac_0    fastai
fastcore                  1.0.11                     py_0    fastai
fastprogress              1.0.0              pyh39e3cac_0    fastai
fastscript                1.0.0                         0    fastai
flask                     1.1.1                      py_1  
fontconfig                2.13.0               h9420a91_0  
freetype                  2.9.1                h8a8886c_1  
fribidi                   1.0.10               h7b6447c_0  
future                    0.18.2                   py37_1  
gast                      0.3.3                      py_0  
gitdb                     4.0.5                      py_0  
gitpython                 3.1.0                      py_0  
glib                      2.63.1               h5a9c865_0  
google-auth               1.11.2                     py_0  
google-auth-oauthlib      0.4.1                      py_2  
google-pasta              0.2.0                      py_0  
gorilla                   0.3.0                    pypi_0    pypi
graphite2                 1.3.14               h23475e2_0  
graphviz                  2.40.1               h21bd128_2  
grpcio                    1.27.2           py37hf8bcb03_0  
gst-plugins-base          1.14.0               hbbd80ab_1  
gstreamer                 1.14.0               hb453b48_1  
gunicorn                  20.0.4                   py37_0  
h5py                      2.10.0           py37h7918eee_0  
harfbuzz                  1.8.8                hffaf4a1_0  
hdf5                      1.10.4               hb1b8bf9_0  
horovod                   0.19.5                   pypi_0    pypi
icu                       58.2                 he6710b0_3  
idna                      2.8                      py37_0  
importlib-metadata        1.7.0                    py37_0  
importlib_metadata        1.7.0                         0  
intel-openmp              2020.0                      166  
ipykernel                 5.1.4            py37h39e3cac_0  
ipython                   7.12.0           py37h5ca1d4c_0  
ipython_genutils          0.2.0                    py37_0  
ipywidgets                7.5.1                      py_0  
isodate                   0.6.0                      py_1  
itsdangerous              1.1.0                    py37_0  
jedi                      0.14.1                   py37_0  
jinja2                    2.11.1                     py_0  
jmespath                  0.10.0                     py_0  
joblib                    0.14.1                     py_0  
joblibspark               0.2.0                    pypi_0    pypi
jpeg                      9b                   h024ee3a_2  
jsonschema                3.0.2                    py37_0  
jupyter_client            5.3.4                    py37_0  
jupyter_core              4.6.1                    py37_0  
keras-preprocessing       1.1.2                    pypi_0    pypi
kiwisolver                1.1.0            py37he6710b0_0  
koalas                    1.2.0                    pypi_0    pypi
krb5                      1.16.4               h173b8e3_0  
ld_impl_linux-64          2.33.1               h53a641e_7  
libedit                   3.1.20181209         hc058e9b_0  
libffi                    3.2.1                hd88cf55_4  
libgcc-ng                 9.1.0                hdf63c60_0  
libgfortran-ng            7.3.0                hdf63c60_0  
libpng                    1.6.37               hbc83047_0  
libpq                     11.2                 h20c2e04_0  
libprotobuf               3.11.4               hd408876_0  
libsodium                 1.0.16               h1bed415_0  
libstdcxx-ng              9.1.0                hdf63c60_0  
libtiff                   4.1.0                h2733197_0  
libuuid                   1.0.3                h1bed415_2  
libxcb                    1.14                 h7b6447c_0  
libxml2                   2.9.9                hea5a465_1  
lightgbm                  2.3.0            py37he6710b0_0  
lz4-c                     1.8.1.2              h14c3975_0  
mako                      1.1.2                      py_0  
markdown                  3.1.1                    py37_0  
markupsafe                1.1.1            py37h14c3975_1  
matplotlib                3.1.3                    py37_0  
matplotlib-base           3.1.3            py37hef1b27d_0  
mistune                   0.8.4           py37h14c3975_1001  
mkl                       2020.0                      166  
mkl-service               2.3.0            py37he904b0f_0  
mkl_fft                   1.0.15           py37ha843d7b_0  
mkl_random                1.1.0            py37hd6b4f25_0  
mleap                     0.16.1                   pypi_0    pypi
mlflow                    1.11.0                   pypi_0    pypi
msrest                    0.6.18                   pypi_0    pypi
msrestazure               0.6.4                    pypi_0    pypi
murmurhash                1.0.2            py37he6710b0_0  
nb_conda                  2.2.1                    py37_0  
nb_conda_kernels          2.2.4                    py37_0  
nbconvert                 5.6.1                    py37_1  
nbdev                     1.0.18                     py_0    fastai
nbformat                  5.0.7                      py_0  
ncurses                   6.2                  he6710b0_1  
networkx                  2.4                        py_1  
ninja                     1.10.0           py37hfd86e86_0  
nltk                      3.4.5                    py37_0  
notebook                  6.1.1                    py37_0  
numpy                     1.18.1           py37h4f9e942_0  
numpy-base                1.18.1           py37hde5b4d6_1  
oauthlib                  3.1.0                      py_0  
olefile                   0.46                     py37_0  
openssl                   1.1.1g               h7b6447c_0  
opt-einsum                3.3.0                    pypi_0    pypi
opt_einsum                3.1.0                      py_0  
packaging                 20.1                       py_0  
pandas                    1.0.1            py37h0573a6f_0  
pandoc                    2.10.1                        0  
pandocfilters             1.4.2                    py37_1  
pango                     1.42.4               h049681c_0  
paramiko                  2.7.1                      py_0  
parso                     0.5.2                      py_0  
patsy                     0.5.1                    py37_0  
pcre                      8.44                 he6710b0_0  
petastorm                 0.9.5                    pypi_0    pypi
pexpect                   4.8.0                    py37_1  
pickleshare               0.7.5                 py37_1001  
pillow                    7.0.0            py37hb39fc2d_0  
pip                       20.0.2                   py37_3  
pixman                    0.40.0               h7b6447c_0  
plac                      0.9.6                    py37_1  
plotly                    4.9.0                      py_0  
preshed                   3.0.2            py37he6710b0_1  
prometheus_client         0.8.0                      py_0  
prompt_toolkit            3.0.3                      py_0  
protobuf                  3.11.4           py37he6710b0_0  
psutil                    5.6.7            py37h7b6447c_0  
psycopg2                  2.8.4            py37h1ba5d50_0  
ptyprocess                0.6.0                    py37_0  
pyarrow                   1.0.1                    pypi_0    pypi
pyasn1                    0.4.8                      py_0  
pyasn1-modules            0.2.7                      py_0  
pycparser                 2.19                     py37_0  
pygments                  2.5.2                      py_0  
pyjwt                     1.7.1                    py37_0  
pynacl                    1.3.0            py37h7b6447c_0  
pyodbc                    4.0.30           py37he6710b0_0  
pyopenssl                 19.1.0                     py_1  
pyparsing                 2.4.6                      py_0  
pyqt                      5.9.2            py37h05f1152_2  
pyrsistent                0.16.0           py37h7b6447c_0  
pysocks                   1.7.1                    py37_1  
python                    3.7.6                h0371630_2  
python-dateutil           2.8.1                      py_0  
python-editor             1.0.4                      py_0  
python-graphviz           0.14                       py_0  
pytorch                   1.6.0           py3.7_cuda10.1.243_cudnn7.6.3_0    pytorch
pytz                      2019.3                     py_0  
pyyaml                    5.3.1                    pypi_0    pypi
pyzmq                     18.1.1           py37he6710b0_0  
qt                        5.9.7                h5867ecd_1  
querystring-parser        1.2.4                    pypi_0    pypi
readline                  7.0                  h7b6447c_5  
requests                  2.22.0                   py37_1  
requests-oauthlib         1.3.0                      py_0  
retrying                  1.3.3                    py37_2  
rsa                       4.0                        py_0  
s3transfer                0.3.3                    py37_1  
scikit-learn              0.22.1           py37hd81dba3_0  
scipy                     1.4.1            py37h0b6359f_0  
seaborn                   0.10.0                   pypi_0    pypi
send2trash                1.5.0                    py37_0  
sentencepiece             0.1.85                   pypi_0    pypi
setuptools                45.2.0                   py37_0  
simplejson                3.17.0           py37h7b6447c_0  
sip                       4.19.8           py37hf484d3e_0  
six                       1.14.0                   py37_0  
smmap                     3.0.4                      py_0  
spacy                     2.3.1            py37hfd86e86_0  
spark-tensorflow-distributor 0.1.0                    pypi_0    pypi
sqlite                    3.31.1               h62c20be_1  
sqlparse                  0.3.0                      py_0  
srsly                     1.0.2            py37he6710b0_0  
statsmodels               0.11.0           py37h7b6447c_0  
tabulate                  0.8.3                    py37_0  
tensorboard               2.3.0                    pypi_0    pypi
tensorboard-plugin-wit    1.7.0                    pypi_0    pypi
tensorflow                2.3.0                    pypi_0    pypi
tensorflow-base           2.2.0           mkl_py37hd506778_0  
tensorflow-estimator      2.3.0                    pypi_0    pypi
termcolor                 1.1.0                    pypi_0    pypi
terminado                 0.8.3                    py37_0  
testpath                  0.4.4                      py_0  
thinc                     7.4.1            py37hfd86e86_0  
tk                        8.6.8                hbc83047_0  
torchvision               0.7.0                py37_cu101    pytorch
tornado                   6.0.3            py37h7b6447c_3  
tqdm                      4.42.1                     py_0  
traitlets                 4.3.3                    py37_0  
unixodbc                  2.3.7                h14c3975_0  
urllib3                   1.25.8                   py37_0  
wasabi                    0.8.0                      py_0  
wcwidth                   0.1.8                      py_0  
webencodings              0.5.1                    py37_1  
websocket-client          0.56.0                   py37_0  
werkzeug                  1.0.0                      py_0  
wheel                     0.34.2                   py37_0  
widgetsnbextension        3.5.1                    py37_0  
wrapt                     1.11.2           py37h7b6447c_0  
xgboost                   1.1.1                    pypi_0    pypi
xz                        5.2.4                h14c3975_4  
yaml                      0.2.5                h7b6447c_0  
zeromq                    4.3.1                he6710b0_3  
zipp                      3.1.0                      py_0  
zlib                      1.2.11               h7b6447c_3  
zstd                      1.3.7                h0b5b093_0  
```
</details>
",thanks trying reproduce like issue may cause machine learning spec top following work install sh pip install number trying use running issue would nice understand root cause issue summary complete list environment issue consistently name version build channel main astor blas bleach blinker catalogue click cryptography cycler decorator dill docker flask future gast glib gorilla graphite jinja mako markdown notebook pillow pip python sip six spacy tabulate tornado wasabi wheel,issue,positive,positive,positive,positive,positive,positive
692821319,"Honestly, I don't recall how the obj det code works at the moment, and it'll be a while before I'm looking at it again. So I'll just accept the PR, and if anyone finds that the behavior isn't right, please let me know and we can try again!",honestly recall code work moment looking accept anyone behavior right please let know try,issue,positive,positive,positive,positive,positive,positive
692818511,Thanks to you both. A PR that fixes the names to be unique would be great! And another one which warns if there are dupe names would also be nice. Don't worry about the header_subheader thing though...,thanks unique would great another one dupe would also nice worry thing though,issue,positive,positive,positive,positive,positive,positive
692816720,"Good catch! 

Alternatively, `nbdev` can be modified to assign `<header>_<sub-header>` (or some combination of them) as a tag to the sub-headers.
I am willing to contribute!

cc @hamelsmu @jph00 ",good catch alternatively assign header combination tag willing contribute,issue,negative,positive,positive,positive,positive,positive
692712199,"Forum members has the same issue, and the solution they found was to delete EXISTING directory imdb_tok that was malformed. In my case, there is NO such directory.",forum issue solution found delete directory malformed case directory,issue,negative,neutral,neutral,neutral,neutral,neutral
692698751,Many thanks! I'll merge this now. But I don't really like the fact that other callbacks have to know to call `self.learn.to_detach`. I wonder if the underlying problem is that really we need a `DistributedLearner`? That seems like it might be the right place for the `gather` stuff - what do you think?,many thanks merge really like fact know call wonder underlying problem really need like might right place gather stuff think,issue,positive,positive,positive,positive,positive,positive
692688200,"I can't reproduce that. I've tried running the code you provided on colab and on my own machine, and it works in both cases.

Can you see if you can find out you've got installed on your box which causes this behavior, or whether there's some other bit of code you ran first?",ca reproduce tried running code provided machine work see find got box behavior whether bit code ran first,issue,negative,positive,positive,positive,positive,positive
692643325,"@IRailean yeah, I believe in previous versions of fastai x.get_meta('img_size') may have returned None, which is why this stopped working in more recent versions. I will try to run this against my older environment tomorrow to validate this though. I got stuck when actually determining what changed this behavior across the different versions of fastai, as I couldn't really find code that seemed responsible. 

If you check the git blame _get_sz hasn't changed within the last 9 months. https://github.com/fastai/fastai/blame/72590db2e66af6dd0eaa8c8874a80f11a4b8cbc2/fastai/vision/core.py#L244

Taking a step back, I think I may have simply gotten to deep into trying to understand the differences, I think your solution should work. You could probably submit a pull request and see what Jeremy says. ",yeah believe previous may returned none stopped working recent try run older environment tomorrow validate though got stuck actually behavior across different could really find code responsible check git blame within last taking step back think may simply gotten deep trying understand think solution work could probably submit pull request see,issue,positive,positive,neutral,neutral,positive,positive
692570601,"Take a look at _unscale_pnts function in vision/core.py The problem may be that for unscaling it uses the original size of a picture not the resized one. 
I hardcoded sz variable in _unscale_pnts to a resized picture size: 
sz = fastuple((700, 700)) (In DataBlock API I used Resize(700, method=ResizeMethod.Squish)
and it worked! (Working also with other ResizeMethods.

So this may be the issue.

In PointScaler class there is decodes function which call self._get_sz function:
```
def decodes(self, x:TensorPoint): return _unscale_pnts(x.view(-1, 2), self._get_sz(x))
```
And self._get_sz is defined as:
```
def _get_sz(self, x):
        sz = x.get_meta('img_size')
        assert sz is not None or self.sz is not None, ""Size could not be inferred, pass it in the init of your TensorPoint with `img_size=...`""
        return self.sz if sz is None else sz
```
As I can see in the code attribute img_size is set once at creation time and will not be changed further (in fact, it will, in _unscale_pnts function, but it is useless as it is assigning original image size to img_size variable) :
(class TensorPoint)
```
def create(cls, t, img_size=None)->None:
        ""Convert an array or a list of points `t` to a `Tensor`""
        return cls(tensor(t).view(-1, 2).float(), img_size=img_size)
```
Thus, here self.sz will be the size of a resized picture, sz size of an original picture.
And as sz is not None we will return the original size of a picture and will unscale bbox wrongly.

But how do we get self.sz correctly? Where it is set?

In PointScaler decodes for image.
```
def decodes(self, x:(PILBase,TensorImageBase)): 
        return self._grab_sz(x)
```
It will grab the size and will assign it to self.sz:
```
def _grab_sz(self, x):
        self.sz = [x.shape[-1], x.shape[-2]] if isinstance(x, Tensor) else x.size
        return x
```

**Possible solution:**
decodes function in PointScaler must be called for image object first to get the actual image size and only then decodes will be called for TensorPoint object. 
If this condition is always true, we can change _get_sz function in PointScaler class:

```
def _get_sz(self, x):
        sz = x.get_meta('img_size')
        assert sz is not None or self.sz is not None, ""Size could not be inferred, pass it in the init of your TensorPoint with `img_size=...`""
        return self.sz if sz is None else sz
```
to 
```
def _get_sz(self, x):
        sz = x.get_meta('img_size')
        assert sz is not None or self.sz is not None, ""Size could not be inferred, pass it in the init of your TensorPoint with `img_size=...`""
        return sz if self.sz is None else self.sz
```
prioritizing self.sz over sz. Note, that, in this case, img_size property for TensorPoint will be updated with new self.sz value.",take look function problem may original size picture one variable picture size used resize worked working also may issue class function call function self return defined self assert none none size could pas return none else see code attribute set creation time fact function useless original image size variable class create none convert array list tensor return tensor thus size picture size original picture none return original size picture unscale wrongly get correctly set image self return grab size assign self tensor else return possible solution function must image object first get actual image size object condition always true change function class self assert none none size could pas return none else self assert none none size could pas return none else note case property new value,issue,positive,positive,positive,positive,positive,positive
692507561,"Adding my gist to this one: https://gist.github.com/marii-moe/be625c65e6d8aa783370cc70c7bc7ae2

I am continuing to look into this one, but I am fairly stuck on it. I believe it is related to ImageBBox._meta['img_size'] and decoding the bounding boxes, but I haven't been able to put that into a gist tonight, it is only something I noticed that behavs differently than previous versions.",gist one look one fairly stuck believe related bounding able put gist tonight something differently previous,issue,negative,positive,positive,positive,positive,positive
692502560,Will continue to add my findings from last week as I manage to prove to myself that I can trust those findings. Never did come to a solution though. ,continue add last week manage prove trust never come solution though,issue,negative,neutral,neutral,neutral,neutral,neutral
692206646,"Copying response from https://github.com/pytorch/pytorch/issues/44628

conv2d is called internally by `fastai` library. 

Notice that when `_conv_forward` fails, it has weights as a Tensor already, and only `input` is a  list of one single value 0, literally `[0]` as seen in the debug dump above. 

I understand that `input` must have come as `[0]` (single-element list of zero) from fastai directly somehow. I was trying to follow the logic in both of these libraries, but couldn't completely follow how `input` was going through all of these functions. ",response internally library notice tensor already input list one single value literally seen dump understand input must come list zero directly somehow trying follow logic could completely follow input going,issue,negative,positive,neutral,neutral,positive,positive
692140888,"Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/fastai/fastai/pull/2793""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 Review Jupyter notebook visual diffs & provide feedback on notebooks. 

---

 <i>Powered by <a href='https://www.reviewnb.com/?utm_source=gh'>ReviewNB</a></i>",check pull request review notebook visual provide feedback powered,issue,negative,neutral,neutral,neutral,neutral,neutral
692005376,"Hi,

I am getting this error:
```
AttributeError: 'Learner' object has no attribute 'lr_find'
```
Please let me know why am I getting this? I see everyone using this but no one gets this error. I am using `'2.0.10'` version of fastai. I imported `Learner` like this:
`from fastai.vision.learner import Learner`",hi getting error object attribute please let know getting see everyone one error version learner like import learner,issue,negative,neutral,neutral,neutral,neutral,neutral
691815766,"I tested locally with fastai installed from this branch (https://github.com/fastai/fastbook/issues/263) 
`pip install git+git://github.com/Tagar/fastai.git`

and it solves the [issue](https://github.com/fastai/fastbook/issues/263)",tested locally branch pip install issue,issue,negative,neutral,neutral,neutral,neutral,neutral
691810831,"Looks like all tests passed except this one - 

<img width=""715"" alt=""Screen Shot 2020-09-13 at 10 58 11 PM"" src=""https://user-images.githubusercontent.com/3013418/93045503-9ce12100-f614-11ea-9892-84e9fc8ea443.png"">

The reason is that I didn't regenerate the callback/schedule.py from notebook, and not sure why that new line is now missing. 
",like except one screen shot reason regenerate notebook sure new line missing,issue,negative,positive,positive,positive,positive,positive
691707914,"Haven't used gradient before.  Looks like the `imdb_tok` folder is being created though just not the `.pkl` file.  It can sometimes take a while depending on the machine and is usually produced last.

Maybe someone with gradient experience can chime in or better yet check the [forums](https://forums.fast.ai/) ",used gradient like folder though file sometimes take depending machine usually produced last maybe someone gradient experience chime better yet check,issue,positive,positive,neutral,neutral,positive,positive
691706769,"I'm using Gradient, not Colab.
This cell fails:

---------------------------------------------------------------------------
FileNotFoundError                         Traceback (most recent call last)
<ipython-input-17-395b8030fad4> in <module>
      1 from fastai.text.all import *
----> 2 dls = TextDataLoaders.from_folder(source, valid='test', bs=32)

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/text/data.py in from_folder(cls, path, train, valid, valid_pct, seed, vocab, text_vocab, is_lm, tok_tfm, seq_len, backwards, **kwargs)
    222         ""Create from imagenet style dataset in `path` with `train` and `valid` subfolders (or provide `valid_pct`)""
    223         splitter = GrandparentSplitter(train_name=train, valid_name=valid) if valid_pct is None else RandomSplitter(valid_pct, seed=seed)
--> 224         blocks = [TextBlock.from_folder(path, text_vocab, is_lm, seq_len, backwards) if tok_tfm is None else TextBlock(tok_tfm, text_vocab, is_lm, seq_len, backwards)]
    225         if not is_lm: blocks.append(CategoryBlock(vocab=vocab))
    226         get_items = partial(get_text_files, folders=[train,valid]) if valid_pct is None else get_text_files

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/text/data.py in from_folder(cls, path, vocab, is_lm, seq_len, backwards, min_freq, max_vocab, **kwargs)
    210     def from_folder(cls, path, vocab=None, is_lm=False, seq_len=72, backwards=False, min_freq=3, max_vocab=60000, **kwargs):
    211         ""Build a `TextBlock` from a `path`""
--> 212         return cls(Tokenizer.from_folder(path, **kwargs), vocab=vocab, is_lm=is_lm, seq_len=seq_len,
    213                    backwards=backwards, min_freq=min_freq, max_vocab=max_vocab)
    214 

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastai/text/core.py in from_folder(cls, path, tok, rules, **kwargs)
    276         if tok is None: tok = WordTokenizer()
    277         output_dir = tokenize_folder(path, tok=tok, rules=rules, **kwargs)
--> 278         res = cls(tok, counter=(output_dir/fn_counter_pkl).load(),
    279                   lengths=(output_dir/fn_lengths_pkl).load(), rules=rules, mode='folder')
    280         res.path,res.output_dir = path,output_dir

/opt/conda/envs/fastai/lib/python3.8/site-packages/fastcore/utils.py in load(fn)
    522 def load(fn:Path):
    523     ""Load a pickle file from a file name or opened file""
--> 524     if not isinstance(fn, io.IOBase): fn = open(fn,'rb')
    525     try: return pickle.load(fn)
    526     finally: fn.close()

FileNotFoundError: [Errno 2] No such file or directory: '/storage/data/imdb_tok/counter.pkl'
",gradient cell recent call last module import source path train valid seed backwards create style path train valid provide splitter none else path backwards none else backwards partial train valid none else path backwards path build path return path path none path path load load path load pickle file file name file open try return finally file directory,issue,negative,negative,neutral,neutral,negative,negative
691706088,"Fix is right, but the change needs to be made in the notebook, not the auto-generated module. :) ",fix right change need made notebook module,issue,negative,positive,positive,positive,positive,positive
691705002,"So running:
`dls = TextDataLoaders.from_folder(source, valid='test', bs=32)`

should now create the `imdb_tok` folder at `/storage/data/` and this should contain the `counter.pkl` file",running source create folder contain file,issue,negative,neutral,neutral,neutral,neutral,neutral
691703438,"Got it. Maybe it's worth adding some feedback, like ""Now run the next cell""?",got maybe worth feedback like run next cell,issue,positive,positive,positive,positive,positive,positive
691702400,"FYI the workers issue will be solved in a PR soon, `predict` isn't passing in `workers` to `get_preds`, only to the `DL`. Sorry!",issue soon predict passing sorry,issue,negative,negative,negative,negative,negative,negative
691690631,"I create a new environment and reinstall pytorch and fastai, but it still fails. Is python 3.8 ok for it? I have no idea.",create new environment reinstall still python idea,issue,negative,positive,positive,positive,positive,positive
691685521,Hard to say. It seems like it tries to convert the text to integer in the [encodes method](https://github.com/fastai/fastai/blob/cdd9cf33aa74fdeb64717ac1d03662040c1b3d2d/fastai/data/transforms.py#L240) but the vocab doesn't have 'pos' as a key. Because it works in Google Colab it is most likely a error in your local installation. Maybe try creating a new conda environment and reinstall fastai there.,hard say like convert text integer method key work likely error local installation maybe try new environment reinstall,issue,negative,negative,neutral,neutral,negative,negative
691682922,@TannerGilbert That solved the problem on Colab. But the KeyError problem occurs at my local environment with the latest fastai installed by the conda command.,problem problem local environment latest command,issue,negative,positive,positive,positive,positive,positive
691682419,"The default version of FastAI on Google Colab is 1.0.62. Therefore you need to update before running the code using:

```
!pip install fastai --upgrade -q
```

After that training worked for me without any issues (I only needed to decrease the batch size to not run out of memory):
![fastai_imdb](https://user-images.githubusercontent.com/36239763/93021414-bbc6bf80-f5e2-11ea-9c0c-46f2d9ec5bd5.png)
",default version therefore need update running code pip install upgrade training worked without decrease batch size run memory,issue,negative,neutral,neutral,neutral,neutral,neutral
691675639,Ok thanks. Maybe also change the text in the installation section of the README to indicate that the library needs to be updated to version 2,thanks maybe also change text installation section indicate library need version,issue,negative,positive,positive,positive,positive,positive
691675157,There's nothing we can do on Colab directly (we've already asked). I'll add a cell to the top of each notebook to update the lib with pip.,nothing directly already add cell top notebook update pip,issue,negative,positive,positive,positive,positive,positive
691674467,LanguageModelData is from a real old version of FastAI (0.7 as far as I have seen). With FastAI 2 you can use TextDataLoaders instead. For more information on how to implement ULMFit with FastAI 2 you can check out [the documentation](https://docs.fast.ai/tutorial.text#The-ULMFiT-approach),real old version far seen use instead information implement check documentation,issue,negative,positive,positive,positive,positive,positive
691672372,"Pretty sure this is also caused from moving the old documentation from docs.fast.ai to fastai1.fast.ai. Google took some time to realize that some urls have changed. 

Related issues:
https://github.com/fastai/fastai/issues/2776",pretty sure also moving old documentation took time realize related,issue,positive,positive,positive,positive,positive,positive
691622966,"@muellerzr Hi, Could you tell how to fix the above-mentioned error (n_workers) for Windows, please? The last versions ```2.0.9,2.0.10``` of fastai keep failing in Windows when we want to make predictions on tabular data. https://github.com/fastai/fastai/pull/2721",hi could tell fix error please last keep failing want make tabular data,issue,negative,neutral,neutral,neutral,neutral,neutral
691618095,I'm putting a note here in case someone else is looking at this (and then [the related issue in the fastcore repo]()) as I was---the earliest release where this issue was resolved was `fastai==2.0.10`,note case someone else looking related issue release issue resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
691592740,"By any chance are you using `colab`?  Did'nt have any issues running this on `colab`

The `imdb_tok`  folder as well as the `pkl` file are created after running this line:
`dls = TextDataLoaders.from_folder(untar_data(URLs.IMDB), valid='test', bs=32)`

Try this to resolve:

run this in a separate cell
`source = untar_data(URLs.IMDB)`

then run:
`dls = TextDataLoaders.from_folder(source, valid='test', bs=32)`

this should now create `imdb_tok` and the `pkl` file

If this does not resolve, delete the `imdb_tok` folder and then re-run the `dls=` line

See if that helps",chance running folder well file running line try resolve run separate cell source run source create file resolve delete folder line see,issue,positive,neutral,neutral,neutral,neutral,neutral
691575528,"If you are referring to this cell:
```
from fastai.tabular.all import *
path = untar_data(URLs.ADULT_SAMPLE)

dls = TabularDataLoaders.from_csv(path/'adult.csv', path=path, y_names=""salary"",
    cat_names = ['workclass', 'education', 'marital-status', 'occupation',
                 'relationship', 'race'],
    cont_names = ['age', 'fnlwgt', 'education-num'],
    procs = [Categorify, FillMissing, Normalize])

learn = tabular_learner(dls, metrics=accuracy)
```
Then it is behaving as expected.  There should be no output.  The output will generate when you run the very next cell:

`learn.fit_one_cycle(3)`

The reason the `ML_SAMPLE` cell has an output is because that cell has `learn.fine_tune(10)`  in the cell so as expected you get an output",cell import path salary normalize learn output output generate run next cell reason cell output cell cell get output,issue,negative,neutral,neutral,neutral,neutral,neutral
691560144,"Google Colab has its own version of pandas. 
In settings.ini we have 2 requirments for pandas: ""pandas"" and ""pandas>=1.1.0"". Maybe, pip during installing process ignores second requirment and will not install pandas with version >=1.1.0. 
Why there are two pandas reqs in settings.ini file, why it is required?

Update:
This commit removed pandas min version req. https://github.com/fastai/fastai/commit/ad2ae9675a71360dd60f5890496580b30662d25e#diff-8228e1469ce874d99adad6441463f503
But there are still two pandas reqs.",version maybe pip process second install version two file update commit removed min version still two,issue,negative,neutral,neutral,neutral,neutral,neutral
691450444,"When using images from the validation set during training, the loss is affected from these images as well thus causing the model to recognize specific features from validation data that will limit generalization.
I think that there should be a total separation between the training and validation sets.",validation set training loss affected well thus causing model recognize specific validation data limit generalization think total separation training validation,issue,negative,neutral,neutral,neutral,neutral,neutral
691198801,You need to set `num_workers` to zero in your call to `ImageDataLoaders`,need set zero call,issue,negative,neutral,neutral,neutral,neutral,neutral
691026614,"thank you danvelev,  the issue was due to different version. I trained model on colab but while deploying on production the version I installed using pip it was latest so by downgrading I manged it.
Thank you",thank issue due different version trained model production version pip latest thank,issue,positive,positive,positive,positive,positive,positive
690967169,I am pretty sure that different people will get different first links on google. Please provide your first link,pretty sure different people get different first link please provide first link,issue,positive,positive,positive,positive,positive,positive
690932357,"I had the same error and managed to fix it by updating my library of fastai to be matching the version of fastai where I load the file.
E.g. code where I was exporting the model was running 1.0.60, code loading the model was running 2.0.10. Hence by making sure those version are matching you will avoid this error (seems like there are quite some difference between fastai v1.0.* and fastai v2.0.*)
(make sure to check the versions in python itself as well, not just with `pip list` -> e.g. `import fastai; fastai.__version__`) I was checking installed packages in pip, without realising that I needed to restart my kernel after up-/downgrading for instance 😅 🤦‍♂️

NOTE: if you have the same case as me, would recommend you to downgrade the version on the code where you load the model, since upgrading the other one would deprecate your code and give you more errors on the functions you are using. ;) 

Hope this helps and saves you some time debugging 🙌",error fix library matching version load file code model running code loading model running hence making sure version matching avoid error like quite difference make sure check python well pip list import pip without restart kernel instance note case would recommend downgrade version code load model since one would deprecate code give hope time,issue,positive,positive,positive,positive,positive,positive
690728322,"Actually, having thought about it a bit more, does it matter that the second image in the Siamese pair, which is the 'reference' to compare with the first image (from validation set), is in the training set? During inference, you would be feeding the trained model a test-image and a reference-image (known class/category) anyways, right? And so the validation-set is being used in a similar way, i.e. comparing the validation-image with a reference-image (known class/category from training set), right?

Interested to hear from others who have more knowledge and experience in this...",actually thought bit matter second image pair compare first image validation set training set inference would feeding trained model known anyways right used similar way known training set right interested hear knowledge experience,issue,negative,positive,positive,positive,positive,positive
690725865,"If you're coming to this issue later on, the issue I ran into with this was that I had `fastcore==1.0.9` installed with `fastai==2.0.6`.

I downgraded to `fastcore==1.0.0` and got this to work",coming issue later issue ran got work,issue,negative,neutral,neutral,neutral,neutral,neutral
690584331,"The search uses google, and google is still showing search results that were available with version 1 since docs.fast.ai was used for FastAI version 1 first. As the page returns a 404 error, it shouldn't take too long until this link disappears from the search.",search still showing search available version since used version first page error take long link search,issue,negative,positive,positive,positive,positive,positive
690580672,"To everyone this may concern;

I have unsubscribed to this site , please STOP sending me any more emails.

Thank you
ntr.lvin.wiccan.witch@gmail.com

On Thu, Sep 10, 2020, 1:48 PM Tanner Gilbert <notifications@github.com>
wrote:

> I think this error is a result of moving the old fastai v1 documentation
> from docs.fast.ai to fastai1.fast.ai.
>
>    - Callback FastAI v2: https://docs.fast.ai/callback.core
>    - Callback FastAI v1: https://fastai1.fast.ai/callback.html
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2776#issuecomment-690569121>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/ANXWOF3JDQZWPTYQXYGB2XTSFEGNFANCNFSM4RASHVCQ>
> .
>
",everyone may concern unsubscribed site please stop sending thank tanner gilbert wrote think error result moving old documentation thread reply directly view,issue,negative,positive,neutral,neutral,positive,positive
690569121,"I think this error is a result of moving the old fastai v1 documentation from docs.fast.ai to fastai1.fast.ai.

- Callback FastAI v2: https://docs.fast.ai/callback.core
- Callback FastAI v1: https://fastai1.fast.ai/callback.html",think error result moving old documentation,issue,negative,positive,neutral,neutral,positive,positive
690432114,"I think you are right – well spotted. There seem to be two places where this `SiameseTransform` code (near identical) needs fixing in the notebook. Will you be able to make the changes and submit a PR? I think that might be easiest for Jeremy and co to review and merge. Might also be worth adding in some cells with the `assert` test that you used, to highlight the importance of checking and testing for such train/val leakage? (the tutorial notebook is not part of the fastai library code base, and so there is no obvious way to add the `assert` test elsewhere, other than within the notebook itself to show)",think right well spotted seem two code near identical need fixing notebook able make submit think might easiest review merge might also worth assert test used highlight importance testing leakage tutorial notebook part library code base obvious way add assert test elsewhere within notebook show,issue,positive,positive,neutral,neutral,positive,positive
690353647,"@jph00 No problem. I also found some errors in the FastAI v1 documentation that where caused by moving the repository from fastai/fastai to fastai/fastai1 and moving the documentation from docs.fast.ai to fastai1.fast.ai.

I created a pull request that should fix most of the broken links and also fixes the documentation side that was linking to the wrong repo: https://github.com/fastai/fastai1/pull/2",problem also found documentation moving repository moving documentation pull request fix broken link also documentation side linking wrong,issue,negative,negative,negative,negative,negative,negative
689979873,Thanks!  Having issues submitting the corrections hence creating a new PR #2780 with the updates and closing this one,thanks hence new one,issue,negative,positive,positive,positive,positive,positive
689899817,"Thanks for the pointer, I re-wrote the code using `hasattr`  and hope this is a better version.  It was tested with the same images and works fine",thanks pointer code hope better version tested work fine,issue,positive,positive,positive,positive,positive,positive
689827319,"@sgugger I have a script that uses 'LanguageModelData' function. I can't find the installation instructions for version 0.7 of fastai, as suggested by you here:

> The scripts are for the old version of the library (0.7) so you should use that version. Installation instructions are [here](https://github.com/fastai/fastai/tree/master/old).

Would you know the equivalent function of LanguageModelData in v1.0.x and onwards of fastai or a way to install v0.7 to run a code with this function?
",script function ca find installation version old version library use version installation would know equivalent function onwards way install run code function,issue,negative,positive,neutral,neutral,positive,positive
689594090,"I see thanks, I didn't expected `.test_dl` to use the datablock parameters but it seems it does, I just wanted to make sure the test set is loaded the exact same way the validation dataset was.

still I need to already have a datasets or dataloaders to call `.test_dl` or `.test_set` I was trying to make a test set directly from a datablock, but I can work with this.",see thanks use make sure test set loaded exact way validation still need already call trying make test set directly work,issue,positive,positive,positive,positive,positive,positive
689016257,The fix has to be made in the progress callback. Working on it right now.,fix made progress working right,issue,negative,positive,positive,positive,positive,positive
688724965,"Had the same problem with `from fastai.tabular.all import *`. What helped me was changing `pip install fastai` to `pip install fastai --upgrade`, running the cell and restarting the runtime",problem import pip install pip install upgrade running cell,issue,negative,neutral,neutral,neutral,neutral,neutral
688723272,I have encountered this problem when working with fastai on google colab. Inplace option would be a life saver,problem working option would life saver,issue,negative,neutral,neutral,neutral,neutral,neutral
688634699,"Seems true tried this just now, I was using fastai 2.0.0 and you recommended 2.0.9, Things go sideways in just minor patch releases of the same version",true tried go sideways minor patch version,issue,negative,positive,positive,positive,positive,positive
688526974,"It is not supposed to work like that. `Transforms` use the training set to `setup`. In your case, there is no training item, so transform have no way to setup, thus the error.

If you want to create test sets refer to this [section](https://docs.fast.ai/data.core#Add-test-set-for-inference). ",supposed work like use training set setup case training item transform way setup thus error want create test refer section,issue,negative,neutral,neutral,neutral,neutral,neutral
688501241,"The error is not due to exporting the learner. I verified it. There is something wrong in `learn.tta()`. If you run `learn.tta()` before exporting then the code will still fail with the same error.

UPDATE: The error occurs when we run `learn.tta` multiple times. When I first ran `learn.tta` it worked as it should. But when I ran it again `learn.tta` I got the above error.

`learn.epoch = 0` solves the issue. I think the reason is in `MasterBar.update` `start_t` is only defined when val=0 i.e. epoch=0.",error due learner something wrong run code still fail error update error run multiple time first ran worked ran got error issue think reason defined,issue,negative,negative,negative,negative,negative,negative
688499414,Use `pip install fastai==2.0.9`. I think pip does not upgrade a package if there is only a patch release. I verified on the master branch and the code is working. So probably you have an older fastai version.,use pip install think pip upgrade package patch release master branch code working probably older version,issue,negative,positive,positive,positive,positive,positive
688452947,"Thanks for your reply. Yes, everything fine with version ```2.0.8``` in Windows. However, recent update ```2.0.9``` throws:
```
2020-09-07T07:55:59.5903654Z -- 1. Failure: tabular ops predict  --------------------------------------------
2020-09-07T07:55:59.5903948Z `force(expr)` threw an error.
2020-09-07T07:55:59.5904364Z Message: AttributeError: Can't pickle local object 'make_python_function.<locals>.python_function'
2020-09-07T07:55:59.5904570Z 
2020-09-07T07:55:59.5904808Z Detailed traceback: 
2020-09-07T07:55:59.5905515Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\fastai\tabular\learner.py"", line 18, in predict
2020-09-07T07:55:59.5906176Z     inp,preds,_,dec_preds = self.get_preds(dl=dl, with_input=True, with_decoded=True)
2020-09-07T07:55:59.5906676Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\fastai\learner.py"", line 235, in get_preds
2020-09-07T07:55:59.5906989Z     self._do_epoch_validate(dl=dl)
2020-09-07T07:55:59.5907873Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\fastai\learner.py"", line 188, in _do_epoch_validate
2020-09-07T07:55:59.7797723Z     with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)
2020-09-07T07:55:59.7798178Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\fastai\learner.py"", line 155, in _with_events
2020-09-07T07:55:59.7798446Z     try:       self(f'before_{event_type}')       ;f()
2020-09-07T07:55:59.7798834Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\fastai\learner.py"", line 161, in all_batches
2020-09-07T07:55:59.7799095Z     for o in enumerate(self.dl): self.one_batch(*o)
2020-09-07T07:55:59.7799473Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\fastai\data\load.py"", line 103, in __iter__
2020-09-07T07:55:59.7799746Z     for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
2020-09-07T07:55:59.7800153Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\site-packages\torch\utils\data\dataloader.py"", line 737, in __init__
2020-09-07T07:55:59.7800331Z     w.start()
2020-09-07T07:55:59.7800844Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\multiprocessing\process.py"", line 105, in start
2020-09-07T07:55:59.7801085Z     self._popen = self._Popen(self)
2020-09-07T07:55:59.7801449Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\multiprocessing\context.py"", line 223, in _Popen
2020-09-07T07:55:59.7801728Z     return _default_context.get_context().Process._Popen(process_obj)
2020-09-07T07:55:59.7802198Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\multiprocessing\context.py"", line 322, in _Popen
2020-09-07T07:55:59.7802396Z     return Popen(process_obj)
2020-09-07T07:55:59.7802771Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\multiprocessing\popen_spawn_win32.py"", line 65, in __init__
2020-09-07T07:55:59.7802996Z     reduction.dump(process_obj, to_child)
2020-09-07T07:55:59.7803354Z   File ""C:\Users\RUNNER~1\AppData\Local\R-MINI~1\envs\R-RETI~1\lib\multiprocessing\reduction.py"", line 60, in dump
2020-09-07T07:55:59.7803700Z     ForkingPickler(file, protocol).dump(obj)
```",thanks reply yes everything fine version however recent update failure tabular predict force threw error message ca pickle local object detailed file line predict file line file line file line try self file line enumerate file line file line file line start self file line return file line return file line file line dump file protocol,issue,negative,positive,positive,positive,positive,positive
688451271,"I was unable to reproduce your error but I did get another one which seems to be affected by this recent update [#2721](https://github.com/fastai/fastai/pull/2721).  This works fine on my windows machine with `fastai 2.0.8` but throws this error with version `2.0.9`

```
Empty                                     Traceback (most recent call last)
~\AppData\Roaming\Python\Python37\site-packages\torch\utils\data\dataloader.py in _try_get_data(self, timeout)
    778         try:
--> 779             data = self._data_queue.get(timeout=timeout)
    780             return (True, data)

~\Anaconda3\envs\fastai_2020_N\lib\multiprocessing\queues.py in get(self, block, timeout)
    104                     if not self._poll(timeout):
--> 105                         raise Empty
    106                 elif not self._poll():

Empty: 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-12-a8e547ce62ec> in <module>
----> 1 learn.predict(row, n_workers=12)

~\AppData\Roaming\Python\Python37\site-packages\fastai\tabular\learner.py in predict(self, row, n_workers)
     16         dl = self.dls.test_dl(row.to_frame().T, num_workers=0)
     17         dl.dataset.conts = dl.dataset.conts.astype(np.float32)
---> 18         inp,preds,_,dec_preds = self.get_preds(dl=dl, with_input=True, with_decoded=True)
     19         b = (*tuplify(inp),*tuplify(dec_preds))
     20         full_dec = self.dls.decode(b)

~\AppData\Roaming\Python\Python37\site-packages\fastai\learner.py in get_preds(self, ds_idx, dl, with_input, with_decoded, with_loss, act, inner, reorder, cbs, n_workers, **kwargs)
    233         if with_loss: ctx_mgrs.append(self.loss_not_reduced())
    234         with ContextManagers(ctx_mgrs):
--> 235             self._do_epoch_validate(dl=dl)
    236             if act is None: act = getattr(self.loss_func, 'activation', noop)
    237             res = cb.all_tensors()

~\AppData\Roaming\Python\Python37\site-packages\fastai\learner.py in _do_epoch_validate(self, ds_idx, dl)
    186         if dl is None: dl = self.dls[ds_idx]
    187         self.dl = dl
--> 188         with torch.no_grad(): self._with_events(self.all_batches, 'validate', CancelValidException)
    189 
    190     def _do_epoch(self):

~\AppData\Roaming\Python\Python37\site-packages\fastai\learner.py in _with_events(self, f, event_type, ex, final)
    153 
    154     def _with_events(self, f, event_type, ex, final=noop):
--> 155         try:       self(f'before_{event_type}')       ;f()
    156         except ex: self(f'after_cancel_{event_type}')
    157         finally:   self(f'after_{event_type}')        ;final()

~\AppData\Roaming\Python\Python37\site-packages\fastai\learner.py in all_batches(self)
    159     def all_batches(self):
    160         self.n_iter = len(self.dl)
--> 161         for o in enumerate(self.dl): self.one_batch(*o)
    162 
    163     def _do_one_batch(self):

~\AppData\Roaming\Python\Python37\site-packages\fastai\data\load.py in __iter__(self)
    101         self.randomize()
    102         self.before_iter()
--> 103         for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
    104             if self.device is not None: b = to_device(b, self.device)
    105             yield self.after_batch(b)

~\AppData\Roaming\Python\Python37\site-packages\torch\utils\data\dataloader.py in __next__(self)
    361 
    362     def __next__(self):
--> 363         data = self._next_data()
    364         self._num_yielded += 1
    365         if self._dataset_kind == _DatasetKind.Iterable and \

~\AppData\Roaming\Python\Python37\site-packages\torch\utils\data\dataloader.py in _next_data(self)
    972 
    973             assert not self._shutdown and self._tasks_outstanding > 0
--> 974             idx, data = self._get_data()
    975             self._tasks_outstanding -= 1
    976 

~\AppData\Roaming\Python\Python37\site-packages\torch\utils\data\dataloader.py in _get_data(self)
    939         else:
    940             while True:
--> 941                 success, data = self._try_get_data()
    942                 if success:
    943                     return data

~\AppData\Roaming\Python\Python37\site-packages\torch\utils\data\dataloader.py in _try_get_data(self, timeout)
    790             if len(failed_workers) > 0:
    791                 pids_str = ', '.join(str(w.pid) for w in failed_workers)
--> 792                 raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))
    793             if isinstance(e, queue.Empty):
    794                 return (False, None)

RuntimeError: DataLoader worker (pid(s) 20252, 19284, 8980, 11452, 6872, 20204, 19932, 3140, 27916, 4960, 18616, 4984) exited unexpectedly
```
Typically this error refers to `num_workers` being put to `0` but in this case I am not sure how to resolve this issue.

No change in the code, same as the notebook you referenced above and it works fine on `colab` and `windows with 2.0.8`",unable reproduce error get another one affected recent update work fine machine error version empty recent call last self try data return true data get self block raise empty empty handling exception another exception recent call last module row predict self row self act inner reorder act none act noop self none self self ex final self ex try self except ex self finally self final self self enumerate self self none yield self self data self assert data self else true success data success return data self raise worker return false none worker unexpectedly typically error put case sure resolve issue change code notebook work fine,issue,positive,positive,neutral,neutral,positive,positive
687752016,"Hmm, I found out that the correct page for the documentation seems to be https://docs.fast.ai/callback.progress#ShowGraphCallback, is `docs.fast.ai/callbacks` an outdated reference? Maybe the search index should be updated.",found correct page documentation outdated reference maybe search index,issue,negative,negative,negative,negative,negative,negative
687676031,Thanks @vishalbakshi - that fixed the 2 problems for me!  But it seems there is a tutorial / colab version pairing problem that I hope gets addressed by this issue.,thanks fixed tutorial version problem hope issue,issue,negative,positive,positive,positive,positive,positive
687658147,"Hi @rfernand2 I found a potential solution ([from the fast.ai course forums](https://forums.fast.ai/t/modulenotfounderror-no-module-named-fastai-vision-all-on-kaggle-notebook/77008)) which is to run `!pip install fastai --upgrade`, then restart the runtime, upon which the `fastai.vision.all` import worked for me.
",hi found potential solution course run pip install upgrade restart upon import worked,issue,negative,neutral,neutral,neutral,neutral,neutral
687565581,"**Update**: I can report that downgrading to fastcore=1.0.0 appears to fix this issue.  Perhaps this commit introduced a bug somehow?

https://github.com/fastai/fastcore/commit/ea1c33f1c3543e6e4403b1d3b7702a98471f3515#diff-2d5ca7a202ff50e2df29f58cfa4a4c12",update report fix issue perhaps commit bug somehow,issue,negative,neutral,neutral,neutral,neutral,neutral
686507218,"In reality what this PR does is modify the `RNNDropout` function, adding support for sequences of more than 1 dimension.
It is mostly for my use with ConvLSTM networks, where I want to do dropout consistent over the time axis. I implemented a kind of `AWD-ConvLSTM` that I hope to push to fastai soon.",reality modify function support dimension mostly use want dropout consistent time axis kind hope push soon,issue,positive,positive,positive,positive,positive,positive
686502173,"could you please tell the sentence, which is required to be simplified.
Sorry for the inconvenience caused",could please tell sentence simplified sorry inconvenience,issue,negative,negative,negative,negative,negative,negative
686489612,"Unsubscribe

On Thu, 3 Sep 2020, 17:02 Jeremy Howard, <notifications@github.com> wrote:

> Closed #2753 <https://github.com/fastai/fastai/pull/2753>.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/2753#event-3724605280>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEX7N7T7TAVJEEQ6P6FWGQDSD6HYFANCNFSM4QUU4KRQ>
> .
>
",wrote closed thread reply directly view,issue,negative,neutral,neutral,neutral,neutral,neutral
686399818,Could you add some prose in markdown briefly explaining this multidimensional support and showing how to use it?,could add prose markdown briefly explaining multidimensional support showing use,issue,negative,neutral,neutral,neutral,neutral,neutral
686398636,"I'm very grateful for you writing this! :) 

It's more of a code walk-thru than an explanation of what things are actually for, so I think this would be better as the basis for a blog post, rather than part of the docs. I do agree that a tutorial explaining this class is needed, but I think that might need to be written by me, since no-one else yet knows why things are the way they are in this class!...",grateful writing code explanation actually think would better basis post rather part agree tutorial explaining class think might need written since else yet way class,issue,positive,positive,positive,positive,positive,positive
686395996,"I'd rather not replace active with passive voice like this, or to replace simple language with less readable language.",rather replace active passive voice like replace simple language le readable language,issue,positive,negative,neutral,neutral,negative,negative
686286463,"<p>Hi Jeremy, still updating on your comments and will commit asap thanks</p>",hi still commit thanks,issue,positive,positive,positive,positive,positive,positive
686053222,I've got things better set up to notify me now. But feel free to tag me if you don't get a timely response,got better set notify feel free tag get timely response,issue,positive,positive,positive,positive,positive,positive
686052615,@jph00 Not sure if we're still supposed to tag you on PR's,sure still supposed tag,issue,negative,positive,positive,positive,positive,positive
686049414,"The way to log model should be more robust, mainly if the saved model file changes while being uploaded (for example when using `fine_tune` on short epochs).",way log model robust mainly saved model file example short,issue,positive,positive,neutral,neutral,positive,positive
686029478,Actually I'm going to take advantage of this PR to implement another small improvement on model logging,actually going take advantage implement another small improvement model logging,issue,positive,negative,negative,negative,negative,negative
685733627,"Unfortunately, it also makes it incorrect, I believe, since valid_pct None and `0` have very different meanings. Your change would make a valid_pct of `0` be ignored, and replaced with a GrandparentSplitter!",unfortunately also incorrect believe since none different change would make,issue,negative,negative,negative,negative,negative,negative
685303469,"I am sorry. I should have changed the code in Jupyter Notebook(nbdev). I will close this PR, and will make another one.
sorry about the inconvenience!",sorry code notebook close make another one sorry inconvenience,issue,negative,negative,negative,negative,negative,negative
685295749,"<p>Re-worded the sentence and included <code>fastai.medical.imaging</code>  and <code>pydicom.dcmread</code>  so hopefully reads better now</p>

---

 <a href='https://app.reviewnb.com/fastai/fastai/pull/2740/discussion/'>View entire conversation</a> on ReviewNB<div id=""RAICReplyForNotification-ReviewNBCommentContext-DoNotDelete""></div>",sentence included code code hopefully better entire conversation div,issue,positive,positive,positive,positive,positive,positive
685289305,"<p>gotcha on that one, was fighting with the words on this one changed to <code>try to choose</code></p>

---

 <a href='https://app.reviewnb.com/fastai/fastai/pull/2740/discussion/'>View entire conversation</a> on ReviewNB<div id=""RAICReplyForNotification-ReviewNBCommentContext-DoNotDelete""></div>",one fighting one code try choose entire conversation div,issue,negative,neutral,neutral,neutral,neutral,neutral
685288119,"<p>Ah yes, I'm on a windows machines! will take that out</p>

---

 <a href='https://app.reviewnb.com/fastai/fastai/pull/2740/discussion/'>View entire conversation</a> on ReviewNB<div id=""RAICReplyForNotification-ReviewNBCommentContext-DoNotDelete""></div>",ah yes take entire conversation div,issue,negative,neutral,neutral,neutral,neutral,neutral
685183604,"FYI, it's actually `make docs` which does the readme. I've run it now. Many thanks for the PR!",actually make run many thanks,issue,negative,positive,positive,positive,positive,positive
685183075,Nice job! Just some minor suggestions to look at. Please let me know when you've had a chance to fix them up.,nice job minor look please let know chance fix,issue,positive,positive,positive,positive,positive,positive
685182802,"View / edit / reply to <a href='https://app.reviewnb.com/fastai/fastai/pull/2740/discussion/'>this conversation</a> on ReviewNB

<span id='282064' class='CommentSeparator-DoNotDelete'> _jph00 commented on 2020-09-01T23:16:41Z_
----------------------------------------------------------------</span>
<p>""Try to find""</p>
<br/>

 


<span id='386836' class='CommentSeparator-DoNotDelete'> _asvcode commented on 2020-09-02T04:41:42Z_
----------------------------------------------------------------</span>
<p>updated</p>

<div class='ThreadMetadata-DoNotDelete' data-state='RESOLVED' data-cellIndex='45' data-originalCommitID='a35550183494ae6007ee7e2b1584532af1baec3a' data-path='nbs/61_tutorial.medical_imaging.ipynb'/>

<div id='282064' class='CommentFooter-DoNotDelete' data-authorLogin='jph00' data-authorAvatarURL='https://avatars1.githubusercontent.com/u/346999?v=4' data-createdAt='2020-09-01T23:16:41Z'/>

<div id='386836' class='CommentFooter-DoNotDelete' data-authorLogin='asvcode' data-authorAvatarURL='https://avatars3.githubusercontent.com/u/25020209?v=4' data-createdAt='2020-09-02T04:41:42Z'/>
",view edit reply conversation span try find span div div div,issue,negative,neutral,neutral,neutral,neutral,neutral
685182796,"View / edit / reply to <a href='https://app.reviewnb.com/fastai/fastai/pull/2740/discussion/'>this conversation</a> on ReviewNB

<span id='903295' class='CommentSeparator-DoNotDelete'> _jph00 commented on 2020-09-01T23:16:40Z_
----------------------------------------------------------------</span>
<p>I would say it will ""try to choose"" the best selection</p>
<br/>

 



<span id='521069' class='CommentSeparator-DoNotDelete'> _asvcode commented on 2020-09-02T04:35:12Z_
----------------------------------------------------------------</span>
<p>gotcha on that one, was fighting with the words on this one changed to try to choose</p>

<div class='ThreadMetadata-DoNotDelete' data-state='RESOLVED' data-cellIndex='41' data-originalCommitID='a35550183494ae6007ee7e2b1584532af1baec3a' data-path='nbs/61_tutorial.medical_imaging.ipynb'/>

<div id='903295' class='CommentFooter-DoNotDelete' data-authorLogin='jph00' data-authorAvatarURL='https://avatars1.githubusercontent.com/u/346999?v=4' data-createdAt='2020-09-01T23:16:40Z'/>

<div id='521069' class='CommentFooter-DoNotDelete' data-authorLogin='asvcode' data-authorAvatarURL='https://avatars3.githubusercontent.com/u/25020209?v=4' data-createdAt='2020-09-02T04:35:12Z'/>
",view edit reply conversation span would say try choose best selection span one fighting one try choose div div div,issue,negative,positive,positive,positive,positive,positive
685182793,"View / edit / reply to <a href='https://app.reviewnb.com/fastai/fastai/pull/2740/discussion/'>this conversation</a> on ReviewNB

<span id='692773' class='CommentSeparator-DoNotDelete'> _jph00 commented on 2020-09-01T23:16:40Z_
----------------------------------------------------------------</span>
<p>remove <code>num_dataloaders</code>  here</p>
<br/>

 


<span id='683011' class='CommentSeparator-DoNotDelete'> _asvcode commented on 2020-09-02T04:31:14Z_
----------------------------------------------------------------</span>
<p>Ah yes, I'm on a windows machines! will take that out</p>

<div class='ThreadMetadata-DoNotDelete' data-state='RESOLVED' data-cellIndex='37' data-originalCommitID='a35550183494ae6007ee7e2b1584532af1baec3a' data-path='nbs/61_tutorial.medical_imaging.ipynb'/>

<div id='692773' class='CommentFooter-DoNotDelete' data-authorLogin='jph00' data-authorAvatarURL='https://avatars1.githubusercontent.com/u/346999?v=4' data-createdAt='2020-09-01T23:16:40Z'/>

<div id='683011' class='CommentFooter-DoNotDelete' data-authorLogin='asvcode' data-authorAvatarURL='https://avatars3.githubusercontent.com/u/25020209?v=4' data-createdAt='2020-09-02T04:31:14Z'/>
",view edit reply conversation span remove code span ah yes take div div div,issue,negative,neutral,neutral,neutral,neutral,neutral
685182790,"View / edit / reply to <a href='https://app.reviewnb.com/fastai/fastai/pull/2740/discussion/'>this conversation</a> on ReviewNB

<span id='356228' class='CommentSeparator-DoNotDelete'> _jph00 commented on 2020-09-01T23:16:39Z_
----------------------------------------------------------------</span>
<p>Maybe mention that  <code>dcmread</code>  comes from <code>pydicom</code>,  otherwise it's not clear why you're mentioned it. Also say that <code>fastai.medical.imaging</code>  uses functionality from pydicom</p>
<br/>

 


<span id='592469' class='CommentSeparator-DoNotDelete'> _asvcode commented on 2020-09-02T04:56:05Z_
----------------------------------------------------------------</span>
<p>Re-worded the sentence and included <code>fastai.medical.imaging</code>  and <code>pydicom.dcmread</code>  so hopefully reads better now</p>

<div class='ThreadMetadata-DoNotDelete' data-state='RESOLVED' data-cellIndex='17' data-originalCommitID='a35550183494ae6007ee7e2b1584532af1baec3a' data-path='nbs/61_tutorial.medical_imaging.ipynb'/>

<div id='356228' class='CommentFooter-DoNotDelete' data-authorLogin='jph00' data-authorAvatarURL='https://avatars1.githubusercontent.com/u/346999?v=4' data-createdAt='2020-09-01T23:16:39Z'/>

<div id='592469' class='CommentFooter-DoNotDelete' data-authorLogin='asvcode' data-authorAvatarURL='https://avatars3.githubusercontent.com/u/25020209?v=4' data-createdAt='2020-09-02T04:56:05Z'/>
",view edit reply conversation span maybe mention code come code otherwise clear also say code functionality span sentence included code code hopefully better div div div,issue,positive,positive,positive,positive,positive,positive
685122390,"Yeah I think we should fix the changes in nbdev first

is the most current version of nbdev not being used here?  I think it is?",yeah think fix first current version used think,issue,negative,positive,positive,positive,positive,positive
685116072,"I think until the issue with `nbdev` is fixed we should manually make this change in README. (if that's allowed)

WDYT? @hamelsmu ",think issue fixed manually make change,issue,negative,positive,neutral,neutral,positive,positive
685111230,"Thanks for the clarification!

Seems a problem in converting the links specifically pointing to `https://docs.fast.ai/<x.html>` by `nbdev` as all the links in `index.ipynb` are in fact appropriate.

I am looking into it!",thanks clarification problem converting link specifically pointing link fact appropriate looking,issue,negative,positive,positive,positive,positive,positive
685110720,"I'll go ahead and close this PR, please feel free to open a new one with changes to `index.ipynb`",go ahead close please feel free open new one,issue,positive,positive,positive,positive,positive,positive
684881872,I imagine post changing how inference is done Jeremy may fix this to some degree,imagine post inference done may fix degree,issue,negative,neutral,neutral,neutral,neutral,neutral
684880179,"While I agree with you, the bug is in the fact that you can send in an L of items and it will return a string *decoded* representation of the translated items. ",agree bug fact send return string representation,issue,negative,neutral,neutral,neutral,neutral,neutral
684836578,"Is your `preds[2]` a list/ tensor of indices or one single index? From my understanding, `Categorize` is meant to process one single item, instead of a list of items. So i think it makes sense to output a string (or `Category`)

```
In [11]: cat = Categorize(add_na = False, vocab = ['dog', 'cat'])

In [12]: cat.decode(0)
Out[12]: 'cat'
```

I use `Dataset` level `decode` for decoding list of items. e.g.

```
In [6]: cat = Categorize(add_na = False)

In [7]: tds = Datasets(['cat', 'dog', 'cat'], tfms = [cat])

In [8]: tds.decode([0, 0, 1])
Out[8]: ('cat', 'cat', 'dog')
```",tensor index one single index understanding categorize meant process one single item instead list think sense output string category cat categorize false use level decode list cat categorize false cat,issue,negative,negative,negative,negative,negative,negative
684643059,"This is pretty elegant en useful, thanks!",pretty elegant en useful thanks,issue,positive,positive,positive,positive,positive,positive
684399528,Hi @hamelsmu could you please review the PR,hi could please review,issue,negative,neutral,neutral,neutral,neutral,neutral
683738963,"5 runs w/ 3 GPUs DDP -> https://gist.github.com/antorsae/7157da6ec9e5fa40a961806a92fc91d7
5 runs w/ 3 GPUs DP -> https://gist.github.com/antorsae/29f0d95e80c981157011d9e8ff2737a6
5 runs w/ single GPU -> https://gist.github.com/antorsae/48f852a7e39c0e4f828cc5e014f81ed4

Note that not much can be told from the results above b/c the real issue is padding a few items at the end of `DistributedDL`. 

Validation metrics would be inaccurate b/c of the padded items but reallistically padded items in the above scenario have a minuscule impact (classes are relatively balanced and further distribution makes it that a few single items cannot have a big impact in metric). 

Bigger issue is calling `get_preds` (which the code does not do) which may potentially result in a different number of items returned (b/c of the padding)... which this PR fixes.",single note much told real issue padding end validation metric would inaccurate scenario minuscule impact class relatively balanced distribution single big impact metric bigger issue calling code may potentially result different number returned padding,issue,negative,positive,neutral,neutral,positive,positive
683499041,"I believe the data is there - it's just that the initial tokens are padding, since the data is sorted for you by size (and show_batch truncates). If you check the actual data and see it really is all padding, feel free to re-open this with the code showing that.",believe data initial padding since data sorted size check actual data see really padding feel free code showing,issue,positive,positive,positive,positive,positive,positive
683498313,"Oh also, could you try running tests of a regular (non-weighted) DL to confirm it gives the same results for, say, 5 runs of Imagenette over 20 epochs?",oh also could try running regular confirm say,issue,negative,neutral,neutral,neutral,neutral,neutral
683498134,"This looks great. Did you want to close #2687 since this includes that functionality (AFAICT)?

This will take me a while to review - but it's certainly a priority!",great want close since functionality take review certainly priority,issue,positive,positive,positive,positive,positive,positive
683477058,Tests are limited b/c of difficulting in simulating a proper DDP mode in test. I have tested this in train/valid/inference with `WeightedDL` and works OK in my 1-off tests.,limited proper mode test tested work,issue,negative,negative,neutral,neutral,negative,negative
683466471,"Showing batch after runinng the first DataBlock works fine though. The second Datablock causes the bug.
```python
dls_lm = DataBlock(
    blocks=TextBlock.from_folder(path, is_lm=True),
    get_items=get_imdb, splitter=RandomSplitter(0.1)
).dataloaders(path, path=path, bs=128, seq_len=80)

dls_lm.show_batch(max_n=2)
```",showing batch first work fine though second bug python path path,issue,negative,positive,positive,positive,positive,positive
683445705,"Originally I closed this issue, however I realized this is actually a bug because it will return a string representation of a decoded list!",originally closed issue however actually bug return string representation list,issue,negative,negative,neutral,neutral,negative,negative
683444588,"I would further expect these two to be the same, but they are not:

```python
Category(learn.dls.vocab[o[2]])
learn.dls.vocab[o[2]]
```",would expect two python category,issue,negative,neutral,neutral,neutral,neutral,neutral
683435720,"First: you need to upgrade via `pip install fastai --upgrade`

Second: Colab (not sure if you're doing the free version or the paid)'s GPU's are much smaller than what Jeremy runs on, so lower the batch size.

Finally, this is a question better suited for forums.fast.ai rather than opening a github issue",first need upgrade via pip install upgrade second sure free version much smaller lower batch size finally question better rather opening issue,issue,positive,positive,positive,positive,positive,positive
683435538,I've decided since you're going to completely rework inference to not do the inference guide yet. I'd rather wait until after you make your adjustments @jph00 ,decided since going completely rework inference inference guide yet rather wait make,issue,negative,positive,neutral,neutral,positive,positive
683378461,"also, I tried `num_workers=0` but got the same error.",also tried got error,issue,negative,neutral,neutral,neutral,neutral,neutral
683311421,I believe the answer would be in the form of something like a DecodingCallback that can either decode everything (inps and outs) or optionally x or y (both would default to True) ,believe answer would form something like either decode everything optionally would default true,issue,positive,positive,positive,positive,positive,positive
683294285,"Debugging Notes
* There are 127 docs currently indexed by Google from docs.fast.ai https://www.google.com/search?q=site:docs.fast.ai
*  https://support.google.com/webmasters/answer/9012289 may help to identify why these urls are not indexed by Google.

Reference
* https://nbdev.fast.ai/search",currently indexed may help identify indexed reference,issue,negative,neutral,neutral,neutral,neutral,neutral
683098773,Along with this I'm going to write a tutorial.inference documentation to hit on a few key points. ,along going write documentation hit key,issue,negative,neutral,neutral,neutral,neutral,neutral
683020866,Fixed w #2716. Close for now.  May explore additional processor in the future for more robust white space handling similar to other Transforms such as FillMissing and Categorify.,fixed close may explore additional processor future robust white space handling similar,issue,negative,positive,neutral,neutral,positive,positive
683019365,"Humm, seems like the tests didn't pass in a notebook I did not modify.",like pas notebook modify,issue,negative,neutral,neutral,neutral,neutral,neutral
682473533,It is part of the old library and is at https://fastai1.fast.ai/vision.models.html (so this can be closed) ,part old library closed,issue,negative,neutral,neutral,neutral,neutral,neutral
682390695,"Hi @hamelsmu it is found by googling. I want to check the model provided by FastAI and it is the second results showed.

![image](https://user-images.githubusercontent.com/1913891/91537313-b297dc00-e8db-11ea-861e-616dde7857b4.png)
",hi found want check model provided second image,issue,negative,neutral,neutral,neutral,neutral,neutral
682357731,I agree 100%. This was probably something I justified more in my head after spending too much time coding it. I'll try again if I come up with a cleaner solution. ,agree probably something head spending much time try come cleaner solution,issue,positive,positive,positive,positive,positive,positive
682243550,"You should revert the capitalization to `XResNet`, since `ResNet` is how it's spelled in PyTorch.

Why move from using `__init__` to a class method? (In general, we should aim to make most things available through `__init__`, because that's the usual expected way to construct an object, and it's less verbose - but I'm open to using a class method if there's big enough benefits)",revert capitalization since move class method general aim make available usual way construct object le verbose open class method big enough,issue,negative,positive,neutral,neutral,positive,positive
682223419,"Well, they're not as intended, but it is intended that I fix nbdev to make them correct! :)",well intended intended fix make correct,issue,negative,neutral,neutral,neutral,neutral,neutral
682156852,"oh snap, i just realized that these links might be as intended (see issue #2652 )",oh snap link might intended see issue,issue,negative,neutral,neutral,neutral,neutral,neutral
682148356,"It seems that a lot of time is spent on fastai2 these days. But if I'm not mistaken the same bug is in fastai2 too.

In fact the examples in my gist are correct - maybe they are too much simplified. I could actually make them more understandable if that helps.

So I'm wondering if this bug will be reopened or if it would be better to create a pull request?",lot time spent day mistaken bug fact gist correct maybe much simplified could actually make understandable wondering bug would better create pull request,issue,negative,positive,positive,positive,positive,positive
681141527,"Appreciate all that you do Jeremy!

On Wed, Aug 26, 2020 at 2:51 PM Jeremy Howard <notifications@github.com>
wrote:

> Many thanks - fixed.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2685#issuecomment-681059817>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AP3QILKA2O5GHY6M3QN3OWTSCVKSVANCNFSM4QK73P6Q>
> .
>
",appreciate wed wrote many thanks fixed thread reply directly view,issue,positive,positive,positive,positive,positive,positive
681062894,"Seems to be a colab bug, so I'll close this. But if you find a workaround for it, do let me know!",bug close find let know,issue,negative,neutral,neutral,neutral,neutral,neutral
681059199,"OK I think this should be fixed now, without needing to run `make docs`.",think fixed without needing run make,issue,negative,positive,neutral,neutral,positive,positive
681054180,Better fix is to first run `make docs`. ,better fix first run make,issue,negative,positive,positive,positive,positive,positive
681044156,"@prairie-guy some digging resulted in that it should point to here: https://docs.fast.ai/dev/, however here the `.md`'s still won't show",digging point however still wo show,issue,negative,neutral,neutral,neutral,neutral,neutral
681000987,"No we can't really do it like this, with hard-coded callback names and other hacks. We need to come up with a flexible decoupled API. Feel free to create an issue explaining exactly what you're looking for, with some examples, and we can always get to it once we look at new features.",ca really like need come flexible feel free create issue explaining exactly looking always get look new,issue,positive,positive,positive,positive,positive,positive
680994845,"(Don't merge yet, tabular's `predict` fails, looking into it)",merge yet tabular predict looking,issue,negative,neutral,neutral,neutral,neutral,neutral
680906795,"Thanks main reason I thought of this is there are (broken) links to this
page from the Contributing guide and I think from some places in the README

On Wed, Aug 26, 2020 at 6:22 AM Jeremy Howard <notifications@github.com>
wrote:

>
>
> OK I've added the links from that page to the sidebar. Some are a bit out
> of date and many are overly verbose though.
>
>
>
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2688#issuecomment-680875896>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AALKJESVIE36XENYCWC5MKTSCUD77ANCNFSM4QLEYKSA>
> .
>
>
>
",thanks main reason thought broken link page guide think wed wrote added link page bit date many overly verbose though thread reply directly view,issue,negative,positive,positive,positive,positive,positive
680905364,"sorry, need to fix one thing still",sorry need fix one thing still,issue,negative,negative,negative,negative,negative,negative
680875896,OK I've added the links from that page to the sidebar. Some are a bit out of date and many are overly verbose though.,added link page bit date many overly verbose though,issue,negative,positive,positive,positive,positive,positive
680861294,"I'm not sure if any of those links are actually useful, and/or up to date. They're from fastai1. Maybe you can take a look and see if any are helpful? If so, we should include the helpful ones directly, after ensuring they're up to date.",sure link actually useful date maybe take look see helpful include helpful directly date,issue,positive,positive,positive,positive,positive,positive
680860815,Oh sorry ignore me. That link is to something else. I'll respond to your issue.,oh sorry ignore link something else respond issue,issue,negative,negative,negative,negative,negative,negative
680859456,"Many thanks! No need to do anything to build docs - as from yesterday, it's all done automatically by `docs.yml` GH workflow.",many thanks need anything build yesterday done automatically,issue,negative,positive,positive,positive,positive,positive
680859034,"Many thanks - this is very helpful. I've fixed it ( believe) in a more general way:
https://github.com/fastai/fastai/commit/2c18fe5e03a8628625b436b7141313674c6d73d0",many thanks helpful fixed believe general way,issue,positive,positive,positive,positive,positive,positive
680635910,">  and it is my understanding that this qualifies as a bug and not a faulty keyboard actuator.

Blocked and reported for abuse.",understanding bug faulty keyboard actuator blocked abuse,issue,negative,neutral,neutral,neutral,neutral,neutral
680410288,"Something like this is what I am trying to avoid: 
``` 
m = xresnet34()
m = nn.Sequential(*list(m.children())[:-2])
```
Instead I want to be able to do this: 
```
m = xresnet34()[:-2]
```",something like trying avoid list instead want able,issue,negative,positive,positive,positive,positive,positive
680323897,"It's in the site below. The source code for class Dataloader.
https://docs.fast.ai/data.load#DataLoader

On Tue, Aug 25, 2020 at 7:43 PM Ishan Dahal <ishan.dahal88@gmail.com> wrote:

> Hey Jeremy,
> Great to hear from you.
> I was browsing the website to understand different class and functions and
> came across it.
>
",site source code class tue wrote hey great hear browsing understand different class came across,issue,positive,positive,positive,positive,positive,positive
680322312,"Hey Jeremy,
Great to hear from you.
I was browsing the website to understand different class and functions and
came across it.
",hey great hear browsing understand different class came across,issue,positive,positive,positive,positive,positive,positive
680254661,Got it ! Closing this and will submit a new PR. Thanks,got submit new thanks,issue,negative,positive,positive,positive,positive,positive
680221566,"Great! You might want to add some prose about how the class uses `funcs_kwargs`, which means you can either subclass it, or you can pass in any callback listed in `_methods`. (I wouldn't actually say `_methods` in the prose, but provide the full list for the reader's convenience)",great might want add prose class either subclass pas listed would actually say prose provide full list reader convenience,issue,positive,positive,positive,positive,positive,positive
680220660,"@asvcode 

1. copy your notebook somewhere
2. clone this repo fresh
3. copy your notebook back
4. run the notebook, clean it, test, build lib etc. 
5. open a PR

This is because submodules can introduce confusion, best to avoid it",copy notebook somewhere clone fresh copy notebook back run notebook clean test build open introduce confusion best avoid,issue,positive,positive,positive,positive,positive,positive
680214165,"Thanks @hamelsmu, I've tried numerous things to try to resolve the conflicts and I just cannot seem to get them to work.  I made the error of including docs in the commit and I have tried to revert the commit `git revert bf78838` and I get the following error:

```
error: could not revert bf78838... added export
hint: after resolving the conflicts, mark the corrected paths
hint: with 'git add <paths>' or 'git rm <paths>'
hint: and commit the result with 'git commit'
```

I then tried `git rm docs ` and that messed up the notebook so I had to re-do it.  The docs files requires write access so I have been trying to just remove this file from the commit but so far have been unable to.

Would appreciate any help on this.  Thanks",thanks tried numerous try resolve seem get work made error commit tried revert commit git revert get following error error could revert added export hint mark corrected hint add hint commit result tried git notebook write access trying remove file commit far unable would appreciate help thanks,issue,positive,positive,neutral,neutral,positive,positive
680207828,"@KushajveerSingh sorry for all the changes introducing conflicts. I was removing the docs submodule. All done now. Should be safe to submit your PR, assuming all goes well!",sorry removing done safe submit assuming go well,issue,positive,neutral,neutral,neutral,neutral,neutral
680199110,I couldn't find a cleaner way to filter runs than this,could find cleaner way filter,issue,negative,neutral,neutral,neutral,neutral,neutral
680182189,"OK, my fear materialized:

Mind my ugly `print` for debugging:
```
#export
@log_args(but_as=TfmdDL.__init__)
@delegates()
class WeightedDL(TfmdDL):
    def __init__(self, dataset=None, bs=None, wgts=None, **kwargs):
        super().__init__(dataset=dataset, bs=bs, **kwargs)
        wgts = array([1.]*len(dataset) if wgts is None else wgts)
        self.wgts = wgts/wgts.sum()

    def get_idxs(self):
        if self.n==0: return []
        if not self.shuffle: return super().get_idxs()
        r = list(np.random.choice(self.n, self.n, p=self.wgts))
        print(f""{os.getpid()} => {r}"")
        return r
```
```
list(WeightedDL(list(range(50)),wgts=[1] * 50,bs=32,shuffle=True,num_workers=3))
```
As pointed out `get_idxs` gets executed in each subprocesses, and yields different indexes for each subprocess:
```
116188 => [25, 39, 49, 35, 27, 47, 14, 31, 45, 47, 43, 3, 41, 22, 19, 28, 49, 31, 21, 31, 23, 47, 38, 27, 31, 46, 36, 12, 28, 5, 16, 7, 22, 33, 3, 21, 34, 13, 41, 0, 40, 7, 14, 3, 13, 49, 6, 4, 15, 42]
116191 => [37, 10, 2, 38, 33, 32, 40, 29, 10, 13, 24, 42, 11, 40, 39, 27, 24, 8, 21, 19, 4, 34, 12, 45, 33, 46, 5, 32, 36, 31, 20, 9, 35, 2, 15, 21, 17, 36, 48, 43, 48, 15, 25, 6, 8, 37, 11, 17, 37, 8]
116196 => [14, 46, 33, 42, 3, 9, 45, 17, 27, 30, 23, 19, 43, 37, 21, 12, 10, 38, 16, 11, 31, 6, 40, 8, 9, 37, 8, 14, 38, 21, 43, 6, 24, 34, 45, 46, 24, 49, 45, 38, 39, 11, 13, 23, 20, 33, 3, 8, 16, 18]
```
...which is essentially the inconsistencies pytorch documentation warns you against when using `seed`. 

The reason why this happens is:
a) `get_idxs` did not use `self.rng`
b) `get_idxs` is a called in the context of _each_ subprocess.

I'm going to submit a PR to fix this. I do not think it is realistic to impose such a low-level and subtle detail to `get_idxs`.
",fear mind ugly print export class self super array none else self return return super list print return list list range pointed executed different essentially documentation seed reason use context going submit fix think realistic impose subtle detail,issue,negative,negative,neutral,neutral,negative,negative
680163068,"Yeah it's complex code, because the PyTorch DataLoader foundations are not at all well decoupled, so trying to use them externally is a big ugly hack :( ",yeah complex code well trying use externally big ugly hack,issue,negative,negative,negative,negative,negative,negative
680161920,"@jph00 Thanks for the pointer. I realized what I was missing. Each worker contains the information of the `DataLoader`. Simple things that don't point out, when you don't know stuff. ",thanks pointer missing worker information simple point know stuff,issue,negative,neutral,neutral,neutral,neutral,neutral
680159996,"
> Thanks @antorsae <https://github.com/antorsae> for that explanation. I just have one more question regarding fastai implementation of `DataLoader`. `DataLoader` does not use `wif`. `_FakeLoader` calls `_wif`, which sets the worker info that you mentioned in your previous message. But the `wif` function passed in `DataLoader` is not used in the code or is passed to `_FakeLoader`, so how is it happening in this case? (Am I still missing something?)


It's called in the line `ds.wif()`, which is park of `FakeLoader`.
",thanks explanation one question regarding implementation use worker previous message function used code happening case still missing something line park,issue,negative,negative,neutral,neutral,negative,negative
680156638,"
> A lot of care must be put when shuffling/sampling b/c behavior may silently break if not careful. I am going to check if `WeightedDL` is OK or not.


By the way I'm not sure anyone has actually looked carefully at my DataLoader code before, so if you think of any approaches that might make things simpler and more reliable, do say so! I'm not happy with how subtle things are right now. The user API for sampling really needs to be improved so that users don't need to know or care about this inner details.
",lot care must put behavior may silently break careful going check way sure anyone actually carefully code think might make simpler reliable say happy subtle right user sampling really need need know care inner,issue,positive,positive,positive,positive,positive,positive
680155569,"On Tue, Aug 25, 2020, at 9:51 AM, antorsae wrote:
> `wif` is an abbreviation for `worker_initialization_fn` (yes I know what you're thinking, wlcme to fstai)


We should at least document that abbreviation. If we wanted to use a longer name, I'd go with ``worker_init_func`, since `init` is a well known abbrev, and `fn` is ambiguous (we normally use it for `filename` and not `function`).`
",tue wrote abbreviation yes know thinking least document abbreviation use longer name go since well known ambiguous normally use function,issue,positive,negative,neutral,neutral,negative,negative
680154940,"> Some of those should be in markdown prose, not in docstrings, since docstrings should be just a brief sentence on one line in fast.ai libs.

Had started working on this. I realized the better approach later.

Thanks @antorsae for that explanation. I just have one more question regarding fastai implementation of `DataLoader`. `DataLoader` does not use `wif`. `_FakeLoader` calls `_wif`, which sets the worker info that you mentioned in your previous message. But the `wif` function passed in `DataLoader` is not used in the code or is passed to `_FakeLoader`, so how is it happening in this case? (Am I still missing something?)",markdown prose since brief sentence one line working better approach later thanks explanation one question regarding implementation use worker previous message function used code happening case still missing something,issue,positive,positive,neutral,neutral,positive,positive
680144813,"`wif` is an abbreviation for `worker_initialization_fn` (yes I know what you're thinking, wlcme to fstai)

This is all internal stuff inspired by pytorch multiprocessing; some background: https://pytorch.org/docs/stable/data.html#single-and-multi-process-data-loading.

I correct what I said about ""care must be taken to use python's random functionality (vs numpy or pytorch's) due to the way random seeds are sync'd between subprocesses inside _FakeLoader.""; what happens is:

a) when/if subprocesses are created (in `_FakeLoader`) each subprocess has its own different seed, which gets initialized via `set_seed(...)`:

```
def _wif(worker_id):
    set_num_threads(1)
    info = get_worker_info()
    ds = info.dataset.d
    ds.nw,ds.offs = info.num_workers,info.id
    set_seed(info.seed)
    ds.wif()
```

note that that `info.seed` is actually different for each worker/subprocess, so each subprocesses cannot shuffle the indexes carelessly b/c that would result in duplicated items; so:

b) fastai `DataLoader` has a `self.rng` random number generator initialized and maintained in the main process. calls to `self.randomize()` which happens in the main process refresh this random number generator, e.g. as DL is read/iterated.

c) when/if subprocesses are created inside `__iter__` in the main process `self.rng` is copied to forked subprocesses, which may call `shuffle_fn` which uses that consistent random number generator which is the same across subprocesses; hence rendering consistent behavior.

A lot of care must be put when shuffling/sampling b/c behavior may silently break if not careful (e.g. if you did not use `self.rng` for shuffling). I am going to check whether `WeightedDL` is OK or not.",abbreviation yes know thinking internal stuff inspired background correct said care must taken use python random functionality due way random sync inside different seed via note actually different shuffle carelessly would result random number generator main process main process refresh random number generator inside main process copied forked may call consistent random number generator across hence rendering consistent behavior lot care must put behavior may silently break careful use shuffling going check whether,issue,positive,negative,negative,negative,negative,negative
680144150,"Good points from @antorsae . Some of those should be in markdown prose, not in docstrings, since docstrings should be just a brief sentence on one line in fast.ai libs.",good markdown prose since brief sentence one line,issue,negative,positive,positive,positive,positive,positive
680118533,"> Use `from fastai.text.all import *` to import `AWD_LSTM`. Then you can use `language_model_learner(dls, AWD_LSTM)`.

When I did **from fastai.text.all import AWD_LSTM** I got this error:
```
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-17-74c956224b63> in <module>
      4 import fastai
      5 import fastai.text
----> 6 from fastai.text.all import AWD_LSTM
      7 
      8 from sklearn.linear_model import LogisticRegression

ModuleNotFoundError: No module named 'fastai.text.all'
```",use import import use import got error recent call last module import import import import module,issue,negative,neutral,neutral,neutral,neutral,neutral
680107959,"> care must be taken to use python's random functionality (vs numpy or pytorch's) due to the way random seeds are sync'd between subprocesses inside _FakeLoader.

@antorsae Didn't know that. Is it a pytorch internal thing? Can you guide me on how you know about this thing?

Also, do you know what is the use of `wif` method. I am not able to find a link on its usage.

",care must taken use python random functionality due way random sync inside know internal thing guide know thing also know use method able find link usage,issue,negative,negative,negative,negative,negative,negative
680087307,"We should try to fix nbdev so that the right links are shown rather than referencing the absolute URLS as I attempted to do in #2680  

cc: @jph00 ",try fix right link shown rather absolute,issue,negative,positive,positive,positive,positive,positive
680080360,"A few comments:

> shuffle (bool): If `True`, then data is shuffled after every epoch.
Instead of every epoch, I'd say every time dataloader is fully read/iterated.

> get_idxs = Returns a list of indices to be used in the next epoch. If `shuffle=True`, then the indices are passed to `shuffle_fn` which returns shuffled indices. In case of iterable-style dataset, it returns a list of `[None]*n`.
Returns a list of indices to reference the dataset. It is responsible of calling `shuffle_fn` internally if `shuffle=True`. 

> shuffle_fn = Returns a random permutation of `idxs`. `idxs` is a list of items (can be indices, or anything).
care must be taken to use python's `random` functionality (vs numpy or pytorch's) due to the way random seeds are sync'd between subprocesses inside `_FakeLoader`. 
",shuffle bool true data every epoch instead every epoch say every time fully list index used next epoch index index case list none list index reference responsible calling internally random permutation list index anything care must taken use python random functionality due way random sync inside,issue,positive,negative,negative,negative,negative,negative
680058733,I guess we should fix nbdev?  At least that sounds like the right answer,guess fix least like right answer,issue,negative,negative,neutral,neutral,negative,negative
680056235,Ok the reason I was led astray is that everything shows up correctly for `help(cls)` and `?cls` but oddly not for tab completion!   ,reason led astray everything correctly help oddly tab completion,issue,negative,negative,negative,negative,negative,negative
680052087,"@Trento89 I looked at your notebook and It appears this issue is concerning fastaiv1 - I think this issue should be transferred there. 

~I'll go ahead and transfer this there~.  Nevermind
cc: @jph00 ",notebook issue concerning think issue transferred go ahead transfer,issue,negative,neutral,neutral,neutral,neutral,neutral
680049186,"Looks like this was the case for previous versions as well, which is very very strange. I would have expected it to show `PILImage` here. So perhaps it's just a bug bug. The issue is the class signature shows:
```python
def ImageBlock(cls=PILImage):
```

If I had to guess it's taking the metaclass from `PILBase` for the type hinting rather than the super class that's inheriting it, not sure 100% how to fix that",like case previous well strange would show perhaps bug bug issue class signature python guess taking type rather super class sure fix,issue,positive,positive,positive,positive,positive,positive
680046392,"@hamelsmu problem still persists. Just built with dev, see the attached screenshot:

![image](https://user-images.githubusercontent.com/7831895/91184326-82bdbe00-e6ba-11ea-9dff-4b0dae89f4d9.png)
",problem still built dev see attached image,issue,negative,neutral,neutral,neutral,neutral,neutral
680044317,"I can confirm that this is no longer the case in the latest fastai

I get this when doing help(ImageBlock)


![image](https://user-images.githubusercontent.com/1483922/91183005-c8b95880-e69f-11ea-8c09-f84c237c3b26.png)

![image](https://user-images.githubusercontent.com/1483922/91183082-e25aa000-e69f-11ea-9d60-d03e1b5ad610.png)

I was also able to verify this in a Colab notebook https://colab.research.google.com/drive/1DSqxFCN3i7rnpZjHuRPgDN9zkpsOUNpK?usp=sharing

I'll go ahead and close this 

",confirm longer case latest get help image image also able verify notebook go ahead close,issue,negative,positive,positive,positive,positive,positive
680041249,"We actually need to strip the outputs and non-markdown non-heading cells for this, and commit that to `clean` folder. I'll work on it.",actually need strip commit clean folder work,issue,positive,positive,positive,positive,positive,positive
680040526,"Thanks Hamel! Do you think it's better to fix it this way, or should we fix nbdev to generate the links correctly in the readme?",thanks hamel think better fix way fix generate link correctly,issue,positive,positive,positive,positive,positive,positive
679873786,"Current idea is something like this: 
```
    def __getitem__(self,idx):
        cls=self.__class__
        cast(self,nn.Sequential)
        items=self[idx]
        cast(self,cls)
        return cast(items,cls)
```
Just don't like all of the casts to get it to work. ",current idea something like self cast self cast self return cast like get work,issue,positive,neutral,neutral,neutral,neutral,neutral
679837353,"Ideas for ""fixes""

1. override __getitem__ to include casting to nn.Sequential and back to take advantage of nn.Sequential.__getitem__
2. Change the initializer to also handle OrderedDict
3. Completely rewrite __getitem__

Still trying to find something cleaner, not happy with any of these solutions as the moment. ",override include casting back take advantage change also handle completely rewrite still trying find something cleaner happy moment,issue,positive,positive,positive,positive,positive,positive
679641869,"As Jeremy recommended, this is not a bug in the library. Please post on the forums for help with this issue. (And in general it’s best practice to do so then open an issue if it still can’t be resolved) ",bug library please post help issue general best practice open issue still resolved,issue,positive,positive,positive,positive,positive,positive
679636016,"> We need much more information in regards to this, what code were you using? What are all the library versions exactly? What imports did you call?

Kindly find the response inline:
from fastai import *
from fastai.vision import *
from fastai.vision import image
model = load_learner(""./weights/"",'mobilenetv2_8epochs_best.pkl')

Was getting NameError: name 'load_learner' is not defined
fast ai version 2.0 
fast ai version 1.6 it is working fine..",need much information code library exactly call kindly find response import import import image model getting name defined fast ai version fast ai version working fine,issue,positive,positive,positive,positive,positive,positive
679560810,"Hi Jeremy, I updated the notebook and added #export to the cell and added a short markdown.  Hope this is acceptable now.",hi notebook added export cell added short markdown hope acceptable,issue,positive,neutral,neutral,neutral,neutral,neutral
679427986,"Thanks for this! Take a look at the docs for any of the other classes, such as `L` in `fastcore`, to see how things should look. Each method name and its docstring needs to fit on one line. (Also there's some conflicts to resolve)",thanks take look class see look method name need fit one line also resolve,issue,positive,positive,positive,positive,positive,positive
679374610,"we're moving some servers. if it's still not working in 48 hours for you, let us konw.",moving still working let u,issue,negative,neutral,neutral,neutral,neutral,neutral
679363808,"Hi Jeremy,

I believe we are talking about fastai/data/load.py. Is that correct?
 Also, your last commit removed a line of documentation from above file and the corresponding notebook as well. Was that documentation redundant?

Thanks",hi believe talking correct also last commit removed line documentation file corresponding notebook well documentation redundant thanks,issue,positive,neutral,neutral,neutral,neutral,neutral
679335311,"I should add that this is the only dataset that is not working for me.  CIFAR_100, MNIST, PETS... all others work normally.",add working work normally,issue,negative,positive,positive,positive,positive,positive
679292258,`path = untar_data(URLs.CIFAR)` is working for me. I am using the master version of fastai.,path working master version,issue,negative,neutral,neutral,neutral,neutral,neutral
679291452,"Use `from fastai.text.all import *` to import `AWD_LSTM`. Then you can use `language_model_learner(dls, AWD_LSTM)`.",use import import use,issue,negative,neutral,neutral,neutral,neutral,neutral
679164820,"What looks to be happening is you trained on the dev version of fastai2, hence why the pickle is looking for `Tuple`. You can try @riven314's suggestion and then re-export your model. (I would personally recommend loading the model in, saving the weights via `learn.save()`, then update the library, rebuild `DataLoaders`, load your model in then export. ",happening trained dev version hence pickle looking try riven suggestion model would personally recommend loading model saving via update library rebuild load model export,issue,negative,neutral,neutral,neutral,neutral,neutral
679163804,"We need much more information in regards to this, what code were you using? What are all the library versions exactly? What imports did you call?",need much information code library exactly call,issue,negative,positive,positive,positive,positive,positive
679144569,"According to [this fastcore commit](https://github.com/fastai/fastcore/commit/4b2023783c2c58715fe501c381bc255e45dfba1a#diff-2d5ca7a202ff50e2df29f58cfa4a4c12), `Tuple` has been recently renamed as `fastuple`. 
Try install the latest version of fastai and fastcore, and then run again",according commit recently try install latest version run,issue,negative,positive,positive,positive,positive,positive
679074873,"Unfortunately colab doesn't run ""real"" juptyer, so some things just don't work.",unfortunately run real work,issue,negative,negative,negative,negative,negative,negative
679054412,"Im going to submit a PR about https://github.com/fastai/fastai/issues/2637 and indirectly touches some of the assumptions/conventions made by `DataLoader`. Some comments/questions:

1. `get_idxs` is executed in the context of `_FakeLoader` b/c is executed at the beginning of `sample()`. This means that each worker will execute `get_idxs`. Is that intentional? Wouldn't it be better to have something like:

```
   def sample(self):
        return (b for i,b in enumerate(self._idxs) if i//(self.bs or 1)%self.nw==self.offs)

    def __iter__(self):
        self.randomize()
        self.before_iter()
        self._idxs=self.get_idxs()
        for b in _loaders[self.fake_l.num_workers==0](self.fake_l):
            if self.device is not None: b = to_device(b, self.device)
            yield self.after_batch(b)
        self.after_iter()
        if hasattr(self, 'it'): delattr(self, 'it')
```
so that `get_idxs` gets executed only once in the context of the main process?

2. What are the minimum assumptions about `DataLoader`? Pytorch's `DataLoader` has a clear set of assumptions, but with `DataLoader` I'm not sure. The most notorious one is `n`, one example:

```
    class RepeatedDL(TfmdDL):
    def __init__(self,dl,repeats,num_workers=None):
        repeats=max(repeats,1)
        if num_workers is None: num_workers = min(16, defaults.cpus)
        super().__init__(dataset=dl.dataset,bs=dl.bs,num_workers=num_workers,pin_memory=dl.pin_memory,timeout=dl.timeout,
                        shuffle=dl.shuffle,drop_last=dl.drop_last,indexed=dl.indexed,n=dl.n,device=dl.device,
                        after_batch=dl.after_batch)
        store_attr(self, 'dl,repeats')

    def get_idxs(self): return np.repeat(self.dl.get_idxs(),self.repeats).tolist()
    def __len__(self): return len(self.dl) * self.repeats
```
The purpose of `RepeatedDL` is take an existing `DataLoader` and just repeat items, e.g.  0 0 0 1 1 1 2 2 2 (if repeats=3). This may be useful for TTA so you can also see w/ `show_batch` how different augmentations look like. `RepeatedDL` purposedly decides to keep `dl.n` the same and just modifies `__len__` and `get_idxs`. `get_idxs` returns more items than `self.n`; and the assumption I made is to treat  `self.n` as if it was private to the original `dl` making no assumptions about its use; but other people may make different assumptions about relation between `self.n` and `get_idxs` and `__len__`.",going submit indirectly made executed context executed beginning sample worker execute intentional would better something like sample self return enumerate self none yield self self executed context main process minimum clear set sure notorious one one example class self none min super self self return self return purpose take repeat may useful also see different look like purposedly keep assumption made treat private original making use people may make different relation,issue,positive,positive,positive,positive,positive,positive
678804442,"> Also, less impactful but the validation metrics are still not perfect b/c the DDP wrapping DL DistributedDL pads batches to be evenly divisible

Could you please create a new issue for this?",also le validation metric still perfect wrapping evenly divisible could please create new issue,issue,positive,positive,positive,positive,positive,positive
678803266,Thanks. The readme is actually auto-generated from index.ipynb so we need to fix it there.,thanks actually need fix,issue,negative,positive,neutral,neutral,positive,positive
678692332,"Here's a solution for anyone else who wants to go through with wiped outputs;

```py
!pip install nbstripout==0.3.7 -q

files_in_directory = !ls
notebooks_in_directory = list(filter(lambda file: file.endswith("".ipynb""), files_in_directory))

!nbstripout {"" "".join(notebooks_in_directory)}
```

Copy it into a cell, run it, then shutdown that notebook, close it, and open it again - the outputs should be cleared.",solution anyone else go pip install list filter lambda file copy cell run shutdown notebook close open,issue,negative,neutral,neutral,neutral,neutral,neutral
678689446,"Also just to clarify; I know those are displaying the data outputs, but there is still pre-displayed model outputs in other locations, the images are just examples of what I mean.",also clarify know data still model mean,issue,negative,negative,negative,negative,negative,negative
678683001,"I removed the call to XGBoost etc from there as bits were failing and while i could put it under #test or something, considering XGBoost isn’t in the library i didn’t want to risk it. So now it just describes what to grab in a way familiar to those why use it. ",removed call failing could put test something considering library want risk grab way familiar use,issue,negative,positive,positive,positive,positive,positive
678681383,Did you use some spell checking tool for all these fixes? I'm looking for a way to do this quickly also.,use spell tool looking way quickly also,issue,negative,positive,positive,positive,positive,positive
678630561,"I think the links are supposed to redirect to:
- https://docs.fast.ai/quick_start
- https://docs.fast.ai/tutorial
- https://docs.fast.ai/migrating_pytorch
- https://docs.fast.ai/migrating_ignite
- https://docs.fast.ai/migrating_lightning
- https://docs.fast.ai/migrating_catalyst

Edit: Found some more broken links in [contributing](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md):
- https://docs.fast.ai/dev/style.html --> https://docs.fast.ai/style.html (occurs multiple times)
- https://docs.fast.ai/dev/develop.html --> ? (occurs multiple times)
- https://github.com/fastai/fastai/blob/master/tests/test_core.py --> https://github.com/fastai/fastai1/blob/master/tests/test_core.py (occurs multiple times)
- https://docs.fast.ai/dev/test.html --> https://docs.fast.ai/test.html (occurs multiple times)
- https://docs.fast.ai/dev/abbr.html --> ? (occurs multiple times)
",think link supposed redirect edit found broken link multiple time multiple time multiple time multiple time multiple time,issue,negative,negative,neutral,neutral,negative,negative
678610413,`pip install fastai --upgrade` resolves this issue,pip install upgrade issue,issue,negative,neutral,neutral,neutral,neutral,neutral
678544708,The (easier) option is `pip install fastai —upgrade`. ,easier option pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
678326592,"Note that users of google colab will get this error, presumably this will be resolved when pypi points to v2. In the meantime I just ran:
```
!git clone --recurse-submodules https://github.com/fastai/fastai
!pip install -e ""fastai[dev]""
```
And restarted the runtime",note get error presumably resolved ran git clone pip install dev,issue,negative,neutral,neutral,neutral,neutral,neutral
678160233,"No, the notebooks have been updated to reflect the pip version releasing later today. Until that moment please use `from fastai2.x` rather than `fastai`.",reflect pip version later today moment please use rather,issue,negative,neutral,neutral,neutral,neutral,neutral
678115812,"@Ayush-Parhi  I know, that's why I think that the tutorial is outdated. However, I wanted to use the ""ImageDataLoaders"" from the tutorial, but this class in not present in ""fastai.vision""..
",know think tutorial outdated however use tutorial class present,issue,negative,negative,negative,negative,negative,negative
678020384,@jph00 CI has been switched to the new containers pointing at `fastai` instead of `fastai2`,switched new pointing instead,issue,negative,positive,positive,positive,positive,positive
678004101,I'll change it locally since we have a conflict.,change locally since conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
677731733,"I think I reported this in error. `to_detach(...)` gave me an error when in DDP inside `AccumMetric` so I mistakenly did `.detach().cpu()` which disabled the offending code bit that gave the error:

`torch.distributed.all_gather(res, x if ndim > 0 else x[None])`

but it is needed in DDP mode.

Now that I understand all this a bit better I've change all gather to make `x` contiguous and it works.

I am hesitant to do a PR b/c it is 1 line change in https://github.com/fastai/fastai/blob/master/nbs/03_data.core.ipynb but I don't know how to do proper test case for this:

```
#export
def maybe_gather(x, axis=0):
    ""Gather copies of `x` on `axis` (if training is distributed)""
    if num_distrib()<=1: return x
    ndim = x.ndim
    res = [x.new_zeros(*x.shape if ndim > 0 else (1,)) for _ in range(num_distrib())]
    torch.distributed.all_gather(res, x.contiguous() if ndim > 0 else x[None])
    return torch.cat(res, dim=axis) if ndim > 0 else torch.cat(res, dim=axis).mean()
```

Also, less impactful but the validation metrics are still not perfect b/c the DDP wrapping DL `DistributedDL` pads batches to be evenly divisible:

```
    def sample(self):
        idxs = self.get_idxs()
        if self.shuffle: idxs = self.shuffle_fn(idxs)
        # add extra samples to make it evenly divisible
        idxs += idxs[:(self.total_n - len(idxs))]
        # subsample
        idxs = idxs[self.rank:self.total_n:self.world_size]
        return (b for i,b in enumerate(idxs) if i//(self.bs or 1)%self.nw==self.offs)
```

and this is not accounted for (as far as I can see) anywhere else.",think error gave error inside mistakenly disabled code bit gave error else none mode understand bit better change gather make contiguous work hesitant line change know proper test case export gather axis training distributed return else range else none return else also le validation metric still perfect wrapping evenly divisible sample self add extra make evenly divisible subsample return enumerate far see anywhere else,issue,negative,positive,positive,positive,positive,positive
676858531,"This is the first time I have ever written docs, so I am looking forward to learning. ",first time ever written looking forward learning,issue,negative,positive,positive,positive,positive,positive
676856297,"Look like boris may have fixed the error here: https://github.com/fastai/fastai/pull/2641/commits/9deaf73354001f716b36890003c16b42570870f4

I'll watch that for updates. ",look like may fixed error watch,issue,negative,positive,neutral,neutral,positive,positive
676850799,Seems we are getting the same error in 'CI / test-nbdev-sync (pull_request) '. If you figure out what is causing it I would like to know too. I'm on discord. ,getting error figure causing would like know discord,issue,negative,neutral,neutral,neutral,neutral,neutral
676847910,"The error in CI / test-nbdev-sync (pull_request)  happened in my local too, but I thought it was just something broken with my local setup. Currently trying to diagnose what is causing this issue. ",error local thought something broken local setup currently trying diagnose causing issue,issue,negative,negative,neutral,neutral,negative,negative
676603751,"same issue trying to run python train.py

```python
from fastai2.vision.allimport *
 
path = untar_data(URLs.PETS)
path.ls()
 
files = get_image_files(path/""images"")
len(files)
 
def label_func(f): return f[0].isupper()
 
dls = ImageDataLoaders.from_name_func(path, files, label_func, item_tfms=Resize(224))
 
dls.show_batch()
 
learn = cnn_learner(dls, resnet34, metrics=error_rate)
learn.fine_tune(1)
```

Traceback (most recent call last):
  File ""train.py"", line 2, in <module>
    from fastai2.vision.all import *
  File ""/opt/conda/lib/python3.7/site-packages/fastai2/vision/all.py"", line 1, in <module>
    from ..basics import *
  File ""/opt/conda/lib/python3.7/site-packages/fastai2/basics.py"", line 1, in <module>
    from .data.all import *
  File ""/opt/conda/lib/python3.7/site-packages/fastai2/data/all.py"", line 1, in <module>
    from ..torch_basics import *
  File ""/opt/conda/lib/python3.7/site-packages/fastai2/torch_basics.py"", line 2, in <module>
    from .imports import *
  File ""/opt/conda/lib/python3.7/site-packages/fastai2/imports.py"", line 29, in <module>
    from fastcore.all import *
  File ""/opt/conda/lib/python3.7/site-packages/fastcore/all.py"", line 3, in <module>
    from .dispatch import *
  File ""/opt/conda/lib/python3.7/site-packages/fastcore/dispatch.py"", line 9, in <module>
    from .utils import *
  File ""/opt/conda/lib/python3.7/site-packages/fastcore/utils.py"", line 782, in <module>
    IN_IPYTHON,IN_JUPYTER,IN_COLAB,IN_NOTEBOOK = in_ipython(),in_jupyter(),in_colab(),in_notebook()
  File ""/opt/conda/lib/python3.7/site-packages/fastcore/utils.py"", line 774, in in_jupyter
    return get_ipython().__class__.__name__ == 'ZMQInteractiveShell'
NameError: name 'get_ipython' is not defined",issue trying run python python path return path learn recent call last file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module import file line module file line return name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
676529178,I'm planning to thoroughly look at sampler next week - in particular to see if we can avoid the slowness on Windows.,thoroughly look sampler next week particular see avoid,issue,negative,positive,neutral,neutral,positive,positive
676528825,I'll try to look at this next week - feel free to do a PR in the meantime if you're interested.,try look next week feel free interested,issue,positive,positive,positive,positive,positive,positive
676483729,"@jph00 sorry just pinging you on this one because it introduces some breaking changes on `log_dataset` that would be nice to get done before the release if you have a chance

I'll do some performance improvements later but it's not as critical",sorry one breaking would nice get done release chance performance later critical,issue,negative,positive,neutral,neutral,positive,positive
675682313,"Here is my proposed modification to make it work as I described: 

```
#export
def add_datepart(df, field_name, prefix=None, drop=True, time=False):
    ""Helper function that adds columns relevant to a date in the column `field_name` of `df`.""
    make_date(df, field_name)
    field = df[field_name]
    prefix = ifnone(prefix, re.sub('[Dd]ate$', '', field_name))
    attr = ['Year', 'Month', 'Week', 'Day', 'Dayofweek', 'Dayofyear', 'Is_month_end', 'Is_month_start',
            'Is_quarter_end', 'Is_quarter_start', 'Is_year_end', 'Is_year_start']
    if time: attr = attr + ['Hour', 'Minute', 'Second']
    for n in attr: df[prefix + n] = getattr(field.dt, n.lower())
    mask = ~field.isna()
    df[prefix + 'Elapsed'] = np.where(mask,field.values.astype(np.int64) // 10 ** 9,None)
    if drop: df.drop(field_name, axis=1, inplace=True)
    return df
```

The key here is checking if the date column has any fields that are na and then using np.where to only evaluate the dates and to set the value to None otherwise.  ",modification make work export helper function relevant date column field prefix prefix ate time prefix mask prefix mask none drop return key date column na evaluate set value none otherwise,issue,positive,positive,positive,positive,positive,positive
675230263,You need to either pass `ordered=False` to `get_preds` or (more commonly) use `DatasetType.Fix`,need either pas commonly use,issue,negative,negative,negative,negative,negative,negative
675229073,"Turns out it's not a bug, just a missing feature. Bounding boxes are clamped, but TensorPoints aren't. Will consider adding that feature later.",turn bug missing feature bounding consider feature later,issue,negative,negative,neutral,neutral,negative,negative
671077735,"I go to the pytorch dropout implement:
https://github.com/pytorch/pytorch/blob/5d474e1812b2343b7dc1c9561f5f154334ccae38/torch/csrc/api/src/nn/modules/dropout.cpp#L24-L34
```
Tensor DropoutImplBase<Derived>::forward(Tensor input) {
  if (options.rate_ == 0 || !this->is_training()) {
    return input;
  }

  auto scale = 1.0f / (1.0f - options.rate_);
  auto boolean_mask = noise_mask(input).uniform_(0, 1) > options.rate_;
  auto noise = boolean_mask.to(input.dtype()).mul_(scale);

  return input * noise;
}
```
It also uses a mask to implement dropout, but let ouput=input when p==0. Maybe we can write a similar function but remove `options.rate_ == 0`.",go dropout implement tensor derived tensor input return input auto scale auto input auto noise scale return input noise also mask implement dropout let maybe write similar function remove,issue,negative,neutral,neutral,neutral,neutral,neutral
671071796,"To my understanding, this F.dropout(x, p=0) thing seems a pytorch bug (or a weird feature?).
A simple fix is to apply dropout on a mask, and then multiply it to the variable which actually needs dropout:
```
def _mask_dropout(x, drop_p, training=True):
        mask = x.new_ones(x.size())
        mask = F.dropout(mask, p=drop_p, training=training)
        x = x * mask
        return x
```
This operation forces the output be always computed from the input, not give a shallow copy. The side effect is a slight increase in memory.

I don't know if there are other places have the same problem. However, if it does, this simple fix seems not so good, should we need to consider a more comprehensive plan about this?  I'm not sure about doing a PR, I might just leave it to discuss.

",understanding thing bug weird feature simple fix apply dropout mask multiply variable actually need dropout mask mask mask mask return operation output always input give shallow copy side effect slight increase memory know problem however simple fix good need consider comprehensive plan sure might leave discus,issue,positive,positive,neutral,neutral,positive,positive
671030779,"> Sorry for the delay on this one. In fastai2 can you take a look at how I've handled it in `32_text.models.awdlstm.ipynb`? When I check `named_parameters` it looks OK to me. Please let me know if you see any problems. If you think it's OK, I'd be happy to accept a PR that does something similar for fastai v1.

Thank you for your reply. I took a look at `32_text.models.awdlstm.ipynb `, I think there still be a problem.

Please try my test ipynb code:
```
#export
class WeightDropout(Module):
    ""A module that warps another layer in which some weights will be replaced by 0 during training.""

    def __init__(self, module, weight_p, layer_names='weight_hh_l0'):
        self.module,self.weight_p,self.layer_names = module,weight_p,L(layer_names)
        for layer in self.layer_names:
            #Makes a copy of the weights of the selected layers.
            w = getattr(self.module, layer)
            delattr(self.module, layer)
            self.register_parameter(f'{layer}_raw', nn.Parameter(w.data))
            setattr(self.module, layer, w.clone())
            if isinstance(self.module, (nn.RNNBase, nn.modules.rnn.RNNBase)):
                self.module.flatten_parameters = self._do_nothing

    def _setweights(self):
        ""Apply dropout to the raw weights.""
        for layer in self.layer_names:
            raw_w = getattr(self, f'{layer}_raw')
            if self.training: w = F.dropout(raw_w, p=self.weight_p)
            else: w = raw_w.clone()
            setattr(self.module, layer, w)
            
            print(""drop p:"", self.weight_p)
            print(""raw_w type, should be Parameter:"", type(getattr(self, f'{layer}_raw')))
            print(""w type, should be Tensor:"", type(getattr(self.module, f'{layer}')))
            print(""raw_w leaf, should be True:"", getattr(self, f'{layer}_raw').is_leaf)
            print(""w leaf, should be False:"", getattr(self.module, f'{layer}').is_leaf)
            print(""Is w a shallow copy of raw_w:"", id(raw_w)==id(w))


    def forward(self, *args):
        self._setweights()
        with warnings.catch_warnings():
            # To avoid the warning that comes because the weights aren't flattened.
            warnings.simplefilter(""ignore"", category=UserWarning)
            return self.module.forward(*args)

    def reset(self):
        for layer in self.layer_names:
            raw_w = getattr(self, f'{layer}_raw')
            setattr(self.module, layer, raw_w.clone())
        if hasattr(self.module, 'reset'): self.module.reset()

    def _do_nothing(self): pass

# when p is not 0
module = nn.LSTM(5,7)
dp_module = WeightDropout(module, 0.4)
wgts = dp_module.module.weight_hh_l0
tst_inp = torch.randn(10,20,5)
h = torch.zeros(1,20,7), torch.zeros(1,20,7)
dp_module.reset()
x,h = dp_module(tst_inp,h)
loss = x.sum()
loss.backward()

print('\n')

# when p is 0
module = nn.LSTM(5,7)
dp_module = WeightDropout(module, 0.0)
wgts = dp_module.module.weight_hh_l0
tst_inp = torch.randn(10,20,5)
h = torch.zeros(1,20,7), torch.zeros(1,20,7)
dp_module.reset()
x,h = dp_module(tst_inp,h)
loss = x.sum()
loss.backward()
```

Which will produce:
```
drop p: 0.4
raw_w type, should be Parameter: <class 'torch.nn.parameter.Parameter'>
w type, should be Tensor: <class 'torch.Tensor'>
raw_w leaf, should be True: True
w leaf, should be False: False
Is w a shallow copy of raw_w: False


drop p: 0.0
raw_w type, should be Parameter: <class 'torch.nn.parameter.Parameter'>
w type, should be Tensor: <class 'torch.nn.parameter.Parameter'>
raw_w leaf, should be True: True
w leaf, should be False: True
Is w a shallow copy of raw_w: True
```

As we can see, when p!=0, everything is ok. However, when p==0, something is broken.
This problem roots in F.dropout() simply pass the input as the output, as id(raw_w)==id(w). That is why I use a function _mask_dropout.",sorry delay one take look handled check please let know see think happy accept something similar thank reply took look think still problem please try test code export class module module another layer training self module module layer copy selected layer layer layer layer self apply dropout raw layer self layer else layer print drop print type parameter type self layer print type tensor type layer print leaf true self layer print leaf false layer print shallow copy id forward self avoid warning come ignore return reset self layer self layer layer self pas module module loss print module module loss produce drop type parameter class type tensor class leaf true true leaf false false shallow copy false drop type parameter class type tensor class leaf true true leaf false true shallow copy true see everything however something broken problem simply pas input output id use function,issue,positive,negative,neutral,neutral,negative,negative
670855947,"Hi Jeremy,

could you explain why you want to include ""all"" predicted ""0""s?

Sure, accuracy is basically (sum(TP) + sum(TN)) / total predictions for binary classification, but for multi-class and multi-label this way of calculating accuracy does not work anymore, mainly because we have just one ""1"" for the correct class and many ""0""s for all other classes.

So here is a simple example. Assume we have a multi-class problem with 100 distinct classes (e.g. animals, plants, cars etc.).


A minimal (validation) dataset could have 100 observations - one for each of the 100 classes:

```
y_true = torch.eye(100,100)
```

A very naiive baseline model may always predict the same class (for all of the 100 observations):

```
y_pred = torch.cat([torch.ones(100,1),     # first class always 1.0
                    torch.zeros(100,99)],  # other classes always 0.0
                   dim=1)
```

This would leave us with only **one out of 100** observations having its class predicted correctly.

And here is what we get as results from the different accuracy implementations:

1. fastai
```
accuracy_thresh(y_pred, y_true, thresh=0.5, sigmoid=False)
tensor(0.9802)
```

2. sklearn
```
from sklearn.metrics import accuracy_score
accuracy_score(y_true.numpy(), y_pred.numpy())
0.01
```

3. my proposal
```
accuracy_multi_exact(y_pred, y_true, thresh=0.5, sigmoid=False)
tensor(0.0100)
```

In fact, for 100 classes the accuracy we would get when using `accuracy_thresh` would never be lower than 98% no matter how many observations we have in the validation dataset. This does not seem right.",hi could explain want include sure accuracy basically sum sum total binary classification way calculating accuracy work mainly one correct class many class simple example assume problem distinct class minimal validation could one class model may always predict class first class always class always would leave u one class correctly get different accuracy tensor import proposal tensor fact class accuracy would get would never lower matter many validation seem right,issue,negative,positive,positive,positive,positive,positive
670685424,"Sorry for the delay on this one. In fastai2 can you take a look at how I've handled it in `32_text.models.awdlstm.ipynb`? When I check `named_parameters` it looks OK to me. Please let me know if you see any problems. If you think it's OK, I'd be happy to accept a PR that does something similar for fastai v1.",sorry delay one take look handled check please let know see think happy accept something similar,issue,positive,positive,positive,positive,positive,positive
670611255,"Thanks for letting us know. I've added that flag to fastai v1 in master. Please try it out and see if that works for you. For v2, we'll be releasing with pytorch 1.6 requirement from the start, so we won't add this flag. We could add a little conversion function however if people needed that.",thanks u know added flag master please try see work requirement start wo add flag could add little conversion function however people,issue,positive,positive,neutral,neutral,positive,positive
670567302,"@jph00 this is a bug report. `apply_tfms` scales images before padding them, so `resize_method=ResizeMethod.PAD` doesn't do anything. 

I'm fairly sure all that needs to be done is:
```diff
 if size is not None: 
     crop_target = _get_crop_target(size, mult=mult) 
-     if resize_method in (ResizeMethod.CROP,ResizeMethod.PAD): 
+     if resize_method in (ResizeMethod.CROP,): 
         target = _get_resize_target(x, crop_target, do_crop=(resize_method==ResizeMethod.CROP)) 
         x.resize(target) 
```",bug report scale padding anything fairly sure need done size none size target target,issue,negative,positive,positive,positive,positive,positive
670553321,Thanks for the detective work! I'll revert that PR.,thanks detective work revert,issue,negative,positive,positive,positive,positive,positive
670552040,"We're not likely to fix this, since v2 has a different packaging system, sorry.",likely fix since different system sorry,issue,negative,negative,negative,negative,negative,negative
670542132,"We are not able to provide support here, sorry.",able provide support sorry,issue,negative,neutral,neutral,neutral,neutral,neutral
670541237,"I believe the current approach is correct. In your first example in your gist, the right answer isn't 0.5, since that's ignoring all the correctly predicted ""0""s.",believe current approach correct first example gist right answer since correctly,issue,negative,positive,positive,positive,positive,positive
670539971,Closing this now since our workaround in fastai2 has been working fine for a while now so all's well.,since working fine well,issue,negative,positive,positive,positive,positive,positive
670539116,"We're not able to accept this PR, since the diff is changing every line of the notebook. Please only change the minimum number of lines for what you're adding.",able accept since every line notebook please change minimum number,issue,positive,positive,positive,positive,positive,positive
670537528,Could you please include tests in your PR that check the behavior of all expected tensor shapes?,could please include check behavior tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
670536207,"We're not adding new features to v1, sorry! But please consider contributing this functionality to v2 when it's out in a few weeks.",new sorry please consider functionality,issue,negative,negative,negative,negative,negative,negative
670535548,"Thanks for this PR! We're not adding new functionality to v1 - but if you're interested, we'd be happy to consider this functionality for v2, after it's released in a few weeks. BTW, you might be interested in checking out the implementations here:
https://github.com/rwightman/pytorch-image-models",thanks new functionality interested happy consider functionality might interested,issue,positive,positive,positive,positive,positive,positive
669200749,"Try importing from `fastai.tabular` instead of `fastai.structured`.

`fastai.structured` methods are moved to `fastai.tabular`.

So,

```python
from fastai.tabular import *
```

will do the job.
",try instead python import job,issue,negative,neutral,neutral,neutral,neutral,neutral
667737935,(delete this issue when possible. Might create it again in a more organized notebook and provide data to reproduce),delete issue possible might create organized notebook provide data reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
666315535,(the return on cell 22 is ok. I moved the file on bash to become lm.pth),return cell file bash become,issue,negative,neutral,neutral,neutral,neutral,neutral
665852973,"Absolutely! :) The MVE is the code here: https://github.com/fastai/fastai/issues/2616#issuecomment-665838264

Having said that, don't worry about it too much, because I've tried patching it now and it's working fine. :) ",absolutely code said worry much tried working fine,issue,negative,positive,positive,positive,positive,positive
665850175,"Could you post, in an ideal world, a MVE of what you'd like to ""just work""?",could post ideal world like work,issue,positive,positive,positive,positive,positive,positive
665847252,"Thanks @hameerabbasi . I've read that before - but just took another look thru to re-check. There doesn't seem to be any suggestion there of a way to subclass Tensor and retain `__dict__`; apologies if I'm missing it, however.

(There is the `MetadataTensor` approach mentioned in the docs, but that doesn't create a subclass, which causes problems with code that expects tensors to subclass `Tensor`. I think it would also cause problems with serialization, although I haven't looked into it.)",thanks read took another look seem suggestion way subclass tensor retain missing however approach create subclass code subclass tensor think would also cause serialization although,issue,negative,neutral,neutral,neutral,neutral,neutral
665842625,"Just looking at the helpful `ScalarTensor` example of `__torch_function__` in the docs, and whilst that is very cool functionality, I don't think it will handle what we need, which really is sub-classing. We'd have to heavily rewrite fastai2's foundations otherwise.

I can just patch pytorch to copy over `__dict__` in `as_subclass`, I guess. I'll try that now.",looking helpful example whilst cool functionality think handle need really heavily rewrite otherwise patch copy guess try,issue,positive,positive,neutral,neutral,positive,positive
665838566,How do I use `__torch_function__` to subclass `Tensor` and keep `__dict__` ?,use subclass tensor keep,issue,negative,neutral,neutral,neutral,neutral,neutral
665838264,"Here's an example:

```
t = tensor([1.0])
t.requires_grad = True
o = tensor([1.0])
z1 = t+o
setattr(z1,'_meta',1)

class TensorBase(Tensor):
    def __repr__(self):
        return re.sub('tensor', self.__class__.__name__, super().__repr__())

z2 = z1.as_subclass(TensorBase)
z2,z2.requires_grad, z1,z1.requires_grad
```

Result is as expected:

```
(TensorBase([2.], grad_fn=<AliasBackward>),
 True,
 tensor([2.], grad_fn=<AddBackward0>),
 True)
```

But `z2._meta` is missing.",example tensor true tensor class tensor self return super result true tensor true missing,issue,positive,positive,positive,positive,positive,positive
665838144,"That was intentional. However, one can use `__torch_function__` for exactly that purpose.",intentional however one use exactly purpose,issue,negative,positive,positive,positive,positive,positive
665837412,"Yes that fixes that problem.

However, it seems to lose `__dict__`, so any attrs added are removed. Is that intentional? Is there a workaround?",yes problem however lose added removed intentional,issue,negative,neutral,neutral,neutral,neutral,neutral
665836375,"@jph00 Can you possibly test `as_subclass`, which uses `alias`, to see if it has these shortcomings?",possibly test alias see,issue,negative,neutral,neutral,neutral,neutral,neutral
665834461,"Thanks this is great to know, @ezyang. Yes we rely on it heavily, in order to monkey-patch in the exact change that that PR makes. Can you please let us know when a nightly is available, so we can test it? It'll be terrific to remove our monkey-patching.

Also, `_make_subclass` previously deleted the grad history and the `requires_grad` attr. Has that been fixed too?",thanks great know yes rely heavily order exact change please let u know nightly available test terrific remove also previously grad history fixed,issue,positive,positive,positive,positive,positive,positive
660555258,"The `Imputer` error has already been solved 4 months ago in this commit: https://github.com/fastai/fastai/commit/3b54ef1575f941721c7d5ec4011ebaf51cd06eeb.
To solve https://github.com/fastai/fastai/issues/2609 you need to install fastai 0.7.0, which you can do either like this:
```bash
git clone https://github.com/fastai/fastai.git
pip install ./fastai/old/.
```
or like this (for Google Colab you must first uninstall the previously installed version of fastai):
```
pip uninstall fastai
pip install ""git+https://github.com/fastai/fastai#egg=fastai&subdirectory=old""
```
Both of these two methods will get you the latest commit of fastai 0.7.0 so you won't face the `Imputer` import error.",imputer error already ago commit solve need install either like bash git clone pip install like must first previously version pip pip install two get latest commit wo face imputer import error,issue,positive,positive,positive,positive,positive,positive
658518075,[This thread](https://forums.fast.ai/t/save-both-model-architecture-and-weights-into-one-file/49498/2) on the fast.ai forums may be helpful. Does `learn.export()` meet your needs?,thread may helpful meet need,issue,negative,neutral,neutral,neutral,neutral,neutral
658047865,"> For the Import Imputer error still persists without changing structured.py  

If I continue to run the notebooks in google colab, I need to add the import imputer everytime to the structured.py?
",import imputer error still without continue run need add import imputer,issue,negative,neutral,neutral,neutral,neutral,neutral
657240920,"I managed the error with the following code:
```

test = (TextList.from_df(df, path, cols='texts'))

learn_fwd = load_learner(path + '/fwd_learn_c', test=test)

pred_fwd,lbl_fwd = learn_fwd.get_preds(ds_type=DatasetType.Test)
```",error following code test path path,issue,negative,neutral,neutral,neutral,neutral,neutral
657100075,"> `pip install ""git+https://github.com/fastai/fastai#egg=fastai&subdirectory=old""`

Are you talking about replacing this? -
```python
!pip install torchvision==0.1.9
!pip install fastai==0.7.0
!pip install torchtext==0.2.3
```
For the Import Imputer error still persists without changing structured.py

Still learning :)",pip install talking python pip install pip install pip install import imputer error still without still learning,issue,negative,neutral,neutral,neutral,neutral,neutral
657094872,"> When this notebook is run on Google Colab, an error is thrown - ModuleNotFoundError: No module named 'fastai.structured'
> I have tested and provided steps in the form of an additional markdown block to resolve this error for the students new to the ML course.

Nice work but I feel this is way shorter 
`pip install ""git+https://github.com/fastai/fastai#egg=fastai&subdirectory=old""`
",notebook run error thrown module tested provided form additional markdown block resolve error new course nice work feel way shorter pip install,issue,negative,positive,positive,positive,positive,positive
656623097,"> I think the problem that vgg19 isn't included in fastai library, but GradCam should work for all architectures

I used models.squeezenet1_0, same issue

learn = cnn_learner(data, models.squeezenet1_0, metrics=accuracy)
interp = ClassificationInterpretation.from_learner(learn)
interp.plot_top_losses(4, figsize=(8,8),heatmap=True)

---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-12-ea4627e4eb6b> in <module>
      1 losses,idxs = interp.top_losses()
----> 2 interp.plot_top_losses(4, figsize=(8,8),heatmap=True)

/media/storage_0x00/ENV/miniconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/learner.py in _cl_int_plot_top_losses(self, k, largest, figsize, heatmap, heatmap_thresh, alpha, cmap, show_text, return_fig)
    179         im.show(ax=axes.flat[i], title=title)
    180         if heatmap:
--> 181             mult = self.GradCAM(idx,self.ds_type,heatmap_thresh,image=False)
    182             if mult is not None:
    183                 sz = list(im.shape[-2:])

/media/storage_0x00/ENV/miniconda3/envs/fastai/lib/python3.6/site-packages/fastai/vision/learner.py in _cl_int_gradcam(self, idx, ds_type, heatmap_thresh, image)
    147     acts  = hook_a.stored[0].cpu() #activation maps
    148     if (acts.shape[-1]*acts.shape[-2]) >= heatmap_thresh:
--> 149         grad = hook_g.stored[0][0].cpu()
    150         grad_chan = grad.mean(1).mean(1)
    151         mult = F.relu(((acts*grad_chan[...,None,None])).sum(0))

TypeError: 'NoneType' object is not subscriptable",think problem included library work used issue learn data learn recent call last module self alpha mult mult none list self image activation grad mult none none object,issue,negative,neutral,neutral,neutral,neutral,neutral
656609711,"I think the problem that vgg19 isn't included in fastai library, but GradCam should work for all architectures ",think problem included library work,issue,negative,neutral,neutral,neutral,neutral,neutral
656603408,"I met the same issue:
CUDA Version: 10.1
torch  1.3.0
fastai 1.0.59",met issue version torch,issue,negative,neutral,neutral,neutral,neutral,neutral
654871389,"I'm also getting the following error messages right at the moment the progress bar appears, after which the training takes place as if nothing happened:
```
Exception in thread Thread-1:-------------------------------------------------------------------------------------| 0.00% [0/190 00:00<00:00]
Traceback (most recent call last):
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py"", line 639, in run_mod_and_filter_tensor_outputs
    outs = wrap_retval(mod(*_clone_inputs(inputs)))
RuntimeError: Input type (CUDAFloatType) and weight type (CUDAHalfType) should be the same
The above operation failed in interpreter.
Traceback (most recent call last):
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/conv.py(342): conv2d_forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/conv.py(345): forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torchvision/models/resnet.py(60): forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/container.py(100): forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/container.py(100): forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/container.py(100): forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py(1034): trace_module
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py(882): trace
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/utils/tensorboard/_pytorch_graph.py(285): graph
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/tensorboardX/writer.py(794): add_graph
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py(424): write
/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py(234): _queue_processor
/usr/lib/python3.6/threading.py(864): run
/usr/lib/python3.6/threading.py(916): _bootstrap_inner
/usr/lib/python3.6/threading.py(884): _bootstrap


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File ""/usr/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/usr/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py"", line 234, in _queue_processor
    request.write()
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py"", line 424, in write
    self.tbwriter.add_graph(model=self.model, input_to_model=self.input_to_model)
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/tensorboardX/writer.py"", line 794, in add_graph
    self._get_file_writer().add_graph(graph(model, input_to_model, verbose))
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/utils/tensorboard/_pytorch_graph.py"", line 285, in graph
    trace = torch.jit.trace(model, args)
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py"", line 882, in trace
    check_tolerance, _force_outplace, _module_class)
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py"", line 1044, in trace_module
    check_tolerance, _force_outplace, True, _module_class)
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/autograd/grad_mode.py"", line 49, in decorate_no_grad
    return func(*args, **kwargs)
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py"", line 677, in _check_trace
    traced_outs = run_mod_and_filter_tensor_outputs(traced_func, inputs, 'trace')
  File ""/home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py"", line 645, in run_mod_and_filter_tensor_outputs
    ' with test inputs.\nException:\n' + indent(str(e)))
torch.jit.TracingCheckError: Tracing failed sanity checks!
Encountered an exception while running the trace with test inputs.
Exception:
        Input type (CUDAFloatType) and weight type (CUDAHalfType) should be the same
        The above operation failed in interpreter.
        Traceback (most recent call last):
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/conv.py(342): conv2d_forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/conv.py(345): forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torchvision/models/resnet.py(60): forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/container.py(100): forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/container.py(100): forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/container.py(100): forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(516): _slow_forward
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py(530): __call__
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py(1034): trace_module
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/jit/__init__.py(882): trace
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/torch/utils/tensorboard/_pytorch_graph.py(285): graph
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/tensorboardX/writer.py(794): add_graph
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py(424): write
        /home/ubuntu/MultiClassLabeling/myenv/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py(234): _queue_processor
        /usr/lib/python3.6/threading.py(864): run
        /usr/lib/python3.6/threading.py(916): _bootstrap_inner
        /usr/lib/python3.6/threading.py(884): _bootstrap
```",also getting following error right moment progress bar training place nothing exception thread recent call last file line input type weight type operation interpreter recent call last forward forward forward forward forward trace graph write run handling exception another exception recent call last file line file line run file line file line write file line graph model verbose file line graph trace model file line trace file line true file line return file line file line test indent tracing sanity exception running trace test exception input type weight type operation interpreter recent call last forward forward forward forward forward trace graph write run,issue,negative,positive,neutral,neutral,positive,positive
653737909,"> If my changes are not enough to merge how can I help

Close this PR =)",enough merge help close,issue,negative,neutral,neutral,neutral,neutral,neutral
652925718,"I get the following error while trainning the dataset using AWD -LSTM:

Training models\generator\piano_to_guitar_light.pth
Traceback (most recent call last):
  File ""C:/Users/sweth/MusicMine/Training_LSTM.py"", line 162, in <module>
    args.nh, args.nl, args.min_freq, args.dropout, args.epochs)
  File ""C:/Users/sweth/MusicMine/Training_LSTM.py"", line 104, in main
    train_and_save(learner, lrs[i], epochs, save_names[i])
  File ""C:\Users\sweth\MusicMine\utils.py"", line 42, in train_and_save
    learner.fit(lr, 1, wds=1e-6, cycle_len=epochs, use_clr=(32, 10), metrics=metrics)
  File ""C:\Users\sweth\anaconda3\envs\musicminefinal\lib\site-packages\fastai\learner.py"", line 302, in fit
    return self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)
  File ""C:\Users\sweth\anaconda3\envs\musicminefinal\lib\site-packages\fastai\learner.py"", line 221, in fit_gen
    self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len, on_cycle_end=cycle_end, div=clr_div, cut_div=cut_div,
ValueError: __len__() should return >= 0



the specification of my model is 
bs = 32
 bptt = 200
 em_sz = 400
 nh = 600
 nl = 4
 min_freq = 1
 epochs = 3
 dropout = 1
  training=""light""
 load_model = True
My total number of training files and test files are more than the bs value",get following error awd training recent call last file line module file line main learner file line file line fit return file line return specification model dropout light true total number training test value,issue,positive,positive,positive,positive,positive,positive
652387250,@sgugger @jph00 could you guide as to whom should i tag as a reviewer here? Lets get it completed.,could guide tag reviewer get,issue,negative,neutral,neutral,neutral,neutral,neutral
647934612,"@lsb
Unfortunately, I don't have access to merge this pull request!
But I think your changes aren't enough to merge.
Thank you for your contribution :)",unfortunately access merge pull request think enough merge thank contribution,issue,negative,negative,negative,negative,negative,negative
647842053,"I see that these changes are approved and not merged, is there anything I can do to help close this issue either positively or negatively?",see anything help close issue either positively negatively,issue,positive,negative,negative,negative,negative,negative
646959878,"> I read the source code of learner.py, and found that parameter, ""arch"", should be models.resnet101 instead of models.resnet101() (they are different!!!)

Do you mean the resnet101 can not be pretrained?",read source code found parameter arch instead different mean,issue,negative,negative,negative,negative,negative,negative
646490557,"I notice that there seem issues in fastai2 as well, though I didn't dig into that too much.",notice seem well though dig much,issue,negative,positive,positive,positive,positive,positive
642887473,I'm pretty sure this change caused 0 of the test failures/cancellations.,pretty sure change test,issue,positive,positive,positive,positive,positive,positive
641146859,"I had the same issue just now. I am happy to create a PR if there are no side effects of removing the quotemark. Alternatively, one could add an option to the SPProcessor. As far as I can see this was introduced by #2507 . ",issue happy create side effect removing alternatively one could add option far see,issue,positive,positive,positive,positive,positive,positive
640561604,"I agree with @andresti , please refer to this [discussion](https://forums.fast.ai/t/multifit-runtime-error-permission-denied/72874). The {quotemark} around model_prefix parameter need to be removed.
",agree please refer discussion around parameter need removed,issue,positive,neutral,neutral,neutral,neutral,neutral
639276625,"If it helps anyone, I found a workaround. Instead of an explicit splitting function, I made the split inside the class method `from_dfs`. Now the images in the validation set are correct (though we get a shuffled set).
```python
    @classmethod
    def from_dfs(cls, df:DataFrame, path='.', cols=0, colsB=1, **kwargs):
        ""Create an `ItemList` in `path` from the inputs in the `cols` of `df`.""
        itemsB = ImageList.from_df(df[df['is_valid']==False], path, colsB).items
        t_res = super().from_df(df[df['is_valid']==False],path,cols, itemsB=itemsB, **kwargs)
        t_res.path = path
        itemsB = ImageList.from_df(df[df['is_valid']==True], path, colsB).items
        v_res = super().from_df(df[df['is_valid']==True],path,cols, itemsB=itemsB, **kwargs)
        v_res.path = path
        return ItemLists(t_res.path, t_res, v_res)
```
To create databunch
```python
bs = 32
data = (ImageTupleList.from_dfs(df, path='.', cols=0, colsB=1)
         .label_from_df(cols=target_col, label_cls=FloatList)
         .databunch(bs=bs))
```",anyone found instead explicit splitting function made split inside class method validation set correct though get set python create path path super path path path super path path return create python data,issue,positive,positive,positive,positive,positive,positive
638249128,"Hi, I am having the same issue.

I am not sure how to suppress the warning

I tried running

```
import warnings
warnings.filterwarnings(""ignore"", category=UserWarning, module=""torch.nn.functional"")
```
But this still shows the same error, although the training seems to be progressing.  I realized that I've written the wrong torch module, but which is the right module to add here? `torch.autograd.backward`?
Edit: 

I think I  solved it by running 
```import warning
 warning.filterwarning(""ignore)
```
Although I am not sure if this is the right way. My python knowledge is very poor - it's just been a few months. 


Thank you. ",hi issue sure suppress warning tried running import ignore still error although training written wrong torch module right module add edit think running import warning ignore although sure right way python knowledge poor thank,issue,negative,positive,positive,positive,positive,positive
635680946,"> Ok so it's clearly that line that fails for you
> 
> ```
> libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
> ```
> 
> in fastai.sixel. I'm not too familiar with libsixel and din't write that part but maybe there is another flag that makes this work for you?
> 
> This is a minimum example at this stage that works for me (and probably not for you)
> 
> ```
> import numpy as np
> import matplotlib.pyplot as plt
> import libsixel,io
> 
> def _sixel_encode(data, width, height):
>     s = io.BytesIO()
>     output = libsixel.sixel_output_new(lambda data, s: s.write(data), s)
>     dither = libsixel.sixel_dither_new(256)
>     w,h = int(width),int(height)
>     libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
>     libsixel.sixel_encode(data, w, h, 1, dither, output)
>     return s.getvalue().decode('ascii')
> 
> def plot_sixel(fig=None):
>     if not libsixel:
>         warn(""You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel"")
>         return
>     if fig is None: fig = plt.gcf()
>     fig.canvas.draw()
>     dpi = fig.get_dpi()
>     res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
>     print(res)
> 
> fig, ax = plt.subplots(1,1)
> x = np.linspace(0,100)
> y = np.exp(x)
> ax.plot(x, y)
> ax.set_ylabel(""Loss"")
> ax.set_xlabel(""Learning Rate"")
> plot_sixel(fig)
> ```

Use code above，I get an error like yours:
```usr/lib/python3.8/site-packages/libsixel/__init__.py in sixel_dither_initialize(dither, data, width, height, pixelformat, method_for_largest, method_for_rep, quality_mode)
    516     _sixel.sixel_dither_initialize.argtypes = [c_void_p, c_char_p, c_int, c_int, c_int,
    517                                               c_int, c_int, c_int]
--> 518     status = _sixel.sixel_dither_initialize(dither, data, width, height, pixelformat,
    519                                             method_for_largest,
    520                                             method_for_rep,

ArgumentError: argument 2: <class 'TypeError'>: wrong type
```
After reading saitoha‘s [example code](https://github.com/saitoha/libsixel/blob/5db717dfef6fa327cd4025e7352550f63d20699c/examples/python/converter.py), edit this line
```
res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
```
to
```
res = _sixel_encode(fig.canvas.buffer_rgba().tobytes(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
```
Then all works fine.
",clearly line dither data familiar di write part maybe another flag work minimum example stage work probably import import import io data width height output lambda data data dither width height dither data data dither output return warn could see plot see return fig none fig print fig ax loss learning rate fig use code get error like dither data width height status dither data width height argument class wrong type reading example code edit line work fine,issue,negative,positive,neutral,neutral,positive,positive
635242337,"@WarrenPretorius (and everybody else with this error), I was having the same problem as you, then I realized that writing `learn = cnn_learner(...)` instead of `learn = unet_learner(...)` had something to do with this error… :facepalm:

Now I have a more manageable `RuntimeError: CUDA error: device-side assert triggered`, the buik is done.",everybody else error problem writing learn instead learn something manageable error assert triggered done,issue,negative,neutral,neutral,neutral,neutral,neutral
634540358,"> > There was an indexing added in the below code. However, it fails when the return value of average is integer because integer cannot be indexed. Thus, the checks looks for the `ndim` of the return value, and indexes only if it is not 0
> 
> @aayushagrawal135 could you please tell what caused the error(which line in your code) and also what were you trying to do originally.

I ran the code cell `fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)` in the file in `courses/ml1/lesson4-mnist_sgd.ipynb`. Only changes I made in the jupyter notebook were to remove `.cuda()` calls since I am not using a GPU. This led to the traceback,

```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-27-4d27984296a1> in <module>
----> 1 fit(net, md, n_epochs=5, crit=loss, opt=opt, metrics=metrics)

~/repos/fastai/courses/ml1/fastai/model.py in fit(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, visualize, **kwargs)
    161 
    162         if not all_val:
--> 163             vals = validate(model_stepper, cur_data.val_dl, metrics, epoch, seq_first=seq_first, validate_skip = validate_skip)
    164             stop=False
    165             for cb in callbacks: stop = stop or cb.on_epoch_end(vals)

~/repos/fastai/courses/ml1/fastai/model.py in validate(stepper, dl, metrics, epoch, seq_first, validate_skip)
    241             loss.append(to_np(l))
    242             res.append([to_np(f(datafy(preds), datafy(y))) for f in metrics])
--> 243     return [np.average(loss, 0, weights=batch_cnts)[0]] + list(np.average(np.stack(res), 0, weights=batch_cnts))
    244 
    245 def get_prediction(x):

IndexError: invalid index to scalar variable.
```
",indexing added code however return value average integer integer indexed thus return value could please tell error line code also trying originally ran code cell fit net file made notebook remove since led recent call last da module fit net fit model data opt metric stepper visualize validate metric epoch stop stop validate stepper metric epoch metric return loss list invalid index scalar variable,issue,positive,positive,positive,positive,positive,positive
634229606,"> There was an indexing added in the below code. However, it fails when the return value of average is integer because integer cannot be indexed. Thus, the checks looks for the `ndim` of the return value, and indexes only if it is not 0

@aayushagrawal135 could you please tell what caused the error(which line in your code) and also what were you trying to do originally.",indexing added code however return value average integer integer indexed thus return value could please tell error line code also trying originally,issue,positive,positive,positive,positive,positive,positive
632692059,"My PyTorch version is these.
PyTorch Version:  1.4.0
Torchvision Version:  0.5.0
When I use fastai .pth weight file in PyTorch model using pytorch_model.load_state_dict(new_state_dict) it's get error ( Unexpected key(s) in state_dict: """").
What is the fastai torchvision version? What is the reason behind this error?",version version version use weight file model get error unexpected key version reason behind error,issue,negative,negative,negative,negative,negative,negative
632651592,"Yes, you should upgrade to 1.0.61 then. Please reopen if that doesn't fix your issue.",yes upgrade please reopen fix issue,issue,positive,neutral,neutral,neutral,neutral,neutral
632651171,Please use the [forum](https://forums.fast.ai/) to help debug your code. We keep the issues for known bugs only.,please use forum help code keep known,issue,positive,neutral,neutral,neutral,neutral,neutral
632045742,What's your fastai version? There was a bug with `WeightDropout` that could be causing this but it has been fixed.,version bug could causing fixed,issue,negative,positive,neutral,neutral,positive,positive
631421067,This is to port a module from BigGAN in fastai layers. I'd not change the implementation but instead clearly document it only works for layers with even dimensions.,port module change implementation instead clearly document work even,issue,negative,positive,positive,positive,positive,positive
630522286,"> Your y’s will always be zero because they are unlabeled. Labeled test sets are natively supported only in fastai2. There are workarounds in v1, search the forums. To get your tensor(1), take the argmax of your raw probabilities (the other two numbers)

`predicted_classes = preds.argmax(axis=1)`


",always zero unlabeled test natively search get tensor take raw two,issue,negative,negative,negative,negative,negative,negative
630121090,"Please reopen if you want to address the comments up there, closing since there hasn't been any activity in a while.",please reopen want address since activity,issue,negative,neutral,neutral,neutral,neutral,neutral
629255254,"Hi, I was having the same issue (fastai v. 1.0.61).

The error is:
`~/miniconda3/envs/training/lib/python3.7/site-packages/fastai/text/data.py in train_sentencepiece(texts, path, pre_rules, post_rules, vocab_sz, max_vocab_sz, model_type, max_sentence_len, lang, char_coverage, tmp_dir, enc)
    435         f""--unk_id={len(defaults.text_spec_tok)} --pad_id=-1 --bos_id=-1 --eos_id=-1"",
    436         f""--user_defined_symbols={','.join(spec_tokens)}"",
--> 437         f""--model_prefix={quotemark}{cache_dir/'spm'}{quotemark} --vocab_size={vocab_sz} --model_type={model_type}""]))
    438     raw_text_path.unlink()
    439     return cache_dir

OSError: Not found: """"/[path]/docs/tmp/all_text.out"""": No such file or directory Error #2
`

But actually the all_text.out file exists at the path and the contents seem fine. I managed to fix the problem by changing `quotemark = '\""'` to `quotemark = ''` in fastai/text/data.py
 ",hi issue error path return found path file directory error actually file path content seem fine fix problem,issue,negative,positive,positive,positive,positive,positive
629126583,"> @koushikam it seems like you are using v1.0 fastai with old notebooks. You need to use v0.7 of fastai for this old ML1 course or you can copy old code for your function `train_cats` from here: https://github.com/fastai/fastai/blob/master/old/fastai/structured.py#L112.
> 
> But, I have question related to `structured.py` module. Why this module is not in v1.0. It has fantastic methods for data. At least the medoths should be migrated to new modules as `add_datepart` migrated to `tabular` module. Am I missing anythig? Thanks.

i agree with you , i am facing the same issue ",like old need use old course copy old code function question related module module fantastic data least new tabular module missing thanks agree facing issue,issue,positive,positive,neutral,neutral,positive,positive
628617576,No the library is not split in separate packages. You'll need to make you own fork for that.,library split separate need make fork,issue,negative,neutral,neutral,neutral,neutral,neutral
628337240,Can we do the installation of the specific library for inference in fastai.  Such as we required for inference only load_learner() module for prediction can we installation only that library.,installation specific library inference inference module prediction installation library,issue,negative,neutral,neutral,neutral,neutral,neutral
628122640,"Hmm alright, I see. Let me try that! Thanks!",alright see let try thanks,issue,positive,positive,positive,positive,positive,positive
627931166,"This has already been addressed before. `load_learner` serializes function names using pickle, so you need to use the **same module** at training at inference time containing all your extra stuff.

Here `load_learner` is looking for `ModelResnetClassifier` in main because it was defined there when you exported the `Learner`. You need to fix your export file by exporting your Learner in a script that will have `ModelResnetClassifier` come from the same python modules you are using in production.",already function pickle need use module training inference time extra stuff looking main defined learner need fix export file learner script come python production,issue,negative,positive,neutral,neutral,positive,positive
627634060,"@sgugger Does it matter if the pytorch model is imported from another module or not? I'm trying to load and run a learner with flask, but wherever I paste the model definition, it doesn't seem to be able to find it. ",matter model another module trying load run learner flask wherever paste model definition seem able find,issue,negative,positive,positive,positive,positive,positive
626650778,I've just removed the print statement entirely since it's done on the whole tensor so it should be fast and there is no way to add a progress bar.,removed print statement entirely since done whole tensor fast way add progress bar,issue,negative,positive,positive,positive,positive,positive
626444169,"This is way too vague for us to do anything to help. What is your environment? Where does `dest` point to?
In general, please follow the template to file an issue otherwise we won't really be able to help.",way vague u anything help environment point general please follow template file issue otherwise wo really able help,issue,positive,positive,neutral,neutral,positive,positive
626389207,"Could you guide as to what should I do regarding this?

It broke for me while running the 4th jupyter notebook for the machine learning course, so I sent in a PR. As of now, I have the change locally and I am continuing with the lectures.",could guide regarding broke running th notebook machine learning course sent change locally,issue,negative,neutral,neutral,neutral,neutral,neutral
626360209,"As I said, a progress bar if possible, or simply printing ""done."" when it's done.",said progress bar possible simply printing done done,issue,negative,neutral,neutral,neutral,neutral,neutral
626357573,"When the last message being displayed is ""Computing similarities..."" indicating something is in the middle of being done, then the cell suddenly stops executing with nothing that confirms it ended successfully gives the impression for new users that something went wrong instead.

A good example done right is the message right before it, the ""Getting activations..."" has a progress bar that reaches 100% indicating it is done, a similar bar or even a simple ""done."" message could avoid needless first time confusion.

As I said, it's a minor issue with - I assume - a simple fix, if no one thinks it's worth fixing, then go ahead and close this issue.",last message displayed something middle done cell suddenly nothing ended successfully impression new something went wrong instead good example done right message right getting progress bar done similar bar even simple done message could avoid needle first time confusion said minor issue assume simple fix one worth fixing go ahead close issue,issue,negative,positive,positive,positive,positive,positive
626327397,"I'm not sure what the issue is. The function tells you what it's doing, and when it's done... well your ntoebook is not executing anything so you know it?",sure issue function done well anything know,issue,positive,positive,positive,positive,positive,positive
626326987,"No, this breaks everything in the library. Note that if the factory methods of `ImageDataBunch` do not help you in your problem, you should switch to the data block API. Those factory methods are not guaranteed to work in every use case you may have, they are just tools for easy data creation for beginners.",everything library note factory help problem switch data block factory work every use case may easy data creation,issue,negative,positive,positive,positive,positive,positive
626172739,"No, this does not check if the attribute is `True` anymore, just that it exists. So it's not a real fix. It should be something like `getattr(data, 'backward', False)` to check if it's there with a default to `False` if it's not.",check attribute true real fix something like data false check default false,issue,positive,negative,neutral,neutral,negative,negative
626172107,"I double-checked and those are the correct values indeed. I think that's because we added some csv files in those dataset to make it easy to use pascal for multi-label problems and forgot to update those checks.

Thanks for fixing!",correct indeed think added make easy use forgot update thanks fixing,issue,positive,positive,positive,positive,positive,positive
626171636,"Not sure it will work fully with a list of dependent variables, but this is a first step, thanks!",sure work fully list dependent first step thanks,issue,positive,positive,positive,positive,positive,positive
625944048,This issue is so old that I don’t think I can be helpful try the fastai forums,issue old think helpful try,issue,negative,positive,neutral,neutral,positive,positive
625920504,"@hamelsmu  Hi! I am getting a similar error now when loading the databunch. 

  File ""/home/views.py"", line 641, in get
    path, r""/home/data_save.pkl"")
  File ""/usr/local/lib/python3.7/site-packages/fastai/basic_data.py"", line 281, in load_data
    ll = torch.load(source, map_location='cpu') if defaults.device == torch.device('cpu') else torch.load(source)
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 529, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 702, in _legacy_load
    result = unpickler.load()
AttributeError: Can't get attribute 'RobertaTextList' on <module '__main__' from 'manage.py'>


Could you probably help me with this? ",hi getting similar error loading file line get path file line source else source file line load return file line result ca get attribute module could probably help,issue,negative,neutral,neutral,neutral,neutral,neutral
625385703,It's feature-complete but the doc is not yet entirely done indeed.,doc yet entirely done indeed,issue,negative,neutral,neutral,neutral,neutral,neutral
625384607,"Thanks sgugger! Options 2 and 3 both work.

I haven't tried fastai2, the documentation seems a bit sparser than fastai1, so I assumed it wasn't ""final"" yet.",thanks work tried documentation bit assumed final yet,issue,negative,positive,neutral,neutral,positive,positive
625209623,"The fix has been done in fastai v2. It requires deep changes in the `WeightDropout` layer of the AWD-LSTM so could have some backward-compatibility problems, so I would advise you to do one of the following:
- switch to the fastai2 model
- pin PyTorch to 1.4.0
- ignore all warnings",fix done deep layer could would advise one following switch model pin ignore,issue,negative,neutral,neutral,neutral,neutral,neutral
625208030,"You are comparing the documentation of `tabular_learner` with the init of the model. In the middle, there was a call to a function that changed those embedding sizes in [here](https://github.com/fastai/fastai/blob/564896d7b84b59bee40db19ee298a1028235442b/fastai/tabular/learner.py#L15).

As said in #2559, please use the [forum](https://forums.fast.ai/) for question around the code.",documentation model middle call function size said please use forum question around code,issue,negative,neutral,neutral,neutral,neutral,neutral
625206583,"This is after the variables have been joined. The first 0 is because it hasn't been in any linear layer at this stage.

In general, please use the [forum](https://forums.fast.ai/) for questions around the code as we keep the issues for bugs only.",first linear layer stage general please use forum around code keep,issue,negative,positive,positive,positive,positive,positive
625205699,"Please use the [forum](https://forums.fast.ai/) to debug your code, we keep the issues for bugs in the library only.",please use forum code keep library,issue,negative,neutral,neutral,neutral,neutral,neutral
623605694,"> @sgugger To change the loss function used by a learner, do you change the attribute `learn.loss_func` or `learn.lossfunc` like in the example above ? Or can you use it interchangeably ?
> 
> Using fastai v 1.0.52 , pytorch v 1.1.0

`learn.loss_func=CrossEntropyFlat(axis=1, weight = class_weights.cuda()) ` because if you use `learn.lossfunc=...` and then you check it typing `learn.loss_func`, you will find that nothing changed and the loss function is still > FlattenedLoss of CrossEntropyLoss() with no weights that you can check using `learn.loss_func.weight`",change loss function used learner change attribute like example use interchangeably weight use check find nothing loss function still check,issue,negative,neutral,neutral,neutral,neutral,neutral
623360043,"> > In any case, if the `ImageCleaner` doesnt work in colab it's because they don't support all ipywidget widgets, there is no exterior magic in it (if you look at the source code, we only import from widgets and Layout). Maybe there is workaround but I have no time figuring it out. I suspect it's possible we have to import the widgets from google.colab instead of the one from ipywidget but
> > The issue is closed because there is nothing we can do about it on the fastai side.
> 
> Hi, I've just started fast.ai and I'm on part 1 v3 lesson 2: https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb
> 
> I'm just encountering this information that Google Colab is incompatible with parts of fast.ai's course, such as ImageCleaner. If I had known this earlier I would not have spent time getting used to Colab, which already seems to deviate from default Jupyter's normal key commands and UI.
> 
> Perhaps you could remove it from the the list of suggested hosted platforms on fast.ai v3's intro page, or at least add a warning? It is listed as one of two free options. There is no mention of it being incompatible with parts of the course.
> 
> Is there another hosted service that runs Jupyter Notebook rather than Lab? I don't have a nice GPU so I need a hosted option. Thanks for any advice.

I've just arrived to this part and i was working with colab too, so i'd need an alternative to google colab in case there is no way of cleaning datasets as well as further problems related to colab.

Thanks for any advice :)",case doesnt work support exterior magic look source code import layout maybe time suspect possible import instead one issue closed nothing side hi part lesson information incompatible course known would spent time getting used already deviate default normal key perhaps could remove list page least add warning listed one two free mention incompatible course another service notebook rather lab nice need option thanks advice part working need alternative case way cleaning well related thanks advice,issue,positive,positive,positive,positive,positive,positive
622568798,"Release has been made, now you just need to wait for it to make its way up to colab.",release made need wait make way,issue,negative,neutral,neutral,neutral,neutral,neutral
622033939,"There will be a new release soon, that should fix the problem on colab once it's out there.",new release soon fix problem,issue,negative,positive,positive,positive,positive,positive
622032163,"@hamedonline Thanks for the link, I got over it by downgrading my Pytorch on Colab

`!pip install -q torch==1.4 torchvision==0.5.0`",thanks link got pip install,issue,negative,positive,positive,positive,positive,positive
621956932,"> I got the same error as @gchanan when I tried the first notebook of `fastai` course, is it related to this or something else? I'm sorry to reply back on a closed issue, but didn't want to open a new one unncessarily!

That issue has been fixed but the fix won't show up until a release. You need to install the latest unreleased patches via here:
https://github.com/fastai/fastai/blob/master/README.md#bug-fix-install

However, take note that other warnings might still exist.",got error tried first notebook course related something else sorry reply back closed issue want open new one issue fixed fix wo show release need install latest unreleased via however take note might still exist,issue,negative,positive,neutral,neutral,positive,positive
621947193,"I got the same error as @gchanan when I tried the first notebook of `fastai` course, is it related to this or something else? I'm sorry to reply back on a closed issue, but didn't want to open a new one unncessarily!",got error tried first notebook course related something else sorry reply back closed issue want open new one,issue,negative,negative,neutral,neutral,negative,negative
621798514,"Thanks, in particular for adding the test! (MacOS tests have been broken for a while but tests are passing otherwise)",thanks particular test broken passing otherwise,issue,negative,negative,neutral,neutral,negative,negative
620746548,"Hi there,
Unfortunately, there is no active developer to help me in the forum,
although my problem is not difficult.

https://forums.fast.ai/t/feature-fusion/69786


On Tuesday, April 28, 2020, Sylvain Gugger <notifications@github.com> wrote:

> Closed #2551 <https://github.com/fastai/fastai/issues/2551>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2551#event-3279957373>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AMOXGR7VFZ5EJYOUHZ3JBU3RO276VANCNFSM4MSKFUEQ>
> .
>
",hi unfortunately active developer help forum although problem difficult wrote closed thread reply directly view,issue,negative,negative,negative,negative,negative,negative
620559725,Please use the [forum](https://forums.fast.ai/) for help with your code. We keep the issues for bug only.,please use forum help code keep bug,issue,positive,neutral,neutral,neutral,neutral,neutral
618964338,Thanks for flagging this! Note that you can directly open a PR when you have a fix for your problem.,thanks flagging note directly open fix problem,issue,negative,positive,neutral,neutral,positive,positive
618963422,You should make sure to post in an appropriate thread (like [fastai users](https://forums.fast.ai/c/fastai-users)) and make sure to post all information to reproduce your problem. Opening an issue won't really help unless it's to fix a bug in the library.,make sure post appropriate thread like make sure post information reproduce problem opening issue wo really help unless fix bug library,issue,positive,positive,positive,positive,positive,positive
618346100,"Yeah, there are a bunch of warnings. I fixed them in v2, will look at this when I have time (if anyone wants to tackle it before, I welcome any PR :) )",yeah bunch fixed look time anyone tackle welcome,issue,positive,positive,positive,positive,positive,positive
618303335,"Looks like this fix is not enough, or maybe I'm missing something?
The previous issue was fixed but in addition I get this red flagged warnings right after following lines.
![image](https://user-images.githubusercontent.com/24595790/80085591-aa1a4800-856d-11ea-80fc-2db1fd9b8889.png)
![image](https://user-images.githubusercontent.com/24595790/80085653-c61de980-856d-11ea-896e-4b23a7b047c5.png)

",like fix enough maybe missing something previous issue fixed addition get red right following image image,issue,negative,positive,neutral,neutral,positive,positive
617987197,"Hi, this issue seems to have come up again in 1.0.60; interp.pred_class returns a list of single class values (e.g. 
```
tensor([2, 5, 5, 0, 2, 0, 4, 5, 3, 5, 2, 1, 2, 5, 1, 0, 2, 0, 5, 2, 5, 2, 0, 0,
      ...
        4, 4, 2, 1, 1, 4, 5, 2, 1, 5])
```
instead of one-hot encoded arrays:

```
tensor([[0., 0., 1., 0., 0., 1.],
        [0., 0., 0., 0., 0., 1.],
        [1., 0., 0., 0., 0., 1.],
        ...,
        [0., 0., 1., 0., 0., 0.],
        [0., 1., 0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 1.]])
```
My confusion matrix makes no sense! ",hi issue come list single class tensor instead tensor confusion matrix sense,issue,negative,negative,neutral,neutral,negative,negative
617838026,Fixed the issue with the tests. In general it looks like some extra float will be required.,fixed issue general like extra float,issue,negative,positive,neutral,neutral,positive,positive
617828728,I also ran into this problem today. Would it be possible to simply fix the `torch` and `torchvision` versions in the fastai requirements?,also ran problem today would possible simply fix torch,issue,negative,neutral,neutral,neutral,neutral,neutral
616897454,"In general, fastai v1 is not going to be compatible with latest PyTorch releases (v2 will). We're happy to take PRs that fixes issues without breaking backward compatibility but we're not proactively testing fastai v1 against the nightlies.",general going compatible latest happy take without breaking backward compatibility testing,issue,positive,positive,positive,positive,positive,positive
613723676,"No, you probably have some other problems in your install as the current init works without problem for many many users. Look at the [forum](https://forums.fast.ai/) to help debug your install.",probably install current work without problem many many look forum help install,issue,positive,positive,positive,positive,positive,positive
613265934,"Awesome, verified that it's working correctly on fastai master. Thank you Sylvain! ",awesome working correctly master thank,issue,positive,positive,positive,positive,positive,positive
613162198,@sgugger I finally figured out I was in the wrong repo. This is an actual reported issue with the course v3 and I submitted a PR here. https://github.com/fastai/course-v3/pull/489,finally figured wrong actual issue course,issue,negative,negative,negative,negative,negative,negative
612998673,"Ok, finally went to the bottom of this. It was due to `WeightDropout` not really working. I fixed that, but note that you may need to adjust your weight dropout.",finally went bottom due really working fixed note may need adjust weight dropout,issue,negative,positive,neutral,neutral,positive,positive
612436343,"Got it, thanks for the update – let me know if I can help.",got thanks update let know help,issue,positive,positive,positive,positive,positive,positive
612434518,"Just an update: I managed to reproduce this bug on a smaller scale and am trying to get some minimal reproducer to find its cause. Not sure yet if it's inside fastai or PyTorch. It's a very subtle one, so it might take me a while to get to the root of it.",update reproduce bug smaller scale trying get minimal reproducer find cause sure yet inside subtle one might take get root,issue,negative,positive,neutral,neutral,positive,positive
611935134,"Aha! I was thinking that the `cat_names` and `cont_names` passed by the user to the constructor would be overwritten, but I see now that the user should never call the constructor. Everything works when the user creates a partial function instead. I understand the design now.

I'll post replies to the forum posts, suggesting the partial function approach.

Thank you!",aha thinking user constructor would see user never call constructor everything work user partial function instead understand design post forum suggesting partial function approach thank,issue,negative,negative,neutral,neutral,negative,negative
611547871,"Yep, it happens if I call those two lines as well.

<img width=""498"" alt=""Screen Shot 2020-04-09 at 11 06 01 PM"" src=""https://user-images.githubusercontent.com/2199875/78903863-b1921980-7ab6-11ea-8c29-0f1f423e8e38.png"">

Let me know if there's something else I should try.
",yep call two well screen shot let know something else try,issue,positive,neutral,neutral,neutral,neutral,neutral
611500528,"`Learner.predict` is a generic method that works across applications, so having it check the size automatically is kind of impossible. I'm surprised PyTorch did not give you a helpful shape error (usually that's how I would expect this to end). In any case the v2 approach as the channel inversion done in a separate transform will probably be less surprising to anyone :)

Docs of `Image` could certainly be improved to state they expect a tensor with channel first. Any PR doing this would be welcome.",generic method work across check size automatically kind impossible give helpful shape error usually would expect end case approach channel inversion done separate transform probably le surprising anyone image could certainly state expect tensor channel first would welcome,issue,positive,positive,positive,positive,positive,positive
611496815,"Since you have the model available, it's going to be easier for you test than me. `ModelOnCPU` just does
```
model.cpu()
model.to(previous_device)
```
Could you just try this (instead of `with ModelOnCPU(m) as m: pass`) and see if it still gives you garbage predictions?",since model available going easier test could try instead pas see still garbage,issue,negative,positive,positive,positive,positive,positive
611496678,"Thank you!
Maybe that should be added to the documentation or emphasized, since it doesn't seem to be obvious. (I am new to Neural networks, so maybe it's just that)

One thing that could possibly be improved, might be a check on shape before running Learner's `predict` method. As right now it silently kills the kernel and debugging this without any errors makes it that much harder. [Please see the forum post](https://forums.fast.ai/t/lesson-3-unet-learner-segmentation-inference/68089/3). In the current state it took 10x longer to find the problem than to find a solution :)",thank maybe added documentation since seem obvious new neural maybe one thing could possibly might check shape running learner predict method right silently kernel without much harder please see forum post current state took longer find problem find solution,issue,negative,positive,neutral,neutral,positive,positive
611494223,"`Image` expects tensors with channel first (since PyTorch will ultimately want that), so you should make sure you do that permutation if not using the fastai's method `open_image`.
In your case, maybe `pil2tensor` is what you need to use (takes a PIL image or a numpy array and does the permutation and conversion to tensor).

Please reopen if this does not solve your problem, but I believe your bug just comes from a shape error.",image channel first since ultimately want make sure permutation method case maybe need use image array permutation conversion tensor please reopen solve problem believe bug come shape error,issue,negative,positive,positive,positive,positive,positive
611492399,"The categorical and continuous names change during preprocessing so the processors need to be instantiated one after the other when you group them in a `TabularPreprocessor` (unless you are using preprocessors that have already been setup on a separate dataset). 
This is not a bug but what enable the whole pipeline to work (`FillMissing` will add new categorical variables that are then passed to `Categorize`)

The cat_names and cont_names should be passed to your preprocess function. As for `FillMissing`, using it with another strategy is just a matter of using `partial`: `partial(FillMissing, fill_strategy=FillStrategy.CONSTANT)`.",categorical continuous change need one group unless already setup separate bug enable whole pipeline work add new categorical categorize function another strategy matter partial partial,issue,negative,positive,neutral,neutral,positive,positive
611492298,"I might have found a more specific problem - I found that notebook throws an error when trying to display `Image` made from numpy array with error `ValueError: third dimension must be 3 or 4`

While Inspecting source code I noticed the `image2np` method which turns tensor back to numpy, switching it's shape
as a result when running
`image2np(torch.from_numpy(r_img).float()).shape` I get shape `(512,3,512)`
Which would explain why matplotlib is raising the error (as it is looking for 3rd element in the tuple).

Comparing `Image` Shape when initializing it from path with `open_image(image_path)` vs `Image(tensor)` I see that

`open_image(image_path).shape` -> (3,512,512)
`Image(tensor).shape` -> (512,512,3)

Is it a bug in the method or should the tensor be mutated in some way before passing it to Image initialization? 

UPDATE:

I've managed to get it work (and the predict method not to kill kernel ) with this:

```
r_img, h, w= resize_image(images[1])  
im = Image(torch.from_numpy(r_img).cpu().permute(2,1,0))
result = learner.predict(im)
```

And it seems to be running fine. But I have not seen anyone suggest this kind of approach. Is this how it is supposed to be used or is this a bug? 

(Found also a[ suggested approach in forum](https://forums.fast.ai/t/how-to-use-the-cnn-learner-to-predict-a-numpy-image/40702/3), but it is facing the same problem with wrong shape)",might found specific problem found notebook error trying display image made array error third dimension must source code method turn tensor back switching shape result running get shape would explain raising error looking element image shape path image tensor see image tensor bug method tensor way passing image update get work predict method kill kernel image result running fine seen anyone suggest kind approach supposed used bug found also approach forum facing problem wrong shape,issue,negative,positive,neutral,neutral,positive,positive
610968660,"Ok that makes sense, I pushed a new version, tell me if everything's fine for you",sense new version tell everything fine,issue,negative,positive,positive,positive,positive,positive
610936914,"Now I mean store it in the before fit event:
```
self.old_dl = dl
```
and then set it back in the after fit event:
```
self.data.train_dl = self.old_dl
```",mean store fit event set back fit event,issue,positive,positive,positive,positive,positive,positive
610933648,"> it's probably better to just keep a reference to the train_dl before changing it, storing it and then set it back at the end (in case the train_dl was not built with the defaults)

I'm not sure to fully understand what you advise there. You prefer the version I already committed where the `self.train_dl` was stored in the intermediate `dl` variable then re-assigned at the end to `self.train_dl` ? If so that's already what `OverSampling` is using so nothing's left to change 😊 ",probably better keep reference set back end case built sure fully understand advise prefer version already intermediate variable end already nothing left change,issue,positive,positive,positive,positive,positive,positive
610922085,"Yes, adding to `Oversampling` should be good. I was trying to reproduce the default `train_dl` but now that I think of it, it's probably better to just keep a reference to the train_dl before changing it, storing it and then set it back at the end (in case the train_dl was not built with the defaults).",yes good trying reproduce default think probably better keep reference set back end case built,issue,positive,positive,positive,positive,positive,positive
610843290,"Yes I agree, it was taken from the `OverSamplingCallback` but I also think it would look cleaner to remove the temporary assignment to `ds, dl` and have this: 

```python    
def on_train_begin(self, **kwargs):
         self.labels = self.data.train_dl.y.items
         assert np.issubdtype(self.labels.dtype, np.integer), ""Can only undersample integer values""
         _,self.label_counts = np.unique(self.labels,return_counts=True)
         if self.weights is None: self.weights = torch.DoubleTensor((1/self.label_counts)[self.labels])
         self.total_len_undersample = int(self.data.c*np.min(self.label_counts))
         sampler = WeightedRandomSampler(self.weights, self.total_len_undersample)
         self.data.train_dl = self.data.train_dl.new(shuffle=False, sampler=sampler)
```

If you agree with that change, I can also modify the `OverSamplingCallback` accordingly. Also I noticed that you added `drop_last=True`, should I add that ?",yes agree taken also think would look cleaner remove temporary assignment python self assert integer none sampler agree change also modify accordingly also added add,issue,positive,neutral,neutral,neutral,neutral,neutral
610682778,"Thanks for your PR, but there is a syntax error. Please fix before we can merge.",thanks syntax error please fix merge,issue,negative,positive,positive,positive,positive,positive
610626470,"Hi there, thanks for your PR! It looks good but I was thinking we should maybe put back the original training dataloader at the end of training to clean up? Something like
```
self.data.train_dl = self.data.train_dl.new(shuffle=True, drop_last=True, sampler=None)
```
What do you think?",hi thanks good thinking maybe put back original training end training clean something like think,issue,positive,positive,positive,positive,positive,positive
610369814,"@sgugger Thank you for the quick fix! Noted, will do so in future :)",thank quick fix noted future,issue,negative,positive,positive,positive,positive,positive
610365357,"Oh thanks for pointing it out! Note that in situations like this where you find the fix, you can directly suggest a PR :)",oh thanks pointing note like find fix directly suggest,issue,positive,positive,positive,positive,positive,positive
610139337,"> In any case, if the `ImageCleaner` doesnt work in colab it's because they don't support all ipywidget widgets, there is no exterior magic in it (if you look at the source code, we only import from widgets and Layout). Maybe there is workaround but I have no time figuring it out. I suspect it's possible we have to import the widgets from google.colab instead of the one from ipywidget but
> The issue is closed because there is nothing we can do about it on the fastai side.

Hi, I've just started fast.ai and I'm on part 1 v3 lesson 2: https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb

I'm just encountering this information that Google Colab is incompatible with parts of fast.ai's course, such as ImageCleaner. If I had known this earlier I would not have spent time getting used to Colab, which already seems to deviate from default Jupyter's normal key commands and UI. 

Perhaps you could remove it from the the list of suggested hosted platforms on fast.ai v3's intro page, or at least add a warning? It is listed as one of two free options. There is no mention of it being incompatible with parts of the course. 

Is there another hosted service that runs Jupyter Notebook rather than Lab? I don't have a nice GPU so I need a hosted option. Thanks for any advice.",case doesnt work support exterior magic look source code import layout maybe time suspect possible import instead one issue closed nothing side hi part lesson information incompatible course known would spent time getting used already deviate default normal key perhaps could remove list page least add warning listed one two free mention incompatible course another service notebook rather lab nice need option thanks advice,issue,negative,positive,positive,positive,positive,positive
609804256,"Check out this pull request on&nbsp; <a href=""https://app.reviewnb.com/fastai/fastai/pull/2536""><img align=""absmiddle""  alt=""ReviewNB"" height=""28"" class=""BotMessageButtonImage"" src=""https://raw.githubusercontent.com/ReviewNB/support/master/images/button_reviewnb.png""/></a> 

 You'll be able to see Jupyter notebook diff and discuss changes. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>.",check pull request able see notebook discus powered,issue,negative,positive,positive,positive,positive,positive
609473622,"Thanks! Just changed to fit our usual style (if statements with only one line are set on the same line in fastai, to save vertical space).",thanks fit usual style one line set line save vertical space,issue,positive,positive,positive,positive,positive,positive
609424023,"> Thanks but since it changes the behavior of the plot, I would like this to be controlled by a flag that defaults to False to not surprise anyone (I just tried it and it's actually less readable for me, probably because I'm used to those plots). Could you add that?

Of course why not! I'm on it..",thanks since behavior plot would like flag false surprise anyone tried actually le readable probably used could add course,issue,positive,negative,neutral,neutral,negative,negative
609422472,"Thanks but since it changes the behavior of the plot, I would like this to be controlled by a flag that defaults to False to not surprise anyone (I just tried it and it's actually less readable for me, probably because I'm used to those plots). Could you add that?",thanks since behavior plot would like flag false surprise anyone tried actually le readable probably used could add,issue,positive,negative,neutral,neutral,negative,negative
609422127,Yes but it is much faster from our experiments. There was a comment in the code that explained that. Don't know where it went.,yes much faster comment code know went,issue,negative,positive,positive,positive,positive,positive
607797150,"Please post feature requests on the [forum](https://forums.fast.ai/). We keep issues for known bugs only. As it has been asked several times, we will take into consideration, but since it's quite a breaking change, it will be for v2 only.",please post feature forum keep known several time take consideration since quite breaking change,issue,negative,neutral,neutral,neutral,neutral,neutral
606589180,"Thanks for your PR!
You are welcome to present those changes in your fork of this project, but we are just minimally maintaining the old versions of the course and do not wish to add substantial changes (other than trivial bug fix or typo correction) to them.
",thanks welcome present fork project minimally old course wish add substantial trivial bug fix typo correction,issue,positive,positive,positive,positive,positive,positive
605655532,The same thing is also mentioned in the article [Deep Learning on a Shoestring](https://docs.fast.ai/tutorial.resources.html). If you would kindly update that also.,thing also article deep learning shoestring would kindly update also,issue,negative,positive,positive,positive,positive,positive
605649945,Yes the default was changed because this function breaks things in some cases. Will adapt the docs.,yes default function adapt,issue,negative,neutral,neutral,neutral,neutral,neutral
603884904,"I ran the following commands from the https://course.fast.ai/start_gradient.html instructions:

```
pip install fastai --upgrade
cd course-v3
git pull
```

Still getting this error. Maybe something is wrong with the Gradient container that someone set up?",ran following pip install upgrade git pull still getting error maybe something wrong gradient container someone set,issue,negative,negative,negative,negative,negative,negative
603880675,"@sgugger I believe I am using the new version of the course. I followed the setup instructions. Please help me understand what's wrong.

![Selection_999(304)](https://user-images.githubusercontent.com/148813/77548995-0f571c80-6e8e-11ea-9cff-c374169de93d.png)
",believe new version course setup please help understand wrong,issue,negative,negative,negative,negative,negative,negative
603213511,Please follow the issue template.,please follow issue template,issue,negative,neutral,neutral,neutral,neutral,neutral
599418632,"You can still call `.show()`, which should trigger a warning instead of an error. And yes, in general, you will need to clamp your values between 0 and 1 before displaying the images.

You do no need to do this to train your model however, which is why the fastai library does not do this automatically after applying some operations that may give values greater than 1, such as an interpolation.

I'm curious as to why it happened though. It may be linked to the new behavior of `grid_sample` in PyTorch in v1.4.0, so I'd stay with PyTorch <= 1.3.1 while using fastai v1.",still call trigger warning instead error yes general need clamp need train model however library automatically may give greater interpolation curious though may linked new behavior stay,issue,negative,positive,positive,positive,positive,positive
598714231,"Closing the issue then. In general, please use the forum for problems like this :)",issue general please use forum like,issue,positive,positive,neutral,neutral,positive,positive
598706925,"> Hi @xiaosuzhang ,
> 
> Can you check the num_workers passed in the dataloader? It should be set to 0 in Windows based systems as Pytorch's Multiworkers don't work well on windows.
> If it is a tutorial, you need to pass the argument explicitly else it will default to 4 i guess, which is why it's failing

Thank's for you solution. It has already worked.",hi check set based work well tutorial need pas argument explicitly else default guess failing thank solution already worked,issue,negative,neutral,neutral,neutral,neutral,neutral
598635452,"Hi @xiaosuzhang ,

Can you check the num_workers passed in the dataloader? It should be set to 0 in Windows based systems as Pytorch's Multiworkers don't work well on windows. 
If it is a tutorial, you need to pass the argument explicitly else it will default to 4 i guess, which is why it's failing",hi check set based work well tutorial need pas argument explicitly else default guess failing,issue,negative,neutral,neutral,neutral,neutral,neutral
598203754,"In v1, there will be no change to the current implementation. You can subclass `ImageMask` to implement your defaults then define a custom `SegmentationItemList` using it. v2 will be more flexible.",change current implementation subclass implement define custom flexible,issue,negative,neutral,neutral,neutral,neutral,neutral
597167716,"Ah my bad, I though you were doing this at each forward pass cause I dind't read properly. We can certainly add this. Sorry for the misunderstanding!",ah bad though forward pas cause read properly certainly add sorry misunderstanding,issue,negative,negative,negative,negative,negative,negative
597165468,"Hi @sgugger 

> Well if that is the case, then the weights will never be changed, so the PR has no use there either.

This is the issue that the PR fixes. When a Pytorch embedding is created with a padding idx then the weights at the padding index are set to zero. If you subsequently initialise the embedding then those zeros in the padding index are overwritten with something that is non zero. The PR just sets those weights back to zero. I've attached a screenshot of some code in case what I am saying is not clear.

![Screenshot 2020-03-10 at 15 35 20](https://user-images.githubusercontent.com/858721/76329713-d4c57f80-62e4-11ea-9536-14390425cb4e.png)

The BOS token I can understand. Then network needs to learn its representation and every record the data set will have one, but I think this is different for padding. The number of padding tokens used is dependent on the length of the sequence relative to the longest sequence in the batch.

at inference why should this
`<BOS><THE><FILM><WAS><GREAT><PAD><PAD><PAD>`

be different from this?
`<BOS><THE><FILM><WAS><GREAT>`

If those padding tokens are non-zero I don't see how they can be equivalent.









",hi well case never use either issue padding padding index set zero subsequently padding index something non zero back zero attached code case saying clear token understand network need learn representation every record data set one think different padding number padding used dependent length sequence relative sequence batch inference film great pad pad pad different film great padding see equivalent,issue,positive,positive,positive,positive,positive,positive
597129505,"> As such the padded space caries no information relating to the input and its gradients should be zero, which cannot be the case unless their values are zero

Well if that is the case, then the weights will never be changed, so the PR has no use there either. But if the model does encounter a padding token for which the outputs are not discarded, then it will compute a gradient that is meant to make the loss lower. So in that case, I don't see why updating those weights would be hurtful, the model will just learn a semantic representation of the padding token, the same way it learns a representation of the BOS token.",space caries information input zero case unless zero well case never use either model encounter padding token compute gradient meant make loss lower case see would hurtful model learn semantic representation padding token way representation token,issue,negative,neutral,neutral,neutral,neutral,neutral
597127746,"Hi @sgugger thanks for the reply. Maybe I am missing something, but I can't think of a scenario where the network should learn padding parameters. In fact I thought the entire point of them was to allow the network to handle tensors of variable lengths, with the padding used to fill up the space of the longest tensor. As such the padded space caries no information relating to the input and its gradients should be zero, which cannot be the case unless their values are zero ( or if Pytorch sets the gradients to be zero for the padding index internally). If they are non zero then any subsequent affine layer gets affected and I can't see how that could possibly be correct?",hi thanks reply maybe missing something ca think scenario network learn padding fact thought entire point allow network handle variable padding used fill space tensor space caries information input zero case unless zero zero padding index internally non zero subsequent affine layer affected ca see could possibly correct,issue,negative,neutral,neutral,neutral,neutral,neutral
597073832,"Ok with this. I will revisit and implement my way to avoid the multiple conversions if I have time someday.
Thanks a lot for investigating and fixing this bug!",revisit implement way avoid multiple time someday thanks lot investigating fixing bug,issue,negative,positive,neutral,neutral,positive,positive
597073460,"Note sure this is desirable: the network can learn something about the padding index that could be helpful (otherwise it would leave it to zero). I'd leave this as is, unless there is compelling evidence it changes anything.",note sure desirable network learn something padding index could helpful otherwise would leave zero leave unless compelling evidence anything,issue,positive,positive,positive,positive,positive,positive
596784119,"I implemented option 2.b. of @martinsotir's benchmark. I didn't feel familiar enough with the code and coding guidelines to change `cm` to a numpy array and then change all the subclasses. If it is the solution that you prefer, feel free to change it and close this request. You could also disregard any of these changes but I think some people could benefit from them.",option feel familiar enough code change array change solution prefer feel free change close request could also disregard think people could benefit,issue,positive,positive,positive,positive,positive,positive
596737253,"I think cm can become a numpy array, with the conversion to torch tensor done only once at `on_epoch_end`. Then, all subclasses would just need to call `super().on_epoch_end()` at the start of their `super().on_epoch_end`.",think become array conversion torch tensor done would need call super start super,issue,positive,positive,positive,positive,positive,positive
596733321,"A quick bench:

```python
n_classes = 20 # 2000
batch_size = 256

targs = torch.randint(low=0, high=n_classes, size=(batch_size,))
preds = torch.randint(low=0, high=n_classes, size=(batch_size,))
```
### Option 0: With tensor broadcasting (orignal source)

```python
cm = torch.zeros((n_classes, n_classes), device=torch.device('cpu'), dtype=torch.int32)
x = torch.arange(0, n_classes)
cm = ((preds==x[:, None]) & (targs==x[:, None, None])).sum(dim=2, dtype=torch.float32)
```

### Option 1:  with loop indexing

```python
%%timeit
cm = torch.zeros((n_classes, n_classes), device=torch.device('cpu'), dtype=torch.int32)
for i in range(batch_size):
  cm[targs[i], preds[i]] += 1
```

### Option 2.a:  With np.add.at + numpy array

```python
%%timeit
cm = np.zeros((n_classes, n_classes), dtype=np.int32)
np.add.at(cm, (targs ,preds), 1)
```

### Option 2.b With np.add.at + tensor -> numpy -> tensor conversion

```python
%%timeit
cm = torch.zeros((n_classes, n_classes), device=torch.device('cpu'), dtype=torch.int32)
cm_temp_numpy = cm.numpy()
np.add.at(cm_temp_numpy, (targs ,preds), 1)
cm = torch.from_numpy(cm_temp_numpy)
````

### Results

|            | `n_classes= 20` | `n_classes= 2000` |
|------------|-------------------|---------------------|
| 0.  tensor broadcasting + sum  | 480 µs            | 3.65 s              |
| 1.  loop indexing | 6.26 ms           | 18.2 ms             |
| 2.a  np.add.at| 86.9 µs           | 12.1 ms             |
| 2.b np.add.at + tensor <-> numpy conversion | 95.5 µs           | 11.8 ms             |

`np.add.at` is fast in both situations. If we want `cm` to remain a torch tensor (keeping the API unchanged), the torch-> numpy -> torch conversion seems to be quick enough (no copy in most cases I presume ?).",quick bench python option tensor orignal source python none none none option loop indexing python range option array python option tensor tensor conversion python tensor sum loop indexing tensor conversion fast want remain torch tensor keeping unchanged torch conversion quick enough copy presume,issue,negative,positive,positive,positive,positive,positive
596717902,"The loop would probably be very slow. If numpy has a function that does the trick, maybe the conversion to numpy would be the least disruptive (we don't really want to make substantial changes to v1 right now, since v2 is our main focus).",loop would probably slow function trick maybe conversion would least disruptive really want make substantial right since main focus,issue,positive,positive,neutral,neutral,positive,positive
596715401,"Hi @sgugger , I have been working with @Shadeswalker on this issue.

We encounter this slowdown using Recall and Precision metrics with a Fastai learner (each metric computation will hang the CPU for ~4s for each batch when N_labels=10k). To my knowledge this issue has been fixed in fastaiV2 by using scikit-learn metrics. For this PR we were looking for the least invasive patch.

> Would it be acceptable to compute the confusion matrix at the end of the phase instead of at the end of each batch?

Seems a good solution to us, though it may be disruptive depending on how this metric used by fastai users ? (I am relatively new to the fastai library :) ). This would also require storing predictions and targets for all the validation datasets and it may increase memory usage when N_val_samples >> N_labels^2.

> gives a +1 on cm[0,0], but it should give a +2, given the fact there are 2 targets and predictions 0.

Good catch. Instead of indexing `cm` directly we could use a loop, or use `np.add.at(cm, (targ, pred), 1)` if we use a numpy array instead of the CPU torch.tensor for `cm` (`np.add.at` is [not available for pythorch when indices are multidimensional](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.index_add_)).",hi working issue encounter slowdown recall precision metric learner metric computation batch knowledge issue fixed metric looking least invasive patch would acceptable compute confusion matrix end phase instead end batch good solution u though may disruptive depending metric used relatively new library would also require validation may increase memory usage give given fact good catch instead indexing directly could use loop use use array instead available index multidimensional,issue,positive,positive,positive,positive,positive,positive
596649054,"> I understand the problem and the slowdown, but your suggested change does not produce the same result:
> 
> ```
> targ = tensor([0,2,1,3,0])
> pred = tensor([0,1,1,3,0])
> cm[targ, pred] += 1
> ```
> 
> gives a +1 on cm[0,0], but it should give a +2, given the fact there are 2 targets and predictions 0.

Ah yes, my bad!

> Would it be acceptable to compute the confusion matrix at the end of the phase instead of at the end of each batch?

If the initialization of the CM is not done at each batch I don't see any issues with that.",understand problem slowdown change produce result tensor tensor give given fact ah yes bad would acceptable compute confusion matrix end phase instead end batch done batch see,issue,negative,negative,negative,negative,negative,negative
596645487,"I understand the problem and the slowdown, but your suggested change does not produce the same result:
```
targ = tensor([0,2,1,3,0])
pred = tensor([0,1,1,3,0])
cm[targ, pred] += 1
```
gives a +1 on cm[0,0], but it should give a +2, given the fact there are 2 targets and predictions 0.

Would it be acceptable to compute the confusion matrix at the end of the phase instead of at the end of each batch?",understand problem slowdown change produce result tensor tensor give given fact would acceptable compute confusion matrix end phase instead end batch,issue,negative,neutral,neutral,neutral,neutral,neutral
596275727,"You are using the old course with version 1.4.0 of PyTorch. It is compatible with version 0.3 as is expressed in the [requirements](https://github.com/fastai/fastai/blob/27ab982e94a75cd81920b5ab6155f6961d69174c/environment.yml#L94) for the old course. If you do not follow the installations instructions for the old course, do not expect it to work. If you want to use more recent versions of PyTorch, please follow the [last version of our course](https://course.fast.ai/).",old course version compatible version expressed old course follow old course expect work want use recent please follow last version course,issue,negative,positive,neutral,neutral,positive,positive
596134275,"Thanks for your PR! There is no plan to keep the old course up to date with the new versions of the libraries (your code will fail with all people having an old version btw).
We can constrain the version of sklearn to a maximum, but not make changes like this.",thanks plan keep old course date new code fail people old version constrain version maximum make like,issue,negative,positive,neutral,neutral,positive,positive
596134138,"This is because you are training on multiple GPUs without using fastai distributed module, so you see the progress bar of each GPU. Your epochs are not repeated, no.",training multiple without distributed module see progress bar repeated,issue,negative,neutral,neutral,neutral,neutral,neutral
596018608,"all code
'''
from fastai import *
from fastai.vision import *
from fastai.callbacks.hooks import *
from fastai.distributed import *
import argparse
from fastai.callbacks import *
from sklearn.metrics import mean_absolute_error,r2_score,mean_absolute_error
from fastai.metrics import error_rate
np.random.seed(42)

parser = argparse.ArgumentParser()
parser.add_argument(""--local_rank"", type=int)
args = parser.parse_args()
torch.cuda.set_device(args.local_rank)
torch.distributed.init_process_group(backend='nccl', init_method='env://')

DATA_PATH = '***'
data = ImageDataBunch.from_folder(DATA_PATH, train=""."", valid_pct=0.2, ds_tfms=get_transforms(), size=224, bs=64, num_workers=4).normalize(imagenet_stats)
#data.show_batch(rows=3, figsize=(15,15))

wd=1e-2
learn = cnn_learner(data,models.resnet101,metrics=error_rate, wd= wd)
plt.switch_backend('Agg')
#learn.lr_find()
#learn.recorder.plot()
#plt.savefig(""ori.png"")

def newtrain():
        lr = 1e-3
        learn.fit_one_cycle(20, slice(lr), pct_start=0.8, callbacks=[SaveModelCallback(learn, every='epoch', name = 'stage1', monitor='dice')])
        lr_find(learn)
        learn.recorder.plot_lr()
        learn.save('stage-1')
        plt.savefig(""liver_stage1.png"")
newtrain()
'''
and here are my training step:
'''
epoch     train_loss  valid_loss  error_rate  time    
epoch     train_loss  valid_loss  error_rate  time    ---------------------------------------------------| 0.00% [0/510 00:00<00:00]
0         0.900816    0.665730    0.204910    03:55                                                                                            
0         0.853243    0.636195    0.204910    03:56                                                                                     
1         0.713103    0.548370    0.182748    03:51                                                                                            
1         0.707130    0.548361    0.182748    03:52                                                                                     
2         0.611245    0.480037    0.173258    03:51                                                                                            
2         0.613976    0.499895    0.173258    03:50     -------------------------------------------------| 0.00% [0/510 00:00<00:00]    
3         0.547943    0.450105    0.164503    03:51                                                                                            
3         0.555117    0.454073    0.164503    03:50                                                                                     
4         0.525317    0.431651    0.157830    03:51                                                                                            
4         0.520752    0.429502    0.157830    03:52                                                                                     
5         0.503877    0.402140    0.147545    03:51                                                                                            
5         0.485039    0.409282    0.147545    03:50                                                                                     
6         0.471035    0.384446    0.138545    03:51                                                                                            
6         0.437211    0.386524    0.138545    03:52                                                                                     
7         0.441435    0.367307    0.129791    03:52                                                                                            
7         0.443754    0.368157    0.129791    03:51                                                                                     
8         0.441576    0.344207    0.122873    03:53                                                                                            
8         0.421347    0.345141    0.122873    03:52                                                                                     
9         0.413469    0.336272    0.119995    03:50                                                                                             
9         0.404962    0.337356    0.119995    03:50                                                                                      
10        0.392405    0.316121    0.114118    03:52                                                                                             
10        0.389751    0.327623    0.114118    03:52                                                                                      
11        0.388876    0.318401    0.114301    03:51                                                                                             
11        0.388485    0.328782    0.114301    03:52                                                                                      
12        0.393110    0.303263    0.105730    03:51                                                                                             
12        0.365484    0.308623    0.105730    03:52                                                                                      
13        0.382581    0.298208    0.104690    03:50                                                                                             
13        0.348877    0.303230    0.104690    03:51                                                                                      
14        0.355841    0.294234    0.098445    03:50                                                                                             
14        0.348680    0.289573    0.098445    03:51                                                                                      
15        0.346630    0.286972    0.099180    03:51                                                                                             
15        0.340996    0.284068    0.099180    03:50                                                                                      
16        0.333279    0.280358    0.095506    03:50                                                                                             
16        0.362145    0.278046    0.095506    03:50                                                                                      
17        0.339084    0.270761    0.095139    03:50                                                                                             
17        0.329470    0.277648    0.095139    03:50                                                                                      
18        0.329258    0.265324    0.091282    03:50                                                                                             
18        0.335396    0.267863    0.091282    03:51                                                                                      
19        0.310762    0.264930    0.090731    03:50                                                                                             
19        0.318840    0.264458    0.090731    03:50                                                                                      
epoch     train_loss  valid_loss  error_rate  time    
epoch     train_loss  valid_loss  error_rate  time    --------------------------------------------------| 0.00% [0/510 00:00<00:00]
0         1.176450    #na#        00:35                                                                                                     
0         0.868749    #na#        00:35        
'''
it looks like it trains repeat,every epoch has twice
",code import import import import import import import import parser data learn data slice learn name learn training step epoch time epoch time epoch time epoch time na na like repeat every epoch twice,issue,negative,neutral,neutral,neutral,neutral,neutral
595789582,I don't understand what your problem is. Could you explain it a bit better? Also make sure to put all your code between ``` so that we can see the formatting. ,understand problem could explain bit better also make sure put code see,issue,negative,positive,positive,positive,positive,positive
595279844,"@sgugger Yes, it was saved with the SaveModelCallback which uses `learn.save()`. Any way to get the encoder out in order to train a decoder?",yes saved way get order train,issue,positive,neutral,neutral,neutral,neutral,neutral
595262989,"One line of code is not enough to reproduce. It looks like you are trying to use `load_encoder` with  model you saved using `learn.save()` and not `learn.save_encoder`, but I can't be sure without seeing the whole code.

Please reopen with more details if needed.",one line code enough reproduce like trying use model saved ca sure without seeing whole code please reopen,issue,positive,positive,positive,positive,positive,positive
594554142,It looks like you want to use v0.7 of fastaim for which should not use a conda install but follow the instructions [here](https://github.com/fastai/fastai/tree/master/old).,like want use use install follow,issue,negative,neutral,neutral,neutral,neutral,neutral
594434324,@austinmw I'm running into a similar error while running fastai in Kaggle and trying to load a DPN model. What solution did you come up with?,running similar error running trying load model solution come,issue,negative,neutral,neutral,neutral,neutral,neutral
594423148,"from fastai.transforms import tfms_from_model, CropType
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
ModuleNotFoundError: No module named 'fastai.transforms'

Platform: Linux

i have installed fastai using 
conda install -c fastai fastai",import recent call last file line module module platform install,issue,negative,neutral,neutral,neutral,neutral,neutral
594157111,"> None of the software we depend on seems to be following it either.

Just curious, I raised this issue partially because [pytorch is pretty good about it](https://github.com/pytorch/pytorch/issues/14693), do you have any dependencies in mind that don't follow the spec? It seems like the only ones I can see are some dev dependencies but that doesn't matter to end users.",none depend following either curious raised issue partially pretty good mind follow spec like see dev matter end,issue,positive,positive,positive,positive,positive,positive
594000700,"I was running into this same issue on my mac. Ran fine with `num_workers=0` but not with more than zero unless I set the pixels to 80 or lower.

I made a few changes and now things are working:
- switched from python 3.6.8 to 3.7.6
- increased shared memory settings as described here: http://flummox-engineering.blogspot.com/2014/05/increasing-shared-memory-for-os-x.html
- installed latest versions of all libs as of this writing installed from pip

Unfortunately I did all of these things at once so it's unclear which of them actually solved the issue for me. If I have some time later, I may try to pinpoint but in a bit of a rush right now.

I'm now able to train with `num_workers=16` and 500 pixel images without issue. I hope this helps someone.",running issue mac ran fine zero unless set lower made working switched python memory latest writing pip unfortunately unclear actually issue time later may try pinpoint bit rush right able train without issue hope someone,issue,negative,positive,positive,positive,positive,positive
593978478,"There is no plan to respect that spec in the future, no. None of the software we depend on seems to be following it either. In general we use the [forum](https://forums.fast.ai/) to discuss feature requests, so I encourage you to open a topic there if you want to discuss this further with the community.",plan respect spec future none depend following either general use forum discus feature encourage open topic want discus community,issue,positive,positive,neutral,neutral,positive,positive
593455376,Please follow the template to report an issue. There is absolutely nothing we can do with so little information. ,please follow template report issue absolutely nothing little information,issue,negative,positive,neutral,neutral,positive,positive
592921300,"@renato145 

So in the `__init__` method, I have added `self.c = 2` as suggested [here](https://docs.fast.ai/basic_data.html) for binary classification. I have also attached my [code](https://gist.github.com/Flock1/1bbf76b6fac2269b9ab005e463c67feb) in case you want to have a look at it. When I run the code, I get the following error:

> AttributeError: ‘dict’ object has no attribute ‘shape’

And when I try to run `datas.show_batch()`, I get this:

>AttributeError: ‘NumbersDataset’ object has no attribute ‘x’

I also tried to return the `torch tensor` as an array instead of a dictionary but I still got the above error. 
When I use `DataBunch.create` instead of `DataBunch`, I get this:

>TypeError: new() argument after * must be an iterable, not builtin_function_or_method

In the end, I also added `datas.c = 1` (since the final image is a binary image), I still get the above error.
What should I do?
",method added binary classification also attached code case want look run code get following error object attribute shape try run get object attribute also tried return torch tensor array instead dictionary still got error use instead get new argument must iterable end also added since final image binary image still get error,issue,negative,positive,neutral,neutral,positive,positive
590133808,"Hi, if you want to do regression with the `unet_learner` you probably will want to have 1 class (or 3 if you want RBG images as output). You will also need to make sure that you are using an appropriate loss_function for the case. It will be good for you to check the super-resolution approach on lesson 7.",hi want regression probably want class want output also need make sure appropriate case good check approach lesson,issue,positive,positive,positive,positive,positive,positive
589552964,"@renato145, I have one more question. This was about classification. What if I want to do a regression problem? Let's say, image reconstruction using UNet. I can't have number of classes there",one question classification want regression problem let say image reconstruction ca number class,issue,negative,neutral,neutral,neutral,neutral,neutral
589225426,"Please take your time to learn v2, but every PR is always welcome. Worst case scenario is we ask you to rewrite some bits of it if they don't go well with the rest of the code, and we don't bite ;)",please take time learn every always welcome worst case scenario ask rewrite go well rest code bite,issue,negative,negative,neutral,neutral,negative,negative
589170563,Last comment deleted: I realize it's not useful until I'm warmed up to v2 and ready to contribute.,last comment realize useful warmed ready contribute,issue,positive,positive,positive,positive,positive,positive
588601921,"@renato145, I found this while scrolling through the page
`data = DataBunch.create(train_ds, valid_ds, bs=2, num_workers=1)`
Maybe I'll need to `create` a DataBunch for FastAI to properly get it.  And yeah, I also found the answer to my question:
`self.c = 2`",found page data maybe need create properly get yeah also found answer question,issue,positive,neutral,neutral,neutral,neutral,neutral
588583385,"I have checked, and the `classes` parameter works for the the `DataBlock` api. Since you are using a custom dataloader I would recommend that you add `c` in your `NumbersDataset`:
```python
class NumbersDataset():
    def __init__(self, inputs, labels):
        self.X = inputs
        self.y = labels
        self.c = something_that_calculates_the_number_of_classes(labels)
```",checked class parameter work since custom would recommend add python class self,issue,negative,neutral,neutral,neutral,neutral,neutral
588577796,"@renato145, thank you very much for the reply. I kinda figured out by going to the source 😅. However, I want to know what type does it accept? I gave the number of classes both in `list` as well as `int` format but it didn't accept it. ",thank much reply figured going source however want know type accept gave number class list well format accept,issue,positive,positive,positive,positive,positive,positive
588546198,"Hi, in fastai 'c'  usually refers to the number of classes, for a segmentation databunch to know the number of classes, you need to specify which classes to use.
`data = DataBunch(train_dl = dataloader_train, valid_dl = dataloader_valid, classes=URCLASSES)`

Let me know if this work, I cant check right now.
[https://forums.fast.ai/t/help-on-segmentationitemlist/35046](url)",hi usually number class segmentation know number class need specify class use data let know work cant check right,issue,negative,positive,neutral,neutral,positive,positive
588334559,"Okay, is there an alternative function for `proc_df` in the new course as well?",alternative function new course well,issue,negative,positive,positive,positive,positive,positive
588291225,Agree that v2 is **the** focus.  Will keep the PR minimal.  Thx for pointing out the challenge with batches of different lengths.,agree focus keep minimal pointing challenge different,issue,negative,negative,neutral,neutral,negative,negative
588281482,"The old course is not compatible with v1, as is written at the top of every notebook. That's why the function `train_cat` is not in v1, there is another approach used that you can discover on the [new course](https://course.fast.ai/).",old course compatible written top every notebook function another approach used discover new course,issue,negative,positive,positive,positive,positive,positive
588278652,"Feature request should be done one the [forum](https://forums.fast.ai/). Some people have written a custom callback to enable this.
Having it in the library is not a priority at the moment as we are focusing on the development of v2. It will probably be featured in v2.",feature request done one forum people written custom enable library priority moment development probably featured,issue,negative,neutral,neutral,neutral,neutral,neutral
588278063,"I can't think of anything, but you would have more help for this on the [forum](https://forums.fast.ai/). We keep GitHub for bugs only, most of the discussion and debugging happens there :)

Closing this issue in the meantime. Please reopen if you discover a specific bug whil investigating the matter more.",ca think anything would help forum keep discussion issue please reopen discover specific bug investigating matter,issue,positive,neutral,neutral,neutral,neutral,neutral
588276002,"The dynamic aspect of text classification (batches with various lengths) will make it hard to get real performance in a distributed fashion, and what is needed is probably a custom sampler. This is not something we are keen on tackling ourselves as our focus is on v2 right now. A PR with the dirty fix can certainly be merged as a first step. ",dynamic aspect text classification various make hard get real performance distributed fashion probably custom sampler something keen tackling focus right dirty fix certainly first step,issue,negative,negative,neutral,neutral,negative,negative
588250863,"So I was able to adjust the script to make it much faster and now it is not hanging anymore.
1- I have replaced the tokenizer with the basic tokenizer because my data is already tokenized.
```
tok = Tokenizer(
    pre_rules = [],
    post_rules = [],
    n_cpus=tok_paralle_threads,
    tok_func=BaseTokenizer)
```
2- I added an if statement to only store models when the world rank is 0 and make all other nodes to wait it.
```
if i % 500 == 0 and world_rank == 0:
        learn.save_encoder(saveEncoderFilePath + 
                       '-' + str(run) +
                       '-' + str(epoch) +
                       '-' + str(i))
        learn.save(SaveModelFilePath +
               '-' + str(run) +
                '-' + str(epoch) +
                '-' + str(i))
        tensor = torch.ones(1)
        torch.distributed.all_reduce(tensor, op=dist.reduce_op.SUM)
```
3- changed from_csv to from_df.
```
    df_train = pd.read_csv(trainFolderPath+trainFile,header=None)

    data_lm = TextLMDataBunch.from_df(trainFolderPath,
                        df_train,
                        df_valid,
                        text_cols=0,
                        bs=batchSize,
                        vocab=bfdVocab,
                        tokenizer=tok,
                        include_eos=False,
                        bptt=maxSequenceLength)
```

Here is the new code:

```
from fastai.text import *
from fastai.callbacks.tracker import *
#from fastai.callbacks.tensorboard import *
from pytorch_lamb import Lamb
import os
import glob
from fastai.distributed import *
import argparse
import pandas as pd

vocabFilePath = 'vocab.txt'
trainFolderPath = '/train/'
trainFilesGlob = 'train*'
validFileName =  'valid.txt'
validFilePath = trainFolderPath + validFileName
trainFiles = [os.path.basename(x) for x in glob.glob(trainFolderPath+trainFilesGlob )]
numberOfTrainingFiles = len(trainFiles)
saveEncoderFilePath = 'lm_encoder'
SaveModelFilePath = 'model'
project_id = 'rnn_lm'
tboard_path = Path('data/tensorboard/' + project_id)

#print(trainFiles)

batchSize = 128
maxSequenceLength = 100
drop_mult = 0.1
qrnn = False
bidir = True

epochs = 300
lr = 1e-3
run = 1

tok_paralle_threads = 42

world_size = int(os.environ['OMPI_COMM_WORLD_SIZE'])
world_rank = int(os.environ['OMPI_COMM_WORLD_RANK'])
local_rank = int(os.environ['OMPI_COMM_WORLD_LOCAL_RANK'])

parser = argparse.ArgumentParser()
parser.add_argument('--backend', default='nccl', type=str,
                    help='pytorch dist backend')
parser.add_argument('--sharedfile', default=None, type=str,
                    help='sharedfile for nccl init')
args = parser.parse_args()
#torch.cuda.set_device(args.local_rank)
torch.cuda.set_device(local_rank)

#torch.distributed.init_process_group(backend='nccl', init_method='env://')
sharedfile='file://%s'%(args.sharedfile)
if args.backend == 'ddl':
    torch.distributed.init_process_group(backend=args.dist_backend)
    world_size = dist.get_world_size()
    world_rank = dist.get_rank()
else:
    torch.distributed.init_process_group(args.backend, init_method=sharedfile,
                            rank=world_rank, world_size=world_size)

# Reading vocab file
with open(vocabFilePath, 'r') as file:
    tokens = file.read().replace('\n', '')
    
# Generate vocab class
bfdVocab = text.transform.Vocab.create(tokens, max_vocab=1000, min_freq=1)

# Print vocab size
print('Vocab size is ' + str(len(bfdVocab.itos)))

# Generate tokinizer
tok = Tokenizer(
    pre_rules = [],
    post_rules = [],
    n_cpus=tok_paralle_threads,
    tok_func=BaseTokenizer)

def modelConfig(qrnn:bool=False,bidir:bool=False):
    config = awd_lstm_lm_config.copy()
    config['emb_sz'] = 512
    config['n_hid'] = 4096
    config['n_layers'] = 4
    config['qrnn'] = qrnn
    config['bidir'] = bidir
    return config

df_valid = pd.read_csv(validFilePath,header=None)

for epoch in range(0,epochs):
  print('Epoch: ' + str(epoch))
  for i, trainFile in enumerate(trainFiles):
    '''
    data_lm = TextLMDataBunch.from_csv(trainFolderPath, 
                                       csv_name=trainFile,
                                       valid_pct=0.001,
                                       test = validFilePath,
                                       text_cols=0,
                                       bs=batchSize,
                                       vocab=bfdVocab,
                                       tokenizer=tok, 
                                       include_eos=True,
                                       bptt=maxSequenceLength)
    '''
    df_train = pd.read_csv(trainFolderPath+trainFile,header=None)

    data_lm = TextLMDataBunch.from_df(trainFolderPath,
                        df_train,
                        df_valid,
                        text_cols=0,
                        bs=batchSize,
                        vocab=bfdVocab,
                        tokenizer=tok,
                        include_eos=False,
                        bptt=maxSequenceLength)

    if epoch == 0 and i == 0:
      learn = language_model_learner(data_lm, 
                              arch=AWD_LSTM, 
                              pretrained=False,
                              drop_mult=drop_mult,
                              config=modelConfig(qrnn=qrnn,bidir=bidir),
                              opt_func=Lamb,
                              metrics=[accuracy, Perplexity()]).to_fp16().to_distributed(local_rank)
      #learn.callback_fns.append(partial(LearnerTensorboardWriter, 
      #                              base_dir=tboard_path, 
      #                              name='lstm_4_layers'))
    else:
      learn.data = data_lm
    
    #if os.path.exists(saveEncoderFilePath):
    #  learner.load_encoder(saveEncoderFilePath)               
    
    learn.fit_one_cycle(1, lr)

    del data_lm

    if i % 100 == 0 and world_rank == 0::
        print('Epoch: ' + str(epoch) + ' file: ' + str(i) + ' finished.')

    if i % 500 == 0 and world_rank == 0:
        learn.save_encoder(saveEncoderFilePath + 
                       '-' + str(run) +
                       '-' + str(epoch) +
                       '-' + str(i))
        learn.save(SaveModelFilePath +
               '-' + str(run) +
                '-' + str(epoch) +
                '-' + str(i))
        tensor = torch.ones(1)
        torch.distributed.all_reduce(tensor, op=dist.reduce_op.SUM)
```

Do you have any more suggestions to make it more optimized?",able adjust script make much faster hanging basic data already added statement store world rank make wait run epoch run epoch tensor tensor new code import import import import lamb import o import import import import path print false true run parser else reading file open file generate class print size print size generate return epoch range print epoch enumerate test epoch learn accuracy perplexity partial else print epoch file finished run epoch run epoch tensor tensor make,issue,negative,negative,neutral,neutral,negative,negative
588095309,"@renato145, I am using `DataBunch` object. But still I am getting the error. This is what I am doing:

```
class NumbersDataset():
    def __init__(self, inputs, labels):
        self.X = inputs
        self.y = labels

    def __len__(self):
        return len(self.X)

    def __getitem__(self, idx):
        img_train = cv2.imread(self.X[idx])
        img_mask = cv2.imread(self.y[idx])
        img_train = cv2.resize(img_train, (224,224), interpolation = cv2.INTER_LANCZOS4) 
        img_mask = cv2.resize(img_mask, (224,224), interpolation = cv2.INTER_LANCZOS4) 
        return img_train, img_mask

X = list(df['input_img'])  # This contains the location of the input image 
y = list(df['mask_img'])  # This contains the location of the mask image

X_train, X_valid, y_train, y_valid = train_test_split(
     X, y, test_size=0.33, random_state=42)

dataset_train = NumbersDataset(X_train, y_train)
dataloader_train = DataLoader(dataset_train, batch_size=4, shuffle=True, num_workers=2)

dataset_valid = NumbersDataset(X_valid, y_valid)
dataloader_valid = DataLoader(dataset_valid, batch_size=4, shuffle=True, num_workers=2)

data = DataBunch(train_dl = dataloader_train, valid_dl = dataloader_valid)

leaner = unet_learner(data = data, arch = models.resnet34)
```

And I get this error:

> AttributeError: 'NumbersDataset' object has no attribute 'c'

What do you suggest?",object still getting error class self self return self interpolation interpolation return list location input image list location mask image data leaner data data arch get error object attribute suggest,issue,negative,neutral,neutral,neutral,neutral,neutral
588060321,@sgugger Try training a ULMFiT model with integral labels from a Pandas dataframe. This will then happen in the `text_learner.predict()` method.,try training model integral happen method,issue,negative,neutral,neutral,neutral,neutral,neutral
587514451,"You are so welcome.  I must thank you and Jeremy for the open platform and
opportunity to learn and help.


On Tue, Feb 18, 2020 at 10:48 PM Sylvain Gugger <notifications@github.com>
wrote:

> Thanks a lot for the fix!
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/2498?email_source=notifications&email_token=AEXXI7SRMFP3BHJUJYG3V7LRDPYKNA5CNFSM4KW6XT6KYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOEMCHVGI#issuecomment-587496089>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEXXI7XNZ6BU32SA4ETVBM3RDPYKNANCNFSM4KW6XT6A>
> .
>
",welcome must thank open platform opportunity learn help tue wrote thanks lot fix thread reply directly view,issue,positive,positive,positive,positive,positive,positive
587350071,"> There is the from_classes method if I remember correctly for doing that.
> 
> **Edit** The exact method is ImageDataBunch.single_from_classes.

Okay thanks a lot, I'll check this out.",method remember correctly edit exact method thanks lot check,issue,negative,positive,positive,positive,positive,positive
587192105,"I am having the same issue with DataBunch (de)serialization. @sgugger , maybe the cure for this is an option to use lower-level APIs (e.g. optionally passing NumPy arrays that we manage ourselves instead of DataBunches for training)? I found it a bit strange that I had to convert my NumPy arrays to a dataframe in order to use a language model.",issue de serialization maybe cure option use optionally passing manage instead training found bit strange convert order use language model,issue,negative,negative,neutral,neutral,negative,negative
587070809,"There is the from_classes method if I remember correctly for doing that.

**Edit** The exact method is ImageDataBunch.single_from_classes.",method remember correctly edit exact method,issue,negative,positive,positive,positive,positive,positive
587067652,"Okay but if I use learn.save(), I have to recreate a DataBunch that fit the original one. Is there any way to use the pair export/load_learner ? Or a simple way to create an empty DataBunch with only the pth model ? ",use recreate fit original one way use pair simple way create empty model,issue,positive,positive,positive,positive,positive,positive
587050383,"Thanks for all the details, it made solving the issue really easy :)
In this case, I think the best is to store the attribute as is (and not the square) so that the representation is as comprehensive as possible.",thanks made issue really easy case think best store attribute square representation comprehensive possible,issue,positive,positive,positive,positive,positive,positive
587042462,"Please use the forum for debugging your code, this is also going to benefit more members of the community if we have the discussion there. Here BCEWithLogitsLoss is unvalid because you don't have one-hot encoded targets.",please use forum code also going benefit community discussion unvalid,issue,positive,neutral,neutral,neutral,neutral,neutral
587042018,"YEs, a PR with this would be most welcome. Thanks!",yes would welcome thanks,issue,positive,positive,positive,positive,positive,positive
587041049,"Exactly. the `y` in `get_preds` is the target, which, in the case of a test set, is just a sequence of 0s since there is no labels.",exactly target case test set sequence since,issue,negative,positive,positive,positive,positive,positive
587035642,`load_learner` is the command to load an exported learner and is the one that fails. To load the model in saved with `learn.save()` you have to use `learn.load()`.,command load learner one load model saved use,issue,negative,neutral,neutral,neutral,neutral,neutral
587003206,"> Appreciate and thanks for fixing this in v2.
> So if I understand it, I can still do the inference using the `load_learner()`. So, like
> 
> ```
> learn.save('first') -> Linux
> load_learner(path, 'first') -> Windows
> ```
> 
> This should unblock me, thanks will give a try.

@sgugger I tried this way :

learn.save('first') -> Windows
load_learner(path, 'first') -> Linux

And I got the error 

```
File ""/app/jsonPost.py"", line 16, in <module>
    prediction4Angles = load_learner(path='/models', file='4angles.pkl')
  File ""/usr/local/lib/python3.6/site-packages/fastai/basic_train.py"", line 618, in load_learner
    state = torch.load(source, map_location='cpu') if defaults.device == torch.device('cpu') else torch.load(source)
  File ""/usr/local/lib64/python3.6/site-packages/torch/serialization.py"", line 529, in load
    return _legacy_load(opened_file, map_location, pickle_module, **pickle_load_args)
  File ""/usr/local/lib64/python3.6/site-packages/torch/serialization.py"", line 702, in _legacy_load
    result = unpickler.load()
  File ""/usr/lib64/python3.6/pathlib.py"", line 1004, in __new__
    % (cls.__name__,))
NotImplementedError: cannot instantiate 'WindowsPath' on your system
```

Any idea ?

FastAI version: 1.0.60",appreciate thanks fixing understand still inference like path unblock thanks give try tried way path got error file line module file line state source else source file line load return file line result file line system idea version,issue,positive,positive,positive,positive,positive,positive
586713982,"This is linked to multiprocessing on Windows with PyTorch not really working. You should bring the issue to them (I think several issues are opened for that problem). As far as I know, there is nothing much we can do on our side...",linked really working bring issue think several problem far know nothing much side,issue,negative,positive,positive,positive,positive,positive
586674999,"code
'''
from fastai.vision import models, URLs, ImageDataBunch, cnn_learner, untar_data, accuracy
path = untar_data(URLs.CIFAR,dest='./')  # 下载数据集，这里只是MNIST的子集，只包含3和7的图像,会下载并解压（untar的命名原因）到/root/.fastai/data/mnist_sample（如果你是root用户）下，包含训练数据，测试数据，包含label的csv文件
data = ImageDataBunch.from_folder(path)  # 利用ImageDataBunch读取文件夹，返回一个ImageDataBunch对象
learn = cnn_learner(data, models.vgg16_bn, metrics=accuracy)  # 构建cnn模型，使用resnet18预训练模型
learn.fit_one_cycle(4)
'''",code import accuracy path data path learn data,issue,negative,neutral,neutral,neutral,neutral,neutral
586306193,"One could argue that you need to clean up the csv file as a separate steps (it won't work if you don't put links but random text, obviously), but I don't the see the harm in filtering for empty strings. Don't hesitate to suggest a PR.",one could argue need clean file separate wo work put link random text obviously see harm filtering empty hesitate suggest,issue,negative,negative,neutral,neutral,negative,negative
586302652,"This comes from the different OS going through files differently. 
The factory method won't change so you need to use the data block API to assemble your data and add your test set. There you will have the possibility to give a list of files, that you can then sort (in v2 there is even a function to get that result directly).",come different o going differently factory method wo change need use data block assemble data add test set possibility give list sort even function get result directly,issue,negative,positive,neutral,neutral,positive,positive
585874628,"I also looked for multiprocessing bugs in that configuration online and found no bug reports. I’ll try to make a synthetic dataset I can upload and reproduce it on my MBP, but that only has 16 GiB of RAM",also configuration found bug try make synthetic reproduce gib ram,issue,negative,neutral,neutral,neutral,neutral,neutral
585873533,This used less than 30% of the system’s RAM at its peak ,used le system ram peak,issue,negative,neutral,neutral,neutral,neutral,neutral
585798204,"As it is, it's a bit hard to know the cause of the bug and if it comes from fastai:
- it could be one bad sample 
- it could be Ubuntu on windows + multiprocessing in python
- it could be the fact you get our of RAM that triggers the error

For the last one, only v2 will support tokenizing from files without loading everything in memory. The second one can be tested by using anther env, and you'll know if it's the first one once the tokenization is over.

If you say batching texts by 100k samples is a workaround, I think it points toward the third one being the cause, in which case you should switch to v2.

Closing as I don't have a clear reproducer, but please reopen with more info if you have them.",bit hard know cause bug come could one bad sample could python could fact get ram error last one support without loading everything memory second one tested anther know first one say think toward third one cause case switch clear reproducer please reopen,issue,negative,negative,neutral,neutral,negative,negative
585768488,"@sgugger I am trying to use a loss function different to the default FlattenedLoss (learn.lr_find() trains fine) but when I pass it as above ( `learn.loss_func = nn.BCEWithLogitsLoss()` ) I get the error:

`ValueError                                Traceback (most recent call last)
<ipython-input-29-d81c6bd29d71> in <module>
----> 1 learn.lr_find()

~\.conda\envs\ml\lib\site-packages\fastai\train.py in lr_find(learn, start_lr, end_lr, num_it, stop_div, wd)
     30     cb = LRFinder(learn, start_lr, end_lr, num_it, stop_div)
     31     epochs = int(np.ceil(num_it/len(learn.data.train_dl)))
---> 32     learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)
     33 
     34 def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,

~\.conda\envs\ml\lib\site-packages\fastai\basic_train.py in fit(self, epochs, lr, wd, callbacks)
    200         callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(callbacks)
    201         self.cb_fns_registered = True
--> 202         fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)
    203 
    204     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

~\.conda\envs\ml\lib\site-packages\fastai\basic_train.py in fit(epochs, learn, callbacks, metrics)
     99             for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):
    100                 xb, yb = cb_handler.on_batch_begin(xb, yb)
--> 101                 loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)
    102                 if cb_handler.on_batch_end(loss): break
    103 

~\.conda\envs\ml\lib\site-packages\fastai\basic_train.py in loss_batch(model, xb, yb, loss_func, opt, cb_handler)
     28 
     29     if not loss_func: return to_detach(out), yb[0].detach()
---> 30     loss = loss_func(out, *yb)
     31 
     32     if opt is not None:

~\.conda\envs\ml\lib\site-packages\torch\nn\modules\module.py in __call__(self, *input, **kwargs)
    530             result = self._slow_forward(*input, **kwargs)
    531         else:
--> 532             result = self.forward(*input, **kwargs)
    533         for hook in self._forward_hooks.values():
    534             hook_result = hook(self, input, result)

~\.conda\envs\ml\lib\site-packages\torch\nn\modules\loss.py in forward(self, input, target)
    599                                                   self.weight,
    600                                                   pos_weight=self.pos_weight,
--> 601                                                   reduction=self.reduction)
    602 
    603 

~\.conda\envs\ml\lib\site-packages\torch\nn\functional.py in binary_cross_entropy_with_logits(input, target, weight, size_average, reduce, reduction, pos_weight)
   2122 
   2123     if not (target.size() == input.size()):
-> 2124         raise ValueError(""Target size ({}) must be the same as input size ({})"".format(target.size(), input.size()))
   2125 
   2126     return torch.binary_cross_entropy_with_logits(input, target, weight, pos_weight, reduction_enum)

ValueError: Target size (torch.Size([2, 1, 64, 128])) must be the same as input size (torch.Size([2, 2, 64, 128]))`


Any ideas why I can't use these different Loss Functions?

Thanks",trying use loss function different default fine pas get error recent call last module learn learn learn learner dynamic clip fit self self true fit self self none fit learn metric loss loss break model opt return loss opt none self input result input else result input hook hook self input result forward self input target input target weight reduce reduction raise target size must input size return input target weight target size must input size ca use different loss thanks,issue,positive,positive,positive,positive,positive,positive
585135008,"Strange, the tests failed with ""HTTP Error 403: Forbidden"", which seems unrelated to my change....

https://dev.azure.com/fastdotai/fastai/_build/results?buildId=6859&view=logs&j=d1113ce6-f179-58af-fca7-fd734ada1ab9&t=c6941af0-1990-549e-1833-f8e1570af56d&l=547

But I'm able to download the model https://download.pytorch.org/models/resnet34-333f7ec4.pth from a browser..... could it be a transient error?

Re-triggering the test with `git commit --amend -m '..... blah blah blah .....'`",strange error forbidden unrelated change able model browser could transient error test git commit amend blah blah blah,issue,negative,positive,positive,positive,positive,positive
584781211,"The problem comes from torchvision.models, not fastai. You should raise an issue on their side.

Here are the imports we do from torchvision if you want to check which one fails to help them:
```
from torchvision.models import ResNet,resnet18,resnet34,resnet50,resnet101,resnet152
from torchvision.models import mobilenet_v2
from torchvision.models import SqueezeNet,squeezenet1_0,squeezenet1_1
from torchvision.models import densenet121,densenet169,densenet201,densenet161
from torchvision.models import vgg11_bn,vgg13_bn,vgg16_bn,vgg19_bn,alexnet
```",problem come raise issue side want check one help import import import import import,issue,negative,neutral,neutral,neutral,neutral,neutral
584584299,"Hello,

This is the code

data = (ImageList.from_folder(""/kaggle/input/naruto-hand-sign-dataset/Pure Naruto Hand Sign Data/"")
        .split_by_rand_pct()          
        .label_from_folder()
        .add_test_folder() 
        .transform(get_transforms(),size=128)
        .databunch()
        .normalize(imagenet_stats))


but for me, no test data is being generated

![image](https://user-images.githubusercontent.com/20688709/74231588-ed924380-4cec-11ea-8d29-ac203f7770d7.png)

Would be grateful for any help. Thanks!",hello code data hand sign test data image would grateful help thanks,issue,positive,positive,positive,positive,positive,positive
582680765,"@sgugger, 

Progress on avoiding the deadlock following your suggestion:

1. In `LRFinder.on_batch_end()`, do not abort the epoch in distributed mode, let it finish.  Defer to aborting the training in `on_epoch_end()`.  Also print a suggestion on `plot(skip_end=..)` value to use.

2. Also scale up the number of epochs to use in `lr_find()` by the number of GPUs , to adequately cover the range of learning rates.

In my testing, GPUs synced up happily at end of epoch.  Time overhead is only a partial epoch after loss expansion,  despite the extended number of epochs.  I've conducted 100 runs of the `bs=1` case, and no deadlock.

Really appreciate your suggestion.   Could you be so kind to review this short patch?  If it looks acceptable, I will draft a PR.

 https://github.com/fastai/fastai/compare/master...philtrade:master?diff=unified

Thank you.







",progress deadlock following suggestion abort epoch distributed mode let finish defer training also print suggestion plot value use also scale number use number adequately cover range learning testing happily end epoch time overhead partial epoch loss expansion despite extended number case deadlock really appreciate suggestion could kind review short patch acceptable draft thank,issue,positive,positive,positive,positive,positive,positive
582550382,"Hi Sylvain,

Increasing epochs in distributed `lr_find()` seems to address the issue of not enough number of batches to reach the point of expanding losses:

```
def lr_find(learn:Learner, start_lr:Floats=1e-7, end_lr:Floats=10, num_it:int=100, stop_div:bool=True, wd:float=None):
    ...
    epochs = int(np.ceil(num_it/len(learn.data.train_dl)))
 +  if num_distrib() > 1: epochs *= num_distrib()
    learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)
```
Now `bs=8`, 3 GPUs, `epochs` scaled up from 2 to 6, `lr_find()` would early-stop in the 3rd epoch.  Previously it ran out after 2 epochs without seeing loss expansion.

Next will try the deadlock avoidance approach you mentioned --- let them run the full course.
",hi increasing distributed address issue enough number reach point expanding learn learner scaled would epoch previously ran without seeing loss expansion next try deadlock avoidance approach let run full course,issue,negative,positive,neutral,neutral,positive,positive
582171121,"Thanks for the response Sylvain.  I wanna touch upon your suggested implementation, then share my observations from experiments on the effect of batch size (`bs` when creating the training data) in distributed training.

In short, the approximate **number of batches** seems to matter to `lr_find()`, because the learning rate is stepped in `LRFinder.on_batch_end()`.   In distributed training with multiple GPUs, the number of batches processed per GPU is scaled down, and sometimes too low before `lr_find()` can see an expanding loss to stop early.

### On the implementation you proposed

> *""run its full course on all processes""*

Do you mean in `LRFinder.on_batch_end()`, limit the early stopping by expanding losses to non-distributed training?  E.g. `(smooth_loss > 4*self.best_loss and not num_distrib())`? 

> *""showing the loss of process 0 up to the point this process would have stopped.""*

Something like: let `DistributedRecorder.on_train_end()` do the `smooth_loss > 4 * best_loss` logic, and trim the `recorder.{losses,lrs}` up to the rediscovered *best loss* ?

This sounds like a feasible lock-free approach. 

Nonetheless we remain facing the issue below, when running `lr_find()` in distributed mode.

### On the impact of `bs` to `lr_find()` in distributed training:

From my observation, lr_find needs enough *number of batches* as a runway to discover the run-away losses, which **curiously, seems to be independent of the batch size, and of the number of GPUs used in distributed training**.   And because in distributed mode the *number of batches* is reduced (divided by the number of GPUs) at the same batch size, the runway got shorter, sometimes too short.

Using the DL1, lesson3-camvid as an example, on a GTX1080Ti, typically it needs around 68-72 batches to hit the loss expansion.

#### When `lr_find()` works in non-distributed single GPU mode, with long enough runway:

First three charts shows that in single GPU training, how `lr_find()` works OK with bs=8,4,2, 
andthe total # of batches per epoch is 75, 150, and 300 respectively.  However, `lr_find()` stops at the similar proximity of batch # 70, # 72, and # 68 respectively.

Notice the batch number at which `lr_find()` stopped at, in the output
>> `Rank [0] LR Finder is complete @ batch# ....`

**`bs=8`, non-distributed:**
![bs=8, non-DDP](https://user-images.githubusercontent.com/19887230/73792729-c0c4b600-4759-11ea-826b-21ba974af0f5.png)

**`bs=4`, non-distributed:**
![bs=4 non-DDP](https://user-images.githubusercontent.com/19887230/73792902-25801080-475a-11ea-9f91-051d850e9a5b.png)

**`bs=2`, non-distributed:**
![bs=2 non-DDP](https://user-images.githubusercontent.com/19887230/73792918-2fa20f00-475a-11ea-9367-bd3c3131a093.png)

### But in Distributed Training, Total # of batches is scaled down, and becomes too short for `lr_find()` -- it needs 70-ish before seeing expanding loss.

Now when in DDP mode with 3 GPUs, `lr_find()` exhausts the run without early_stopping at bs=8 and 4, because total *number of batches* per epoch are scaled down from 75 and 150, by 3,  to **25 and 50**.  The `bs=8` run `lr_find()` automatically scales up to 2 epochs, but still, 25x2=50, falls short.  **Notice the shorter learning rate range of the x-axis, when compared to above single GPU mode**.

*Please pardon the ascii progress bar output below, as I haven't gotten html progress bar display to work in distributed training.*

**`bs=8`, distributed:**
![bs=8 DDP bn=25, epoch = 2](https://user-images.githubusercontent.com/19887230/73794090-7ee93f00-475c-11ea-988b-7b87e98cf25c.png)

**`bs=4`, distributed:**
![bs=4 DDP bn=50](https://user-images.githubusercontent.com/19887230/73794162-b0faa100-475c-11ea-83de-7fb78b09100a.png)

**Changing `num_it` doesn't help:**  @ `bs=8`, lr_find() runs with`num_it=200`

**`bs=8`, `num_it=200`, distributed:**
![bs=8 DDP bn=25 num_it = 200](https://user-images.githubusercontent.com/19887230/73795123-b9ec7200-475e-11ea-9b8f-f0a3cf4c0836.png)

**Finally `lr_find()` in distributed training mode finds the `best_loss`**, when @ `bs=2` because the runway becomes long enough: 300/3 = 100 (> 72).

**`bs=2`, distributed:**
![bs=2 DDP bn=100](https://user-images.githubusercontent.com/19887230/73795023-7560d680-475e-11ea-8dd6-539b36b3f215.png)

#### On Dead Lock

**But @ `bs=2`, # of batches = 100, it spuriously dead lock**, when one process early-stopped, and waiting for other process at `on_train_end()`'s `learn.load('tmp')` call, **while other processes doing other things, and ended up waiting for the early-quitter to sync up at another point, to reduce the losses *maybe* ??  How they became out of sync,  I don't have an idea yet. 

![bs=2 lr_find DDP deadlock](https://user-images.githubusercontent.com/19887230/73795488-9a097e00-475f-11ea-8a3d-f63b259b1a0a.png)

But the probability of the deadlock increased with smaller `bs` from my observation, more on_batch_end() calls -->  to more opportunities for early stopping, .   As I type this, running with `bs=1` the smallest possible, it deadlocked with 2 processes finished, waiting on rank-0 process this time:

![Screen Shot 2020-02-04 at 4 02 23 PM](https://user-images.githubusercontent.com/19887230/73798485-c45f3980-4767-11ea-87a8-e7ccf6af972e.png)

####  Apparently, with multiple GPU, effective batch size maybe bigger, but total **number** of batches to step through is smaller.  As the learning rate is stepped in `LRFinder.on_batch_end()`,  with fewer batches, it covers shorter range of learning rate. 

So the training data's `bs` needs to be small enough to generate enough *number of batches* for `lr_find()`, but later when training, it may need to be restored to a higher number, to take advantage of the multiple GPUs.  On top of that, distributed `lr_find()`, as of now, has the risk of deadlock quite frequently.

In order to run an existing notebook in  distributed training, demanding user to ""adjust `bs` just for the `lr_find()` then later restore it again when training model on multiple GPUs"", seems not very user-friendly.

What may be the solution? 

I went to the route of running `lr_find()` in  ""temporarily non-distributed mode, on the rank-0 process"",  such that users won't be surprised, as `lr_find()` behaves similarly in distributed vs non-distributed setup.

But I'm definitely open to brain storming on better solutions!!

Sorry about this long posts, it took me a long time to debug the deadlock and understand this much.  Thanks.

*Edited on Feb 5, 2020 for readability*
",thanks response wan na touch upon implementation share effect batch size training data distributed training short approximate number matter learning rate stepped distributed training multiple number per scaled sometimes low see expanding loss stop early implementation run full course mean limit early stopping expanding training showing loss process point process would stopped something like let logic trim recorder best loss like feasible approach nonetheless remain facing issue running distributed mode impact distributed training observation need enough number runway discover curiously independent batch size number used distributed training distributed mode number reduced divided number batch size runway got shorter sometimes short example typically need around hit loss expansion work single mode long enough runway first three single training work total per epoch respectively however similar proximity batch respectively notice batch number stopped output rank finder complete batch distributed training total scaled becomes short need seeing expanding loss mode run without total number per epoch scaled run automatically scale still short notice shorter learning rate range single mode please pardon ascii progress bar output gotten progress bar display work distributed training distributed epoch distributed help distributed finally distributed training mode runway becomes long enough distributed dead lock spuriously dead lock one process waiting process call ended waiting sync another point reduce maybe sync idea yet deadlock probability deadlock smaller observation early stopping type running possible finished waiting process time screen shot apparently multiple effective batch size maybe bigger total number step smaller learning rate stepped shorter range learning rate training data need small enough generate enough number later training may need higher number take advantage multiple top distributed risk deadlock quite frequently order run notebook distributed training demanding user adjust later restore training model multiple may solution went route running temporarily mode process wo similarly distributed setup definitely open brain storming better sorry long took long time deadlock understand much thanks readability,issue,positive,positive,neutral,neutral,positive,positive
582153632,Is there a fix for this issue? The models which were using the vision modules of fastai are now working differently. ,fix issue vision working differently,issue,negative,neutral,neutral,neutral,neutral,neutral
581949453,"Running lr find in process 0 only will change the effective batch size compared to the distributed training. I think the check should be to let the training run its full course on all processes for this, to avoid the dead-lock, then just showing the loss of process 0 up to the point this process would have stopped.",running find process change effective batch size distributed training think check let training run full course avoid showing loss process point process would stopped,issue,negative,positive,positive,positive,positive,positive
581188053,"> Does this work with earlier versions of pandas and achieves the same result?

@sgugger 
It does now :)  Good catch.  I thought I had checked that but obviously something was messed up in my environment when I did as None doesn't work prior to 1.0.0

Let me know if the the way I coded that is ok.  I took the inspiration from #2457 ",work result good catch thought checked obviously something environment none work prior let know way took inspiration,issue,positive,positive,positive,positive,positive,positive
581179796,"Ah, my mistake. Will push a fix in a few minutes and revert to your code.",ah mistake push fix revert code,issue,negative,neutral,neutral,neutral,neutral,neutral
581178830,"@sgugger The problem is that `self.get_monitor_value()` returns a numpy array during lm learner training, so it will fail since numpy doesn't have `cpu()`

That's why I added the check.",problem array learner training fail since added check,issue,negative,negative,negative,negative,negative,negative
581167346,"Thanks for your PR. As I commented on #2481, we need a util function that works for both cases, this will fail for any user with an earlier version of Pillow, so this is not the solution.",thanks need function work fail user version pillow solution,issue,negative,negative,negative,negative,negative,negative
581167127,"Thanks for your PR! Since the call to `.cpu()` already does that test inside, I simplified a little bit the code you added.",thanks since call already test inside simplified little bit code added,issue,negative,positive,neutral,neutral,positive,positive
581048870,"Thank you.

Perhaps leave the old one as a note, for those who still run older versions? As the newer version you suggested will fail for the older one.",thank perhaps leave old one note still run older version fail older one,issue,negative,negative,neutral,neutral,negative,negative
580990637,"The thing is since they did not offer backward compatibility, it's actually one of those two commands... I'll write an util function to grab the version when I have a bit of time.",thing since offer backward compatibility actually one two write function grab version bit time,issue,negative,neutral,neutral,neutral,neutral,neutral
580384095,"Note that any PR clarifying the tutorial is welcome ;). If it wasn't clear to you, chances are it's not clear for other people as well.",note tutorial welcome clear clear people well,issue,positive,positive,positive,positive,positive,positive
580382492,"Oh I see that makes sense.
I followed the tutorial section https://docs.fast.ai/tutorial.data.html

> 
> Let's begin with our sample of the MNIST dataset.
> ```
> mnist = untar_data(URLs.MNIST_TINY)
> tfms = get_transforms(do_flip=False)
> ```
> It's set up with an imagenet structure so we use it to load our training and validation datasets, then label, transform, convert them into ImageDataBunch and finally, normalize them.
> ```
> data = (ImageList.from_folder(mnist)
>         .split_by_folder()          
>         .label_from_folder()
>         .transform(tfms, size=32)
>         .databunch()
>         .normalize(imagenet_stats))
> ```

Which i read as that the MNIST dataset is set up like the ImageNet dataset (concerning folder structure etc.) and wondered why it says `.normalize(imagenet_stats)` when we are using the MNIST dataset.

It isn't clear in the beginners tutorial linked above that the model which is used was pretrained on imagenet. So i somehow ended up thinking I should use mnist_stats for the MNIST dataset.

I guess I should have just read more carefully in the other parts of the docs, thanks for clearing that up.
",oh see sense tutorial section let begin sample set structure use load training validation label transform convert finally normalize data read set like concerning folder structure clear tutorial linked model used somehow ended thinking use guess read carefully thanks clearing,issue,positive,positive,positive,positive,positive,positive
580373410,"Not all models are pretrained, only the one created via the convenience function `cnn_learner`. Users also define their own models and might need those `cifar_stats` or `mnist_stats`. There are plenty of examples of this in the course.",one via convenience function also define might need plenty course,issue,negative,neutral,neutral,neutral,neutral,neutral
580369718,"I think it should be made more clear that all models in fast.ai use the pretained version from torchvision which have all been pretrained on imagenet and should all be fed with images that are normalized with imagenet_stats.

I was thoroughly confused as why there are also mnist_stats and cifar_stats in fast.ai included when all models have to use imagenet_stats.",think made clear use version fed thoroughly confused also included use,issue,negative,negative,negative,negative,negative,negative
580319074,"Sure @sgugger. If I can be of help in this matter, like updating the URLs class etc., do tell me.",sure help matter like class tell,issue,positive,positive,positive,positive,positive,positive
580311648,"ok, I'll see if I can figure this out in the next days.",see figure next day,issue,negative,neutral,neutral,neutral,neutral,neutral
580310773,"It's not in the corresponding doc notebook (at least not in the main part, it's in the Undocumented please move section). If you want to make a PR fixing this, it should appear during our next build.",corresponding doc notebook least main part undocumented please move section want make fixing appear next build,issue,negative,negative,neutral,neutral,negative,negative
580309979,Seems like  a good idea! I will work on this when I have time (probably next week).,like good idea work time probably next week,issue,positive,positive,positive,positive,positive,positive
580309788,"Unfortunately there is nothing we can do on our side to fix this: you need to re-export your model with 1.4.0 then `load_learner` should work again.
From what I understand, they changed the code of LSTM, so when we unpickle a model trained with a previous version that has an LSTM, it crashes.",unfortunately nothing side fix need model work understand code model trained previous version,issue,negative,negative,negative,negative,negative,negative
579605852,"Updating Pytorch worked. [Here](https://forums.fast.ai/t/solved-imagecleaner-causes-attributeerror-tensor-object-has-no-attribute-ndim/60796) is the solution:
```
conda remove fastai && conda install -c fastai fastai
conda remove pytorch  torchvision && conda install -c pytorch  torchvision
conda install fastai -c fastai.
```",worked solution remove install remove install install,issue,negative,neutral,neutral,neutral,neutral,neutral
579346410,"No idea, that's something you should check on the [forum](https://forums.fast.ai/) or ask PaperSpace directly.",idea something check forum ask directly,issue,negative,positive,neutral,neutral,positive,positive
579341620,thanks for your quick reply! how do I update the pytorch version on paperspace?,thanks quick reply update version,issue,negative,positive,positive,positive,positive,positive
579337886,"This part may need a more recent pytorch, so try to update your pytorch (I think they added `ndim` in 1.1.0).",part may need recent try update think added,issue,negative,neutral,neutral,neutral,neutral,neutral
578800613,"The docs file are auto-generated from the notebooks, so you should put that change in [here](https://github.com/fastai/fastai/blob/master/docs_src/tutorial.data.ipynb) and it will propagate to the docs once we rebuild them (otherwise your change will be erased next time we build the documentation). Closing this PR as it's easier if you do it in a new one.",file put change propagate rebuild otherwise change erased next time build documentation easier new one,issue,negative,positive,neutral,neutral,positive,positive
578445760,"Thanks for your PR, but there is a mode that determines if improvement should be understood as greater or less. That mode is automatically set to less if there is `loss` or `error` in the name of the metric, which is all done in the base class `TrackerCallback`. 
You can set that mode to `min` or `max` if the automatic pick does not work for your problem.",thanks mode improvement understood greater le mode automatically set le loss error name metric done base class set mode min automatic pick work problem,issue,negative,negative,neutral,neutral,negative,negative
577859212,"You are not passing `cat_names` and `cont_names` to `TabularList`, which is probably where you error comes from.",passing probably error come,issue,negative,neutral,neutral,neutral,neutral,neutral
577786271,Thanks for flagging. It should be `None` indeed.,thanks flagging none indeed,issue,negative,positive,positive,positive,positive,positive
577720557,"Got it, it's the thing returned that is different. Thanks!",got thing returned different thanks,issue,negative,positive,neutral,neutral,positive,positive
577719562,"@sgugger 

As of now, SP saves 2 files - `path/'""cache_dir"".vocab' and path/'""cache_dir"".model'` and returns `path/""tmp/spm""` path. When the latter is used to read the cached vocab again, it won't be found.

So I fixed the paths, making it consistent with `load`",path latter used read wo found fixed making consistent load,issue,negative,positive,positive,positive,positive,positive
577708148,"I don't understand what this PR changes, could you elaborate? Thanks!",understand could elaborate thanks,issue,negative,positive,positive,positive,positive,positive
577707526,"No, this is the default from [torchvision](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.RandomResizedCrop), there is no error there. I agree this is low, a value we often use is 0.35 but I think the default should be the same as the underlying transform.",default error agree low value often use think default underlying transform,issue,negative,neutral,neutral,neutral,neutral,neutral
577412467,"In my case, when I type !pip freeze within Jupyter Notebook, pandas_summary is not listed there.  However, when I do pip freeze within the terminal, it is clearly listed.  I launched Jupyter Notebook from that pip environment, so I'm unclear as to why the module doesn't show up.",case type pip freeze within notebook listed however pip freeze within terminal clearly listed notebook pip environment unclear module show,issue,negative,positive,positive,positive,positive,positive
577240679,"This is dangerous as it makes your predictions be in a different order. You can always do it with
```
dbunch.test_dl = dbunch.test_dl.new(shuffle=True)
```
but I don't think exposing the argument is a good idea.",dangerous different order always think argument good idea,issue,negative,positive,neutral,neutral,positive,positive
576300072,"No, those are the rights URLs, you would change to the old versions of the datasets with this. Please open an issue with your error so we can fix this.",would change old please open issue error fix,issue,negative,positive,neutral,neutral,positive,positive
576051037,"Hi there, thanks for you PR. The link is for a Keras example however, not fastai so I'm not really sure there is support. You can reach to fastai users on the [forum](https://forums.fast.ai/), they'll read that more than the REAMDE in any case.",hi thanks link example however really sure support reach forum read case,issue,positive,positive,positive,positive,positive,positive
576006601,"Checked the directory is valid and added a clear error message if that's not the case. It's trickier for an empty directory, but I added some clearer message error mentioning the data source is empty. There are also warnings that the training set and the validation set both are empty.",checked directory valid added clear error message case empty directory added clearer message error data source empty also training set validation set empty,issue,negative,negative,neutral,neutral,negative,negative
575956797,"I worked around this problem by ""padding"" the confusion matrix vertically as follows.

```
def padd_plot_conf_matrix(conf_matrix, x_labels, y_labels):
    
    blank_array = [[-1 for i in range(len(y_lables))]]
    pad_conf_matrix = np.concatenate((blank_array, conf_matrix, blank_array ))
    
    plt.figure(figsize=[9,9]) # Change this as needed.
    plt.imshow(pad_conf_matrix, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title(""Confusion matrix"", color=""blue"")
    plt.xlabel('Predicted', color=""blue"")
    plt.ylabel('Actual', color=""blue"")
    plt.tight_layout()
    plt.colorbar()
    
    x_posits = np.arange(len(x_lables))
    y_posits = np.arange(len(y_lables)+2)
    plt.xticks(x_posits, x_labels, rotation=90)
    plt.yticks(y_posits, [""""] + y_labels + [""""])
    
    thresh = conf_matrix.max()/2.
    for i in range(1, len(y_lables)+1):
        for j in range(len(x_lables)):
            plt.text(j,i, pad_conf_matrix[i,j], fontsize=20, horizontalalignment=""center"",
                        color=""white"" if D[i,j]>thresh else ""black"")

    plt.show()
```
![image](https://user-images.githubusercontent.com/7789659/72693012-de501980-3ae3-11ea-9ae5-d41e96ca86d3.png)",worked around problem padding confusion matrix vertically range change confusion matrix blue blue blue thresh range range center white thresh else black image,issue,negative,negative,neutral,neutral,negative,negative
575454374,Did anyone ever find the cause of the problem?,anyone ever find cause problem,issue,negative,neutral,neutral,neutral,neutral,neutral
575021202,"Please reopen it. Hiding warning actually worsened situation, because people are left unaware. With latest release of pytorch 1.4.0, behavior did change and this is basically dealbreaker. Most of existing models and things using vision module are, for obvious reasons, working differently.",please reopen warning actually situation people left unaware latest release behavior change basically vision module obvious working differently,issue,negative,positive,neutral,neutral,positive,positive
574712930,"Thanks for your adoption,I am so happy to hear that.



---Original---
From: ""Sylvain Gugger""<notifications@github.com&gt;
Date: Wed, Jan 15, 2020 22:22 PM
To: ""fastai/fastai""<fastai@noreply.github.com&gt;;
Cc: ""郑恒毅""<hengyi0919@qq.com&gt;;""Author""<author@noreply.github.com&gt;;
Subject: Re: [fastai/fastai] Add a function named 'data_deleter' in 'image_cleaner.py',and add the function name to '__all__'. (#2455)



Thanks for your PR. I just edited the docstring to take one line and be consistent with the rest of the library.
 
—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub, or unsubscribe.",thanks adoption happy hear date wed author author subject add function add function name thanks take one line consistent rest library thread reply directly view,issue,positive,positive,positive,positive,positive,positive
574680987,Thanks for your PR. I just edited the docstring to take one line and be consistent with the rest of the library.,thanks take one line consistent rest library,issue,negative,positive,positive,positive,positive,positive
573414520,"Oh thanks for flagging! Made a typo, wanted to write self.",oh thanks flagging made typo write self,issue,negative,positive,positive,positive,positive,positive
573198466,"> 
> 
> > The problem somehow lies in your installation of ipywidgets: fastai did create it properly from what you're telling me, but it's not showing for some reason. I'm no expert in ipywidgets, so apart from trying to reinstall it properly, I don't have any better advice :-/
> 
> Thanks very much! After hours of struggling(forgive me i'm a beginner :-p ), finally i solved this problem(If that happened on mac or windows) by running these codes in the terminal:
> 
> ```
> # for mac terminal, use the command below; for windows cmd, add '--user' to the end of each command.
> 
> ###  First, reinstall ipywidgets and widgetsnbextension 
> pip install --upgrade --force-reinstall ipywidgets
> 
> pip install --upgrade --force-reinstall widgetsnbextension 
> 
> ### Second, install jupyter-js-widgets/extension
> jupyter nbextension install --py widgetsnbextension
> 
> ### Third, enable  widgetsnbextension
> jupyter nbextension enable --py widgetsnbextension --sys-prefix
> ```
> 
> now, we can enjoy lesson2_download.ipynb again. Simply type `jupyter notebook` in the terminal and open it in the browser.

This still isn't working for me, I have the same output as you have listed in your original post. I'm on not using colab or lab (just a regular jupyter notebook, and I' on windows (used --user, everything worked smoothly on the terminal end) but still no changes. Any recommendations?
Thanks!",problem somehow installation create properly telling showing reason expert apart trying reinstall properly better advice thanks much struggling forgive beginner finally problem mac running terminal mac terminal use command add user end command first reinstall pip install upgrade pip install upgrade second install install third enable enable enjoy simply type notebook terminal open browser still working output listed original post lab regular notebook used user everything worked smoothly terminal end still thanks,issue,positive,positive,positive,positive,positive,positive
571975693,"Please use the [forum](https://forums.fast.ai/) for installation issues, along with all the details (what command did you run for instance), thanks!",please use forum installation along command run instance thanks,issue,positive,positive,positive,positive,positive,positive
571626748,Thanks for flagging. I went for another fix (similar to yours but putting in the one place it comes from instead of two different places).,thanks flagging went another fix similar one place come instead two different,issue,negative,positive,neutral,neutral,positive,positive
571616632,"Thanks for flagging! It's a regression in a recent PR where the code was a tiny bit wrong, but I didn't catch it. Should be fixed now.",thanks flagging regression recent code tiny bit wrong catch fixed,issue,negative,negative,neutral,neutral,negative,negative
571300874,I guess error appeared because numpy got updated and what used to work with old numpy does not function now. I'm using numpy==1.17.4,guess error got used work old function,issue,negative,positive,neutral,neutral,positive,positive
570503723,"It's because you are using the `SaveModelCallback` in your lr finder run. Those two callbacks are incompatible, so you should do the lr finder before adding `SaveModelCallback`.
(That incompatibility has been solved in v2, so this won't be a problem anymore in a few months when v2 is released.)",finder run two incompatible finder incompatibility wo problem,issue,negative,neutral,neutral,neutral,neutral,neutral
570501443,"No, you must fill the X when doing a PR, not in the general template.",must fill general template,issue,negative,positive,neutral,neutral,positive,positive
570143078,"Do we have a consistent way of getting the segfault? I have been trying fresh installs but didn't get anything wrong. Closing the issue, please reopen with a reproducible example.",consistent way getting trying fresh get anything wrong issue please reopen reproducible example,issue,negative,positive,neutral,neutral,positive,positive
570006792,"hi @sgugger  thanks for your update.

Yes, the rename in v2 is much better than 'auto'. Also, I highly appreciate if we could use Full words instead of abbreviation. 

Abbreviations look much easy for people like you and other well AI-Educated people, but it's really hard for me who is just landed in the world of AI + Python + all jargon.

I know many of you guys coming from research organizations, but the IT industry likes to make things e.g. parameters, function names etc. crystal clear.

I come from an .NET developer and now TypeScript developer, here are some suggestions for naming conventions:

https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/general-naming-conventions
https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/inside-a-program/coding-conventions
https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/naming-guidelines

I know some guys don't like Microsoft world, then using some other naming conventions, but please not using Abbreviation especially when documents are not fully covered.

Thanks for you guys to bring Fast.Ai to us.
I have to see it is a brilliant AI framework and probably the best AI framework that I have seen so far.

Great job~!",hi thanks update yes rename much better also highly appreciate could use full instead abbreviation look much easy people like well people really hard landed world ai python jargon know many coming research industry make function crystal clear come developer typescript developer naming know like world naming please abbreviation especially fully covered thanks bring u see brilliant ai framework probably best ai framework seen far great,issue,positive,positive,positive,positive,positive,positive
569893289,"Thanks for flagging. Next time, don't hesitate to suggest a PR directly with your changes!",thanks flagging next time hesitate suggest directly,issue,negative,positive,positive,positive,positive,positive
569884654,"I'm curious how you imagine an auto could work for any user-defined metric or loss. In any case this was a user contribution to copy the API of Keras.

Note that the rewrite for v2 is using one parameter named comp, defaulting to None that will then go to np.less or np.greater depending on the same test, but is not called auto. Hope that it feels clearer.",curious imagine auto could work metric loss case user contribution copy note rewrite one parameter none go depending test auto hope clearer,issue,negative,negative,neutral,neutral,negative,negative
569827558,"if 'auto' doesn't mean to work in every case, then the word: auto is really misleading.
Suggestion to change 'auto' to 'best_guess' so that people will be aware of the situation and when things don't work out, they will not miss this piece: mode='auto'.

As the perception of auto means: it's smart enough to figure things out by itself.",mean work every case word auto really misleading suggestion change people aware situation work miss piece perception auto smart enough figure,issue,negative,positive,neutral,neutral,positive,positive
569629551,"Yes, but `auto` is not meant to work in every case. I'll had the test but in general, you should pass along the correct mode when using a metric that needs to be as small as possible.",yes auto meant work every case test general pas along correct mode metric need small possible,issue,negative,negative,neutral,neutral,negative,negative
569397369,"> It's normal you have to manually call update(0), as it signifies you are starting the iteration (which is different than the init) when not directly iterating through the progressbar.

Thanks for clarifying and the quick merge",normal manually call update starting iteration different directly thanks quick merge,issue,negative,positive,positive,positive,positive,positive
569396089,"Thanks for the PR! Failure in the tests is independent so I will merge. 
It's normal you have to manually call update(0), as it signifies you are starting the iteration (which is different than the init) when not directly iterating through the progressbar.",thanks failure independent merge normal manually call update starting iteration different directly,issue,negative,positive,neutral,neutral,positive,positive
569218610,"Thanks for pointing this out. As you said, it's best to fix fastprogress directly, which I just did. I also made a new release, so check you have the version 0.2.0 of fastprogress.",thanks pointing said best fix directly also made new release check version,issue,positive,positive,positive,positive,positive,positive
567505608,Thanks! I can't remember why we set it this way but it seems safer to use the official implementation indeed.,thanks ca remember set way use official implementation indeed,issue,negative,positive,positive,positive,positive,positive
567041205,You need the code for 'WeightedLabelSmoothingCrossEntropy' in the same script as you are trying to load your `Learner`. Note that exporting the learner exports the weights and the name of the functions used to create the model/data but when using custom ones (as is the case here) you need to have the code for them too in your production environment.,need code script trying load learner note learner name used create custom case need code production environment,issue,negative,neutral,neutral,neutral,neutral,neutral
567024852,"@dsblank i had to install different (older) versions of everything to get it running now. 
later i will try to get the new versions and then try again.
",install different older everything get running later try get new try,issue,negative,positive,neutral,neutral,positive,positive
567018981,"@yamennassif Try importing ""torch"" first. Does that help?",try torch first help,issue,negative,positive,positive,positive,positive,positive
567018633,"i have the same error with Python 3.7 on ubuntu 16LTS 
but with fastai.text instead of fastai.vision

whenever i import it it will just segfault",error python instead whenever import,issue,negative,neutral,neutral,neutral,neutral,neutral
566799732,"Actually, it seems I have to import torch first:

```python
import torch
import fastai.vision
```
where this causes a segfault:
```python
import fastai.vision
```",actually import torch first python import torch import python import,issue,negative,positive,positive,positive,positive,positive
566781759,"I'm not sure exactly what the issue was, but removing older versions of torch, torchvision, torchvision_nightly, and installing from fresh, with latest fastai 1.0.59 makes everything work again.",sure exactly issue removing older torch fresh latest everything work,issue,positive,positive,positive,positive,positive,positive
565765466,"As an alternative to the solution above, you could also tell pytorch not to use the (non-existing-in-a-macbook) CUDA GPU, by adding a few lines to the top of the Jupiter notebook. These lines will force pytorch to use the CPU. Fair warning: this is dreadfully slow. On my 2019 2.8Ghz quad core i7 MPB it takes 24 minutes per epoch, so about an hour for all four epochs on the learn.fit_one_cycle(4) resnet34 example. That said, it /does/ work without having to modify anything else in the notebook.

Taking the fastai lesson 1 notebook as an example, all you need to do is add the lines:

import torch
defaults.device = torch.device('cpu')

in between the second and third code blocks in the notebook to yield: 

%reload_ext autoreload
%autoreload 2
%matplotlib inline

**import torch
defaults.device = torch.device('cpu')**

bs = 64
",alternative solution could also tell use top notebook force use fair warning dreadfully slow quad core per epoch hour four example said work without modify anything else notebook taking lesson notebook example need add import torch second third code notebook yield import torch,issue,negative,positive,positive,positive,positive,positive
565709285,"For completeness, sgugger's suggestion looks like the line below when applied to the fastai lesson 1 example:

data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=get_transforms(), size=224, bs=bs, num_workers=0, ).normalize(imagenet_stats)

The comma after num_workers=0, is critical.
",completeness suggestion like line applied lesson example data pat comma critical,issue,negative,neutral,neutral,neutral,neutral,neutral
564400622,"> So after talking with Jeremy we'd like to replace the old urls, not add new names. Can you amend your PR to do that? Thanks!

Done in this [PR](https://github.com/fastai/fastai/pull/2432).",talking like replace old add new amend thanks done,issue,positive,positive,positive,positive,positive,positive
564269896,"So after talking with Jeremy we'd like to replace the old urls, not add new names. Can you amend your PR to do that? Thanks!",talking like replace old add new amend thanks,issue,positive,positive,positive,positive,positive,positive
564137624,Thanks! Let me just check with Jeremy if we want to erase the old urls or have two different sets.,thanks let check want erase old two different,issue,negative,positive,positive,positive,positive,positive
563260588,"Hi there, just closing this issue since the tests are passing on GCP and it doesn't seem there is anything we can do on our side to help (please fell free to correct me if I'm wrong).",hi issue since passing seem anything side help please fell free correct wrong,issue,positive,negative,neutral,neutral,negative,negative
563000446,This is error is due the autoreload magic and not the fastai library. Remove the cell where you included that magic to get rid of it.,error due magic library remove cell included magic get rid,issue,negative,positive,positive,positive,positive,positive
562875193,"This is a shape mismatch between the outputs of your model and targets that causes this error in the loss function, not a bug in the library. Please use the [forum](https://forums.fast.ai/) if you need help to debug it. The quick steps to debug are:
```
xb,yb = data.one_batch()
out = learn.model(xb)
loss = learn.loss_func(out, yb)
```
and you can inspect the shapes of xb, yb and out to solve your problem.",shape mismatch model error loss function bug library please use forum need help quick loss inspect solve problem,issue,negative,positive,positive,positive,positive,positive
562138818,"Thanks for your PR! I think we can tweak it to make everything fit in one line using something like
```
return a if cond1 else b if cond2 else c
```
Would you mind adjusting your code?",thanks think tweak make everything fit one line something like return cond else cond else would mind code,issue,positive,positive,positive,positive,positive,positive
561501830,"> > If so, Could you guys give an example or template about how to correctly use export() and load_learner functions in the customization case?
> 
> Did you get any best template to recover the same learner?

Hi @ashutoshraj , not yet, I still use learner.save. do you have any updates recently?",could give example template correctly use export case get best template recover learner hi yet still use recently,issue,positive,positive,positive,positive,positive,positive
561347387,"Awesome, thanks for fixing it so quickly!",awesome thanks fixing quickly,issue,positive,positive,positive,positive,positive,positive
561212338,"Thanks a lot for the thorough investigation of this bug. I had seen it from time to time but never got a reliable reproducer.
It turns out a reset is necessary before freezing/unfreezing (something linked to the hack inside WeightDropout) so I just added that.",thanks lot thorough investigation bug seen time time never got reliable reproducer turn reset necessary something linked hack inside added,issue,negative,positive,neutral,neutral,positive,positive
559519395,"Note that you don't have to assign the value returned, the return is just there to make it easy to chain statements, such as:
```
learn = learn.load(""trained_model"").to_fp16()
```
Will add the missing type annotation.",note assign value returned return make easy chain learn add missing type annotation,issue,negative,positive,positive,positive,positive,positive
559362918,"> If so, Could you guys give an example or template about how to correctly use export() and load_learner functions in the customization case?

Did you get any best template to recover the same learner?",could give example template correctly use export case get best template recover learner,issue,positive,positive,positive,positive,positive,positive
559261703,"Like I said, your stack trace has sizes mismatch, for a text model on the vocab size, which means you don;t have the same vocab across processes (could come from the splitting train/validation, not sure since there is not all your code here).

Your workaround can't work since only the master process actually saves things in `Learner.save` (not sure which version of fastai you're using, but this is the case in master), so most of your tmp-something files don't exist.",like said stack trace size mismatch text model size across could come splitting sure since code ca work since master process actually sure version case master exist,issue,positive,positive,positive,positive,positive,positive
558964654,"Thanks for the quick reply @sgugger !

The use case this will be applied to is the scheduled training on an ever-changing dataset, e.g.:
- Every 5 minutes, the dataset will be downloaded (it may change compared to 5 minutes ago).
- A new process will be spun off to do the training, using the downloaded dataset.
- Hence, there may be multiple training processes running concurrently, but each with their own downloaded dataset.

Thus far, the only portion of the fastai code that does not work well with concurrent training processes is the LR finder (which is what this issue is about).

Hope this better explains the issue.

If this use case is not generally applicable then I'm ok to use a custom-made patch to the fastai code.

Otherwise, hope that it's something that the fastai developers can consider, especially if other fastai users face the same scenario / use case. I don't mind contributing to the fastai code as well if so :)",thanks quick reply use case applied training every may change ago new process spun training hence may multiple training running concurrently thus far portion code work well concurrent training finder issue hope better issue use case generally applicable use patch code otherwise hope something consider especially face scenario use case mind code well,issue,positive,positive,positive,positive,positive,positive
558845416,"I see, thanks! Always thought the size in transforms was just for the resizing but guess it is used by both. As for my case, I leave the solution in case others come in the future:

Doing 
`transform(([split_image_in_half(), crop_pad()], [crop_pad()]), tfm_y=True, size=512, padding_mode='zeros')`

instead of 

`transform(([split_image_in_half(), crop_pad(size=512, padding_mode='zeros')], [crop_pad(size=512, padding_mode='zeros')]), tfm_y=True)`

or

`.transform(([split_image_in_half(), crop_pad()], [crop_pad()]), tfm_y=True, size=512, padding_mode='zeros', resize_method=ResizeMethod.PAD)`

worked.",see thanks always thought size guess used case leave solution case come future transform instead transform worked,issue,positive,positive,neutral,neutral,positive,positive
558822058,Thanks! Everything was correct indeed :),thanks everything correct indeed,issue,negative,positive,positive,positive,positive,positive
558775807,"Yes, this is the same issue. The problem comes from the `pathlib` library that has incompatible path objects between different operating systems. You need to save/load your `Learner` object, not export it.",yes issue problem come library incompatible path different operating need learner object export,issue,negative,neutral,neutral,neutral,neutral,neutral
558762697,"@sgugger Hey I too get the `NotImplementedError: cannot instantiate 'PosixPath' on your system` error.

For reference, I created the .pkl file in kaggle using learn.export() and am currently trying to use it in a Windows Machine. From what I can infer from above this shouldn't be creating a problem right?",hey get system error reference file currently trying use machine infer problem right,issue,negative,positive,positive,positive,positive,positive
558676897,"I'm not sure about your use case but the cropping will be the last transform to be applied (it has an order of 99 and all transforms are sorted by order in apply_tfms).
`crop_pad` is a bit weird in the sense that the size you pass to `crop_pad` only matter if you use it directly:
```
img = crop_pad(size=256)(img)
```
When using `apply_tfms`, the size is replaced by the size you pass along, so you need to give it there too:
```
img = img.apply_tfms(crop_pad, size=256)
```
I tested both on an example and the output has the right shape. It's the same for the `padding_mode`, you need to pass it to `apply_tfms` or it will be replaced by the default of that function.",sure use case last transform applied order sorted order bit weird sense size pas matter use directly size size pas along need give tested example output right shape need pas default function,issue,negative,positive,neutral,neutral,positive,positive
558659133,"There is a `new_zeros` method for tensor that would this more nicely. I think `zer = fps.new_zeros(1)` would work and be nicer, if you don't mind changing your code.",method tensor would nicely think zer would work mind code,issue,negative,positive,positive,positive,positive,positive
558658361,"Oh good catch, thanks!",oh good catch thanks,issue,positive,positive,positive,positive,positive,positive
558198263,"I just looked and the safeguards for load/save are already there (only the master model is save and there is a `distrib_barrier` before the load). Form your stack trace, it appears you don't share the same vocabulary accross processes. You should do the preprocessing before anything distributed then load your data exactly the same way in all processes.",already master model save load form stack trace share vocabulary anything distributed load data exactly way,issue,positive,positive,positive,positive,positive,positive
558181385,You have to run an LR finder on a single process. It is not compatible with distributed training (losses are not reduced for instance). I can add a hack to prevent the error but it won't fix the fact that the result is going to be misleading.,run finder single process compatible distributed training reduced instance add hack prevent error wo fix fact result going misleading,issue,negative,negative,neutral,neutral,negative,negative
557931842,"I had this error when importing labels from cleaned.csv. Changed code in ""image_cleaner.py"" for a quick fix:
        idxs = ((i for i in fns_idxs if items[i].is_file())
changed to:
        idxs = ((i for i in fns_idxs if Path(items[i]).is_file())",error code quick fix path,issue,negative,positive,positive,positive,positive,positive
557774401,"Since there is no real impact, let's ignore and keep the focus on other, more important stuff.
Thanks for your excellent work, Sylvain @sgugger.",since real impact let ignore keep focus important stuff thanks excellent work,issue,positive,positive,positive,positive,positive,positive
556041050,"I have no idea of how to fix this and we are fully focused on 2 development, so I just put a known issue in the documentation in this [commit](https://github.com/fastai/fastai/commit/4bc7e047cb3dcc45804d27d3c3659b4fffc7129b).",idea fix fully development put known issue documentation commit,issue,negative,neutral,neutral,neutral,neutral,neutral
556040680,This [commit](https://github.com/fastai/fastai/commit/4bc7e047cb3dcc45804d27d3c3659b4fffc7129b) adds the known issue flag in the docs.,commit known issue flag,issue,negative,neutral,neutral,neutral,neutral,neutral
556028408,"Yes `Learner.summary` didn't even work with the text models at first. This is a known issue that we don't plan to fix in v1 as we're focused on v2 now. If you have a simple fix, feel free to suggest a PR, otherwise it will stay like this.

I will add a mention in the docs about this and close the issue",yes even work text first known issue plan fix simple fix feel free suggest otherwise stay like add mention close issue,issue,positive,positive,positive,positive,positive,positive
555625492,"> If I try to call
> 
> `leaner.load(NAME)`
> 
> I get this error:
> 
> ```
>     learner = get_learner(model_name, model_dir, callbacks=[store_inputs], root=root, transform=get_transform(None, scale=10),  tr=0.45, n=1)
>   File ""/Users/vaevictis/Documents/Project/Master-Thesis/core/estimators/utils.py"", line 31, in get_learner
>     learner.load(load_metric)
>   File ""/usr/local/lib/python3.6/site-packages/fastai/basic_train.py"", line 261, in load
>     if purge: self.purge(clear_opt=ifnone(with_opt, False))
>   File ""/usr/local/lib/python3.6/site-packages/fastai/basic_train.py"", line 320, in purge
>     self.callbacks = [load_callback(c,s, self) for c,s in cb_state.items()]
>   File ""/usr/local/lib/python3.6/site-packages/fastai/basic_train.py"", line 320, in <listcomp>
>     self.callbacks = [load_callback(c,s, self) for c,s in cb_state.items()]
>   File ""/usr/local/lib/python3.6/site-packages/fastai/basic_train.py"", line 577, in load_callback
>     init_kwargs, others = split_kwargs_by_func(state, class_func.__init__)
>   File ""/usr/local/lib/python3.6/site-packages/fastai/core.py"", line 262, in split_kwargs_by_func
>     args = func_args(func)
>   File ""/usr/local/lib/python3.6/site-packages/fastai/core.py"", line 253, in func_args
>     code = func.__code__
> AttributeError: 'wrapper_descriptor' object has no attribute '__code__'
> ```
> 
> My `fastai` version is `1.0.50.post1`
> 
> Thank you in advance,
> 
> Best

Make sure you have `@dataclass` annotation above your custom callback class.",try call name get error learner none file line file line load purge false file line purge self file line self file line state file line file line code object attribute version post thank advance best make sure annotation custom class,issue,positive,positive,positive,positive,positive,positive
555601185,"@sgugger Thank you, I understand. Yet, have a look at the code again: Github makes it look like a lot changed, but it's just changing single values to lists and iterating over them. ",thank understand yet look code look like lot single,issue,positive,negative,neutral,neutral,negative,negative
555533272,"Thanks for your PR.
It's a lot of changes for this simple callback, so I think it should have its own separate class. I'm closing this for now as we try to stabilize the core of v1 before the v2 release, and especially since it would make a lot of sense to have this be part of a fastai-contrib repo we will build soon for v2. In the meantime, do not hesitate to make a gist out of your code and share it on the forum so that people can use it as it seems like a useful feature. Thanks again!",thanks lot simple think separate class try stabilize core release especially since would make lot sense part build soon hesitate make gist code share forum people use like useful feature thanks,issue,positive,positive,positive,positive,positive,positive
555531641,"Thanks!
I think all the inner details can be added in the doc notebook, especially as it can be done in some interacting way. And the behavior of this concat function can be further explained there.",thanks think inner added doc notebook especially done way behavior function,issue,negative,positive,neutral,neutral,positive,positive
555530586,"The `path` attribute of the `LabelList` is only used to be passed to `DataBunch` then the `Learner`, and only the training one. So while this is a bug, I'm not sure it has any impact on anything. If the fix is easy, please go ahead and make a PR otherwise I wouldn't bother.",path attribute used learner training one bug sure impact anything fix easy please go ahead make otherwise would bother,issue,positive,positive,positive,positive,positive,positive
555491189,"It is meant to be as having a tiny last batch will cause instability in the batchnorm layers. And if the batch is of size 1, it will cause an error.
You can change this by adding `data.train_dl = data.train_dl.new(drop_last=False)` but for the reasons above, it isn't recommended unless you have a model without batchnorm.",meant tiny last batch cause instability batch size cause error change unless model without,issue,negative,neutral,neutral,neutral,neutral,neutral
555488419,It seems the fix is trivial. I am willing to provide a PR.,fix trivial willing provide,issue,negative,positive,positive,positive,positive,positive
555303556,... and type hints fixed in one more place.,type fixed one place,issue,negative,positive,neutral,neutral,positive,positive
555250671,This is a very old version of fastai that seems mixed up with a new one. You should try to do a clean install.,old version mixed new one try clean install,issue,negative,positive,positive,positive,positive,positive
555169328,"Oh sorry, I forgot. I also messed up and deleted the repo so I'll remake the pull request",oh sorry forgot also remake pull request,issue,negative,negative,negative,negative,negative,negative
555076186,"OK, removed the comments. They were not the most elegant, sure.

Although I must add that having worked with `fastai.text` a few times at different points in time, every time I come back to it I find it a bit confusing. Several lists of (lists of) tensors get passed around, in ways and for reasons that are not very clear. 

I do get it, a lot of it is for `RNNTrainer`'s benefit, but neither the reason not the exact way seems very apparent from the code. I think for people that are not using a `learner` as a black box, but also haven't spent much time developing the library, some amount of in-code explanations would be useful.  Unfortunately, I do not know how to do it exactly within `fast.ai`'s coding style.

Sorry for the ranty message, maybe you (@sgugger) have some idea how to make this code more approachable? (it's internal structure, the interfaces seem completely fine...) 
",removed elegant sure although must add worked time different time every time come back find bit several get around way clear get lot benefit neither reason exact way apparent code think people learner black box also spent much time library amount would useful unfortunately know exactly within style sorry ranty message maybe idea make code approachable internal structure seem completely fine,issue,positive,positive,neutral,neutral,positive,positive
555048130,"Hi there, just checking if you wanted to close this PR or make the modification I requested. Thanks!",hi close make modification thanks,issue,negative,positive,positive,positive,positive,positive
555046374,"Thanks for your PR! All the type annotations are good. For the concat method, I would rather not add those comments. For one, the method is private-ish so the end user doesn't need to know how it works and then I personally find the source code more helpful than those comments. In any case, any bit of extra documentation should go in the corresponding doc notebook.",thanks type good method would rather add one method end user need know work personally find source code helpful case bit extra documentation go corresponding doc notebook,issue,positive,positive,positive,positive,positive,positive
554720518,"For a newer implementation this might be what you are looking:
https://docs.fast.ai/tabular.html

Still figuring the details though.",implementation might looking still though,issue,negative,neutral,neutral,neutral,neutral,neutral
554717831,"@sgugger what does ""before"" means. Please provide a link or reference an earlier issue.

This is relevant for all of us who are trying to follow the Machine Learning Course:
https://github.com/fastai/fastai/blob/master/courses/ml1/lesson1-rf.ipynb

Thanks in advance.",please provide link reference issue relevant u trying follow machine learning course thanks advance,issue,positive,positive,positive,positive,positive,positive
552954312,"Oh, so then we can't do anything until they fix it on their side...",oh ca anything fix side,issue,negative,neutral,neutral,neutral,neutral,neutral
552674277,I have no problem with the first two changes (This can be/It is and contributing/coming) but the third change you made makes the sentence less clear to me. I'd like to keep the current version for this part.,problem first two third change made sentence le clear like keep current version part,issue,negative,positive,neutral,neutral,positive,positive
552673485,"Please follow the template to file an issue. Also, this doesn't seem to have any link with the fastai library.",please follow template file issue also seem link library,issue,negative,neutral,neutral,neutral,neutral,neutral
552476851,"ah @sgugger already fixed this hah. Redundant comment above, please ignore =P

Edit: Seems like adding quotes will not solve this. I have commented in the commit page. Not sure how to actually fix it though -- I don't know how to correctly escape/quote args that are passed to .cc...",ah already fixed hah redundant comment please ignore edit like solve commit page sure actually fix though know correctly,issue,positive,positive,neutral,neutral,positive,positive
552476704,"I can see that it's passing something like `""--input=/path/to/with space/tmp/all_text.out --max_sentence_length=20480""` into `SentencePieceTrainer.Train`, where the expected args are space-separated and thus it thinks `space/tmp/all_text.out` is the next argument, which is an unknown field for TrainerSpec. This is repeated for `--model_prefix=` later on in the arg list.

Not sure how best to fix this... I guess we could try to pass some quotes / escape chars so that SentencePieceTrainer knows that it is a path with space in it (I could not get that to work), or perhaps detect the path with space first, and change the `--input` and `--model_prefix` (both seem to be temp) to another path without space in it, before calling `SentencePieceTrainer`?",see passing something like thus next argument unknown field repeated later list sure best fix guess could try pas escape path space could get work perhaps detect path space first change input seem temp another path without space calling,issue,positive,positive,positive,positive,positive,positive
552468374,"Added quotes, which should normally solve this issue. Thanks for flagging!",added normally solve issue thanks flagging,issue,positive,positive,positive,positive,positive,positive
552381007,"That's cool @rwightman, do you think it's possible to apply your solution to simpler unets, for example the one in camvid segmentation? 
I'm trying to build a solution or a workaround for this.
Thanks for the help
",cool think possible apply solution simpler example one segmentation trying build solution thanks help,issue,positive,positive,positive,positive,positive,positive
552145615,"Please use the template to file an issue, we can't help you otherwise.",please use template file issue ca help otherwise,issue,positive,neutral,neutral,neutral,neutral,neutral
550423642,"No it won't, since the derivative of this with respect to the trainable layers will be 0. It just doesn't have any effect until we unfreeze up to the last to second layer (or more).",wo since derivative respect trainable effect unfreeze last second layer,issue,negative,neutral,neutral,neutral,neutral,neutral
550422958,"No, as you can see on the lines after, it handles listy inputs/outputs. The `hook_func` you pass will have to handle listy inputs/outputs, but the `Hook` class in general can handle them.",see pas handle hook class general handle,issue,negative,positive,neutral,neutral,positive,positive
550368575,"@sgugger I'm encountering an issue at the same line when trying to install fastai via pip3 on a Ubuntu 16.04 Docker container. 
The shebang at the top of setup.py specifies it's intended to be interpreted by Python 2.7, but `print(f""Error: Invalid group name(s): {', '.join(invalid_groups)}"")` is only valid syntax in Python 3. During the installation process, setup.py is run with Python 2.7, producing a syntax error rather than the useful error message that is supposed to be printed here.
",issue line trying install via pip docker container shebang top intended python print error invalid group name valid syntax python installation process run python syntax error rather useful error message supposed printed,issue,negative,positive,positive,positive,positive,positive
550195250,"Hi @sgugger, 

The `hookfn` in the  [Hook](https://github.com/fastai/fastai/blob/master/fastai/callbacks/hooks.py#L18) class is also expecting the input and output to be tensors. Which prevents me from implementing a `HookCallback`",hi hook class also input output,issue,negative,neutral,neutral,neutral,neutral,neutral
550016028,"Yes `ActivationStats` only works with neural nets whose activations are all tensors, you will have to write your own `CallbackHook` for AWD-LSTMs.",yes work neural whose write,issue,negative,neutral,neutral,neutral,neutral,neutral
549401856,"Hi @sgugger, 
I apologize for the lack of clarity. I am not trying to argue against the benefits of gradually unfreezing the layers. 

My only confusion is, won't adding terms to the loss which the model can't reduce have a detrimental effect on the learning process?   ",hi apologize lack clarity trying argue gradually unfreezing confusion wo loss model ca reduce detrimental effect learning process,issue,negative,neutral,neutral,neutral,neutral,neutral
549379209,"I still don't understand what the problem is. The penalty is the same kind as weight decay, which is only applied to unfrozen layers. When the network is frozen, AR/TAR is added to the loss but doesn't add anything to the gradients since the variables it depends on are not flagged with them, it only gets applied when you unfreeze those layers, exactly like weight decay isn't applied to frozen layers.

It doesn't mean we should always unfreeze all layers to have weight decay applied. The effects of gradually unfreezing have been shown to be beneficial in the ablation studies of the ULMFiT paper. AS for your experiment, yes a network frozen will have poorer results than a network with more trainable layers but that's not a fair comparison (and you will likely see the same difference with no AR/TAR). SOTA for a forward AWD-IMDB is 94.9% as shown in[this notebook](https://github.com/fastai/fastai/blob/master/examples/ULMFit.ipynb).",still understand problem penalty kind weight decay applied unfrozen network frozen added loss add anything since applied unfreeze exactly like weight decay applied frozen mean always unfreeze weight decay applied effect gradually unfreezing shown beneficial ablation paper experiment yes network frozen network trainable fair comparison likely see difference forward shown notebook,issue,negative,positive,positive,positive,positive,positive
549233948,"Hi @sgugger , 
No, this is not just a verification of a doubt. 
The documentation states that the TAR and AR regularizations have been taken from [this](https://arxiv.org/abs/1708.02182) paper. 
Now the section describing TAR and AR states: 

```
AR penalizes activations that are significantly larger than 0 as
a means of regularizing the network.
```
and 
```
TAR falls under the broad category of slowness regularizers
 (Hinton, 1989; Földiák, 1991; Luciw & Schmidhuber, 2012; Jonschkowski & Brock, 2015)
 which penalize the model from producing large changes in the hidden state.
```
which imply these terms are intended to have a regularization effect on the LSTM. 

So the mismatch as per my understanding is this: 
In its default state, we are adding a term to regularize the last LSTM in the AWD_LSTM but that can't happen because we are not letting the gradients affect the last LSTM. 


Thus, when everything is frozen apart from the last layer we should not be adding the AR and  TAR terms. The regularization term should be added when the LSTM which we are using to compute the term is not frozen. 

EDIT: I tried putting this into code [here](https://github.com/vimarshc/fastai_experiments/blob/master/Norm_Stabilizer.ipynb).
And though I realize there is a bit of variance every time you run an experiment, at least in this iteration unfreezing the LSTM does give better results. 

I shall try to plot graphs for the observations as the paper states. ",hi verification doubt documentation tar ar taken paper section tar ar ar significantly network tar broad category brock penalize model large hidden state imply intended regularization effect mismatch per understanding default state term regularize last ca happen affect last thus everything frozen apart last layer ar tar regularization term added compute term frozen edit tried code though realize bit variance every time run experiment least iteration unfreezing give better shall try plot paper,issue,negative,positive,neutral,neutral,positive,positive
549207409,"I don't understand what the issue is. In the first example, everything is frozen apart from the last group of layer (which doesn't include the last LSTM, as explained in the [ULMFiT paper](https://arxiv.org/abs/1801.06146), and in the second one, everything apart from the last two groups are frozen. 
If this is just to understand the mechanism of how the library works, please use the [forum](https://forums.fast.ai/) as we keep issues for known bugs only.",understand issue first example everything frozen apart last group layer include last paper second one everything apart last two frozen understand mechanism library work please use forum keep known,issue,negative,positive,neutral,neutral,positive,positive
549135465,"Not in v1 no. We'll look at integrating closer with the transformes repo in v2. Closing this as we keep issues for bugs only, please use the [forum](https://forums.fast.ai/) for feature requests.",look closer keep please use forum feature,issue,negative,neutral,neutral,neutral,neutral,neutral
549091693,"SO if this fixes it, I'm going to close this issue. Please reopen if needed.",going close issue please reopen,issue,negative,neutral,neutral,neutral,neutral,neutral
549067046,"Update the ```UnicodeEncodeError: 'ascii' codec can't encode character '\u2588' in position 15: ordinal not in range(128)``` error was the same as the [unicode error of fast progress](https://github.com/fastai/fastprogress/issues/21) a simple fix was using ```export LC_ALL=""en_US.UTF-8```",update ca encode character position ordinal range error error fast progress simple fix export,issue,negative,positive,neutral,neutral,positive,positive
549065029,"@sgugger I tried your suggestions I am getting the following error 
```epoch     train_loss  valid_loss  accuracy  iou_curb  time
/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/vision/models/unet.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if ssh != up_out.shape[-2:]:
/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/vision/models/unet.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if ssh != up_out.shape[-2:]:
/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/vision/models/unet.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if ssh != up_out.shape[-2:]:
/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/vision/models/unet.py:31: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!
  if ssh != up_out.shape[-2:]:
Exception in thread Thread-1:
Traceback (most recent call last):
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py"", line 234, in _queue_processor
    request.write()
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/callbacks/tensorboard.py"", line 424, in write
    self.tbwriter.add_graph(model=self.model, input_to_model=self.input_to_model)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/writer.py"", line 520, in add_graph
    self.file_writer.add_graph(graph(model, input_to_model, verbose))
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/tensorboardX/pytorch_graph.py"", line 96, in graph
    torch.onnx._optimize_trace(trace, torch._C._onnx.OperatorExportTypes.ONNX_ATEN_FALLBACK)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/onnx/__init__.py"", line 42, in _optimize_trace
    trace.set_graph(utils._optimize_graph(trace.graph(), operator_export_type))
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/onnx/utils.py"", line 155, in _optimize_graph
    graph = torch._C._jit_pass_onnx(graph, operator_export_type)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/onnx/__init__.py"", line 52, in _run_symbolic_function
    return utils._run_symbolic_function(*args, **kwargs)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/onnx/utils.py"", line 504, in _run_symbolic_function
    return fn(g, *inputs, **attrs)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/onnx/symbolic.py"", line 88, in wrapper
    args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/onnx/symbolic.py"", line 88, in <listcomp>
    args = [_parse_arg(arg, arg_desc) for arg, arg_desc in zip(args, arg_descriptors)]
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/onnx/symbolic.py"", line 45, in _parse_arg
    raise RuntimeError(""ONNX symbolic expected a constant value in the trace"")
RuntimeError: ONNX symbolic expected a constant value in the trace

Traceback (most recent call last):
  File ""UNet_benchmark.py"", line 124, in <module>
    learn.fit_one_cycle(10, slice(lr), pct_start=0.9)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/train.py"", line 23, in fit_one_cycle
    learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py"", line 200, in fit
    fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py"", line 99, in fit
    for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastprogress/fastprogress.py"", line 75, in __iter__
    if self.auto_update: self.update(i+1)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastprogress/fastprogress.py"", line 92, in update
    self.update_bar(val)
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastprogress/fastprogress.py"", line 104, in update_bar
    else: self.on_update(val, f'{100 * val/self.total:.2f}% [{val}/{self.total} {elapsed_t}<{remaining_t}{end}]')
  File ""/home/ubuntu/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastprogress/fastprogress.py"", line 274, in on_update
    if printing(): WRITER_FN(to_write, end = '\r')
UnicodeEncodeError: 'ascii' codec can't encode character '\u2588' in position 15: ordinal not in range(128)```",tried getting following error epoch accuracy time converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize converting tensor python might cause trace incorrect ca record data flow python value constant future trace might generalize exception thread recent call last file line file line run file line file line write file line graph model verbose file line graph trace file line file line graph graph file line return file line return file line wrapper zip file line zip file line raise symbolic constant value trace symbolic constant value trace recent call last file line module slice file line file line fit fit self file line fit file line file line update file line else end file line printing end ca encode character position ordinal range,issue,positive,positive,neutral,neutral,positive,positive
549061825,"Your metric should return a tensor (remove the `.item()`) because otherwise, it can't be accumulated over all the processes of your distributed training.",metric return tensor remove otherwise ca distributed training,issue,negative,neutral,neutral,neutral,neutral,neutral
549061209,"I am facing the exact issue. Probably @sgugger might be able to shed some insight ? 
",facing exact issue probably might able shed insight,issue,negative,positive,positive,positive,positive,positive
548536579,"You're welcome, and thank you for reviewing the change!

Phil


On Fri, Nov 1, 2019 at 3:30 AM Sylvain Gugger <notifications@github.com>
wrote:

> Looks good, thanks a lot!
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/2393?email_source=notifications&email_token=AEXXI7V6W6WMEJNQG2HYLTLQRMW6NA5CNFSM4JHPTDG2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOECY7KDY#issuecomment-548533519>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AEXXI7VMQD4ZM3HELXOLPWTQRMW6NANCNFSM4JHPTDGQ>
> .
>
",welcome thank change wrote good thanks lot thread reply directly view,issue,positive,positive,positive,positive,positive,positive
548507747,"Sure, if I catch the update before you I'll post it here =)",sure catch update post,issue,negative,positive,positive,positive,positive,positive
548370075,"Yes, it looks like pillow-simd didn't catch up with the latest pillow release. Can you check from time to time what version pillow simd is? I'll do the same and when they release their 6.2 version, we can remove this.",yes like catch latest pillow release check time time version pillow release version remove,issue,positive,positive,positive,positive,positive,positive
548162551,"@sgugger I mentioned this to jeremy recently but probably best to leave a note here... I was working on some hooks for feature collection recently and ran into this problem, this was the first issue I came across on github. 

My usage is a bit different than the DynamicUnet, but I think the approach would work. If you stash the tensors in the hooks in a dict by tensor.device it prevents the mixup with DataParallel usage.

My WIP, messy example:
https://github.com/rwightman/pytorch-image-models/blob/condconvs_and_features/timm/models/gen_efficientnet.py#L1076
",recently probably best leave note working feature collection recently ran problem first issue came across usage bit different think approach would work stash usage messy example,issue,negative,positive,positive,positive,positive,positive
547397751,"> I did `sudo apt install libsixel-bin libsixel-dev libsixel1` and now I don't get the exception error anymore, but still no graph. Now the error is:
> 
> > LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
> 
> Of course I have `learn.recorder.plot()` in my code.

It's useful !  Thank you!",apt install get exception error still graph error finder complete type see graph course code useful thank,issue,negative,positive,positive,positive,positive,positive
546668084,"I solved the error by updating pandas with
pip install --upgrade pandas",error pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
546603395,"I've made the error message clearer in [this commit](https://github.com/fastai/fastai/commit/f89e59bc2f9baa1551f252b3f84fb5ecea71a20c), so closing this PR.",made error message clearer commit,issue,negative,neutral,neutral,neutral,neutral,neutral
546602827,"It's jsa169 (on the forum). See [this topic](https://forums.fast.ai/t/tensorboard-integration/38023). Closing the issue in the meantime, we will have a maintained tensorboard integration in v2.",forum see topic issue integration,issue,negative,neutral,neutral,neutral,neutral,neutral
546507106,I believe @sgugger had already made the required changes and hence the issue was closed. Fastai version has changed since then. Probably the newest version wouldnt have the same issue,believe already made hence issue closed version since probably version wouldnt issue,issue,negative,negative,neutral,neutral,negative,negative
546477205,"I have a similar issue, can you explain better how you solved it?",similar issue explain better,issue,negative,positive,positive,positive,positive,positive
546383209,"The forum is the place to ask this question, we keep issues for bugs in the library only.",forum place ask question keep library,issue,negative,neutral,neutral,neutral,neutral,neutral
546382908,"You can even add the test set after creating your DataBunch (it has a test method), but yes, in this case you need to add your test set *after* the transform step.",even add test set test method yes case need add test set transform step,issue,negative,neutral,neutral,neutral,neutral,neutral
546368129,"Ah, I see! How can I figure out the name of the author? There is no info about him/her in the docs.",ah see figure name author,issue,negative,neutral,neutral,neutral,neutral,neutral
546353536,"Exactly, I don't want transforms to be applied to my test set. The problem, is I am not capable of adding a test_set.
My hope was to have a default behavior when passing a `test_set` without labels, overriding the `tfm_y=True`.
As `test` sets are always unlabeled on fastai, how to do you deal with `tfm_y=True` for an Image->Image pipeline?
Digging into the code, if you add a test_set with the data_block API using:
`.add_test_folder(test_path, tfms=None, tfm_y=False))`  before the transforms, then `tfm_y` for the test dataset will be overriden by the transforms argument `tfm_y`.

Ok I think I got it, you have to add test sets after transforms. For me that was counter intuitive, Maybe a warning if you add them before transforms. The problem is that transforms is optional, so they could be added after labeling.
```
ImageImageList.from_folder(train_path)
       .split_by_rand_pct()
       .label_from_func(lambda x: x)
       .transform(get_transforms(), tfm_y=True)
       .add_test_folder(test_path, tfms=None, tfm_y=False)
       .databunch(bs=bs).normalize(imagenet_stats, do_y=True)
```
This works.

A last comment, the `normalize(do_y=True)` knows not to apply to test sets for instance.
",exactly want applied test set problem capable hope default behavior passing without test always unlabeled deal image pipeline digging code add test argument think got add test counter intuitive maybe warning add problem optional could added lambda work last comment normalize apply test instance,issue,negative,positive,positive,positive,positive,positive
546345477,"You can't apply transforms at inference without post-processing your results. I don't know what your transforms are but if you crop your inputs for instance, then the predictions you get are only for that cropped part and not the image in its totality.
The error is there to make you realize something is wrong (though the meassage could be clearer). You have to disable those transforms by creating your test set passing `tfms=None, tfm_y=False`.",ca apply inference without know crop instance get part image totality error make realize something wrong though could clearer disable test set passing,issue,negative,negative,negative,negative,negative,negative
546344306,"It's very usual that the test set does not have labels, and we want to produce those labels. So you get a `LabelList` with `EmptyLabel`, how to solve this?
Maybe there is another way of doing this that I am not seeing?",usual test set want produce get solve maybe another way seeing,issue,negative,negative,negative,negative,negative,negative
546339914,"This step fails on purpose as it is a sign something is wrong: trying to apply transforms to an input when they should also be applied to the target, which means they should be reversed on the predicted output to get proper predictions.
I don't think letting them pass is a good idea, at least not without a proper warning.",step purpose sign something wrong trying apply input also applied target reversed output get proper think pas good idea least without proper warning,issue,negative,negative,neutral,neutral,negative,negative
546339375,"This is an external contribution, so you will have more luck seeking help on the forum with the person who implemented it. This is not maintained on our side and will only be fully added in fastai v2.",external contribution luck seeking help forum person side fully added,issue,positive,neutral,neutral,neutral,neutral,neutral
545949846,"Thanks @acere 
For some reason the same code used in v2 was causing this problem and your fix worked perfectly. I just pushed it in the source code of v1 too. ",thanks reason code used causing problem fix worked perfectly source code,issue,positive,positive,positive,positive,positive,positive
545645975,"I am unsure what the issue is. Installing fastai with conda is not supposed to put any files in a fastai directory, just installing the library in your conda environment to use it in python/ipython/jupyter.",unsure issue supposed put directory library environment use,issue,negative,neutral,neutral,neutral,neutral,neutral
545445538,Please follow the template for an issue. We can't magically fix a bug just from a partial error message without seeing any code.,please follow template issue ca magically fix bug partial error message without seeing code,issue,negative,positive,positive,positive,positive,positive
544514259,"Yes, this is a clunky check to make sure the model has parameters. This is corrected in v2 already, I'll push a fix for v1.",yes check make sure model corrected already push fix,issue,positive,positive,positive,positive,positive,positive
544300887,There is a function `rank_distrib` that could be useful to use (and adapt if it doesn't always return the right result). That's what we use in distributed.,function could useful use adapt always return right result use distributed,issue,negative,positive,positive,positive,positive,positive
544260770,"By the way, sometimes both threads try to write the same model, resulting in a bad model file. I suggest just adding the SaveModelCallBack when local_rank == 0.",way sometimes try write model resulting bad model file suggest,issue,negative,negative,negative,negative,negative,negative
544260531,"But why did you close the issue? It's not a problem with pytorch, it's a compatibility issue with fastai. It's not a problem with from_name_re, just with an ImageDataBunch in general. It seems some default behaviour that fast.ai relies on will be changed next version and pytorch is warning us about that.

I'm getting the same warnings since upgrading to pytorch 1.3.

Here is a workaround:
import warnings
warnings.simplefilter(""ignore"")

Edit: Oh, I see, [here](https://github.com/fastai/fastai/issues/2370) is the issue reported too.",close issue problem compatibility issue problem general default behaviour next version warning u getting since import ignore edit oh see issue,issue,negative,positive,neutral,neutral,positive,positive
544200785,"My bad, this is seems to be problem with PyTorch and shows up throughout the whole lesson 1.",bad problem throughout whole lesson,issue,negative,negative,negative,negative,negative,negative
544198512,"This was an oversight on our side, thanks for fixing!",oversight side thanks fixing,issue,negative,positive,positive,positive,positive,positive
543208870,"Oh sorry. Didn't know that. I'll try to reproduce it with inbuilt datasets.
Which one would you prefer?

On Thu, Oct 17, 2019 at 6:46 AM Sylvain Gugger <notifications@github.com>
wrote:

> Closed #2382 <https://github.com/fastai/fastai/issues/2382>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2382?email_source=notifications&email_token=AAFDWXH7DDOOLFBOLTM2WUTQPBUCDA5CNFSM4JBUUIGKYY3PNVWWK3TUL52HS4DFWZEXG43VMVCXMZLOORHG65DJMZUWGYLUNFXW5KTDN5WW2ZLOORPWSZGOUI2IHHI#event-2721350557>,
> or unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AAFDWXBWFFZAM26L7VR2IJDQPBUCDANCNFSM4JBUUIGA>
> .
>
-- 
Regards Nitin Pasumarthy Sent from a mobile
",oh sorry know try reproduce inbuilt one would prefer wrote closed thread reply directly view sent mobile,issue,negative,negative,negative,negative,negative,negative
543197723,"Thinking twice, it doesn't hurt to convert the predictions to float in `get_preds`. Even in training, the outputs are converted to floats by the callback. Just running the tests to check it doesn't break anything but this makes TTA work in FP16 mode.",thinking twice hurt convert float even training converted running check break anything work mode,issue,negative,neutral,neutral,neutral,neutral,neutral
543190161,"> I can add a defensive test at the beginning of TTA so that the error comes immediately

It will be great, thank you!

> Mixed precision isn't meant to be used outside of training

Generally speaking, you are right.
However, sometimes even inference is taking too long (and TTA takes 9x time!), and FP16 can give it a boost. So if it is possible to use FP16 in TTA, maybe it's not a bad thing to do?
If you are worried about this approach being unexpected for users, we can add a UserWarning.",add defensive test beginning error come immediately great thank mixed precision meant used outside training generally speaking right however sometimes even inference taking long time give boost possible use maybe bad thing worried approach unexpected add,issue,negative,positive,neutral,neutral,positive,positive
543183090,Mixed precision isn't meant to be used outside of training. I can add a defensive test at the beginning of TTA so that the error comes immediately (good practice is to always try thing on a sample first to avoid bad surprises :) ),mixed precision meant used outside training add defensive test beginning error come immediately good practice always try thing sample first avoid bad,issue,negative,positive,neutral,neutral,positive,positive
543181711,"I'm not sure what the bug in the library is? The fact you're not managing to train those models on your data suggests a problem with your model or data. Please use the [forum](https://forums.fast.ai) for help on this, we keep the issues for known bugs only.",sure bug library fact train data problem model data please use forum help keep known,issue,positive,positive,positive,positive,positive,positive
543149592,"I'd like to raise this issue again.
TTA can take some time (e.g. for me it takes 4 hours for current RSNA Kaggle competition), and it's a shame that issue raises only at the end of TTA process.

I guess, that the expected behavior is at least to check whether model is in fp16 and raise an exception at the beginning of the method.

Also, at the moment torch.stack works for fp16, and the actual issue is with torch.mean. It can be handled in a couple of ways:
1) Convert tensors in all_preds to FP32 (we can even convert it back to FP16 later)
2) Use safe FP16 mean implementation (e.g. like mentioned: https://github.com/pytorch/pytorch/issues/12115)

@sgugger could you please check this issue? If you think that one of the solutions I mentioned is reasonable, I am willing to implement it into PR since current behavior can be a bit irritating for users.",like raise issue take time current competition shame issue end process guess behavior least check whether model raise exception beginning method also moment work actual issue handled couple way convert even convert back later use safe mean implementation like could please check issue think one reasonable willing implement since current behavior bit irritating,issue,negative,negative,neutral,neutral,negative,negative
542870839,"It's hard to say without seeing your installation details (please follow the template) but I would say your version of fastai is too old and prior to rename of this function. This runs fine on the latest version, you should update your library.",hard say without seeing installation please follow template would say version old prior rename function fine latest version update library,issue,negative,positive,positive,positive,positive,positive
542746395,"Ok, should be fixed by [this commit](https://github.com/fastai/fastai/commit/531e0f0ddeaba8dff93e79c3a9e9deb807755c17). The problem was that there was another `TextClassificationInterpretation` defined in models.awd_lstm and this one didn't have the `ordered=True` in the call to get_preds.",fixed commit problem another defined one call,issue,negative,positive,neutral,neutral,positive,positive
542731348,"```
learn = text_classifier_learner(data, arch=AWD_LSTM ,drop_mult=0.7, metrics=[accuracy])
##fine-tuning steps
interp = TextClassificationInterpretation.from_learner(learn) 

```
now when i use interp.show_top_losses(10) it's showing wrong datapoints corresponding to loss column.
so I investigate further and found that value and indices in interp.top_losses() does not match. so I used learn object to get the prediction with losses and modified the show_top_losses function.",learn data accuracy learn use showing wrong corresponding loss column investigate found value index match used learn object get prediction function,issue,negative,negative,negative,negative,negative,negative
542727015,"That function doesn't know the learner object, so this can't work. The function will only give the correct output if the `Learner` used to create it is called `learn`, you can't rely on that kind of behavior.

I don't understand the bug you are trying to fix so maybe start with a small reproducible example so we can address it properly.",function know learner object ca work function give correct output learner used create learn ca rely kind behavior understand bug trying fix maybe start small reproducible example address properly,issue,positive,positive,positive,positive,positive,positive
542723579,learn is the text_classifier_learner. I used learn object as interpretation was generating wrong ids corresponding to losses. So the loss column of show_top_losses() is not being matched with text column.,learn used learn object interpretation generating wrong corresponding loss column text column,issue,negative,negative,negative,negative,negative,negative
542696441,I don't understand your PR: what is this `learn` you use everywhere? It's not an argument of the function...,understand learn use everywhere argument function,issue,negative,neutral,neutral,neutral,neutral,neutral
541952210,Your last comment help me sort out my issue. Thanks.,last comment help sort issue thanks,issue,positive,positive,neutral,neutral,positive,positive
541652731,"There is a typo in your cod, you typed `self.setp_size = 1` instead of `self.step_size = 1`.

When asked for an attribute it doesn't have, `LearnerCallback` tries to get it inside its `Learner` (which is why you see this error message).",typo cod instead attribute get inside learner see error message,issue,negative,neutral,neutral,neutral,neutral,neutral
541488709,"I understand why you may like it more this way but in general, please refrain from PRs just changing the style of the code like this (see the [style note](https://docs.fast.ai/dev/style.html) for more thoughts of Jeremy about that).

While I'd agree with some of this spacing (deconstruting a tuple never has a space in fastai: `a,b = c,d`, the other changes are fine by me) the choice is ultimately on the person who originally wrote the code and we would like to spend time coding and not discussing minor stile issues (see the first note in the contributing file ""Contributing to Parkinson’s law of triviality has negative consequences for a project. Let’s focus on deep learning!"")",understand may like way general please refrain style code like see style note agree spacing never space fine choice ultimately person originally wrote code would like spend time minor stile see first note file law triviality negative project let focus deep learning,issue,positive,positive,neutral,neutral,positive,positive
541488130,"There is no need to add 17 interrogation marks, it's rather rude to do so. Especially when you don't even mention where your code comes from and don't follow our issue template.
For what it's worth, it looks like fastai 0.7 code, so no, it can't run with v1.0.x.",need add interrogation rather rude especially even mention code come follow issue template worth like code ca run,issue,negative,neutral,neutral,neutral,neutral,neutral
541484998,"That kwarg doesn’t exist in pytorch 1.2.0 or earlier, so if we do this, fastai will stop working with people having those versions.",exist stop working people,issue,negative,neutral,neutral,neutral,neutral,neutral
541481393,"The commit that added the change to PyTorch mentions [(PyTorch Commit)](https://github.com/pytorch/pytorch/commit/74b65c32be68b15dc7c9e8bb62459efbfbde33d8):
> The old functionality can still be achieved by setting `align_corners=True`

So why not set that as the default value in [c3c3241](https://github.com/fastai/fastai/commit/c3c3241d769245252e87baa7e147fefa2313e524)?
",commit added change commit old functionality still setting set default value,issue,positive,positive,neutral,neutral,positive,positive
541339351,"That could be a desired feature yes. This is not something we will implement as we're in the development of v2 and this callback is an external contribution.  Closing the issue as this is not a standing bug, you should post on the [forum](https://forums.fast.ai/) to see if someone wants to tackle this (or suggest a PR if you want to tackle it yourself).",could desired feature yes something implement development external contribution issue standing bug post forum see someone tackle suggest want tackle,issue,positive,neutral,neutral,neutral,neutral,neutral
541338862,Please follow the template when filing an issue. We can't help you if we don't understand what your problem is.,please follow template filing issue ca help understand problem,issue,negative,neutral,neutral,neutral,neutral,neutral
541268930,"when we have the orror: ctypes.ArgumentError: argument 2: <class 'TypeError'>: wrong type,
i have a temporary idea:
add code in the front: 
from fastprogress.fastprogress import IN_NOTEBOOK
IN_NOTEBOOK=True
and improve the code: learn.recorder.plot() to learn.recorder.plot(suggestion=True),

you can see the origin code:*/fastai/basic_train.py
in class Recorder(), see the function plot() last code:
if not IN_NOTEBOOK: plot_sixel(fig)
because plot first choice is notebook,  second choice plot_sixel(fig),
we can force choice notebook,that will be ok,and will print the best lr in epoch",argument class wrong type temporary idea add code front import improve code see origin code class recorder see function plot last code fig plot first choice notebook second choice fig force choice notebook print best epoch,issue,negative,positive,positive,positive,positive,positive
541254615,"It’s hard to know what you think the bug is if you don’t give us any code. If you use directly rmse_loss as a metric, you won’t get the square root of the mse loss since it averages the rmse losses of each batch. You should use RMSELoss() to have the real value.",hard know think bug give u code use directly metric get square root loss since batch use real value,issue,negative,positive,neutral,neutral,positive,positive
541238161,"It looks like the fix you made for this issue [2c97552](https://github.com/fastai/fastai/commit/2c975521aa8430bfafbbb27255c0c711a1354096) uses **.squeeze_check()** but the solution you linked to uses **flatten_check**

https://github.com/fastai/fastai/blob/2c975521aa8430bfafbbb27255c0c711a1354096/fastai/metrics.py#L76

Maybe the clarification I need is to be sure which solution is the correct one because we are still seeing that the MSE loss is more that the square of RMSE.",like fix made issue solution linked maybe clarification need sure solution correct one still seeing loss square,issue,positive,positive,positive,positive,positive,positive
541138817,"Thanks for flagging the issue! It should be fixed now (we just ignore the warning for no and will expose the argument when we bump the minimal version of PyTorch supported, but since the arg isn't there in 1.2 or earlier, we can't really use it).",thanks flagging issue fixed ignore warning expose argument bump minimal version since ca really use,issue,negative,positive,neutral,neutral,positive,positive
541135211,This has been fixed a while ago and is in the latest release. Outputs and targets are flattened before computing the metrics: https://github.com/fastai/fastai/blob/c655762c3dc835ea61ad9143d84f1c3b47fe60f4/fastai/metrics.py#L82,fixed ago latest release metric,issue,negative,positive,positive,positive,positive,positive
541125029,This does not appear to have made it into the releases. Was there another fix that resolved this?,appear made another fix resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
540952821,"> import numpy as np
> import matplotlib.pyplot as plt
> import libsixel,io
> 
> def _sixel_encode(data, width, height):
>     s = io.BytesIO()
>     output = libsixel.sixel_output_new(lambda data, s: s.write(data), s)
>     dither = libsixel.sixel_dither_new(256)
>     w,h = int(width),int(height)
>     libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
>     libsixel.sixel_encode(data, w, h, 1, dither, output)
>     return s.getvalue().decode('ascii')
> 
> def plot_sixel(fig=None):
>     if not libsixel:
>         warn(""You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel"")
>         return
>     if fig is None: fig = plt.gcf()
>     fig.canvas.draw()
>     dpi = fig.get_dpi()
>     res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
>     print(res)
> 
> fig, ax = plt.subplots(1,1)
> x = np.linspace(0,100)
> y = np.exp(x)
> ax.plot(x, y)
> ax.set_ylabel(""Loss"")
> ax.set_xlabel(""Learning Rate"")
> plot_sixel(fig)

I have the same error:
    libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
  File ""/data/soft/anaconda3/envs/hq1_workspace/lib/python3.6/site-packages/libsixel/__init__.py"", line 506, in sixel_dither_initialize
    quality_mode)
ctypes.ArgumentError: argument 2: <class 'TypeError'>: wrong type
and i have re-install libsixel twice",import import import io data width height output lambda data data dither width height dither data data dither output return warn could see plot see return fig none fig print fig ax loss learning rate fig error dither data file line argument class wrong type twice,issue,negative,negative,negative,negative,negative,negative
540951942,"is there any other ways to solve this problem?my computer system is centos,can't install mlterm",way solve problem computer system ca install,issue,negative,neutral,neutral,neutral,neutral,neutral
540877801,"Could you make a PR with that switch? In general if you have figured a fix with your bug, you can just create a PR for us to review :)",could make switch general figured fix bug create u review,issue,negative,positive,neutral,neutral,positive,positive
540237308,"PyTorch only added AdamW recently and we have our own implementation in fastai that is way older, so this is not a mistake. The key is not here but in the argument `true_wd` of `Learner` that defaults to `True`. See the [documentation](https://docs.fast.ai/basic_train.html#Learner) of `Learner` for more details.",added recently implementation way older mistake key argument learner true see documentation learner,issue,negative,positive,positive,positive,positive,positive
540078596,"`TestList` has a sep attribute though it has been added in a recent version. I'm thinking you are trying to load some data that was saved with an older version since I can't reproduce the bug on my side.
Just reprocess your data with the same version and you shouldn't have any problem.",attribute though added recent version thinking trying load data saved older version since ca reproduce bug side reprocess data version problem,issue,negative,positive,neutral,neutral,positive,positive
539278201,Is there a build of v1.3.0 like the nightlies somewhere easily accessible? ,build like somewhere easily accessible,issue,positive,positive,positive,positive,positive,positive
539271284,did you get a chance to test v1.3.0 against fastai ? 1.3.0 was branched off of master branch on at end of september.,get chance test branched master branch end,issue,negative,neutral,neutral,neutral,neutral,neutral
539098516,"I can't reproduce the failure with the nightlies. My best guess would be that something fails with setting up a directory without writing permissions in PyTorch integration testing. In any case this is a test we don't really need, the function in itself is already thoroughly tested, so we removed it.

Let me know if the tests pass now on your side @soumith and I'll close this issue.",ca reproduce failure best guess would something setting directory without writing integration testing case test really need function already thoroughly tested removed let know pas side close issue,issue,negative,positive,positive,positive,positive,positive
539047006,You forgot the extension: .tgz. Note that `untar_data` downloads it for you automatically.,forgot extension note automatically,issue,negative,neutral,neutral,neutral,neutral,neutral
539044679,"Oh thanks for warning us and including fastai on your integration testing. 
Not sure the issue here is related to anything in PyTorch since the normal `learn.purge` before passes and this is a test of a failure if we operate on a non-writable dir. Maybe there is a change in the error message. Let us know if it stays in the release branch, I'll try to reproduce on the nightlies in the meantime. ",oh thanks warning u integration testing sure issue related anything since normal test failure operate maybe change error message let u know stay release branch try reproduce,issue,negative,positive,positive,positive,positive,positive
538789012,"Tests are passing so it doesn't seem like it destroys anything :)
Thanks for the fix!",passing seem like anything thanks fix,issue,positive,positive,positive,positive,positive,positive
538754339,"@sgugger I think the code is worth updating independent of Python version.  The `imports/core.py` module is double importing `abc`.  I do not see the second import of `abc` being used so I think it is unnecessary (please correct me if I am wrong).  

I will issue a pull request that changes the [line](https://github.com/fastai/fastai/blob/af395a701d6660543c49804b4f2cb53a6e67f261/fastai/imports/core.py#L9)

`from collections import abc,  Counter, defaultdict, Iterable, namedtuple, OrderedDict`

to:

```
from collections import Counter, defaultdict, namedtuple, OrderedDict
from collections.abc import Iterable
```",think code worth independent python version module double see second import used think unnecessary please correct wrong issue pull request line import counter iterable import counter import iterable,issue,negative,negative,negative,negative,negative,negative
538646314,Thanks for flagging the issue! should be fixed now.,thanks flagging issue fixed,issue,negative,positive,positive,positive,positive,positive
538400768,I'm guessing the fix is just to import the right abc. Is it compatible with python 3.6? That's the minimal version we require.,guessing fix import right compatible python minimal version require,issue,negative,positive,neutral,neutral,positive,positive
537494372,"Yeah this is going to be terribly hacky. v2 will handle normalization better for tuple of images, so I suggest closing this for now and wait for the v2 release :)",yeah going terribly hacky handle normalization better suggest wait release,issue,negative,negative,negative,negative,negative,negative
537009112,"I was afraid of that part getting broken, it would be easy to change `denormalize` to work in a similar fashion to `_normalize_batch` (I think I would also move the functionality to `normalize` to maintain greater symmetry between the two).
All of that still leaves that singleton list getting returned from `one_batch` though. I am not sure if it makes sense to add a check for it that flattens that singleton (and possibly in other places in the code) or to give up on this whole thing and keep using my hacked version.",afraid part getting broken would easy change work similar fashion think would also move functionality normalize maintain greater symmetry two still leaf singleton list getting returned though sure sense add check singleton possibly code give whole thing keep hacked version,issue,negative,positive,neutral,neutral,positive,positive
536323522,Thanks for your PR. I don't think we should change the behavior with patience though.,thanks think change behavior patience though,issue,negative,positive,positive,positive,positive,positive
535937247,There is a problem for the denomalization then (see failing tests). You can run the tests locally by just typing pytest.,problem see failing run locally,issue,negative,neutral,neutral,neutral,neutral,neutral
535936756,"It's going to be v2 in the end, not v1.1, and it's under active development. You can track the progress on the [forum](https://forums.fast.ai/c/fastai-users/fastai-v2).",going end active development track progress forum,issue,positive,negative,negative,negative,negative,negative
535925582,"Dear @sgugger, just went trough the thread. When will v1.1 of fastai be realeased aproximately?",dear went trough thread,issue,negative,neutral,neutral,neutral,neutral,neutral
535420519,"fastai.conv_learner is available in old version of fastai.
install old version using 
pip install fastai==0.7.0 --no-deps",available old version install old version pip install,issue,negative,positive,positive,positive,positive,positive
535051650,"> @sgugger Hi. I tried this now.
> 
> ```
> p = cv2.imread('rooster.jpg') # p is numpy array with shape (height,width,channels)
> t = pil2tensor(p, dtype=np.uint8) # converts to numpy tensor
> t = t.permute(2,0,1) # Move num_channels as first dimension
> t = t.float()/255. #Convert to float
> im = Image(t) # Convert to fastAi Image - this class has ""apply_tfms""
> learn1.predict(im)
> ```
> 
> But it gives me the following error:
> 
> ```
> <ipython-input-160-770b213cea6a> in <module>
>       3 t = t.permute(2,0,1) # Move num_channels as first dimension
>       4 t = t.float()/255. #Convert to float
> ----> 5 im = Image(t) # Convert to fastAi Image - this class has ""apply_tfms""
>       6 learn1.predict(im)
> 
> TypeError: 'module' object is not callable
> ```

you are probably calling module but you have to call object of module",hi tried array shape height width tensor move first dimension convert float image convert image class following error module move first dimension convert float image convert image class object callable probably calling module call object module,issue,negative,positive,positive,positive,positive,positive
534722350,"This is a problem with your installation of PyTorch and multiprocessing, not fastai. You can work around it by passing `num_workers=0` when you create your `DataBunch`. This notebook runs fine on my side.",problem installation work around passing create notebook fine side,issue,negative,positive,positive,positive,positive,positive
534690089,"And `learn.lr_find()` also results in the same error

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _try_get_batch(self, timeout)
    510         try:
--> 511             data = self.data_queue.get(timeout=timeout)
    512             return (True, data)

/opt/conda/lib/python3.6/queue.py in get(self, block, timeout)
    172                         raise Empty
--> 173                     self.not_empty.wait(remaining)
    174             item = self._get()

/opt/conda/lib/python3.6/threading.py in wait(self, timeout)
    298                 if timeout > 0:
--> 299                     gotit = waiter.acquire(True, timeout)
    300                 else:

/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py in handler(signum, frame)
     62         # Python can still get and update the process status successfully.
---> 63         _error_if_any_worker_fails()
     64         if previous_handler is not None:

RuntimeError: DataLoader worker (pid 7921) is killed by signal: Bus error. 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-16-d81c6bd29d71> in <module>()
----> 1 learn.lr_find()

/opt/conda/lib/python3.6/site-packages/fastai/train.py in lr_find(learn, start_lr, end_lr, num_it, stop_div, wd)
     30     cb = LRFinder(learn, start_lr, end_lr, num_it, stop_div)
     31     epochs = int(np.ceil(num_it/len(learn.data.train_dl)))
---> 32     learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)
     33 
     34 def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,

/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
    197         callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(callbacks)
    198         if defaults.extra_callbacks is not None: callbacks += defaults.extra_callbacks
--> 199         fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)
    200 
    201     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, learn, callbacks, metrics)
     97             cb_handler.set_dl(learn.data.train_dl)
     98             cb_handler.on_epoch_begin()
---> 99             for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):
    100                 xb, yb = cb_handler.on_batch_begin(xb, yb)
    101                 loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)

/opt/conda/lib/python3.6/site-packages/fastprogress/fastprogress.py in __iter__(self)
     70         self.update(0)
     71         try:
---> 72             for i,o in enumerate(self._gen):
     73                 if i >= self.total: break
     74                 yield o

/opt/conda/lib/python3.6/site-packages/fastai/basic_data.py in __iter__(self)
     73     def __iter__(self):
     74         ""Process and returns items from `DataLoader`.""
---> 75         for b in self.dl: yield self.proc_batch(b)
     76 
     77     @classmethod

/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in __next__(self)
    574         while True:
    575             assert (not self.shutdown and self.batches_outstanding > 0)
--> 576             idx, batch = self._get_batch()
    577             self.batches_outstanding -= 1
    578             if idx != self.rcvd_idx:

/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _get_batch(self)
    541         elif self.pin_memory:
    542             while self.pin_memory_thread.is_alive():
--> 543                 success, data = self._try_get_batch()
    544                 if success:
    545                     return data

/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _try_get_batch(self, timeout)
    517             if not all(w.is_alive() for w in self.workers):
    518                 pids_str = ', '.join(str(w.pid) for w in self.workers if not w.is_alive())
--> 519                 raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))
    520             if isinstance(e, queue.Empty):
    521                 return (False, None)

RuntimeError: DataLoader worker (pid(s) 7921, 7923, 7925) exited unexpectedly
```",also error recent call last self try data return true data get self block raise empty item wait self true else handler signum frame python still get update process status successfully none worker signal bus error handling exception another exception recent call last module learn learn learn learner dynamic clip fit self self none fit self self none fit learn metric loss self try enumerate break yield self self process yield self true assert batch self success data success return data self raise worker return false none worker unexpectedly,issue,positive,positive,positive,positive,positive,positive
534683541,"```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _try_get_batch(self, timeout)
    510         try:
--> 511             data = self.data_queue.get(timeout=timeout)
    512             return (True, data)

/opt/conda/lib/python3.6/queue.py in get(self, block, timeout)
    172                         raise Empty
--> 173                     self.not_empty.wait(remaining)
    174             item = self._get()

/opt/conda/lib/python3.6/threading.py in wait(self, timeout)
    298                 if timeout > 0:
--> 299                     gotit = waiter.acquire(True, timeout)
    300                 else:

/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/signal_handling.py in handler(signum, frame)
     62         # Python can still get and update the process status successfully.
---> 63         _error_if_any_worker_fails()
     64         if previous_handler is not None:

RuntimeError: DataLoader worker (pid 3692) is killed by signal: Bus error. 

During handling of the above exception, another exception occurred:

RuntimeError                              Traceback (most recent call last)
<ipython-input-35-7255105954f6> in <module>()
----> 1 data.show_batch(rows=3, figsize=(12,9))

/opt/conda/lib/python3.6/site-packages/fastai/basic_data.py in show_batch(self, rows, ds_type, reverse, **kwargs)
    183     def show_batch(self, rows:int=5, ds_type:DatasetType=DatasetType.Train, reverse:bool=False, **kwargs)->None:
    184         ""Show a batch of data in `ds_type` on a few `rows`.""
--> 185         x,y = self.one_batch(ds_type, True, True)
    186         if reverse: x,y = x.flip(0),y.flip(0)
    187         n_items = rows **2 if self.train_ds.x._square_show else rows

/opt/conda/lib/python3.6/site-packages/fastai/basic_data.py in one_batch(self, ds_type, detach, denorm, cpu)
    166         w = self.num_workers
    167         self.num_workers = 0
--> 168         try:     x,y = next(iter(dl))
    169         finally: self.num_workers = w
    170         if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)

/opt/conda/lib/python3.6/site-packages/fastai/basic_data.py in __iter__(self)
     73     def __iter__(self):
     74         ""Process and returns items from `DataLoader`.""
---> 75         for b in self.dl: yield self.proc_batch(b)
     76 
     77     @classmethod

/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in __next__(self)
    574         while True:
    575             assert (not self.shutdown and self.batches_outstanding > 0)
--> 576             idx, batch = self._get_batch()
    577             self.batches_outstanding -= 1
    578             if idx != self.rcvd_idx:

/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _get_batch(self)
    541         elif self.pin_memory:
    542             while self.pin_memory_thread.is_alive():
--> 543                 success, data = self._try_get_batch()
    544                 if success:
    545                     return data

/opt/conda/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _try_get_batch(self, timeout)
    517             if not all(w.is_alive() for w in self.workers):
    518                 pids_str = ', '.join(str(w.pid) for w in self.workers if not w.is_alive())
--> 519                 raise RuntimeError('DataLoader worker (pid(s) {}) exited unexpectedly'.format(pids_str))
    520             if isinstance(e, queue.Empty):
    521                 return (False, None)

RuntimeError: DataLoader worker (pid(s) 3684, 3688, 3690, 3691, 3692, 3693, 3695, 3698) exited unexpectedly

Exception in thread Thread-5:
Traceback (most recent call last):
  File ""/opt/conda/lib/python3.6/threading.py"", line 916, in _bootstrap_inner
    self.run()
  File ""/opt/conda/lib/python3.6/threading.py"", line 864, in run
    self._target(*self._args, **self._kwargs)
  File ""/opt/conda/lib/python3.6/site-packages/torch/utils/data/_utils/pin_memory.py"", line 21, in _pin_memory_loop
    r = in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
  File ""/opt/conda/lib/python3.6/multiprocessing/queues.py"", line 113, in get
    return _ForkingPickler.loads(res)
  File ""/opt/conda/lib/python3.6/site-packages/torch/multiprocessing/reductions.py"", line 276, in rebuild_storage_fd
    fd = df.detach()
  File ""/opt/conda/lib/python3.6/multiprocessing/resource_sharer.py"", line 57, in detach
    with _resource_sharer.get_connection(self._id) as conn:
  File ""/opt/conda/lib/python3.6/multiprocessing/resource_sharer.py"", line 87, in get_connection
    c = Client(address, authkey=process.current_process().authkey)
  File ""/opt/conda/lib/python3.6/multiprocessing/connection.py"", line 487, in Client
    c = SocketClient(address)
  File ""/opt/conda/lib/python3.6/multiprocessing/connection.py"", line 614, in SocketClient
    s.connect(address)
ConnectionRefusedError: [Errno 111] Connection refused
```
is the complete error",recent call last self try data return true data get self block raise empty item wait self true else handler signum frame python still get update process status successfully none worker signal bus error handling exception another exception recent call last module self reverse self reverse none show batch data true true reverse else self detach try next iter finally detach self self process yield self true assert batch self success data success return data self raise worker return false none worker unexpectedly exception thread recent call last file line file line run file line file line get return file line file line detach conn file line client address file line client address file line address connection complete error,issue,positive,positive,positive,positive,positive,positive
534649760,"@sgugger Hi. I tried this now. 

```
p = cv2.imread('rooster.jpg') # p is numpy array with shape (height,width,channels)
t = pil2tensor(p, dtype=np.uint8) # converts to numpy tensor
t = t.permute(2,0,1) # Move num_channels as first dimension
t = t.float()/255. #Convert to float
im = Image(t) # Convert to fastAi Image - this class has ""apply_tfms""
learn1.predict(im)
```

But it gives me the following error:

```
<ipython-input-160-770b213cea6a> in <module>
      3 t = t.permute(2,0,1) # Move num_channels as first dimension
      4 t = t.float()/255. #Convert to float
----> 5 im = Image(t) # Convert to fastAi Image - this class has ""apply_tfms""
      6 learn1.predict(im)

TypeError: 'module' object is not callable

```
",hi tried array shape height width tensor move first dimension convert float image convert image class following error module move first dimension convert float image convert image class object callable,issue,negative,positive,positive,positive,positive,positive
534611918,"Thanks for flagging. In the future, don't hesitate to directly suggest a PR when you have figured the fix :)",thanks flagging future hesitate directly suggest figured fix,issue,negative,positive,positive,positive,positive,positive
534536915,"That's because you don't specify the orders of the columns in your test set. You should either have a dataframe with the columns in the right order or pass along a `TextList` in `add_test`:
```
test_list = TextList.from_df(df_tst, cols=['language', 'title'])
learn.data.add_test(test_list, label=None)
```",specify test set either right order pas along,issue,negative,positive,positive,positive,positive,positive
534535887,"I think your fix is the correct one, you should submit a PR with it. Thanks for flagging the issue!",think fix correct one submit thanks flagging issue,issue,negative,positive,positive,positive,positive,positive
533815926,"This is a generic error that tells something went wrong during multiprocessing. There is nothing we can do to help without seeing the code you run. Please use the [forum](https://forums.fast.ai/) to debug your code, we keep the issues for standing bugs only.",generic error something went wrong nothing help without seeing code run please use forum code keep standing,issue,negative,negative,negative,negative,negative,negative
533815808,"Yes, the problem comes from the pathlib library, Path objects are not compatible between Windows and Linux once serialized. We have a workaround for inference in `Learner.export` and `load_learner` but for data objects, there is no compatibility between saving on one OS and loading on another one. 
This is a known issue that will be addressed in v2, but it's too much work for v1.",yes problem come library path compatible inference data compatibility saving one o loading another one known issue much work,issue,negative,positive,positive,positive,positive,positive
533649412,"You should put a either valid_pct then, to get at least one text in your validation set.",put either get least one text validation set,issue,negative,negative,negative,negative,negative,negative
533646980,"I don't. If it's the source if the problem the issue can be closed, I didn't understand it from the docs. Thanks. ",source problem issue closed understand thanks,issue,negative,positive,neutral,neutral,positive,positive
533638515,"Are you sure you have more than 5 texts in your folder? This could also happen if you have a very short corpus, in which case you should lower batch size and bppt.",sure folder could also happen short corpus case lower batch size,issue,negative,positive,positive,positive,positive,positive
533231020,"bug is still there, however due to another bug with papermill it not always reaches the line where it fails :( I will dive deeper to this",bug still however due another bug always line dive,issue,negative,negative,negative,negative,negative,negative
533095097,"No, the behavior of the function shouldn't change. It's very easy to remove the context if needed.",behavior function change easy remove context,issue,negative,positive,positive,positive,positive,positive
533094780,"I don't see a reason why we're not using `to_detach`, will fix later this morning.",see reason fix later morning,issue,negative,neutral,neutral,neutral,neutral,neutral
533055022,Wouldn't it be better to adapt the output of the method just to return the predicted/generated words? I think it make more sense for practical use cases.,would better adapt output method return think make sense practical use,issue,negative,positive,positive,positive,positive,positive
532686581,Thanks for the PR. You should present your widget on the [forum](https://forums.fast.ai/) so that people know it exists and start using it.,thanks present forum people know start,issue,negative,positive,neutral,neutral,positive,positive
532414242,PyTorch changed the way to install CPU-only builds: https://github.com/fastai/fastai/pull/2333. Simple `conda install`s are now possible.,way install simple install possible,issue,negative,neutral,neutral,neutral,neutral,neutral
532218611,Thanks. WOuld you mind making a PR adjusting the documentation?,thanks would mind making documentation,issue,negative,positive,positive,positive,positive,positive
531892716,Still can't reproduce but it should be fixed by [this commit](https://github.com/fastai/fastai/commit/b73f345aa87b71a11bb50960ac3af7cbdd3654ee).,still ca reproduce fixed commit,issue,negative,positive,neutral,neutral,positive,positive
531852843,"@sgugger I have uploaded the complete example of the code to produce the bug at below link,

[https://nbviewer.jupyter.org/github/mdalvi/fast-ai-lessons/blob/master/course-v3/nbs/dl1/lesson1_exercise.ipynb](https://nbviewer.jupyter.org/github/mdalvi/fast-ai-lessons/blob/master/course-v3/nbs/dl1/lesson1_exercise.ipynb)",complete example code produce bug link,issue,negative,positive,neutral,neutral,positive,positive
531787803,"I just tried to reproduce your bug and couldn't do it. I made a mistake in my previous comment: the init does take regular PyTorch dataloaders and converts them to `DeviceDataLoader`.

I suspect you create your dataloaders before importing fastai, which has some monkey-patching on PyTorch to add functionality, and that is why you had the bug. Please let me know if that's not the case and you can give me a minimal reproducer while reopening this issue, and I'll dig into it more.",tried reproduce bug could made mistake previous comment take regular suspect create add functionality bug please let know case give minimal reproducer issue dig,issue,negative,negative,neutral,neutral,negative,negative
531785268,"I can't reproduce that bug, either on master or v1.0.57.
Are you sure your minimal example consistently throws it?",ca reproduce bug either master sure minimal example consistently,issue,negative,positive,positive,positive,positive,positive
531571167,"I see, I thought it was pytorch dataloader because in the definition of the class `DataBunch`, the type of `train_dl` gives direct link to pytorch dataloader page. 

thanks for the reply.",see thought definition class type direct link page thanks reply,issue,negative,positive,positive,positive,positive,positive
531523175,"I guess the library could wrap them up automatically for you, will look if it's easy to add on Monday.",guess library could wrap automatically look easy add,issue,negative,positive,positive,positive,positive,positive
531523149,"`DataBunch` init needs to get `DeviceDataLoader`, not PyTorch `DataLoader`. If you have datasets, the easiest way to build a `DataBunch` is to use `DataBunch.create(train_ds, valids_ds,...)`, otherwise you need to wrap your dataloaders in `DeviceDataLoader` (that will put things on the GPU if needed) to get rid of this bug. ",need get easiest way build use otherwise need wrap put get rid bug,issue,negative,neutral,neutral,neutral,neutral,neutral
531293728,"I have just created a pull request #2326. Please let me know if I should change anything. I think it should be linked to this issue - perhaps I am temporarily blind, but I'm not seeing an obvious way to do this.",pull request please let know change anything think linked issue perhaps temporarily blind seeing obvious way,issue,negative,negative,negative,negative,negative,negative
531280771,That seems like a better idea. Would you mind suggesting a PR with that?,like better idea would mind suggesting,issue,positive,positive,positive,positive,positive,positive
530482759,"Appreciate and thanks for fixing this in v2.
So if I understand it, I can still do the inference using the `load_learner()`. So, like
```
learn.save('first') -> Linux
load_learner(path, 'first') -> Windows
```

This should unblock me, thanks will give a try.",appreciate thanks fixing understand still inference like path unblock thanks give try,issue,positive,positive,positive,positive,positive,positive
530447041,"Looking into this, the issue is there on the data save because we serialize its path. Note that `Learner.export` and `load_learner` should work cross-platform if your problem is inference, but yeah, it won't work for `DataBunch.save`.

This is too much work to fix for v1, so this issue will be resolved in v2.",looking issue data save serialize path note work problem inference yeah wo work much work fix issue resolved,issue,positive,positive,positive,positive,positive,positive
530437287,"Right.

The data was created with below line of code:

```
data_lm = (TextList.from_folder(path)
             .filter_by_folder(include=['train', 'test', 'unsup'])
             .random_split_by_pct(0.1)
             .label_for_lm()
             .databunch(bs=bs))

data_lm.save('data_lm.pkl')
```",right data line code path,issue,negative,positive,positive,positive,positive,positive
530384434,I can't say if this is linked to this issue without knowing how you created the data in the first place and why there is a `Pathlib` object serialized with it.,ca say linked issue without knowing data first place object,issue,negative,positive,positive,positive,positive,positive
530278660,"@sgugger I am still getting this error. Was this fixed?
I have trained models in Linux system. But when i try to load the data_lm.pkl on windows, i get the below error:

**'cannot instantiate 'PosixPath' on your system'**

**Code:**
`data_lm = load_data(path, 'data_lm.pkl', bs=bs)
`

**Version:
Fast AI - 1.0.57**

**Stack Trace:**

```
NotImplementedError                       Traceback (most recent call last)
<ipython-input-17-cf62ba5d43bb> in <module>()
----> 1 data_lm = load_data(path, 'data_lm.pkl', bs=bs)

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\basic_data.py in load_data(path, file, bs, val_bs, num_workers, dl_tfms, device, collate_fn, no_check, **kwargs)
    275     ""Load a saved `DataBunch` from `path/file`. `file` can be file-like (file or buffer)""
    276     source = Path(path)/file if is_pathlike(file) else file
--> 277     ll = torch.load(source, map_location='cpu') if defaults.device == torch.device('cpu') else torch.load(source)
    278     return ll.databunch(path=path, bs=bs, val_bs=val_bs, num_workers=num_workers, dl_tfms=dl_tfms, device=device,
    279                         collate_fn=collate_fn, no_check=no_check, **kwargs)

~\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\serialization.py in load(f, map_location, pickle_module, **pickle_load_args)
    384         f = f.open('rb')
    385     try:
--> 386         return _load(f, map_location, pickle_module, **pickle_load_args)
    387     finally:
    388         if new_fd:

~\AppData\Local\Continuum\anaconda3\lib\site-packages\torch\serialization.py in _load(f, map_location, pickle_module, **pickle_load_args)
    571     unpickler = pickle_module.Unpickler(f, **pickle_load_args)
    572     unpickler.persistent_load = persistent_load
--> 573     result = unpickler.load()
    574 
    575     deserialized_storage_keys = pickle_module.load(f, **pickle_load_args)

~\AppData\Local\Continuum\anaconda3\lib\pathlib.py in __new__(cls, *args, **kwargs)
   1000         if not self._flavour.is_supported:
   1001             raise NotImplementedError(""cannot instantiate %r on your system""
-> 1002                                       % (cls.__name__,))
   1003         self._init()
   1004         return self

NotImplementedError: cannot instantiate 'PosixPath' on your system
```

If this is not yet fixed, is there a way to mitigate this. Training on Windows is very slow, so ideal for us is to train on Linux and then just for inference use windows.

Thanks.",still getting error fixed trained system try load get error system code path version fast ai stack trace recent call last module path path file device load saved file file buffer source path path file else file source else source return load try return finally result raise system return self system yet fixed way mitigate training slow ideal u train inference use thanks,issue,positive,positive,positive,positive,positive,positive
529595372,"This [commit](https://github.com/fastai/fastai/commit/54e3b9a656aea1b7a89d4acff4b0d0ce073a8f97) makes `MultiLabelFbeta` a regular metric, you should pass it in metrics now and hopefully all problems will be solved.",commit regular metric pas metric hopefully,issue,positive,neutral,neutral,neutral,neutral,neutral
529495211,"I have begun to lay out the ground material for a fix, but am stuck with a bug I'm not understanding fully. Basically PyTorch doesn't want to do the backward pass in this:
```
x,y = learn.data.one_batch()
y = to_half(y)
x,y = x.cuda(),y.cuda()
out = learn.model.generator(x)
loss = learn.model.critic(out).mean()
loss.backward()
```
For some reason, the gradients of the batchnorm (in FP32) for the critic cause some problems here, but not when training the critic.",begun lay ground material fix stuck bug understanding fully basically want backward pas loss reason critic cause training critic,issue,negative,neutral,neutral,neutral,neutral,neutral
529473344,"It's impossible to help without a minimal reproducer and the whole error stack trace. If you need help debugging your code and putting together such a minimal example of the bug, please use the [forum](https://forums.fast.ai/).

Closing the issue since I don't know if it's a ug in your code or the library, don't hesitate to reopen with all the necessary info. ",impossible help without minimal reproducer whole error stack trace need help code together minimal example bug please use forum issue since know ug code library hesitate reopen necessary,issue,negative,negative,negative,negative,negative,negative
529232851,Please follow the template for issues. Questions should be asked on the [forum](https://forums.fast.ai/).,please follow template forum,issue,negative,neutral,neutral,neutral,neutral,neutral
528381785,"This is not a bug in fastai but in your code. Don't pass a metric as a callback function, pass it as a metric.",bug code pas metric function pas metric,issue,negative,neutral,neutral,neutral,neutral,neutral
528381279,"> @sgugger Correct me if I am wrong, but I think in the plot top losses function, there needs to be an argument for the dataset type also.

No, the method that creates an interpet object from the learner as that argument, so it's not needed in top_losses.",correct wrong think plot top function need argument type also method object learner argument,issue,negative,neutral,neutral,neutral,neutral,neutral
527735635,"@sgugger Correct me if I am wrong, but I think in the plot top losses function, there needs to be an argument for the dataset type also.",correct wrong think plot top function need argument type also,issue,negative,neutral,neutral,neutral,neutral,neutral
527637553,"Thanks, just made a few cosmetic changes to save vertical spaces, will merge once the tests are passing.",thanks made cosmetic save vertical merge passing,issue,positive,positive,positive,positive,positive,positive
527636962,"Seems reasonable, functionality added in master.",reasonable functionality added master,issue,negative,positive,positive,positive,positive,positive
527547782,Reopened from #2308 due to unclear technical error including requested changes from #2308.,due unclear technical error,issue,negative,negative,neutral,neutral,negative,negative
527535668,I'll look into it when I have some time available and see (as I need to learn how to do it first).,look time available see need learn first,issue,negative,positive,positive,positive,positive,positive
527534287,"It's probably possible, though I don't have time to implement something like this.",probably possible though time implement something like,issue,negative,neutral,neutral,neutral,neutral,neutral
527514179,"Ugh, annoying. Even with the reorganization, the monkey-patch is seen while importing from tabular.data, guess we'll have to go with the different name.",ugh annoying even reorganization seen guess go different name,issue,negative,negative,negative,negative,negative,negative
527438384,"The issue is caused by importing fastai.widgets, which imports TabularDatabunch in tabular.data, which runs the code in models and replaces the monkey-patched `plot_top_losses`.

I don't like giving a different name for the same functionality and will solve the issue later this morning with a new `tabular.learner` module where the monkey-patch will happen without being touched by `fastai.widgets`.",issue code like giving different name functionality solve issue later morning new module happen without touched,issue,positive,positive,neutral,neutral,positive,positive
527404743,"> We are on the right track. I think we can simplify it a little bit more.
> 
> Also, I have no idea why that is, but the diff on the train.py file shows the entire file as changed, not just the things you added. Do you have any idea why that is? It makes reviewing the PR a bit hard for me.

FYI, it was because `<LF>` was replaced with `<CRLF>` (windows line endings)",right track think simplify little bit also idea file entire file added idea bit hard line,issue,negative,negative,neutral,neutral,negative,negative
527178106,"Looks to be tied to Seb's self attention layer, not this, so we're good.",tied self attention layer good,issue,negative,positive,positive,positive,positive,positive
527169999,Don't merge this yet though @sgugger I tried running this on another dataset and I'm getting CUDA errors. This needs to be solved before we do anything. ,merge yet though tried running another getting need anything,issue,negative,neutral,neutral,neutral,neutral,neutral
527129807,"No, fixing the import is good. Just remove the test and I'll merge the PR, thanks!",fixing import good remove test merge thanks,issue,positive,positive,positive,positive,positive,positive
527125469,"This is not an issue with the library but with the course, I'm closing this issue here, can you open the same one in the course-v3 repo? Thanks!",issue library course issue open one thanks,issue,negative,positive,neutral,neutral,positive,positive
526989894,"okay, should I remove the test that tests nothing to leave only the relative import ? Or shall we simply close it ? :)",remove test nothing leave relative import shall simply close,issue,negative,neutral,neutral,neutral,neutral,neutral
526928204,"I looked into it and tried a few things but I have absolutely no idea why. At first I thought it was because I had moved `fit_fc` to the start, but that did not do anything when I had moved it to the very end. I simplified it a bit more for you, and also got rid of the extra scheduler function as I don't believe that would've been beneficial here since it's just a function now. But let me know if we should have kept it.",tried absolutely idea first thought start anything end simplified bit also got rid extra function believe would beneficial since function let know kept,issue,negative,positive,positive,positive,positive,positive
526912903,"We are on the right track. I think we can simplify it a little bit more.

Also, I have no idea why that is, but the diff on the train.py file shows the entire file as changed, not just the things you added. Do you have any idea why that is? It makes reviewing the PR a bit hard for me.",right track think simplify little bit also idea file entire file added idea bit hard,issue,negative,negative,neutral,neutral,negative,negative
526912296,"Changes are perfect, thanks!
You can DM me on the forum for private questions.",perfect thanks forum private,issue,positive,positive,positive,positive,positive,positive
526651908,Thanks!. You need to add it [here](https://github.com/fastai/fastai/blob/fdc79857745498135aa60b1137c7e137f5d757c0/fastai/vision/learner.py#L40) too if you want users to be able to use it in ` cnn_learner`.,thanks need add want able use,issue,negative,positive,positive,positive,positive,positive
526621064,"Fixes are all done, let me know if that's close to what you are talking about via the API",done let know close talking via,issue,negative,neutral,neutral,neutral,neutral,neutral
526608102,I believe I simplified it per your request. The callback should just have an `__init__` to set up the scheduler correct?,believe simplified per request set correct,issue,negative,neutral,neutral,neutral,neutral,neutral
526545609,"Sorry to have closed this too quickly. This should be fixed now :)
",sorry closed quickly fixed,issue,negative,negative,negative,negative,negative,negative
526541141,"Ah good point, I skimmed through your file too fast. Let me look into it more.",ah good point skimmed file fast let look,issue,negative,positive,positive,positive,positive,positive
526540352,"I thought the way I had done it was using the data block API, all of the operations I carried out are as per the docs?  I will have a look at a custom ItemList but in the past found it quite awkward to do",thought way done data block carried per look custom past found quite awkward,issue,negative,negative,negative,negative,negative,negative
526520588,"The CI installs the latest version of fastai, not 0.7, and not in local, so that test doesn't test anything.",latest version local test test anything,issue,negative,positive,positive,positive,positive,positive
526520281,"You can't use the methods `predict`, `show_batch` and `show_results` if you didn't use the fastai data block API to load your data. You need to create a custom `ItemList` if you want to use them. Otherwise, just do `model.eval()(item)`",ca use predict use data block load data need create custom want use otherwise item,issue,negative,neutral,neutral,neutral,neutral,neutral
526491616,"I had this problem that I wanted to import fastai (1.x) as a ""local module"" (that is, import what's next to your python script). So that it doesn't get confused with my other fastai folder (0.7), I renamed it ""fastai1"" and did ""import fastai1 as fastai"" in my python script. Because of this new name some imports did not work.
In the test I tried to reproduce the circumstances of my problem so it can be checked that the imports work better now :)
Almost every imports used this ""import ..basic_train"" notation, just a few were actually calling ""import fastai.basic_train"" so I thought I'd change this and contribute.",problem import local module import next python script get confused folder import python script new name work test tried reproduce problem checked work better almost every used import notation actually calling import thought change contribute,issue,negative,positive,neutral,neutral,positive,positive
526372961,"@Vanrap if you are using the fastai dev version (installing fastai from github), then you can use it. Otherwise, you will have to wait for the next version of fastai so you can install from PyPI and use it.",dev version use otherwise wait next version install use,issue,negative,neutral,neutral,neutral,neutral,neutral
526135803,"Awesome! Thank you very much @sgugger ! So does this mean EfficientNets are officially a part of the fast ai vision models? Can I use them in my code now, or would we have to run more trials/tests?

And also, Im curious what @@ -0,0 +1,15 @@ mean in the file.",awesome thank much mean officially part fast ai vision use code would run also curious mean file,issue,positive,positive,neutral,neutral,positive,positive
526097321,Thanks for amending. I just used core for getting the `try_import` function instead of rewriting it and removed some vertical space to be consistent with the style of the rest of the library. Will merge when the tests pass.,thanks used core getting function instead removed vertical space consistent style rest library merge pas,issue,negative,positive,positive,positive,positive,positive
526096315,"Thanks for your PR, I made a suggestion with some changes if you don't mind editing it a bit,",thanks made suggestion mind bit,issue,negative,positive,positive,positive,positive,positive
526090011,"As the issue template states:
```
from fastai.utils.show_install import *
show_install()
```
You can also
```
import fastai
fastai.__version__
```",issue template import also import,issue,negative,neutral,neutral,neutral,neutral,neutral
525791621,I am curious about this too. Given a statement like found in this course: https://github.com/fastai/fastai/blob/master/courses/dl2/pascal-multi.ipynb how can you find what version you do have installed?,curious given statement like found course find version,issue,positive,negative,neutral,neutral,negative,negative
525786402,"Hmm. Would it be fine if we use 
`pretrainedmodels = try_import('efficientnet-pytorch')`
`if not pretrainedmodels:`
     `     raise Exception('Error: efficientnet-pytorch is needed. pip install efficientnet-pytorch')`
`from efficientnet_pytorch import EfficientNet `

and then define functions for each EfficientNet model? I believe this would keep us up to date on the pytorch repo.",would fine use raise exception pip install import define model believe would keep u date,issue,negative,positive,positive,positive,positive,positive
525741850,"No, we should import the package for efficient net the same way we do it for the cadene models (which is why I linked that module).",import package efficient net way linked module,issue,negative,neutral,neutral,neutral,neutral,neutral
525691192,Thanks for replying @sgugger! I totally understand that using code from [this repo ](https://github.com/lukemelas/EfficientNet-PyTorch)would not be practical. Can you please elaborate on what exactly you expect in the amended PR? Do you mean I should try to add EfficientNet to Cadene models?,thanks totally understand code practical please elaborate exactly expect mean try add,issue,positive,positive,positive,positive,positive,positive
525660409,"Thanks for your PR! I'm all for adding new models, but it doesn't feel right to take all the code from  https://github.com/lukemelas/EfficientNet-PyTorch and just put it in fastai. Plus, it would mean we'd need to cherrypick any commit made to fix bugs or make the model better.

The package is pip-installable, so we should do something like the [cadene models](https://github.com/fastai/fastai/blob/master/fastai/vision/models/cadene_models.py) which require a separate package and then tries to import it and raises an exception with a clear error message giving the instructions to install.

Would you mind amending your PR?",thanks new feel right take code put plus would mean need commit made fix make model better package something like require separate package import exception clear error message giving install would mind,issue,positive,positive,positive,positive,positive,positive
525183257,"That's not possible because once things are batched in a PyTorch dataloader, we don't get the indices they come back from, only the tensors. v2 will have a more general dataloader that we rewrote, which might make things like this possible, but this won't be added in v1.

Closing the issue since we keep those for standing bugs only, please add this to the thread in the [forum](https://forums.fast.ai) dedicated to new features.",possible get index come back general might make like possible wo added issue since keep standing please add thread forum new,issue,positive,positive,neutral,neutral,positive,positive
525182087,"Thanks for fixing those imports. I'm not too sure I understand what the test is testing, could you explain a little bit more?",thanks fixing sure understand test testing could explain little bit,issue,positive,positive,positive,positive,positive,positive
524750017,"No, this is just to properly initialize the weights with a copy of the raw weights. `training=False` is on purpose to have a copy of them. Note that in the forward function, we do use `training=self.training`, this is only for initialization.",properly initialize copy raw purpose copy note forward function use,issue,negative,negative,negative,negative,negative,negative
524667685,"I did something similar to what @stas00 mentioned with 

```
! unzip file.zip
```

but I wanted to put the files in a specific location that I thought might be useful to somebody else.

```
! unzip -q -j {str(filename)} -d {str(data_folder)}
```

-q = quiet mode
-j = put everything in a single directory
filename is a PosixPath of the zip file
-d = unzip to this directory
data_folder is a PosixPath of the desired directory",something similar put specific location thought might useful somebody else quiet mode put everything single directory zip file directory desired directory,issue,positive,positive,neutral,neutral,positive,positive
523945404,"Hi again.

I'm aware that this issue is closed but I found recently a case where applying the workaround is difficult. You couldn't train a network twice with two image sizes and evaluate how well perform in a test dataset each time:
```
src = (SegmentationItemList.from_folder(path_img)
       .split_by_fname_file('../valid.txt')
       .label_from_func(get_y_fn, classes=codes))

# The first time works
data = (src.transform(get_transforms(), size=128, tfm_y=True)
        .add_test_folder(tfm_y=False)
        .databunch(bs=bs)
        .normalize(imagenet_stats))

# The second time don't work.
data = (src.transform(get_transforms(), size=224, tfm_y=True)
        .add_test_folder(tfm_y=False)
        .databunch(bs=bs)
        .normalize(imagenet_stats))
```
**Error message**
```
Exception: It's not possible to apply those transforms to your dataset:
 Not implemented: you can't apply transforms to this type of item (EmptyLabel)
```
This training with different image sizes is recommended by Jeremy in the fastai course V3. See lesson 3 (https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb) where he does:

```
...

src = (SegmentationItemList.from_folder(path_img)
       .split_by_fname_file('../valid.txt')
       .label_from_func(get_y_fn, classes=codes))

data = (src.transform(get_transforms(), size=size, tfm_y=True)
        .databunch(bs=bs)
        .normalize(imagenet_stats))

...

data = (src.transform(get_transforms(), size=224, tfm_y=True)
        .add_test_folder(tfm_y=False)
        .databunch(bs=bs)
        .normalize(imagenet_stats))

...
```",hi aware issue closed found recently case difficult could train network twice two image size evaluate well perform test time first time work data second time work data error message exception possible apply ca apply type item training different image size course see lesson data data,issue,negative,negative,neutral,neutral,negative,negative
523909920,"Also when I export and re-import the learner according to the examples online, I am able to run, but some reason I only get predictions on 16384 instances out of ~50k samples.

Also there seems to be no way of clearly designated the classes, but I guess I can figure that out :) ",also export learner according able run reason get also way clearly class guess figure,issue,negative,positive,positive,positive,positive,positive
523908373,"Right, but I also got an error on that one. When I run:
`learn.get_preds(ds_type=DatasetType.Test)`
I get: 

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-47-ce77ea7f5e1e> in <module>()
----> 1 learn.get_preds(ds_type=DatasetType.Test)

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py in get_preds(self, ds_type, with_loss, n_batch, pbar)
    330         lf = self.loss_func if with_loss else None
    331         return get_preds(self.model, self.dl(ds_type), cb_handler=CallbackHandler(self.callbacks),
--> 332                          activ=_loss_func2activ(self.loss_func), loss_func=lf, n_batch=n_batch, pbar=pbar)
    333 
    334     def pred_batch(self, ds_type:DatasetType=DatasetType.Valid, batch:Tuple=None, reconstruct:bool=False) -> List[Tensor]:

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py in get_preds(model, dl, pbar, cb_handler, activ, loss_func, n_batch)
     41     ""Tuple of predictions and targets, and optional losses (if `loss_func`) using `dl`, max batches `n_batch`.""
     42     res = [torch.cat(o).cpu() for o in
---> 43            zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]
     44     if loss_func is not None:
     45         with NoneReduceOnCPU(loss_func) as lf: res.append(lf(res[0], res[1]))

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/basic_train.py in validate(model, dl, loss_func, cb_handler, pbar, average, n_batch)
     53     with torch.no_grad():
     54         val_losses,nums = [],[]
---> 55         if cb_handler: cb_handler.set_dl(dl)
     56         for xb,yb in progress_bar(dl, parent=pbar, leave=(pbar is not None)):
     57             if cb_handler: xb, yb = cb_handler.on_batch_begin(xb, yb, train=False)

~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/fastai/callback.py in set_dl(self, dl)
    253         ""Set the current `dl` used.""
    254         if hasattr(self, 'cb_dl'): self.callbacks.remove(self.cb_dl)
--> 255         if isinstance(dl.dataset, Callback):
    256             self.callbacks.append(dl.dataset)
    257             self.cb_dl = dl.dataset

AttributeError: 'NoneType' object has no attribute 'dataset'
```

I really love this library but the inference procedure is confusing coming out of Keras / Scikit-learn background.",right also got error one run get recent call last module self else none return self batch reconstruct list tensor model optional zip validate model none validate model average none self set current used self object attribute really love library inference procedure coming background,issue,positive,positive,positive,positive,positive,positive
523571592,"I tried `pad_first=False` while creating the `TextClasDataBunch` (passed it as an argument in `.from_df()`), but that still gave different results from `predict` and`get_preds` in a small number of examples (and the probability of the classes isn't the same using the 2 methods). 

I am not sure what you mean by properly passing the padding token index? I couldn't find a reference to that in the examples/documentation - could you link me to an example?",tried argument still gave different predict small number probability class sure mean properly passing padding token index could find reference could link example,issue,negative,negative,neutral,neutral,negative,negative
523367384,"But this happens not only for callbacks, but for other modules also, for example if I do `from fastai.vision import`, then again suggests abc, abstract method and so on, same case for `from fastai.datasets import`
I want to have a look at datasets available in fastai.datasets but instead it suggests me abc, abstractmethod and so on. ",also example import abstract method case import want look available instead,issue,negative,positive,positive,positive,positive,positive
523362481,"No, the mnist examples uses an imagenet pretrained model, so it's normal to use the `imagenet_stats` on which the model was pretrained. This is an example of use of transfer learning.",model normal use model example use transfer learning,issue,negative,positive,positive,positive,positive,positive
523361897,"Please refer to the [contributing guide](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md#note-for-new-contributors-from-jeremy) and the multiple discussions on the forum. This is not a design that will change and that is balanced that carefully crafted `__all__` variables. callbacks init is missing an `__all__` and I'll make a PR to fix that later today, but the use of import * won't change.",please refer guide multiple forum design change balanced carefully missing make fix later today use import wo change,issue,negative,negative,neutral,neutral,negative,negative
523067889,"Nope, though normally the difference should be quasi-inexistent since the linear decoder ignores the tokens coming from padding. Are you sure you properly passed the padding token index (if it's not 1)? 
Maybe the difference comes from the fact the padding is done first, can you also try with padding at the end (by passing pad_first=False to `TextClasDataBunch`)?",nope though normally difference since linear coming padding sure properly padding token index maybe difference come fact padding done first also try padding end passing,issue,negative,positive,positive,positive,positive,positive
523065553,"Ok, the problem comes from using `CrossEntropyFlat` as a loss function. I will fix this when I have time, in the meantime, you should use `nn.CrossEntropyLoss`.",problem come loss function fix time use,issue,negative,neutral,neutral,neutral,neutral,neutral
523064075,"Thanks @sgugger for the explanation - the trouble is that my unlabelled ""test set"" is pretty big, with more than a million examples. Using `predict` on an example-by-example basis is pretty slow - that is why I was using `get_preds`. However, if `predict` is the more trustworthy method, is there a way to speed it up while getting predictions for a large set of examples?  ",thanks explanation trouble test set pretty big million predict basis pretty slow however predict trustworthy method way speed getting large set,issue,positive,positive,neutral,neutral,positive,positive
523060232,"Yes, it's normal you see some differences. The predictions with `get_preds` are batched, so padding is applied to make all text the same lengths. This can induce some small changes compared to predict (which is the one you should trust more). ",yes normal see padding applied make text induce small predict one trust,issue,positive,negative,neutral,neutral,negative,negative
523055906,"Yes it should! That's a good catch, could you suggest a PR with a fix since you found it?",yes good catch could suggest fix since found,issue,positive,positive,positive,positive,positive,positive
522784784,"Sylvain,
Sorry for being late,
Here is the gist:
https://gist.github.com/mmauri/c5d1ae1fe2b797bc026ed5f0daeabd3b

Maybe am I doing something wrong, with the conversion from np to tensor & cuda?",sorry late gist maybe something wrong conversion tensor,issue,negative,negative,negative,negative,negative,negative
522708904,"Just wanted to check in about this ordering issue: when I use `ordered=True` with `learn.get_preds()` for a text classification task (on a test set), I get *almost* all the predicted classes being the same as that with `learn.predict()`. In my specific use case, I tested it with 20k test examples, and the labels predicted by the two methods disagree for 18 examples. The class probabilities predicted by the two methods are comparable, but not exactly equal. Here's some more details about my use case:
FastAI version:
```
fastai.__version__
'1.0.55'
``` 
**Training procedure:**
1. Trained language model on large text corpus.
2. Used the vocabulary of trained language model to build text classification data bunch:
```
data_clas = TextClasDataBunch.from_df(path = ""./"", train_df = labelled_data_train, 
                                      valid_df = labelled_data_valid, 
                                      text_cols =  ""post_title"", 
                                      label_cols = ""Theme"", 
                                      vocab=data_lm.train_ds.vocab, 
                                      bs=128)
```
3. 2 different methods for predicting on the test set:
a) Add test set to the TextClasDataBunch and use `learn.get_preds` for prediction:
```
data_clas = TextClasDataBunch.from_df(path = ""./"", train_df = labelled_data_train, 
                                      valid_df = labelled_data_valid, 
                                      test_df = unlabelled_data_to_classify,
                                      text_cols =  ""post_title"", 
                                      label_cols = ""Theme"", 
                                      vocab=data_lm.train_ds.vocab, 
                                      bs=64)

learn.data = data_clas
learn.get_preds(ds_type = DatasetType.Test, ordered=True)
```
b) Use `learn.predict` with raw text (in the form that was fed into the making of the TextClasDataBunch) one-by-one:
```
learn.predict(unlabelled_data_to_classify[""post_title""][0])
```
The predicted probabilities for the classes are not exactly equal with the two methods, though the predicted classes agree for all but 18 examples. An example of class probabilities predicted by the two methods:
**From learn.get_preds:** `tensor([3.1438e-03, 1.3936e-03, 4.4555e-03, 6.6271e-06, 5.3898e-05, 1.7909e-02, 9.7046e-01, 3.1595e-06, 1.4689e-04, 1.6489e-04, 2.2673e-03])`
**From learn.predict:** `tensor([2.3362e-03, 1.4350e-03, 3.3952e-03, 6.5755e-06, 4.2005e-05, 1.4958e-02, 9.7555e-01, 2.4424e-06, 1.3988e-04, 1.9556e-04, 1.9414e-03])`

Is there some source of randomness that can produce the difference in the predicted probabilities? Or is it because of the fact that I am not tokenizing the text while feeding it to `learn.predict` - I did so because the examples on the Inference page made it seem that the tokenization can happen within the learner, given it has a TextClasDataBunch (and the rules needed to make it) associated. Thanks for any clues!

@sgugger @StatisticDean ",check issue use text classification task test set get almost class specific use case tested test two disagree class two comparable exactly equal use case version training procedure trained language model large text corpus used vocabulary trained language model build text classification data bunch path theme different test set add test set use prediction path theme use raw text form fed making class exactly equal two though class agree example class two tensor tensor source randomness produce difference fact text feeding inference page made seem happen within learner given make associated thanks,issue,negative,positive,neutral,neutral,positive,positive
522448043,"Yes, GAN training has not been tested with mixed precision so I'm not surprised it doesn't work. Will investigate when OI have some bandwidth. ",yes gan training tested mixed precision work investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
522447771,Good catch! Would you mind suggesting a PR to fix this since you already found a solution? Thanks!,good catch would mind suggesting fix since already found solution thanks,issue,positive,positive,positive,positive,positive,positive
522429551,"The bug apparently is in Matplotlib:
https://github.com/matplotlib/matplotlib/issues/14897

As a workaround I set the y-axis limits manually
```
cm_fig = interp.plot_confusion_matrix(return_fig=True)
ax = cm_fig.gca()
ax.set_ylim(interp.data.c - .5, - .5)
```",bug apparently set manually ax,issue,negative,positive,neutral,neutral,positive,positive
522257994,"Hi,

Did you find the reason why the freeze/ unfreeze method not working?
I encounter the same problem now.

Any reply will be appreciated. Thank you!",hi find reason unfreeze method working encounter problem reply thank,issue,negative,neutral,neutral,neutral,neutral,neutral
522231890,"Hi,

I am sorry if I make a mistake while posting here, but I'm quite new to the process of asking questions about library development. 
Right now I am facing the same Broken Pipe Error. 
I installed Pytorch and Fastai yesterday (using Anaconda, on Windows 10 64 bits). Well, first of all after conda installing pytorch, I couldn't conda install fastai as there were some conflicts that the install didn't manage to resolve. When using ""pip install fastai"", however, it worked (I'm mentionning this because maybe it could be why I still have this broken pipe error in August ?)

In any case, I read multiple threads, and found what is supposed to be a workaround but doesn't work for me, using if __name__ == '__main__':

Could anyone please tell me what steps I can take to solve this Broken Pipe error ?

Thanks and have a nice day",hi sorry make mistake posting quite new process library development right facing broken pipe error yesterday anaconda well first could install install manage resolve pip install however worked maybe could still broken pipe error august case read multiple found supposed work could anyone please tell take solve broken pipe error thanks nice day,issue,negative,negative,neutral,neutral,negative,negative
521545886,The test seems tricky to implement in the CI as we don't run anything with notebooks. Thanks for the addition!,test tricky implement run anything thanks addition,issue,negative,positive,positive,positive,positive,positive
521328532,+1. Would be interested to know what the best practices are too.,would interested know best,issue,positive,positive,positive,positive,positive,positive
521152989,"> > If you want to do a classification with three values, you should convert them as categories, otherwise it won't work yes (unless your three values are the integers 0, 1 and 2).
> > If you want to do a regression, you should specify y_range = (min,max) so that the data object knows it.
> 
> i set the learner = tabular_learner(y_ranger = [0.500])
> but still get error...

y_range cannot contain a single value, it should include both min. and max. values",want classification three convert otherwise wo work yes unless three want regression specify min data object set learner still get error contain single value include min,issue,negative,negative,neutral,neutral,negative,negative
521151394,"> If you want to do a classification with three values, you should convert them as categories, otherwise it won't work yes (unless your three values are the integers 0, 1 and 2).
> If you want to do a regression, you should specify y_range = (min,max) so that the data object knows it.

i set the learner = tabular_learner(y_ranger = [0.,500.]) 
but still get error...",want classification three convert otherwise wo work yes unless three want regression specify min data object set learner still get error,issue,negative,neutral,neutral,neutral,neutral,neutral
520921712,"Please follow the template to report a bug, there is nothing we can do to help with so little information.",please follow template report bug nothing help little information,issue,negative,negative,negative,negative,negative,negative
520921475,I'm not sure why you want to change the README this way. Is this a mistake?,sure want change way mistake,issue,negative,positive,positive,positive,positive,positive
520309747,"Your code is correct so there must be some kind of problem with your data. We use GitHub for known issues only, so I'm closing this here, but you can ask for help on the [forum](https://forums.fast.ai/).",code correct must kind problem data use known ask help forum,issue,positive,positive,positive,positive,positive,positive
519970360,Thanks! Tests were failing due to some unrelated bug with the release of PyTorch 1.2.0. ,thanks failing due unrelated bug release,issue,negative,positive,neutral,neutral,positive,positive
519923934,"Seems a little bit dangerous and it makes the tests fail. Even with the test succeeding, I think this should be an additional param that defaults to `False`.",little bit dangerous fail even test succeeding think additional param false,issue,negative,negative,negative,negative,negative,negative
519583170,"The example of code given in the original issue runs fine in v1.0.55 as well as 1.0.56 as well as master, so I'm guessing you have another issue.  Without a reproducible example, there is nothing I can do to help.",example code given original issue fine well well master guessing another issue without reproducible example nothing help,issue,positive,positive,positive,positive,positive,positive
519570332,"@sgugger Hi Sylvain, I am getting the same error with 1.0.55 on colab with either K80 or Tesla T4
Thanks",hi getting error either thanks,issue,negative,positive,positive,positive,positive,positive
519397862,"The means are adjusted for various batch sizes by the library, so this part isn't a problem. Happy to look at a PR fixing this!",various batch size library part problem happy look fixing,issue,negative,positive,positive,positive,positive,positive
519386577,"this is how i add it .When i start the training some times it gets called i mean sampler and some times not or at the end of first epoch. So for this reason i raised this ,atleast event should get called.
`learn2.callback_fns.append(partial(OverSamplingCallback1, df=df_train.copy(),val_id=val_idx,weights=[1,1,1,1,1]))`",add start training time mean sampler time end first epoch reason raised event get partial,issue,negative,negative,neutral,neutral,negative,negative
519381499,"> I'm not sure what the bug is. Callbacks can't change the sampler or the batch sampler of a dataloader without creating a new one and setting it properly in `self.learn.data.train_dl` (or valid). That's why your iter is never called, this sampler hasn't been passed to any of the dataloaders.
> 
> In general, debugging code is best done using the [forum](https://forums.fast.ai).

m sorry i missed out these lines .THere is inconsistency in the way call back is invoked  and hence sampler init.  This is what bug is ,print statement as indicator or whether the call back is called or not is some times getting printed some times not,there was mistake in sampler which i corrected it but then callback was not calling the updated the Sampler object definition,eventually i had to restart the kernel.
```
def on_batch_begin(self, **kwargs):
        self.sample= class_balancer(df=self.df,bs=self.bs,trn_idx=self.train_idx,ratio=self.ratio)
        
        self.learn.data.train_dl.dl.batch_sampler = BatchSampler(self.sample,self.learn.data.train_dl.batch_size, False)
```
",sure bug ca change sampler batch sampler without new one setting properly valid iter never sampler general code best done forum sorry inconsistency way call back hence sampler bug print statement indicator whether call back time getting printed time mistake sampler corrected calling sampler object definition eventually restart kernel self false,issue,positive,positive,neutral,neutral,positive,positive
519331650,"Something like this should work (although I haven't tested it yet):

```
def dice(input:Tensor, targs:Tensor)->Rank0Tensor:
    ""Dice coefficient metric for binary target.""
    
    # Threshold targs
    n = targs.shape[0]
    input = input.argmax(dim=1).view(n,-1)
    targs = targs.view(n,-1) 
    
    # Compute dice
    intersect = (input * targs).sum(dim=1).float()
    union = (input + targs).sum(dim=1).float()    
    dice = 2. * intersect / union
    
    # Replace zero union values with 1
    dice[union == 0.] = 1
    
    # Return mean
    return dice.mean()
```",something like work although tested yet dice input tensor tensor dice coefficient metric binary target threshold input compute dice intersect input union input dice intersect union replace zero union dice union return mean return,issue,negative,negative,negative,negative,negative,negative
519227225,It was probably used in an earlier version but then we forgot to remove that line. Thanks for catching this error!,probably used version forgot remove line thanks catching error,issue,negative,positive,positive,positive,positive,positive
519226884,"I'm not sure what the bug is. Callbacks can't change the sampler or the batch sampler of a dataloader without creating a new one and setting it properly in `self.learn.data.train_dl` (or valid). That's why your iter is never called, this sampler hasn't been passed to any of the dataloaders.

In general, debugging code is best done using the [forum](https://forums.fast.ai).",sure bug ca change sampler batch sampler without new one setting properly valid iter never sampler general code best done forum,issue,positive,positive,positive,positive,positive,positive
519178742,"> Thank you for the clarification, @fredguth.
> 
> You mean, you did:
> 
> ```
> pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ torchvision==0.2.1.post1
> ```
> 
> and it ignored the fact that it was told to install specifically this version of the package? Can you please show the full output of that command above?
> 
> oh, wait, I see from your logs that it did install torchvision==0.2.1.post1, yet it fetched torch-0.4.1 - odd - I removed torch from its requirements, so it shouldn't want that dependecy at all... perhaps some previous uninstalls were incomplete?

Thank you, this solved my problem.",thank clarification mean pip install post fact told install specifically version package please show full output command oh wait see install post yet fetched odd removed torch want perhaps previous incomplete thank problem,issue,negative,negative,neutral,neutral,negative,negative
518774946,"The `ObjectItemList` from the fastai library is meant to be used with a model like a RetinaNet or a FPN that produce as many outputs as the final anchors, a lot of them being background. Your use case is different so you should use a different class (probably subclassing `ObjectItemList`).

I'm not sure which lesson notebook you have pointed to as there are no lessons in fastai v1 for object detection yet.",library meant used model like produce many final lot background use case different use different class probably sure lesson notebook pointed object detection yet,issue,positive,positive,positive,positive,positive,positive
518771249,"Then, how should be avoided the error in the cross_entropy calculation, @sgugger? I can add one extra output layer, but that's not what the output of the model should be. Why that error is not found in the lesson that I've pointed? ",error calculation add one extra output layer output model error found lesson pointed,issue,negative,neutral,neutral,neutral,neutral,neutral
518654856,"The 0 is hardcoded to be background in fastai, and any label index gets added 1 yes. That's not a bug, that's to be used with the Focal loss implemented in the object detection notebook.",background label index added yes bug used focal loss object detection notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
518576856,"I tried your notebook and the confusion matrix is displayed properly, so there is something wrong with your matplotlib I'd guess.",tried notebook confusion matrix displayed properly something wrong guess,issue,negative,negative,negative,negative,negative,negative
518557511,Closing for now since no news in a week and there are needed changes. Please don't hesitate to reopen (or open a new PR) with the requested changes.,since news week please hesitate reopen open new,issue,negative,positive,neutral,neutral,positive,positive
518557219,"I'm afraid there is little anyone can do to help on this since we don't have your data or your model. Plus part of your code (like the Learner creation) is missing. On the examples I have, the confusion matrix is looking correct.
If you have a more minimal reproducible example where the confusion matrix is clearly wrong, and that we can reproduce, I'll be happy to dig into it and find a fix, but I can't fix something I can't reproduce.",afraid little anyone help since data model plus part code like learner creation missing confusion matrix looking correct minimal reproducible example confusion matrix clearly wrong reproduce happy dig find fix ca fix something ca reproduce,issue,positive,negative,negative,negative,negative,negative
518385737,Just tried vanilla Jupyter notebook and getting the same result. Also tried chrome and safari just in case. If this doesn't seem to be reproducible I'll try to make time to test other environments and compare.,tried vanilla notebook getting result also tried chrome safari case seem reproducible try make time test compare,issue,negative,neutral,neutral,neutral,neutral,neutral
518350673,"I think this is an issue with the yaxis limits because the matrix elements in the plot should be square, but they are not, thus, the text is probably properly aligned but half of the square is cut from the figure. I have no clue on why would Jupyter lab modify matplotlib behaviour though.",think issue matrix plot square thus text probably properly half square cut figure clue would lab modify behaviour though,issue,negative,negative,negative,negative,negative,negative
518340530,Jupyter lab might very well be the reason. Did you try in jupyter notebook?,lab might well reason try notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
518339004,"Fixed, results aren't that different for this part and it was a typo, so there was no need to rerun ;)",fixed different part typo need rerun,issue,negative,positive,neutral,neutral,positive,positive
518304071,"I don't have the compute to rerun the example (results would differ). Also,
in the docs (https://docs.fast.ai/text.html) they use `drop_mult=0.5` for
training both the LM standalone and the classifier, instead of using it
just for the latter as in the notebook.

man. 5. aug. 2019 kl. 17:10 skrev Sylvain Gugger <notifications@github.com>:

> Yes, it should be wd=0.1 everywhere. Would you mind making a PR to fix
> this?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2262?email_source=notifications&email_token=ABTX3RHUZDRVOBHVMXFXJ2DQDA7IFA5CNFSM4IJJQWYKYY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGOD3SD33Y#issuecomment-518274543>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/ABTX3RBCNXBWMKNA5U5OBF3QDA7IFANCNFSM4IJJQWYA>
> .
>
",compute rerun example would differ also use training classifier instead latter notebook man yes everywhere would mind making fix thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
518294406,"Sure, here's the .ipynb contents (I'm viewing with JupyterLab v1.0.4):

```
{
 ""cells"": [
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""### Quick and simple image classifier from google image results""
   ]
  },
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""##### Download images\n"",
    ""\n"",
    ""e.g.\n"",
    ""```python\n"",
    ""keywords = \""Polar bears,balloons,'couch AND red','jaguar -animal -cat','dog OR cat'\""\n"",
    ""arguments = {\""keywords\"":keywords,\""limit\"":2, \""print_urls\"":True, \""format\"":\""jpg\""}\n"",
    ""```""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""# ! rm -rf ./downloads/*""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""from google_images_download import google_images_download\n"",
    ""\n"",
    ""response = google_images_download.googleimagesdownload()\n"",
    ""#keywords = \""keywords\"":\""dog,cat,tiger,'bear -teddy'\""\n"",
    ""keywords = \""'trench work','excavation site'\""\n"",
    ""arguments = {\""keywords\"":keywords,\""limit\"":100, \""print_urls\"":False, \""format\"":\""jpg\""}\n"",
    ""paths = response.download(arguments)""
   ]
  },
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""##### Optionally view all the images""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""%matplotlib inline\n"",
    ""from PIL import Image\n"",
    ""import matplotlib.pyplot as plt\n"",
    ""\n"",
    ""for label,path_list in paths[0].items():\n"",
    ""    print(label)\n"",
    ""    for p in path_list:\n"",
    ""        img = Image.open(p)\n"",
    ""        plt.imshow(img)\n"",
    ""        plt.show();""
   ]
  },
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""Then rename the subdirectories in `./downloads/` if desired""
   ]
  },
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""##### Model""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""import os\n"",
    ""from os.path import join, exists\n"",
    ""from glob import glob\n"",
    ""from fastai.vision import *\n"",
    ""from fastai.metrics import error_rate\n"",
    ""from fastai.callbacks import * \n"",
    ""from fastai.widgets import *\n"",
    ""\n"",
    ""path = Path(os.path.join(os.getcwd(),'downloads'))\n"",
    ""\n"",
    ""for l in glob(join(path,'[!.csv]*')): verify_images(join(path,l), max_size=224)""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""if exists(join(path,'cleaned.csv')): \n"",
    ""    df = pd.read_csv(join(path,'cleaned.csv'))\n"",
    ""    src = ImageList.from_df(df,path)\n"",
    ""else: \n"",
    ""    src = ImageList.from_folder(path)\n"",
    ""\n"",
    ""data = (src\n"",
    ""        .split_by_rand_pct(0.25)\n"",
    ""        .label_from_folder()\n"",
    ""        .transform(get_transforms(), size=224)\n"",
    ""        .databunch(bs=16, num_workers=0))""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""data.show_batch(figsize=(6,6), hide_axis=False)\n"",
    ""print(data.classes)""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""callback_fns = [ShowGraph, \n"",
    ""                partial(EarlyStoppingCallback, monitor='accuracy', min_delta=0.01, patience=3)]\n"",
    ""learn = cnn_learner(data, models.resnet18, metrics=[error_rate, accuracy], callback_fns=callback_fns);\n"",
    ""#learn.mixup(alpha=0.4);""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""learn.lr_find()\n"",
    ""learn.recorder.plot(suggestion=True)\n"",
    ""lr = learn.recorder.min_grad_lr""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""callbacks = [TerminateOnNaNCallback()]\n"",
    ""learn.fit_one_cycle(50, max_lr=lr*50, callbacks=callbacks)""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""learn.unfreeze()""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""learn.lr_find()\n"",
    ""learn.recorder.plot(suggestion=True)\n"",
    ""lr = learn.recorder.min_grad_lr""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""learn.fit_one_cycle(50, slice(lr))""
   ]
  },
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""##### Evaluate""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""interp = ClassificationInterpretation.from_learner(learn)\n"",
    ""losses,idxs = interp.top_losses()\n"",
    ""len(data.valid_ds)==len(losses)==len(idxs)""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""interp.plot_top_losses(9, figsize=(15,11))""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""interp.plot_confusion_matrix(figsize=(5,5))""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""interp.most_confused(min_val=2)""
   ]
  },
  {
   ""cell_type"": ""code"",
   ""execution_count"": null,
   ""metadata"": {},
   ""outputs"": [],
   ""source"": [
    ""ds, idxs = DatasetFormatter().from_toplosses(learn)\n"",
    ""ImageCleaner(ds, idxs, path);""
   ]
  },
  {
   ""cell_type"": ""markdown"",
   ""metadata"": {},
   ""source"": [
    ""Then start back at modeling phase with cleaned data!""
   ]
  }
 ],
 ""metadata"": {
  ""kernelspec"": {
   ""display_name"": ""Python 3"",
   ""language"": ""python"",
   ""name"": ""python3""
  },
  ""language_info"": {
   ""codemirror_mode"": {
    ""name"": ""ipython"",
    ""version"": 3
   },
   ""file_extension"": "".py"",
   ""mimetype"": ""text/x-python"",
   ""name"": ""python"",
   ""nbconvert_exporter"": ""python"",
   ""pygments_lexer"": ""ipython3"",
   ""version"": ""3.6.5""
  }
 },
 ""nbformat"": 4,
 ""nbformat_minor"": 4
}

```

",sure content markdown source quick simple image classifier image markdown source polar red true code null source code null source import response dog cat tiger work false markdown source optionally view code null source import import label print label markdown source rename desired markdown source model code null source import import join import import import import import path path join path join path code null source join path join path path else path data code null source print code null source partial learn data accuracy code null source code null source code null source code null source code null source slice markdown source evaluate code null source learn code null source code null source code null source code null source learn path markdown source start back modeling phase data python language python name python name version name python python version,issue,positive,positive,neutral,neutral,positive,positive
518275867,"Can't reproduce on my side, could you share the totality of the code used?",ca reproduce side could share totality code used,issue,negative,neutral,neutral,neutral,neutral,neutral
518274543,"Yes, it should be wd=0.1 everywhere. Would you mind making a PR to fix this?",yes everywhere would mind making fix,issue,negative,neutral,neutral,neutral,neutral,neutral
518233320,"@sgugger Hi, sorry for the late reply, but this does not seem to be working for me:

<img width=""599"" alt=""Screenshot 2019-08-05 09 25 29"" src=""https://user-images.githubusercontent.com/12224358/62468034-0c72b480-b763-11e9-9313-6230dffc9abd.png"">
",hi sorry late reply seem working,issue,negative,negative,negative,negative,negative,negative
518140311,"There is no option to change the the alignments of the text (it's hard-coded centered horizontally and vertically). What you seem to be missing from your figure is to pass a `figsize` argument to get a square. In my case, 
```
interp.plot_confusion_matrix(figsize=(9,9))
```
displays the confusion matrix quite nicely.",option change text centered horizontally vertically seem missing figure pas argument get square case confusion matrix quite nicely,issue,negative,positive,positive,positive,positive,positive
518136230,"The problem is linked to multiprocessing in windows with PyTorch. If you pass `num_workers=0` in the `.databunch()` function, you will disable it and get rid of the problem. Since reading the texts is pretty fast, you don't really need it anyway.",problem linked pas function disable get rid problem since reading pretty fast really need anyway,issue,negative,positive,positive,positive,positive,positive
517983192,"I just tried running the same code on Windows Subsystem for Linux and it works fine. So it's a problem with windows probably. Also I found [this](https://stackoverflow.com/questions/15900366/all-example-concurrent-futures-code-is-failing-with-brokenprocesspool). That seems to be pretty much the case with me as well. Although running it as a python script and calling the databunch from within `__name__ == '__main__' `didn't help in my case when using windows.

I am not closing the issue so that if anyone knows of a fix to make it work on windows can help.",tried running code subsystem work fine problem probably also found pretty much case well although running python script calling within help case issue anyone fix make work help,issue,positive,positive,positive,positive,positive,positive
517279609,"Transforms are always applied at the item level, what was happening before the fix is that their state wasn't randomized at each call on __getitem__, (which is the resolve thing), so they were always applied the same way.",always applied item level happening fix state call resolve thing always applied way,issue,negative,neutral,neutral,neutral,neutral,neutral
517278212,"Great, thanks the quick fix! 

I can see how your change makes it so that tfms are applied to the item now, but I can't figure out why they were being applied to the entire dataset before. Is there a separate step that applies it to the entire dataset if they were not applied to the item? Or are they still being applied to the entire dataset, but then an additional tfm is applied at the item level?",great thanks quick fix see change applied item ca figure applied entire separate step entire applied item still applied entire additional applied item level,issue,positive,positive,positive,positive,positive,positive
517269215,"Thanks a lot! (tests fail for another reason, fixed in an additional commit)",thanks lot fail another reason fixed additional commit,issue,negative,negative,neutral,neutral,negative,negative
517161537,"Thanks for your PR, but as mentioned [here](https://docs.fast.ai/gen_doc_main.html), the docs are auto-generated from the notebooks in docs_src. If I merge your PR, the change will be overwritten next time we build the docs.
Would you mind making a new PR with the file vision.models.ipynb changed instead?",thanks merge change next time build would mind making new file instead,issue,negative,positive,positive,positive,positive,positive
516901069,"Explaining the code explains how the function works and how the value is computed, so this is great for the documentation. fastai is primarily aimed at coders, not mathematicians, so they will probably prefer your comments to the wikipedia page.

As for the source code, not including any code comment and limiting vertical space is pretty much the only part of our [style guide](https://docs.fast.ai/dev/style.html) we strictly enforce. ",explaining code function work value great documentation primarily probably prefer page source code code comment limiting vertical space pretty much part style guide strictly enforce,issue,positive,positive,positive,positive,positive,positive
516896510,"@sgugger , I'm not sure this comments should be put to the docs?

If I understand correctly docs are intended for API users to explain how to use the metric function and how value is calculated.
And this comments rather explain to library developers why the code is written this way.
To make the docs more clear we can add a link to Wikipedia article and a note that Dice = 1 if both label and predicted mask is empty.",sure put understand correctly intended explain use metric function value calculated rather explain library code written way make clear add link article note dice label mask empty,issue,positive,positive,positive,positive,positive,positive
516849155,"Thanks a lot for your PR. We don't comment code in fastai like you did however, and leave all those bits you explained for the [docs](https://docs.fast.ai/). Could you amend your PR to only leave the code on its own in metrics.py and add the details around the formula in `docs_src/metrics.ipynb`? Thanks in advance.",thanks lot comment code like however leave could amend leave code add around formula thanks advance,issue,positive,positive,positive,positive,positive,positive
516847675,"You can't train in mixed precision on the CPU, so you either need to run this on a machine with a GPU o remove the `learn.to_fp16()` command.",ca train mixed precision either need run machine remove command,issue,negative,neutral,neutral,neutral,neutral,neutral
515986922,"Are you sure you are using the latest version? I downloaded your dataset and your sample notebook is running fine. To use an editable install of the fastai library run
```
conda remove fastai
```
then in the cloned fastai repo:
```
pip install -e "".[dev]""
```",sure latest version sample notebook running fine use install library run remove pip install dev,issue,negative,positive,positive,positive,positive,positive
515977215,"This is an installation problem, not a bug in the library. Please check the [dedicated thread on the forum](https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111/364).",installation problem bug library please check thread forum,issue,negative,neutral,neutral,neutral,neutral,neutral
515787639,"Added the option in fastprogress to not automatically clear the outputs. To use it, you have to do an editable install (until the next release), then:
```
from fastprogress import fastprogress
fastprogress.CLEAR_OUTPUT = False
```",added option automatically clear use install next release import false,issue,negative,negative,negative,negative,negative,negative
515705909,This can't be added in train as this is generic and used in all applications (text and tabular). You should put this in vision.image,ca added train generic used text tabular put,issue,negative,neutral,neutral,neutral,neutral,neutral
515492744,"You're right ! I forgot that Processors were called at labelization, hence why the error happens at this moment. Thank you.",right forgot hence error moment thank,issue,negative,positive,positive,positive,positive,positive
515465170,The default of `TextList` is to receive texts that it will tokenize and numericalize. You are passing ids so you should deactivate this by adding `processsor = []` in your arguments.,default receive passing deactivate,issue,negative,neutral,neutral,neutral,neutral,neutral
515272516,"Thanks @sgugger.
`from fastai.vision.models.xresnet2 import *` is fine now.
How about this `from fastai.vision.models.presnet import *`? 😆 ",thanks import fine import,issue,positive,positive,positive,positive,positive,positive
515092303,This is embarrassing. I had used `load` instead of `load_encoder`. Closing issue. ,embarrassing used load instead issue,issue,negative,neutral,neutral,neutral,neutral,neutral
515058079,"It seems like a waste of code, but it's actually faster this way (we did run benchmarks), so we're not changing it until we are proved wrong :)",like waste code actually faster way run proved wrong,issue,negative,negative,negative,negative,negative,negative
515057703,"Not sure if it should be considered as an issue, passing `tfm_y=True` to transform should set it to `True` everywhere. You can use `add_test` after that call (or even after creating the `DataBunch`) to avoid this, as you pointed out.",sure considered issue passing transform set true everywhere use call even avoid pointed,issue,negative,positive,positive,positive,positive,positive
514872072,"It can be fixed by this command in my env.
```shell
sed -i 's/as model_zoo/as model_zoo\nfrom ...torch_core import Module\n/' /opt/conda/lib/python3.6/site-packages/fastai/vision/models/xresnet2.py
```",fixed command shell import,issue,negative,positive,neutral,neutral,positive,positive
514854857,"Check out this pull request on ReviewNB: https://app.reviewnb.com/fastai/fastai/pull/2242 

 You'll be able to see visual diffs and write comments on notebook cells. Powered by <a href='https://www.reviewnb.com'>ReviewNB</a>.",check pull request able see visual write notebook powered,issue,negative,positive,positive,positive,positive,positive
514390369,"Thanks!

I set `num_workers` to 0 in the `Seq2SeqDataBunch` definition and the error went away.

Loading the dataset got a lot slower though.

It works fine on Linux machine.

I'll close it.",thanks set definition error went away loading got lot though work fine machine close,issue,negative,positive,positive,positive,positive,positive
514337213,where is v2 development taking place? is it available on github?,development taking place available,issue,negative,positive,positive,positive,positive,positive
514201154,"The notebook runs fine for me. You should try to set `num_workers` to 0 in your DataBunch to get a better error message (or maybe it's going to work), PyTorch multiprocessing on Windows isn't always reliable.",notebook fine try set get better error message maybe going work always reliable,issue,negative,positive,positive,positive,positive,positive
513992271,"Please suggest improvements and new features on the [forum](https://forums.fast.ai/), we keep issues for known bugs only.",please suggest new forum keep known,issue,negative,positive,positive,positive,positive,positive
513802364,"FYI you only need save/load, not the save_encoder/load_encoder part. If you are not encountering the problem in multhithreading, I'd suggest not multi-threading and using batch predictions instead.

In any case I'd need a self-contained reproducible example (not relying on exterior data/model) do be able to fix the issue, as I wasn't able to reproduce with just the code. Closing this for now but please reopen if you manage to build such a self-contained reproducer and I will try to fix the problem.",need part problem suggest batch instead case need reproducible example exterior able fix issue able reproduce code please reopen manage build reproducer try fix problem,issue,negative,positive,positive,positive,positive,positive
513801262,Ok this seems a nice temp fix. I'm not sure I'll investigate the more general issue as we have v2 coming soon and it will initialize callback funcs in init.,nice temp fix sure investigate general issue coming soon initialize,issue,positive,positive,positive,positive,positive,positive
513608598,"> Are you sure that you are actually predicting and not checking the values during a training loop? (in other words, is your model frozen for the predictions; model.eval()) Because it sounds a lot like your model changes a tiny bit each time in a non-deterministic manner.

I use learn.save_encoder() and learn.save() to end the training, when I predict I use the learn.predict(), as illustrated in the documentation, so I also want to know is this way save&load safe.",sure actually training loop model frozen lot like model tiny bit time manner use end training predict use documentation also want know way save load safe,issue,positive,positive,positive,positive,positive,positive
513607846,"> Ok, the one that is off is really off. That's weird. Do you have something similar when asking for the predictions four times in a row without multi-threading?

I haven't encountered this problem so far without multi-threading.
",one really weird something similar four time row without problem far without,issue,negative,negative,negative,negative,negative,negative
513579224,"Are you sure that you are actually predicting and not checking the values during a training loop? (in other words, is your model frozen for the predictions; model.eval()) Because it sounds a lot like your model changes a tiny bit each time in a non-deterministic manner. ",sure actually training loop model frozen lot like model tiny bit time manner,issue,positive,positive,positive,positive,positive,positive
513569206,"In the second commit (fe0cdba) I introduced a boolean flag `cb_fns_registered`. It is used in `get_preds()` to run `callback_fns` registration with the learner if that has not been done previously. For example, when `get_preds()` is called immediately after creating the learner.

Resolves: #2235",second commit flag used run registration learner done previously example immediately learner,issue,negative,negative,neutral,neutral,negative,negative
513477015,"Ok, the one that is off is really off. That's weird. Do you have something similar when asking for the predictions four times in a row without multi-threading?",one really weird something similar four time row without,issue,negative,negative,negative,negative,negative,negative
513432321,"This time the former wrong sentence is correct, but there is another wrong sentence:
(Category 0, tensor(0), tensor([9.9946e-01, 5.3958e-04])) Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition and language modeling.
(Category 1, tensor(1), tensor([5.3150e-06, 9.9999e-01])) Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition and language modeling.
(Category 0, tensor(0), tensor([9.9946e-01, 5.3958e-04])) Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition and language modeling.
(Category 0, tensor(0), tensor([9.9946e-01, 5.3958e-04])) Real-life document recognition systems are composed of multiple modules including field extraction, segmentation recognition and language modeling.
",time former wrong sentence correct another wrong sentence category tensor tensor document recognition composed multiple field extraction segmentation recognition language modeling category tensor tensor document recognition composed multiple field extraction segmentation recognition language modeling category tensor tensor document recognition composed multiple field extraction segmentation recognition language modeling category tensor tensor document recognition composed multiple field extraction segmentation recognition language modeling,issue,negative,negative,negative,negative,negative,negative
513430695,"Ah sorry, I misread. I tried your example and there is a tiny bit of difference when predicting on different thread, no greater than 2e-4, but that could suffice to change the predicted class if it's a close one. So maybe the threading does affect the predictions in some way (though that's more likely to be on the PyTorch side than ours).
Can you try printing the whole predictions, not just the category, to confirm if the difference is small? ",ah sorry misread tried example tiny bit difference different thread greater could suffice change class close one maybe affect way though likely side try printing whole category confirm difference small,issue,negative,negative,neutral,neutral,negative,negative
513252614,"Thanks! I noticed you're passing `senetence.split()` and not just `sentence`, why is that? Normally `learn.predict` will tokenize the text for you.",thanks passing sentence normally text,issue,negative,positive,positive,positive,positive,positive
513249405,We can certainly try to move this to post_init and see if it breaks anything. It would make more sense to have them initialized there.,certainly try move see anything would make sense,issue,negative,positive,positive,positive,positive,positive
513129955,`data.train_ds.x.items` is an array of numbers from `0` until `len(train_ds.x)-1` for me. I am not sure what it would be useful for. But I have found what is useful for me: `data.train_ds.x.inner_df`. Thank you for your help.,array sure would useful found useful thank help,issue,positive,positive,positive,positive,positive,positive
513049555,"Looking good, thanks a lot!",looking good thanks lot,issue,positive,positive,positive,positive,positive,positive
512978197,"@sgugger Yes, the `data.show_batch()` is working. Here is the proof:
![image](https://user-images.githubusercontent.com/25510740/61490095-c7602b80-a9c9-11e9-869a-cd574ee8d574.png)
More over `y,type(y)` after `x,y = data.one_batch()` gives:
```
(tensor([ 4,  9, 20, 19,  9,  4, 12,  0,  9, 23, 20, 14, 23,  7, 12, 12,  4,  4,
         20,  3, 12, 21,  4,  3, 12, 20, 17,  6, 20, 26,  0, 12, 19, 22, 12, 24,
         21,  0, 23, 17,  8, 14,  4, 21, 22, 17, 12,  3, 21,  4, 21, 12, 24, 18,
          9, 17,  0,  9, 12, 20, 13,  4, 20,  3]), torch.Tensor)
``` ",yes working proof image type tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
512885935,"I can't reproduce on a dataset I have. Are you sure your data is properly loaded? Can you double-check the output of `data.show_batch()` and that when you can `x,y = data.one_batch()`, the `y` is a tensor of ints with only one dimension?",ca reproduce sure data properly loaded output tensor one dimension,issue,negative,positive,positive,positive,positive,positive
512875209,Closing since it has been a while with no news. Please reopen with reproducible code if you get the time to dig into it.,since news please reopen reproducible code get time dig,issue,negative,neutral,neutral,neutral,neutral,neutral
512874853,"Yes, the model is loaded in a thread-safe way AFAICT.
Again, I can't help without code to reproduce.",yes model loaded way ca help without code reproduce,issue,positive,neutral,neutral,neutral,neutral,neutral
512874361,"Those aren't saved, but if reproducibility is your issue, you can pass a `seed` for the random split to be the same.
Otherwise, you can access the selected items in `data.train_ds.x.items` and `data.valid_ds.x.items` once at the `DataBunch` stage.

In general, we use the [forum](https://forums.fast.ai/) for questions around the library and keep issues for known bugs only.",saved reproducibility issue pas seed random split otherwise access selected stage general use forum around library keep known,issue,negative,negative,negative,negative,negative,negative
512804709,"(Promise we're good to go here, triple quadruple checked myself :) )",promise good go triple quadruple checked,issue,positive,positive,positive,positive,positive,positive
512663593,"Finished the documentation too :) Let me know if there are issues. I wasn't 100% sure if I could include the other repository bit. The goal was to make it available, if there's a better way to go about that (like just having it on the forum and lead to the forum post instead let me know!)",finished documentation let know sure could include repository bit goal make available better way go like forum lead forum post instead let know,issue,positive,positive,positive,positive,positive,positive
512633126,"text classification model, data is abstract text, python code.
First I fine-tuning the language model and text classification model, then use the data=load_data(), learn=text_classifier_learner(data...), lean.load_encoder(encoder), learn.load(model) to load the text classification model, is the model loaded this way thread-safe?",text classification model data abstract text python code first language model text classification model use data model load text classification model model loaded way,issue,negative,positive,positive,positive,positive,positive
512626351,Got it. Thank you! Did not know quite how to do the python check for that.,got thank know quite python check,issue,negative,neutral,neutral,neutral,neutral,neutral
512625027,"YEah your way is a bit clunky. A better way would be to use isinstance:
```
isinstance(interp.learn.data, TabularDataBunch)
```",yeah way bit better way would use,issue,positive,positive,positive,positive,positive,positive
512621751,Thanks for your suggestion! I've updated the test accordingly.,thanks suggestion test accordingly,issue,negative,positive,positive,positive,positive,positive
512545986,One afterthought though is is there a better way to check for a tabular databunch type in python that you know of? This would help in the future if in V2 you guys change that. ,one afterthought though better way check tabular type python know would help future change,issue,positive,positive,positive,positive,positive,positive
512527585,Okay now it's all done :) Let me know any further changes you would like or need!,done let know would like need,issue,negative,neutral,neutral,neutral,neutral,neutral
512474886,"Don't push just yet though please, I realized what you meant now by the one liners for those checks, fixing now :)",push yet though please meant one fixing,issue,negative,neutral,neutral,neutral,neutral,neutral
512439048,"I have made the changes you suggested, along with discovered and fixed a bug with the image display, and some spelling errors",made along discovered fixed bug image display spelling,issue,negative,positive,neutral,neutral,positive,positive
512335636,It's impossible to answer the question without more information. What kind of model? On what data? With which code?,impossible answer question without information kind model data code,issue,negative,negative,neutral,neutral,negative,negative
512251442,"Not 100% sure why those checks failed, doesn't seem related to my functionality though if I'm not mistaken?",sure seem related functionality though mistaken,issue,negative,positive,positive,positive,positive,positive
512038603,"Yes that would require a different sampler entirely. @tmabraham can you document properly that the callback only work for single-label problems? Thanks.
Closing the issue, asking for new features should be done on the [forum](https://forums.fast.ai)",yes would require different sampler entirely document properly work thanks issue new done forum,issue,positive,positive,neutral,neutral,positive,positive
512032467,"I did not design the callback with multi-label classification problems in mind. It may be hard because it is meant to adjust the class distribution based on their frequencies, but different labels have different distributions but they are also multiple labels per image.",design classification mind may hard meant adjust class distribution based different different also multiple per image,issue,negative,negative,neutral,neutral,negative,negative
511734633,"@sgugger  To change the loss function used by a learner, do you change the attribute `learn.loss_func` or `learn.lossfunc` like in the example above ? Or can you use it interchangeably ? 

Using fastai v 1.0.52 , pytorch v 1.1.0",change loss function used learner change attribute like example use interchangeably,issue,negative,neutral,neutral,neutral,neutral,neutral
511671171,"> > The problem somehow lies in your installation of ipywidgets: fastai did create it properly from what you're telling me, but it's not showing for some reason. I'm no expert in ipywidgets, so apart from trying to reinstall it properly, I don't have any better advice :-/
> 
> Thanks very much! After hours of struggling(forgive me i'm a beginner :-p ), finally i solved this problem(If that happened on mac or windows) by running these codes in the terminal:
> 
> ```
> # for mac terminal, use the command below; for windows cmd, add '--user' to the end of each command.
> 
> ###  First, reinstall ipywidgets and widgetsnbextension 
> pip install --upgrade --force-reinstall ipywidgets
> 
> pip install --upgrade --force-reinstall widgetsnbextension 
> 
> ### Second, install jupyter-js-widgets/extension
> jupyter nbextension install --py widgetsnbextension
> 
> ### Third, enable  widgetsnbextension
> jupyter nbextension enable --py widgetsnbextension --sys-prefix
> ```
> 
> now, we can enjoy lesson2_download.ipynb again. Simply type `jupyter notebook` in the terminal and open it in the browser.

In order to get this block of code to work on my Mac I had to add --user after this command (even though it says to only append that if you're on Windows):
```
### Second, install jupyter-js-widgets/extension
jupyter nbextension install --py widgetsnbextension
```

Changing that line to: ` jupyter nbextension install --py widgetsnbextension --user` fixed it for me.",problem somehow installation create properly telling showing reason expert apart trying reinstall properly better advice thanks much struggling forgive beginner finally problem mac running terminal mac terminal use command add user end command first reinstall pip install upgrade pip install upgrade second install install third enable enable enjoy simply type notebook terminal open browser order get block code work mac add user command even though append second install install line install user fixed,issue,negative,positive,positive,positive,positive,positive
511616245,"That is very weird. I don't see how this could have any effect to break the dataloader. Haven't tested on Windows but your example runs fine on my machine. Will try on Windows when I can access a proper install there.

For clearing the output, I can add an option to fastprogress to remove that. Will work on it when I have a bit of time. ",weird see could effect break tested example fine machine try access proper install clearing output add option remove work bit time,issue,negative,negative,neutral,neutral,negative,negative
511320796,@tmabraham  Sorry I actually meant se_resnext and not resnext  and yes we don't have se_resnext101_64x4d. I'm changing the title,sorry actually meant yes title,issue,negative,negative,negative,negative,negative,negative
511311188,"This is super useful, @tmabraham. Thanks a lot!",super useful thanks lot,issue,positive,positive,positive,positive,positive,positive
511234118,"@swagato-c I am confused. You are talking about resnext101 but then your code has se_resnext101. Also, I don't think se_resnext101_64x4d exists. You will need separate metadata for the resnext models.",confused talking code also think need separate,issue,negative,negative,negative,negative,negative,negative
511231882,"Sorry about that! I was experimenting in my notebook, and when I copied and pasted the code from the notebook, I accidentally left that in. It should be fixed now.",sorry notebook copied pasted code notebook accidentally left fixed,issue,negative,negative,negative,negative,negative,negative
511213226,"Sure, why don't you suggest a PR for it?
In general we keep issues for known bugs only and suggest new features on the [forum](https://forums.fast.ai/) or directly in PRs.",sure suggest general keep known suggest new forum directly,issue,negative,positive,positive,positive,positive,positive
510910049,"If so, Could you guys give an example or template about how to correctly use export() and load_learner functions in the customization case?",could give example template correctly use export case,issue,negative,neutral,neutral,neutral,neutral,neutral
510904044,"Your `Vocab` and `classes` should be initialized with lists, not dictionaries. This code passes
```
from fastai.text import *
ids = [np.array([0,0]),np.array([0,1])]*5 # notice diffrent number of elements in arrays
lbl = [0]*10
data = TextClasDataBunch.from_ids('/tmp', vocab=Vocab([BOS, PAD]),
                                  train_ids=ids, train_lbls=lbl,
                                  valid_ids=ids, valid_lbls=lbl, classes=[0], bs=8)
data.show_batch()
```",class code import notice number data pad,issue,negative,neutral,neutral,neutral,neutral,neutral
510880554,"Hi there, those questions should be asked on the [forum](https://forums.fast.ai/) where you'll find plenty of help. Issues on GitHub are for standing bugs only.",hi forum find plenty help standing,issue,negative,neutral,neutral,neutral,neutral,neutral
510058018,Yes metrics that are classes aren't pickle-able because of the weakref to Learner. I've pushed a rough fix that doesn't address the underlying problem (which will be solved by v2) by removing the automatic purge of the Learner in load.,yes metric class learner rough fix address underlying problem removing automatic purge learner load,issue,negative,negative,neutral,neutral,negative,negative
509778919,"@sgugger Ah I see now, my misunderstanding sorry. Thanks for the explanation. ",ah see misunderstanding sorry thanks explanation,issue,negative,negative,negative,negative,negative,negative
509761613,"I need a fully contained reproducible example to fix, like I said, I couldn't reproduce your bug. It's probably linked to the way you gathered your data too.",need fully reproducible example fix like said could reproduce bug probably linked way data,issue,negative,neutral,neutral,neutral,neutral,neutral
509760887,"Hi, I updated fastai to the latest version and reran the training and predicting and I'm back at the original error again",hi latest version training back original error,issue,negative,positive,positive,positive,positive,positive
509729251,"dtype == int does not work with Int64. Can you please add a '... or dtype == ""Int64""'?
Thank you.",work please add thank,issue,positive,neutral,neutral,neutral,neutral,neutral
509654030,"You need to pass a config in your call to `Learner` to use the old size:
```
config = awd_lstm_lm_config.copy()
config['n_hid'] = 1150
learn = bla_learner(..., config=config)
```",need pas call learner use old size learn,issue,negative,positive,neutral,neutral,positive,positive
509650593,"Hi, I have updated to 1.0.55 and not get a tensor shape error. I have tried changing the `awd_lstm_lm_config['n_hid']` but this isn't fixing it. Thanks for the help.

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-16-752e3a734fec> in <module>
----> 1 learn.load('./unga_uf_1');

/efs/data/jpb/fastai/fastai/fastai/basic_train.py in load(self, file, device, strict, with_opt, purge, remove_module)
    269             model_state = state['model']
    270             if remove_module: model_state = remove_module_load(model_state)
--> 271             get_model(self.model).load_state_dict(model_state, strict=strict)
    272             if ifnone(with_opt,True):
    273                 if not hasattr(self, 'opt'): self.create_opt(defaults.lr, self.wd)

~/anaconda3/envs/fastai_test/lib/python3.6/site-packages/torch/nn/modules/module.py in load_state_dict(self, state_dict, strict)
    769         if len(error_msgs) > 0:
    770             raise RuntimeError('Error(s) in loading state_dict for {}:\n\t{}'.format(
--> 771                                self.__class__.__name__, ""\n\t"".join(error_msgs)))
    772 
    773     def _named_members(self, get_members_fn, prefix='', recurse=True):

RuntimeError: Error(s) in loading state_dict for SequentialRNN:
	size mismatch for 0.rnns.0.weight_hh_l0_raw: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).
	size mismatch for 0.rnns.0.module.weight_ih_l0: copying a param with shape torch.Size([4600, 400]) from checkpoint, the shape in current model is torch.Size([4608, 400]).
	size mismatch for 0.rnns.0.module.weight_hh_l0: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).
	size mismatch for 0.rnns.0.module.bias_ih_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).
	size mismatch for 0.rnns.0.module.bias_hh_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).
	size mismatch for 0.rnns.1.weight_hh_l0_raw: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).
	size mismatch for 0.rnns.1.module.weight_ih_l0: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).
	size mismatch for 0.rnns.1.module.weight_hh_l0: copying a param with shape torch.Size([4600, 1150]) from checkpoint, the shape in current model is torch.Size([4608, 1152]).
	size mismatch for 0.rnns.1.module.bias_ih_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).
	size mismatch for 0.rnns.1.module.bias_hh_l0: copying a param with shape torch.Size([4600]) from checkpoint, the shape in current model is torch.Size([4608]).
	size mismatch for 0.rnns.2.module.weight_ih_l0: copying a param with shape torch.Size([1600, 1150]) from checkpoint, the shape in current model is torch.Size([1600, 1152]).
```",hi get tensor shape error tried fixing thanks help recent call last module load self file device strict purge state true self self strict raise loading self error loading size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model size mismatch param shape shape current model,issue,negative,positive,neutral,neutral,positive,positive
509633911,"I can't reproduce on master. I see you're using v1.0.51 on your install details, try updating the library and see if the bug persists? I think it has been fixed already.",ca reproduce master see install try library see bug think fixed already,issue,negative,positive,neutral,neutral,positive,positive
509632507,"Thanks for flagging, I was supposed to tackle that a long time ago but forgot. Just returning o when there is no vocab is fine and give a consistent representation.",thanks flagging supposed tackle long time ago forgot fine give consistent representation,issue,positive,positive,positive,positive,positive,positive
509631184,"Thanks, this is a step in the right direction. The functions `roc_curve` and `auroc_curve` can be useful on their own, it's just that they are only appropriate if you have all your predictions and targets available (for instance after a `get_preds`), they are not suitable to be passed to `Learner` directly as you pointed out however.",thanks step right direction useful appropriate available instance suitable learner directly pointed however,issue,positive,positive,positive,positive,positive,positive
509629133,"Thanks a lot, just renamed the variable out_shape but it's looking good!",thanks lot variable looking good,issue,positive,positive,positive,positive,positive,positive
509494243,"hi Sylvain  : Please let me know how I can contribute to do the PR ?

Thanks,
Jyoti Bose

On Tue, Jul 9, 2019 at 6:58 AM Sylvain Gugger <notifications@github.com>
wrote:

> Just checking if you're still interested in doing a PR for the fix. I can
> do it otherwise.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2194?email_source=notifications&email_token=AHCRTFIH5G25KODAHRBXNCTP6PSTRA5CNFSM4H4ZRZE2YY3PNVWWK3TUL52HS4DFVREXG43VMVBW63LNMVXHJKTDN5WW2ZLOORPWSZGODZOZUHI#issuecomment-509450781>,
> or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AHCRTFNIZ7J2XB7QSXWKNXTP6PSTRANCNFSM4H4ZRZEQ>
> .
>
",hi please let know contribute thanks bose tue wrote still interested fix otherwise thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
509450781,Just checking if you're still interested in doing a PR for the fix. I can do it otherwise.,still interested fix otherwise,issue,negative,positive,positive,positive,positive,positive
509349225,"Your expected behavior is the weird one IMO. You say calling `fit_one_cycle` resets the RNGs but it does not, that is exactly what I'm explaining in my previous posts. The RNGs have been set with a seed, you ask for random permutations three times in a row with your three epochs, then three permutations again which are going to be
- the same as before if you set the random seed again (which would reset the RNGs)
- not the same as before if you don't set the seed again

In any case there is nothing in the fastai library or PyTorch that induces this behavior since it's the normal behavior of the random libraries. There is probably something in Keras/TF to make it behave this way on the other hand.

Closing the issue since there is no bug here.",behavior weird one say calling exactly explaining previous set seed ask random three time row three three going set random seed would reset set seed case nothing library behavior since normal behavior random probably something make behave way hand issue since bug,issue,negative,negative,negative,negative,negative,negative
509347206,Sorry see my edit above for an example of expected behaviour. Why does calling `fit_one_cycle` reset the RNGs?,sorry see edit example behaviour calling reset,issue,negative,negative,negative,negative,negative,negative
509346428,"In trial 1 you set the seed and ask for n random numbers (first training) then ask for n new random numbers, which are going to be random since you didn't reset the seed (second training).

In trial 2 you set the seed and ask for n random numbers (first training) then set the seed again and ask for n random numbers, which are going to be the same ones as before (second training).

Setting the seed just initialize your random number generators, then, when you draw numbers you need to set the seed again to get the same ones.",trial set seed ask random first training ask new random going random since reset seed second training trial set seed ask random first training set seed ask random going second training setting seed initialize random number draw need set seed get,issue,negative,negative,negative,negative,negative,negative
509345181,"Sorry maybe I wasn't clear. I do not understand why seeds should have to be set before each call to fit. 

If the generators are seeded once at the beginning of the session, why should they ever have to be seeded again? What is causing the seeds to be reset?

**For Example**: in Tensorflow or Keras once RNGs are seeded they never have to be re-seeded again, even between `fit` calls and model initializations. They only ever need to be re-seeded if the session is reset.
Is some function in FastAI or Torch resetting the RNGs to cause them to have to be re-seeded?",sorry maybe clear understand set call fit seeded beginning session ever seeded causing reset example seeded never even fit model ever need session reset function torch cause,issue,positive,positive,positive,positive,positive,positive
509340564,"I'm not sure I understand what you think the bug is. In trial 1, you set the seeds before the first fit but not the second, so you get a different behavior in the second fit. A training is random by essence, since the data is shuffled at every epoch in the training set, so this is completely expected.

In trial 2 you set the seeds before each call so get the same behavior each time. This all seems perfectly normal to me.
",sure understand think bug trial set first fit second get different behavior second fit training random essence since data every epoch training set completely trial set call get behavior time perfectly normal,issue,positive,positive,positive,positive,positive,positive
509211808,"Ah true, it's only used in `cnn_learner`. Thanks for flagging!",ah true used thanks flagging,issue,positive,positive,positive,positive,positive,positive
508923137,"This runs normally for me. I think it's link to PyTorch DataLoader being slow on Windows ([see here](https://github.com/pytorch/pytorch/issues/12831) for the issue filed on PyTorch). In general you can't have fast DataLoader in jupyter notebook on windows because of some issues linked to multiprocessing, from my understanding.

Closing because this isn't linked to fastai and there is little we can do about it on our side.",normally think link slow see issue general ca fast notebook linked understanding linked little side,issue,negative,negative,neutral,neutral,negative,negative
508584556,"Yes, PyTorch Batchnorm layers require a batch size of more than one otherwise you don't have an std. Nothing we can do about in fastai.",yes require batch size one otherwise nothing,issue,negative,neutral,neutral,neutral,neutral,neutral
508108262,"This is mostly legacy code now, so just the fix is enough. New version of UlmFIT with v1 is [here](https://github.com/fastai/fastai/blob/master/examples/ULMFit.ipynb)",mostly legacy code fix enough new version,issue,negative,positive,positive,positive,positive,positive
507977294,"Sure.

This seems to be related to the ulmfit_v1 branch and is not on master. Should I add some tests, and if so, where would be the right place to put them?",sure related branch master add would right place put,issue,negative,positive,positive,positive,positive,positive
507719518,"Mmmm, there is little I can do about the second problem: subclassing the DataLoader from PyTorch and removing arguments in the constructor is definitely not compatible with fastai.

A workaround if you just want to train a model is to create your own data class, with an attribute `train_dl`, `valid_dl` and `device`. If you pass that to Learner, you should be fine.

fastai v2 won't require a custom collate function like v1 does, so the broader issue will be solved in it, for the short term, there is nothing else I can do.",little second problem removing constructor definitely compatible want train model create data class attribute device pas learner fine wo require custom collate function like issue short term nothing else,issue,positive,positive,neutral,neutral,positive,positive
507674933,"Sure, would you mind making a PR with it?",sure would mind making,issue,negative,positive,positive,positive,positive,positive
507407099,"I just checked and scikit learn returns 0 and issues a warning in those cases, so I think we should mimic that behavior.",checked learn warning think mimic behavior,issue,negative,neutral,neutral,neutral,neutral,neutral
507405996,"Thanks for the feedback. So indeed for recall, having a null sum probably means there is an issue with the validation set. However for precision, if one class end-up never been predicted, then the sum will be zero for that class. I ran into this issue while training a classifier on a very skewed dataset, where some of the classes have very few samples. Because of that some classes are not predicted and the averaged precision is NaN. Then maybe the eps only makes sense for the precision case, in order to at least have a feel of the precision for the rest of the classes.",thanks feedback indeed recall null sum probably issue validation set however precision one class never sum zero class ran issue training classifier skewed class class precision nan maybe sense precision case order least feel precision rest class,issue,negative,negative,neutral,neutral,negative,negative
507257849,"Thanks for the PR. Since we're summing integers, it's not really numerical stability we're talking about. I'm open to have a test for the sum 0 and a sensible result (I do think NaN is a good value since precision/recall are just not defined in those situations though) but adding an eps to the denominator isn't a right solution IMO.

Also, not that if you get an error it means there is not a single item of the measured class in the whole validation set (metric is computed after going through the whole thing) so it's really weird to have a 0 sum at that point, which is why the user should also get a weird result.",thanks since really numerical stability talking open test sum sensible result think nan good value since defined though denominator right solution also get error single item measured class whole validation set metric going whole thing really weird sum point user also get weird result,issue,positive,positive,neutral,neutral,positive,positive
507064873,"Np, `filter_by_rand` is indeed the function you would want for your use case.

Thanks for the PR!",indeed function would want use case thanks,issue,negative,positive,positive,positive,positive,positive
507063772,"Sorry I forgot to rename the function as you suggested, apologies for killing the build bot.",sorry forgot rename function killing build bot,issue,negative,negative,negative,negative,negative,negative
507063570,"Added the changes.

My use case for `filter_by_rand ` was to get a sample of a larger data set to run some quick tests, is this the correct function to use?   The reason I asked about global seeds is because I wanted the same sample set for each run but I didn't really want to seed all the other prng's which are used throughout the fastai library.  It probably doesn't matter I just remember Jeremy mentioning that it is useful for finding bugs if you have random initialization.",added use case get sample data set run quick correct function use reason global sample set run really want seed used throughout library probably matter remember useful finding random,issue,positive,positive,neutral,neutral,positive,positive
507062595,"I think `set_all_seed` would be even more appropriate. I don't have use cases for `filter_by_rand` in mind, but in any case it needs setting the seed for everything apart from numpy as you pointed out, so if someone wants randomness, they can set the seed to a random number after collecting the data. 

Didn't torch.manual_seed was doing everything PyTorch related now, so if that's the case, no need to add something else.",think would even appropriate use mind case need setting seed everything apart pointed someone randomness set seed random number data everything related case need add something else,issue,negative,neutral,neutral,neutral,neutral,neutral
507062333,"Hi, no that's not a problem, if I set the numpy seed as well should I rename the function to something more appropriate like set_random_seed()?

Is it intentional then to set global seeds every time instead of creating generators and passing them around?  That is if I pass a seed to filter_by_rand() I might just want the same data set but not want the same batch data loading order, model weight initialization etc. which are also randomly generated.

I think that now [torch.manual_seed()](https://pytorch.org/docs/stable/notes/randomness.html) sets the seed for all devices have you experienced anything different?",hi problem set seed well rename function something appropriate like intentional set global every time instead passing around pas seed might want data set want batch data loading order model weight also randomly think seed experienced anything different,issue,negative,positive,positive,positive,positive,positive
507059823,"Thanks for spotting that. One change I would make is to make `set_uniform_seed` set the seed received (leave the if None test in the function filter_by_rand) and set all the seeds (torch, torch.cuda, random and numpy) since it could then be used by someone wanted to launch a reproducible training.

Do you mind adding that yo your PR or do your prefer I merge and apply that change afterward?",thanks spotting one change would make make set seed received leave none test function set torch random since could used someone launch reproducible training mind yo prefer merge apply change afterward,issue,negative,negative,negative,negative,negative,negative
507037744,"> > > The problem somehow lies in your installation of ipywidgets: fastai did create it properly from what you're telling me, but it's not showing for some reason. I'm no expert in ipywidgets, so apart from trying to reinstall it properly, I don't have any better advice :-/
> > 
> > 
> > Thanks very much! After hours of struggling(forgive me i'm a beginner :-p ), finally i solved this problem(If that happened on mac or windows) by running these codes in the terminal:
> > ```
> > # for mac terminal, use the command below; for windows cmd, add '--user' to the end of each command.
> > 
> > ###  First, reinstall ipywidgets and widgetsnbextension 
> > pip install --upgrade --force-reinstall ipywidgets
> > 
> > pip install --upgrade --force-reinstall widgetsnbextension 
> > 
> > ### Second, install jupyter-js-widgets/extension
> > jupyter nbextension install --py widgetsnbextension
> > 
> > ### Third, enable  widgetsnbextension
> > jupyter nbextension enable --py widgetsnbextension --sys-prefix
> > ```
> > 
> > 
> > now, we can enjoy lesson2_download.ipynb again. Simply type `jupyter notebook` in the terminal and open it in the browser.
> 
> @light : your solution works for jupyter notebook but NOT colab notebook, right? If it only works for jupyter notebook and (I assume that you use a local machine), where do you use GPU? Thanks!

i assume colab would not have supported all widgets, please refer to what sgugger said. i use my local gpu by jupter notebook.",problem somehow installation create properly telling showing reason expert apart trying reinstall properly better advice thanks much struggling forgive beginner finally problem mac running terminal mac terminal use command add user end command first reinstall pip install upgrade pip install upgrade second install install third enable enable enjoy simply type notebook terminal open browser light solution work notebook notebook right work notebook assume use local machine use thanks assume would please refer said use local notebook,issue,positive,positive,positive,positive,positive,positive
506921731,"> > The problem somehow lies in your installation of ipywidgets: fastai did create it properly from what you're telling me, but it's not showing for some reason. I'm no expert in ipywidgets, so apart from trying to reinstall it properly, I don't have any better advice :-/
> 
> Thanks very much! After hours of struggling(forgive me i'm a beginner :-p ), finally i solved this problem(If that happened on mac or windows) by running these codes in the terminal:
> 
> ```
> # for mac terminal, use the command below; for windows cmd, add '--user' to the end of each command.
> 
> ###  First, reinstall ipywidgets and widgetsnbextension 
> pip install --upgrade --force-reinstall ipywidgets
> 
> pip install --upgrade --force-reinstall widgetsnbextension 
> 
> ### Second, install jupyter-js-widgets/extension
> jupyter nbextension install --py widgetsnbextension
> 
> ### Third, enable  widgetsnbextension
> jupyter nbextension enable --py widgetsnbextension --sys-prefix
> ```
> 
> now, we can enjoy lesson2_download.ipynb again. Simply type `jupyter notebook` in the terminal and open it in the browser.

@Light : your solution works for jupyter notebook but NOT colab notebook, right? If it only works for jupyter notebook and (I assume that you use a local machine), where  do you use GPU? Thanks!",problem somehow installation create properly telling showing reason expert apart trying reinstall properly better advice thanks much struggling forgive beginner finally problem mac running terminal mac terminal use command add user end command first reinstall pip install upgrade pip install upgrade second install install third enable enable enjoy simply type notebook terminal open browser light solution work notebook notebook right work notebook assume use local machine use thanks,issue,positive,positive,positive,positive,positive,positive
506763731,You can still find the original classes in src.train/src.valid after splitting then src.train.x/src.valid.x after labelling.,still find original class splitting,issue,negative,positive,positive,positive,positive,positive
506761811,"I see now this was intentional. Class names alter every time I run methods on a callable.
```
.split_by_folder();
.label_from_folder();
```
you may close the incident and thanks for the prompt answer.",see intentional class alter every time run callable may close incident thanks prompt answer,issue,negative,positive,positive,positive,positive,positive
506728787,"I don't understand where the bug is. When split any `ItemList` becomes an `ItemLists`, then when labelled it becomes a `LabelLists`. What where you thinking you would see?",understand bug split becomes becomes thinking would see,issue,negative,neutral,neutral,neutral,neutral,neutral
506728096,"Thanks a lot! There is a little thing to change IMO: having the learner as an attribute creates a cyclical reference (the learner has a reference to the callback and the callback one to the learner) which causes memory leak issues.
You should use `LearnerCallback` as superclass then uncomment `super().__init__(learn)` in your init, the `LearnerCallback` class is specifically there to remove that problem by using a weak reference to the `Learner`.",thanks lot little thing change learner attribute cyclical reference learner reference one learner memory leak use superclass super learn class specifically remove problem weak reference learner,issue,negative,negative,neutral,neutral,negative,negative
506524884,"This is not a bug, if you don't provide layer groups or build some later with `Learner.split`, all parameters are in the same parameter groups and there is no freezing/unfreezing or differential learning rates.

That's why functions like `cnn_learner` exist, to do this split for you behind the scenes.",bug provide layer build later parameter differential learning like exist split behind,issue,negative,negative,negative,negative,negative,negative
506013383,"Looking good! If we always have a way to get it right, we don't need an argument, no.",looking good always way get right need argument,issue,negative,positive,positive,positive,positive,positive
506012935,"Yes, `data.train_dl` is sufficient.

```python
def unet_learner(data:DataBunch, arch:Callable, pretrained:bool=True, blur_final:bool=True,
                 norm_type:Optional[NormType]=NormType, split_on:Optional[SplitFuncOrIdxList]=None, blur:bool=False,
                 self_attention:bool=False, y_range:Optional[Tuple[float,float]]=None, last_cross:bool=True,
                 bottle:bool=False, cut:Union[int,Callable]=None, **learn_kwargs:Any)->Learner:
    ""Build Unet learner from `data` and `arch`.""
    meta = cnn_config(arch)
    body = create_body(arch, pretrained, cut)
    try:
        size = data.train_ds[0][0].size
    except:
        size = next(iter(data.train_dl))[0].shape[-2:]
    model = to_device(DynamicUnet2(body, n_classes=data.c, img_size=size, blur=blur, blur_final=blur_final,
          self_attention=self_attention, y_range=y_range, norm_type=norm_type, last_cross=last_cross,
          bottle=bottle), data.device)
    learn = Learner(data, model, **learn_kwargs)
    learn.split(ifnone(split_on, meta['split']))
    if pretrained: learn.freeze()
    apply_init(model[2], nn.init.kaiming_normal_)
    return learn
````
is it ok now?

> I think `unet_leaner` should also take a size argument to overwrite the result of `data.train_ds[0][0]`

is this comment still valid? I don't see why you would want to overwrite the size. 
",yes sufficient python data arch callable optional optional blur optional float float bottle cut union callable learner build learner data arch meta arch body arch cut try size except size next iter model body learn learner data model meta model return learn think also take size argument overwrite result comment still valid see would want overwrite size,issue,negative,neutral,neutral,neutral,neutral,neutral
506008479,"> Glad you solved it and thanks for the detailed instructions! That'll help people :)
> I'd suggest you copy them in the topic you mentioned on the forum for maximum visibility.

ok, no problem. ",glad thanks detailed help people suggest copy topic forum maximum visibility problem,issue,positive,positive,positive,positive,positive,positive
506003791,"Glad you solved it and thanks for the detailed instructions! That'll help people :)
I'd suggest you copy them in the topic you mentioned on the forum for maximum visibility.",glad thanks detailed help people suggest copy topic forum maximum visibility,issue,positive,positive,positive,positive,positive,positive
505999861,"> The problem somehow lies in your installation of ipywidgets: fastai did create it properly from what you're telling me, but it's not showing for some reason. I'm no expert in ipywidgets, so apart from trying to reinstall it properly, I don't have any better advice :-/

Thanks very much! After hours of struggling(forgive me i'm a beginner :-p ), finally i solved this problem(If that happened on mac or windows) by running these codes in the terminal:

```
# for mac terminal, use the command below; for windows cmd, add '--user' to the end of each command.

###  First, reinstall ipywidgets and widgetsnbextension 
pip install --upgrade --force-reinstall ipywidgets

pip install --upgrade --force-reinstall widgetsnbextension 

### Second, install jupyter-js-widgets/extension
jupyter nbextension install --py widgetsnbextension

### Third, enable  widgetsnbextension
jupyter nbextension enable --py widgetsnbextension --sys-prefix

```
now, we can enjoy lesson2_download.ipynb again. Simply type `jupyter notebook` in the terminal and open it in the browser.",problem somehow installation create properly telling showing reason expert apart trying reinstall properly better advice thanks much struggling forgive beginner finally problem mac running terminal mac terminal use command add user end command first reinstall pip install upgrade pip install upgrade second install install third enable enable enjoy simply type notebook terminal open browser,issue,positive,positive,positive,positive,positive,positive
505996499,"Yes, good idea! But test the dataset first as it's faster. Also, no need for the `.dl`, just `data.train_dl` should be enough I think.",yes good idea test first faster also need enough think,issue,positive,positive,positive,positive,positive,positive
505990437,"Will something like this be okay if the DataBunch was created from PyTorch dataloaders?
```python
next(iter(data.train_dl.dl))[0].shape[-2:]
```
",something like python next iter,issue,negative,neutral,neutral,neutral,neutral,neutral
505863071,"Thanks! I think `unet_leaner` should also take a size argument to overwrite the result of `data.train_ds[0][0]`. Also we should do this a try except block (that would end with size=None) because if someone created their DataBunch from PyTorch dataloaders, it won't have a `train_ds`.",thanks think also take size argument overwrite result also try except block would end someone wo,issue,negative,positive,positive,positive,positive,positive
505860860,"The problem somehow lies in your installation of ipywidgets: fastai did create it properly from what you're telling me, but it's not showing for some reason. I'm no expert in ipywidgets, so apart from trying to reinstall it properly, I don't have any better advice :-/",problem somehow installation create properly telling showing reason expert apart trying reinstall properly better advice,issue,negative,positive,positive,positive,positive,positive
505696380,"Sorry about recommenting this closed issue, but I still got this problem and 3 other people too.. not caused by colab or jupyter lab, see link: https://forums.fast.ai/t/imagecleaner-doesnt-render/37152

Is the problem not solved? I got the following output when i was running the [lesson2_download.ipynb](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson2-download.ipynb):

input:
```
from fastai.vision import *
from fastai.widgets import *
path = Path('data/bears')
db = (ImageList.from_folder(path)
     .split_none()
      .label_from_folder()
      .transform(get_transforms(), size=224)
      .databunch()
     )
learn_cln = cnn_learner(db, models.resnet34, metrics=error_rate)
learn_cln.load('stage-2')
ds, idxs = DatasetFormatter().from_toplosses(learn_cln)
ImageCleaner(ds, idxs, path)
```


Output: (no render)
```
HBox(children=(VBox(children=(Image(value=b'\xff\xd8\xff\xe0\x00\x10JFIF\x00\x01\x01\x01\x00d\x00d\x00\x00\xff…
Button(button_style='primary', description='Next Batch', layout=Layout(width='auto'), style=ButtonStyle())
<fastai.widgets.image_cleaner.ImageCleaner at 0x28c1ce7a198>
```
",sorry closed issue still got problem people lab see link problem got following output running input import import path path path path output render image button batch,issue,negative,negative,negative,negative,negative,negative
505518823,"Right, do you mind making a PR with that change? Thanks.",right mind making change thanks,issue,negative,positive,positive,positive,positive,positive
505444067,"What you added to master is perfect for what I need to do, thanks! ",added master perfect need thanks,issue,positive,positive,positive,positive,positive,positive
505440736,"It's not really a bug and more of a defense mechanism: you are trying to apply some transforms to images in your test set so the predicted output of the model won't match the inputs. In this case a center crop is applied if your image isn't a square so you won't get predictions on all the image + the output will be at a different size.

It's very tricky to handle the test set when `tfm_y=True` but you're right that the library should allow you to pass custom tfms/tfm_y for the test set, which is what I added in master.",really bug defense mechanism trying apply test set output model wo match case center crop applied image square wo get image output different size tricky handle test set right library allow pas custom test set added master,issue,negative,positive,neutral,neutral,positive,positive
504996723,"Thanks for your PR, but please change the notebook `vision.learner.ipynb` and not the HTML file: the docs are auto-generated from the notebooks so if I merge your PR, the change will be erased at the next build.",thanks please change notebook file merge change erased next build,issue,positive,positive,neutral,neutral,positive,positive
504467679,"Steps to be able to plot to console using fastai on Ubuntu 18.04 desktop/

You need Python 3.6, this will not work with 3.7. To create a new conda env with Python 3.6 execute the following `conda create -n py36 python=3.6 anaconda`. You can activate it by running `source activate py36`. Make sure you have fastai installed in the new env. 

```
git clone git@github.com:saitoha/libsixel.git
cd libsixel/
./configure --enable-python --prefix=/usr/local
sudo make install
cd python
python setup.py install

cd ../..
git clone git@github.com:saitoha/PySixel.git
cd PySixel
python setup.py install

sudo apt install mlterm
```

Run `mlterm`. From under it you should now be able to run the following [script](https://gist.github.com/radekosmulski/54dc35136133cfceb67aded2004d18c2) and plots should appear in console.
```",able plot console need python work create new python execute following create anaconda activate running source activate make sure new git clone git make install python python install git clone git python install apt install run able run following script appear console,issue,positive,positive,positive,positive,positive,positive
504462613,"I am using mlterm on Ubuntu 18.04 desktop (I tried both compiling it from source and installing a package using `sudo apt install mlterm`. I compiled libsixel from https://github.com/saitoha/libsixel master with the following command `./configure --enable-python --prefix=/usr/local` but I also had to install through `python setup.py install`. I am using Anaconda and Python 3.7.

When I try to run the minimal example from #2170 I get the following error:
```
Traceback (most recent call last):
  File ""min_example.py"", line 30, in <module>
    plot_sixel(fig)
  File ""min_example.py"", line 21, in plot_sixel
    res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
  File ""min_example.py"", line 10, in _sixel_encode
    libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
  File ""/home/radek/anaconda3/envs/fastai/lib/python3.7/site-packages/libsixel_python-0.5.0-py3.7.egg/libsixel/__init__.py"", line 506, in sixel_dither_initialize
    quality_mode)
ctypes.ArgumentError: argument 2: <class 'TypeError'>: wrong type
```
`img2sixel` from mlterm works though.

I came across [PySixel](https://github.com/saitoha/PySixel). I created a new conda env with python 3.6. I installed PySixel and ran `python setup.py install` in the libsixel repo IIRC. After this change, both the minimal example from #2170 passes and I can also plot from fastai.",tried source package apt install master following command also install python install anaconda python try run minimal example get following error recent call last file line module fig file line file line dither data file line argument class wrong type work though came across new python ran python install change minimal example also plot,issue,negative,positive,neutral,neutral,positive,positive
504445772,"Oh I'm sorry, I misunderstood your issue. There was a bug indeed, should be fixed in master now.",oh sorry misunderstood issue bug indeed fixed master,issue,negative,negative,negative,negative,negative,negative
504443313,"Thanks for your reply.

I followed your suggestion and I'm still seeing the error.

Here's my updated code:
```
from fastai.text import *
defaults.device=torch.device('cpu')

data_clas = TextClasDataBunch.load(directory_path/""data"", training_path, bs=batch_size, device='cpu')
learn = text_classifier_learner(data_clas, arch=AWD_LSTM, drop_mult=0.5)
learn.load_encoder('fine_tuned_enc', device='cpu')
```

and here's my stack trace:
```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-7-bd0a25d40193> in <module>()
----> 1 learn.load_encoder('fine_tuned_enc', device='cpu')

C:\Program Files\Anaconda3\lib\site-packages\fastai\text\learner.py in load_encoder(self, name, device)
     67         if device is None: device = self.data.device
     68         if hasattr(encoder, 'module'): encoder = encoder.module
---> 69         encoder.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth'))
     70         encoder.load_state_dict(torch.load(self.path/self.model_dir/f'{name}.pth', map_location=device))
     71         self.freeze()

C:\Program Files\Anaconda3\lib\site-packages\torch\serialization.py in load(f, map_location, pickle_module)
    365         f = open(f, 'rb')
    366     try:
--> 367         return _load(f, map_location, pickle_module)
    368     finally:
    369         if new_fd:

C:\Program Files\Anaconda3\lib\site-packages\torch\serialization.py in _load(f, map_location, pickle_module)
    536     unpickler = pickle_module.Unpickler(f)
    537     unpickler.persistent_load = persistent_load
--> 538     result = unpickler.load()
    539
    540     deserialized_storage_keys = pickle_module.load(f)

C:\Program Files\Anaconda3\lib\site-packages\torch\serialization.py in persistent_load(saved_id)
    502             if root_key not in deserialized_objects:
    503                 deserialized_objects[root_key] = restore_location(
--> 504                     data_type(size), location)
    505             storage = deserialized_objects[root_key]
    506             if view_metadata is not None:

C:\Program Files\Anaconda3\lib\site-packages\torch\serialization.py in default_restore_location(storage, location)
    111 def default_restore_location(storage, location):
    112     for _, _, fn in _package_registry:
--> 113         result = fn(storage, location)
    114         if result is not None:
    115             return result

C:\Program Files\Anaconda3\lib\site-packages\torch\serialization.py in _cuda_deserialize(obj, location)
     92 def _cuda_deserialize(obj, location):
     93     if location.startswith('cuda'):
---> 94         device = validate_cuda_device(location)
     95         return obj.cuda(device)
     96

C:\Program Files\Anaconda3\lib\site-packages\torch\serialization.py in validate_cuda_device(location)
     76
     77     if not torch.cuda.is_available():
---> 78         raise RuntimeError('Attempting to deserialize object on a CUDA '
     79                            'device but torch.cuda.is_available() is False. '
     80                            'If you are running on a CPU-only machine, '

RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU.
```

Am I missing something?",thanks reply suggestion still seeing error code import data learn stack trace recent call last module self name device device none device name name load open try return finally result size location storage none storage location storage location result storage location result none return result location location device location return device location raise object false running machine object device false running machine please use map missing something,issue,negative,negative,neutral,neutral,negative,negative
504409091,"Ok, you're the second person to have that error now (see #2170)
I put a minimal example there that doesn't use fastai at all. Can you see if you manage to somehow make it work? I'm unsure if this is a bug in our code or libsixel.",second person error see put minimal example use see manage somehow make work unsure bug code,issue,negative,negative,neutral,neutral,negative,negative
504214928,"Oh, those are the normal widgets indeed. I was confused because in your first notebook I saw
```
from google.colab import widgets
```
so there clearly are some google colab-specific widgets.

In any case, if the `ImageCleaner` doesnt work in colab it's because they don't support all ipywidget widgets, there is no exterior magic in it (if you look at the source code, we only import from widgets and Layout). Maybe there is workaround but I have no time figuring it out. I suspect it's possible we have to import the widgets from google.colab instead of the one from ipywidget but 
1. it would require some ugly code in the library to make the switch
2. I don't know if it's the only thing to change ",oh normal indeed confused first notebook saw import clearly case doesnt work support exterior magic look source code import layout maybe time suspect possible import instead one would require ugly code library make switch know thing change,issue,negative,negative,neutral,neutral,negative,negative
504198802,"> No it's not. Google doesn't support ipywidgets, it supports its own set of widgets which are different. `ImageCleaner` will continue to not work in colab and probably never will since they made the choice to design a new tool instead of using the one everyone else uses.
> 
> The issue is closed because there is nothing we can do about it on the fastai side.

@sgugger could you look at [this](https://colab.research.google.com/github/jupyter-widgets/ipywidgets/blob/master/docs/source/examples/Using%20Interact.ipynb#scrollTo=ngbH-aW5wPnW) notebook? is this different than `ipywidgets` that fastai is using?",support set different continue work probably never since made choice design new tool instead one everyone else issue closed nothing side could look notebook different,issue,negative,positive,neutral,neutral,positive,positive
504180008,"This is not linked to the first call to `load_encoder` but the fact the model is placed on the same device as your data, which is the GPU by default. If you pass `device='cpu'` in your call to `data_clas`, or choose `defaults.device=torch.device('cpu')`, you will indicate to the library your intent to work on the CPU and it will solve your issue.",linked first call fact model device data default pas call choose indicate library intent work solve issue,issue,negative,positive,positive,positive,positive,positive
504179254,"No it's not. Google doesn't support ipywidgets, it supports its own set of widgets which are different. `ImageCleaner` will continue to not work in colab and probably never will since they made the choice to design a new tool instead of using the one everyone else uses.

The issue is closed because there is nothing we can do about it on the fastai side.",support set different continue work probably never since made choice design new tool instead one everyone else issue closed nothing side,issue,negative,positive,neutral,neutral,positive,positive
503543257,"The problem lies in your PyTorch installation (it can't load the wrapped C libraries) so you you should ask on [their forum](https://discuss.pytorch.org/) or file an issue on their repo.

Note that normally, torch is installed by default on colab, as well as fastai.",problem installation ca load wrapped ask forum file issue note normally torch default well,issue,negative,positive,positive,positive,positive,positive
503159602,"I agree. I am unsuccessfully attempting to find an alternate value for some of the default arguments to `sixel_dither_initialize` that works for both of us, and will update this issue if I find one. If not, I'll log an issue with the libsixel folks.

Thanks again for your help with this. I'm closing the issue.",agree unsuccessfully find alternate value default work u update issue find one log issue thanks help issue,issue,positive,positive,neutral,neutral,positive,positive
503135424,"As far as I can tell, this seems to be a bug in your install or libsixel: this is a simple example unrelated to fastai taht should work. Maybe file an issue with libsixel if re-installing doesn't fix the problem?",far tell bug install simple example unrelated work maybe file issue fix problem,issue,negative,positive,neutral,neutral,positive,positive
502816348,Never mind; mistook layers & layer groups,never mind mistook layer,issue,negative,neutral,neutral,neutral,neutral,neutral
502768515,"Yes, it fails with the same error:
```
Traceback (most recent call last):
  File ""sixeltest.py"", line 30, in <module>
    plot_sixel(fig)
  File ""sixeltest.py"", line 21, in plot_sixel
    res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
  File ""sixeltest.py"", line 10, in _sixel_encode
    libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/libsixel/__init__.py"", line 506, in sixel_dither_initialize
    quality_mode)
ctypes.ArgumentError: argument 2: <class 'TypeError'>: wrong type
```",yes error recent call last file line module fig file line file line dither data file line argument class wrong type,issue,negative,negative,negative,negative,negative,negative
502759069,"Ok so it's clearly that line that fails for you
```
libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
```
in fastai.sixel. I'm not too familiar with libsixel and din't write that part but maybe there is another flag that makes this work for you?  

This is a minimum example at this stage that works for me (and probably not for you)
```
import numpy as np
import matplotlib.pyplot as plt
import libsixel,io

def _sixel_encode(data, width, height):
    s = io.BytesIO()
    output = libsixel.sixel_output_new(lambda data, s: s.write(data), s)
    dither = libsixel.sixel_dither_new(256)
    w,h = int(width),int(height)
    libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
    libsixel.sixel_encode(data, w, h, 1, dither, output)
    return s.getvalue().decode('ascii')

def plot_sixel(fig=None):
    if not libsixel:
        warn(""You could see this plot with `libsixel`. See https://github.com/saitoha/libsixel"")
        return
    if fig is None: fig = plt.gcf()
    fig.canvas.draw()
    dpi = fig.get_dpi()
    res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
    print(res)

fig, ax = plt.subplots(1,1)
x = np.linspace(0,100)
y = np.exp(x)
ax.plot(x, y)
ax.set_ylabel(""Loss"")
ax.set_xlabel(""Learning Rate"")
plot_sixel(fig)
```",clearly line dither data familiar di write part maybe another flag work minimum example stage work probably import import import io data width height output lambda data data dither width height dither data data dither output return warn could see plot see return fig none fig print fig ax loss learning rate fig,issue,negative,positive,positive,positive,positive,positive
502757735,"Thanks for scratching your head over this in any case.

Your matplotlib example doesn't work either, also failing with a `ctypes.ArgumentError`:

```
  File ""plottest.py"", line 16, in main
    plot_sixel(fig)
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/sixel.py"", line 21, in plot_sixel
    res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/sixel.py"", line 10, in _sixel_encode
    libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/libsixel/__init__.py"", line 506, in sixel_dither_initialize
    quality_mode)
ctypes.ArgumentError: argument 2: <class 'TypeError'>: wrong type
```",thanks scratching head case example work either also failing file line main fig file line file line dither data file line argument class wrong type,issue,negative,negative,neutral,neutral,negative,negative
502741473,"I am a bit at a loss then. Can you plot a simple matplotlib figure? For instance can you see something with this?
```
from fastai.script import *
from fastai.vision import *
from fastai.sixel import *

@call_parse
def main():
    
    fig, ax = plt.subplots(1,1)
    x = np.linspace(0,100)
    y = np.exp(x)
    ax.plot(x, y)
    ax.set_ylabel(""Loss"")
    ax.set_xlabel(""Learning Rate"")
    ax.set_xscale('log')
    ax.xaxis.set_major_formatter(plt.FormatStrFormatter('%.0e'))
    plot_sixel(fig)
```",bit loss plot simple figure instance see something import import import main fig ax loss learning rate fig,issue,negative,positive,neutral,neutral,positive,positive
502734648,Me too. I've also verified the `libsixel-python` install by successfully running their utility: https://github.com/saitoha/libsixel/blob/master/examples/python/converter.py,also install successfully running utility,issue,negative,positive,positive,positive,positive,positive
502731105,"Unfortunately, I had the same results running WLStty on Windows 10:
```Traceback (most recent call last):
  File ""train_mnist.py"", line 5, in <module>
    @call_parse
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/script.py"", line 40, in call_parse
    func(**args.__dict__)
  File ""train_mnist.py"", line 12, in main
    learn.recorder.plot()
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py"", line 556, in plot
    if not IN_NOTEBOOK: plot_sixel(fig)
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/sixel.py"", line 21, in plot_sixel
    res = _sixel_encode(fig.canvas.buffer_rgba(), fig.get_figwidth()* dpi, fig.get_figheight() * dpi)
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/sixel.py"", line 10, in _sixel_encode
    libsixel.sixel_dither_initialize(dither, data, w, h, libsixel.SIXEL_PIXELFORMAT_RGBA8888)
  File ""/home/bulrich/anaconda3/envs/fastai/lib/python3.7/site-packages/libsixel/__init__.py"", line 506, in sixel_dither_initialize
    quality_mode)
ctypes.ArgumentError: argument 2: <class 'TypeError'>: wrong type
```",unfortunately running recent call last file line module file line file line main file line plot fig file line file line dither data file line argument class wrong type,issue,negative,negative,negative,negative,negative,negative
502683605,"I’m using iTerm2 version 3.3.0beta12 on macOS, and haven’t noticed any issues with its sixel support so far. Happy to try whatever terminal you’re using on any OS to verify the behavior. ",version beta support far happy try whatever terminal o verify behavior,issue,positive,positive,positive,positive,positive,positive
502679212,"I have no problem with this script on my side (note that `learn.recorder.plot()` is meant to be used in conjunction with `learn.lr_find()`, not the `fit` methods). Which terminal are you using?",problem script side note meant used conjunction fit terminal,issue,negative,positive,positive,positive,positive,positive
502667887,"Yes, a classification TextDataBunch already has a training and validation sampler to put the samples in order of length (with a bit of randomness for the training set) so you can't pass your own. 

You will need to manually create your data loaders and your DataBunch in this case, and can't use the factory methods.",yes classification already training validation sampler put order length bit randomness training set ca pas need manually create data case ca use factory,issue,positive,neutral,neutral,neutral,neutral,neutral
502268397,"Sure, take the time you need!",sure take time need,issue,negative,positive,positive,positive,positive,positive
502229386,"I won't be able to work on this for a while, so I'm going to close this and re-open it later.",wo able work going close later,issue,negative,positive,positive,positive,positive,positive
502218801,"But why did you remove the very useful diagnostics information? There are many ways to mess things up and `pip` is not always going to help. 

Seeing the exact path fastai is loaded from is going to be very helpful, so I recommend you restore the diagnostics part, with the extra information you added as one possible solution.",remove useful diagnostics information many way mess pip always going help seeing exact path loaded going helpful recommend restore diagnostics part extra information added one possible solution,issue,positive,positive,positive,positive,positive,positive
502160821,Any ideas about @K0T3R  error? I got the same error when running learn.unfreeze(),error got error running,issue,negative,neutral,neutral,neutral,neutral,neutral
501820704,Don't forget to run the tests locally (with `pytest` in your cloned copy of the fastai repo) as you're breaking existing behavior. It looks like you need to also adapt the create methods for the various `TextDataBunch`,forget run locally copy breaking behavior like need also adapt create various,issue,negative,neutral,neutral,neutral,neutral,neutral
501581755,"Hey, I tried the same but got the following error..
data_class.train_dl = data_class.train_dl.new(shuffle=False, sampler=WeightedRandomSampler)
ValueError: sampler should be an instance of torch.utils.data.Sampler, but got sampler=<class 'torch.utils.data.sampler.WeightedRandomSampler'>
I thins there is a typo in the fastai's source code. 
It should accept ""torch.utils.data.sampler"" not ""torch.utils.data.Sampler""",hey tried got following error sampler instance got class typo source code accept,issue,negative,neutral,neutral,neutral,neutral,neutral
501258371,"Yes, the idea was to have people use the data block API for that, but exposing them in the higher factory methods is fine. Thanks!",yes idea people use data block higher factory fine thanks,issue,positive,positive,positive,positive,positive,positive
501178934,"Hi @attibalazs , you may try 
`learn = load_learner(Path(ROOT_PATH), 'fastai-retinanet.pkl')`
fastai will look for export.pkl by default if you do not specify file name as the 2nd parameter.",hi may try learn path look default specify file name parameter,issue,negative,neutral,neutral,neutral,neutral,neutral
501089710,"I know you don't like hanging outstanding issues, so I will close this one for now and update it if I discover something new to add.",know like hanging outstanding close one update discover something new add,issue,positive,positive,positive,positive,positive,positive
500910109,"I am sorry, I pulled to the wrong fork. Thanks for the feedback tho!",sorry wrong fork thanks feedback tho,issue,negative,negative,negative,negative,negative,negative
500863229,"I did `sudo apt install libsixel-bin libsixel-dev libsixel1` and now I don't get the exception error anymore, but still no graph. Now the error is:

> LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.

Of course I have `learn.recorder.plot()` in my code.

",apt install get exception error still graph error finder complete type see graph course code,issue,negative,positive,positive,positive,positive,positive
500843571,"Hi there, this is great work! I am closing this however, because this should be in a separate repo, not in the core fastai library. Once you have created it, please ping me with the link to it as we would love to link to if from the docs or on the forum and give it the best visibility we can since it's really great!",hi great work however separate core library please ping link would love link forum give best visibility since really great,issue,positive,positive,positive,positive,positive,positive
500589126,"We can definitely add an addendum to the documentation clarifying it doesn't work for GANs, I'll merge any PR fixing this.",definitely add addendum documentation work merge fixing,issue,negative,neutral,neutral,neutral,neutral,neutral
500588486,"The critic is a binary classifier on images. Therefore one could expect to use an interpreter to visualize gradients. In this setting, data is a collection of images with two classes.

IMO the documentation is misleading.",critic binary classifier therefore one could expect use interpreter visualize setting data collection two class documentation misleading,issue,negative,neutral,neutral,neutral,neutral,neutral
500577067,"There is no interpretation object built for GAN trainings, and no plans to add one with the command `.interpret()` as it would require a custom method to get the predictions that generate images with the generator at the same time. The whole `Interpretation`  classes are thought for labelled data and by definition, GANs aren't.

You can open a thread on the [forum](https://forums.fast.ai/) and try to build this feature with other folks interested.",interpretation object built gan add one command would require custom method get generate generator time whole interpretation class thought data definition open thread forum try build feature interested,issue,negative,positive,positive,positive,positive,positive
500413734,"Scanned through the library and it was used once, so I changed it to use the regular init.",library used use regular,issue,negative,neutral,neutral,neutral,neutral,neutral
500201456,"Thanks, makes a lot of sense. Probably it would be a good idea to check the instance type and the error message to point to the tutorial itself. That would certainly alleviate new fastai users when dealing with this type of errors which are not clear where they are coming from. Closing issue. ",thanks lot sense probably would good idea check instance type error message point tutorial would certainly alleviate new dealing type clear coming issue,issue,positive,positive,positive,positive,positive,positive
500176404,"This does work; thank you. That being said, I do think the current behavior will be unexpected to most users, making the cut feature less accessible to many. I think it would be more intuitive if the default behavior was to cut to the last _available_ layer in the truncated encoder rather than a hard-coded value.  

For anyone who finds this post looking to cut resnet models, it's as simple as using a  function like this:
```
def split_fn(m, cut):
  return (m[0][cut-1], m[1])
```
Then in the learner pass `cut=5` and `split_on = partial(split_fn, cut=5)` to cut to the first five layers of the encoder and split at the last layer.






",work thank said think current behavior unexpected making cut feature le accessible many think would intuitive default behavior cut last layer truncated rather value anyone post looking cut simple function like cut return learner pas partial cut first five split last layer,issue,negative,positive,positive,positive,positive,positive
500160631,"Note that you don't need to run the tool that updates the docs yourself, I do it every day to keep.

Thanks a lot for your PR!",note need run tool every day keep thanks lot,issue,negative,positive,positive,positive,positive,positive
500158667,"I wouldn't characterize this as a bug: you are passing a custom cut that is incompatible with the default split. You should then pass your own custom split too, with `split_on=...` in your call to `cnn_learner`, using a value like the function `_resnet_split` but with a different index (obliviously not 6).

Please reopen if this doesn't work (not tested but it should).",would characterize bug passing custom cut incompatible default split pas custom split call value like function different index obliviously please reopen work tested,issue,positive,neutral,neutral,neutral,neutral,neutral
500113858,"Check out this pull request on ReviewNB: https://app.reviewnb.com/fastai/fastai/pull/2154 

 Visit www.reviewnb.com to know how we simplify your Jupyter Notebook workflows.",check pull request visit know simplify notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
500090348,"I had a chance to look at this new argument `find_unused_parameters`. It looks like a bad naming, as it actually workarounds against the situation where some params don't participate in the loss calculation and ""brings them into the fold"" https://github.com/pytorch/pytorch/blob/master/torch/nn/parallel/distributed.py#L195

So I guess, instead of the developer hunting down some ""lost"" params, it finds a way to involve all params.

Now I'm going to look specifically at `WeightDropout` as you suggested might be the culprit.

But, regardless of the outcome, it looks like my ""fix"" is a legit workaround for a time being. 

I will post more as I gain more understanding.",chance look new argument like bad naming actually situation participate loss calculation fold guess instead developer hunting lost way involve going look specifically might culprit regardless outcome like fix legit time post gain understanding,issue,negative,negative,negative,negative,negative,negative
500080429,"By all means, please go ahead and propose a PR with this change!",please go ahead propose change,issue,negative,neutral,neutral,neutral,neutral,neutral
500080348,"This is probably some legacy code, but I'd need to double check it's not used in any subclass of ItemList before removing. Will try to do that tomorrow.",probably legacy code need double check used subclass removing try tomorrow,issue,negative,neutral,neutral,neutral,neutral,neutral
499946205,"True, name is displayed but not stored, thanks for flagging. Do you want to make a PR with your fix?",true name displayed thanks flagging want make fix,issue,positive,positive,positive,positive,positive,positive
499886108,"Makes sense. Just double-checked it wasn't used when we do things like grad cam, but it's not.",sense used like grad cam,issue,negative,neutral,neutral,neutral,neutral,neutral
499487327,"Ok,I will check it. I already run fastai code on Colab and  Colab supports fastai very well, thanks!",check already run code well thanks,issue,positive,positive,positive,positive,positive,positive
499483240,It may be linked to the hack around weight dropout but I can't be sure.,may linked hack around weight dropout ca sure,issue,negative,positive,positive,positive,positive,positive
499482811,Looks like you have some installation problem. There is a [dedicated thread](https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111/356) on the forum for this.,like installation problem thread forum,issue,negative,neutral,neutral,neutral,neutral,neutral
499457278,"OK, as per my further testing as as per this (thread)[https://stackoverflow.com/questions/50948391/whats-the-fastest-way-to-recursively-search-for-files-in-python] os.walk is currently the fastest.

Please ignore the pull request.",per testing per thread currently please ignore pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
499238340,"I'm a little bit confused on what functionality this adds compared to the [current get_files](https://github.com/fastai/fastai/blob/2df2447ea7a351933a40096aedcdaad229bcc981/fastai/data_block.py#L30), could you explain to me what's added?

Also Path.glob is way slower than os.walk for a recurse search, which is why we use the latter (difference needs a big dataset like ImageNet to be really seem but is quite important).",little bit confused functionality current could explain added also way recurse search use latter difference need big like really seem quite important,issue,negative,positive,neutral,neutral,positive,positive
498860133,"Another puzzle after further debugging, the grad of the params inside the optimizers are good at on_backward_end.

```
for param_group in self.learn.opt.param_groups:
            for p in param_group['params']:
                print(p.grad)
```

Following that I can safely conclude the issue is not that the tensors inside the opt are disconnected. To be sure, I did some sneaky dirty out of Fastai's callback spirit force-step and force-zero_grad:
```
for param_group in self.learn.opt.param_groups:
            for p in param_group['params']:
                print(p)
                print(p.grad)
                break
            break
self.learn.opt.step()
self.learn.opt.zero_grad()
for param_group in self.learn.opt.param_groups:
            for p in param_group['params']:
                print(p)
                print(p.grad)
                break
            break
```
~~And it works really fine (finally !). Now the question is why the opt.step() and opt.zero_grad() are not performed. The original code works fine pointers speaking. As a proxy I'm performing self.learn.opt.step() and self.learn.opt.zero_grad() inside the on_backward_end callback.~~

Edit 2 : there are further things happening, the step was happening right eventually. When printing all the states progress in on_step_end the actual weight is moving as intended. However, at the next on_batch_begin the weights are reinitialised like the step never happened. 

Edit 3 : it was eventually a simple issue with on_batch_end that was performing during training while it should have been done only at inference. My mistake !",another puzzle grad inside good print following safely conclude issue inside opt disconnected sure sneaky dirty spirit print print break break print print break break work really fine finally question original code work fine speaking proxy inside edit happening step happening right eventually printing progress actual weight moving intended however next like step never edit eventually simple issue training done inference mistake,issue,positive,positive,positive,positive,positive,positive
498779505,Yeah normally it just works because tensors are mutable. No idea why you get them disconnected from the optimizer here.,yeah normally work mutable idea get disconnected,issue,negative,positive,positive,positive,positive,positive
498767052,"After trying to use param_groups from self.opt, the results stays the same. Here is the code I used : 
 ```
def on_train_begin(self, **kwargs:Any)->None:
        ""Reinit the opt and reassign the actual params pointer to the opt""
        for param_group in self.learn.opt.param_groups:
            for p in param_group['params']:
                for i in range(self.actual_params.__len__()):
                    if torch.equal(self.actual_params[i], p):
                        self.actual_params[i] = p
        #new_opt = self.learn.opt.new_with_params(self.actual_params)
        #self.learn.opt.opt = new_opt.opt
```
The comments part was also tried as an on off without success. 

What's puzzling is that this way of doing with pointers doesn't disconnect the weights from the optimizer in the raw Pytorch code.",trying use stay code used self none opt reassign actual pointer opt range part also tried without success puzzling way disconnect raw code,issue,negative,positive,neutral,neutral,positive,positive
498743991,The lr is overwritten by defaults.lr or the learning rate you pass to fit.,learning rate pas fit,issue,negative,positive,positive,positive,positive,positive
498743395,"> That suggests you are using parameters that are disconnected from the optimizer. Instead of looping over self.model.modules() to get them, maybe loop on the param groups `self.opt.param_groups()` then `param_group['params']`?

Just saw it, I'll try.",disconnected instead looping get maybe loop param saw try,issue,negative,neutral,neutral,neutral,neutral,neutral
498743112,"A further debugging : I tried to apply an on_train_begin like in fastai/fp16.py to reassign the optimizer.
```
def on_train_begin(self, **kwargs:Any)->None:
        ""Reinit the opt""
        print(self.learn.opt)
        new_opt = self.learn.opt.new_with_param(self.actual_params)
        self.learn.opt.opt = new_opt.opt
```

2 weirds things are happening. First the print : 
```
OptimWrapper over SGD (
Parameter Group 0
    dampening: 0
    lr: 0.003
    momentum: 0.9
    nesterov: True
    weight_decay: 0.0005

Parameter Group 1
    dampening: 0
    lr: 0.003
    momentum: 0.9
    nesterov: True
    weight_decay: 0.0005
).
True weight decay: False
```

It seems the lr didn't take into account lr parameter of the line `opt_func = partial(optim.SGD, lr=0.1, momentum=0.9, nesterov = True)`. Second, a line later : 
```
<ipython-input-13-814cb8ecfe83> in on_train_begin(self, **kwargs)
     36         ""Reinit the opt""
     37         print(self.learn.opt)
---> 38         new_opt = self.learn.opt.new_with_param(self.actual_params)
     39         self.learn.opt.opt = new_opt.opt
     40 

TypeError: 'NoneType' object is not callable
```.",tried apply like reassign self none opt print happening first print parameter group momentum true parameter group momentum true true weight decay false take account parameter line partial true second line later self opt print object callable,issue,positive,positive,positive,positive,positive,positive
498740466,"That suggests you are using parameters that are disconnected from the optimizer. Instead of looping over self.model.modules() to get them, maybe loop on the param groups `self.opt.param_groups()` then `param_group['params']`?",disconnected instead looping get maybe loop param,issue,negative,neutral,neutral,neutral,neutral,neutral
498732704,"(sorry for the inconvenience if it's still not a good issue !)
After further debugging, it appears I have pinpointed the issue (while still not managing to solve it).

The optimizer step is not modifying the weights, thus rendering the network unable to learn. I have a modified MWE gist so has to show this issue (can be run on one GPU) : https://gist.github.com/sebastienwood/74ee9cd2013c0ce9cde2ccbc4ca949b0

The gist print detailed information on the models weights and grad, and show that they are indeed pointing to the weights and grad stored inside the callback function. It just seems that the step is not performed as the weights are not moving. I have applied the same printing information at multiple step of the callback process and the quantization to binary is working as intended. The grad are also moving on the print that is done on backward end. At one point, the grads are simply saturating to 0 themselves, yet the original weights are still here.",sorry inconvenience still good issue issue still solve step thus rendering network unable learn gist show issue run one gist print detailed information grad show indeed pointing grad inside function step moving applied printing information multiple step process quantization binary working intended grad also moving print done backward end one point simply yet original still,issue,negative,positive,neutral,neutral,positive,positive
498657401,"Ah yes, properly displaying LaTeX equations on GitHub pages requires MatJax, which is heavy and would make the docs load more slowly. We're investigating how to make it performant and only used on the needed pages.",ah yes properly latex heavy would make load slowly investigating make performant used,issue,negative,negative,negative,negative,negative,negative
498446725,You are right they're not anymore. I fixed a small bug and added the weight decay flag :) ,right fixed small bug added weight decay flag,issue,negative,positive,neutral,neutral,positive,positive
498391963,"Oh, if the docs are wrong, feel free to suggest a PR to fix them! If you pass a wd to learner, it will be passed at the creation of the optimizer, yes. ",oh wrong feel free suggest fix pas learner creation yes,issue,positive,negative,neutral,neutral,negative,negative
498385352,"I made a quick update following your comments, it may be worth to precise in the doc that true_wd has impacts outside of Adam ! :) Which makes me think : does the Learner wd parameter erase the opt_func wd parameter ? 
Eg in :
opt_func = partial(optim.SGD, lr=args.lr, momentum=args.mom, nesterov = args.nest, weight_decay=args.wd)
        learn = Learner(data, model, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy], opt_func=opt_func, callback_fns=ShowGraph, true_wd=False)

I could precise it in summary() if it's the case :) ",made quick update following may worth precise doc outside think learner parameter erase parameter partial learn learner data model accuracy could precise summary case,issue,negative,positive,positive,positive,positive,positive
498372775,Thanks for tackling this! I left a few comments for changes I think would make it a little bit better.,thanks tackling left think would make little bit better,issue,positive,positive,positive,positive,positive,positive
498371691,"This way too broad for us to work with. I'm very happy to fix a bug with a small reproducible example (that works on one GPU), but this could come from any line of your re-implementation in fastai or be a deep problem on the library. If it's the latter it needs to be fixed, but you need to make the task a little bit easier on the maintainers and try to find which part has the problem by using exact same data/model/training loop in both cases and trying to find what create the problem. 

I'd suggest moving this on the forum to get help from the community, closing the issue in the meantime.",way broad u work happy fix bug small reproducible example work one could come line deep problem library latter need fixed need make task little bit easier try find part problem exact loop trying find create problem suggest moving forum get help community issue,issue,negative,positive,neutral,neutral,positive,positive
497970793,Oh I see what you mean. Yes it's unnecessary in freeze and unfreeze.,oh see mean yes unnecessary freeze unfreeze,issue,negative,negative,negative,negative,negative,negative
497969920,But `freeze_to` does that in the last line `self.create_opt(defaults.lr)`. So how does this happen? In the `freeze` function after calling `self.freeze_to(-1)` no other code is being executed. So we are creating optimizer twice.,last line happen freeze function calling code executed twice,issue,negative,neutral,neutral,neutral,neutral,neutral
497965789,"Thanks for your PR!
I've just restyled some if statements that fit on one line (our usual style guide), used a list comprehension to compute the predictions instead of a for loop and removed unused arguments in your new predict method. Let me know if anything feels off.",thanks fit one line usual style guide used list comprehension compute instead loop removed unused new predict method let know anything,issue,positive,positive,positive,positive,positive,positive
497965425,"Yes, the optimizer needs to be created again because at creation, it only takes trainable parameters. After a freeze/unfreeze those change so it needs to be adjusted.",yes need creation trainable change need,issue,positive,neutral,neutral,neutral,neutral,neutral
497719496,"Please use the [forum](https://forums.fast.ai/) to ask question about the library, issues are for standing bugs only.",please use forum ask question library standing,issue,negative,neutral,neutral,neutral,neutral,neutral
497562620,"> Widgets don't work in colab (it's not a jupyter notebook).

Looks they work [now](https://colab.research.google.com/notebooks/widgets.ipynb).
also, `ipywidgets` are supported now. You can test run the [tutorials](https://colab.research.google.com/github/jupyter-widgets/ipywidgets/blob/master/docs/source/examples/Index.ipynb).


",work notebook work also test run,issue,negative,neutral,neutral,neutral,neutral,neutral
497554202,"No you can't run 
```
ClassificationInterpretation.from_learner(learn, data_test.train_dl)
```
as this method takes a `ds_type` for its second argument, so DatasetType.something
If you want to use a new set, do `data.test_dl = data_test.whatever_dl` then use this method with `ds_type=DatasetType.Test`

In general, please use the forum to debug code as it will benefit more people if it's there.",ca run learn method second argument want use new set use method general please use forum code benefit people,issue,negative,positive,neutral,neutral,positive,positive
497552875,"I can't replicate this issue on the ADULTS dataset as an example, only my own private dataset I am working with. But both were made the exact same way. Should I move this to a forum post to help debug where I can show the notebook?

Edit: I accidentally was using two different versions. Does not work for ADULTS either",ca replicate issue example private working made exact way move forum post help show notebook edit accidentally two different work either,issue,negative,positive,neutral,neutral,positive,positive
497551380,"When I do that for another databunch object (like you suggest making if we want it labeled) the error still pops up. This was working before I moved to the newest dev build, but perhaps I am confused on what you mean. If I generate a new databunch object like such:

```
data_test = (TabularList.from_df(test, path=nbPath, cat_names=cat_var, cont_names=cont_var,
                           procs=procs)
       .split_none()
       .label_from_df(dep_var)
       .databunch())
```

I should be able to run this, correct?

`ClassificationInterpretation.from_learner(learn, data_test.train_dl)`


This happens also if I just try to run this:
`ClassificationInterpretation.from_learner(learn, data.train_dl)`

Where data is the original databunch object",another object like suggest making want error still working dev build perhaps confused mean generate new object like test able run correct learn also try run learn data original object,issue,negative,positive,neutral,neutral,positive,positive
497547538,"It takes a ds_type, not a dataset, which is an enum with only 5 cases, so you can't have an error. If you want to use a different dataset, you can easily change your DataBunch attributes with `data.test_dl = bla`",ca error want use different easily change,issue,negative,positive,positive,positive,positive,positive
497514755,"If possible, otherwise other people won't be able to use your feature :)",possible otherwise people wo able use feature,issue,negative,positive,positive,positive,positive,positive
497514533,Oops! My apologies! Do I need to submit another PR for that fix?,need submit another fix,issue,negative,neutral,neutral,neutral,neutral,neutral
497514349,"Yup, indeed it was (always best to pull master before adding a new feature ;) )",indeed always best pull master new feature,issue,positive,positive,positive,positive,positive,positive
497512832,I believe I have an issue. Was probs replaced with preds in the most recent library? In terms of interp.preds(),believe issue recent library,issue,negative,neutral,neutral,neutral,neutral,neutral
497504186,Gotcha. Okay! I wasn't sure if a functionality like that would be important. Thanks!!!!!!,sure functionality like would important thanks,issue,positive,positive,positive,positive,positive,positive
497481419,"Thanks!
`show_all` would be a bit too long to actually show anything. If it just returns a dataframe, it would be more of a `df_with_loss` method or something of the like. Not too sure it's as useful?",thanks would bit long actually show anything would method something like sure useful,issue,positive,positive,positive,positive,positive,positive
497393189,"Really I suppose this adds ClassificationInterpretation to  tabular inherently, as it was not there originally. Also, would it be worth having a show_all value where we can view the entirety of the losses into a dataframe? Or would that be better suited for a separate show_losses",really suppose tabular inherently originally also would worth value view entirety would better separate,issue,positive,positive,positive,positive,positive,positive
497364935,"The bug fix isn't in the latest version (v1.0.52 was released before it) so you have to use an editable install. Just tested your example and it worked fine on master, without the need to pass `heatmap=False`.",bug fix latest version use install tested example worked fine master without need pas,issue,negative,positive,positive,positive,positive,positive
497360864,"Had this issue today on latest version, while I have not a cnn_learner I didn't specify the heatmap arg. It however produced an error.

```
model = models.WideResNet(num_groups=3, N=3,num_classes=100,k=6,drop_p=args.droprate)
learn = Learner(data, model, loss_func=nn.CrossEntropyLoss(), metrics=[accuracy])
learn.lr_find()
mingradlr = learn.recorder.min_grad_lr
learn.fit_one_cycle(5, mingradlr)
interp.plot_top_losses(9)
```

The error message : 
```
TypeError                                 Traceback (most recent call last)
<ipython-input-12-776eb7830b8b> in <module>
----> 1 interp.plot_top_losses(9)

~/anaconda3/lib/python3.7/site-packages/fastai/vision/learner.py in _cl_int_plot_top_losses(self, k, largest, figsize, heatmap, heatmap_thresh, return_fig)
    145             xb,_ = self.data.one_item(im, detach=False, denorm=False)
    146             m = self.learn.model.eval()
--> 147             with hook_output(m[0]) as hook_a:
    148                 with hook_output(m[0], grad= True) as hook_g:
    149                     preds = m(xb)

TypeError: 'WideResNet' object is not subscriptable
```

It can be resolved by specifing the heatmap arg to False when calling plot_top_losses.",issue today latest version specify however produced error model learn learner data model accuracy error message recent call last module self true object resolved false calling,issue,negative,positive,neutral,neutral,positive,positive
496927723,"`TabularLine.from_csv` doesn't really take `cols` as an argument (we have to accept it because other kinds of ItemList.from_csv need it), the columns for the inputs are cat_names + col_names. That's why you have this issue.",really take argument accept need issue,issue,negative,positive,positive,positive,positive,positive
496913337,"I am having a similar issue:
""ValueError: Expected input batch_size (8) to match target batch_size (1382400).""

I'm following the same procedure as presented in https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid.ipynb but in my case I'm trying to implement it using squeezenet1_1 instead of resnet34.

The only change I've made to the code is to replace
`learn = unet_learner(data, models.resnet34, metrics=metrics, wd=wd)`
with
`learn = cnn_learner(data, models.squeezenet1_1, metrics=accuracy)`

When it comes to executing `lr_find()` however, the following gets produced:

`ValueError                                Traceback (most recent call last)
<ipython-input-36-c7a9c29f9dd1> in <module>()
----> 1 learn.lr_find()
      2 learn.recorder.plot()

8 frames
/usr/local/lib/python3.6/dist-packages/fastai/train.py in lr_find(learn, start_lr, end_lr, num_it, stop_div, wd)
     30     cb = LRFinder(learn, start_lr, end_lr, num_it, stop_div)
     31     epochs = int(np.ceil(num_it/len(learn.data.train_dl)))
---> 32     learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)
     33 
     34 def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=True, clip:float=None,

/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
    197         callbacks = [cb(self) for cb in self.callback_fns + listify(defaults.extra_callback_fns)] + listify(callbacks)
    198         if defaults.extra_callbacks is not None: callbacks += defaults.extra_callbacks
--> 199         fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)
    200 
    201     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py in fit(epochs, learn, callbacks, metrics)
     99             for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):
    100                 xb, yb = cb_handler.on_batch_begin(xb, yb)
--> 101                 loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)
    102                 if cb_handler.on_batch_end(loss): break
    103 

/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py in loss_batch(model, xb, yb, loss_func, opt, cb_handler)
     28 
     29     if not loss_func: return to_detach(out), yb[0].detach()
---> 30     loss = loss_func(out, *yb)
     31 
     32     if opt is not None:

/usr/local/lib/python3.6/dist-packages/fastai/layers.py in __call__(self, input, target, **kwargs)
    265         if self.floatify: target = target.float()
    266         input = input.view(-1,input.shape[-1]) if self.is_2d else input.view(-1)
--> 267         return self.func.__call__(input, target.view(-1), **kwargs)
    268 
    269 def CrossEntropyFlat(*args, axis:int=-1, **kwargs):

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    491             result = self._slow_forward(*input, **kwargs)
    492         else:
--> 493             result = self.forward(*input, **kwargs)
    494         for hook in self._forward_hooks.values():
    495             hook_result = hook(self, input, result)

/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py in forward(self, input, target)
    940     def forward(self, input, target):
    941         return F.cross_entropy(input, target, weight=self.weight,
--> 942                                ignore_index=self.ignore_index, reduction=self.reduction)
    943 
    944 

/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py in cross_entropy(input, target, weight, size_average, ignore_index, reduce, reduction)
   2054     if size_average is not None or reduce is not None:
   2055         reduction = _Reduction.legacy_get_string(size_average, reduce)
-> 2056     return nll_loss(log_softmax(input, 1), target, weight, None, ignore_index, None, reduction)
   2057 
   2058 

/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py in nll_loss(input, target, weight, size_average, ignore_index, reduce, reduction)
   1867     if input.size(0) != target.size(0):
   1868         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'
-> 1869                          .format(input.size(0), target.size(0)))
   1870     if dim == 2:
   1871         ret = torch._C._nn.nll_loss(input, target, weight, _Reduction.get_enum(reduction), ignore_index)

ValueError: Expected input batch_size (8) to match target batch_size (1382400).`

(P.s. I'm relatively inexperienced with fastai and ML in general)

",similar issue input match target following procedure case trying implement instead change made code replace learn data learn data come however following produced recent call last module learn learn learn learner dynamic clip fit self self none fit self self none fit learn metric loss loss break model opt return loss opt none self input target target input else return input axis self input result input else result input hook hook self input result forward self input target forward self input target return input target input target weight reduce reduction none reduce none reduction reduce return input target weight none none reduction input target weight reduce reduction raise input match target dim ret input target weight reduction input match target relatively inexperienced general,issue,negative,positive,positive,positive,positive,positive
496853095,"Hello!

The version of fastai used by the notebooks depends on you and your environment. 
Since those are on a different project maybe you ran them against another version.

Anyway, thank you for the quick fix. You're right with the last paragraph :)",hello version used environment since different project maybe ran another version anyway thank quick fix right last paragraph,issue,negative,positive,positive,positive,positive,positive
496834226,"hey @pyjaime thanks for this! Functions in `learner.py` still had probs as you mentioned. I actually ran all the course-v3 with interpretation and all the tests. I would say fastai that been used in notebook might be not my edited version? But then I even added new notebooks with new features and they ran just fine. Anyway, it's hopefully fixed now.

Besides this is dev branch for a reason, it allows us to catch each other's bugs of earlier 😄 Thanks again. We are just humans after all, and it might be a good idea to add a test for `plot_top_losses` and `plot_multi_top_losses`, which are missing.",hey thanks still actually ran interpretation would say used notebook might version even added new new ran fine anyway hopefully fixed besides dev branch reason u catch thanks might good idea add test missing,issue,positive,positive,positive,positive,positive,positive
496825349,"hey @KeremTurgutlu,

I see you updated the parameter again from probs to preds. That's ok, but you didn't update the references to ClassificationInterpretation, again. 

Check https://github.com/fastai/fastai/issues/2118 and read the bug carefully. You have to edit fastai/vision/learner.py **at least** (look for *probs* in the whole project!). Don't know how you *""Tested course notebooks wherever Interpretation is used""* but you have to be more cautious.

",hey see parameter update check read bug carefully edit least look whole project know tested course wherever interpretation used cautious,issue,negative,negative,neutral,neutral,negative,negative
496820843,"hello @bwanaaa 

it's broken again because of https://github.com/fastai/fastai/pull/2121

hey @sgugger, could you reopen the issue please?",hello broken hey could reopen issue please,issue,negative,negative,negative,negative,negative,negative
496782392,"I have the same issue. I just followed the example of text classification. It hangs when I called TextLMDataBunch.from_df


import fastai
from fastai import *
from fastai.text import * 
import pandas as pd
import numpy as np
from functools import partial
import io
import os

from sklearn.datasets import fetch_20newsgroups
dataset = fetch_20newsgroups(shuffle=True, random_state=1, remove=('headers', 'footers', 'quotes'))
documents = dataset.data


df = pd.DataFrame({'label':dataset.target, 'text':dataset.data})
##Select only label 1 and 10 for classification
df = df[df['label'].isin([1,10])]
df = df.reset_index(drop = True)
df['label'].value_counts()

###Remove non-letter
df['text'] = df['text'].str.replace(""[^a-zA-Z]"", "" "")


import nltk
nltk.download('stopwords')

from nltk.corpus import stopwords 
stop_words = stopwords.words('english')



# tokenization 
tokenized_doc = df['text'].apply(lambda x: x.split())

# remove stop-words 
tokenized_doc = tokenized_doc.apply(lambda x: [item for item in x if item not in stop_words])

# de-tokenization 
detokenized_doc = [] 
for i in range(len(df)): 
    t = ' '.join(tokenized_doc[i]) 
    detokenized_doc.append(t) 

df['text'] = detokenized_doc

##Split dataset into training and validation
from sklearn.model_selection import train_test_split

# split data into training and validation set
df_trn, df_val = train_test_split(df, stratify = df['label'], test_size = 0.4, random_state = 12)


# Language model data
data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = """")

# Classifier model data
#data_clas = TextClasDataBunch.from_df(path = """", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)




",issue example text classification import import import import import import partial import io import o import select label classification drop true remove import import lambda remove lambda item item item range split training validation import split data training validation set stratify language model data path classifier model data path,issue,negative,positive,positive,positive,positive,positive
496758060,"still getting this error with  fastai==1.0.53.dev0 (the most recent fastai)

created new conda environment p37FASTAI-DEV
Installed dev with
```

git clone https://github.com/fastai/fastai
cd fastai
tools/run-after-git-clone
pip install -e "".[dev]""
```

Additional info
```text
=== Software === 
python        : 3.7.3
fastai        : 1.0.53.dev0
fastprogress  : 0.1.21
torch         : 1.1.0
nvidia driver : 418.56
torch cuda    : 9.0.176 / is available
torch cudnn   : 7501 / is enabled

=== Hardware === 
nvidia gpus   : 1
torch devices : 1
  - gpu0      : 12192MB | TITAN X (Pascal)

=== Environment === 
platform      : Linux-4.15.0-50-generic-x86_64-with-debian-buster-sid
distro        : Ubuntu 18.04 bionic
conda env     : p37FASTAI-DEV
python        : /home/stefan/miniconda3/envs/p37FASTAI-DEV/bin/python
sys.path      : /home/stefan/fastai/examples
/home/stefan/miniconda3/envs/p37FASTAI-DEV/lib/python37.zip
/home/stefan/miniconda3/envs/p37FASTAI-DEV/lib/python3.7
/home/stefan/miniconda3/envs/p37FASTAI-DEV/lib/python3.7/lib-dynload

/home/stefan/miniconda3/envs/p37FASTAI-DEV/lib/python3.7/site-packages
/home/stefan/fastai
/home/stefan/miniconda3/envs/p37FASTAI-DEV/lib/python3.7/site-packages/IPython/extensions
/home/stefan/.ipython
```

To reproduce execute dogs_cats.ipynb in examples folder of fastai directoy",still getting error dev recent new environment dev git clone pip install dev additional text python dev torch driver torch available torch hardware torch environment platform python reproduce execute folder,issue,negative,positive,positive,positive,positive,positive
496743699,"@davidwyue

your solution stalls for me at this line
```

pip install git+https://github.com/fastai/fastai.git
Collecting git+https://github.com/fastai/fastai.git
  Cloning https://github.com/fastai/fastai.git to /tmp/pip-req-build-dglludhh
  Running command git clone -q https://github.com/fastai/fastai.git /tmp/pip-req-build-dglludhh
```
and the only thing inside the /tmp/pip-req-build-dglludhh is a .git folder",solution line pip install running command git clone thing inside folder,issue,negative,neutral,neutral,neutral,neutral,neutral
496721273,Closing for the same reasons as the issue. Thanks a lot for the PR as it gave us an example on which we have built. The fork can still be accessible for anyone who wants to use this even if the PR is closed (and you can link on the forum to help people find it @bfarzin).,issue thanks lot gave u example built fork still accessible anyone use even closed link forum help people find,issue,positive,positive,positive,positive,positive,positive
496720960,"Thanks for all the discussion and great scripts in this thread.  This as all been taken into account and will be solved in the v2 we're currently developping (first dev can be seen [here](https://github.com/fastai/fastai_docs/blob/master/dev_nb/202_tokenizing.ipynb)). v1 will keep the current tokenizer, so there is little point keeping this issue open: it's known and consequently treated.",thanks discussion great thread taken account currently first dev seen keep current little point keeping issue open known consequently,issue,positive,positive,positive,positive,positive,positive
496715721,Thanks so much for this very thoughtful PR! :) We've decided we don't want to accept sponsorships for fastai at this time. ,thanks much thoughtful decided want accept time,issue,positive,positive,positive,positive,positive,positive
496715464,"Sorry we sat on this so long! I agree named ranges are the right way to do this, but for teaching I think many people will not understand what they're seeing. So I think it's best we stick with range addresses for our teaching workbooks.",sorry sat long agree right way teaching think many people understand seeing think best stick range teaching,issue,positive,positive,positive,positive,positive,positive
496714444,"I updated my branch to be consistent with fastai/master. As a result it looks like this pull request modifies a yml and jupyter notebook file. Am I doing something incorrect, or does github just not update the pull request to keep in sync with the target branch?",branch consistent result like pull request notebook file something incorrect update pull request keep sync target branch,issue,negative,positive,positive,positive,positive,positive
496711691,Great. I removed the `model.eval()` in the `predict` method. ,great removed predict method,issue,positive,positive,positive,positive,positive,positive
496695995,"Seems good, just one unnecessary model.eval() to remove and we can merge, thanks!",good one unnecessary remove merge thanks,issue,positive,positive,positive,positive,positive,positive
496604449,"Cool, thanks! Now looking at the docs I see more things to fix, will do it as soon as possible :)",cool thanks looking see fix soon possible,issue,positive,positive,positive,positive,positive,positive
496596501,"Oh, they were there. I just forgot to run the script that makes the sidebar to have it updated. Done now :)",oh forgot run script done,issue,negative,neutral,neutral,neutral,neutral,neutral
496573784,Thanks a lot! It looks like new docs_src notebooks `vision.interpret` and `text.interpret` are not visible in https://docs.fast.ai/ but other changes are reflected. What might be the reason for this? Was there any additional step that I've missed for adding new doc notebooks?,thanks lot like new visible reflected might reason additional step new doc,issue,positive,positive,positive,positive,positive,positive
496479698,"For the training loop you should use on_batch_begin and on_batch_end and control the flag train. This would also work with get_preds and predict normally, as those are the callbacks always called.",training loop use control flag train would also work predict normally always,issue,negative,positive,positive,positive,positive,positive
496452190,"Hello! 
 
>     * Can you mention the other problems that you are referring to? So that we can quickly fix them. Apart from **probs -> preds** everything should be same.

Well, it isn't a different problem... it's just that I found more references. You'll easily see those when refactoring! :)",hello mention quickly fix apart everything well different problem found easily see,issue,negative,positive,positive,positive,positive,positive
496379081,"Previously used Conda install method to install which hit the same error with current release.

Confirmed workaround working when using the pip install method from master branch in test environment:

```
sudo apt-get purge nvidia*
sudo add-apt-repository ppa:graphics-drivers
sudo apt-get update

sudo apt-get install nvidia-driver-430 -y
sudo reboot

#Install Miniconda
wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh

# Install miniconda

conda install jupyterhub
conda install notebook

pip install git+https://github.com/fastai/fastai.git

sudo apt-get install nodejs
sudo npm install -g configurable-http-proxy

jupyterhub

```",previously used install method install hit error current release confirmed working pip install method master branch test environment purge update install install install install install notebook pip install install install,issue,negative,positive,neutral,neutral,positive,positive
496347477,"How is this 
`do an editable install of master`

done? I thought in linux all files were editable. Isn't it enough to edit the files you mentioned in your patch here?

https://github.com/fastai/fastai/commit/21faa5d187b2cccf2a48315d183c2863ed2cdc50",install master done thought enough edit patch,issue,negative,neutral,neutral,neutral,neutral,neutral
496338985,"It would be for the test mode of each validation phase : I have some callbacks that would need to be called under a normal test/validation loop (ie no gradient descent). It would then be of use also at inference time.

On_batch_begin would be a good candidate callback as per your reply but then it would miss an on_batch_end to ensure I would put the FP32 weights when going out of inference/test/validation.",would test mode validation phase would need normal loop ie gradient descent would use also inference time would good candidate per reply would miss ensure would put going,issue,positive,positive,positive,positive,positive,positive
496320815,"I'm not sure what you're asking for: the callback system is designed for the training loop, so on_train_begin and on_train_end are called respectively at the beginning of the training loop and at the end for setup/clean-up.
Model is put on training mode at the beginning of each epoch just before on_epoch_begin, and set on test mode at the beginning of each validation phase.

If you're talking about inference, the callbacks aren't called in get_preds/predict, apart from on_batch_begin. ",sure system designed training loop respectively beginning training loop end model put training mode beginning epoch set test mode beginning validation phase talking inference apart,issue,positive,positive,positive,positive,positive,positive
496285341,"I will run the notebooks with all the already existing interpretation classes and also add tests for each, based on those same examples. Sorry for the trouble 😄  ",run already interpretation class also add based sorry trouble,issue,negative,negative,negative,negative,negative,negative
496284780,I have no objection to make probs -> preds as long as nothing is forgotten ;) Make sure notebook 01 runs with the change!,objection make long nothing forgotten make sure notebook change,issue,negative,positive,positive,positive,positive,positive
496283030,"Thanks for fixing that I must have forgot to change references in learner methods. 

- The reason why I changed the name from probs to preds in base `Interpretation` is that predictions might not be always probabilities for some other task. 

- Can you mention the other problems that you are referring to? So that we can quickly fix them. Apart from **probs -> preds** everything should be same.

- I strongly agree with adding tests for interpretation methods.

Thanks a lot!",thanks fixing must forgot change learner reason name base interpretation might always task mention quickly fix apart everything strongly agree interpretation thanks lot,issue,positive,positive,neutral,neutral,positive,positive
496270251,Good catch! Thanks a lot for the fix!,good catch thanks lot fix,issue,positive,positive,positive,positive,positive,positive
496186091,"Hey Kerem, 

I saw you changed the ClassificationInterpretation's **probs** parameter to **preds** (not judging that), but didn't change the /fastai/vision/learner.py reference. And I think it isn't the only one problem.

I'll write a quick fix for that (don't know if it will be accepted), and then you could do a proper refactoring with no hurry (maybe with tests). I hope that is right for you.

Thank you!",hey saw parameter change reference think one problem write quick fix know accepted could proper hurry maybe hope right thank,issue,positive,positive,positive,positive,positive,positive
496081504,I will add documentation as a next step. Thanks a lot! ,add documentation next step thanks lot,issue,negative,positive,neutral,neutral,positive,positive
496073068,"Ok, this is looking good, thanks a lot!
I don't know where that 1. came from for IoU but it seems like a bug, thanks for fixing and adding tests. Merging the progress up to know, don't forget to add documentation of your new feature :)",looking good thanks lot know came like bug thanks fixing progress know forget add documentation new feature,issue,positive,positive,positive,positive,positive,positive
496037832,"I am adding this change to `def dice()` in `metrics.py`, iou should be 1 if union is 0. Am I missing a point, or was it left without 1 on purpose? Also tests for `iou` metric seem to pass with and without this change, I am adding the test case when union = 0 as well.",change dice union missing point left without purpose also metric seem pas without change test case union well,issue,negative,negative,neutral,neutral,negative,negative
496030816,Example [notebook](https://github.com/KeremTurgutlu/experimental/blob/master/SegmentationInterpretation.ipynb) for segmentation interpret.,example notebook segmentation interpret,issue,negative,neutral,neutral,neutral,neutral,neutral
496022559,"Thanks for the quick feedback :)

Let me do these changes and also need to fix one thing with `SegmentationIntepretation`, then I can update the PR. I didn't quite understand how to monkey patch for all interpretation purposes to use just one object. For now I am keeping them as separate classes which inherit from `Interpretation` with all the other changes you suggested. 

Just realized it is indeed a really good advice to keep application interpret separate, e.g. multilabel classification interpret can be different for vision and tabular this way :)",thanks quick feedback let also need fix one thing update quite understand monkey patch interpretation use one object keeping separate class inherit interpretation indeed really good advice keep application interpret separate classification interpret different vision tabular way,issue,positive,positive,positive,positive,positive,positive
496016578,"Thanks, this looks nicely refactored! The problem I have is that we tried to keep the applications separate but this puts them together in one module. I would suggest to have:
- the base interpretation classes (Intepretation, ClassificationInterpretation...) in either an interpretation module or the train module
- then have an interpretation module in each of the application, which would import the base interpretation module and add the new stuff (segmentation, object detection for image for isntance) or monkey-patch for new methods (show_top_losses for instance). I would remove TextClassificationInterpretation and just monkey-patch ClassificationInterpretation in the text.interpretation module, so that it's all in one object which gets new functionality depending on the applications loaded.",thanks nicely problem tried keep separate together one module would suggest base interpretation class either interpretation module train module interpretation module application would import base interpretation module add new stuff segmentation object detection image new instance would remove module one object new functionality depending loaded,issue,negative,negative,neutral,neutral,negative,negative
495842976,"Yes, the mixup callback doesn't handle lists or categorical variables. You should take the code source of the Callback and adapt it to your use case.",yes handle categorical take code source adapt use case,issue,negative,neutral,neutral,neutral,neutral,neutral
495820672,I don't think mixup is meant for tabular data or any data apart from images for that matter.,think meant tabular data data apart matter,issue,negative,neutral,neutral,neutral,neutral,neutral
495768576,"Can you provide a minimal code example so that we can reproduce the issue. I've tried saving and loading locally with CPU, it worked. So there might be another issue. Maybe you should also create an issue for this for easier tracking. Thanks",provide minimal code example reproduce issue tried saving loading locally worked might another issue maybe also create issue easier thanks,issue,positive,positive,neutral,neutral,positive,positive
495602125,"When using this metric and save and load the learn object, I get a pickle error.

learn.fit_one_cycle(1,0.1,moms=(0.8,0.7))
learn.save('first')
learn.load('first)

--> 292     pickler.dump(obj)
    293 
    294     serialized_storage_keys = sorted(serialized_storages.keys())

TypeError: can't pickle weakref objects",metric save load learn object get pickle error sorted ca pickle,issue,negative,neutral,neutral,neutral,neutral,neutral
495478884,"> @jantic I have problem with the this line : [32](https://github.com/fastai/fastai/blob/c32d553d4afd32caab93db3e07a27c1048b85044/fastai/callbacks/tensorboard.py#L32) ` self.tbwriter = SummaryWriter(log_dir=str(log_dir))`
> It seems that [SummaryWriter](https://github.com/lanpa/tensorboardX/blob/7669082fb2504e5730ea8a19853de786a92bf8c7/tensorboardX/writer.py#L191)'s input for TensorboardX should be `logdir` not `log_dir`.
> It gives me `TypeError: __init__() got an unexpected keyword argument 'log_dir'` error

Facepalm.  They changed the variable name recently:

https://github.com/lanpa/tensorboardX/commit/bf8c6795779fbf225a6bbfefb5a53f9191e7440e#diff-0900f72201599ce7d24575f21ca88a85

I'll just change it to be a positional argument to make things easy and submit a pull request.  Thanks!",problem line input got unexpected argument error variable name recently change positional argument make easy submit pull request thanks,issue,negative,positive,positive,positive,positive,positive
495473917,"@jantic I have problem with the this line : [32](https://github.com/fastai/fastai/blob/c32d553d4afd32caab93db3e07a27c1048b85044/fastai/callbacks/tensorboard.py#L32) ```  self.tbwriter = SummaryWriter(log_dir=str(log_dir))```
It seems that [SummaryWriter](https://github.com/lanpa/tensorboardX/blob/7669082fb2504e5730ea8a19853de786a92bf8c7/tensorboardX/writer.py#L191)'s input for TensorboardX should be `logdir` not `log_dir`.
It gives me ```TypeError: __init__() got an unexpected keyword argument 'log_dir'``` error",problem line input got unexpected argument error,issue,negative,positive,neutral,neutral,positive,positive
495471655,Tests are failing because the fix needs to be applied to TextDataBunch to. Will do.,failing fix need applied,issue,negative,neutral,neutral,neutral,neutral,neutral
495466825,"This bug has been fixed in master. It will be in the next release. In the meantime you can either:
- do an editable install of master
or
- revert nbconvert to a version strictly before 5.5.0 (since the bug came for a change of API on their side)",bug fixed master next release either install master revert version strictly since bug came change side,issue,negative,positive,neutral,neutral,positive,positive
494800084,"My bad, this issue has already been answered [in a commit on the master](https://github.com/fastai/fastai/commit/74ff274773ef20d7611cffd08c57b1143a07058d). Instead of raising an Exception, the next version of the package will simply warn the user.",bad issue already commit master instead raising exception next version package simply warn user,issue,negative,negative,negative,negative,negative,negative
494636821,Just pushed a fix to make it optional (it grabs the use_on_y attribute if it's there but doesn't complain if it's not).,fix make optional attribute complain,issue,negative,neutral,neutral,neutral,neutral,neutral
494632409,"I believe this change has caused an issue with MixedItemList and applying transformations. Specially when working with Tabular and Image Item List together in MixedItemList.

This code below works in version 1.0.51, but in 1.0.52

```
mixed = (MixedItemList([imgList, tabList], path='', inner_df=tabList.inner_df)
            .split_by_idx(valid_idx=testSplit.index)
            .label_from_df(cols=5, label_cls=FloatList)          
            .transform(tfms=[[get_transforms()[0], []], [get_transforms()[1], []]], size=100))

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-52-48b160eaf03c> in <module>
      2            .split_by_idx(valid_idx=testSplit.index)
      3            .label_from_df(cols=5, label_cls=FloatList)
----> 4            .transform(tfms=[[get_transforms()[0], []], [get_transforms()[1], []]], size=100))

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in transform(self, tfms, **kwargs)
    491         if not tfms: tfms=(None,None)
    492         assert is_listy(tfms) and len(tfms) == 2, ""Please pass a list of two lists of transforms (train and valid).""
--> 493         self.train.transform(tfms[0], **kwargs)
    494         self.valid.transform(tfms[1], **kwargs)
    495         if self.test: self.test.transform(tfms[1], **kwargs)

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in transform(self, tfms, tfm_y, **kwargs)
    712         self.tfms,  self.tfmargs   = tfms,kwargs
    713         self.tfm_y, self.tfmargs_y = tfm_y,kwargs
--> 714         self.tfms_y = None if tfms is None else list(filter(lambda t: t.use_on_y, listify(tfms)))
    715         return self
    716 

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in <lambda>(t)
    712         self.tfms,  self.tfmargs   = tfms,kwargs
    713         self.tfm_y, self.tfmargs_y = tfm_y,kwargs
--> 714         self.tfms_y = None if tfms is None else list(filter(lambda t: t.use_on_y, listify(tfms)))
    715         return self
    716 

AttributeError: 'list' object has no attribute 'use_on_y'
```

Is there work around that I can implement? Maybe adding the 'use_on_y' attribute to the tabular transformation object? Or should I open up an issue?


",believe change issue specially working tabular image item list together code work version mixed recent call last module transform self none none assert please pas list two train valid transform self none none else list filter lambda return self lambda none none else list filter lambda return self object attribute work around implement maybe attribute tabular transformation object open issue,issue,negative,positive,neutral,neutral,positive,positive
494482466,"Using a 1.0.52 freshly installed with pip, I happen to have a similar issue when running my scripts at the command line (see below).  

I have installed `libsixel-python`, but it did not change the outcome.

I run on Windows, and so do the production servers of my company. So no native support of sixel here.

The error I face:

```python
learner = text.language_model_learner(data=data, drop_mult=drop_mult,
                                      pretrained=False,
                                      config=awd_lstm_params,
                                      arch=text.AWD_LSTM,
                                      callback_fns=text.ShowGraph)
learner.lr_find(num_it=3)
learner.recorder.plot(skip_start=0)

epoch     train_loss  valid_loss  accuracy  time
0         7.916819    #na#        00:47
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
---------------------------------------------------------------------------
Exception                                 Traceback (most recent call last)
<ipython-input-1-3180105ba161> in <module>()
     81                                       callback_fns=text.ShowGraph)
     82 learner.lr_find(num_it=3)
---> 83 learner.recorder.plot(skip_start=0)

~\AppData\Local\Continuum\anaconda3\envs\bdclcl\lib\site-packages\fastai\basic_train.py in plot(self, skip_start, skip_end, suggestion, return_fig, **kwargs)
    542             self.min_grad_lr = lrs[mg]
    543         if ifnone(return_fig, defaults.return_fig): return fig
--> 544         if not IN_NOTEBOOK: plot_sixel(fig)
    545
    546     def plot_losses(self, skip_start:int=0, skip_end:int=0, return_fig:bool=None)->Optional[plt.Figure]:

~\AppData\Local\Continuum\anaconda3\envs\bdclcl\lib\site-packages\fastai\sixel.py in plot_sixel(fig)
     14 def plot_sixel(fig=None):
     15     if not libsixel:
---> 16         raise Exception('Error: `libsixel` is needed. See https://github.com/saitoha/libsixel')
     17     if fig is None: fig = plt.gcf()
     18     fig.canvas.draw()

Exception: Error: `libsixel` is needed. See https://github.com/saitoha/libsixel
```

Any help would be mucch appreciated :)",freshly pip happen similar issue running command line see change outcome run production company native support error face python learner epoch accuracy time na finder complete type see graph exception recent call last ba module plot self suggestion return fig fig self optional fig raise exception see fig none fig exception error see help would,issue,negative,positive,neutral,neutral,positive,positive
494226833,"No, the idea is to have the get method called for all of these items, which is why there is the index into self instead of self.item: it goes through __getitem__ which in turns calls get.",idea get method index self instead go turn get,issue,negative,neutral,neutral,neutral,neutral,neutral
494014613,"That is what's needed yes, plus some metada to explain the library where to cut and split. 
We just finished developing that model. Making it usable with `cnn_learner` and providing a pretrained model is in our plans and will be in v1.1 (the ultimate plan being for it to be integrated in torchvision directly), just be a little bit more patient ;)",yes plus explain library cut split finished model making usable providing model ultimate plan directly little bit patient,issue,negative,negative,neutral,neutral,negative,negative
493822834,">As said up there, there is no pretrained model for xresnet, it's then not suitable for use with `cnn_learner` which requires a pretrained architecture.

But not all `cnn_learner`'s require pretrained architectures, correct? @mariopi27 created his with `pretrained=False`. I upgraded from fastai `1.0.50` to `1.0.52` and started seeing this error as well.

~Is this related to: https://github.com/fastai/fastai/commit/67e866623aa52b51f7e139dc2fc10a78c30b6b06~ (After looking into it more, I doubt it)

The error says:
```
TypeError: xresnet() got multiple values for argument 'expansion'
```

It appears this error occurs when you specify both a positional argument and a keyword argument: https://stackoverflow.com/questions/21764770/typeerror-got-multiple-values-for-argument

So the problem is probably related to: https://github.com/fastai/fastai/blob/9b9014b8967186dc70c65ca7dcddca1a1232d99d/fastai/vision/models/xresnet.py#L78-L92

I see that `expansion=e` is setting `expansion` explicitly, but I don't understand where the other argument would be coming from. 

Is it because `create_body` creates the model with `model = arch(pretrained)`?

The xresnet function's signature looks like:

```
def xresnet(expansion, n_layers, name, pretrained=False, **kwargs):
```

If we are calling this with `arch(pretrained)` does it try to pass `False` (or `True`) as `expansion`? Since `pretrained` isn't passed as a keyword argument, it doesn't get placed in `**kwargs` does it? (My Python knowledge is pretty limited here)

I think one easy workaround would be to rewrite `xresnet` as:

```
def xresnet(pretrained, expansion, n_layers, name, **kwargs):
  if pretrained == True:
     raise Exception(""XResNet cannot use pretrained models"") 
```

One consideration is that this will break any callers who were depending on the order of `xresnet`'s parameters.",said model suitable use architecture require correct seeing error well related looking doubt error got multiple argument error specify positional argument argument problem probably related see setting expansion explicitly understand argument would coming model model arch function signature like expansion name calling arch try pas false true expansion since argument get python knowledge pretty limited think one easy would rewrite expansion name true raise exception use one consideration break depending order,issue,negative,positive,positive,positive,positive,positive
493707741,"Yes, `_check_kwargs` wasn't passed the right transforms for y. This should be fixed now, thanks for flagging!",yes right fixed thanks flagging,issue,positive,positive,positive,positive,positive,positive
493053684,You should ask those questions on the [forum](https://forums.fast.ai/) as there'll be more people to help you there. We keep the issues in GitHub for bugs only.,ask forum people help keep,issue,negative,neutral,neutral,neutral,neutral,neutral
493053433,"This bug has been fixed in master already, it will be in the next release. In the meantime, either make a dev install or revert to v1.0.51, I think this version didn't have it.",bug fixed master already next release either make dev install revert think version,issue,negative,positive,neutral,neutral,positive,positive
493021494,"when I'm trying to use TransformerXL model, such as:
`    path = untar_data(URLs.IMDB_SAMPLE)
    data = TextLMDataBunch.from_csv(path, 'texts.csv')
    vocab_size = len(data.vocab.itos)
    transformer_model = get_language_model(TransformerXL,vocab_size)
    learn = LanguageLearner(data, transformer_model)
    learn.fit(1)`

I received the error:
 `path for imdb dataset: /home/zjk/.fastai/data/imdb_sample
epoch     train_loss  valid_loss  accuracy  time    
Traceback (most recent call last):
  File ""/home/zjk/fastai_transformerXl/LM_test.py"", line 40, in <module>
    test1()
  File ""/home/zjk/fastai_transformerXl/LM_test.py"", line 36, in test1
    learn.fit(1)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py"", line 199, in fit
    fit(epochs, self, metrics=self.metrics, callbacks=self.callbacks+callbacks)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py"", line 101, in fit
    loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py"", line 26, in loss_batch
    out = model(*xb)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/container.py"", line 92, in forward
    input = module(input)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/models/transformer.py"", line 229, in forward
    inp = layer(inp, r=pos_enc, u=self.u, v=self.v, mask=mask, mem=mem)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/models/transformer.py"", line 152, in forward
    def forward(self, x:Tensor, mask:Tensor=None, **kwargs): return self.ff(self.mhra(x, mask=mask, **kwargs))
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/nn/modules/module.py"", line 493, in __call__
    result = self.forward(*input, **kwargs)
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/models/transformer.py"", line 49, in forward
    return self.ln(x + self.drop_res(self.out(self._apply_attention(x, mask=mask, **kwargs))))
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/models/transformer.py"", line 108, in _apply_attention
    wq,wk,wv = map(lambda x:x.view(bs, x_len, self.n_heads, self.d_head), (wq,wk,wv))
  File ""/home/zjk/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/models/transformer.py"", line 108, in <lambda>
    wq,wk,wv = map(lambda x:x.view(bs, x_len, self.n_heads, self.d_head), (wq,wk,wv))
RuntimeError: shape '[64, 70, 10, 41]' is invalid for input of size 3673600`

some additional info:
fastai:1.0.52
pytorch:1.10
ubuntu 16.04",trying use model path data path learn data received error path epoch accuracy time recent call last file line module test file line test file line fit fit self file line fit loss file line model file line result input file line forward input module input file line result input file line forward layer file line result input file line forward forward self tensor mask return file line result input file line forward return file line map lambda file line lambda map lambda shape invalid input size additional,issue,negative,positive,positive,positive,positive,positive
492969424,"@rubenaranamorera I'm also trying to train a TransformerXL to classify and sequence generate, would you share you  ""TransformerXL classification model""? Thanks ",also trying train sequence generate would share classification model thanks,issue,positive,positive,positive,positive,positive,positive
492865304,"This is a random test, so it's jsut you being out of luck I think.",random test luck think,issue,negative,negative,negative,negative,negative,negative
492863649,"Looks like failed accuracy assertion:

```    def test_accuracy(learn):
        this_tests(accuracy)
>       assert accuracy(*learn.get_preds()) > 0.9
E       assert tensor(0.8941) > 0.9
E        +  where tensor(0.8941) = accuracy(*[tensor([[0.1554, 0.8446],\n        [0.3865, 0.6135],\n        [0.6020, 0.3980],\n        ...,\n        [0.5815, 0.4185],\n...0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0])])
E        +    where [tensor([[0.1554, 0.8446],\n        [0.3865, 0.6135],\n        [0.6020, 0.3980],\n        ...,\n        [0.5815, 0.4185],\n...0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0])] = <bound method Learner.get_preds of Learner(data=ImageDataBunch;\n\nTrain: LabelList (709 items)\nx: ImageList\nImage (3, 2... 1))\n  (10): ReLU(inplace)\n  (11): AdaptiveAvgPool2d(output_size=1)\n  (12): Flatten()\n)], add_time=True, silent=False)>()
E        +      where <bound method Learner.get_preds of Learner(data=ImageDataBunch;\n\nTrain: LabelList (709 items)\nx: ImageList\nImage (3, 2... 1))\n  (10): ReLU(inplace)\n  (11): AdaptiveAvgPool2d(output_size=1)\n  (12): Flatten()\n)], add_time=True, silent=False)> = Learner(data=ImageDataBunch;\n\nTrain: LabelList (709 items)\nx: ImageList\nImage (3, 28, 28),Image (3, 28, 28),Image (3, ..., 1))\n  (10): ReLU(inplace)\n  (11): AdaptiveAvgPool2d(output_size=1)\n  (12): Flatten()\n)], add_time=True, silent=False).get_preds

tests/test_vision_train.py:43: AssertionError```",like accuracy assertion learn accuracy assert accuracy assert tensor tensor accuracy tensor tensor bound method learner flatten bound method learner flatten learner image image flatten,issue,negative,neutral,neutral,neutral,neutral,neutral
492655027,I think it should be fixed now. Let me know if you encounter any problem!,think fixed let know encounter problem,issue,negative,positive,neutral,neutral,positive,positive
492452284,"> First one can be fixed easily, but the next two are way trickier since the fastai library needs to get the batch size somehow. Note that the library doesn't handle listy outputs either (unless you use a callback to reduce that to a single output).

I was able to get this working locally with dictionaries by adding a bit of hacky code to take the batch size from yb.values()[0]. Interestingly I think the issue with listy outputs is different, as fastai does get the batch size from the first element, but instead fails due to uses of *xb in functions attempting to unpack the list into arguments. Though I haven't tried patching those, so it might still hit an issue getting the batch size later.

> Are all your ys (or at least the first) with the batch size as the first dimension? Maybe we could have something that recursively tries to get the first element then takes it's first dim.

Yes, and it seems reasonable to require the batch size be the first dimension of the ys. So that recursive function to compute batch_size sounds great.

Thanks!",first one fixed easily next two way since library need get batch size somehow note library handle either unless use reduce single output able get working locally bit hacky code take batch size interestingly think issue different get batch size first element instead due unpack list though tried might still hit issue getting batch size later least first batch size first dimension maybe could something get first element first dim yes reasonable require batch size first dimension recursive function compute great thanks,issue,positive,positive,positive,positive,positive,positive
492395197,"> This PR won't initialize the decoder when tie_weights=False, 

The decoder [does get an init](https://github.com/fastai/fastai/blob/6ba17b21599a6fc441794ffd130bc31b5333b4a0/fastai/text/models/awd_lstm.py#L140). Maybe we should have a better default in there?  `xavier_normal_` ?
I agree that if it is not tied, this uniform range might not be a good idea.

>it doesn't change anything when tie_weight=True (since the decoder is tied to the encoder) so I don't see how it would change anything during training.

That is what I thought too.  However, with a test, you can see how you link the `LinearDecoder` weights to the Embedding and then you now have a layer that is `Linear`.  Once you run the Init, you get a standard deviation of the weights that = 0.02 rather than 1.  And this breaks your ability to train (I am watching accuracy here, it does not move) An example follows:

```
from fastai.text import *
path = untar_data(URLs.IMDB_SAMPLE)
data_lm = TextLMDataBunch.from_csv(path, 'texts.csv')

config = tfmer_lm_config.copy()
config['n_layers'] = 6
config['n_heads'] = 6
config['ctx_len'] = 512
config['d_model'] = 768
config['d_inner'] = 3072

print(config)

model = get_language_model(Transformer, len(data_lm.vocab.itos), config=config, drop_mult=1.0)

print(f'encoder std: {model[0].encoder.weight.std()}')

learn = LanguageLearner(data_lm, model, **{'alpha':0,'beta':0})
learn.unfreeze()
learn.fit_one_cycle(5, max_lr=8e-5, div_factor=5, pct_start=1.0)
```
```
{'ctx_len': 512, 'n_layers': 6, 'n_heads': 6, 'd_model': 768, 'd_head': 64, 'd_inner': 3072, 'resid_p': 0.1, 'attn_p': 0.1, 'ff_p': 0.1, 'embed_p': 0.1, 'output_p': 0.0, 'bias': True, 'scale': True, 'act': <Activation.GeLU: 3>, 'double_drop': False, 'tie_weights': True, 'out_bias': False, 'init': <function init_transformer at 0x7fd609839378>, 'mask': True}
encoder std: 0.0200047567486763
epoch     train_loss  valid_loss  accuracy  time    
0         7.648284    6.933128    0.083482  00:27                                                                                   
1         6.992075    6.347262    0.083482  00:27                                                                                   
2         6.521496    5.987786    0.083482  00:27                                                                                   
3         6.254437    5.888292    0.083482  00:27                                                                                   
4         6.153402    5.879700    0.083482  00:27                                                                                   
5         6.127126    5.878162    0.083482  00:27                                                                                   
6         6.114800    5.875361    0.083482  00:27                                                                                   
7         6.112779    5.869525    0.083482  00:17                                                                                   
8         6.117646    5.877021    0.083482  00:12                                                                                   
9         6.116013    5.873543    0.083482  00:12                                                                                    
Total time: 03:56
```

Change the init, you can train:
```
nn.init.normal_(model[0].encoder.weight,0,1)
print(f'encoder std: {model[0].encoder.weight.std()}')
```
```
{'ctx_len': 512, 'n_layers': 6, 'n_heads': 6, 'd_model': 768, 'd_head': 64, 'd_inner': 3072, 'resid_p': 0.1, 'attn_p': 0.1, 'ff_p': 0.1, 'embed_p': 0.1, 'output_p': 0.0, 'bias': True, 'scale': True, 'act': <Activation.GeLU: 3>, 'double_drop': False, 'tie_weights': True, 'out_bias': False, 'init': <function init_transformer at 0x7f47b8008378>, 'mask': True}
encoder std: 0.01999562233686447
encoder std: 0.9997439384460449
epoch     train_loss  valid_loss  accuracy  time    
0         95.500992   40.837852   0.022351  00:12                                                                                    
1         53.763382   27.212849   0.091622  00:12                                                                                    
2         38.949074   21.942659   0.093318  00:12                                                                                    
3         31.039608   18.837091   0.088676  00:12                                                                                    
4         26.803869   21.505276   0.045521  00:12                                                                                    
5         24.380877   15.822821   0.095938  00:12                                                                                    
6         24.476906   23.919594   0.027321  00:12                                                                                    
7         23.012466   14.401671   0.117827  00:12                                                                                    
8         22.269203   19.510082   0.044673  00:12                                                                                    
9         19.240519   13.089678   0.107426  00:13 
```
One more tweak that I think is worth it for these models, you can scale the output and get better convergence (but I don't think this generalizes for all language models, or at least I have not tested that yet.)
```
from fastai.text import *                                                                                                                     
path = untar_data(URLs.IMDB_SAMPLE)                                                                                                           
data_lm = TextLMDataBunch.from_csv(path, 'texts.csv')                                                                                         
                                                                                                                                              
config = tfmer_lm_config.copy()                                                                                                               
config['n_layers'] = 6                                                                                                                        
config['n_heads'] = 6                                                                                                                         
config['ctx_len'] = 512                                                                                                                       
config['d_model'] = 768                                                                                                                       
config['d_inner'] = 3072                                                                                                                      
                                                                                                                                              
print(config)                                                                                                                                 
model = get_language_model(Transformer, len(data_lm.vocab.itos), config=config, drop_mult=1.0)                                                
                                                                                                                                              
class tfm_decoder(nn.Module):                                                                                                                 
    def __init__(self,d_model=768,d_vocab=8842, enc:nn.Module=None):                                                                          
        super().__init__()                                                                                                                    
        self.tgt_word_prj = nn.Linear(d_model, d_vocab, bias=False)                                                                           
        nn.init.xavier_normal_(self.tgt_word_prj.weight)                                                                                      
                                                                                                                                              
        if enc: self.tgt_word_prj.weight = enc.weight                                                                                         
        self.x_logit_scale = (d_model ** -0.5)                                                                                                
                                                                                                                                              
    def forward(self,input:Tuple[Tensor,Tensor])->Tuple[Tensor,Tensor,Tensor]:                                                                
        raw_outputs,outputs = input                                                                                                           
        decoded = self.tgt_word_prj(raw_outputs[0]) * self.x_logit_scale                                                                      
        return decoded, raw_outputs, outputs                                                                                                  
                                                                                                                                              
model[1] = tfm_decoder(768, len(data_lm.vocab.itos), model[0].encoder)                                                                        
                                                                                                                                              
print(f'encoder std: {model[0].encoder.weight.std()}')                                                                                        
nn.init.normal_(model[0].encoder.weight,0,1)                                                                                                  
print(f'encoder std: {model[0].encoder.weight.std()}')                                                                                        
                                                                                                                                              
learn = LanguageLearner(data_lm, model, **{'alpha':0,'beta':0})                                                                               
learn.unfreeze()                                                                                                                              
learn.fit_one_cycle(10, max_lr=8e-5, div_factor=5, pct_start=1.0) 
```
```
{'ctx_len': 512, 'n_layers': 6, 'n_heads': 6, 'd_model': 768, 'd_head': 64, 'd_inner': 3072, 'resid_p': 0.1, 'attn_p': 0.1, 'ff_p': 0.1, 'embed_p': 0.1, 'output_p': 0.0, 'bias': True, 'scale': True, 'act': <Activation.GeLU: 3>, 'double_drop': False, 'tie_weights': True, 'out_bias': False, 'init': <function init_transformer at 0x7f24c0af1400>, 'mask': True}
encoder std: 0.020003292709589005
encoder std: 0.9999027252197266
epoch     train_loss  valid_loss  accuracy  time    
0         8.145821    7.105320    0.080833  00:12                                                                                   
1         7.323191    6.781451    0.106726  00:12                                                                                   
2         7.014435    6.603555    0.122515  00:12                                                                                   
3         6.771075    6.363043    0.143080  00:12                                                                                   
4         6.533041    6.146296    0.155923  00:13                                                                                   
5         6.338411    5.988508    0.163185  00:13                                                                                   
6         6.185056    5.884889    0.169807  00:13                                                                                   
7         6.058295    5.779028    0.174539  00:12                                                                                   
8         5.933101    5.657488    0.183780  00:12                                                                                   
9         5.818246    5.565749    0.189628  00:12 
```",wo initialize get maybe better default agree tied uniform range might good idea change anything since tied see would change anything training thought however test see link layer linear run get standard deviation rather ability train watching accuracy move example import path path print model transformer print model learn model true true false true false function true epoch accuracy time total time change train model print model true true false true false function true epoch accuracy time one tweak think worth scale output get better convergence think language least tested yet import path path print model transformer class self super forward self input tensor tensor tensor tensor tensor input return model model print model model print model learn model true true false true false function true epoch accuracy time,issue,positive,positive,positive,positive,positive,positive
492342831,"I think this init method is the one that was used by default in the article introducing Transformer and used again in TransformerXL.
This PR won't initialize the decoder when tie_weights=False, and it doesn't change anything when tie_weight=True (since the decoder is tied to the encoder) so I don't see how it would change anything during training.",think method one used default article transformer used wo initialize change anything since tied see would change anything training,issue,negative,neutral,neutral,neutral,neutral,neutral
492315595,"Thank you for sharing the details of the failure. My feeling is that pytorch needs to have a way to fall back to cpu and not fail.

An easy workaround is setting the env var `CUDA_VISIBLE_DEVICES=""""`, in which case pytorch will not try to check if you even have a gpu. I suppose that this the way that I was referring to in the previous paragraph.
",thank failure feeling need way fall back fail easy setting case try check even suppose way previous paragraph,issue,negative,negative,negative,negative,negative,negative
492304992,"```text
>>> import torch
>>> torch.cuda.is_available()
True
>>> torch.tensor(1).cuda()
C:\Users\user\Miniconda3\lib\site-packages\torch\cuda\__init__.py:118: UserWarning:
    Found GPU0 GeForce ... which is of cuda capability 3.0.
    PyTorch no longer supports this GPU because it is too old.
    The minimum cuda capability that we support is 3.5.

  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))
tensor(1, device='cuda:0')
>>> torch.tensor(1).cuda() + torch.tensor(1).cuda()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
RuntimeError: CUDA error: no kernel image is available for execution on the device
```
So PyTorch reports that CUDA is available though warns that GPU is too old, and even allows to put a tensor on a GPU, but every other operation fails. PyTorch already has this issue reported:  https://github.com/pytorch/pytorch/issues/17966.

I looked at the updated instructions. Ok, I'll try to go with custom dependencies if there is no other way.",text import torch true found capability longer old minimum capability support name major capability tensor recent call last file line module error kernel image available execution device available though old even put tensor every operation already issue try go custom way,issue,negative,positive,positive,positive,positive,positive
492237218,"First one can be fixed easily, but the next two are way trickier since the fastai library needs to get the batch size somehow. Note that the library doesn't handle listy outputs either (unless you use a callback to reduce that to a single output).

Are all your `ys` (or at least the first) with the batch size as the first dimension? Maybe we could have something that recursively tries to get the first element then takes it's first dim.",first one fixed easily next two way since library need get batch size somehow note library handle either unless use reduce single output least first batch size first dimension maybe could something get first element first dim,issue,negative,positive,positive,positive,positive,positive
492157169,Seems it was a problem related with multithreading. Making it single thread solved all issues and improved the performance,problem related making single thread performance,issue,negative,negative,neutral,neutral,negative,negative
492154337,"Is it possible to make this a soft failure or make it only generate a warning or something? There don't appear to be binaries for libsixel for Windows, in any case pip install libsixel-python won't install them, and this makes existing scripts suddenly error out when updating fastai. I'm not even using any of the sixel features, so why should it fail in the first place?",possible make soft failure make generate warning something appear case pip install wo install suddenly error even fail first place,issue,negative,negative,neutral,neutral,negative,negative
492101448,"Well that was dumb mistake on my part.  I'm going to write what I did wrong incase someone reaches this thread via Google Search:

The lesson learned is if you have any custom transformation functions that are arguments to the tokenizer, you have to bring that back into the context, because when you load the databunch it is going to look for this.  

In my case, I had a function called `pass_through` that I passed to the Tokenizer as a `pre_rule`, I have to make sure I define this function or import it in the context that I'm loading the databunch.  ",well dumb mistake part going write wrong incase someone thread via search lesson learned custom transformation bring back context load going look case function make sure define function import context loading,issue,negative,negative,neutral,neutral,negative,negative
491841201,"> There is no `self` in the signature of the function in the docs so it's weird to make a reference to it. You can add a short documentation of those functions, but you would need to move them from the section they are in: everything in there is ignored.

Thanks! it is very helpful.",self signature function weird make reference add short documentation would need move section everything thanks helpful,issue,positive,negative,neutral,neutral,negative,negative
491829165,"> it converts `item` which is a category name to an index.

Thanks, yes, this is much simpler and clear.",item category name index thanks yes much simpler clear,issue,positive,positive,positive,positive,positive,positive
491811097,Same here: there is no `c2i` in the definition of this function. Just say it converts `item` which is a category name to an index.,definition function say item category name index,issue,negative,neutral,neutral,neutral,neutral,neutral
491810526,"Only refers to the argument of the function you have: here it should be ""create the inner mapping category name to index (stored in `c2i`) from the `classes`.""
But don't reference to `self` when tehre is no `self`.",argument function create inner category name index class reference self self,issue,negative,neutral,neutral,neutral,neutral,neutral
491809593,"There is no `self` in the signature of the function in the docs so it's weird to make a reference to it. You can add a short documentation of those functions, but you would need to move them from the section they are in: everything in there is ignored.",self signature function weird make reference add short documentation would need move section everything,issue,negative,negative,negative,negative,negative,negative
491631030,"> I wouldn't document process more than to say it's internally called after the labeling to apply the processors. What you did in the other PR was enough, no need for more!
> The end user will never have to call it himself.

Thanks, it is helpful.",would document process say internally apply enough need end user never call thanks helpful,issue,negative,positive,neutral,neutral,positive,positive
491630928,"> You should just say `a` is something you can index into like a dataframe, an array or a list.

Thanks, I got it",say something index like array list thanks got,issue,positive,positive,positive,positive,positive,positive
491623067,"Made a few changes: `heatmap` will default to `True` if it detects the model is like a `cnn_learner` produced model, `False` otherwise, and if you try to use `heatmap=True` with a model that doesn't have the right characteristics, it will print a useful error message.",made default true model like produced model false otherwise try use model right print useful error message,issue,positive,positive,positive,positive,positive,positive
491622314,"Ah, posted without debugging enough on my own, sorry. In a clean notebook environment it's working. ",ah posted without enough sorry clean notebook environment working,issue,negative,negative,neutral,neutral,negative,negative
491621791,"Yes, this is even in v1.0.52. What I just added in master is to also print the minimum divided by 10 as another suggestion.",yes even added master also print minimum divided another suggestion,issue,negative,neutral,neutral,neutral,neutral,neutral
491621567,"> Since I don't have a CUDA 3.5-capable GPU, I tried to install a CPU-only build of PyTorch:

Are you saying that since you have an old GPU, pytorch tries to use it and fails to work, rather than automatically using its cpu mode? If so, this is a bug in pytorch and please consider reporting it to the pytorch team. You haven't shown what errors you get with the `pytorch` package on your GPU so I'm just guessing here.

Normally, you shouldn't need `pytorch-cpu` as the `pytorch` package works with and without GPU.

> ([Installation instructions](https://docs.fast.ai/install.html) mention `torchvision` instead of `torchvision-cpu`, but it results in both `pytorch-cpu` and `pytorch` being installed.)

You're correct, those are outdated instructions. I have just updated them: https://docs.fast.ai/install.html#cpu-build
",since tried install build saying since old use work rather automatically mode bug please consider team shown get package guessing normally need package work without installation mention instead correct outdated,issue,negative,negative,neutral,neutral,negative,negative
491621085,I didn't write the heatmap functionality and I only discovered it wasn't working on all models with your issue. Will make the default be `False`. If you want to make a PR to add a warning in the docs it will only work with a `cnn_learner` it would be much appreciated.,write functionality discovered working issue make default false want make add warning work would much,issue,negative,negative,negative,negative,negative,negative
491620939,"I think puting a functionality in Learner and expecting it to come from
cnn_learner is an issue..
Your discretion

On Sun, 12 May 2019, 22:04 Sylvain Gugger, <notifications@github.com> wrote:

> Closed #2080 <https://github.com/fastai/fastai/issues/2080>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2080#event-2335397908>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AK4B3JKW4TVIPZYCAGUIXTDPVBS3ZANCNFSM4HMKOQRQ>
> .
>
",think functionality learner come issue discretion sun may wrote closed thread reply directly view mute thread,issue,negative,neutral,neutral,neutral,neutral,neutral
491620871,How is your data created? I just type the same code on the data of lesson 1 and couldn't reproduce your bug.,data type code data lesson could reproduce bug,issue,negative,neutral,neutral,neutral,neutral,neutral
491620507,"With `heatmap=True`, the model is expected to come from `cnn_learner`, so you should create it this way: 
```
learn = cnn_learner(data, models.alexnet)
```",model come create way learn data,issue,negative,neutral,neutral,neutral,neutral,neutral
491619508,I'll close the other PR: this one does exactly what's necessary. Thanks!,close one exactly necessary thanks,issue,negative,positive,neutral,neutral,positive,positive
491619424,"I wouldn't document process more than to say it's internally called after the labeling to apply the processors. What you did in the other PR was enough, no need for more!
The end user will never have to call it himself.",would document process say internally apply enough need end user never call,issue,negative,neutral,neutral,neutral,neutral,neutral
491610420,"> If you set `suggestion=True` as an argument for `learn.recorder.plot` it will print the steepest slope. However, sometimes it is wrong if the plot is not so smooth.

Awesome, thanks @tmabraham! Is this implemented in the master branch now? I can just pull and start using it?",set argument print slope however sometimes wrong plot smooth awesome thanks master branch pull start,issue,negative,positive,positive,positive,positive,positive
491554742,"If you set `suggestion=True` as an argument for `learn.recorder.plot` it will print the steepest slope. However, sometimes it is wrong if the plot is not so smooth.",set argument print slope however sometimes wrong plot smooth,issue,negative,negative,neutral,neutral,negative,negative
491539998,"Thanks @sgugger for being open to the idea.
Yes, simply printing few suggested values would be enough for me.
I'll leave up to the experts to decide What values to print out. :)
As I go through the lessons, I'll let you know if I find other ways to improve accessibility. I suspect that mostly I would run into problems when I need to decide something looking at visualization tools like plots.
Since Jupyter is not accessible with screen reader, I just convert lesson notebookss to script using jupyter nbconvert, and run everything in headless terminal, and ignore matplotlib stuff.
Other things might not have big of impact, but learning rate seems pretty important from what I gathered so far.
Thanks again.",thanks open idea yes simply printing would enough leave decide print go let know find way improve accessibility suspect mostly would run need decide something looking visualization like since accessible screen reader convert lesson script run everything headless terminal ignore stuff might big impact learning rate pretty important far thanks,issue,positive,positive,positive,positive,positive,positive
491508164,"I hadn't thought of it that way. What would be an helpful way to suggest values then? I can think of two values to try (minimum/10 and steepest slope). Would printing them when you type learn.recorder.plot() be helpful enough?

Please let us know if there are other areas in which the library can be improved as we are committed to make it as accessible as possible.",thought way would helpful way suggest think two try slope would printing type helpful enough please let u know library make accessible possible,issue,positive,positive,positive,positive,positive,positive
491507996,"From the direction we're heading right now, there won't be this data attribute anymore in 1.1, which is why I closed the issue ;)",direction heading right wo data attribute closed issue,issue,negative,positive,neutral,neutral,positive,positive
491507911,Sorry clicked the wrong button and merged instead of closing.,sorry wrong button instead,issue,negative,negative,negative,negative,negative,negative
491507830,"You should just say `a` is something you can index into like a dataframe, an array or a list.",say something index like array list,issue,negative,neutral,neutral,neutral,neutral,neutral
491507709,"You're right that this isn't a bug but a consequence of a misuse of the library. What's annoying here is that it ""almost"" works, aside from the memory leak, everything is training just fine. Maybe a warning could be useful. Do you think it could be a good idea to add a check at the creation of a `Databunch` (or at the creation of an `ItemList`) that verifies that what is returned is a subclass of `ItemBase` and print a warning if it doesn't? I'm assuming that a lot of things will change in fastai's 1.1 so it might not be worth doing a PR right now, but I would be happy to contribute.",right bug consequence misuse library annoying almost work aside memory leak everything training fine maybe warning could useful think could good idea add check creation creation returned subclass print warning assuming lot change might worth right would happy contribute,issue,positive,positive,positive,positive,positive,positive
491459819,"This isn't a bug in the sense that when using the fastai library, you should have your datasers return `ItemBase` [docs](https://docs.fast.ai/core.html#ItemBase). As the docs say: ""All items used in fastai should subclass this.""
In it you should implement the `.data` attribute that will be your tensors as instructed in [this tutorial](https://docs.fast.ai/tutorial.itemlist.html#Creating-a-custom-ItemBase-subclass). 

The whole of this will very likely change in 1.1 in any case, which is why I'm closing this issue.",bug sense library return say used subclass implement attribute instructed tutorial whole likely change case issue,issue,negative,positive,neutral,neutral,positive,positive
491283855,"Okay thanks

On Fri, May 10, 2019, 16:03 Sylvain Gugger <notifications@github.com> wrote:

> Closed #2067 <https://github.com/fastai/fastai/issues/2067>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/2067#event-2333053657>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AIRFR7S4XIAUH6WMLZE6FQLPUVXBFANCNFSM4HMC3KTQ>
> .
>
",thanks may wrote closed thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
491280890,Please follow the template when filing an issue. There is nothing we can do with so little.,please follow template filing issue nothing little,issue,negative,negative,negative,negative,negative,negative
490994980,I think this is unrelated. However this one has merge conflicts with your previous PR so I can't merge it. Can you do a new clean PR? Thanks.,think unrelated however one merge previous ca merge new clean thanks,issue,positive,positive,positive,positive,positive,positive
490969840,"I have tried twice but have no idea why ""Build--Summary"" failed. What shall I do about it? 

thanks!",tried twice idea build summary shall thanks,issue,negative,positive,positive,positive,positive,positive
490899710,"Don't forget to run the test suite locally before pushing your PR, you were missing an import ;)
Thanks a lot!",forget run test suite locally pushing missing import thanks lot,issue,negative,neutral,neutral,neutral,neutral,neutral
490895562,"Methods that being with an _ are private and aren't supposed to be used directly, so we shouldn't document them.",private supposed used directly document,issue,negative,positive,neutral,neutral,positive,positive
490895340,Same as #2052 . This is interesting but you should label a split `ItemLists` for your example.,interesting label split example,issue,negative,positive,positive,positive,positive,positive
490894613,"I don't want to show the use of labelling `ItemList` directly in the docs as it's not standard good practice (you had to hack your way around and use the filter `from_item_lists=True`).
Can you do an example when you label a split ItemLists?",want show use directly standard good practice hack way around use filter example label split,issue,negative,positive,positive,positive,positive,positive
490893295,"I think this is linked to a bug recently fixed in master but can't be 100% sure. The bug was introduced in 1.0.52 and wasn't in 1.0.51 I believe, so double-check your model in production uses 1.0.51? Or try master and see if it persists?",think linked bug recently fixed master ca sure bug believe model production try master see,issue,negative,positive,positive,positive,positive,positive
490854981,"Change:
LanguageModelLoader
For:
LanguageModelPreLoader

Page: https://github.com/fastai/fastai/blob/master/CHANGES.md
Part: 1.0.40 (2019-01-17)
Info: LanguageModelLoader becomes LanguageModelPreLoader and is a dataset to wrap in a pytorch DataLoader",change page part becomes wrap,issue,negative,neutral,neutral,neutral,neutral,neutral
490716689,"It was, just telling you how to help more efficiently in the future ;)",telling help efficiently future,issue,positive,neutral,neutral,neutral,neutral,neutral
490713743,"Apologies! Hope it was still a net-positive help, despite having to trouble you with some code housekeeping...",hope still help despite trouble code housekeeping,issue,positive,negative,negative,negative,negative,negative
490566776,Thanks! Next time don't forget to run the tests locally before making a PR as there were imports missing to make the test you added work.,thanks next time forget run locally making missing make test added work,issue,negative,neutral,neutral,neutral,neutral,neutral
490471934,"As said up there, there is no pretrained model for xresnet, it's then not suitable for use with `cnn_learner` which requires a pretrained architecture.",said model suitable use architecture,issue,negative,positive,positive,positive,positive,positive
490438085,"It seems like there is a problem with the xresnet model in the current version.

fastai                            1.0.52    

`from fastai.vision import *`
`path = untar_data(URLs.MNIST_SAMPLE)`

`data = ImageDataBunch.from_folder(path)`

`learn = cnn_learner(data, models.xresnet34, metrics = accuracy, pretrained=False)`

`learn.fit(1)`


results in 

TypeError: xresnet() got multiple values for argument 'expansion'

`
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-18-9613abaa75d2> in <module>
      5 data = ImageDataBunch.from_folder(path)
      6 
----> 7 learn = cnn_learner(data, models.xresnet34, metrics = accuracy, pretrained=False)
      8 
      9 learn.fit(1)

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/vision/learner.py in cnn_learner(data, base_arch, cut, pretrained, lin_ftrs, ps, custom_head, split_on, bn_final, init, concat_pool, **kwargs)
     95     meta = cnn_config(base_arch)
     96     model = create_cnn_model(base_arch, data.c, cut, pretrained, lin_ftrs, ps=ps, custom_head=custom_head,
---> 97         split_on=split_on, bn_final=bn_final, concat_pool=concat_pool)
     98     learn = Learner(data, model, **kwargs)
     99     learn.split(split_on or meta['split'])

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/vision/learner.py in create_cnn_model(base_arch, nc, cut, pretrained, lin_ftrs, ps, custom_head, split_on, bn_final, concat_pool)
     81         split_on:Optional[SplitFuncOrIdxList]=None, bn_final:bool=False, concat_pool:bool=True):
     82     ""Create custom convnet architecture""
---> 83     body = create_body(base_arch, pretrained, cut)
     84     if custom_head is None:
     85         nf = num_features_model(nn.Sequential(*body.children())) * (2 if concat_pool else 1)

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/vision/learner.py in create_body(arch, pretrained, cut)
     53 def create_body(arch:Callable, pretrained:bool=True, cut:Optional[Union[int, Callable]]=None):
     54     ""Cut off the body of a typically pretrained `model` at `cut` (int) or cut the model as specified by `cut(model)` (function).""
---> 55     model = arch(pretrained)
     56     cut = ifnone(cut, cnn_config(arch)['cut'])
     57     if cut is None:
`",like problem model current version import path data path learn data metric accuracy got multiple argument recent call last module data path learn data metric accuracy data cut meta model cut learn learner data model meta cut optional create custom architecture body cut none else arch cut arch callable cut optional union callable cut body typically model cut cut model cut model function model arch cut cut arch cut none,issue,negative,negative,neutral,neutral,negative,negative
490421310,"Oh! That would be it.


On Wed., 8 May 2019, 7:29 pm sandalaphon, <notifications@github.com> wrote:

> '''no supported gpus found on this system'''
> You need a gpu.
> I got the same error trying to run this on my laptop but it ran fine on
> remote gpu.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/1646#issuecomment-490416954>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AHN356M45KTRADHXDGOYHUTPUKMRNANCNFSM4GXU2ODQ>
> .
>
",oh would may wrote found system need got error trying run ran fine remote reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
490416954,"'''no supported gpus found on this system'''
You need a gpu.
I got the same error trying to run this on my laptop but it ran fine on remote gpu.",found system need got error trying run ran fine remote,issue,negative,positive,positive,positive,positive,positive
490384739,"Thanks Sylvain. I realised that after reading some of the comments. So I
manually deleted some of the images that were causing my loss function to
blow up. That worked.

Thanks for your response. Appreciate it!



On Tue, May 7, 2019 at 8:55 PM Sylvain Gugger <notifications@github.com>
wrote:

> Widgets don't work in colab (it's not a jupyter notebook).
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/1539#issuecomment-490067238>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AL57A5QZAPAU26XILP4BW5TPUF33TANCNFSM4GTEXANA>
> .
>
",thanks reading manually causing loss function blow worked thanks response appreciate tue may wrote work notebook reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
490258780,"Please use the [forum](https://forums.fast.ai/) for questions related to the library. You'll probably find the answer to this one in an existing topic (but feel free to create one if you don't find it) and more generally, this is where the community is so you'll have a better chance at having an answer.
We only use GitHub for tracking standing bugs.",please use forum related library probably find answer one topic feel free create one find generally community better chance answer use standing,issue,positive,positive,positive,positive,positive,positive
490087415,Thanks for the warning! It's not ideal to have to test for the version of nbconvert and apply the correct version of the function but it should work for what we need.,thanks warning ideal test version apply correct version function work need,issue,positive,positive,positive,positive,positive,positive
490067591,"Thanks!
Having docs in notebooks makes it easier for anyone to interact with the docs, which trumps the fact it's a little bit harder to maintain in our opinion ;)",thanks easier anyone interact fact little bit harder maintain opinion,issue,positive,negative,neutral,neutral,negative,negative
490060555,"Can it also be changed like this?
`learner.data.batch_size = 4`

Without creating a new `DataBunch`",also like without new,issue,negative,positive,positive,positive,positive,positive
490009543,"Hi I am trying to run ImageCleaner(ds, idxs, path) command in my notebook. I am using Colab platform to run this notebook. It just keeps running forever. I don't see any output. How do I make sure it is running in Jupyter Notebook and Jupyter Lab?",hi trying run path command notebook platform run notebook running forever see output make sure running notebook lab,issue,negative,positive,positive,positive,positive,positive
489683488,"Wow, that was lightning fast. Thank you very much! ",wow lightning fast thank much,issue,positive,positive,positive,positive,positive,positive
489683151,"Fixed in [this commit](https://github.com/fastai/fastai/commit/097af1dbdd9c571a7dab89241f7c55ba8c84deac). It will be in the next release of fastai, in the meantime you can either stay with 1.0.51 or do an editable install of the library.",fixed commit next release either stay install library,issue,negative,positive,neutral,neutral,positive,positive
489682527,"Oh, that's what happens when you have x designing two different things (input and variable in the lambda function). I see the problem, will push a fix shortly, thanks for raising the issue!
",oh designing two different input variable lambda function see problem push fix shortly thanks raising issue,issue,negative,positive,neutral,neutral,positive,positive
489681682,"As of fastai 1.0.52 , I get a runtime error after loading LM data into a TransformerXL and then running lr_find(). The error seems connected to these changes described above (until and including 1.0.51 it worked fine):  

![image](https://user-images.githubusercontent.com/9308099/57238980-fc93e900-702a-11e9-8257-e37fb0e443d5.png)
![image](https://user-images.githubusercontent.com/9308099/57239034-15040380-702b-11e9-92c9-9c9da2971937.png)
![image](https://user-images.githubusercontent.com/9308099/57239058-23521f80-702b-11e9-927c-e80df9525b78.png)

I would be grateful for any suggestions on how to fix this problem. 
Best regards
Johannes Lackner
",get error loading data running error connected worked fine image image image would grateful fix problem best johannes,issue,negative,positive,positive,positive,positive,positive
489628892,"Internal for now, as we're polishing the roadmap. Once it's ready we'll publish it on the forum (hope by end of week).
Since you're holding off, I'm closing this PR and we can reopen (or start anew) once v1.1 is out and you're ready to tackle this!",internal ready publish forum hope end week since holding reopen start anew ready tackle,issue,positive,positive,positive,positive,positive,positive
489627955,"Thank you for the warning! I'll hold off.
Is there any discussion on forum etc where I can follow along 1.1 dev
goals, or is it mostly internal?


On Mon, May 6, 2019 at 8:54 AM Sylvain Gugger <notifications@github.com>
wrote:

> Hi there, fair warning, we are in the midst of completely rewriting this
> part of the library for v1.1.0. While we will still accept any PR, maybe it
> would be best to put your contribution on hold until v1.1 is out (by the
> end of this month I hope)?
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/2000#issuecomment-489609513>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAVQIKH7R3SO5Y4GLWLC3MTPUATANANCNFSM4HH7TQ3A>
> .
>
",thank warning hold discussion forum follow along dev mostly internal mon may wrote hi fair warning midst completely part library still accept maybe would best put contribution hold end month hope thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
489609513,"Hi there, fair warning, we are in the midst of completely rewriting this part of the library for v1.1.0. While we will still accept any PR, maybe it would be best to put your contribution on hold until v1.1 is out (by the end of this month I hope)?",hi fair warning midst completely part library still accept maybe would best put contribution hold end month hope,issue,positive,positive,positive,positive,positive,positive
489608806,"Thanks for pointing it out and your detailed analysis! This has been fixed recently and will be in the next release of fastai, in the meantime you can install master with
```
!pip install git+https://github.com/fastai/fastai
```",thanks pointing detailed analysis fixed recently next release install master pip install,issue,negative,positive,positive,positive,positive,positive
489604183,Those kinds of questions are best answered on the [fast.ai forums](https://forums.fast.ai/).  Have a look there and post if you still can't find a resolution.,best look post still ca find resolution,issue,positive,positive,positive,positive,positive,positive
489585656,"
OK thanks. Do you guys know how i can get the NLP sample to completed on 1050i+4GBGRAM.

With bs=16 & “torch.cuda.empty_cache()” between every save/load I am able to get to unfreezing the last 2 layer. Training with unfreezing the last 3 layers throws GPU OOM.

E.g. reduced batch size? or a simpler architecture? v2018 of the course had a bptt setting - and i see references to that in learner.py - is there a way i can set that while creating the learner?",thanks know get sample every able get unfreezing last layer training unfreezing last reduced batch size simpler architecture course setting see way set learner,issue,negative,positive,positive,positive,positive,positive
489542493,"@parthopdas none of the above has anything to do with the GPU or with model training. It has to do with preprocessing of the text, which happens on the CPU and main RAM. ",none anything model training text main ram,issue,negative,positive,positive,positive,positive,positive
489536964,"guys do you know if the above optimizations will resolve [this issue](https://forums.fast.ai/t/getting-cuda-oom-on-lesson3-imdb-notebook-with-a-bs-8/30080/15?u=partho).

So far all the notebooks (with some hyper-param tweakings) have been able to complete on my 1050i+4GBGRAM.

It will be great if the ch4 examples also can be done on my laptop. I think it makes the overall library easier to play with rather than having to get a better gpu or ssh/ts to the cloud.


",know resolve issue far able complete great also done think overall library easier play rather get better cloud,issue,positive,positive,positive,positive,positive,positive
489473085,"@edmundoandrade , can you please let me know which fastai version you are working with?

I've been trying to save and load the model with this approach using '1.0.52' but I get the following KeyError: 

KeyError: '0.encoder.weight'

and when I check the loaded model I can see that the name has changed to ""0.module.encoder.weight"" but then when I fix that in the fastai code I end up with many more issues.... 

Thanks,",please let know version working trying save load model approach get following check loaded model see name fix code end many thanks,issue,positive,positive,positive,positive,positive,positive
489465491,"> I like this one, but this including the whole of #2040 which is too long as I commented there. Can you fix it?

Thanks! it is done now.",like one whole long fix thanks done,issue,positive,positive,positive,positive,positive,positive
489429655,"Yes, it will be done by tomorrow afternoon.
(Got a little carried away on the coursework this week)

On Sun, May 5, 2019 at 9:02 AM Sylvain Gugger <notifications@github.com>
wrote:

> Hi @sutt <https://github.com/sutt> . Do you have time to follow up on
> this? Happy to apply the fix myself if you don't.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/2006#issuecomment-489424524>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAVQIKFXOF5RBVPZLOWNJI3PT3LIBANCNFSM4HI4K2QA>
> .
>
",yes done tomorrow afternoon got little carried away week sun may wrote hi time follow happy apply fix reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
489424524,Hi @sutt . Do you have time to follow up on this? Happy to apply the fix myself if you don't.,hi time follow happy apply fix,issue,positive,positive,positive,positive,positive,positive
489424391,"I like this one, but this including the whole of #2040 which is too long as I commented there. Can you fix it?",like one whole long fix,issue,negative,positive,neutral,neutral,positive,positive
489424266,"Thanks, I wouldn't show all convert modes, just two are enough to show you can do it, then link to PIL documentation relevant page (as it's their feature, not ours).",thanks would show convert two enough show link documentation relevant page feature,issue,negative,positive,positive,positive,positive,positive
489329960,"Ah, it makes the test fails because it's creating a models directory when we didn't have one and were testing for failure. I'll add something to make it read-only.",ah test directory one testing failure add something make,issue,negative,negative,negative,negative,negative,negative
489329214,"Np, we just need to put it in the right place ;)",need put right place,issue,negative,positive,positive,positive,positive,positive
489324354,"I reverted this because you made your PR on the release branch, not the master branch. Can you do it again on the master branch?",made release branch master branch master branch,issue,negative,neutral,neutral,neutral,neutral,neutral
489322298,"`collate _fn` don't take those arguments, this is a standard PyTorch collate function that is expected here, to collate samples in a batch.
It's impossible to help you without seeing the whole code, but from what I'm seeing, the bug comes from your side so I'm closing this and suggest we continue the discussion on the [forum](https://forums.fast.ai/) as issues are for bugs in the library only.",collate take standard collate function collate batch impossible help without seeing whole code seeing bug come side suggest continue discussion forum library,issue,negative,negative,negative,negative,negative,negative
489281325,"I am experiencing the same issue. I am able to create a custom ItemList, split, label, train and then create a databunch but whenever I try use `.one_batch()`  it threw the error 

> RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 36 and 47 in dimension 1 at /pytorch/aten/src/TH/generic/THTensor.cpp:711

This led me to dive further into collating the batch where I tried to return it through

```
class MixedTabularDataBunch(DataBunch):
    @classmethod
    def create(cls, train_ds, valid_ds, test_ds=None, path:PathOrStr='.', bs=64, 
               pad_idx=1, pad_first=True, no_check:bool=False, **kwargs) -> DataBunch:
        
        # calls an above collate padding method 
        collate_fn = partial(mixed_tabular_pad_collate, pad_idx=pad_idx, pad_first=pad_first)

        return super().create(train_ds, valid_ds, test_ds, path=path, bs=bs, **kwargs).

```

Then, when I try to reconstruct the databunch I got the above `'AssertionError: can only join a child process' error mentioned`, and this:

> /usr/local/lib/python3.6/dist-packages/fastai/basic_data.py:269: UserWarning: It's not possible to collate samples of your dataset together in a batch.
  warn(message)

It will not let me input any of the super() arguments `num_workers=num_workers`,  `device=device`, `tfms=tfms` or `collate_fn=collate_fn` into my classmethod return, and without specifyingthe collate_fn it doesn't seem to do it manually ",issue able create custom split label train create whenever try use threw error invalid argument size must match except dimension got dimension led dive batch tried return class create path collate padding method partial return super try reconstruct got join child process error possible collate together batch warn message let input super return without seem manually,issue,positive,positive,positive,positive,positive,positive
489136731,test_metrics is the good place for that. Thanks a lot for your PR!,good place thanks lot,issue,positive,positive,positive,positive,positive,positive
489088758,"A bit hacky but it works, and I can't think of a way to do it more nicely while still keeping the changes minimal. You can suggest a PR with this line.",bit hacky work ca think way nicely still keeping minimal suggest line,issue,negative,positive,positive,positive,positive,positive
489086863,"Yes that is why this is done [here](https://github.com/fastai/fastai/blob/fa1b0b451eb284bd782b218a0b1f29a9ecc8c46c/fastai/basic_train.py#L601). If you're using `LabelList.load_state` directly, you should feed it something you go with `LabelList.export`.",yes done directly feed something go,issue,negative,positive,neutral,neutral,positive,positive
488794366,"I have to install xterm and run
```xterm -ti vt340```
in order to see the graph.  This is great, and I hope more terminals support this in the near future. 
 Thanks for your help.",install run order see graph great hope support near future thanks help,issue,positive,positive,positive,positive,positive,positive
488789338,"Ah progress! Your terminal must support sixel, so double-check if the one you're using does or not and maybe change the application you're using.
In any case, you can always get your figure with
```
fig = learn.recorder.plot(return_fig=True)
```
then save it somewhere.",ah progress terminal must support one maybe change application case always get figure fig save somewhere,issue,positive,neutral,neutral,neutral,neutral,neutral
488787875,"I installed libsixel-python 
```
pip3 install --trusted-host pypi.org --trusted-host files.pythonhosted.org libsixel-python
```
and it no longer gives me the error, but there is no plot.",pip install longer error plot,issue,negative,neutral,neutral,neutral,neutral,neutral
488785468,"You get this error because `libsixel = try_import('libsixel')` returns None, so your fastai can't import it. I'd double check it's in your environment to make sure you have it there. If it's there and if you can't import libsixel after an install, it seems to me the problem lies in libsixel and you should file an issue toward them.",get error none ca import double check environment make sure ca import install problem file issue toward,issue,negative,positive,positive,positive,positive,positive
488782254,"I installed libsixel1:
```
daniel@099dtaualii:SuccessMetrics$ sudo aptitude install libsixel1
The following NEW packages will be installed:
  libsixel1 
0 packages upgraded, 1 newly installed, 0 to remove and 127 not upgraded.
Need to get 0 B/93.0 kB of archives. After unpacking 431 kB will be used.
Selecting previously unselected package libsixel1:amd64.
(Reading database ... 366968 files and directories currently installed.)
Preparing to unpack .../libsixel1_1.8.2-1_amd64.deb ...
Unpacking libsixel1:amd64 (1.8.2-1) ...
Processing triggers for libc-bin (2.28-0ubuntu1) ...
Setting up libsixel1:amd64 (1.8.2-1) ...
Processing triggers for libc-bin (2.28-0ubuntu1) ...
```
Then ran my code again:
```                                         
daniel@099dtaualii:SuccessMetrics$ ./tabular_fastai.py 
epoch     train_loss  valid_loss  accuracy  time    
0         0.343621    0.335889    0.850000  00:03                                                                                                      
epoch     train_loss  valid_loss  accuracy  time    
0         1.646899    #na#        00:00                                                                                                              
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
Traceback (most recent call last):
  File ""./tabular_fastai.py"", line 64, in <module>
    learn.recorder.plot_lr()
  File ""/home/daniel/.local/lib/python3.6/site-packages/fastai/basic_train.py"", line 509, in plot_lr
    if not IN_NOTEBOOK: plot_sixel(fig)
  File ""/home/daniel/.local/lib/python3.6/site-packages/fastai/sixel.py"", line 16, in plot_sixel
    raise Exception('Error: `libsixel` is needed. See https://github.com/saitoha/libsixel')
Exception: Error: `libsixel` is needed. See https://github.com/saitoha/libsixel
```
and still get the error.  What do I do now?",aptitude install following new newly remove need get used previously unselected package reading currently unpack setting ran code epoch accuracy time epoch accuracy time na finder complete type see graph recent call last file line module file line fig file line raise exception see exception error see still get error,issue,negative,positive,neutral,neutral,positive,positive
488664370,"Thanks for those, but this is the documentation of fastai. You don't need to talk about standard python methods that are well documented elsewhere.",thanks documentation need talk standard python well elsewhere,issue,positive,positive,neutral,neutral,positive,positive
488660977,Closing as this isn't a bug in the library. We can continue the discussion on the [forum](https://forums.fast.ai/) if you need more help!,bug library continue discussion forum need help,issue,negative,neutral,neutral,neutral,neutral,neutral
488660752,"As the error indicates, you need libsixel installed to display graphics in command line. See [here](https://github.com/saitoha/libsixel) to install.",error need display graphic command line see install,issue,negative,neutral,neutral,neutral,neutral,neutral
488564141,"Massive update @thousfeet! Thank you for this.

However, I'm running into an issue when I try to use it?

```
AttributeError                            Traceback (most recent call last)
<ipython-input-144-1aad6567562c> in <module>
----> 1 txt_ci.show_top_losses(5)

AttributeError: 'TextClassificationInterpretation' object has no attribute 'show_top_losses'
```

I've uninstalled fastai via pip uninstall, and reinstalled it.

Potentially I have to build from source?",massive update thank however running issue try use recent call last module object attribute uninstalled via pip potentially build source,issue,negative,neutral,neutral,neutral,neutral,neutral
488370833,"Oh, if this is a custom kind of data then you will need to write your own `ItemList`. I suggest you have a look at [this tutorial](https://docs.fast.ai/tutorial.itemlist.html) that explains how to do so.",oh custom kind data need write suggest look tutorial,issue,positive,positive,positive,positive,positive,positive
488368816,"Hi Sylvain,

Thanks for getting back to me so quickly!

I’ll have a look into ItemList subclasses, I have a lot of problems getting other classes to work for my application, but I’ve cleaned the data various different ways since then.

The .csv files I am using have 2 columns. The first is a continuous time interval of an event (foot hitting the ground) and the second is the interval since last step

I have done a lot of research into the use of deep convolutional networks for physiological classification

If there’s anything else you feel I’m missing the point to, would you let me know?

Sent from Mail<https://go.microsoft.com/fwlink/?LinkId=550986> for Windows 10

________________________________
From: Sylvain Gugger <notifications@github.com>
Sent: Wednesday, May 1, 2019 6:43:37 PM
To: fastai/fastai
Cc: Hagenov; Author
Subject: Re: [fastai/fastai] databunch creation and usage issues (#2022)


I think your problem comes from the fact you're using ItemList and not one of its subclass. ItemList is the base abstract class, it's not suitable to be used directly unless your data is basic arrays.
Since you mention a CNN, I'm guessing you have images? You should use ImageList then.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub<https://github.com/fastai/fastai/issues/2022#issuecomment-488354964>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AL62CWIEZP7MXKRIBZA24ITPTHJETANCNFSM4HJUTX2Q>.
",hi thanks getting back quickly look lot getting class work application data various different way since first continuous time interval event foot ground second interval since last step done lot research use deep convolutional physiological classification anything else feel missing point would let know sent mail sent may author subject creation usage think problem come fact one subclass base abstract class suitable used directly unless data basic since mention guessing use thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
488354964,"I think your problem comes from the fact you're using `ItemList` and not one of its subclass. `ItemList` is the base abstract class, it's not suitable to be used directly unless your data is basic arrays. 
Since you mention a CNN, I'm guessing you have images? You should use `ImageList` then.",think problem come fact one subclass base abstract class suitable used directly unless data basic since mention guessing use,issue,negative,negative,neutral,neutral,negative,negative
488354102,"Oh that's because the function was moved, so its documentation should be moved too. If you want to have a go at it and suggest a PR, go ahead!",oh function documentation want go suggest go ahead,issue,negative,neutral,neutral,neutral,neutral,neutral
487913975,"Regarding your memory concerns, take into consideration that tokenization is a *very* memory intensive operation (as just about anything in NLP is). Spacy is clever in trying to optimize as much as it can by caching all tokens, hashing them and not keeping multiple copies of strings in memory but, again, the limitations of Python's multi-process concurrency model takes its toll as the cache cannot be shared by the tokenizers. 
Even worse, memory that is garbage collected by Python [is not guaranteed to be released back](http://effbot.org/pyfaq/why-doesnt-python-release-the-memory-when-i-delete-a-large-object.htm) to the OS - the only way to have this guarantee is to have the memory-intensive operation run in a subprocess and have that terminate immediately after work, which is exactly what we try _not_ to do here.  

So here's hoping the good folks working on Swift will deliver us swiftly from the nightmare of working with cutting edge technology on cutting edge hardware using legacy tools. :-)",regarding memory take consideration memory intensive operation anything spacy clever trying optimize much keeping multiple memory python concurrency model toll cache even worse memory garbage collected python back o way guarantee operation run terminate immediately work exactly try good working swift deliver u nightmare working cutting edge technology cutting edge hardware legacy,issue,positive,negative,neutral,neutral,negative,negative
487788951,I will definitely look at your code as I create the new tokenizer and will appropriately cite on the bits I take. I'm leaving this PR open until v1.1.0 is out (at least in a branch state) so anyone can fork your code in the meantime.,definitely look code create new appropriately cite take leaving open least branch state anyone fork code,issue,positive,positive,neutral,neutral,positive,positive
487787348,"Totally ok with putting on hold.  Glad that it can be of some help to you when you come back to it (if it is.) 
Great exercise for me to work through the details.  I understand that part of the code much better than I did before.  I believe I can create my own files that reference this and use till you get to it.  

Thanks for having a look.  Let me know if I can help in any way with it when you get around to the details.  Happy to assist!
",totally hold glad help come back great exercise work understand part code much better believe create reference use till get thanks look let know help way get around happy assist,issue,positive,positive,positive,positive,positive,positive
487786376,"Thank you, Bobak, but as discussed in the [issue](https://github.com/fastai/fastai/issues/1998) I was already planning on resolving it but it can't happen until the course material is merged into master (new fastai code base), so now is a really bad timing to sort the nuances out.

I think you work would be very helpful to me to complete this task, I hope you're OK if we put this on hold and then revisit it once the new code base is created.

Until then @kliron or any person interested could use your branch if need to (it's breaking the test suite though, so at their own risks).
",thank issue already ca happen course material master new code base really bad timing sort think work would helpful complete task hope put hold revisit new code base person interested could use branch need breaking test suite though,issue,positive,negative,negative,negative,negative,negative
487764756,"I saw how yours does that with different files.  I think that something like your indexing is the right way to go, but need to think about how that fits into the rest of the framework for Fastai.
",saw different think something like indexing right way go need think rest framework,issue,negative,positive,positive,positive,positive,positive
487762269,"I don't really know what you mean by single data copy. My example reads separate files and there is no redundant copies of the same data across the worker processes. If I needed to read from a single csv file, then I would use the `skiprows=...` and `nrows...` arguments of `read_csv` in Pandas to read partitions of rows in each worker, the row ranges being supplied by the main process. Same technique would work with a plaintext file by treating it as a single-column csv and using a character that would never exist in the text as a `sep` value, eg `sep=\b`.
Memory mapping would be useful if the file was larger than your available RAM.",really know mean single data copy example separate redundant data across worker read single file would use read worker row main process technique would work file treating character would never exist text value memory would useful file available ram,issue,negative,positive,neutral,neutral,positive,positive
487759601,"Good insight about the closure.  That makes sense.   I do agree it is work and slowness.  but I also think for Fastai, it is important to keep users updated of some kind of status.  In particular if you have things running for hours out of a notebook then seeing status will be important.  I am putting out a PR as a first pass at this.  Time to run is the same, memory use is N * single data copy.  I am curious if you have an example of using a memory map to prevent copying the data to each process? (or at least that is what I think is going on, I am not sure...)",good insight closure sense agree work also think important keep kind status particular running notebook seeing status important first pas time run memory use single data copy curious example memory map prevent data process least think going sure,issue,positive,positive,positive,positive,positive,positive
487745620,"To do that you would initialize the progress bar from within the main function and pass it as an argument to the worker processes (this argument would have a default value of `None`). Either initialize it with the number of objects the reporter process will have, in which case the reported number will be falsely low, or, initialize it with the total number and call `.update(n)` where `n` is the number of workers, in which case the reported progress is inaccurate but hopefully close to the truth.
In the latter case, you need to also pass the number n as yet another argument...

As you see, this quicky becomes a steaming pile of sh*t just to report some freaking progress. Observe how all of the above would be solved by creating a closure that would capture the progress bar object and the number of workers which you could pass to a selected process to call. But this is impossible because Callables are not picklable and therefore cannot be passed as Process arguments.
",would initialize progress bar within main function pas argument worker argument would default value none either initialize number reporter process case number falsely low initialize total number call number case progress inaccurate hopefully close truth latter case need also pas number yet another argument see becomes steaming pile sh report progress observe would closure would capture progress bar object number could pas selected process call impossible therefore process,issue,positive,negative,neutral,neutral,negative,negative
487606892,"Will do, I plan to submit a pull request with branch named `rebugfix-recurse_eq `sometime soon then",plan submit pull request branch sometime soon,issue,negative,neutral,neutral,neutral,neutral,neutral
487599772,"This is a legitimate concern as we never know how this core function may be used in the future and anyone who sees it is going to assume it works, so you should go ahead and suggest your second fix.

If you want to add more tests, it's all in the tests folder of the repo.",legitimate concern never know core function may used future anyone going assume work go ahead suggest second fix want add folder,issue,negative,neutral,neutral,neutral,neutral,neutral
487595770,"Great, glad it was merged!

Infact, due to not being familiar with the fastai codebase, now I'm not sure if the fix would suffix due to the case when two lists might have different sublists, for example

```
>>> arr1 = [[1]]
>>> arr2 = [1]
>>> def is_listy(x)->bool: return isinstance(x, (tuple,list))
... 
>>> def recurse_eq(arr1, arr2):
...     if is_listy(arr1): return len(arr1) == len(arr2) and np.all([recurse_eq(x,y) for x,y in zip(arr1,arr2)])
...     else:              return np.all(np.atleast_1d(arr1 == arr2))
... 
>>> recurse_eq(arr1,arr2)
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""<stdin>"", line 2, in recurse_eq
  File ""<stdin>"", line 2, in <listcomp>
  File ""<stdin>"", line 2, in recurse_eq
TypeError: object of type 'int' has no len()
```

First, is this a legitimate concern, due to how fastai is using ItemBase(i.e preconditions or data passed in to the self.data and other.data of the `ItemBase.__eq__`)? 

Second, should the above actually be equal?(i.e. [[1]] is equal to [1])

Third, if in the future I want to contribute code with modifying tests you guys have hooked to github, how would I do that and which folder can I find that in? 

The fix for the above depending on [[1]] not being equal to [1] would be 

```
def recurse_eq(arr1, arr2):
    if is_listy(arr1): return is_listy(arr2) and len(arr1) == len(arr2) and np.all([recurse_eq(x,y) for x,y in zip(arr1,arr2)])
    else:              return np.all(np.atleast_1d(arr1 == arr2))
```
",great glad due familiar sure fix would suffix due case two might different example bool return list return zip else return recent call last file line module file line file line file line object type first legitimate concern due data second actually equal equal third future want contribute code hooked would folder find fix depending equal would return zip else return,issue,positive,positive,positive,positive,positive,positive
487591697,"Thanks for the detail.  I will see if I can get the latter one working as well.

Thinking more, I don't really want to know just when the process is finished.  That is too coarse.  What would be great would be to `queue` or follow just the first of the parallel processes.  The timing might be a bit off for full completion, but it will be close and will track just a single process.  Any thoughts on how to do that?",thanks detail see get latter one working well thinking really want know process finished coarse would great would queue follow first parallel timing might bit full completion close track single process,issue,positive,positive,positive,positive,positive,positive
487569909,This is too long for docstrings that we want short and to the point. You can add more prose in the doc notebook instead!,long want short point add prose doc notebook instead,issue,negative,negative,neutral,neutral,negative,negative
487568817,"`loss_batch` is at the heart of the training loop so we're not going to change it lightly. 
The training loop is however completely customizable with callbacks. During `on_loss_begin`, `last_output` will contain your three outputs and you can save them, return one, then add the two other parts of the loss in `on_backward_begin`. You should look at what `RNNTrainer` does (in callbacks.rnn) to get some example on how to write this.

Please switch on the forum if you need more help with this!",heart training loop going change lightly training loop however completely contain three save return one add two loss look get example write please switch forum need help,issue,positive,positive,positive,positive,positive,positive
487441440,"when a model is saved using` learn.save('model')`, then later loaded using` learn.load('model')`, the loaded learner object does not have a recorder attribute and hence I can't access training stats like `plot_losses`. Is there a way I can save the learner object such that it would save these attributes along with it? ",model saved later loaded loaded learner object recorder attribute hence ca access training like way save learner object would save along,issue,positive,neutral,neutral,neutral,neutral,neutral
487437177,Oh it seems github was smart enough to kick off the tests and good to see they all passed!,oh smart enough kick good see,issue,positive,positive,positive,positive,positive,positive
487436574,"I've made the changes and force pushed with the` git commit --amend --no-edit` to the forked repo(wasn't sure if this is the correct practice). 
Is there any way to run the tests above even though I took this approach, or should I make a whole new PR and close this one? 

The new code is now

```
def recurse_eq(arr1, arr2):
    if is_listy(arr1): return len(arr1) == len(arr2) and np.all([recurse_eq(x,y) for x,y in zip(arr1,arr2)])
    else:              return np.all(np.atleast_1d(arr1 == arr2))

```",made force git commit amend forked sure correct practice way run even though took approach make whole new close one new code return zip else return,issue,positive,positive,positive,positive,positive,positive
487426051,"This is making the tests fails, because it also happens that arr1 and arr2 are ints or floats. You should amend your PR to add the test inside the `is_listy` condition.",making also amend add test inside condition,issue,negative,neutral,neutral,neutral,neutral,neutral
487408682,"I did not update the HTML. When I committed the code, I also saw that some HTML changes were pushed. And I don't know how they occurred in the first place, as I did not make any edits in the `docs` folder.",update code also saw know first place make folder,issue,negative,positive,positive,positive,positive,positive
487398872,"Thanks. Please note you don't have to update the HTML yourself, we will do it on our side.",thanks please note update side,issue,positive,positive,positive,positive,positive,positive
487364780,"Alright! The trick was to just type:

`fastai`
`https://download.pytorch.org/whl/cpu/torch-1.0.1.post2-cp36-cp36m-linux_x86_64.whl`

in `requirements.txt`. 

I was doing a `pip freeze > requirements.txt` which does not work. I'm still 
This still is problematic for me because every time I pip install something I have to be extra careful to put it in the requirements.txt file manually.",alright trick type pip freeze work still still problematic every time pip install something extra careful put file manually,issue,negative,negative,neutral,neutral,negative,negative
487364049,"Go to command prompt and type the following command:
python -m spacy download en_core_web_lg
python -m spacy link en_core_web_lg en",go command prompt type following command python spacy python spacy link en,issue,negative,neutral,neutral,neutral,neutral,neutral
487360309,"Thanks! It's still going over the roof even with the CPU build, and I'm kinda clueless at this point. 
If I come across something I'll put it up here.

The suggestions on the fastai forums didn't help either. https://forums.fast.ai/t/hosting-a-simple-web-application/13696/19",thanks still going roof even build point come across something put help either,issue,positive,positive,positive,positive,positive,positive
487338381,"Here are the instructions that let you choose and pick what fastai dependencies you want to install:
https://docs.fast.ai/install.html#custom-dependencies

But dependencies of dependencies is beyond of fastai control.

",let choose pick want install beyond control,issue,negative,neutral,neutral,neutral,neutral,neutral
487316013,Please add a boolean flag that defaults to False to provoke this behavior: `learn.predict` is used in all the deployed apps in production as taught in the MOOC so we can't break the existing behavior.,please add flag false provoke behavior used production taught ca break behavior,issue,negative,negative,negative,negative,negative,negative
487315833,"I would default this new behavior to `False` for
1. backward compatibility
2. this adds computation in a function that has been designed to be fast. I don't know what is the impact of the new sort but for an imagenet loading, it could be substantial.",would default new behavior false backward compatibility computation function designed fast know impact new sort loading could substantial,issue,negative,positive,neutral,neutral,positive,positive
487254194,"Language model pre-training should generate two files:
1. pre-trained language model saved with learner.save (e.g. models/model.pth)
2. corresponding vocabulary information saved with databunch.vocab.save (e.g. models/itos.pkl)

To refine your language model using your classifier dataset, use the following template:
learn = language_model_learner(data_lm, AWD_LSTM, pretrained=False, drop_mult=0.7, pretrained_fnames=[""model"", ""itos""])

pretrained=False is required to avoid loading WikiText103 for AWD_LSTM architecture
pretrained_fnames will be used to load those two pre-trained resources (model.pth and itos.pkl)
",language model generate two language model saved corresponding vocabulary information saved refine language model classifier use following template learn model avoid loading architecture used load two,issue,positive,neutral,neutral,neutral,neutral,neutral
487041265,Losses and learning rates are in `learn.recorder.losses` and `learner.recorder.lrs` so you can easily build the table you want.,learning easily build table want,issue,negative,positive,positive,positive,positive,positive
487007327,"Great. Just make sure to drain the reporting queue before starting to process the data queue as `Queue.get` is a blocking call.

Observe that having a reporting queue does incur a nontrivial performance penalty. But so does `imap` and just about every other solution as synchronization primitives need to cross address spaces  - there is simply no way to do such a thing in python in a way that doesn't suck. 

For a zero performance penalty but coarse solution you could initialize the progress bar with the number of workers and then call `.update()` as you read the result from each worker from the data queue.",great make sure drain queue starting process data queue blocking call observe queue incur performance penalty every solution synchronization need cross address simply way thing python way suck zero performance penalty coarse solution could initialize progress bar number call read result worker data queue,issue,negative,positive,positive,positive,positive,positive
486993824,Thanks. I thought a second queue could work but this is all new to me. The example helps a lot.  ,thanks thought second queue could work new example lot,issue,negative,positive,positive,positive,positive,positive
486988453,"Hi! Following a little bit the issue, is there a way to output the table with loss and lr rather than the graph?",hi following little bit issue way output table loss rather graph,issue,negative,negative,neutral,neutral,negative,negative
486931643,@bfarzin ~instead of a `Queue` you could use `multiprocess.Pool.imap` to start the workers and wrap the call in `tqdm()`.~  Just use a second queue to report progress. I updated the example. ,queue could use start wrap call use second queue report progress example,issue,negative,neutral,neutral,neutral,neutral,neutral
486884506,You should look at `parallel` (or even use it directly) for updating the progressbar with multiprocess.,look parallel even use directly,issue,negative,positive,neutral,neutral,positive,positive
486828518,"I have made a lot of progress on this and want to put out a PR for the two of you to look at even though it is not fully completed yet.  I am using the pipe in the tokenizer and spawning processes as indicated. It does run a lot faster.  Much of the code is lifted from @kilron 's example.  I write to a set of files that can then be re-used for Numericalization.   I am curious if you have an opinion about the best place to put those files, right now I use `./` but clearly could put them anywhere. 

One problem I have encountered is not being able to update the `progress_bar` since this is spun out between multiple processes.  What I want to do is track a single one of the processes, but when I try to use `fastprogress` with `Process` something goes wrong (and I get no updates in a notebook and things don't seem to complete)  

Any ideas/suggestions on how to handle this case?  ",made lot progress want put two look even though fully yet pipe spawning run lot faster much code example write set curious opinion best place put right use clearly could put anywhere one problem able update since spun multiple want track single one try use process something go wrong get notebook seem complete handle case,issue,positive,positive,positive,positive,positive,positive
486682956,"That's seems good to me, and I can't think of any other places to add documentation. Thanks!",good ca think add documentation thanks,issue,positive,positive,positive,positive,positive,positive
486678474,"I wonder where I should add the documentation of this? Where ever `tfm_y` is described? 

I have put a note on `Transform` and also in the data_blocks docu wher `tfm_y` is described with the segmentation mask example.
Can you think of more sensible places? Otherwise I think this is good to go",wonder add documentation ever put note transform also segmentation mask example think sensible otherwise think good go,issue,negative,positive,positive,positive,positive,positive
486654253,Got it. Let me try that path and see what I can come up with.,got let try path see come,issue,negative,neutral,neutral,neutral,neutral,neutral
486654110,Nice job on your pull request :),nice job pull request,issue,negative,positive,positive,positive,positive,positive
486653945,"Closing this, not because I don't like the idea, but because I don't want tokenization and numericalization to be merged together. You should keep the two separate processors. Also, it might be easier to start by defining two new processors, then we can test and gradually merge them with the existing ones.",like idea want together keep two separate also might easier start two new test gradually merge,issue,positive,positive,positive,positive,positive,positive
486653872,... I will re-work my PR then. I had merged them to get it faster.  But I understand these points and can work around it.,get faster understand work around,issue,negative,neutral,neutral,neutral,neutral,neutral
486560711,"Edited the initial post with an example script. My use case is reading from files but it shouldn't be that difficult to spread row index ranges of a pandas frame or a CSV file instead of file names across N workers for example. For extremely large files, memory mapping could be used to avoid loading the same file in memory N times.

I'd also like to add that I think tokenization and numericalization are orthogonal processes and should not be merged into a single step. It is not uncommon to want to test different tokenization strategies, or to want to have raw tokens to use in other libraries, merge files from different sources, recreate/merge/split vocabularies, etc. The most common scenario is for example to want to keep capitalization say, for NER tasks, or not, say, for classification tasks. It would be ridiculous to be forced to re-process an enormous corpus just to have a different capitalization strategy. ",initial post example script use case reading difficult spread row index frame file instead file across example extremely large memory could used avoid loading file memory time also like add think orthogonal single step uncommon want test different want raw use merge different common scenario example want keep capitalization say say classification would ridiculous forced enormous corpus different capitalization strategy,issue,negative,negative,neutral,neutral,negative,negative
486532953,"I'm trying to do a better job fixing things that seem like small things to me.  Polishing things as I see them.  Also, this is the first time I've done a pull request 100% from the command line.  ",trying better job fixing seem like small see also first time done pull request command line,issue,positive,positive,positive,positive,positive,positive
486410019,"I have a PR coming that dumps to text file and then generates vocab and tokenizes.  Lowers the RAM usage as we pass through.  It is not as well described as you suggest here and could likely be improved upon.  However, it is a first step in that direction.

I know very little about multiprocessing.  I did find that using `Tokenizer.pipe` did not help me much in a simple form.  I must have been calling it wrong.  I found similar docs on the web indicating that it could speed things up significantly.  ",coming text file ram usage pas well suggest could likely upon however first step direction know little find help much simple form must calling wrong found similar web could speed significantly,issue,negative,negative,neutral,neutral,negative,negative
486258255,"Questions are better asked on the [forum](https://forums.fast.ai), issues on GitHub are for bugs only. Note that this is not the current code in the library.
This corresponds to the idea of randomized bptt introduced in [this article](https://arxiv.org/pdf/1708.02182.pdf).",better forum note current code library idea article,issue,negative,positive,positive,positive,positive,positive
486211412,"It's looking fine to me. I think `DisplayImagePoints` would be a better name since it's mostly about that.
When you refactor, in terms of style, if you could mimic the general style of the library with:
- 1-line docstrings that briefly explain the goal, with args or class/type names between backsticks
- type annotations for your function args
- less vertical space (a lot of blank lines or if statements that could fit on the same line)
that would be great!",looking fine think would better name since mostly style could mimic general style library briefly explain goal type function le vertical space lot blank could fit line would great,issue,positive,positive,positive,positive,positive,positive
485932730,"I was hoping that was the case.  I was having a tough time getting my LM flowing through the data_block API.  Once I swapped to LMTextList instead of just TextList, it all seems to be working much better.  ",case tough time getting flowing instead working much better,issue,negative,positive,neutral,neutral,positive,positive
485930781,"This is an oversight, this function should be public. Thanks for fixing!",oversight function public thanks fixing,issue,negative,positive,neutral,neutral,positive,positive
485930221,It might be corrupt data. I've run the dogs_cats example successfully. This would also explain why it is only working intermittently. ,might corrupt data run example successfully would also explain working intermittently,issue,negative,positive,positive,positive,positive,positive
485918547,"Thinking again, you said you had the issue with `data.show_batch()`. There is no multiprocessing there, we deactivate it in this function. You shouldn't have those errors there, are you sure your copy of the dataset isn't corrupted in some way?",thinking said issue deactivate function sure copy corrupted way,issue,negative,positive,positive,positive,positive,positive
485917473,num_workers=1 does not solve the issue. I will try and raise the issue with PyTorch.,solve issue try raise issue,issue,negative,neutral,neutral,neutral,neutral,neutral
485859581,"> I know how painful it can be to checkout your PR branch and add commits when not used to git :)

FYI, it's trivial to do if you use [fastai-make-pr-branch](https://docs.fast.ai/dev/git.html#helper-program). It does all the work for you.

",know painful branch add used git trivial use work,issue,negative,negative,negative,negative,negative,negative
485791119,"We don't mind quick and dirty, I know how painful it can be to checkout your PR branch and add commits when not used to git :)
Thanks!",mind quick dirty know painful branch add used git thanks,issue,negative,negative,negative,negative,negative,negative
485790737,"Thanks for the detailed analysis. The tokenization is written like this because it is enough for basic needs: you can tokenize and numericalize something as large as wikipedia with it. It's limited if you want larger corpuses, I agree. Will remember the tips about `multiprocessing.Pool` and we are already aware of `pipe` and will soon plug it in (when the current live course is finished).

The RAM issue isn't something we will address just yet. It requires a specific and very different tokenizer and numericalizer to dump things to disk as the work progresses then reading through it once to build the vocab, then another time to numericalize. I may look into this feature sometimes next month if there is sufficient demand for it.

In the meantime, leaving this issue open until I treat points 1 and 2 next week!",thanks detailed analysis written like enough basic need something large limited want agree remember already aware pipe soon plug current live course finished ram issue something address yet specific different dump disk work reading build another time may look feature sometimes next month sufficient demand leaving issue open treat next week,issue,positive,positive,neutral,neutral,positive,positive
485787204,"I forgot you have to pass `num_workers=1` when creating your `DataBunch` to remove the multiprocessing. The post you link to seems to say it's a bug in PyTorch, maybe open an issue there?",forgot pas remove post link say bug maybe open issue,issue,negative,neutral,neutral,neutral,neutral,neutral
485643594,"I've reduced defaults.cpu all the way down to 1 and the error still occurs.

I found this error in the forum. Not sure if it is related.
[https://forums.fast.ai/t/exception-ignored-in-bound-method-dataloaderiter-del-of/34081/3](https://forums.fast.ai/t/exception-ignored-in-bound-method-dataloaderiter-del-of/34081/3) ",reduced way error still found error forum sure related,issue,negative,positive,positive,positive,positive,positive
485574158,"Oh, good catch! thanks for fixing!",oh good catch thanks fixing,issue,positive,positive,positive,positive,positive,positive
485568415,"Ok, probably terrible practice, but I added commits to change these docs.  I would have rather put all of the commits into one file, but I did it with the online edit file functionality.  It seems like it worked ok, but I would figure out how to do it on my local version next time and push the changes up instead. Quick and dirty won me over this time though ",probably terrible practice added change would rather put one file edit file functionality like worked would figure local version next time push instead quick dirty time though,issue,negative,negative,negative,negative,negative,negative
485558523,"Ok, so would you change it to just be fastai.utils and remove the collect_env part then or just note that there is another way to do it?  So for each of these: 
```
docs/performance.md:python -c ""import fastai.utils; fastai.utils.check_perf()""
docs/support.md:   python -c 'import fastai.utils; fastai.utils.show_install(1)'
docs/troubleshoot.md:python -c 'import fastai.utils; fastai.utils.show_install(1)'
docs/troubleshoot.md:python -c 'import fastai.utils; fastai.utils.show_install(1)'
docs_src/utils.collect_env.ipynb:    ""from fastai.utils import *""
```",would change remove part note another way python import python python python import,issue,negative,neutral,neutral,neutral,neutral,neutral
485474452,"Just to clarify, there is only a need to edit the existing docs:
```
docs/performance.md:python -c ""import fastai.utils.collect_env; fastai.utils.collect_env.check_perf()""
docs/support.md:   python -c 'import fastai.utils.collect_env; fastai.utils.collect_env.show_install(1)'
docs/troubleshoot.md:python -c 'import fastai.utils.collect_env; fastai.utils.collect_env.show_install(1)'
docs/troubleshoot.md:python -c 'import fastai.utils.collect_env; fastai.utils.collect_env.show_install(1)'
docs_src/utils.collect_env.ipynb:    ""from fastai.utils.collect_env import *""
```
Thank you.",clarify need edit python import python python python import thank,issue,negative,neutral,neutral,neutral,neutral,neutral
485447724,This is probably due to some inconsistency in padding between the conv layer and the average pooling. I'd suggest to stick with dimensions that are a multiple of 32 on both sizes (don't have to be the same) in the meantime.,probably due inconsistency padding layer average suggest stick multiple size,issue,negative,negative,neutral,neutral,negative,negative
485414946,"Sure, I will get that added today sometime.  ",sure get added today sometime,issue,negative,positive,positive,positive,positive,positive
485408189,Would you mind adding the proper documentation in this PR @kevinbird15 ?,would mind proper documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
485408115,"You can always save the pieces you need independently if you don't want to use pickle. Your ids are in `data.train_ds.x.items` (or valid), the vocab in `data.train_ds.vocab`, the label indices in `data.train_ds.y.items` and the classes in `data.train_ds.classes`.",always save need independently want use pickle valid label index class,issue,positive,neutral,neutral,neutral,neutral,neutral
485264807,"I have no objection, but if you do that, please adjust the docs, otherwise only you will know that there is a different way.",objection please adjust otherwise know different way,issue,negative,neutral,neutral,neutral,neutral,neutral
485231977,"i am also getting the same error ....please help
![Screenshot (1359)](https://user-images.githubusercontent.com/30973767/56466996-c81f0b00-6436-11e9-90ae-b563cc9f6ca7.png)
",also getting error please help,issue,negative,neutral,neutral,neutral,neutral,neutral
485150770,"I'm working on a music generation project using transformer network, I'll share the code once the project is finished. Someone could look into it and see if they can solve it, it'll help others facing this issue as well.",working music generation project transformer network share code project finished someone could look see solve help facing issue well,issue,positive,neutral,neutral,neutral,neutral,neutral
485150412,"In any case there is nothing I can do without a reproducible script.
If you're not able to load 300Mb of texts, there is clearly a problem. I have no problem loading the whole of wikipedia.",case nothing without reproducible script able load clearly problem problem loading whole,issue,negative,positive,positive,positive,positive,positive
485150286,"You can create the vocab by loading one word at a time as well, just keep a dictionary of words with its frequency. I have 300 MB of text files and I can't load them into the memory, having 16GB of RAM. I found a workaround by tokenizing and concatenating the text myself but it shouldn't be this case.

On trying to fix the error, I found that the memory error occurs when the list of strings are converted into a numpy arrays (using the array function in core.py), if you keep them as python lists and concatenate them using the join method, you are able to load more text files.",create loading one word time well keep dictionary frequency text ca load memory ram found text case trying fix error found memory error list converted array function keep python concatenate join method able load text,issue,negative,positive,positive,positive,positive,positive
485149488,You can't create your vocab without loading the full dataset. Those aren't images and it takes a lot of texts to get out of RAM...,ca create without loading full lot get ram,issue,negative,positive,positive,positive,positive,positive
485095242,"I have hit this issue as well. The problem is that the LMDataBunch is trying to load the entire dataset and label it. This shouldn't be the case, if you are loading the entire dataset at once, what is the point of batching?",hit issue well problem trying load entire label case loading entire point,issue,negative,neutral,neutral,neutral,neutral,neutral
484914639,"It's always hard to know exactly what's going on with multiprocessing. You can try to set `defaults.cpu` to a lower value and see if the bug persists?
Not sure this is linked to what's happening in fastai, I think it's a more generic python problem.",always hard know exactly going try set lower value see bug sure linked happening think generic python problem,issue,negative,positive,positive,positive,positive,positive
484618772,"@sgugger Awesome, thanks. I'll try to add a few more tests in the next few days, but feel free to merge if it looks good to you.",awesome thanks try add next day feel free merge good,issue,positive,positive,positive,positive,positive,positive
484600786,"Actually, how do I run a test marked with slow? I tried `pytest -m slow tests/test_vision_gan.py` but it still skipped.",actually run test marked slow tried slow still,issue,negative,negative,negative,negative,negative,negative
484596798,"Yes please, it's better this way.",yes please better way,issue,positive,positive,positive,positive,positive,positive
484596338,"@sgugger Yeah I'll do that. Also, should I include the update to the test registry in my pull?",yeah also include update test registry pull,issue,negative,neutral,neutral,neutral,neutral,neutral
484572136,"Done: https://docs.fast.ai/imports.html

@sgugger, the only issue is how to keep that page up-to-date - since it was created manually very quickly it'll become outdated...

Perhaps at the very least adding this instruction:
```
python -c 'from fastai.basics import *; print(""\n"".join(vars().keys()))'
```
to see the up-to-date real import?

```
__name__
__doc__
__package__
__loader__
__spec__
__annotations__
__builtins__
AUROC
AccumulateScheduler
AdamW
AdaptiveConcatPool2d
AffineFunc
AffineMatrix
AnnealFunc
Any
AnyStr
ArgStar
AverageMetric
BCEFlat
BCEWithLogitsFlat
BatchNorm1dFlat
...
untar_data
url2name
url2path
validate
warn
warnings
weakref
weight_norm
yaml
__version__
```

Well, the following would be more precise, removing the initial symbols:

```
python -c 'a = set([*vars().keys(), ""a""]); from fastai.basics import *; print(*sorted(set(vars().keys())-a), sep=""\n"")'
```",done issue keep page since manually quickly become outdated perhaps least instruction python import print see real import validate warn well following would precise removing initial python set import print sorted set,issue,negative,positive,neutral,neutral,positive,positive
484499611,"This is looking good, thanks a lot! One thing is that we can't have a training without marking it with `@pytest.mark.slow` as we want the suite to run fast most of the times. Can you just add that decorator to the slow test?",looking good thanks lot one thing ca training without marking want suite run fast time add decorator slow test,issue,positive,positive,positive,positive,positive,positive
484497947,Looking good! I'll just put `float_or_x` in core since it belongs there more than in `csv_logger` as a follow-up. Thanks a lot,looking good put core since thanks lot,issue,positive,positive,positive,positive,positive,positive
484496883,"This is looking good and is a good idea. @stas00 can you link to it under core (last item)? I think that would be a good place for it indeed.
Thanks a lot!",looking good good idea link core last item think would good place indeed thanks lot,issue,positive,positive,positive,positive,positive,positive
484312390,Same as your last PR with `to_data`: this doesn't actually test that the tensors have been detached from their history.,last actually test detached history,issue,negative,neutral,neutral,neutral,neutral,neutral
484159365,"Oh, I see. Let me close this. I will PR the `to_detach()` test, and will fix the `to_data()` now.",oh see let close test fix,issue,negative,neutral,neutral,neutral,neutral,neutral
484147963,It's not really testing if we grab the underlying data. You should try with a list of images or text objects.,really testing grab underlying data try list text,issue,negative,positive,positive,positive,positive,positive
483987110,"Well, why would we let the choice for displaying the progress bar for the case `max_workers = 1` and enforce showing the progress bar otherwise ?",well would let choice progress bar case enforce showing progress bar otherwise,issue,positive,neutral,neutral,neutral,neutral,neutral
483761560,"I preferred when they were regrouped in one function, this is getting longer and I don't see the real gain.",preferred one function getting longer see real gain,issue,positive,positive,positive,positive,positive,positive
483760649,"Docs are wrong. Fixing it, thanks for flagging!",wrong fixing thanks flagging,issue,negative,negative,negative,negative,negative,negative
483646778,"Good idea, but that would need to be an option with a boolean flag, as people might not want to use one.",good idea would need option flag people might want use one,issue,negative,positive,positive,positive,positive,positive
483360225,"I think this is what you meant, tell me if something more needs to be added. I have changed the `to_half()` and `to_cpu()`, to make them more clear and less bloated.",think meant tell something need added make clear le bloated,issue,negative,positive,positive,positive,positive,positive
483330386,"Thanks!
It would be nice to have a on the GPU before applying the function (mark your test with the decorator `@pytest.mark.cuda` to note that it would use the GPU). And b should be a list of tensors to be fully testing the function.",thanks would nice function mark test decorator note would use list fully testing function,issue,positive,positive,positive,positive,positive,positive
483242759,Closing this since there was no news in 10 days. Please reopen with a reproducible example.,since news day please reopen reproducible example,issue,negative,neutral,neutral,neutral,neutral,neutral
483242544,"From what you're describing, it sounds like there is not enough RAM to allocate the array with all the ids when the numericalization is done. My advise would be to tokenize and numericalize by chunks and save everything in memory then only load the ids for training. I've seen code on the [forum](https://forums.fast.ai) to do that, don't remember the particular thread.

Closing this as it's not a bug in the library per se, we can continue discussing it on the forum.",like enough ram allocate array done advise would save everything memory load training seen code forum remember particular thread bug library per se continue forum,issue,positive,positive,neutral,neutral,positive,positive
483062353,"This seems to work:

`learner = tabular_learner(train_data, layers=[2000, 100], metrics=[accuracy, AUROC()])`

You need to instantiate AUROC as it's a class, not function, which wraps the metric. Which is exactly as @sgugger replied above, I wasn't paying attention :(",work learner accuracy need class function metric exactly paying attention,issue,negative,positive,positive,positive,positive,positive
483027369,Made the change so float64 is never selected and to print a warning for the user if it would not fit in FP32.,made change float never selected print warning user would fit,issue,positive,positive,positive,positive,positive,positive
482990471,"Yes there might be nans, that would be processed by the tabular processors, but eventually, the tensors will be in FP32, so I don't think it's a good idea to keep the float64.",yes might would tabular eventually think good idea keep float,issue,positive,positive,positive,positive,positive,positive
482989512,"I might be misreading, do you mean all float64 should be converted to float32? If so, I would agree. 

The only reason that a float64 wouldn't become a float32 is when the value exceeds what can be handled by a float32. ",might mean float converted float would agree reason float would become float value handled float,issue,positive,negative,negative,negative,negative,negative
482970034,"I think all floats should be converted to float64: the weights of the models are going to be tensors of float32 at the end anyway, so I don't think there is any benefit keeping them when we want to reduce memory usage.",think converted float going float end anyway think benefit keeping want reduce memory usage,issue,positive,neutral,neutral,neutral,neutral,neutral
482969603,"Like before, your second test doesn't use `to_float`...",like second test use,issue,negative,neutral,neutral,neutral,neutral,neutral
482853920,Thank you. You are totally right. It was a leftover. Let me close it and update it. ,thank totally right leftover let close update,issue,negative,positive,positive,positive,positive,positive
482845682,"Hum, your second state tests to_half, not to_float and is the same as the one before. Is it what you intended?",hum second state one intended,issue,negative,neutral,neutral,neutral,neutral,neutral
482827583,"Also added more clear tensor var names in to_half. 

I think the Pytorch documentation is wrong on the tensor.float thing.
[Here](https://pytorch.org/docs/stable/tensors.html?highlight=float#torch.Tensor.float) they state it is equivalent to torch.float32. 
But while doing the tests, it returned an error if checked against 16, and passed only with 32. ",also added clear tensor think documentation wrong thing state equivalent returned error checked,issue,negative,negative,negative,negative,negative,negative
482808531,"Sorry for the inconvenience. I have push the right commit to this branch, hence tests are all passing now.",sorry inconvenience push right commit branch hence passing,issue,negative,negative,negative,negative,negative,negative
482805357,"Thanks, but there is a slight problem: the test is failing because you didn't properly strip your notebook: you have to run the command
```
tools/run-after-git-clone
```
in the fastai cloned repo for that process to be done automatically. See more [here](https://docs.fast.ai/gen_doc_main.html). If it's easier to close this PR and open a new one with a stripped notebook, please do so!",thanks slight problem test failing properly strip notebook run command process done automatically see easier close open new one stripped notebook please,issue,negative,positive,neutral,neutral,positive,positive
482769379,"Hi there, thanks for your contribution! Can you also had some checks on the intercepted arguments? Like the batch size, or shuffle are as expected?
If not let me know and I'll merge as is.",hi thanks contribution also like batch size shuffle let know merge,issue,positive,positive,positive,positive,positive,positive
482762576,"> 
> 
> Thanks a lot. For future reference, don't forget to run
> 
> ```
> tools/run-after-git-clone
> ```
> 
> before making PRs with the docs notebooks, as it will automatically strip them of unnecessary metadata when you commit. That's why you had a failing test.

Sure, thanks!",thanks lot future reference forget run making automatically strip unnecessary commit failing test sure thanks,issue,positive,positive,neutral,neutral,positive,positive
482723675,"Thanks a lot. For future reference, don't forget to run
```
tools/run-after-git-clone
```
before making PRs with the docs notebooks, as it will automatically strip them of unnecessary metadata when you commit. That's why you had a failing test.",thanks lot future reference forget run making automatically strip unnecessary commit failing test,issue,negative,negative,neutral,neutral,negative,negative
482677393,@benvenutto I'm currently getting the same thing. Any luck?,currently getting thing luck,issue,negative,neutral,neutral,neutral,neutral,neutral
482487363,"> 
> 
> Thanks a lot. One thigns annoy me, and it's the added dependency. Can you put your table in a dataframe instead? If you look at `show_xy` in `TextList`, you'll see we show the data by putting it in a dataframe `df` then going
> 
> ```
> with pd.option_context('display.max_colwidth', -1):
>     display(HTML(df.to_html(index=False)))
> ```
> 
> It would be great if you could use the same here as it would make it consistent with the rest of the library.

I've rewrote it and discarded dependency. Now the table looks like this:
![图片](https://user-images.githubusercontent.com/16859835/56023285-21ed4a00-5d40-11e9-8e20-80b892870c80.png)
",thanks lot one annoy added dependency put table instead look see show data going display would great could use would make consistent rest library dependency table like,issue,positive,positive,positive,positive,positive,positive
482420921,"> 
> 
> Will you also please add to the docs?

Docs is added :D",also please add added,issue,negative,neutral,neutral,neutral,neutral,neutral
482112534,"This is not the same code as before. Here is the code you should use modified from the original one.
```
learn = load_learner('E:\İndirmeler', 'trained_model.pkl')

p = cv2.imread(""One_8.jpg"") # p is numpy array with shape (height,width,channels)

t = pil2tensor(p, dtype=np.uint8) # converts to numpy tensor

t = t.permute(2,0,1) # Move num_channels as first dimension

t = t.float()/255. #Convert to float

im = Image(t) # Convert to fastAi Image - this class has ""apply_tfms""

learn.predict(im)
```",code code use original one learn array shape height width tensor move first dimension convert float image convert image class,issue,negative,positive,positive,positive,positive,positive
482111210,"```
p = cv2.imread(""One_8.jpg"") # p is numpy array with shape (height,width,channels)

t = pil2tensor(p, dtype=np.float32 ) # converts to numpy tensor

im = Image(t) # Convert to fastAi Image - this class has ""apply_tfms""

```

Where should ı change ?",array shape height width tensor image convert image class change,issue,negative,neutral,neutral,neutral,neutral,neutral
482107649,"Oh ok, then like I said: add `.float()/255.` after the permute and you should be fine.",oh like said add permute fine,issue,positive,positive,positive,positive,positive,positive
482107179,I am loading my test image like that because ı have to capturing frame on real time system with opencv. So ı have to convert it  . I think.,loading test image like frame real time system convert think,issue,negative,positive,positive,positive,positive,positive
482104908,"Thanks a lot. One thigns annoy me, and it's the added dependency. Can you put your table in a dataframe instead? If you look at `show_xy` in `TextList`, you'll see we show the data by putting it in a dataframe `df` then going
```
with pd.option_context('display.max_colwidth', -1):
    display(HTML(df.to_html(index=False)))
```
It would be great if you could use the same here as it would make it consistent with the rest of the library.",thanks lot one annoy added dependency put table instead look see show data going display would great could use would make consistent rest library,issue,positive,positive,positive,positive,positive,positive
482103650,"You should load images with `open_image` to make your life easier, but if you want to do the process manually, remember to convert to float and divide by 255. before passing your tensor to `Image`.",load make life easier want process manually remember convert float divide passing tensor image,issue,negative,neutral,neutral,neutral,neutral,neutral
481936896,"Yeah, I think that was the problem. I did run the test locally, but with pytest and a keyword, and did not do a general make test. ",yeah think problem run test locally general make test,issue,negative,positive,neutral,neutral,positive,positive
481735358,Thanks! Will look at this size 1 bug when I have time.,thanks look size bug time,issue,negative,positive,positive,positive,positive,positive
481734917,"This is now fixed in master, thanks for flagging!",fixed master thanks flagging,issue,negative,positive,positive,positive,positive,positive
481683947,"Those questions are best asked (and maybe already answered!) on the [forum](https://forums.fast.ai/). In this case, you're mixing inputs and outputs: the output of the model is a float so the loss function is simply the mean squared error.",best maybe already forum case output model float loss function simply mean squared error,issue,negative,positive,positive,positive,positive,positive
481683155,"Like I said on #1951, this is for speed reasons. We won't change it without evidence that the new way is faster.",like said speed wo change without evidence new way faster,issue,negative,positive,positive,positive,positive,positive
481567554,"So there are two options as ConvLearner doesnt work now 
Replace ConvLearner by 
1. create_cnn 
2. cnn_learner - [link](https://docs.fast.ai/vision.learner.html#cnn_learner)",two doesnt work replace link,issue,negative,neutral,neutral,neutral,neutral,neutral
481455275,"I agree, example was too long.  I updated with the classic ""Zombiegeddon"" :)",agree example long classic,issue,negative,positive,neutral,neutral,positive,positive
481445465,"This is a really long example, which I don't really mind for the text, but for the interesic attention, it makes for a very long tensor. Can you adjust for something a little bit shorter? Thanks a lot!",really long example really mind text attention long tensor adjust something little bit shorter thanks lot,issue,negative,positive,neutral,neutral,positive,positive
481334753,"Was looking at the wrong line, makes sense and should be fixed now.",looking wrong line sense fixed,issue,negative,negative,negative,negative,negative,negative
481332245,"It looks like you only have 1 mismatch, which is why the method fails when you ask for 3 of them (that's the default). This is also why it works when you pass (1). Will add a check about that number.",like mismatch method ask default also work pas add check number,issue,negative,neutral,neutral,neutral,neutral,neutral
481330591,"You should use `TextLMDataBunch`. `TextDataBunch` shouldn't be used directly, it only implements base methods for the subclasses `TextLMDataBunch` and `TextClasDataBunch`.",use used directly base,issue,negative,negative,negative,negative,negative,negative
481328586,"This is without using context manager, i plainly instantiate the callback as follows
`actStats = ActivationStats(learn)`
and use it by passing in 
`learn.fit_one_cycle(3, 0.5, callbacks=actStats)`

prior to doing fit, if i attempt to destroy the actStats and reinstantiate it, i think i will hit this issue. 
",without context manager plainly learn use passing prior fit attempt destroy think hit issue,issue,negative,negative,neutral,neutral,negative,negative
481326620,How do you get hooks destroyed inside a context manager where they are defined?,get inside context manager defined,issue,negative,neutral,neutral,neutral,neutral,neutral
481325629,"Indeed, but unless PyTorch has changed its code, it's much slower...
Closing this since we had done the two different transposes for speed reasons. If you can show this approach is now faster, please reopen with evidence!",indeed unless code much since done two different speed show approach faster please reopen evidence,issue,negative,positive,neutral,neutral,positive,positive
481211690,"Please read and follow the issue template. the command you ask is inside it.
Also there is a thread on the [forum](https://forums.fast.ai) for installation problems.",please read follow issue template command ask inside also thread forum installation,issue,negative,neutral,neutral,neutral,neutral,neutral
481211434,Please follow the issue template. There is a specific command that is there and will give us all your installation information (which doesn't match what you said earlier otherwise you would have an `ImageDataBunch`).,please follow issue template specific command give u installation information match said otherwise would,issue,negative,neutral,neutral,neutral,neutral,neutral
481138213,"Ah. It changes some of the contents in the notebook, so the diff looks horrible. Better not touch it than git reset. XD",ah content notebook horrible better touch git reset,issue,negative,negative,negative,negative,negative,negative
481131475,"i get this error my pygame project:
```
Traceback (most recent call last):
  File ""C:\Users\danny_000\OneDrive\Documents\programming\python\pygame\projects\air madness\mainLoop.py"", line 30, in <module>
    images.plane(x,y,size)
  File ""C:\Users\danny_000\OneDrive\Documents\programming\python\pygame\projects\air madness\images.py"", line 24, in plane
    gameDisplay.blit(pygame.transform.scale(plainIMG, (size, size)), (x,y))
TypeError: an integer is required (got type NoneType)
```
my code still works fine though",get error project recent call last file line module size file line plane size size integer got type code still work fine though,issue,negative,positive,positive,positive,positive,positive
481123381,"please give information about the package version that you used, such as version of python, fastai, etc",please give information package version used version python,issue,negative,neutral,neutral,neutral,neutral,neutral
480919469,":'(.  Even though I could not make export work, I was able to run my code on a test set by tricking fastai in thinking it was a validation set (setting all labels of the test set to 0...) and then simply running:

`preds,y = learn.get_preds(ds_type=DatasetType.Valid)`

Thanks for your help in the forum thread!",even though could make export work able run code test set tricking thinking validation set setting test set simply running thanks help forum thread,issue,positive,positive,positive,positive,positive,positive
480915606,"`MixedItemList` is a development feature that isn't officially supported yet. It was just added for you to play with, but there are some rough edges you will have to work around ;)",development feature officially yet added play rough work around,issue,negative,negative,neutral,neutral,negative,negative
480913548,Please follow the issue template. We aren't magicians and can't help without any information.,please follow issue template ca help without information,issue,positive,neutral,neutral,neutral,neutral,neutral
480845247,"Eh, how could have I confused a sigmoid with a ReLU... Guess I was really tired!",eh could confused sigmoid guess really tired,issue,negative,negative,negative,negative,negative,negative
480843749,"Hum, with y_range this seems to be a sigmoid:

if self.y_range is not None:
            x = (self.y_range[1]-self.y_range[0]) * torch.sigmoid(x) + self.y_range[0]

But I also just realized I could just call F.relu on the output of TabularModel...

Thanks!",hum sigmoid none also could call output thanks,issue,negative,positive,positive,positive,positive,positive
480823878,"Thanks for the changes, it's looking much better. What do you mean by not run the code in the notebook? It's supposed to be run and be interactive... it's a notebook.",thanks looking much better mean run code notebook supposed run interactive notebook,issue,positive,positive,positive,positive,positive,positive
480823108,"You can always copy-paste the source code for the ones you are interested in. If you are really missing a feature that was there and you feel it's important, try to convert it to a tabular processor and make a PR out of it :)

Closing this issue in the meantime since there is no reproducible code for a bug/context.",always source code interested really missing feature feel important try convert tabular processor make issue since reproducible code,issue,negative,positive,positive,positive,positive,positive
480822342,"Unless there is a reproducible bug with code, the forum is the best place to solve this, so closing this issue.",unless reproducible bug code forum best place solve issue,issue,positive,positive,positive,positive,positive,positive
480773589,@Hamdikap I will suggest you to use this forum for your question: https://forums.fast.ai/t/productionizing-models-thread/28353,suggest use forum question,issue,negative,neutral,neutral,neutral,neutral,neutral
480694577,"@koushikam it seems like you are using v1.0 fastai with old notebooks. You need to use v0.7 of fastai for this old ML1 course or you can copy old code for your function `train_cats` from here: https://github.com/fastai/fastai/blob/master/old/fastai/structured.py#L112.

But, I have question related to `structured.py` module. Why this module is not in v1.0. It has fantastic methods for data. At least the medoths should be migrated to new modules as `add_datepart` migrated to `tabular` module. Am I missing anythig? Thanks.",like old need use old course copy old code function question related module module fantastic data least new tabular module missing thanks,issue,positive,positive,neutral,neutral,positive,positive
480660793,Realized the issue: Shouldn't run the code in the notebook of the ipynb. Probably should put that tip in [CONTRIBUTING.md](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md). ,issue run code notebook probably put tip,issue,negative,neutral,neutral,neutral,neutral,neutral
480616558,"Many thanks @sgugger I tried that earlier, and got an error from _init_ saying it got 3 params not 1, will do a bit more reading :)",many thanks tried got error saying got bit reading,issue,negative,positive,positive,positive,positive,positive
480614156,"This is now fixed in master. Please note that `auc_roc_score` won't work directly, you have to use the `AUROC()` metric (unless your outputs have the same size as your targets, but that's not the case in this tabular example).",fixed master please note wo work directly use metric unless size case tabular example,issue,negative,positive,neutral,neutral,positive,positive
480587793,"Thank you. Since I am planning to add more tests, I will definitely make sure to make them more thorough.",thank since add definitely make sure make thorough,issue,positive,positive,positive,positive,positive,positive
480583393,"I think if you pass `y_range = (0,1)` you will have a final ReLU (not visible in the summary but that will be applied during the forward pass). Please tell me if it doesn't work and reopen in this case.",think pas final visible summary applied forward pas please tell work reopen case,issue,negative,neutral,neutral,neutral,neutral,neutral
480583278,"Thanks! Two comments: I get weird HTML codes instead of seeing the markdown on ReviweNB for the datasets notebook. Is it because their representation is buggy or does it appear like this?

For the actual test, we try to avoid downloads during testing since it takes time. Can you use MNIST_TINY and ML_SAMPLE (instead of MNIST_SAMPLE) as your second dataset (it's the smallest one)?",thanks two get weird instead seeing markdown notebook representation buggy appear like actual test try avoid testing since time use instead second one,issue,negative,negative,neutral,neutral,negative,negative
480582921,"Thanks! On a follow-up PR, don't hesitate to add a few more asserts (starts at 0, ends with the right element for instance).",thanks hesitate add right element instance,issue,negative,positive,positive,positive,positive,positive
480525784,"Done now, closing this issue. You can add a request for a new feature (a function that properly does `get_preds` for distributed) on the [forum](https://forums.fast.ai/) and maybe tackle it and submit a PR :)",done issue add request new feature function properly distributed forum maybe tackle submit,issue,negative,positive,neutral,neutral,positive,positive
480502033,"That's annoying that `DistributedSampler` doesn't have a shuffle option. I'll merge this but refine it a little bit later today to create a more general `DistributedSampler` that takes that option `shuffle=False` then we will use pass it the value of `train_dl.shuffle` so it will work in any situation we don't want the data to be randomly dispatched.

Thanks for digging into this!",annoying shuffle option merge refine little bit later today create general option use pas value work situation want data randomly thanks digging,issue,positive,negative,negative,negative,negative,negative
480501686,"The distributed callback only changes the dataloaders to make them distributed during the `on_train_begin` event, that's why you see the difference. The bug is that at the end of training, the dataloaders aren't put back to what they were, I'll fix that today (afterward you will always see 79 iters in `get_preds`)

Note that `get_preds` , isn't written to support distributed training: it doesn't all_reduce the losses and metrics so each GPU will only have its metrics. I'd advise to use it with non-splitted DataLoaders if you don't write your custom evaluation function.",distributed make distributed event see difference bug end training put back fix today afterward always see note written support distributed training metric metric advise use write custom evaluation function,issue,negative,neutral,neutral,neutral,neutral,neutral
480459775,"It's fixed in fastprogress master, we should do a release of that to make it more easily available :)",fixed master release make easily available,issue,negative,positive,positive,positive,positive,positive
480442615,"I made the change and tests in one repo and then copied to the other without testing. What a noob :(

Fixed it now.",made change one copied without testing fixed,issue,negative,positive,neutral,neutral,positive,positive
480408426,"If you click on the line Run tests 1 error, you will see the details.",click line run error see,issue,negative,neutral,neutral,neutral,neutral,neutral
480406419,"Sure, I was in a hurry and didn't wait for the tests to finish. The error
says something is wrong with bash, so I can't tell which test failed
exactly. I'll look for them when I get to my computer.

On Fri, Apr 5, 2019, 21:16 Sylvain Gugger <notifications@github.com> wrote:

> It looks like it's breaking existing behavior since the tests aren't
> passing. Can you check and debug? Thanks!
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1931#issuecomment-480373684>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AGMRiFE4VsefsYlbHSXMc5zH97oD8jZbks5vd5L8gaJpZM4cfBz->
> .
>
",sure hurry wait finish error something wrong bash ca tell test exactly look get computer wrote like breaking behavior since passing check thanks thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
480381881,I can't help without having the full code you are running and your installation template. Please follow the issue template.,ca help without full code running installation template please follow issue template,issue,positive,positive,positive,positive,positive,positive
480378933,"The problem is that you are missing a line in your config file. Wince a recent PR, it needs to add a 
'data_archive_path' line that should point to where you want to store the archives (the behavior is still wrong since it should have been untared in your data path and not your archive path, will investigate)",problem missing line file wince recent need add line point want store behavior still wrong since data path archive path investigate,issue,negative,negative,negative,negative,negative,negative
480373684,It looks like it's breaking existing behavior since the tests aren't passing. Can you check and debug? Thanks!,like breaking behavior since passing check thanks,issue,positive,positive,positive,positive,positive,positive
480347822,Seems like a good idea yes! (which is why providing code would have helped solve this bug earlier),like good idea yes providing code would solve bug,issue,positive,positive,positive,positive,positive,positive
480266529,"Hi Sylvain, I faced the same error. This happened when we do not provide metrics to the learner, so self.learn.recorder.metrics is an empty list.  Maybe should check whether metrics is empty first?",hi faced error provide metric learner empty list maybe check whether metric empty first,issue,negative,positive,neutral,neutral,positive,positive
480262942,"hey i have a problem i am running on the windows 10 platform and i am also getting the same problem..
at the method to create the  databunch for specific language model i am getting  the error

BrokenProcessPool                         Traceback (most recent call last)
<ipython-input-43-b1c7e64c25ea> in <module>
      1 path1=""D:\\fastai\\data\\imdb_sample\\""
----> 2 data_lm = TextDataBunch.from_csv(path1,'texts.csv')
      3    #  from_csv

~\Anaconda3\envs\fastai_v1\lib\site-packages\fastai\text\data.py in from_csv(cls, path, csv_name, valid_pct, test, tokenizer, vocab, classes, delimiter, header, text_cols, label_cols, label_delim, chunksize, max_vocab, min_freq, mark_fields, include_bos, include_eos, **kwargs)
    220                            label_cols=label_cols, label_delim=label_delim, chunksize=chunksize, max_vocab=max_vocab,
    221                            min_freq=min_freq, mark_fields=mark_fields,
--> 222                            include_bos=include_bos, include_eos=include_eos, **kwargs)
    223 
    224     @classmethod

~\Anaconda3\envs\fastai_v1\lib\site-packages\fastai\text\data.py in from_df(cls, path, train_df, valid_df, test_df, tokenizer, vocab, classes, text_cols, label_cols, label_delim, chunksize, max_vocab, min_freq, mark_fields, include_bos, include_eos, **kwargs)
    201                         TextList.from_df(valid_df, path, cols=text_cols, processor=processor))
    202         if cls==TextLMDataBunch: src = src.label_for_lm()
--> 203         else: src = src.label_from_df(cols=label_cols, classes=classes, label_delim=label_delim)
    204         if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))
    205         return src.databunch(**kwargs)

~\Anaconda3\envs\fastai_v1\lib\site-packages\fastai\data_block.py in _inner(*args, **kwargs)
    463             self.valid = fv(*args, from_item_lists=True, **kwargs)
    464             self.__class__ = LabelLists
--> 465             self.process()
    466             return self
    467         return _inner

~\Anaconda3\envs\fastai_v1\lib\site-packages\fastai\data_block.py in process(self)
    517         ""Process the inner datasets.""
    518         xp,yp = self.get_processors()
--> 519         for ds,n in zip(self.lists, ['train','valid','test']): ds.process(xp, yp, name=n)
    520         #progress_bar clear the outputs so in some case warnings issued during processing disappear.
    521         for ds in self.lists:

~\Anaconda3\envs\fastai_v1\lib\site-packages\fastai\data_block.py in process(self, xp, yp, name)
    694                     p.warns = []
    695                 self.x,self.y = self.x[~filt],self.y[~filt]
--> 696         self.x.process(xp)
    697         return self
    698 ",hey problem running platform also getting problem method create specific language model getting error recent call last module path path test class delimiter header path class path else none path return return self return process self process inner zip clear case disappear process self name return self,issue,negative,positive,neutral,neutral,positive,positive
480140138,"I was having this issue too, with plenty of data, and it seems the min_grad_lr is not calculated until I call recorder.plot().",issue plenty data calculated call,issue,negative,neutral,neutral,neutral,neutral,neutral
479956306,I don't think this is related to fastai - we don't call exit anywhere or do anything that would impact an exit code from your script. Feel free to reopen this issue if you find any code to the contrary in the library.,think related call exit anywhere anything would impact exit code script feel free reopen issue find code contrary library,issue,positive,positive,positive,positive,positive,positive
479891892,Can't reproduce. Are you sure your folder contain images?,ca reproduce sure folder contain,issue,negative,positive,positive,positive,positive,positive
479842043,"@danielwpz I've just opened https://colab.research.google.com/, opened the collab.ipynb straight from Github, and run it without any issue at all:

![image](https://user-images.githubusercontent.com/333274/55549038-3e044200-56d5-11e9-8f9f-1558e3f3f79c.png)

Seems to indicate it works fine as is. Maybe it's a problem with your python environment? 

I'd suggest you try for yourself with Google's Collaboratory. Using this link should open it directly. THen re-run every cell: https://colab.research.google.com/github/fastai/fastai/blob/master/examples/collab.ipynb .

Hopefully that should help you find the issue by comparing your environment with the setup at Collaboratory.",straight run without issue image indicate work fine maybe problem python environment suggest try link open directly every cell hopefully help find issue environment setup,issue,positive,positive,positive,positive,positive,positive
479751652,"I'm having a similar error message when I run lesson2_download.ipynb at verify_images(path/c, delete=True, max_size=500)

---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-61-341706d262d1> in <module>()
      1 for c in classes:
      2     print(c)
----> 3     verify_images(path/c, delete=True, max_size=500)

/Users/bingong1/anaconda/lib/python3.6/site-packages/fastai/vision/data.py in verify_images(path, delete, max_workers, max_size, recurse, dest, n_channels, interp, ext, img_format, resume, **kwargs)
    251     func = partial(verify_image, delete=delete, max_size=max_size, dest=dest, n_channels=n_channels, interp=interp,
    252                    ext=ext, img_format=img_format, resume=resume, **kwargs)
--> 253     parallel(func, files, max_workers=max_workers)
    254 
    255 class ImageList(ItemList):

/Users/bingong1/anaconda/lib/python3.6/site-packages/fastai/core.py in parallel(func, arr, max_workers)
    325         with ProcessPoolExecutor(max_workers=max_workers) as ex:
    326             futures = [ex.submit(func,o,i) for i,o in enumerate(arr)]
--> 327             for f in progress_bar(concurrent.futures.as_completed(futures), total=len(arr)): pass
    328 
    329 def subplots(rows:int, cols:int, imgsize:int=4, figsize:Optional[Tuple[int,int]]=None, title=None, **kwargs):

/Users/bingong1/anaconda/lib/python3.6/site-packages/fastprogress/fastprogress.py in __iter__(self)
     62     def __iter__(self):
     63         self.on_iter_begin()
---> 64         self.update(0)
     65         try:
     66             for i,o in enumerate(self._gen):

/Users/bingong1/anaconda/lib/python3.6/site-packages/fastprogress/fastprogress.py in update(self, val)
     77             self.pred_t = 0
     78             self.last_v,self.wait_for = 0,1
---> 79             self.update_bar(0)
     80         elif val >= self.last_v + self.wait_for or val == self.total:
     81             cur_t = time()

/Users/bingong1/anaconda/lib/python3.6/site-packages/fastprogress/fastprogress.py in update_bar(self, val)
     96             warn(""Your generator is empty."")
     97             self.on_update(0, '100% [0/0]')
---> 98         else: self.on_update(val, f'{100 * val/self.total:.2f}% [{val}/{self.total} {elapsed_t}<{remaining_t}{end}]')
     99 
    100 

/Users/bingong1/anaconda/lib/python3.6/site-packages/fastprogress/fastprogress.py in on_update(self, val, text, interrupted)
    167     def on_update(self, val, text, interrupted=False):
    168         self.progress = html_progress_bar(val, self.total, text, interrupted)
--> 169         if self.display: self.out.update(HTML(self.progress))
    170         elif self.parent is not None: self.parent.show()
    171 

AttributeError: 'NoneType' object has no attribute 'update'

when I run show_install(), the output is
```text
=== Software === 
python       : 3.6.1
fastai       : 1.0.51
fastprogress : 0.1.20
torch        : 1.0.1.post2
torch cuda   : None / is **Not available** 

=== Hardware === 
No GPUs available 

=== Environment === 
platform     : Darwin-17.7.0-x86_64-i386-64bit
conda env    : Unknown
python       : /Users/bingong1/anaconda/bin/python
sys.path     : 
/Users/bingong1/anaconda/lib/python36.zip
/Users/bingong1/anaconda/lib/python3.6
/Users/bingong1/anaconda/lib/python3.6/lib-dynload
/Users/bingong1/anaconda/lib/python3.6/site-packages
/Users/bingong1/anaconda/lib/python3.6/site-packages/Mako-1.0.7-py3.6.egg
/Users/bingong1/anaconda/lib/python3.6/site-packages/Sphinx-1.5.6-py3.6.egg
/Users/bingong1/anaconda/lib/python3.6/site-packages/aeosa
/Users/bingong1/anaconda/lib/python3.6/site-packages/IPython/extensions
/Users/bingong1/.ipython
no supported gpus found on this system
```

Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.

Any suggestions what might be the problem?
",similar error message run recent call last module class print path delete recurse resume partial parallel class parallel ex enumerate pas optional self self try enumerate update self time self warn generator empty else end self text interrupted self text text interrupted none object attribute run output text python torch post torch none available hardware available environment platform unknown python egg egg found system please make sure include paste make appear code might problem,issue,negative,positive,neutral,neutral,positive,positive
479619839,"hey guys thanks for replying so quick. Maybe I'm not expressing myself clearly. 

What the issue is:

The document, which is designed to be read and referred by all users, provides a line of code that is supposed to work with `Learner` base class, however in fact it doesn't work with a derived class `CollabLearner `, can we at least have some docs addressing this difference.",hey thanks quick maybe clearly issue document designed read line code supposed work learner base class however fact work derived class least difference,issue,positive,negative,neutral,neutral,negative,negative
479594006,"Yes wrn is meant to be used as a standalone, and will only work on CIFAR10. It's not intended to be used in `cnn_learner`.",yes meant used work intended used,issue,negative,neutral,neutral,neutral,neutral,neutral
479494812,"Yup, please do let us know if you find the reason it didn't work!",please let u know find reason work,issue,negative,neutral,neutral,neutral,neutral,neutral
479494384,"just tried again on my windows machine and it downloaded correctly, size and checksums match with the code, it looks like there is an issue with my linux machine i will try and get to the bottom of it. Thanks for your quick responses, hopefully this will also help others in future. ",tried machine correctly size match code like issue machine try get bottom thanks quick hopefully also help future,issue,positive,positive,positive,positive,positive,positive
479493045,"Ok, so this is definitely wrong. The first part is the size, so it looks like it didn't download the whole thing. Can you try a manual download? Address is `http://files.fast.ai/data/examples/coco_tiny.tgz`",definitely wrong first part size like whole thing try manual address,issue,negative,negative,neutral,neutral,negative,negative
479491972,"thanks for the quick response, i was just about check the checksum on the file

this is what i get:
(7957, '5b4a3a114cbe89f2165bc1fd3d2b7244')

its different from the checksum in the datasets.py which is this:
 URLs.COCO_TINY:(801038, '367467451ac4fba79a647753c2c66d3a'),",thanks quick response check file get different,issue,negative,positive,positive,positive,positive,positive
479491508,"This is an open-source project, not an outlet to vent your frustration. Please be mindful of that, there is no need to capitalize words or bold-emphasis while using a patronizing tone.

That being said, I added an example on how to make a prediction in the `collab` notebook. There is also a whole [tutorial on inference](https://docs.fast.ai/tutorial.inference.html) in the docs. ",project outlet vent frustration please mindful need capitalize patronizing tone said added example make prediction notebook also whole tutorial inference,issue,negative,positive,positive,positive,positive,positive
479490322,"Hi @danielwpz , did you check in courses/ml1 subfolder? You'll find several Jupyter notebooks, and they show you with great details how to use Fast.AI.
",hi check find several show great use,issue,positive,positive,positive,positive,positive,positive
479489960,"That is weird. Just to double-check, can you see the progress bar for the download when you remove it? Then if you do
```
from fastai.datasets import _check_file
_check_file(Config().data_path()/'coco_tiny.tgz')
```
what is the result you see?",weird see progress bar remove import result see,issue,negative,negative,negative,negative,negative,negative
479488556,"i did remove the coco_tiny.tgz file, i still got the error, actually tried a few times.",remove file still got error actually tried time,issue,negative,neutral,neutral,neutral,neutral,neutral
479487903,"This error means you don't have the latest version of the dataset. As instructed, just remove the file `coco_tiny.tgz` to trigger a new download. Just tried on master and it downloads without any issue.",error latest version instructed remove file trigger new tried master without issue,issue,negative,positive,positive,positive,positive,positive
479482319,"There is a version of `fbeta` for single-label problems that is the class `FBeta`. 

As for the ROC curve, why pick the label index number 1 (instead of 0, 2, 3...)? It doesn't seem to make sense. We can also have a variant of this function suitable for single-label classification but I'm not sure it's the one you are suggesting.

Closing this. Maybe you can suggest a PR that checks if it's a single-labeled task and issue a warning instead?",version class roc curve pick label index number instead seem make sense also variant function suitable classification sure one suggesting maybe suggest task issue warning instead,issue,negative,positive,positive,positive,positive,positive
479406298,"Hi, I don't know exactly what is your environment and your case. But in my case, after some days facing. I set the self.seen instead for index in the dataset.py as this: https://github.com/andy-yun/pytorch-0.4-yolov3/issues/55
Hope it helps you.",hi know exactly environment case case day facing set instead index hope,issue,negative,positive,positive,positive,positive,positive
479149224,"And I linked the doc to the menu bar and fixed the outdated API
https://docs.fast.ai/utils.mod_display.html
so this is complete now.

Thanks again
",linked doc menu bar fixed outdated complete thanks,issue,negative,negative,neutral,neutral,negative,negative
479140782,ok.  Thank you for the update.  We can address when that is pushed later,thank update address later,issue,negative,neutral,neutral,neutral,neutral,neutral
479138726,"> Should we check in the new StopAfterNBatches along with this change/update?

Let's just leave it for now, and come back to it after part 2. i.e. no need to sort this problem out for now.

Otherwise we need to break the API and Sylvain says it won't be needed when he reworks it. I pushed my wip into a branch here: https://github.com/fastai/fastai/tree/StopAfterNBatches-learner",check new along let leave come back part need sort problem otherwise need break wo branch,issue,negative,positive,neutral,neutral,positive,positive
479136655,"Thank you, @bfarzin.

So far now I will hold off integrating this ctx manager into StopAfterNBatches, since Sylvain is planning on a much simpler API that could be done globally.

So I will unroll those functions back to how you initially did it.",thank far hold manager since much simpler could done globally unroll back initially,issue,negative,positive,neutral,neutral,positive,positive
479136639,"`lesson7-superres.ipynb` runs as it with the context manager that is pushed out there.  No updates are put out, but I do get new trained values.  So that is as expected.  

I added your new `StopAfterNBatches` and I replicate your error locally.  Working on addressing that now.  

Should we check in the new `StopAfterNBatches` along with this change/update?",context manager put get new trained added new replicate error locally working check new along,issue,negative,positive,positive,positive,positive,positive
479123848,"Took me a couple tries to re-base.  I can see why I want to avoid that whenever I can!  
Thanks for your help and guidance.  Let me run more test cases and assure that things do not fail here.  
",took couple see want avoid whenever thanks help guidance let run test assure fail,issue,negative,negative,negative,negative,negative,negative
479115871,"Here is the new version of StopAfterNBatches (not yet committed):
```
"" Miscellaneous callbacks ""

from ..basic_train import LearnerCallback
from fastai.utils.mod_display import progress_disabled_ctx

class StopAfterNBatches(LearnerCallback):
    ""Stop training after n batches of the first epoch.""
    def __init__(self, learn, n_batches:int=2):
        super().__init__(learn)
        self.n_batches = n_batches-1 # iteration starts from 0
        self.prog_ctx = progress_disabled_ctx(learn)

    def on_batch_end(self, iteration, **kwargs):
        if iteration == self.n_batches:
            return {'stop_epoch': True, 'stop_training': True, 'skip_validate': True}

    def on_train_begin(self, **kwargs): self.prog_ctx.disable()
    def on_train_end(self, **kwargs):   self.prog_ctx.enable()
```

note you have to configure it differently now:

    # 1. global assignment
    defaults.extra_callback_fns = [partial(StopAfterNBatches, n_batches=run_n_batches)]

    # 2. dynamic assignment
    learn.callback_fns.append(partial(StopAfterNBatches, n_batches=run_n_batches))

So you can try it on `lesson7-superres.ipynb` after you rebase master and you will see the:

   `ConsoleProgressBar' object has no attribute 'progress'

error",new version yet miscellaneous import import class stop training first epoch self learn super learn iteration learn self iteration iteration return true true true self self note configure differently global assignment partial dynamic assignment partial try rebase master see object attribute error,issue,positive,positive,positive,positive,positive,positive
479112679,"Also x.func doesn't exist in unet_learner, so I have reworked your context to check that it exists. will commit shortly (and abstracted the functionality out to be used outside of context manager)

https://github.com/fastai/fastai/commit/15e6e1c15033349e37ead1e5a02b3b4c13c8f514

So please rebase your side again. Thank you.",also exist reworked context check commit shortly abstracted functionality used outside context manager please rebase side thank,issue,positive,neutral,neutral,neutral,neutral,neutral
479112163,"Also try this context in `lesson7-superres.ipynb`
this line:
```
 fastai.basic_train.master_bar, fastai.basic_train.progress_bar = fastprogress.force_console_behavior()
```
causes:

```
/mnt/nvme1/fast.ai-1/br/fastai/course-v3/nbs/dl1/fastai/basic_train.py in fit(epochs, learn, callbacks, metrics)
     97             cb_handler.set_dl(learn.data.train_dl)
     98             cb_handler.on_epoch_begin()
---> 99             for xb,yb in progress_bar(learn.data.train_dl, parent=pbar):
    100                 xb, yb = cb_handler.on_batch_begin(xb, yb)
    101                 loss = loss_batch(learn.model, xb, yb, learn.loss_func, learn.opt, cb_handler)

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastprogress/fastprogress.py in __init__(self, gen, total, display, leave, parent, auto_update, txt_len)
    246         self.length = cols-txt_len
    247         self.max_len,self.prefix = 0,''
--> 248         super().__init__(gen, total, display, leave, parent, auto_update)
    249 
    250     def on_interrupt(self):

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastprogress/fastprogress.py in __init__(self, gen, total, display, leave, parent, auto_update)
     49         else:
     50             self.leave,self.display=False,False
---> 51             parent.add_child(self)
     52         self.comment = ''
     53         if not self.auto_update:

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastprogress/fastprogress.py in add_child(self, child)
    198     def add_child(self, child):
    199         self.child = child
--> 200         self.inner_dict['pb2'] = self.child.progress
    201         self.show()
    202 

AttributeError: 'ConsoleProgressBar' object has no attribute 'progress'
```

in the first lr_find call there.",also try context line fit learn metric loss self gen total display leave parent super gen total display leave parent self self gen total display leave parent else false self self child self child child object attribute first call,issue,positive,positive,neutral,neutral,positive,positive
479111591,"Yes. something is not right. All passed here, but seems to be wrong.  I think I got out of sync with Master.  Working on it now.",yes something right wrong think got sync master working,issue,negative,negative,negative,negative,negative,negative
479100657,"And the test error log is here:
https://dev.azure.com/fastdotai/fastai/_build/results?buildId=4341&view=logs
Did it pass on your side?
",test error log pas side,issue,negative,neutral,neutral,neutral,neutral,neutral
479099903,"why is `fastai/utils/mod_display.py` added again as a new file? Needing to rebase your branch?
https://docs.fast.ai/dev/git.html#how-to-keep-your-feature-branch-up-to-date",added new file needing rebase branch,issue,negative,positive,positive,positive,positive,positive
479089521,Thanks!  I got a simple test out.  I will put out a new PR for that,thanks got simple test put new,issue,negative,positive,positive,positive,positive,positive
479001380,"I'll merge this for now, waiting for your additional test. Thanks!",merge waiting additional test thanks,issue,negative,positive,positive,positive,positive,positive
478984796,"The bug was not related to this part of code, so you can merge.",bug related part code merge,issue,negative,neutral,neutral,neutral,neutral,neutral
478983140,"Just restyled for vertical space, let me know when this is ready.",vertical space let know ready,issue,negative,positive,positive,positive,positive,positive
478982544,I just found a bug with the current implementation. Please don't merge for now.,found bug current implementation please merge,issue,negative,neutral,neutral,neutral,neutral,neutral
478981787,"Hi there! The training set has, by default, `drop_last=True`, which means the last batch with less than batch size samples is discarded. This is for stability in training when there are BatchNorm layers. To access the full training set you can either do:
```
data.train_dl = data.train_dl.new(drop_last=False)
```
which will replace the training dataloader with a new one that has `drop_last=False` or use `DatasetType.Fix`, which is the full training set (so no `drop_last`) with the same transforms as the validation set.",hi training set default last batch le batch size stability training access full training set either replace training new one use full training set validation set,issue,negative,positive,positive,positive,positive,positive
478810248,I agree.  I was just going to ask how to check the displayed output.  I’ll write that up tomorrow.  Thanks so much for all the feedback. ,agree going ask check displayed output write tomorrow thanks much feedback,issue,positive,positive,positive,positive,positive,positive
478809103,"looking good - next, it'd be good to have a test to ensure this functionality doesn't break when things change. there are a few existing tests that you could model after - use `CaptureStdout` to capture the output.",looking good next good test ensure functionality break change could model use capture output,issue,positive,positive,positive,positive,positive,positive
478807469,Oh I see now.  I think adding _ctx is a good idea. I’ll do that. ,oh see think good idea,issue,negative,positive,positive,positive,positive,positive
478806637,"I'm not asking for any change, other than putting the enter/exit functionality into functions that could be used elsewhere.

In the case of `StopAfterNBatches` which you can enable globally or locally, the callback already acts as a context manager - we just need to add `on_train_begin`/`on_train_end` which would call your enter/exit funcs - so as soon as it's no longer configured for a given `learn` object or `fit` call, the behavior goes back to normal - i.e. with that change in `StopAfterNBatches` you won't need the context manager (if you're just using it with  `StopAfterNBatches` )

Renaming the originally proposed `progress_disable` to add `_ctx` is just an idea to tell those functions apart.

p.s. as I said originally we can do that next, after this PR is merged. I don't want to slow things down. So please proceed as with your initial intention and I will re-work things to include it in `StopAfterNBatches` unless you will beat me to it (in a separate PR) ;)",change functionality could used elsewhere case enable globally locally already context manager need add would call soon longer given learn object fit call behavior go back normal change wo need context manager originally add idea tell apart said originally next want slow please proceed initial intention include unless beat separate,issue,positive,positive,neutral,neutral,positive,positive
478805669,"@stas00 I don't have a strong point of view. It could be easy to add into `StopAfterNBatches` so you have it in just one line.  Or, there could be a separate call that would flow as you indicate.

What I like about the context manager, is that after my ""test"" it goes back to normal.  And I won't forget to put it back if I am doing this as a smaller test in a bigger notebook or project.  For example, we might wan this to `do_the_magic()` and find the batch size or other params, then proceed as needed.  I see how that works in your use case as well with the `tune` condition.

If you and @sgugger think one way works better than another, I am happy to implement it!  ",strong point view could easy add one line could separate call would flow indicate like context manager test go back normal wo forget put back smaller test bigger notebook project example might wan find batch size proceed see work use case well tune condition think one way work better another happy implement,issue,positive,positive,positive,positive,positive,positive
478802126,"Another thought for post-PR-merge is that there must be a better way to do it. A context manager requires you to go and change all the fit calls which defeats the purpose of `StopAfterNBatches` global callback, which you can turn on/off in one line of code.

So my preference would be a global setting for fastprogress that will do this for me from one place in the notebook.
so perhaps renaming your proposal to `progress_disabled_ctx` and adding `progress_enable`/`progress_disable` that will allow us to:
```
from fastai.callbacks.misc import StopAfterNBatches
from fastai.utils.mod_display import progress_enable, progress_disable
# True turns the speedup on, False return to normal behavior
tune = True # False
if tune:
    defaults.extra_callbacks = [StopAfterNBatches(n_batches=2)]
    progress_disable() # tell fastprogress not to print anything here
else:
    defaults.extra_callbacks = None
    progress_enable() 
```

and `StopAfterNBatches` could do that internally too via `on_train_begin`/`on_train_end` as the enter/exit context, so no mess for the user to figure out. I guess it could do that now, without this extra functionality too ;)

And in which case if it's ""internalized"" my request in an comment is no longer relevant.

p.s. looking again at your code, which clearly requires `learn` to be around (due to `Recorder`) the above code sample won't do, so only integrating it into `StopAfterNBatches` will work. But we would still want to make those functions usable elsewhere, besides the ctx manager.

Thank you!
",another thought must better way context manager go change fit purpose global turn one line code preference would global setting one place notebook perhaps proposal allow u import import true turn false return normal behavior tune true false tune tell print anything else none could internally via context mess user figure guess could without extra functionality case request comment longer relevant looking code clearly learn around due recorder code sample wo work would still want make usable elsewhere besides manager thank,issue,positive,positive,neutral,neutral,positive,positive
478788997,"And when you guys complete please also add an example to deploy that at
https://docs.fast.ai/callbacks.misc.html#StopAfterNBatches
editing `callbacks.misc.ipynb` https://docs.fast.ai/gen_doc_main.html#step-3-edit-the-documents

Thank you!
",complete please also add example deploy thank,issue,positive,positive,neutral,neutral,positive,positive
478788346,It's looking good and useful! I have a few comments to clean this is a little bit before merging.,looking good useful clean little bit,issue,positive,positive,positive,positive,positive,positive
478787821,"Note that on the last of fastprogress, it won't even show the total time (that part isn't printed anymore).",note last wo even show total time part printed,issue,negative,neutral,neutral,neutral,neutral,neutral
478787520,"Good catch, thanks for fixing!",good catch thanks fixing,issue,positive,positive,positive,positive,positive,positive
478787246,Mainly an explanation of what they do with an example would be nice. ,mainly explanation example would nice,issue,negative,positive,positive,positive,positive,positive
478783768,"@tomfisher I did the testing only on `cnn_learner`. I assumed both would produce equally sized outputs and I didn't use tabular_learner so far to be honest. It might need some reshaping beforehand. I will take a look into this issue over the next week. I'm currently a little bit busy unfortunately.

@sgugger I'm working on it. Do you want
1. definitions, explanations and formulas for each single metric?
2. ""how to use"" examples like `auc=AUROC();cnn_learner(...,metrics=[auc],...)`? This might be a little bit repetitive?!
3. parameter clarification for each singe metric or rather some kind of referencing in case of parameter sharing.

Btw on a side note I would like to draw attention to
https://forums.fast.ai/t/part-2-2019-fellowship-invitations-and-some-special-thanks/39329/43, especially to the last couple of posts regarding the fastai v3 part II course selection procedure.",testing assumed would produce equally sized use far honest might need beforehand take look issue next week currently little bit busy unfortunately working want single metric use like might little bit repetitive parameter clarification singe metric rather kind case parameter side note would like draw attention especially last couple regarding part course selection procedure,issue,positive,positive,neutral,neutral,positive,positive
478731781,"It's hard to say without saying the whole code but I have seen this error pop up with older version of PyTorch. Make sure you're using pytorch v1 or v1.0.1 and fastai v1.0.50 or later, then reopen with more details if the bug persists.

For the forum, you have to read for at least 10 minutes before being allowed to post I believe.",hard say without saying whole code seen error pop older version make sure later reopen bug forum read least post believe,issue,negative,positive,neutral,neutral,positive,positive
478662180,"Yup, this has been fixed in master and will be in the next release (double checked with your gist). Note that you can't see it until v1.0.51 is out unless you do a developer install with
```
pip install -e .[dev]
```
inside the fastai repo (it would show v1.0.51dev in `show_install`). ",fixed master next release double checked gist note ca see unless developer install pip install dev inside would show dev,issue,negative,positive,neutral,neutral,positive,positive
478533742,"I tested with a tabular_learner for a binary classification problem, got the following error:

```
learn = tabular_learner(data, layers=[1024, 512, 256],  ps=[0.5, 0.7, 0.9],  loss_func=loss, metrics=[accuracy, auc_roc_score])


16  	    targ = targ[desc_score_indices]
 17  	    d = input[1:] - input[:-1]
 18  	    distinct_value_indices = torch.nonzero(d).transpose(0,1)[0]
 19  	    threshold_idxs = torch.cat((distinct_value_indices, LongTensor([len(targ) - 1])))
 20  	    tps = torch.cumsum(targ * 1, dim=-1)[threshold_idxs]
 21  ->	    fps = (1 + threshold_idxs - tps)
 22  	    if tps[0] != 0 or fps[0] != 0:
 23  	        fps = torch.cat((LongTensor([0]), fps))
 24  	        tps = torch.cat((LongTensor([0]), tps))
 25  	    fpr, tpr = fps.float() / fps[-1], tps.float() / tps[-1]
 26  	    return fpr, tpr
(Pdb) (threshold_idxs - tps).size()
*** RuntimeError: The size of tensor a (7109) must match the size of tensor b (2) at non-singleton dimension 1

```",tested binary classification problem got following error learn data accuracy input input return size tensor must match size tensor dimension,issue,negative,neutral,neutral,neutral,neutral,neutral
478435354,I will do so during the week. Thanks for being patient and helping me through the process. :D,week thanks patient helping process,issue,positive,positive,positive,positive,positive,positive
478407032,and documentation please. Without it only you know about this feature.,documentation please without know feature,issue,negative,neutral,neutral,neutral,neutral,neutral
478391716,"Ok, looking good. Merging this then you can add a test in a separate PR.",looking good add test separate,issue,negative,positive,positive,positive,positive,positive
478378010,Agreed. Gotta develop better software development habits. XD,agreed got ta develop better development,issue,positive,positive,positive,positive,positive,positive
478375456,"> omg, my brain isn't working right, how did I miss that. Should've read through before committing.

That's why we write tests first. Make it a habit and then you can give your brain a break :)",brain working right miss read write first make habit give brain break,issue,negative,positive,positive,positive,positive,positive
478374615,"omg, my brain isn't working right, how did I miss that. Should've read through before committing. ",brain working right miss read,issue,negative,positive,positive,positive,positive,positive
478374406,"Odd, github is not updating things - I have to force page reload to see changes.",odd force page reload see,issue,negative,negative,negative,negative,negative,negative
478373935,"Yeah, those changes are in this new PR. I'll add a few tests when @sgugger green lights my code. ",yeah new add green code,issue,negative,negative,neutral,neutral,negative,negative
478373636,"And you need the rest of the changes from @1904 too.

And if @sgugger gives green light, please add a new test, so that when things get redesigned this feature won't break. Thanks.",need rest green light please add new test get feature wo break thanks,issue,positive,positive,positive,positive,positive,positive
478373077,"Cool, I'll push up my modified `modelpath4file` then. I changed the default `archive` to True so we don't need to touch the tests for now. ",cool push default archive true need touch,issue,positive,positive,positive,positive,positive,positive
478372164,"If it's OK with @sgugger, it's fine with me if as long as it gets cleaned up/untangled after part2. i understand you're referring to the original PR https://github.com/fastai/fastai/pull/1904

",fine long part understand original,issue,negative,positive,positive,positive,positive,positive
478371798,"> The TODO is for after the course, we don't have time to redesign the whole datasets module and thoroughly test right now. i'd suggest focusing on the feature to add for now.

I have code that kinda adds to this mess, but fulfils the feature request. If you guys think it's fine, we can use that code first and then redesign the module altogether. I'd love to help with the redesign and implementation. ",course time redesign whole module thoroughly test right suggest feature add code mess feature request think fine use code first redesign module altogether love help redesign implementation,issue,positive,positive,positive,positive,positive,positive
478371222,"> So we have 2 ways the files are saved in on download:
> `untar_data(url:str, fname:PathOrStr=None, dest:PathOrStr=None...`
> 
> * local path (user defined path)
> * global path (via config object)
> 
> it should work just fine for local path, since a user can say:
> `untar_data(url, ""/download/here/file.tgz"", ""/untar/here/file"")`
> 
> So we could have just stopped here and say, well, why can't you just use this existing feature, right?
> 
> So if you don't override the `fname` and `dest` args then you'd like to have these set by default to 2 different locations, correct? because you want this to be the default behavior and not needing to set it manually in all notebooks.
> 
> If so `untar_data` should set its `dest` when it's not set in the arguments to that new `data_archive_path` and the code modified accordingly.
> 
> Are we on the same page?

Yeah. It is a hassle to specify the exact same location for `dest` in every notebook. 
",way saved local path user defined path global path via object work fine local path since user say could stopped say well ca use feature right override like set default different correct want default behavior needing set manually set set new code accordingly page yeah hassle specify exact location every notebook,issue,positive,positive,positive,positive,positive,positive
478371142,"The TODO is for after the course, we don't have time to redesign the whole datasets module and thoroughly test right now. i'd suggest focusing on the feature to add for now.",course time redesign whole module thoroughly test right suggest feature add,issue,negative,positive,positive,positive,positive,positive
478370500,"Looking more these features need a serious redesign (well it says TODO in the file)

```
def _url2tgz(url, data=True, ext:str='.tgz'):
    return datapath4file(f'{url2name(url)}{ext}', ext=ext) if data else modelpath4file(f'{url2name(url)}{ext}', ext=ext)
```
why are passing `ext` twice? I think it needs to be removed from the first arg.
```
def datapath4file(filename, ext:str='.tgz'):
    ""Return data path to `filename`, checking locally first then in the config file.""
    local_path = URLs.LOCAL_PATH/'data'/filename
    if local_path.exists() or local_path.with_suffix(ext).exists(): return local_path
    else: return Config.data_path()/filename
```
this certainly is a weird logic. You can't check either or but return only one of them. It won't work if someone passed `filename` that includes tgz, like the test I have just fixed, since it the returns the path to filename and not the path.

same applies to `modelpath4file`.

p.s. I'm out for the rest of the day, will resume tomorrow unless you sort it out beforehand, which would be great too.",looking need serious redesign well file return data else passing twice think need removed first return data path locally first file return else return certainly weird logic ca check either return one wo work someone like test fixed since path path rest day resume tomorrow unless sort beforehand would great,issue,positive,positive,neutral,neutral,positive,positive
478368461,"So we have 2 ways the files are saved in on download:
`untar_data(url:str, fname:PathOrStr=None, dest:PathOrStr=None...`

* local path (user defined path)
* global path (via config object)

it should work just fine for local path, since a user can say:
`untar_data(url, ""/download/here/file.tgz"", ""/untar/here/file"")`

So we could have just stopped here and say, well, why can't you just use this existing feature, right?

So if you don't override the `fname` and `dest` args then you'd like to have these set by default to 2 different locations, correct? because you want this to be the default behavior and not needing to set it manually in all notebooks.

If so `untar_data` should set its  `dest` when it's not set in the arguments to that new `data_archive_path` and the code modified accordingly.

Are we on the same page?




",way saved local path user defined path global path via object work fine local path since user say could stopped say well ca use feature right override like set default different correct want default behavior needing set manually set set new code accordingly page,issue,positive,positive,positive,positive,positive,positive
478368057,"I think @stas00 is trying to come up with a new function to replace `modelpath4file`, so I didn't modify that function. I have a modified version that passes the tests locally, so I can commit and push any time we need. ",think trying come new function replace modify function version locally commit push time need,issue,negative,positive,neutral,neutral,positive,positive
478367545,"Yeah, was a little messy downloading the notebook as `.py` and selecting parts of it. Apparently, I didn't copy over the lr_find line. The notebook was always reproducible, though. ",yeah little messy notebook apparently copy line notebook always reproducible though,issue,negative,negative,negative,negative,negative,negative
478367491,"Well, it's a mess because we have started talking about what the API should really be if we separate `data_path` and `data_archive_path`. So let's hold off on experimental changes and first define how we want it to work. Then implementing it is the easy part.",well mess talking really separate let hold experimental first define want work easy part,issue,negative,positive,positive,positive,positive,positive
478367025,"Ah, that *is* different from the code you sent me ;)
Able to reproduce now, this is linked to the learning rate finder test somehow.",ah different code sent able reproduce linked learning rate finder test somehow,issue,negative,positive,positive,positive,positive,positive
478366390,"Interesting, the issue is magically solved if I don't run `lr_find()` for fp16. Once I run `lr_find()`, the model doesn't train. I wonder how `lr_find` would affect the training. Could be something to do with [this callback function](https://github.com/fastai/fastai/blob/master/fastai/callbacks/lr_finder.py#L36)? ",interesting issue magically run run model train wonder would affect training could something function,issue,negative,positive,positive,positive,positive,positive
478366085,"Not sure I follow, this archive path isn't used anywhere so why is the data downloaded in a separate folder?",sure follow archive path used anywhere data separate folder,issue,negative,positive,positive,positive,positive,positive
478360742,Sorry I think I used the master branch of the fork. I'll create a new branch and a new PR that refers back here. :cry: ,sorry think used master branch fork create new branch new back cry,issue,negative,negative,neutral,neutral,negative,negative
478357874,"continuing from the code comment above. Unrelated to this PR:
```
def datapath4file(filename, ext:str='.tgz'):
    ""Return data path to `filename`, checking locally first then in the config file.""
    local_path = URLs.LOCAL_PATH/'data'/filename
    if local_path.exists() or local_path.with_suffix(ext).exists(): return local_path
    else: return Config.data_path()/filename
```
currently this needs some work, as 

1. it's quite ambiguous since the addition of `ext` arg.

So the test calls `fname = datapath4file(f'{url2name(url)}.tgz')` and gets the filename and not the path, because double exists() above doesn't check that the `filename` already includes `tgz` and returns a path that has `tgz` in it, which is wrong. 

So first the test should go:

```    
fname = datapath4file(url2name(url)).with_suffix("".tgz"")
```

I changed this in master - please rebase this in your branch with 
https://docs.fast.ai/dev/git.html#how-to-keep-your-feature-branch-up-to-date

Except now if the file and the path are in different places then this usage is no longer correct. So we need a new function I think. Let me think about it.

2. It doesn't test that `Config.data_path()/filename` actually exists

Now you're saying that it needs to look for it under `Config.data_archive_path()/filename` - why do we need an extra argument for that?


",code comment unrelated return data path locally first file return else return currently need work quite ambiguous since addition test path double check already path wrong first test go master please rebase branch except file path different usage longer correct need new function think let think test actually saying need look need extra argument,issue,negative,positive,neutral,neutral,positive,positive
478357024,"I've run the [cifar notebook](https://github.com/fastai/fastai/blob/master/examples/cifar.ipynb) and it works fine. I ran fp16 with pytorch and apex on CUDA 10 to train cifar10 on resnet34 from scratch in February without any issues, so I doubt it is a hardware/driver/cuda/cudnn thing. ",run notebook work fine ran apex train scratch without doubt thing,issue,negative,positive,positive,positive,positive,positive
478356693,"> @stas00 Coming to think of it, I agree. It's a better idea to set the defaults of data_path and data_archive_path to the same place. 

Great!

> As to hierarchical organization, I don't see any way to easily add per dataset specifications in the config. It could potentially require scrapping a lot of functions in the module, but I haven't thoroughly thought over it. We would probably need to finish the TODOs in the module (""coded more shortly and nicely"" and ""simplify this mess"") before we attempt that.

I think I didn't communicate clearly, I was just talking about various ways this can be used and not saying we need to accomplish this in this PR. All I was trying to say is that once we have the archive setting, then a user will be able to override it globally (because their fast drive is small - this PR), and then a user should be able to override it just for a specific notebook - need to create API (another PR). The hierarchy of the storage does't matter, I was just trying to make a point that not everybody will have all .tgz in one flat folder.

So let's complete this PR with just that - giving a user a way to override the defaults.",coming think agree better idea set place great hierarchical organization see way easily add per could potentially require scrapping lot module thoroughly thought would probably need finish module shortly nicely simplify mess attempt think communicate clearly talking various way used saying need accomplish trying say archive setting user able override globally fast drive small user able override specific notebook need create another hierarchy storage matter trying make point everybody one flat folder let complete giving user way override,issue,positive,positive,positive,positive,positive,positive
478356298,"> @stas00 Coming to think of it, I agree. It's a better idea to set the defaults of data_path and data_archive_path to the same place. As to hierarchical organization, I don't see any way to easily add per dataset specifications in the config. It could potentially require scrapping a lot of functions in the module, but I haven't thoroughly thought over it. We would probably need to finish the TODOs in the module (""coded more shortly and nicely"" and ""simplify this mess"") before we attempt that.

If you guys are willing to write me some specifications and guidelines, I can attempt to clean it up and add per dataset settings to the config file. ",coming think agree better idea set place hierarchical organization see way easily add per could potentially require scrapping lot module thoroughly thought would probably need finish module shortly nicely simplify mess attempt willing write attempt clean add per file,issue,positive,positive,positive,positive,positive,positive
478356116,"@stas00 Coming to think of it, I agree. It's a better idea to set the defaults of data_path and data_archive_path to the same place. As to hierarchical organization, I don't see any way to easily add per dataset specifications in the config. It could potentially require scrapping a lot of functions in the module, but I haven't thoroughly thought over it. We would probably need to finish the TODOs in the module (""coded more shortly and nicely"" and ""simplify this mess"") before we attempt that. ",coming think agree better idea set place hierarchical organization see way easily add per could potentially require scrapping lot module thoroughly thought would probably need finish module shortly nicely simplify mess attempt,issue,positive,positive,positive,positive,positive,positive
478354625,Might be a hardware/drive/cuda/cudnn problem. Does mixed precision work in one setting? Or does it always fail?,might problem mixed precision work one setting always fail,issue,negative,negative,negative,negative,negative,negative
478353603,"Thinking more about it, your proposition is trying to solve only a partial problem - you want the ""./archive"" sub-folder to be a symlink to a bigger drive, so that all downloaded `tgz` get dumped there. But this is not flexible enough, e.g. I don't store large datasets in one flat folder, they are organized in a hierarchical structure and multiple sub-folders.

So ideally depending on the dataset I will want to set the archive folder to a unique path in each specific notebook. 

And then like in your case, some users will want to set the default for archive folder to be global, so it goes into another drive. And they should be able to do so by tweaking the config object once and forget about it.

Hardcoding `./archive` as a default is not super convenient, since you can't just untar files from the console if you need to - you now need to either remember to move them or pass the flag to untar at a different destination.

That's why I suggest that there is no need to change the API, other than making the code use the `data_archive_path` setting from the `Config` object, whose default should be the same as `data_path`, and let the user set it to whatever she wants it to be.

Does it make sense?",thinking proposition trying solve partial problem want bigger drive get flexible enough store large one flat folder organized hierarchical structure multiple ideally depending want set archive folder unique path specific notebook like case want set default archive folder global go another drive able object forget default super convenient since ca untar console need need either remember move pas flag untar different destination suggest need change making code use setting object whose default let user set whatever make sense,issue,positive,positive,positive,positive,positive,positive
478353273,"Code I ran (on both dev build from master and 1.0.50.post1): 
```
from fastai.vision import *

path = Config.data_path()/'planet'
path.mkdir(parents=True, exist_ok=True)

tfms = get_transforms(flip_vert=True, max_lighting=0.1, max_zoom=1.05, max_warp=0.)

np.random.seed(42)
src = (ImageList.from_csv(path, 'train_v2.csv', folder='train-jpg', suffix='.jpg')
       .split_by_rand_pct(0.2)
       .label_from_df(label_delim=' '))

data = (src.transform(tfms, size=128)
        .databunch().normalize(imagenet_stats))

arch = models.resnet50

acc_02 = partial(accuracy_thresh, thresh=0.2)
f_score = partial(fbeta, thresh=0.2)
learn = cnn_learner(data, arch, metrics=[acc_02, f_score]).to_fp16()
# learn = cnn_learner(data, arch, metrics=[acc_02, f_score])

learn.lr_find()

lr = 0.01

learn.fit_one_cycle(5, slice(lr))
```

Results for fp16:
```
epoch     train_loss  valid_loss  accuracy_thresh  fbeta     time    
0         0.842592    0.754226    0.187966         0.476119  00:46                   
1         0.840402    0.750478    0.190125         0.477969  00:45                   
2         0.840895    0.753238    0.189376         0.475770  00:46                   
3         0.839311    0.745062    0.189790         0.477772  00:46                   
4         0.843568    0.753511    0.189231         0.477805  00:46                   
Total time: 03:50
```

Results for fp32:
```
epoch     train_loss  valid_loss  accuracy_thresh  fbeta     time    
0         0.128140    0.110074    0.943771         0.904181  00:42                   
1         0.108145    0.098180    0.949904         0.912403  00:42                   
2         0.101861    0.092210    0.951466         0.921294  00:44                   
3         0.095462    0.087542    0.956465         0.924710  00:41                   
4         0.091450    0.086625    0.955811         0.924713  00:43                   
Total time: 03:33
```",code ran dev build master post import path path data arch partial partial learn data arch learn data arch slice epoch time total time epoch time total time,issue,negative,negative,neutral,neutral,negative,negative
478352442,That is exactly what I did. I will upload a .py file once I run it as a script. ,exactly file run script,issue,negative,positive,positive,positive,positive,positive
478350677,Hmm. This should fix it. Had to modify the test as somebody wrote a test using `datapath4file` intended as the archived version. ,fix modify test somebody wrote test intended version,issue,negative,neutral,neutral,neutral,neutral,neutral
478348534,"I tried to reproduce by adding `to_fp16()` in the cell that defined the learner:
```
acc_02 = partial(accuracy_thresh, thresh=0.2)
f_score = partial(fbeta, thresh=0.2)
learn = cnn_learner(data, arch, metrics=[acc_02, f_score]).to_fp16()
```
and it worked without any issue. Please provide the exact code you are running as we can't fix a bug we aren't able to reproduce.",tried reproduce cell defined learner partial partial learn data arch worked without issue please provide exact code running ca fix bug able reproduce,issue,negative,positive,positive,positive,positive,positive
478315954,"> Hmm, wondering why the checks are not passing.

Because you didn't run the test suite and adjust it to fit the proposed API and one of the tests now fails. 


Click on `Details` and then go to `View more details on Azure Pipelines` at the end of the page which takes you to 
https://dev.azure.com/fastdotai/fastai/_build/results?buildId=4284
then click on the failing job and you will see:
```
=================================== FAILURES ===================================
_____________________________ test_trunc_download ______________________________

    @pytest.mark.skipif(not responses, reason=""requires the `responses` module"")
    def test_trunc_download():
        this_tests(untar_data)
        url = URLs.COCO_TINY
>       fname = datapath4file(f'{url2name(url)}.tgz')
E       TypeError: datapath4file() missing 1 required positional argument: 'archive'

tests/test_vision_data.py:168: TypeError
-------------- generated xml file: /home/vsts/work/1/s/result.xml --------------
```

See how to run the tests:
https://docs.fast.ai/dev/test.html#quick-guide
",wondering passing run test suite adjust fit one click go view azure end page click failing job see module missing positional argument file see run,issue,negative,positive,neutral,neutral,positive,positive
478314346,"@sgugger 
:laughing: :laughing: :laughing:  
:dancer: :dancer: :dancer: ",laughing laughing laughing dancer dancer dancer,issue,positive,neutral,neutral,neutral,neutral,neutral
478294440,Sure. I'll look into writing an implementation and adding it to the docs. I'll shoot up a PR when I'm done. ,sure look writing implementation shoot done,issue,negative,positive,positive,positive,positive,positive
478242673,"Hi there. This could be a useful feature for some users, yes. It's not going to be on our priority list for now but if you're willing to tackle it, we'll gladly look at a PR. I'm closing this here as issues are for standing bugs only, but I've created a topic on the forum to continue the discussion if needed.",hi could useful feature yes going priority list willing tackle gladly look standing topic forum continue discussion,issue,positive,positive,positive,positive,positive,positive
478242408,"There is a `LossMetrics` callback. You just have to use it when the loss function of your `Learner` has an attribute `metric_names` (for the names of l1 and l2) and updates in `forward` an attribute `metrics` (to contain the values of l1 and l2).

There is an example with `FeatureLoss` in [this notebook](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson7-superres.ipynb).",use loss function learner attribute forward attribute metric contain example notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
478210460,"Thank you, @HamsterHuey. 

Fixed @ https://github.com/fastai/fastai/commit/e5693f6d34d0564c24c5f9db48cbd1c36c29d9ef

In the future also please don't hesitate to submit a PR https://docs.fast.ai/dev/git.html#how-to-make-a-pull-request-pr",thank fixed future also please hesitate submit,issue,negative,positive,neutral,neutral,positive,positive
478202180,"You're natural, @RohitMidha23. Looking forward to receiving more PRs from you in the future.",natural looking forward future,issue,negative,positive,neutral,neutral,positive,positive
478202042,"Awesome, thank you, @RohitMidha23!

I will update the docs next.",awesome thank update next,issue,positive,positive,positive,positive,positive,positive
478200133,"Looks like a useful feature to me. I think your situation/setup is common one for large datasets.

Needless to say, but the default should remain as it is now (shared folder).

But let's wait for @sgugger to double check before you proceed. Thank you, @tydlwav ",like useful feature think common one large needle say default remain folder let wait double check proceed thank,issue,positive,positive,neutral,neutral,positive,positive
478199540,"Yes, you found a bug - it should have been `{k}` and not `k`! Good one, @RohitMidha23 

And the rest of your analysis is correct.

So what you're proposing is this:
```
diff --git a/fastai/gen_doc/nbdoc.py b/fastai/gen_doc/nbdoc.py
index 1876e4ba..5daf55bb 100644
--- a/fastai/gen_doc/nbdoc.py
+++ b/fastai/gen_doc/nbdoc.py
@@ -59,7 +59,7 @@ def type_repr(t):
     else: return link_type(t)

 def partial_repr(t):
-    args = (t.func,) + t.args + tuple([f'k={link_type(v)}' for k,v in t.keywords.items()])
+    args = (t.func,) + t.args + tuple([f'{k}={v}' for k,v in t.keywords.items()])
     reprs = ', '.join([link_type(o) for o in args])
     return f'<code>partial(</code>{reprs}<code>)</code>'
```
I rebuilt all nbs and indeed only these 2 entries got modified and they look correct now.

Excellent job, @RohitMidha23.

So next please submit a PR for that code https://docs.fast.ai/dev/git.html#how-to-make-a-pull-request-pr and we will merge it and fix the broken docs automatically - no need to change the docs in your PR that is.",yes found bug good one rest analysis correct git index else return return code partial code rebuilt indeed got look correct excellent job next please submit code merge fix broken automatically need change,issue,positive,positive,positive,positive,positive,positive
478178034,"@stas00 correct me if I'm wrong and I know this is slightly naive but the function `partial_repr` is called only when the object is of instance `partial` as can be seen from this [line](https://github.com/fastai/fastai/blob/255ebe536659a70d7b09dc0d5831fd6331bf6253/fastai/gen_doc/nbdoc.py#L51). 

The thing to note is that only 5 functions use `partial` in their methods. All of these functions have integer arguments as their second and third arguments and hence the function `link_type` is of no use for this particular function, from my understanding. 

When I changed the code in `nbdoc` as I proposed above and built the docs, the `nbdiff` showed only two changes, for `perspective_warp` and `symmetric_warp`. 

The output of nbdiff I got was : 
![Screenshot 2019-03-30 at 4 28 40 AM](https://user-images.githubusercontent.com/38888530/55267326-8c65ab00-52a7-11e9-9c2b-f9142ac96ead.png)
",correct wrong know slightly naive function object instance partial seen line thing note use partial integer second third hence function use particular function understanding code built two output got,issue,negative,negative,negative,negative,negative,negative
478163060,"Without looking at the outcome of this proposed change, if you are removing `link_type` function call, most likely it's going to affect every other situation where there are no nested default values - which is 99% of cases. Perhaps the code could detect that it's a nested definition and encode it as an independent string?

I suggest that while you fix these 2 oddities, you pay close attention that other functions' md/html docstrings don't get impacted.",without looking outcome change removing function call likely going affect every situation default perhaps code could detect definition encode independent string suggest fix pay close attention get impacted,issue,negative,neutral,neutral,neutral,neutral,neutral
478159510,"@stas00 I figured it out to an extent. 
In this line [here](https://github.com/fastai/fastai/blob/62834a277a266c48ebb5e5828e0cca0c36fe86d6/fastai/gen_doc/nbdoc.py#L62) we call `link_type(v)`. For perspective_warp, `size = 8` is the second argument. So when we call `link_type(v)` it gives 8 back as `8`. And now in that line, k = `8`. The problem arises when we call `link_type(v)` again in the next [line](https://github.com/fastai/fastai/blob/62834a277a266c48ebb5e5828e0cca0c36fe86d6/fastai/gen_doc/nbdoc.py#L63). This returns it with an extra \`.
Therein lies our problem. 
Further what has been missed out is that k is actually `size` and hence we should be calling link_type for `k` too. Thereby making this [line](https://github.com/fastai/fastai/blob/62834a277a266c48ebb5e5828e0cca0c36fe86d6/fastai/gen_doc/nbdoc.py#L62) : 
```python 
args = (t.func,) + t.args + tuple([f'{link_type(k)}={link_type(v)}' for k,v in t.keywords.items()])
```
However by following the logic above we get a pair of extra \` which surround the `=`. 
Hence our output looks like : 
![Screenshot 2019-03-30 at 3 05 31 AM](https://user-images.githubusercontent.com/38888530/55263946-bebbdc00-5298-11e9-920d-1cdf79555c4b.png)

With the current code, the simplest solution would be to change this [line](https://github.com/fastai/fastai/blob/62834a277a266c48ebb5e5828e0cca0c36fe86d6/fastai/gen_doc/nbdoc.py#L62) to : 
```python
args = (t.func,) + t.args + tuple([f'{k}={v}' for k,v in t.keywords.items()])
```
Hence our output would look like : 
![Screenshot 2019-03-30 at 3 08 27 AM](https://user-images.githubusercontent.com/38888530/55264357-0c851400-529a-11e9-807a-16f8578b68b8.png)

",figured extent line call size second argument call back line problem call next line extra therein problem actually size hence calling thereby making line python however following logic get pair extra surround hence output like current code solution would change line python hence output would look like,issue,negative,neutral,neutral,neutral,neutral,neutral
478107542,"> I think that `***` is there by design, but I don't know why. Is it `**` + `*` bold+italic?
> It was added in this PR: #1515 fixing the backticks which weren't getting rendered.

@stas00 you're right, I hadn't thought of that. I've fixed it in that case also. The only other problem now would be the extra `` . 

> Also we should probably stick to a clean markdown so also replacing `<code>` with ` everywhere: e.g now we have a mix of both: ` <code>symmetric_warp</code>(**`c`**, **`magnitude`**:<code>partial(</code>[`

I'm not sure why but I think the `<code>` was used for a specific reason. Maybe @bearpelican can clarify more on that. 
",think design know added fixing getting right thought fixed case also problem would extra also probably stick clean markdown also code everywhere mix code magnitude code partial sure think code used specific reason maybe clarify,issue,negative,positive,positive,positive,positive,positive
478098453,"> @stas00 I'm able to get rid of the ***. Minor change in format_param, yes.

careful that other things don't break though.

I think that `***` is there by design, but I don't know why. Is it `**` + `*` bold+italic? 
It was added in this PR: https://github.com/fastai/fastai/pull/1515 fixing the backticks which weren't getting rendered.

Also we should probably stick to a clean markdown so also replacing `<code>` with \` everywhere:  e.g now we have a mix of both: ` <code>symmetric_warp</code>(**`c`**, **`magnitude`**:<code>partial(</code>[`
",able get rid minor change yes careful break though think design know added fixing getting also probably stick clean markdown also code everywhere mix code magnitude code partial,issue,positive,positive,positive,positive,positive,positive
478078686,"@stas00 I'm able to get rid of the ***. Minor change in `format_param`, yes. 
If we remove `code_esc()` from [here](https://github.com/fastai/fastai/blob/35b640d45963967e8b0202e7223c054d56f3b1e4/fastai/gen_doc/nbdoc.py#L34) to make it just `if include_bt: arg_name = arg_name`, it works, not really sure why. However that will make changes in a lot of places.  @bearpelican Can you suggest a work around? ",able get rid minor change yes remove make work really sure however make lot suggest work around,issue,positive,positive,positive,positive,positive,positive
478040686,"Yes, an extraneous \`\` and 2 \*\*\*:
```
***`0`***
***`False`***
```

I have no idea how it came to be. @bearpelican is the magician in charge! ;)

The general area is `fastai/gen_doc/nbdoc.py`, e.g. `format_param` generates those quoted above.",yes extraneous false idea came magician charge general area,issue,negative,negative,negative,negative,negative,negative
477999381,Thanks for flagging! It's fixed in master now.,thanks flagging fixed master,issue,negative,positive,positive,positive,positive,positive
477999178,"> I think the rest of the places where it's in the docs will be updated during a rebuild yes. Merging. Will follow up with two more details: the import in core should be in imports.core and then the new type alias needs to be in the dictionary for pretty printing in the docs.

Will keep that in mind for next time, thanks!

> All done, thanks a lot for your work @bachsh !

It's been a real pleasure!",think rest rebuild yes follow two import core new type alias need dictionary pretty printing keep mind next time thanks done thanks lot work real pleasure,issue,positive,positive,positive,positive,positive,positive
477998526,"As mentioned in the [docstring](https://github.com/fastai/fastai/blob/7d0ca5152c0af43dd195988cdc7efa0c772bd1db/fastai/vision/models/xception.py#L42), there is no pretrained model for this, it's experimental. So you can't use it with `conv_learner`.",model experimental ca use,issue,negative,positive,neutral,neutral,positive,positive
477997990,"All done, thanks a lot for your work @bachsh !
Here is the [follow-up commit](https://github.com/fastai/fastai/commit/7d0ca5152c0af43dd195988cdc7efa0c772bd1db)",done thanks lot work commit,issue,positive,positive,positive,positive,positive,positive
477993949,I think the rest of the places where it's in the docs will be updated during a rebuild yes. Merging. Will follow up with two more details: the import in core should be in imports.core and then the new type alias needs to be in the dictionary for pretty printing in the docs.,think rest rebuild yes follow two import core new type alias need dictionary pretty printing,issue,positive,positive,positive,positive,positive,positive
477987835,"The pretrained transformer model is the first one from openAI, so it uses a different tokenization from fastai. This is probably why you have this bug. Let's continue the conversation on [the forum](https://forums.fast.ai/)",transformer model first one different probably bug let continue conversation forum,issue,negative,positive,positive,positive,positive,positive
477984630,"> the doc nbs need to be updated. I pasted the link with instructions earlier: https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs

Not sure what to update. The docs should update automatically when you generate them, shouldn't they? 

> > > might need to do some grep'ing for the modified functions to catch any examples in docs where `fname` is used (but shouldn't be many instances if any). Also under `examples/`.
> > 
> > 
> > Found a few instances and eliminated them.
> 
> I didn't see the commit, unless it was earlier already, right?

These examples where in the docs (`basic_train.ipynb` and `text.ipynb`)",doc need pasted link sure update update automatically generate might need catch used many also found see commit unless already right,issue,positive,positive,positive,positive,positive,positive
477981156,"@stas00 from what I was able to gather the syntax in the metadata of the notebook should look like : 
```
> <code>symmetric_warp</code>(**`c`**, **`magnitude`**:<code>partial(</code>[`uniform`](/torch_core.html#uniform), `k=`4<code>)</code>=**`0`**, **`invert`**=**`False`**) → [`Image`](/vision.image.html#Image) :: [`TfmCoord`](/vision.image.html#TfmCoord)\n 
```
to generate : 
> <code>symmetric_warp</code>(**`c`**, **`magnitude`**:<code>partial(</code>[`uniform`](/torch_core.html#uniform), `k=`4<code>)</code>=**`0`**, **`invert`**=**`False`**) → [`Image`](/vision.image.html#Image) :: [`TfmCoord`](/vision.image.html#TfmCoord)\n

But the notebook metadata currently is : 
```     
> <code>symmetric_warp</code>(**`c`**, **`magnitude`**:<code>partial(</code>[`uniform`](/torch_core.html#uniform), `k=`4``<code>)</code>=***`0`***, **`invert`**=***`False`***) → [`Image`](/vision.image.html#Image) :: [`TfmCoord`](/vision.image.html#TfmCoord)\n
```
 which generates the issue. 

Working on finding the function that does this now. @bearpelican if you can point me to that it'll be massively helpful!",able gather syntax notebook look like code magnitude code partial uniform uniform code invert false image image generate code magnitude code partial uniform uniform code invert false image image notebook currently code magnitude code partial uniform uniform code invert false image image issue working finding function point massively helpful,issue,positive,negative,negative,negative,negative,negative
477910274,Can someone clearly post the solution.. i am also facing same issue,someone clearly post solution also facing issue,issue,positive,positive,positive,positive,positive,positive
477809281,"
> > might need to do some grep'ing for the modified functions to catch any examples in docs where `fname` is used (but shouldn't be many instances if any). Also under `examples/`.
> 
> Found a few instances and eliminated them.

I didn't see the commit, unless it was earlier already, right?

",might need catch used many also found see commit unless already right,issue,negative,positive,positive,positive,positive,positive
477809082,the doc nbs need to be updated. I pasted the link with instructions earlier:  https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs,doc need pasted link,issue,negative,neutral,neutral,neutral,neutral,neutral
477800163,"That's amazing! 
Thanks for linking me to the resources. I'll get started ASAP. 
",amazing thanks linking get,issue,positive,positive,positive,positive,positive,positive
477798152,"> Perhaps add the doc change into this same PR and we will merge it as one change? If you're comfortable updating the docs that is.

I updated the docstrings. What other docs need changing?

> 
> might need to do some grep'ing for the modified functions to catch any examples in docs where `fname` is used (but shouldn't be many instances if any). Also under `examples/`.

Found a few instances and eliminated them.

> 
> Oh and please add a new entry into CHANGES.md

Thanks, done.",perhaps add doc change merge one change comfortable need might need catch used many also found oh please add new entry thanks done,issue,positive,positive,positive,positive,positive,positive
477793952,"The code + tests looks good, @bachsh. Thank you.

Perhaps add the doc change into this same PR and we will merge it as one change? If you're comfortable updating the docs that is.

might need to do some grep'ing for the modified functions to catch any examples in docs where `fname` is used (but shouldn't be many instances if any). Also under `examples/`.

Oh and please add a new entry into CHANGES.md",code good thank perhaps add doc change merge one change comfortable might need catch used many also oh please add new entry,issue,positive,positive,positive,positive,positive,positive
477793223,"> Just a few small suggestions, but otherwise looks great, @bachsh

Done.",small otherwise great done,issue,positive,positive,positive,positive,positive,positive
477792709,"I added just a few small suggestions, but otherwise looks great, @bachsh.

And we probably should adjust the docs next. https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs",added small otherwise great probably adjust next,issue,positive,positive,positive,positive,positive,positive
477788369,"Yes, of course, @RohitMidha23.

First you need to set things up: https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs

Then learn how to build the docs: https://docs.fast.ai/gen_doc_main.html#building-the-documentation-website

Then you can look at the code under `fastai/gen_doc/` to identify where things go wrong in the doc generator.

@bearpelican developed most of it, so you may have to ask him questions if you get stuck and he is up for helping you and not just fixing it himself.",yes course first need set learn build look code identify go wrong doc generator may ask get stuck helping fixing,issue,negative,negative,negative,negative,negative,negative
477784059,Can I work on this issue? First time trying it out but I would love to try!,work issue first time trying would love try,issue,positive,positive,positive,positive,positive,positive
477782674,"Done. Updated the tests accordingly. Ended up calling the new type:
`PathLikeOrBinaryStream = Union[PathOrStr, BufferedWriter, BytesIO]`
It includes `BufferedWriter` because it is also possible to put a file stream inside",done accordingly ended calling new type union also possible put file stream inside,issue,negative,positive,neutral,neutral,positive,positive
477750957,"Thank you for reporting this documentation problem, @RohitMidha23.

It looks like a bug in the doc converter. It affects at least:
* https://docs.fast.ai/vision.transform.html#_symmetric_warp
* https://docs.fast.ai/vision.transform.html#_perspective_warp

@bearpelican, can you please have a look? The source nb looks correct, but once it's converted it gets messed up.

It looks like it can't handle the extra key=val inside `partial` type - e.g. , it works without the key in `_dihedral_affine` below, but not in `_perspective_warp` that has the arg name:

```
def _dihedral_affine(k:partial(uniform_int,0,7)):
def _perspective_warp(c, magnitude:partial(uniform,size=8)=0, invert=False):
```",thank documentation problem like bug doc converter least please look source correct converted like ca handle extra inside partial type work without key name partial magnitude partial uniform,issue,negative,negative,neutral,neutral,negative,negative
477689364,"> No need to apologize, it's best to have this decision after a thorough discussion.
> 
> I hope to get to this later today, I'm still contemplating on the name for the Type `Union[PathOrStr, BytesIO]`. WDYT?

That works. 

Or alternatively, define:

`PathOrStrOrBytesIO = Union[Path,str,BytesIO]` in `fastai/core.py`.",need apologize best decision thorough discussion hope get later today still name type union work alternatively define union path,issue,positive,positive,positive,positive,positive,positive
477689033,"I don't know the sizes of your datasets, but I've never went OOM, even when tokenizing the whole of wikipedia, so it's a bit of a stretch to say that everyone will be hit by this issue.
Tokenizing gigantic text datasets must be done with a different API to load the data. There are suggestions on the forum for this.",know size never went even whole bit stretch say everyone hit issue gigantic text must done different load data forum,issue,negative,positive,neutral,neutral,positive,positive
477546295,"@sgugger  Sorry for not replying on the thread.
I solve the issue by taking a VM with Big RAM.
As mfojtak is saying everyone is going to hit by this issue. I have not yet tried the solution you propose of doing tokenization outside fast ai.

I am fine in closing this issue, if it doesn't make sense to fix this in fast ai.

Thanks for the help.",sorry thread solve issue taking big ram saying everyone going hit issue yet tried solution propose outside fast ai fine issue make sense fix fast ai thanks help,issue,positive,positive,neutral,neutral,positive,positive
477483970,"No need to apologize, it's best to have this decision after a thorough discussion.

I hope to get to this later today, I'm still contemplating on the name for the Type `Union[PathOrStr, BytesIO]`. WDYT?",need apologize best decision thorough discussion hope get later today still name type union,issue,positive,positive,positive,positive,positive,positive
477405049,"So it looks like we have come to an agreement to not add a new arg but to overload `fname` arg and rename it to `file`. I hope that's OK with you, @bachsh. Apologies for conflicting messages - I personally wasn't aware of that prior discussion at the forums.

So we will now have an arg `file` similar to numpy and pickle:

`file`: file-like object, string, or pathlib.Path",like come agreement add new overload rename file hope conflicting personally aware prior discussion file similar pickle file object string,issue,positive,positive,neutral,neutral,positive,positive
477385888,"I don't follow your reasoning. But I'm OK with it, everybody is used to breaking changes by now.

So we just need to decide on the new arg name then. I listed all the existing options I found here https://github.com/fastai/fastai/pull/1893#issuecomment-477379507, I'm not attached to any of them as long as they are symmetrical (i.e. same arg name for save/load).

`file` seems to be the most commonly used",follow reasoning everybody used breaking need decide new name listed found attached long symmetrical name file commonly used,issue,negative,negative,neutral,neutral,negative,negative
477385237,"If we break something, I'd rather do it now than later.",break something rather later,issue,negative,neutral,neutral,neutral,neutral,neutral
477384884,"My vote is to keep `fname` for now, adding the io support to it. and schedule a rename to a more suitable name once part2 is over - 5 weeks from now, when there will be a huge number of breaking changes.

Pros:

    - very minor change to the codebase and docs
    - not breaking user's code
    - support new functionality

Cons:

    - unintuitive arg name for the next 5 weeks.
",vote keep io support schedule rename suitable name part huge number breaking minor change breaking user code support new functionality unintuitive name next,issue,positive,positive,positive,positive,positive,positive
477381277,"> +1 for `source`.
> I don't like overloading `fname`, even in the interim. We can bump the minor version to 1.1.0 to make this breaking change noticeable, WDYT?

If we were to bump the minor version for all the API changes we would have been at 1.99.0 now. ;)

note, I've been updating one earlier comment of mine with different conventions in major python libs.
https://github.com/fastai/fastai/pull/1893#issuecomment-477379507
if you can think of any other major libs and bring their naming that would be helpful.

That doesn't mean we can't choose a different name, but my feeling is that those folks have already thought hard about it and it's easier on users when a similar convention is used across different libs.
",source like even interim bump minor version make breaking change noticeable bump minor version would note one comment mine different major python think major bring naming would helpful mean ca choose different name feeling already thought hard easier similar convention used across different,issue,positive,negative,neutral,neutral,negative,negative
477380263,"> let's mimic torch.save/torch.load and call it `f`. That's the easiest IMHO.

I don't like this name which implies file, but I'm ok with it.

Naming suggestions for the new Type: `Union[Path, str, BytesIO]`? ",let mimic call easiest like name file naming new type union path,issue,positive,positive,positive,positive,positive,positive
477379507,"> Sure, source for loading functions, and target or dest for save/export.

That'd be confusing if you think of it from the perspective of the user code. But it'd work.

what other major libraries w/ the same functionality `save`/`load` that we could copy a good naming strategy from?
* torch: `f`
* pickle: `file`
* json: `fp`
* tensorflow: supports only files
* numpy: `file`

I think `file` is winning so far.

`handle` is potentially another name used in some interfaces.

numpy's doc: `file : file-like object, string, or pathlib.Path`",sure source loading target think perspective user code work major functionality save load could copy good naming strategy torch pickle file file think file winning far handle potentially another name used doc file object string,issue,positive,positive,positive,positive,positive,positive
477379173,"Sure, `source` for loading functions, and `target` or `dest` for `save`/`export`.",sure source loading target save export,issue,positive,positive,positive,positive,positive,positive
477378886,"it's source for load, but dest for save - `save(source)` reads weird, no?

torch calls it 'f' 
> f – a file-like object (has to implement write and flush) or a string containing a file name",source load save save source weird torch object implement write flush string file name,issue,positive,negative,negative,negative,negative,negative
477378619,"+1 for `source`.
I don't like overloading `fname`, even in the interim. We can bump the minor version to 1.1.0 to make this breaking change noticeable, WDYT?",source like even interim bump minor version make breaking change noticeable,issue,negative,negative,neutral,neutral,negative,negative
477378324,Perhaps for now overload `fname` (keeping its name)and then before the major API change after part2 rename it to something more generic when a lot of things will be renamed anyway.,perhaps overload keeping name major change part rename something generic lot anyway,issue,negative,positive,neutral,neutral,positive,positive
477378182,"Trying to avoid unnecessary changes but if you want to break everything, be my guest ;) Let's rename it source then?",trying avoid unnecessary want break everything guest let rename source,issue,negative,negative,negative,negative,negative,negative
477377789,"Honestly, I think using the same argument is preferable. It's consistent with how `torch.save` works. I implemented it the way you asked for, Sylvain, but if you change your mind please lmk and I'll refactor.",honestly think argument preferable consistent work way change mind please,issue,negative,positive,positive,positive,positive,positive
477377470,"Yes, but we can rename it to something more generic.

The proposed change for example makes:

...`name:PathOrStr=None, return_path:bool=False, with_opt:bool=True, buffer:io.BytesIO=None)`

with 2 similar arguments being far apart, at the very least put them next to each other?

I get lost when sometimes you guys are totally OK with changing and renaming APIs and at other times bolting things on top, without improving the API. 

p.s. I'm in no way opposing this change, it just looks bad.",yes rename something generic change example name buffer similar far apart least put next get lost sometimes totally time bolting top without improving way opposing change bad,issue,negative,negative,neutral,neutral,negative,negative
477376849,"We had that discussion on the forum, I was the one who asked for a different name since some users use fname (me for instance ;) )",discussion forum one different name since use instance,issue,negative,neutral,neutral,neutral,neutral,neutral
477376278,"Any reason why we need a new arg and not just check whether destination is an instance of str or pathlib or io.BytesIO and act accordingly?

Except, I guess the current one is named `fname`, so it doesn't lend itself for various types of destinations. Given that most people don't set the arg name in `save` and just use the ordered arg, perhaps rename it to `target` or `dest` or `where`?",reason need new check whether destination instance act accordingly except guess current one lend various given people set name save use ordered perhaps rename target,issue,negative,positive,neutral,neutral,positive,positive
477301420,Closing this since there is no news in a week and we can't reproduce. Feel free to reopen if the bug persists on master with a reproducible example.,since news week ca reproduce feel free reopen bug master reproducible example,issue,positive,positive,positive,positive,positive,positive
477301148,Thanks! Next time you can suggest a PR directly to fix the mistake ;),thanks next time suggest directly fix mistake,issue,negative,positive,positive,positive,positive,positive
477144698,Closing this since no news in a week. Feel free to reopen with more details (the issue template contains all the information we need from you to be able to sole the bug).,since news week feel free reopen issue template information need able sole bug,issue,positive,positive,positive,positive,positive,positive
477134781,"An other solution that worked for me is to add sort = False argument to splits method as shown below:

train_iterator, valid_iterator, test_iterator = data.BucketIterator.splits(
    (train_data, valid_data, test_data), sort = False,
    batch_size=BATCH_SIZE,
    device=device)",solution worked add sort false argument method shown sort false,issue,negative,negative,negative,negative,negative,negative
476950812,"Thank you for the suggestion, I rewrote the hooks with `Hooks` class. It's quite handy!",thank suggestion class quite handy,issue,negative,positive,positive,positive,positive,positive
476880457,"This is not a bug, the test set in fastai is unlabeled. See the docs [here](https://docs.fast.ai/data_block.html#Add-a-test-set).",bug test set unlabeled see,issue,negative,neutral,neutral,neutral,neutral,neutral
476648357,"Oh yeah, I had forgotten about that. `PooledSelfAttention` seems like a great name! Thanks for this contribution, will merge once the tests are clear.",oh yeah forgotten like great name thanks contribution merge clear,issue,positive,positive,positive,positive,positive,positive
476646091,"```conv1d``` (the old code) also applies spectral norm

But I totally agree that SelfAttention is not a great name for this layer and maybe ```NonLocal``` or ```PooledSelfAttention``` are better",old code also spectral norm totally agree great name layer maybe nonlocal better,issue,positive,positive,positive,positive,positive,positive
476621508,"Thanks, just put the docstring on one line. Merging this, can you please now add full documentation for these new functions in metrics.ipynb?",thanks put one line please add full documentation new,issue,positive,positive,positive,positive,positive,positive
476615262,With have an `HookOutput` class (in callbacks.hook) that could be useful here and make it a bit shorter.,class could useful make bit shorter,issue,negative,positive,positive,positive,positive,positive
476614097,"Those are quite big changes, so I think we should have a new layer for it. I know people were using the current SelfAttention layer and I don't want to break anything for them. Since you have the spectral norm inside we can maybe call it SpectralNormedSelfAttention? Or something like that?",quite big think new layer know people current layer want break anything since spectral norm inside maybe call something like,issue,negative,positive,neutral,neutral,positive,positive
476369392,"This has been fixed since then, please try again with the most recent version (1.0.50) and reopen if the problem persists.

Normally now, after doing `torch.cuda.set_device(1) `, your `defaults.device` should point to that device.",fixed since please try recent version reopen problem normally point device,issue,negative,positive,neutral,neutral,positive,positive
476264091,Found the reason: the ReLU activation was the same object repeated and not different objects. Fixed now.,found reason activation object repeated different fixed,issue,negative,positive,neutral,neutral,positive,positive
476244082,"Just noticed that ReLU does not show up `learn.layer_groups` as well.

```python
learn = tabular_learner(data,layers=[300,200,100], ps=[.6]*3)
learn.layer_groups
```
```text
[Sequential(
   (0): ModuleList()
   (1): Dropout(p=0.0)
   (2): BatchNorm1d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
   (3): Linear(in_features=39, out_features=300, bias=True)
   (4): ReLU(inplace)
   (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
   (6): Dropout(p=0.6)
   (7): Linear(in_features=300, out_features=200, bias=True)
   (8): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
   (9): Dropout(p=0.6)
   (10): Linear(in_features=200, out_features=100, bias=True)
   (11): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
   (12): Dropout(p=0.6)
   (13): Linear(in_features=100, out_features=1, bias=True)
 )]
```
 As you pointed out  the ReLU modules show up in `learn.model` printout.
```python
learn.model
```
```textTabularModel(
  (embeds): ModuleList()
  (emb_drop): Dropout(p=0.0)
  (bn_cont): BatchNorm1d(39, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (layers): Sequential(
    (0): Linear(in_features=39, out_features=300, bias=True)
    (1): ReLU(inplace)
    (2): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (3): Dropout(p=0.6)
    (4): Linear(in_features=300, out_features=200, bias=True)
    (5): ReLU(inplace)
    (6): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (7): Dropout(p=0.6)
    (8): Linear(in_features=200, out_features=100, bias=True)
    (9): ReLU(inplace)
    (10): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (11): Dropout(p=0.6)
    (12): Linear(in_features=100, out_features=1, bias=True)
  )
)


```",show well python learn data text sequential dropout linear dropout linear dropout linear dropout linear pointed show python dropout sequential linear dropout linear dropout linear dropout linear,issue,negative,neutral,neutral,neutral,neutral,neutral
476195240,"Note that the bug is in `Learner.summary`. I can reproduce but when I type `learn.model`, the ReLUs are all there. I don't know why they aren't printed in the summary, will investigate.",note bug reproduce type know printed summary investigate,issue,negative,neutral,neutral,neutral,neutral,neutral
476073200,"> ok I solve this problem by cast target= target.long() into layers.py in the class FlattenedLoss, and the same for accuraccy in metrics

Hi,
Experiencing the exact same problem. Could you please paste your updated classes after making changes? Thanks.
",solve problem cast class metric hi exact problem could please paste class making thanks,issue,negative,positive,positive,positive,positive,positive
475969580,"
If it's still an issue, let's continue troubleshooting it at this dedicated forum thread:
http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111",still issue let continue forum thread,issue,negative,neutral,neutral,neutral,neutral,neutral
475956199,"Thanks. I've forced it this time because it was simple, but please remember to follow [all the instructions here](https://docs.fast.ai/gen_doc_main.html#step-2-setup) for next time, especially the line 
```
tools/run-after-git-clone  # or python tools\run-after-git-clone on windows
```
otherwise your notebooks arrive not properly stripped to us.",thanks forced time simple please remember follow next time especially line python otherwise arrive properly stripped u,issue,negative,negative,neutral,neutral,negative,negative
475922287,"This is not a fastai issue, but something is wrong with your conda setup

> PermissionError: [Errno 13] Permission denied: '/home/frank/anaconda3/.condatmp'

What's your:

`ls -l /home/frank | grep anaconda3`

Make sure it's writable/executable. Try `chmod u+xrw /home/frank/anaconda3`

Also check if perhaps you already have `/home/frank/anaconda3/.condatmp` and it's not writable, do the same as above to fix it if it's.

Also see:
https://github.com/pytorch/pytorch/issues/12758#issuecomment-444075152

And if that's not enough here is more:
https://www.google.com/search?q=PermissionError:+%5BErrno+13%5D+Permission+denied:+%27/.%22condatmp%27%22

",issue something wrong setup permission anaconda make sure try also check perhaps already writable fix also see enough,issue,negative,neutral,neutral,neutral,neutral,neutral
475914795,"You are right my solution only works for my issue, not a good solution. I will fix the `labels_from_df` to force into string always.",right solution work issue good solution fix force string always,issue,positive,positive,positive,positive,positive,positive
475914121,"I'm sorry if I was unclear: as you say there are two ways to fix this, having the ints be ints whenever possible or casting them to strings. The first one breaks the tests (think of a situation when one label is 0, the other one is seven) so I was indicating I'd prefer the second way, which is why I closed the PR. It doesn't prevent us discussing it further like this.

You are more than welcome to suggest a new PR that ensures everything is always cast to strings, which would solve your problems without breaking the library (make sure to run the tests if possible, before pushing your PR).",sorry unclear say two way fix whenever possible casting first one think situation one label one seven prefer second way closed prevent u like welcome suggest new everything always cast would solve without breaking library make sure run possible pushing,issue,positive,positive,positive,positive,positive,positive
475912189,"A bit too early to be closing the PR...

Both `label_from_folder` and `label_from_df` work as expected independently. However, for my specific case, I am using the data block API from different datasets to aggregate them as I explained in the forum to you. An example I create a training dataset using csv file and validation dataset from folder. This is where the methods are inconsistent which each other. Internally `labels_from_folder` convers the folders names o.parts[-2] as strings and then sorts this strings to create a idx label to class name mapping.`labels_from_df` on the other hand does not enforce the column of labels to be string. In my case the column is full of integer values. Hence internally they are sorted as int to then create the i2c mapping. Sadly in python sorting string of numbers and sorting ints of numbers don't produce the same order. Example strings are sorted as 010 going before 002. This inconsistency prohibits me and possible others to use the data block API to interchangeably mix from csv with from folder, cuz they both have different behavior. For my case, the mapping of the training is different than the one for the validation even if they all have the same class names. This is because df treats them as ints and  from_folder treats them as strings. To solve this I created this PR where from_folder is converted into ints when it can.  Another solution is too force the `labels_from_df` to be converted into strings, cuz right now the type is infer.

Any of this two solutions should fix it. I can assure you mine has it's intended behaviour as I am using it in my code. Without it it will train but the mapping of train and val will be wrong and it will not learn.",bit early work independently however specific case data block different aggregate forum example create training file validation folder inconsistent internally create label class name hand enforce column string case column full integer hence internally sorted create sadly python string produce order example sorted going inconsistency possible use data block interchangeably mix folder different behavior case training different one validation even class solve converted another solution force converted right type infer two fix assure mine intended behaviour code without train train wrong learn,issue,positive,negative,neutral,neutral,negative,negative
475907299,"This is making the tests fail so it's breaking something. I'm not sure I understand when you have ints as label? The API is designed to have them be strings all the time, so I'd be curious where you get them, and this is probably the part that needs fixing.",making fail breaking something sure understand label designed time curious get probably part need fixing,issue,negative,negative,neutral,neutral,negative,negative
475864085,"Please follow the template when filing an issue. I'm not trying to be mean, but we can't fix a bug if we don't see at least:
- the code you're running
- the full error message
- your installation details
and ideally a minimal reproducible example.

This looks like #1858 so it may be fixed in master already. Feel free to reopen with all the necessary details.",please follow template filing issue trying mean ca fix bug see least code running full error message installation ideally minimal reproducible example like may fixed master already feel free reopen necessary,issue,positive,positive,neutral,neutral,positive,positive
475858879,"@sgugger Can you please guide me on exactly where and which file do you set defaults.cpus=1?
Thanks :)",please guide exactly file set thanks,issue,positive,positive,positive,positive,positive,positive
475804957,"No I used the following function:

```
    def load_wiki_data(self, bs=70):
        self.model_dir.mkdir(exist_ok=True, parents=True)
        trn_path = self.dataset_path / f'{self.lang}.wiki.train.tokens'
        val_path = self.dataset_path / f'{self.lang}.wiki.valid.tokens'
        tst_path = self.dataset_path / f'{self.lang}.wiki.test.tokens'
        for path_ in [trn_path, val_path, tst_path]:
            assert path_.exists(), f'Error: {path_} does not exist.'

        args = self.tokenizer_to_fastai_args(sp_data_func=self.load_train_text, use_moses=False)

        data_lm = self.lm_databunch(""lm"",
                          train_df=read_wiki_articles(trn_path),
                          valid_df=read_wiki_articles(val_path),
                          classes=None,
                          bs=bs,
                          text_cols='texts',
                          bptt=self.bptt,
                          **args)

        itos, stoi, trn_path = data_lm.vocab.itos, data_lm.vocab.stoi, data_lm.path
        print('Size of vocabulary:', len(itos))
        #print('First 20 words in vocab:', data_lm.vocab.itos[:20])
        return data_lm
```

**Update:** This hack worked when adding it to the above function",used following function self assert exist print vocabulary print return update hack worked function,issue,negative,neutral,neutral,neutral,neutral,neutral
475801525,"Did you use `load_data` to load your data? It might be linked to that since the functionality was added recently. You can hack your way around it by adding the attributes manually to `data.single_ds.x.processor`. I think the tokenize processor might be the first one, so you would go:
```
data.single_ds.x.processor[0].include_bos=True
data.single_ds.x.processor[0].include_eos=False
```",use load data might linked since functionality added recently hack way around manually think processor might first one would go,issue,negative,positive,positive,positive,positive,positive
475798668,The tracker was trying to access metrics that didn't exist.,tracker trying access metric exist,issue,negative,neutral,neutral,neutral,neutral,neutral
475783490,"Yes this bug has been fixed, you should do an editable install before the next release.",yes bug fixed install next release,issue,negative,positive,neutral,neutral,positive,positive
475782526,"No problem, thank you for closing it. What was the root cause?",problem thank root cause,issue,negative,neutral,neutral,neutral,neutral,neutral
475778183,"Sorry, now when running 

```
learn.load('lm_best_with_opt');
learn.save_encoder('testing_enc')
```
which flags:
```
/efs/data/jpb/fastai/fastai/fastai/basic_train.py:323: UserWarning: Wasn't able to properly load the optimizer state again.
  except: warn(""Wasn't able to properly load the optimizer state again."")
```

then
```
print(""\n"".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))
```

gives the following error:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-38-135dd315cd3b> in <module>
----> 1 print(""\n"".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))

<ipython-input-38-135dd315cd3b> in <genexpr>(.0)
----> 1 print(""\n"".join(learn.predict(TEXT, N_WORDS, temperature=0.75) for _ in range(N_SENTENCES)))

/efs/data/jpb/fastai/fastai/fastai/text/learner.py in predict(self, text, n_words, no_unk, temperature, min_p, sep, decoder)
    119         ds = self.data.single_dl.dataset
    120         self.model.reset()
--> 121         xb,yb = self.data.one_item(text)
    122         new_idx = []
    123         for _ in range(n_words): #progress_bar(range(n_words), leave=False):

/efs/data/jpb/fastai/fastai/fastai/basic_data.py in one_item(self, item, detach, denorm, cpu)
    178         ""Get `item` into a batch. Optionally `detach` and `denorm`.""
    179         ds = self.single_ds
--> 180         with ds.set_item(item):
    181             return self.one_batch(ds_type=DatasetType.Single, detach=detach, denorm=denorm, cpu=cpu)
    182 

~/anaconda3/envs/fastai_ulm/lib/python3.6/contextlib.py in __enter__(self)
     79     def __enter__(self):
     80         try:
---> 81             return next(self.gen)
     82         except StopIteration:
     83             raise RuntimeError(""generator didn't yield"") from None

/efs/data/jpb/fastai/fastai/fastai/data_block.py in set_item(self, item)
    594     def set_item(self,item):
    595         ""For inference, will briefly replace the dataset with one that only contains `item`.""
--> 596         self.item = self.x.process_one(item)
    597         yield None
    598         self.item = None

/efs/data/jpb/fastai/fastai/fastai/data_block.py in process_one(self, item, processor)
     80         if processor is not None: self.processor = processor
     81         self.processor = listify(self.processor)
---> 82         for p in self.processor: item = p.process_one(item)
     83         return item
     84 

/efs/data/jpb/fastai/fastai/fastai/text/data.py in process_one(self, item)
    286 
    287     def process_one(self, item):
--> 288         return self.tokenizer._process_all_1(_join_texts([item], self.mark_fields, self.include_bos, self.include_eos))[0]
    289 
    290     def process(self, ds):

AttributeError: 'TokenizeProcessor' object has no attribute 'include_bos'
```",sorry running able properly load state except warn able properly load state print text range following error recent call last module print text range print text range predict self text temperature text range range self item detach get item batch optionally detach item return self self try return next except raise generator yield none self item self item inference briefly replace one item item yield none none self item processor processor none processor item item return item self item self item return item process self object attribute,issue,negative,positive,neutral,neutral,positive,positive
475759911,"Note that in fastai the default (given by data objects) is to use flattened versions of all loss functions: `MSELossFlat` for instance. In this case there's no weird broadcasting.

I don't think the basic training loops should be changed, since it might cause problems when a user ends their model with a squeeze of the output. I'm closing this here because I really think it should be fixed on the PyTorch side.",note default given data use loss instance case weird think basic training since might cause user model squeeze output really think fixed side,issue,negative,negative,neutral,neutral,negative,negative
475757243,"Okay thanks, I've pulled the latest dev version and it's working now",thanks latest dev version working,issue,negative,positive,positive,positive,positive,positive
475756790,"Thanks! fastai speaks American English though, so I changed the name to randomize ;)
Will update the docs after the merge.",thanks though name randomize update merge,issue,negative,positive,positive,positive,positive,positive
475732349,"As indicated by the capital, `Precision` and `Recall` are classes that you need to instantiate: `Precision()` and `Recall()` will work fine ;)",capital precision recall class need precision recall work fine,issue,negative,positive,positive,positive,positive,positive
475614028,"No, this isn't linked to a `label_cls` parameter. If you want `Learner.show_results` to work, your model has to give an output that is exactly of the same format as the targets are, so a tensor of (potentially padded) `bboxes` and `labels`. (Note that `data.show_batch()` uses the same functions and should work properly.)

Otherwise you should use the model by yourself to draw the results as you want.",linked parameter want work model give output exactly format tensor potentially note work properly otherwise use model draw want,issue,negative,positive,neutral,neutral,positive,positive
475353229,"> Do not edit the docs/*html files - those are autogenerated and if you change those, your changes will get overwritten.

From: https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs

Please re-submit with edits to ipynb instead. Thanks.",edit change get please instead thanks,issue,positive,positive,positive,positive,positive,positive
475322532,"You can try my [example](https://www.kaggle.com/liuyd2018/planet-multi-label-image-classification)
I think there is no need to call 'split_none().label_empty().databunch()'

",try example think need call,issue,negative,neutral,neutral,neutral,neutral,neutral
475300286,"We autogenerate the docs about once a day, so your change will become visible on docs.fast.ai then.",day change become visible,issue,negative,neutral,neutral,neutral,neutral,neutral
475292238,"> Do not edit the docs/*html files - those are autogenerated and if you change those, your changes will get overwritten.

From: https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs

Kindly please re-submit with edits to ipynb instead. Thanks.",edit change get kindly please instead thanks,issue,positive,positive,positive,positive,positive,positive
475233549,"Are you sure you are on the latest of fastai? I just tested and the following
```
from fastai.vision import *

path = untar_data(URLs.PETS)
path_img = path/'images'
fnames = get_image_files(path_img)
pat = re.compile(r'/([^/]+)_\d+.jpg$')
src = ImageList.from_folder(path_img).split_by_rand_pct().label_from_re(pat)
src = src.transform(get_transforms(), size=(324,224), resize_method=ResizeMethod.SQUISH)
src.train
```
produces
```
LabelList (5912 items)
x: ImageList
Image (3, 324, 224),Image (3, 324, 224),Image (3, 324, 224),Image (3, 324, 224),Image (3, 324, 224)
y: CategoryList
saint_bernard,staffordshire_bull_terrier,Persian,Maine_Coon,newfoundland
Path: /home/ubuntu/notebooks/data/oxford-iiit-pet/images
```

In general, please include your installation details when filing an issue, as instructed by the template.",sure latest tested following import path pat pat image image image image image path general please include installation filing issue instructed template,issue,positive,positive,positive,positive,positive,positive
475231138,Tentative fix. Please make sure to post the issue with a full reproducible example if you want us to help. Here it's however you trained that learner before that is relevant since it doesn't manage to load the optimizer state. Tried to reproduce on my side but didn't come across a similar bug.,tentative fix please make sure post issue full reproducible example want u help however trained learner relevant since manage load state tried reproduce side come across similar bug,issue,positive,positive,positive,positive,positive,positive
475226213,"Also, you could try again if it ends up your data has no problem after a run on a single process as it may have been linked to #1846",also could try data problem run single process may linked,issue,negative,negative,neutral,neutral,negative,negative
475225879,"Pushed the fastprogress since it's the same as @ericricky and @EtienneT confirmed it worked.
@bny6613 I added the import too, in case people want to use this directly (guessing the others didn't have the problem because `get_ipython` is imported somewhere else in fastai).",since confirmed worked added import case people want use directly guessing problem somewhere else,issue,negative,positive,positive,positive,positive,positive
475221291,"Just faced this issue on Windows as well, so for me it shows that the error is: 

    NameError: name 'get_ipython' is not defined 
And simply adding 

    from IPython import get_ipython 
to the https://github.com/fastai/fastai/blob/master/fastai/utils/ipython.py solves the issue.",faced issue well error name defined simply import issue,issue,negative,neutral,neutral,neutral,neutral,neutral
475214062,"Tested your fork on windows @ericricky  and the fix seems to work!  You should push the pull request.

Thanks,",tested fork fix work push pull request thanks,issue,negative,positive,positive,positive,positive,positive
475091911,"> @stas00 Colab is just running Ubuntu under the hood, so when the code in fastai.utils.ipython runs, __name__ evaluates to 'fastai.utils.ipython' like usual.

Thank you, @ericricky - so my test was invalid and I shouldn't have merged it. Sorry about that.

Let's go with the fastprogress solution then.",running hood code like usual thank test invalid sorry let go solution,issue,positive,negative,negative,negative,negative,negative
475090964,"@stas00 Colab is just running Ubuntu under the hood, so when the code in fastai.utils.ipython runs, `__name__` evaluates to `'fastai.utils.ipython'` like usual.

@sgugger That's another option. We can just do that if you're already using it in fastprogress.

@EtienneT Can you try [my fork](https://github.com/ericricky/fastai) in Windows?",running hood code like usual another option already try fork,issue,negative,negative,negative,negative,negative,negative
475090180,"That's the part where Windows support is flunky. You should try to do the same thing with `defaults.cpus=1` to remove the multiprocessing. If you have an error in your data, you will get a clearer error message then you can do it again with multiproc.
If you don't have an error, it'll just be slower than the multiproc version.",part support flunky try thing remove error data get clearer error message error version,issue,negative,neutral,neutral,neutral,neutral,neutral
475076139,"The full error message: 

BrokenProcessPool Traceback (most recent call last)
in ()
1 # Language model data
----> 2 data_lm = TextLMDataBunch.from_df(train_df = df_trn, valid_df = df_val, path = """")
3
4 # Classifier model data
5 data_clas = TextClasDataBunch.from_df(path = """", train_df = df_trn, valid_df = df_val, vocab=data_lm.train_ds.vocab, bs=32)

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\text\data.py in from_df(cls, path, train_df, valid_df, test_df, tokenizer, vocab, classes, text_cols, label_cols, label_delim, chunksize, max_vocab, min_freq, mark_fields, include_bos, include_eos, **kwargs)
200 src = ItemLists(path, TextList.from_df(train_df, path, cols=text_cols, processor=processor),
201 TextList.from_df(valid_df, path, cols=text_cols, processor=processor))
--> 202 if cls==TextLMDataBunch: src = src.label_for_lm()
203 else: src = src.label_from_df(cols=label_cols, classes=classes, label_delim=label_delim)
204 if test_df is not None: src.add_test(TextList.from_df(test_df, path, cols=text_cols))

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\data_block.py in _inner(*args, **kwargs)
463 self.valid = fv(*args, from_item_lists=True, **kwargs)
464 self.class = LabelLists
--> 465 self.process()
466 return self
467 return _inner

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\data_block.py in process(self)
517 ""Process the inner datasets.""
518 xp,yp = self.get_processors()
--> 519 for ds,n in zip(self.lists, ['train','valid','test']): ds.process(xp, yp, name=n)
520 #progress_bar clear the outputs so in some case warnings issued during processing disappear.
521 for ds in self.lists:

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\data_block.py in process(self, xp, yp, name)
694 p.warns = []
695 self.x,self.y = self.x[~filt],self.y[~filt]
--> 696 self.x.process(xp)
697 return self
698

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\data_block.py in process(self, processor)
73 if processor is not None: self.processor = processor
74 self.processor = listify(self.processor)
---> 75 for p in self.processor: p.process(self)
76 return self
77

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\text\data.py in process(self, ds)
292 tokens = []
293 for i in progress_bar(range(0,len(ds),self.chunksize), leave=False):
--> 294 tokens += self.tokenizer.process_all(ds.items[i:i+self.chunksize])
295 ds.items = tokens
296

~\AppData\Local\Continuum\anaconda3\lib\site-packages\fastai\text\transform.py in process_all(self, texts)
118 if self.n_cpus <= 1: return self._process_all_1(texts)
119 with ProcessPoolExecutor(self.n_cpus) as e:
--> 120 return sum(e.map(self._process_all_1, partition_by_cores(texts, self.n_cpus)), [])
121
122 class Vocab():

~\AppData\Local\Continuum\anaconda3\lib\concurrent\futures\process.py in _chain_from_iterable_of_lists(iterable)
364 careful not to keep references to yielded objects.
365 """"""
--> 366 for element in iterable:
367 element.reverse()
368 while element:

~\AppData\Local\Continuum\anaconda3\lib\concurrent\futures_base.py in result_iterator()
584 # Careful not to keep a reference to the popped future
585 if timeout is None:
--> 586 yield fs.pop().result()
587 else:
588 yield fs.pop().result(end_time - time.time())

~\AppData\Local\Continuum\anaconda3\lib\concurrent\futures_base.py in result(self, timeout)
430 raise CancelledError()
431 elif self._state == FINISHED:
--> 432 return self.__get_result()
433 else:
434 raise TimeoutError()

~\AppData\Local\Continuum\anaconda3\lib\concurrent\futures_base.py in __get_result(self)
382 def __get_result(self):
383 if self._exception:
--> 384 raise self._exception
385 else:
386 return self._result

BrokenProcessPool: A process in the process pool was terminated abruptly while the future was running or pending.",full error message recent call last language model data path classifier model data path path class path path path else none path return self return process self process inner zip clear case disappear process self name return self process self processor processor none processor self return self process self range self return return sum class iterable careful keep element iterable element careful keep reference future none yield else yield result self raise finished return else raise self self raise else return process process pool abruptly future running pending,issue,negative,positive,neutral,neutral,positive,positive
475032412,"Another way to test whether you're in colab is simply
```
try:
    from google import colab
    return True
except: return False
```
That's what is used in fastprogress.",another way test whether simply try import return true except return false used,issue,negative,negative,neutral,neutral,negative,negative
475011390,"@ericricky, so in what situation `__name__ == '__main__'` is False on colab? I opened colab and run it and it was true, hence I merged @EtienneT's PR.

And then perhaps it was my refactoring that broke it, that somehow earlier it was caching it - if you revert it back from https://github.com/fastai/fastai/commit/0e7c798b2cc4037169b99abd3e342f96c8354150 does it work?",situation false run true hence perhaps broke somehow revert back work,issue,negative,negative,neutral,neutral,negative,negative
475003548,"Hum, never really played with Colab so I am not sure what is best here.  But if you want me to test something on windows @ericricky  let me know!",hum never really sure best want test something let know,issue,negative,positive,positive,positive,positive,positive
474996927,"@EtienneT Thanks for the note. Unfortunately, `doc` doesn't work for me in Colab with the dev branch now. I'll try a different test for Colab in my fork and tag you - maybe you can try it out on Windows and see if it works. One option is to try my original test, which is to check to see if `/var/colab` exists, which is definitely less reliable, but probably not as disruptive. Another option would be to call `is_in_colab` when `doc` is run. Idk how to do this in Python, but maybe we can call `is_in_colab` the first time `doc` is run and cache the result",thanks note unfortunately doc work dev branch try different test fork tag maybe try see work one option try original test check see definitely le reliable probably disruptive another option would call doc run python maybe call first time doc run cache result,issue,negative,positive,neutral,neutral,positive,positive
474944954,"Just tested it and it works fine on windows.

Thanks,",tested work fine thanks,issue,positive,positive,positive,positive,positive,positive
474942404,"I refactored it to be just: https://github.com/fastai/fastai/commit/0e7c798b2cc4037169b99abd3e342f96c8354150
```
    ""Is the code running in Google Colaboratory?""
    return (IS_IN_IPYTHON and
            __name__ == '__main__' and
            get_ipython().__class__.__module__ == 'google.colab._shell')
```

Let me know if I broke anything.",code running return let know broke anything,issue,negative,neutral,neutral,neutral,neutral,neutral
474931393,"So from what I can tell, the stable PyTorch version doesn't like the script, so this is not for now.",tell stable version like script,issue,positive,neutral,neutral,neutral,neutral,neutral
474893022,"@ericricky could you test that my change still works in Google Colab?  Without this, windows multi-processing is broken.

Thanks,",could test change still work without broken thanks,issue,negative,negative,neutral,neutral,negative,negative
474889718,"I am trying to fork and submit a pull-request but github clone is super slow...  Here is my fix inside the file ipython.py:

```
def is_in_colab():
    ""Is the code running in Google Colaboratory?""
    def ipython_is_colab():
        if __name__ == '__main__':
            return get_ipython().__class__.__module__ == 'google.colab._shell'

    if IS_IN_IPYTHON and ipython_is_colab(): return True
    else:                                    return False

IS_IN_COLAB = is_in_colab()
```

I just added the `if __name__ == '__main__':`

This seems to make it work in windows.",trying fork submit clone super slow fix inside file code running return return true else return false added make work,issue,positive,negative,neutral,neutral,negative,negative
474849160,"Thanks for flagging this, but you need to change the notebook that is behind this page (so `vision.image.ipynb`) and no the html page itself: docs are auto-generated so your change will be overwritten the next time we build the docs if we don't fix the source of the problem.
More information [here](https://docs.fast.ai/gen_doc_main.html).",thanks flagging need change notebook behind page page change next time build fix source problem information,issue,negative,negative,neutral,neutral,negative,negative
474820649,"We can't help without, at the very minimum, see the whole code you are running, and preferably a reproducible example.",ca help without minimum see whole code running preferably reproducible example,issue,negative,positive,positive,positive,positive,positive
474819770,"Hi there! Classes that are only present in the validation set as considered as unknown. This is the expected behavior and not a bug: if we put some embedding for those, they will stay in their random initial state since the model doesn't get any sample with those classes in the training set. It can't properly learn.

This is why you see the right number when setting a validation pct to 0. Another way to solve this would be to carefully compute validation indices so that all the classes are present in the training set and not use a random split. You would then use `split_by_idx` instead of `rand_split_by_pct`.",hi class present validation set considered unknown behavior bug put stay random initial state since model get sample class training set ca properly learn see right number setting validation another way solve would carefully compute validation index class present training set use random split would use instead,issue,negative,negative,negative,negative,negative,negative
474715553,"I sure i'll try that. Also, I had installed pytorch globally in my system and not inside any conda environment. Do you think that can be the issue?",sure try also globally system inside environment think issue,issue,negative,positive,positive,positive,positive,positive
474714672,"@mengjiexu thanks for your advice. I am actually using gpu on a shared server. I cannot reboot the system. As far as logging out and logging in again is concerned, I have tried that. It did not work. Any other suggestions? Or any idea that you think could be a potential resolve?",thanks advice actually server system far logging logging concerned tried work idea think could potential resolve,issue,positive,positive,neutral,neutral,positive,positive
474694258,"> Thanks! That's a great add!

@sgugger You are welcome! Thank you for this opportunity (docs) for me to contribute back, and I enjoy working on docs.",thanks great add welcome thank opportunity contribute back enjoy working,issue,positive,positive,positive,positive,positive,positive
474548248,"Since you have closed the issue, it seems that you have found the resolve. Could you please share the resolve. I am facing the same error.",since closed issue found resolve could please share resolve facing error,issue,positive,negative,neutral,neutral,negative,negative
474515667,I am also learning about unit testing . Sincere apologies if I have broken things unintentionally. If  new PR is not created for this issue then I am willing contribute for writing test for this one.,also learning unit testing sincere broken unintentionally new issue willing contribute writing test one,issue,negative,positive,positive,positive,positive,positive
474448071,"> Should I make a new PR for the .html update ?

To further clarify:

The maintainers usually commit both and bearpelican is one of the maintainers, so he commits both. Sylvain usually rebuilds all online docs once a day.

For contributors, we try to make things as simple as possible, so asking to just follow the minimal steps required as described here: https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs And also as Sylvain said not having any autogenerated files in the PR makes it easier to review your work.",make new update clarify usually commit one usually day try make simple possible follow minimal also said easier review work,issue,positive,negative,neutral,neutral,negative,negative
474359204,Thanks for flagging! I've just put everything on one line.,thanks flagging put everything one line,issue,negative,positive,positive,positive,positive,positive
474358581,"No you don't need to do it directly (and we prefer you don't as it makes the diff unreadable). I haven't re-built the docs yet, will do this morning (in general it's done once a day).",need directly prefer unreadable yet morning general done day,issue,negative,positive,neutral,neutral,positive,positive
474339561,"I just found out that I didn't update the .html :-(
Looking at bearpelican's commit a11aa0f, I noticed that both .ipynb and the .html were committed.
I think I misread the documentation and thought it would be done after the commit on the github side.

Should I make a new PR for the .html update ?",found update looking commit think misread documentation thought would done commit side make new update,issue,negative,positive,positive,positive,positive,positive
474215366,"no, the red [x] means that some CI test failed - you can click on it to see what, but often it's not a real problem, since some of our tests occasionally fail because they are non-deterministic.

I only edited the url not to include the domain so that the site can be run from anywhere.

You can see the sum-total of your changes by clicking on the [ Files changed ] tab above, all is good and I merged it.

Thank you, @EmbraceLife ",red test click see often real problem since occasionally fail include domain site run anywhere see tab good thank,issue,negative,positive,neutral,neutral,positive,positive
474209888,"![image](https://user-images.githubusercontent.com/8749266/54583474-3abf5400-4a4f-11e9-8c83-920f1728f106.png)

@stas00 Thanks for your helpful guides! I think I have done all the corrections. 
However, as you can seen there is the commit 845ed12 which is crossed, I think it was my attempt to merge my new feature branch with master. Is it not necessary as it is not included in the four steps?

If I want to merge my new-feature-branch with master before I do PR, should I do `git merge --no-edit upstream/master`?",image thanks helpful think done however seen commit crossed think attempt merge new feature branch master necessary included four want merge master git merge,issue,positive,positive,positive,positive,positive,positive
474179700,"You probably did 'git commit -A'. Don't do that, use -a (lower case `a` instead) it will only add files which are already under git. So yes, the extra file shouldn't be there. You can just `git rm filename` and push, or you can delete it from the github interface.

Also the beginning of the notebook has some new stuff which shouldn't be there - appears to be a table of contents. Probably from your experiments with things that weren't in the 4-steps :) or perhaps you have some extension enabled that pushed it in - it shouldn't be in the doc notebook. You can see it appearing in the diff https://github.com/fastai/fastai/pull/1840/files

You can either delete that new cell after you disabled whatever added it there, and commit. Or you can start with a fresh notebook which you can copy from master or the github site and then Ctrl-C the cell in the old notebook and Ctrl-V into the new one (just make sure you're in Command mode, by hitting Esc once)",probably commit use lower case instead add already git yes extra file git push delete interface also beginning notebook new stuff table content probably perhaps extension doc notebook see either delete new cell disabled whatever added commit start fresh notebook copy master site cell old notebook new one make sure command mode,issue,positive,positive,positive,positive,positive,positive
474168639,"A lot of functions aren't tested yet, and the functionality that shows the tests is a new one, to highlight where help would be welcome ;)
If the link was broken, it might be an issue, so double-check and maybe file one so we can fix this.",lot tested yet functionality new one highlight help would welcome link broken might issue maybe file one fix,issue,positive,positive,positive,positive,positive,positive
474167752,"@sgugger Sorry, I am definitely not trying to be non-constructive, and understand this is open-source. I was just trying to figure out why calling `doc(interp.plot_top_losses)` for me in the first lesson (through colab) was returning a ""No tests found"" above the docstring, and why the ""Show in docs"" hyperlink was taking me to github instead of the docs (maybe related to #1660 ?). The ""contribute a test"" also seems to point to a localhost. Will look into opening PRs for these issues. Thanks for quick response.",sorry definitely trying understand trying figure calling doc first lesson found show taking instead maybe related contribute test also point look opening thanks quick response,issue,positive,positive,neutral,neutral,positive,positive
474165289,"Well in an ideal world, we only have perfect PRs, with perfect bug-free code, prefect tests and perfect updates to the docs. This is an open-source project though, so people who make PRs do their best and often, we first merge that we find to be a cool new functionality even if it doesn't have tests or complete doc.
You are more than welcome to fix whatever is missing with another PR that would be deeply appreciated. Nonconstructive criticism is less so.",well ideal world perfect perfect code prefect perfect project though people make best often first merge find cool new functionality even complete doc welcome fix whatever missing another would deeply nonconstructive criticism le,issue,positive,positive,positive,positive,positive,positive
474164392,"Is it common that PRs without tests get merged into the master? `plot_top_losses` is the first example of diving into the docs when going through the fast.ai course, so perhaps it is not the best function to allow changes to without tests.",common without get master first example diving going course perhaps best function allow without,issue,positive,positive,positive,positive,positive,positive
474160707,"Ah, I see.

Perhaps it could check the parent module if it has the NAME defined in there and use it instead? 

One thing for sure, it shouldn't link to non-existing docs, which it does now. i.e. there is no text.models.transformer.ipynb - does it make sense? So it should validate that the target exists before linking to it.",ah see perhaps could check parent module name defined use instead one thing sure link make sense validate target linking,issue,positive,positive,positive,positive,positive,positive
474155898,"Links are being updated. 

Problem is that we assume the doc path should be the same relative location as the module path. 
Docs builder currently doesn't have any idea that - 'text.models.transformer.py' module should be mapped to 'text.models.html'

I'll update/hardcode the links manually for now and think about how to handle 'module -> docs' mappings",link problem assume doc path relative location module path builder currently idea module link manually think handle,issue,negative,neutral,neutral,neutral,neutral,neutral
474146105,"> @bearpelican can we fix the reason behind those broken links?

Yeah, something is messed up in the doc builder:
```
grep TransformerXL docs_src/text.learner.ipynb
    ""- a [`TransformerXL`](/text.models.transformer.html#TransformerXL) ([Dai et al.](https://arxiv.org/abs/1901.02860))\n"",
```
It's written correctly \`TransformerXL\` so it should be updated to the new location? Or perhaps the build script only expands \\'Name\\' once and then never tries to update it if it's already expanded? Perhaps that's the culprit to our many broken anchors.",fix reason behind broken link yeah something doc builder al written correctly new location perhaps build script never update already expanded perhaps culprit many broken,issue,negative,negative,negative,negative,negative,negative
474144544,"@iamshwin, you could re-apply this same fix to the source, which is  `docs_src/text.learner.ipynb` if you want the exercise. The docs explain not to edit html, but ipynb instead. Please see:
https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs 
Thank you!

But really our system should handle those updates automatically - it seems to be a bug. So you can ignore it and will get fixed.",could fix source want exercise explain edit instead please see thank really system handle automatically bug ignore get fixed,issue,negative,positive,positive,positive,positive,positive
474137789,"Thanks a lot, it's looking good!",thanks lot looking good,issue,positive,positive,positive,positive,positive,positive
474137345,"Thanks for catching this, but it's useless to change the html directly since they are auto-generated (so your fix will be erased the next we build the docs). @bearpelican can we fix the reason behind those broken links?",thanks catching useless change directly since fix erased next build fix reason behind broken link,issue,negative,negative,neutral,neutral,negative,negative
474100543,"Okay, good points.
I'll update the pull request with the changes for the data path and models path and I'll also update the pull request with an updated datasets.ipynb with a reference to the optional FASTAI_HOME.",good update pull request data path path also update pull request reference optional,issue,negative,positive,positive,positive,positive,positive
474032367,"plus it needs to be documented. Probably at: https://docs.fast.ai/datasets.html#Config
https://docs.fast.ai/gen_doc_main.html#process-for-contributing-to-the-docs
Thank you.",plus need probably thank,issue,negative,neutral,neutral,neutral,neutral,neutral
474031660,"Fixed now, but please always give a full reproducible example as errors may come from other reasons than the last line you typed. In this case, it's because you used `ShowGraph` as a `Callback` and it takes time to guess this, time that I'd rather spend developing new features ;)",fixed please always give full reproducible example may come last line case used time guess time rather spend new,issue,negative,positive,positive,positive,positive,positive
474026016,"I don't see why not, but if we do this, then the default config should also use that env variable for the defaults to the  data path and the models path.",see default also use variable data path path,issue,negative,neutral,neutral,neutral,neutral,neutral
473902915,"A CUDA device-side assert error usually means there has been a bad index error on a Tensor on the GPU. You can't recover from it and need to restart the notebook. That's not linked to fastai.
After a long training, it's best practice to immediately save your model before anything else can go wrong. 

As for the cause of the error, I just double-checked the function and it worked in my case, so we would need a reproducible example to be able to help. Make sure you have the latest version of fastai too, as the reason of your problem may be a bug that has already been fixed.

Closing for now, please reopen if the problem persists with installation details and code to fully reproduce the bug.",assert error usually bad index error tensor ca recover need restart notebook linked long training best practice immediately save model anything else go wrong cause error function worked case would need reproducible example able help make sure latest version reason problem may bug already fixed please reopen problem installation code fully reproduce bug,issue,negative,positive,positive,positive,positive,positive
473727973,"so with the new release we don't need to use 

> torch.set_num_threads(1)

 anymore right?
and by new release you mean : 1.0.49 ?",new release need use right new release mean,issue,negative,positive,neutral,neutral,positive,positive
473666603,Good catch! Thanks a lot but @jonppe beat you to this in a previous PR (#1828) ;),good catch thanks lot beat previous,issue,positive,positive,positive,positive,positive,positive
473666462,"Thanks a lot! There are just two minors things to change in the notebook before we can merge, if possible.",thanks lot two change notebook merge possible,issue,negative,positive,neutral,neutral,positive,positive
473639778,"Thanks for pointing out using proper folder names in test. Now I actually read what the code is doing.
I added the fix to the method and the unit tests.
",thanks pointing proper folder test actually read code added fix method unit,issue,negative,positive,neutral,neutral,positive,positive
473623176,"> If you don't even see a progress bar appearing, it means the full dataset with all the texts opened doesn't fit in your RAM.

I am new to fastai, sorry if I am missing something. I came accross the same issue.
But shouldn't it lazy load data? It is very unlikely that language model data fits in RAM.

Btw. it is caused by this line in data_block.py if processor is OpenFileProcessor:
```
ds.items = array([self.process_one(item) for item in ds.items])
```

It loads entire text from all file into memory.",even see progress bar full fit ram new sorry missing something came issue lazy load data unlikely language model data ram line processor array item item entire text file memory,issue,negative,negative,neutral,neutral,negative,negative
473620443,"That's super important, sorry about it! Will fix it now. Thanks.",super important sorry fix thanks,issue,positive,positive,positive,positive,positive,positive
473609838,"Please don't forget to update the docs, otherwise new features remain undocumented.
https://docs.fast.ai/callbacks.csv_logger.html

The separation of docs and code makes it very easy to neglect docs.

Thanks.
",please forget update otherwise new remain undocumented separation code easy neglect thanks,issue,negative,positive,positive,positive,positive,positive
473578669,"Oh yes, this is an annoying typo, thanks for catching it! Your test doesn't pass however so that needs fixing. Be careful that `filter_by_folder` filters... by folder, so you need to have items that look like {folder}/{fname}. Then you use names that aren't the same.",oh yes annoying typo thanks catching test pas however need fixing careful folder need look like folder use,issue,positive,negative,neutral,neutral,negative,negative
473480063,"> Np, and if you feel like contributing, you can add this little bit to the doc notebook vision.transform so that other people aren't confused :)

Specifically, https://docs.fast.ai/vision.transform.html#resize - thank you!

",feel like add little bit doc notebook people confused specifically thank,issue,negative,negative,negative,negative,negative,negative
473464277,"Np, and if you feel like contributing, you can add this little bit to the doc notebook `vision.transform` so that other people aren't confused :)",feel like add little bit doc notebook people confused,issue,negative,negative,negative,negative,negative,negative
473463526,"No problem ;)
It's not a bug, this is the intended behavior: the resize is done lazily so if you don't specifically ask for img.data to be computed, it doesn't do anything (that's how we manage to execute all the transforms + resize in one call and one interpolation only).

So to see the change just do:
```
_ = img.data
```
then you will see the size has changed.

Another way is to type `img.refresh()`, which should trigger that computation too (without returning anything).",problem bug intended behavior resize done lazily specifically ask anything manage execute resize one call one interpolation see change see size another way type trigger computation without anything,issue,negative,negative,negative,negative,negative,negative
473462874,"You should use `export` :)
`Learner.save` goes with `Learner.load` and `Learner.export` goes with `load_learner`.",use export go go,issue,negative,neutral,neutral,neutral,neutral,neutral
473321474,"I'm no expert either, just trying to see which way is best. You've convinced me, and if someone disagrees, they can explain their reasoning ;)",expert either trying see way best convinced someone explain reasoning,issue,positive,positive,positive,positive,positive,positive
473320553,"I think it does especially if you are not looking at precision and recall at the same time. for three reasons:

* it is a lot more representative than `nan`
* it is going to be low to reflect the ""poor"" fscore
* it is going up / down regardless of whether some values in precision are `nan` which shows whether the training is doing slightly better or worse

But I am by no means a statistician or a deep learning expert, the final decision is up to you.",think especially looking precision recall time three lot representative nan going low reflect poor going regardless whether precision nan whether training slightly better worse statistician deep learning expert final decision,issue,negative,negative,neutral,neutral,negative,negative
473317021,"That gives an actual number, I agree, but does it make sense?",actual number agree make sense,issue,negative,neutral,neutral,neutral,neutral,neutral
473298778,You have to install from the repo as explained [here](https://github.com/fastai/fastai/tree/master/old#install-as-pip-package). We won't make any new releases with versions < 1.,install wo make new,issue,negative,positive,positive,positive,positive,positive
473296782,We removed the line that was setting threads from fastai and it removes the bug from Windows. Will make a release soon so that it's available for all users.,removed line setting bug make release soon available,issue,negative,positive,positive,positive,positive,positive
473294254,"Thanks for your input. I managed to reproduce the bug and create a minimal reproducible example in pure PyTorch. There is an [issue filed](https://github.com/pytorch/pytorch/issues/17840) that you can follow.

In the meantime, a workaround is to set 
```
torch.set_num_threads(1)
```",thanks input reproduce bug create minimal reproducible example pure issue follow set,issue,positive,positive,positive,positive,positive,positive
473274171,"Then that's a Spacy issue, not a fastai one. This is what they indicate [here](https://spacy.io/models/).",spacy issue one indicate,issue,negative,neutral,neutral,neutral,neutral,neutral
473270579,""" python -m spacy download de "" this command does not work ",python spacy de command work,issue,negative,neutral,neutral,neutral,neutral,neutral
473257680,"Yes if you want the model for another language, you will have to specifically download it (same instruction, replace 'en' by 'de').",yes want model another language specifically instruction replace,issue,negative,neutral,neutral,neutral,neutral,neutral
473198555,"OSError: [E050] Can't find model 'de'. It doesn't seem to be a shortcut link, a Python package or a valid path to a data directory. site:stackoverflow.com",ca find model seem link python package valid path data directory site,issue,negative,neutral,neutral,neutral,neutral,neutral
473131562,"Oh, the function called (`calc_loss`) was removed. Will fix tomorrow morning.",oh function removed fix tomorrow morning,issue,negative,neutral,neutral,neutral,neutral,neutral
473112210,I've misread the paper the eps is not scaled by the number of classes. Thx for noticing,misread paper scaled number class,issue,negative,neutral,neutral,neutral,neutral,neutral
472920639,"Oh yes, that's better, thanks!",oh yes better thanks,issue,positive,positive,positive,positive,positive,positive
472812653,"My apologies for the delay.

I have the repro scenario running under the debugger. Code paths are unfamiliar so I need some help.
Perhaps a screen share over a call with get this done waaay faster.

Also I am not proficient in debugging python - so please let me know if I can collect additional debugger info for you.

Here is what is leading to the hang with the latest pull from fastai/fastai:

If you can give me some hints on what I can tweak or look for next that will be great. 

```python
# start
learn = create_cnn(data, models.resnet34, metrics=error_rate)
# ->
nf = num_features_model(nn.Sequential(*body.children())) * 2
# ->
        try: return model_sizes(m, size=(sz,sz))[-1][1] # sz = 64
# ->
        x = dummy_eval(m, size)
# ->
    return m.eval()(dummy_batch(m, size))
# ->
    return one_param(m).new(1, ch_in, *size).requires_grad_(False).uniform_(-1.,1.) # ch_in = 3
# ->
    return next(m.parameters())
# ->
        self.stored = self.hook_func(module, input, output)
```
> At this point variables on the stack are as follows

| Name | Value | Type |
|-|-|-|
| > | input | <generator object Hook.hook_fn.<locals>.<genexpr> at 0x0000027D3AF5EB10> | generator |
| > | module | Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False) | Conv2d |
| > | output | tensor([[[[ 2.7787e-01,  7.0241e-01,  8.2423e-02,  ..., -3.2922e-01,             1| Tensor |
| > | self | <fastai.callbacks.hooks.Hook object at 0x0000027D3AF5C390> | Hook |

```python
# resuming the above call 
        self.stored = self.hook_func(module, input, output)
# ->
        self.stored = self.hook_func(module, input, output)
# ->
        self.stored = self.hook_func(module, input, output)
# ->
        self.stored = self.hook_func(module, input, output)
```

So the 5th call to self.hook_func hangs.



",delay scenario running code unfamiliar need help perhaps screen share call get done faster also proficient python please let know collect additional leading latest pull give tweak look next great python start learn data try return size return size return size false return next module input output point stack name value type input generator object generator module output tensor tensor self object hook python call module input output module input output module input output module input output th call,issue,positive,positive,positive,positive,positive,positive
472537210,"Did this solve your issue? It's been a while with no news, so I'm closing, but feel free to reopen with an update.",solve issue news feel free reopen update,issue,positive,positive,positive,positive,positive,positive
472522615,"Hi there, sorry it took us so long to reply. I am closing this, not because this isn't useful, but because we think it would be best in a repo separate from fastai. We can then link to it in our docs so that interested users can install it and use it.",hi sorry took u long reply useful think would best separate link interested install use,issue,positive,positive,positive,positive,positive,positive
472517485,"This is a bit hacky but I can't think of another way, so merging. I'll change if I get a better idea. Thanks!",bit hacky ca think another way change get better idea thanks,issue,positive,positive,positive,positive,positive,positive
472513465,"I'm trying to remember where I found that `c-1` instead of `c` since that's what is in the original paper, but couldn't. So let's go with the fix. There is a slight problem in your code: you divide by c twice in creating the eps then doing eps/c. Will fix then merge.",trying remember found instead since original paper could let go fix slight problem code divide twice fix merge,issue,negative,positive,positive,positive,positive,positive
472360293,"<a href='https://www.reviewnb.com/' target='_blank'>ReviewNB</a> lets you review Jupyter Notebooks with visual diff & commenting. 

 Check out this pull request on ReviewNB: https://app.reviewnb.com/fastai/fastai/pull/1813 ",review visual check pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
472243231,"@sgugger No problem, and thank you. Love the course and the library!",problem thank love course library,issue,positive,positive,positive,positive,positive,positive
472216460,"Thanks for that change, @ericricky. But I'll let @bearpelican to review.

The proposed change makes it so that `get_ipython().run_cell_magic()` will be run only in colab, which I'm not sure at all is correct. But I didn't write that part, so Andrew will know for sure.",thanks change let review change run sure correct write part know sure,issue,positive,positive,positive,positive,positive,positive
472131097,"This is the good fix AFAICT (I'll trust you for the `in_collab` test). It doesn't change the current behavior in jupyter notebook and fixes it in collab (see discussion in the mentioned issue). @bearpelican, let me know if you feel differently.",good fix trust test change current behavior notebook see discussion issue let know feel differently,issue,positive,positive,positive,positive,positive,positive
472091185,"@sgugger Sorry, thought I commented a few days ago but I must have forgotten. I'll take another look at it",sorry thought day ago must forgotten take another look,issue,negative,negative,negative,negative,negative,negative
471867242,"Yeah, I know what you mean. I tried that and it did make a difference.

The issue is that usually when there is overfitting, you jack up the `wd` to reduce it. However, with our particular setup, I did not find a logarithmically larger `wd` makes much difference; it does not help reducing overfitting. Probably I am doing it wrong.",yeah know mean tried make difference issue usually jack reduce however particular setup find logarithmically much difference help reducing probably wrong,issue,negative,negative,negative,negative,negative,negative
471859747,"I'd prefer to use open_image, a bit processing (resize, norm etc) and predict. Thats would be fine the last time i tried",prefer use bit resize norm predict thats would fine last time tried,issue,negative,positive,positive,positive,positive,positive
471856067,"Hhm, no issues here at all and sorry to hear that. I am trying to give my constructive professional view (so I think that's fair, not intending making things difficult :-)) but certainly have a limited timebudget. 

So I agree, we should not repeat this PR process in this setting. 

Thx for the support here in any case and making this happen! ",sorry hear trying give constructive professional view think fair intending making difficult certainly limited agree repeat process setting support case making happen,issue,positive,negative,neutral,neutral,negative,negative
471835365,"Thank you, @sgugger. A new test added.",thank new test added,issue,negative,positive,positive,positive,positive,positive
471819218,"I was planning to add an assert with the new clean error you said you added, but it still blows up as before. once there is a user-friendly error, that's what that failing print will check.

You will need to remove the skip to reproduce the problem.",add assert new clean error said added still error failing print check need remove skip reproduce problem,issue,negative,positive,positive,positive,positive,positive
471818346,"It still doesn't work.

this blows up:
```
learn = load_learner(path)
print(learn.summary())
```
with:
```
――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――― test_export_load_learner ―――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――――

    def test_export_load_learner():
        export_file = 'export.pkl'
        for should_destroy in [False, True]:
            learn = fake_learner()
            this_tests(learn.export, load_learner, learn.summary)
            path = learn.path
            model_summary_before = learn.summary()
    
            print(f""\n*** Testing w/ learn.export(destroy={should_destroy})"")
            with CaptureStdout() as cs: learn.export(destroy=should_destroy)
            learn = load_learner(path)
            # XXX: remove the next line when bug is fixed
>           print(learn.summary())

tests/test_basic_train.py:230: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 
fastai/callbacks/hooks.py:166: in model_summary
    info = layers_info(m)
fastai/callbacks/hooks.py:160: in layers_info
    layers_sizes, layers_params, layers_trainable = params_size(m)
fastai/callbacks/hooks.py:141: in params_size
    x = m.data.one_batch(ds_type=ds_type, detach=False, denorm=False)[0]
fastai/basic_data.py:168: in one_batch
    try:     x,y = next(iter(dl))
fastai/basic_data.py:75: in __iter__
    for b in self.dl: yield self.proc_batch(b)
/home/stas/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py:637: in __next__
    return self._process_next_batch(batch)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ 

self = <torch.utils.data.dataloader._DataLoaderIter object at 0x7fcb05d0a5c0>, batch = <torch.utils.data.dataloader.ExceptionWrapper object at 0x7fcb020bbb38>

    def _process_next_batch(self, batch):
        self.rcvd_idx += 1
        self._put_indices()
        if isinstance(batch, ExceptionWrapper):
>           raise batch.exc_type(batch.exc_msg)
E           TypeError: Traceback (most recent call last):
E             File ""/home/stas/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 138, in _worker_loop
E               samples = collate_fn([dataset[i] for i in batch_indices])
E             File ""/home/stas/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 138, in <listcomp>
E               samples = collate_fn([dataset[i] for i in batch_indices])
E             File ""/mnt/nvme1/fast.ai-1/br/fastai/master/fastai/data_block.py"", line 626, in __getitem__
E               if self.item is None: x,y = self.x[idxs],self.y[idxs]
E             File ""/mnt/nvme1/fast.ai-1/br/fastai/master/fastai/data_block.py"", line 106, in __getitem__
E               if isinstance(idxs, Integral): return self.get(idxs)
E             File ""/mnt/nvme1/fast.ai-1/br/fastai/master/tests/utils/fakes.py"", line 42, in get
E               def get(self, i): return RandomItem(*self.sizes)
E           TypeError: type object argument after * must be an iterable, not NoneType

/home/stas/anaconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py:658: TypeError
--------------------------------------------------------------------------- Captured stdout call ---------------------------------------------------------------------------

*** Testing w/ learn.export(destroy=False)

 tests/test_basic_train.py ⨯    
```",still work learn path print false true learn path print testing learn path remove next line bug fixed print try next iter yield return batch self object batch object self batch batch raise recent call last file line file line file line none file line integral return file line get get self return type object argument must iterable call testing,issue,negative,positive,neutral,neutral,positive,positive
471812169,"update: I implemented all this functionality including tests, so nothing else needs to be done.",update functionality nothing else need done,issue,negative,neutral,neutral,neutral,neutral,neutral
471768281,"No problem, I will sort it out.

I also wanted to communicate to you that I find it very difficult to work with you, @Benudek.

I trust you will find someone else with a better character compatibility to continue forward.
",problem sort also communicate find difficult work trust find someone else better character compatibility continue forward,issue,negative,neutral,neutral,neutral,neutral,neutral
471758145,"understand, makes sense. 

Unfortunately I wont get to this any time soon :-( 

So need to close this for now.",understand sense unfortunately wont get time soon need close,issue,negative,negative,negative,negative,negative,negative
471755746,"That's why I said, extract the functionality into a function that is totally unrelated to test registry:

```
def merge_dicts(old, new):
[...]
return merged
```

test:
```
old = { a: [1, 2, 3], b: [4, 5, 6])
new = { a: [11, 12, 13], c: [9])
expected = { a: [11, 12, 13], b: [4, 5, 6], c: [9])
merged = merge_dicts(old, new)
assert expected == merged
```
done. 
this is untested. just showing what I meant.

of course adjust old/new to match our needs - i.e. mimic the same dict structure.",said extract functionality function totally unrelated test registry old new return test old new old new assert done untested showing meant course adjust match need mimic structure,issue,negative,positive,positive,positive,positive,positive
471753487,"I've just pushed another way to fix. Note that it won't work with your example of '3', it filters the base folders only.",another way fix note wo work example base,issue,negative,negative,negative,negative,negative,negative
471751966,"ok, sorry about that, took the text basically from the doc. What would be the correct text to qualify for ?

If helpful and you don't wanna correct directly, can make a simple PR.

",sorry took text basically doc would correct text qualify helpful wan na correct directly make simple,issue,negative,negative,negative,negative,negative,negative
471750566,"Previously merged PR was incorrect. "".[dev]"" applies only to the fastai repo. the script prints this for all fastai user repos.",previously incorrect dev script user,issue,negative,negative,negative,negative,negative,negative
471749181,"This is incorrect. "".[dev]"" applies only to the fastai repo. the script prints this for all fastai user repos.",incorrect dev script user,issue,negative,neutral,neutral,neutral,neutral,neutral
471730645,"Oh, thanks for flagging!
Should be fixed in [this commit](https://github.com/fastai/fastai/commit/4a979c72d2a09337cb89b6f584f207dc6d7db1e8).",oh thanks flagging fixed commit,issue,positive,positive,positive,positive,positive,positive
471730250,"Stas, makes sense :-) 

However - on 2nd look and 3rd look: it looks a little hairy to write tests for this. e.g. setting up data, but also I might need to rewrite the code a little (are you suggesting this with (1)?) to be able calling functions independently.

I wonder if we can be a little 'pragmatic' here  it's a utility function and we have some more-core function without tests ;-) If it fails in 'production' as far as I can see it wouldn't be a 'biggie' and we could fix then based on the edge case detected, that right now I couldn't predict.

So, what I mainly did is below - and yes it's time-consuming ( I always re-ran all tests to try breaking things) and likely not covering all edge cases: 

**1. delete the file test_api_db.json
2. run pytest -sv --testapireg** 

NOW: after that the merge function will call

**3a. open file in editor and take a random entry and overwrite the entry**

_FROM   ""fastai.basic_data.DataBunch.create"": [
        {
            ""file"": ""tests/test_basic_data.py"",
            ""line"": 19,
            ""test"": ""test_DataBunch_Create""
        },
        {
            ""file"": ""tests/test_basic_data.py"",
            ""line"": 33,
            ""test"": ""test_DataBunch_no_valid_dl""
        }
    ],

TO   ""fastai.basic_data.DataBunch.create"": [
        {
            ""file"": ""DUMMY"",
            ""line"": 19,
            ""test"": ""test_DataBunch_Create""
        },
        {
            ""file"": ""tests/test_basic_data.py"",
            ""line"": 33,
            ""test"": ""test_DataBunch_no_valid_dl""
        }
    ],_

EXPECTATION: when rerunning 

**4a. run pytest -sv --testapireg** 

I want to see both: the DUMMY entry and tests/test_basic_data.py

I also changed other lines here with the same expectation and result.

This tests the if-part of the function

_if func_fq_key in old_api_tests_map: 
                for new_entry in new_entries:
                    if new_entry not in old_api_tests_map[func_fq_key]:
                        old_api_tests_map[func_fq_key].append(new_entry)
            else:
                old_api_tests_map[func_fq_key] =  new_entries_            

The else part is tested here

**3b. open file in editor and take out all of ""fastai.basic_data.DataBunch.create"":** 
**4b. run pytest -sv --testapireg** 

I expect to see the entire entry from above see FROM.

Where we see huge gaps here, we could run some more tests manually - could that help?




",sense however look look little hairy write setting data also might need rewrite code little suggesting able calling independently wonder little utility function function without far see would could fix based edge case right could predict mainly yes always try breaking likely covering edge delete file run merge function call open file editor take random entry overwrite entry file line test file line test file dummy line test file line test expectation run want see dummy entry also expectation result function else else part tested open file editor take run expect see entire entry see see huge could run manually could help,issue,positive,positive,neutral,neutral,positive,positive
471723921,"Try 1000, it will go nan in one epoch ;)",try go nan one epoch,issue,negative,neutral,neutral,neutral,neutral,neutral
471719544,"You must not have the latest version (the code I see is pre-fix). You can check your version with 
```
from fastai.utils.show_install import show_install
show_install()
```
and you can download the master version on colab with
```
!pip install git+https://github.com/fastai/fastai
```",must latest version code see check version import master version pip install,issue,negative,positive,positive,positive,positive,positive
471656757,"It looks good, but I don't have a way to test whether it works correctly or not, other than making a whole bunch of changes to tests, re-running them multiple-times, and hope I didn't miss anything  - very time consuming and error-prone.

Can you please add a test that validates its functionality?

i.e. 
1. extract the merging of 2 dicts functionality into its own function
2. write a new test that merges 2 dicts using that new function (simple case and edge cases) and validates that it does the right thing
3. use that function

Thank you. 

p.s. that's how I'd have approached this task - first created a merging dict function, while writing a test that checks that I made no mistakes, then used it in the code.",good way test whether work correctly making whole bunch hope miss anything time consuming please add test functionality extract functionality function write new test new function simple case edge right thing use function thank task first function writing test made used code,issue,positive,positive,positive,positive,positive,positive
471649437,"Hi guys, I still get the same error with the newest version of the notebook in colab

How can we solve this? Or is it still a bug in the fastai library?



```
`---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-36-7aa74a9f84cb> in <module>()
----> 1 learn = Learner(data, Mnist_NN(), loss_func=loss_func, metrics=accuracy)

<string> in __init__(self, data, model, opt_func, loss_func, metrics, true_wd, bn_wd, wd, train_bn, path, model_dir, callback_fns, callbacks, layer_groups, add_time)

/usr/local/lib/python3.6/dist-packages/fastai/basic_train.py in __post_init__(self)
    155         (self.path/self.model_dir).mkdir(parents=True, exist_ok=True)
    156         self.model = self.model.to(self.data.device)
--> 157         self.loss_func = ifnone(self.loss_func, self.data.loss_func)
    158         self.metrics=listify(self.metrics)
    159         if not self.layer_groups: self.layer_groups = [nn.Sequential(*flatten_model(self.model))]

/usr/local/lib/python3.6/dist-packages/fastai/basic_data.py in __getattr__(self, k)
    120         return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)
    121 
--> 122     def __getattr__(self,k:int)->Any: return getattr(self.train_dl, k)
    123     def __setstate__(self,data:Any): self.__dict__.update(data)
    124 

/usr/local/lib/python3.6/dist-packages/fastai/basic_data.py in __getattr__(self, k)
     36 
     37     def __len__(self)->int: return len(self.dl)
---> 38     def __getattr__(self,k:str)->Any: return getattr(self.dl, k)
     39     def __setstate__(self,data:Any): self.__dict__.update(data)
     40 

/usr/local/lib/python3.6/dist-packages/fastai/basic_data.py in DataLoader___getattr__(dl, k)
     18 torch.utils.data.DataLoader.__init__ = intercept_args
     19 
---> 20 def DataLoader___getattr__(dl, k:str)->Any: return getattr(dl.dataset, k)
     21 DataLoader.__getattr__ = DataLoader___getattr__
     22 

AttributeError: 'TensorDataset' object has no attribute 'loss_func'`
```",hi still get error version notebook solve still bug library recent call last module learn learner data string self data model metric path self self return self return self data data self self return self return self data data return object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
471566984,"One minor issue again: it seems “add_metrics” only handles None “mets”, not None “last_metrics”... When the validation set is empty we got None “last_metrics”, so we need to check for that somewhere as well... 

Also, can we initialize “self.no_val” in “Recorder” to “self.learn.data.empty_val”? This seems to work better (rather than let the GAN set it)",one minor issue none none validation set empty got none need check somewhere well also initialize recorder work better rather let gan set,issue,positive,positive,positive,positive,positive,positive
471421386,"I guess this is a place where there needs to be a consensus, about where we should continue to use `pathlib` for the path handling, or even whether we should continue at all if the performance overhead is indeed so bad. Enforcing an agreed upon way of doing things for certain tasks, for example here path handling, at least internally inside the library, will help us avoid bugs like above.

I know that this might be too trivial an issue. So feel free to ignore it.",guess place need consensus continue use path handling even whether continue performance overhead indeed bad agreed upon way certain example path handling least internally inside library help u avoid like know might trivial issue feel free ignore,issue,positive,negative,neutral,neutral,negative,negative
471420323,Sign. I guess that most convenience comes with a performance overhead. `pathlib` is so much nicer to use compared to `os`.,sign guess convenience come performance overhead much use o,issue,negative,positive,positive,positive,positive,positive
471393926,This is a pytorch pretrained mode and the issue is on the pytorch side (torchvision to be more specific). I'd suggest opening an issue on their repo.,mode issue side specific suggest opening issue,issue,negative,neutral,neutral,neutral,neutral,neutral
471335191,"Oh yes, this doesn't work properly in this instance, thanks for flagging.
The problem with converting everything to a Path object is that it can be very slow (for datasets like imagenet for instance), so we would need a speed check, and if this doesn't pass it, we will need another way of fixing the problem.",oh yes work properly instance thanks flagging problem converting everything path object slow like instance would need speed check pas need another way fixing problem,issue,negative,negative,neutral,neutral,negative,negative
471334893,"No, I didn't delete anything.
Your fix breaks the current behavior in jupyter notebooks (which is the environment for which this function was developed) so we can't have it that way. If colab fails silently on something it's not doing properly, we need to include some way to detect if we are in colab or a jupyter notebook to test which instruction to execute.",delete anything fix current behavior environment function ca way silently something properly need include way detect notebook test instruction execute,issue,negative,neutral,neutral,neutral,neutral,neutral
471328785,"@sgugger This still does not work for me. Did you delete my previous comment? See [this notebook](https://colab.research.google.com/gist/ericricky/0ae77f6b9e88c671fde76568b819eb5d/doc_in_colab.ipynb). Note that even in my fork that fixes `doc`, the 'source' link does not work unless opened in a new tab. Can we please reopen?",still work delete previous comment see notebook note even fork doc link work unless new tab please reopen,issue,negative,negative,neutral,neutral,negative,negative
471322349,"Oh good point, thanks!",oh good point thanks,issue,positive,positive,positive,positive,positive,positive
471307102,"ok I solve this problem by cast target= target.long() into layers.py  in the class FlattenedLoss, and the same for accuraccy in metrics ",solve problem cast class metric,issue,negative,neutral,neutral,neutral,neutral,neutral
471275943,"sourceDir=""../input/resnet34333fec4/resnet34-333f7ec4.pth""
targetDir=""/tmp/.torch/models/""
moveFileto(sourceDir,  targetDir)

I tried this, but another error raised, what can I do?",tried another error raised,issue,negative,neutral,neutral,neutral,neutral,neutral
471257256,BTW: Nice to have the heatmap feature so easily available now 👍 Great job!,nice feature easily available great job,issue,positive,positive,positive,positive,positive,positive
471243343,"Ah, sorry for my inaccurate wording. I should have said it as ""1.0.48-dev"".

I was trying to fix another bug I found so that I thought working on master would be best.

Thank you so much!",ah sorry inaccurate wording said trying fix another bug found thought working master would best thank much,issue,positive,positive,positive,positive,positive,positive
471231309,"Thanks, added a try block.",thanks added try block,issue,negative,positive,positive,positive,positive,positive
471226840,"😅... I see, that's how it works... Things get updated in the `_call_and_update` of the dict `new`. I'm still thinking in the old mechanism. Thank you for the explanation! 

Then I think my line in the `on_epoch_end` of `GANTrainer` should be removed (first line), it's redundant and will add metrics twice",see work get new still thinking old mechanism thank explanation think line removed first line redundant add metric twice,issue,negative,positive,neutral,neutral,positive,positive
471226817,"Ah, yeah I do! My console is printing a lot of control characters from the progress bars so it was hard to see.",ah yeah console printing lot control progress hard see,issue,positive,negative,negative,negative,negative,negative
471226640,"Ok, in that case, do you get this error message printed? ""Failed to compute the gradients, there might not be enough points.""",case get error message printed compute might enough,issue,negative,neutral,neutral,neutral,neutral,neutral
471220811,The problem was that `torch.cuda.set_device` doesn't update `defaults.device` which is what we use internally. Note that you have to set this before defining any `DataBunch` or it's going to use the wrong device.,problem update use internally note set going use wrong device,issue,negative,negative,negative,negative,negative,negative
471213657,"Done in [this commit](https://github.com/fastai/fastai/commit/3305fd33dd5e7cc4e07806929396e776e25f934d). By returning the result of `add_metrics` (which checks for None), we make sure the metrics are updated and sent to the recorder.",done commit result none make sure metric sent recorder,issue,negative,positive,positive,positive,positive,positive
471213314,It'll be easier to show you. Let me merge this and I'll update the line.,easier show let merge update line,issue,negative,neutral,neutral,neutral,neutral,neutral
471212989,"Sorry for the confusion. In `_call_and_update` of the `CallbackHandler`, the `state_dict` is passed into each callback, in the `order` as you mentioned. But the updates of `last_metrics` won't be got by later callbacks if it's `None`. In the following example: 

![Untitled](https://user-images.githubusercontent.com/11836586/54075987-d98bc980-4273-11e9-839e-75b80b742e76.png)

My understanding may be wrong, there may be better ways to handle this, but this is what the concern is, hope I made it clearer, as there're quite a few changes going on... 

Anyway, the problem I'm concerned about is, if I train a GAN with empty validation set, the `gen_loss` and `disc_loss` are not showing in the console, because they are added in the `GANTrainer` but it's still `None` in the `Recorder`, for the reason explained above. I wonder could you replicate this issue? 
",sorry confusion order wo got later none following example untitled understanding may wrong may better way handle concern hope made clearer quite going anyway problem concerned train gan empty validation set showing console added still none recorder reason wonder could replicate issue,issue,negative,negative,neutral,neutral,negative,negative
471188661,"The `GANTrainer` callback happens before the `Recorder` (see the [order](https://github.com/fastai/fastai/blob/b6986e1dbf8b2a52e19e6c12e5f90131cdb90825/fastai/vision/gan.py#L74)) so if it returns an updated `last_metrics` list, this is what `Recorder` will receive.
I'm not sure of the problem you think there is here?",recorder see order list recorder receive sure problem think,issue,negative,positive,positive,positive,positive,positive
471179471,"Hi @sgugger, right, I saw `add_metrics` in the `Recorder` was removed which causes this error. Do you mean we can now use the `add_metrics` in `torch_core`? It checks for `None`, yes. But if `last_metrics` is `None` in `on_epoch_end` of `GANTrainer` (only happens when valid set is empty), my solution here does't work, and I don't see how to make it work without further changes. May I missed something? 

If `last_metrics` is an empty list, I can modify it in `GANTrainer` and the `Recorder` will use the updated list, it's like pass by reference; but if it's `None` and I reset it to empty list, in the `Recorder` it's still `None`, so this trick won't work anymore... 

",hi right saw recorder removed error mean use none yes none valid set empty solution work see make work without may something empty list modify recorder use list like pas reference none reset empty list recorder still none trick wo work,issue,negative,negative,neutral,neutral,negative,negative
471179024,"Thanks for the issue. The cause is that `lr_find` saves the state before the dummy training, and then reloads it afterwards. However, it does not reload it in to the correct device, resulting in a redundant copy of the model on GPU 0. We can probably fix this by having `load` default to loading in to the current device, although we'll need to do some testing.",thanks issue cause state dummy training afterwards however reload correct device resulting redundant copy model probably fix load default loading current device although need testing,issue,negative,neutral,neutral,neutral,neutral,neutral
471178715,"> I have checked that 1.0.47.post1 does not have this issue. So the problem is introduced in release-1.0.48.

There is no release 1.0.48. The issue is on master. Please do let us know when you're reporting an issue using master. We certainly like to hear about them (including this one - thanks!) but note that we don't in general expect master to work for everyone all the time; it's where we do all our day to day development. So you should only use it if you're OK finding and fixing bugs.

I've moved the libsixel check inside the function where it's used. So you should find everything works fine now for you without libsixel installed, except of course for fastai.sixel. If you want to test that, you'll need to install the lib from source unfortunately, since there are no packages for it yet.",checked post issue problem release issue master please let u know issue master certainly like hear one thanks note general expect master work everyone time day day development use finding fixing check inside function used find everything work fine without except course want test need install source unfortunately since yet,issue,positive,positive,neutral,neutral,positive,positive
471172280,I didn't find an easy way to install for Mac OS X. So for now we need to download the source code and compile it ourselves.,find easy way install mac o need source code compile,issue,negative,positive,positive,positive,positive,positive
471165693,"did you find a way to install it locally ? Searching around ...

tried some things like: pip install libsixel-python no luck ...

https://forums.fast.ai/t/developer-chat/22363/855?u=benudek

issue might be here: 

https://github.com/fastai/fastai/commit/6432d5dce1fc53dc825c93183cc2cdf97331e264

thx  @kdorichev",find way install locally searching around tried like pip install luck issue might,issue,positive,neutral,neutral,neutral,neutral,neutral
471162428,I have checked that `1.0.47.post1` does not have this issue. So the problem is introduced in `release-1.0.48`.,checked post issue problem,issue,negative,neutral,neutral,neutral,neutral,neutral
471147480,FYI removing `create_cnn` broke the deprecation warning (it's now throwing an error since it's not in all).I put it back.,removing broke deprecation warning throwing error since put back,issue,negative,neutral,neutral,neutral,neutral,neutral
471141952,Got it! I will remember it next time.,got remember next time,issue,negative,neutral,neutral,neutral,neutral,neutral
471140918,"Ok, I'll try that for now until the export works. Thanks a lot @sgugger ",try export work thanks lot,issue,negative,positive,positive,positive,positive,positive
471137966,"But that would suggest that I still need the Train/Val data to reload the model.
",would suggest still need data reload model,issue,negative,neutral,neutral,neutral,neutral,neutral
471133256,"You can use `xb,yb = data.one_item(img)` to get the corresponding batch (with transforms and normalization) before feeding it to your model.
You may also have `res = learn.pred_batch(batch=(xb,yb))` that works directly.",use get corresponding batch normalization feeding model may also work directly,issue,negative,positive,neutral,neutral,positive,positive
471132205,"Thanks, and yes I can see the show_install. Sorry I'm really distracted today ;)",thanks yes see sorry really distracted today,issue,negative,negative,neutral,neutral,negative,negative
471131866,"You should use `add_metrics`that will directly do that check for you and return an updated list.
Thanks in any case, I had forgotten those and this PR is really needed!",use directly check return list thanks case forgotten really,issue,negative,positive,positive,positive,positive,positive
471131437,"Yes, but I don't really know how to predict a single image using the learner. I've been searching for a way and stumbled upon this
```
trn_tfms, val_tfms = tfms_from_model(resnet34,224) # get transformations
im = val_tfms(Image.open(PATH/'train/TESTJPEGS/test1.jpg'))
learn.precompute=False # We'll pass in a raw image, not activations
preds = learn.predict_array(im[None])
np.argmax(preds) # preds are log probabilities of classes
``` 
but the problem is that `tfms_from_model()` is deprecated and I don't know what is the replacement.

I know that I need to get the same transforms and normalization that my model used when loading the model to preprocess the new data, however, I can't seem to find an approach for that. 
",yes really know predict single image learner searching way upon get pas raw image none log class problem know replacement know need get normalization model used loading model new data however ca seem find approach,issue,positive,positive,neutral,neutral,positive,positive
471130851,You can still use `learn.save` and `learn.load` to save then load your model.,still use save load model,issue,negative,neutral,neutral,neutral,neutral,neutral
471129288,"Yup I have the suggestion print out (when it works, I'll double check if that's there when it errors). The `show_install()` output I posted was ran from my training script inside the container. Let me triple check that everything I've said is accurate, will post back shortly with more test details.",suggestion print work double check output posted ran training script inside container let triple check everything said accurate post back shortly test,issue,negative,positive,positive,positive,positive,positive
471127648,"They are the same thing, this is really weird. You won't see the plots but it prints the suggestion, do you have that line? Also, can you check the result of 
```
from fastai.utils.show_install import show_install
show_install()
```
and copy-paste it here?",thing really weird wo see suggestion line also check result import,issue,negative,negative,negative,negative,negative,negative
471125401,"My training logs are being written to console from docker so I can't actually see the plots. In notebook training I can see the plots though, but I don't get this error there. It seemed that the problem was intermittent, although now it looks like `lr_find(learn)` is erroring every time and `learn.lr_find()` is not. Aren't they the same thing though? Apologies if my error feedback is not that useful, please let me know of any other info to add.",training written console docker ca actually see notebook training see though get error problem intermittent although like learn every time thing though error feedback useful please let know add,issue,negative,positive,positive,positive,positive,positive
471124820,"Ah sorry, I missed that. Weird! Do you see the red dot and everything?",ah sorry weird see red dot everything,issue,negative,negative,negative,negative,negative,negative
471124016,"@sgugger I am doing that, `learn.recorder.plot(suggestion=True, return_fig=True)`

Like I said, sometimes it works and sometimes it doesn't (without modifying my code). Don't know if it has something to do with an error while calculating or something else.",like said sometimes work sometimes without code know something error calculating something else,issue,negative,neutral,neutral,neutral,neutral,neutral
471123923,"Ok, I'll stay posted. Do you have any suggestions of ways to use the model for inference?
 ",stay posted way use model inference,issue,negative,neutral,neutral,neutral,neutral,neutral
471123568,"No, this is a standing issue (see #1778), will fix it in the coming days. Production stuff isn't ready yet for object detection.",standing issue see fix coming day production stuff ready yet object detection,issue,negative,positive,positive,positive,positive,positive
471123356,You need to pass `suggestion=True` to make the LR finder try to find a suggestion for you and have that argument.,need pas make finder try find suggestion argument,issue,negative,neutral,neutral,neutral,neutral,neutral
471121850,"Thanks @sgugger, I updated and that resolved the pickle issue, though now I'm presented with another issue which is 
`
AttributeError: 'ObjectCategoryProcessor' object has no attribute 'pad_idx'`

and this is the trace:
```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-15-1a65330eba39> in <module>
----> 1 learn = load_learner(PATH/'train/AnnotatedJPEG/')

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py in load_learner(path, fname, test, **db_kwargs)
    576     state = torch.load(Path(path)/fname, map_location='cpu') if defaults.device == torch.device('cpu') else torch.load(Path(path)/fname)
    577     model = state.pop('model')
--> 578     src = LabelLists.load_state(path, state.pop('data'))
    579     if test is not None: src.add_test(test)
    580     data = src.databunch(**db_kwargs)

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in load_state(cls, path, state)
    551         ""Create a `LabelLists` with empty sets from the serialized `state`.""
    552         path = Path(path)
--> 553         train_ds = LabelList.load_state(path, state)
    554         valid_ds = LabelList.load_state(path, state)
    555         return LabelLists(path, train=train_ds, valid=valid_ds)

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in load_state(cls, path, state)
    663         x = state['x_cls']([], path=path, processor=state['x_proc'], ignore_empty=True)
    664         y = state['y_cls']([], path=path, processor=state['y_proc'], ignore_empty=True)
--> 665         res = cls(x, y, tfms=state['tfms'], tfm_y=state['tfm_y'], **state['tfmargs']).process()
    666         if state.get('tfms_y', False):    res.tfms_y    = state['tfms_y']
    667         if state.get('tfmargs_y', False): res.tfmargs_y = state['tfmargs_y']

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in process(self, xp, yp, name)
    671     def process(self, xp:PreProcessor=None, yp:PreProcessor=None, name:str=None):
    672         ""Launch the processing on `self.x` and `self.y` with `xp` and `yp`.""
--> 673         self.y.process(yp)
    674         if getattr(self.y, 'filter_missing_y', False):
    675             filt = array([o is None for o in self.y.items])

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in process(self, processor)
     72         if processor is not None: self.processor = processor
     73         self.processor = listify(self.processor)
---> 74         for p in self.processor: p.process(self)
     75         return self
     76 

~/anaconda3/envs/fastai/lib/python3.7/site-packages/fastai/vision/data.py in process(self, ds)
    328 
    329     def process(self, ds:ItemList):
--> 330         ds.pad_idx = self.pad_idx
    331         super().process(ds)
    332 
```
I've used a custom `bb_pad_collate()` method, could that have anything to do with the issue?",thanks resolved pickle issue though another issue object attribute trace recent call last module learn path test state path path else path path model path test none test data path state create empty state path path path path state path state return path path state state state state false state false state process self name process self name launch false array none process self processor processor none processor self return self process self process self super used custom method could anything issue,issue,positive,negative,neutral,neutral,negative,negative
471110941,You should first try to update to the latest version of fastai and see if it fixes the bug. We have been working a lot on this since 1.0.41,first try update latest version see bug working lot since,issue,negative,positive,positive,positive,positive,positive
471062035,"Yes create_cnn has been deprecated, you should see a proper error message if you are on the latest fastai, double-check you're not on 0.7",yes see proper error message latest,issue,negative,positive,positive,positive,positive,positive
471037454,"Hi,
I believe create_cnn has been deprecated. Did you try cnn_learner? This problem was brought up on forum... https://forums.fast.ai/t/nameerror-name-create-cnn-is-not-defined/40321/7",hi believe try problem brought forum,issue,negative,neutral,neutral,neutral,neutral,neutral
470981448,"Hi there! New features should be suggested on the appropriate thread on the [forum](https://forums.fast.ai/). We keep issues for standing bugs only.

In the meantime, you can do it manually by creating your own head (just mimic the source code of `create_head`) and then pass your custom head to `create_cnn` with `custom_head=...`.",hi new appropriate thread forum keep standing manually head mimic source code pas custom head,issue,negative,positive,positive,positive,positive,positive
470978350,Closing since it's been two weeks and I can't reproduce the bug. Feel free to re-open with a reproducible example on master.,since two ca reproduce bug feel free reproducible example master,issue,positive,positive,positive,positive,positive,positive
470977965,Re-closing this since we can't reproduce. Please reopen with a reproducible example if needed.,since ca reproduce please reopen reproducible example,issue,negative,neutral,neutral,neutral,neutral,neutral
470976031,"Thanks! Please remember not to run the script to build docs as it makes reading the diff very hard (and would be prone to merge conflicts) though.

Just edit the notebook is enough!",thanks please remember run script build reading hard would prone merge though edit notebook enough,issue,positive,negative,neutral,neutral,negative,negative
470866552,"> Inference stuff on object detection hasn't been implemented yet, I'll work on it in the next few days, but this is a standing issue, yes.

Ohh, I understand ... please let me know when the feature will be available, it's one of the important parts for my project. Thanks)",inference stuff object detection yet work next day standing issue yes understand please let know feature available one important project thanks,issue,positive,positive,positive,positive,positive,positive
470841895,"About the `padding_mode` argument:

There does not seem to be official API documentation about it. It is clearly explained in the general introduction, but maybe people would still have difficulties looking for it?",argument seem official documentation clearly general introduction maybe people would still looking,issue,negative,positive,neutral,neutral,positive,positive
470838757,It is very likely the same issue. I am also using cohen's kappa coefficient. Let me try again.,likely issue also kappa coefficient let try,issue,negative,neutral,neutral,neutral,neutral,neutral
470803884,"Questions like this should be asked on the [forum](https://forums.fast.ai) as we keep the issues for known bugs only.
There are plenty of examples of ItemList in text and tabular. TabulatList returns two inputs for instance.",like forum keep known plenty text tabular two instance,issue,negative,neutral,neutral,neutral,neutral,neutral
470772963,Did that and added stuff to try to find data in any data loader.,added stuff try find data data loader,issue,negative,neutral,neutral,neutral,neutral,neutral
470759089,"but perhaps it can fail in such situation with a user-friend exception message, rather than the current error? e.g.:

   Error: can't call `summary` on a `Learner` object with no training data
",perhaps fail situation exception message rather current error error ca call summary learner object training data,issue,negative,negative,negative,negative,negative,negative
470758577,"I'm not sure it will work in FP16, the bug in FP32 is known and hopefully a fix will arrive soon.",sure work bug known hopefully fix arrive soon,issue,positive,positive,positive,positive,positive,positive
470755593,"And please don't forget to give us your code or a reproducible example when filing an issue, otherwise we can't solve it.",please forget give u code reproducible example filing issue otherwise ca solve,issue,negative,neutral,neutral,neutral,neutral,neutral
470755431,"It's useful to have the index of the array when you want to save multiple files for instance (check `verify_images` in vision.data for instance) but you are right, this absolutely should be documented!
If you can make a PR to the cod notebook core.ipynb and give an example, that would be much appreciated!",useful index array want save multiple instance check instance right absolutely make cod notebook give example would much,issue,positive,positive,positive,positive,positive,positive
470754418,"We should document it, but yes: a `Learner` with no training data can't have summary working. If we want it to work even for complex models, it needs to feed a batch of actual data in the model.",document yes learner training data ca summary working want work even complex need feed batch actual data model,issue,negative,negative,negative,negative,negative,negative
470751506,"Inference stuff on object detection hasn't been implemented yet, I'll work on it in the next few days, but this is a standing issue, yes.
",inference stuff object detection yet work next day standing issue yes,issue,negative,neutral,neutral,neutral,neutral,neutral
470583860,"If it's the same, it was fixed a few hours ago by @sgugger:
https://github.com/fastai/fastai/commit/d5c8be72d6fe14bac7933dfda0b1786442f0aa94
Please try the git master and let us know whether it's resolved for you too.
The fix will be out in the next release.",fixed ago please try git master let u know whether resolved fix next release,issue,negative,positive,neutral,neutral,positive,positive
470579750,"Thank you, @radekosmulski!

Should be doable, but let's see if there is anything else that needs to go in

update: 1.0.47.post1 is out.",thank doable let see anything else need go update post,issue,negative,neutral,neutral,neutral,neutral,neutral
470572782,"Could you guys please document this here:
https://docs.fast.ai/vision.transform.html#resize
or here:
https://docs.fast.ai/vision.image.html#ResizeMethod
whichever is more applicable - and a link to the pytorch issue if there is such, so that we know when it gets fixed?

Thanks.",could please document whichever applicable link issue know fixed thanks,issue,positive,positive,positive,positive,positive,positive
470540788,Had the same [issue](https://github.com/fastai/fastai/issues/1767) yesterday. Add a `;` at the end of the `.load` method to fix the problem,issue yesterday add end method fix problem,issue,negative,neutral,neutral,neutral,neutral,neutral
470489871,Thank you for giving feedback. Now it is better.,thank giving feedback better,issue,positive,positive,positive,positive,positive,positive
470487195,"No, that is the best default for vision problems as it gives better results consistently... but you shouldn't use it if you want to resize with padding and have very rectangular images.",best default vision better consistently use want resize padding rectangular,issue,positive,positive,positive,positive,positive,positive
470486602,"So maybe before PyTorch fixes this problem, we should set the default `padding_mode` to something other than reflection padding?",maybe problem set default something reflection padding,issue,negative,neutral,neutral,neutral,neutral,neutral
470486013,"Ok, the problem was in the metrics that weren't properly defined as dataclass, and it was messing with the representation of your `Learner` (it was loading properly, but since `Learner.load` returns the `Learner` it was trying to show you its repr). If you don't want to install master, just add a ; after `learn.load(...)` and you won't have any error.

Thanks for flagging!",problem metric properly defined messing representation learner loading properly since learner trying show want install master add wo error thanks flagging,issue,negative,positive,neutral,neutral,positive,positive
470482653,"As you can see, this makes the tests fail because sometimes a set of extensions is passed and not a list. There is a convenience function in fastai that will make the thing you pass a list, it's `listify`. Be careful to just leave `extensions` as `None` if it was, as it's tested afterward.",see fail sometimes set list convenience function make thing pas list careful leave none tested afterward,issue,negative,negative,negative,negative,negative,negative
470480689,"Yes, that's exactly the error I was thinking of. Issue is on PyTorch with reflection padding. Pass another `padding_mode`.",yes exactly error thinking issue reflection padding pas another,issue,negative,positive,positive,positive,positive,positive
470433316,"Here we go.

```python
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-56-ee99c62a182b> in <module>
----> 1 data.show_batch(rows=2)

/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_data.py in show_batch(self, rows, ds_type, **kwargs)
    179     def show_batch(self, rows:int=5, ds_type:DatasetType=DatasetType.Train, **kwargs)->None:
    180         ""Show a batch of data in `ds_type` on a few `rows`.""
--> 181         x,y = self.one_batch(ds_type, True, True)
    182         n_items = rows **2 if self.train_ds.x._square_show else rows
    183         if self.dl(ds_type).batch_size < n_items: n_items = self.dl(ds_type).batch_size

/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_data.py in one_batch(self, ds_type, detach, denorm, cpu)
    162         w = self.num_workers
    163         self.num_workers = 0
--> 164         try:     x,y = next(iter(dl))
    165         finally: self.num_workers = w
    166         if detach: x,y = to_detach(x,cpu=cpu),to_detach(y,cpu=cpu)

/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_data.py in __iter__(self)
     73     def __iter__(self):
     74         ""Process and returns items from `DataLoader`.""
---> 75         for b in self.dl: yield self.proc_batch(b)
     76 
     77     @classmethod

/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)
    635                 self.reorder_dict[idx] = batch
    636                 continue
--> 637             return self._process_next_batch(batch)
    638 
    639     next = __next__  # Python 2 compatibility

/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py in _process_next_batch(self, batch)
    656         self._put_indices()
    657         if isinstance(batch, ExceptionWrapper):
--> 658             raise batch.exc_type(batch.exc_msg)
    659         return batch
    660 

RuntimeError: Traceback (most recent call last):
  File ""/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 138, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File ""/opt/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py"", line 138, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/data_block.py"", line 607, in __getitem__
    x = x.apply_tfms(self.tfms, **self.tfmargs)
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/image.py"", line 122, in apply_tfms
    x = tfm(x, size=_get_crop_target(size,mult=mult), padding_mode=padding_mode)
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/image.py"", line 514, in __call__
    return self.tfm(x, *args, **{**self.resolved, **kwargs}) if self.do_run else x
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/image.py"", line 461, in __call__
    if args: return self.calc(*args, **kwargs)
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/image.py"", line 466, in calc
    if self._wrap: return getattr(x, self._wrap)(self.func, *args, **kwargs)
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/image.py"", line 172, in pixel
    self.px = func(self.px, *args, **kwargs)
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/transform.py"", line 191, in _crop_pad
    return f_crop_pad(x, size, padding_mode, row_pct, col_pct)
  File ""/opt/anaconda3/lib/python3.7/site-packages/fastai/vision/transform.py"", line 174, in _crop_pad_default
    x = F.pad(x[None], (col_pad,col_pad,row_pad,row_pad), mode=padding_mode)[0]
  File ""/opt/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py"", line 2685, in pad
    ret = torch._C._nn.reflection_pad2d(input, pad)
RuntimeError: Argument #4: Padding size should be less than the corresponding input dimension, but got: padding (46, 46) at dimension 3 of input [1, 3, 128, 36]
```",go python recent call last module self self none show batch data true true else self detach try next iter finally detach self self process yield self batch continue return batch next python compatibility self batch batch raise return batch recent call last file line file line file line file line size file line return else file line return file line return file line file line return size file line none file line pad ret input pad argument padding size le corresponding input dimension got padding dimension input,issue,negative,positive,neutral,neutral,positive,positive
470361994,"There you go.

```
#!/usr/bin/env python
# coding: utf-8

# In[1]:


from fastai.vision import * 


# In[17]:


BASE_PATH = Path(""."")
TEST_IMG = BASE_PATH/""test_images""
TRAIN_IMG = BASE_PATH/""train_images""
TRAIN_CSV = BASE_PATH/""train/train.csv""
TEST_CSV = BASE_PATH/""test/test.csv""
IMG_SIZE = 99
BATCH_SIZE = 512
PATH = Path(""."")
KAGGLE_PATH = Path(""model_dir"")


# In[3]:


train = pd.read_csv(TRAIN_CSV)
test = pd.read_csv(TEST_CSV)
train_images = os.listdir(TRAIN_IMG)
test_images = os.listdir(TEST_IMG)


# In[4]:


train_img_only = train[[""PetID"", ""AdoptionSpeed""]]
test_img_only = test[[""PetID""]]


# In[5]:


train_img_only[""PetID""] = train_img_only[""PetID""].apply(lambda x: x + ""-1.jpg"")
test_img_only[""PetID""] = test_img_only[""PetID""].apply(lambda x: x + ""-1.jpg"")
train_img_only = train_img_only[train_img_only[""PetID""].isin(train_images)]
test_img_only = test_img_only[test_img_only[""PetID""].isin(test_images)]


# In[6]:


test_img_only[""AdoptionSpeed""] = 2
train_img_only[""PetID""] = train_img_only[""PetID""].apply(lambda x: ""train_images/"" + x )
test_img_only[""PetID""] = test_img_only[""PetID""].apply(lambda x: ""test_images/"" + x)


# In[18]:


data = ImageDataBunch.from_df(BASE_PATH, 
                              train_img_only, 
                              size=IMG_SIZE, ds_tfms=get_transforms(), label_col=""AdoptionSpeed"",
                              num_workers=0,valid_pct=0.2, bs=256
                              )
data.add_test(ImageImageList.from_folder(TEST_IMG))
data.normalize(imagenet_stats);


# In[16]:


data.show_batch(3)


# In[25]:


kappa = KappaScore()
kappa.weights = ""quadratic""    
learn = create_cnn(data, models.resnet34, metrics=[accuracy, kappa])


# In[22]:


learn.fit_one_cycle(2)


# In[23]:


learn.lr_find()


# In[24]:


learn.recorder.plot()


# In[25]:


learn.fit_one_cycle(6, max_lr=slice(1e-4, 1e-3))


# In[26]:


learn.unfreeze()


# In[27]:


learn.lr_find()


# In[28]:


learn.recorder.plot()


# In[29]:


learn.fit_one_cycle(5, max_lr=slice(1e-5, 1e-4))


# In[26]:


learn.save(""v24"")


# In[27]:


learn.load(""v24"")
```",go python import path path path path train test train test lambda lambda lambda lambda data kappa quadratic learn data accuracy kappa,issue,negative,neutral,neutral,neutral,neutral,neutral
470347505,"I found 
train = ImageList.from_csv(path, 'train.csv')#.use_partial_data(0.001)
That seems what i want",found train path want,issue,negative,neutral,neutral,neutral,neutral,neutral
470345528,"Depending on where you are getting it from you can usually do this by simply creating a folder/csv/etc folder with a small subset of your dataset. 

Also these question on how to use the library belongs on the forum, so that others are available to answer, and see the answers that you get as well. ",depending getting usually simply folder small subset also question use library forum available answer see get well,issue,negative,positive,neutral,neutral,positive,positive
470291632,"Thank you, that seems to have fixed it. I think I was getting some CUDA/CPU errors before when I was using the 
```
learn.lossfunc = CrossEntropyFlat(weight = w).cuda())
```
and then when I changed it to try to specify the Flattened version I got the errors I flagged in this issue. It seems to be working now after some changes to the Tensor type. 

I think the original error might have come when I was trying to modify the CrossEntropyFlat.",thank fixed think getting weight try specify version got issue working tensor type think original error might come trying modify,issue,negative,positive,positive,positive,positive,positive
470287786,"Ah, you're right. 
But I can't reproduce your initial bug: just tried
``` 
learn.lossfunc = CrossEntropyFlat(weight = Tensor([1.] * data.c).cuda())
```
on a classification and a segmentation task and I didn't get any errors.",ah right ca reproduce initial bug tried weight tensor classification segmentation task get,issue,negative,positive,positive,positive,positive,positive
470283064,"I tried that but I get the following error after doing ```learn.loss_func = FlattenedLoss(nn.CrossEntropyLoss(weight=w))```:

```
TypeError: forward() missing 2 required positional arguments: 'input' and 'target'
```",tried get following error forward missing positional,issue,negative,negative,neutral,neutral,negative,negative
470210984,"We can't help without seeing the whole code and have a reproducible example. This is probably related to the model you're using, which you don't show here.",ca help without seeing whole code reproducible example probably related model show,issue,negative,positive,neutral,neutral,positive,positive
470179449,"You’re right, I used pip uninstall and I thought it was uninstalled, but I found there’s still an empty folder called pretrainedmodels, after deleting it manually now the import error shows. So we’re all good!",right used pip thought uninstalled found still empty folder manually import error good,issue,negative,positive,positive,positive,positive,positive
470164079,"And I just made several tries, can confirm I see the message properly displayed if I try
```
from fastai.vision.models.cadene_models import *
```
without pretrainedmodels installed.",made several confirm see message properly displayed try import without,issue,negative,neutral,neutral,neutral,neutral,neutral
470161833,"Oh pmodels is my bad, it was when I had imported pretrainedmodels with a shorter name. Will fix with the noop!
",oh bad shorter name fix noop,issue,negative,negative,negative,negative,negative,negative
470160815,"Hi, I have done more checking, they’re all good if:
1. Change the cut of “None” into “noop” (nasnetamobile and pnasnet5large)
2. “pmodels” is not defined, change that into model name string (6 places in the file)

Thanks!
",hi done good change cut none noop defined change model name string file thanks,issue,positive,positive,positive,positive,positive,positive
470155163,"Please use the [forum](https://forums.fast.ai) for debugging, GitHub issues are for bugs in the library only.",please use forum library,issue,negative,neutral,neutral,neutral,neutral,neutral
470152051,"Hi.. I'm working on multi-level image classification problem and need prediction level for all the images specified in a train dataset..I'm using the followings to create Data bunch…

**data = ImageDataBunch.from_folder(path, train=""."", valid_pct=0.1,  ds_tfms=get_transforms(), size=224, num_workers=4).normalize(imagenet_stats)**
Getting the nice predictions, however prediction file is not having the image name but series of integers starting 0 , 1 ,2 ,3 etc..which is not matching with the training set name and order both. Pls note that image names are in text not numbers...Pls suggest what can be done.?
",hi working image classification problem need prediction level train create data data path getting nice however prediction file image name series starting matching training set name order note image text suggest done,issue,negative,positive,positive,positive,positive,positive
470147214,I will remember sticking to code style next time :),remember sticking code style next time,issue,negative,neutral,neutral,neutral,neutral,neutral
470146696,You may not have to. problem comes from the representation of the strings and the way they are displayed in jupyter. I hacked a little thing to fix this.,may problem come representation way displayed hacked little thing fix,issue,negative,negative,negative,negative,negative,negative
470141787,I was not sure if that was intended or not. So now I just have to run like this `print(learn.summary()`,sure intended run like print,issue,positive,positive,positive,positive,positive,positive
470139768,"No, the fact the function doesn't print anything and returns text is intended. It's like when you type `learn.model`: PyTorch doesn't print the model, it returns it, so if you have a later statement in the same cell, you don't see the model.
We do have to find a way to make the result show more prettily in jupyter, that's a given.",fact function print anything text intended like type print model later statement cell see model find way make result show prettily given,issue,negative,positive,positive,positive,positive,positive
470138753,"Yes cut can be a function or an int now, and the old way of doing None should correspond to `noop`.
I'll test more the import issue and report.",yes cut function old way none correspond noop test import issue report,issue,negative,positive,neutral,neutral,positive,positive
470137858,"As always, please give the full stack trace when filing an issue. I don't think this in fastai but probably in PyTorch's pad function: with the default padding mode of reflect, and the fact you have very narrow images, I think it breaks (it can't reflect more than once the image).
Test with `padding_mode = zeros` for instance. ",always please give full stack trace filing issue think probably pad function default padding mode reflect fact narrow think ca reflect image test instance,issue,negative,positive,neutral,neutral,positive,positive
470133609,"Hi, thanks for the cleaning up, it looks way better and fastai-ish now! The code itself looks good, however some recent changes in the “vision/learner.py” may affect the cases where I deliberately set cut to None (I should set to “noop” probably), I’ll test those cases more.

But one thing I notice is, if I uninstall “pretrainedmodels” and run it, it won’t raise error during importing (never reach line 9). Not sure why this is happening, but that’s why in the original code I checked whether it has inceptionv4 (or any model) in the import part. I wonder was this the case on your side as well, or something weird in my environment? Thanks",hi thanks cleaning way better code good however recent may affect deliberately set cut none set noop probably test one thing notice run raise error never reach line sure happening original code checked whether model import part wonder case side well something weird environment thanks,issue,positive,positive,positive,positive,positive,positive
469958489,"@Gokkulnath Ah, I believe that it is pretty general. Cannot recall exactly how it happened.

Here is my tip on how to recreate it:

- Clone two copies of your forked repositories.
- In cloned repo No. 1, make a change in a cell you choose in Jupyter Lab that will lead to output change. Commit and push it.
- In cloned repo No. 2, make a different change in the same cell you choose in Jupyter Notebook that will lead to a different output change. Commit.
- Now when you check `git status` in repo No. 2, you should be able to see something like that it has diverged from the remote.
- Then try to pull from remote and see what happens. What happened to me is that everything breaks apart.",ah believe pretty general recall exactly tip recreate clone two forked make change cell choose lab lead output change commit push make different change cell choose notebook lead different output change commit check git status able see something like remote try pull remote see everything apart,issue,positive,positive,positive,positive,positive,positive
469857241,"Ok, this is going to require a lot of adjusting, but I've been bugging Jeremy to change that name since... everything else was called learner :)",going require lot change name since everything else learner,issue,negative,neutral,neutral,neutral,neutral,neutral
469837179,"The batch size isn't 1 by default, it's the same as the training set. You have to create a new `DataBunch` object for tests to change it.",batch size default training set create new object change,issue,negative,positive,positive,positive,positive,positive
469796848," @odysseus0 Can you please share more details on what problem you faced when running fastai-nbstripout  script on jupyterlab notebooks ?
 I am currently working on making fastai-nbstripout compatible with jupyter lab notebook as well. Can you provide a sample notebook where you had faced the issue.
P.S : I Tried running the tool on lesson notebook and i dont see any difference in the resulting files. I have to check the Doc Notebooks now.. ",please share problem faced running script currently working making compatible lab notebook well provide sample notebook faced issue tried running tool lesson notebook dont see difference resulting check doc,issue,negative,neutral,neutral,neutral,neutral,neutral
469768820,"If it doesn't work with `defaults.cpus=1` then it really comes down to the dataset not fitting in RAM. If you don't even see a progress bar appearing, it means the full dataset with all the texts opened doesn't fit in your RAM.
You should try to tokenize it text by text outside of fastai and put it in a csv/dataframe, then you can use `TextList.from_csv` or `TextList.from_df` with `processor=NumericalizeProcessor` to load it.",work really come fitting ram even see progress bar full fit ram try text text outside put use load,issue,positive,positive,positive,positive,positive,positive
469767099,"Ok, refactored all the duplicates. I checked every model could still load, but I may have done some mistake, so if you don't mind too much, can you double-check I didn't break anything? Thanks a lot!",checked every model could still load may done mistake mind much break anything thanks lot,issue,negative,positive,positive,positive,positive,positive
469758642,"@sgugger I tried you suggestion of setting the defaults.cpu = 1, but it is not working.

Also, I narrow down the issue, and the method 'label_for_lm' is causing it, still not sure why.

Below is the updated code:

`defaults.cpus=1`
`data_lm = (TextList.from_folder(path)
             .filter_by_folder(include=['train', 'test', 'unsup'])
             .random_split_by_pct(0.1)
             .label_for_lm())`

Any idea what can I try next, this is blocking me.",tried suggestion setting working also narrow issue method causing still sure code path idea try next blocking,issue,negative,positive,neutral,neutral,positive,positive
469754679,Thanks! I'll refactor the code a little but this is great!,thanks code little great,issue,positive,positive,positive,positive,positive,positive
469698881,"Ooops, forgot this one, thanks a lot!",forgot one thanks lot,issue,negative,positive,positive,positive,positive,positive
469695895,"This should be in the error message you get, see [here](https://github.com/fastai/fastai/blob/015bc2893ffbec73fc97f69e6c8ad51a115d058c/fastai/basic_train.py#L169).
",error message get see,issue,negative,neutral,neutral,neutral,neutral,neutral
469693158,"It's great. Thanks. @sgugger  It works in my [kernel ver13](https://www.kaggle.com/liuyd2018/planet-multi-label-image-classification?scriptVersionId=11164873)
I set bs=1 for prediction and got 0.93 score ranking top 11% ^^

",great thanks work kernel set prediction got score top,issue,positive,positive,positive,positive,positive,positive
469614065,"Update: After reading some code, I fixed it by passing the `path` variable. Perhaps good idea to make this explicit? :)
```
learn = create_cnn(data, models.resnet34, metrics=[accuracy], 
                   model_dir=Path(""/kaggle/working/""), 
                   path=Path("".""))
```",update reading code fixed passing path variable perhaps good idea make explicit learn data accuracy,issue,negative,positive,positive,positive,positive,positive
469596673,@sgugger thanks for catching this. Please let me know if there are any more changes to be made.,thanks catching please let know made,issue,positive,positive,positive,positive,positive,positive
469584970,"Thanks for the suggestion @sgugger but the problem still remains. I used the following line:

`learn = create_cnn(data, models.resnet34, metrics=[accuracy], model_dir=Path(""/kaggle/working/""))`

And still get the error:
```
---------------------------------------------------------------------------
OSError                                   Traceback (most recent call last)
<ipython-input-34-d81c6bd29d71> in <module>()
----> 1 learn.lr_find()

/opt/conda/lib/python3.6/site-packages/fastai/train.py in lr_find(learn, start_lr, end_lr, num_it, stop_div, wd)
     30     cb = LRFinder(learn, start_lr, end_lr, num_it, stop_div)
     31     epochs = int(np.ceil(num_it/len(learn.data.train_dl)))
---> 32     learn.fit(epochs, start_lr, callbacks=[cb], wd=wd)
     33 
     34 def to_fp16(learn:Learner, loss_scale:float=None, max_noskip:int=1000, dynamic:bool=False, clip:float=None,

/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
    180         if defaults.extra_callbacks is not None: callbacks += defaults.extra_callbacks
    181         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,
--> 182             callbacks=self.callbacks+callbacks)
    183 
    184     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

/opt/conda/lib/python3.6/site-packages/fastai/utils/mem.py in wrapper(*args, **kwargs)
     87 
     88         try:
---> 89             return func(*args, **kwargs)
     90         except Exception as e:
     91             if (""CUDA out of memory"" in str(e) or

/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)
    101         exception = e
    102         raise
--> 103     finally: cb_handler.on_train_end(exception)
    104 
    105 loss_func_name2activ = {'cross_entropy_loss': F.softmax, 'nll_loss': torch.exp, 'poisson_nll_loss': torch.exp,

/opt/conda/lib/python3.6/site-packages/fastai/callback.py in on_train_end(self, exception)
    289     def on_train_end(self, exception:Union[bool,Exception])->None:
    290         ""Handle end of training, `exception` is an `Exception` or False if no exceptions during training.""
--> 291         self('train_end', exception=exception)
    292 
    293 class AverageMetric(Callback):

/opt/conda/lib/python3.6/site-packages/fastai/callback.py in __call__(self, cb_name, call_mets, **kwargs)
    212         ""Call through to all of the `CallbakHandler` functions.""
    213         if call_mets: [getattr(met, f'on_{cb_name}')(**self.state_dict, **kwargs) for met in self.metrics]
--> 214         return [getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs) for cb in self.callbacks]
    215 
    216     def set_dl(self, dl:DataLoader):

/opt/conda/lib/python3.6/site-packages/fastai/callback.py in <listcomp>(.0)
    212         ""Call through to all of the `CallbakHandler` functions.""
    213         if call_mets: [getattr(met, f'on_{cb_name}')(**self.state_dict, **kwargs) for met in self.metrics]
--> 214         return [getattr(cb, f'on_{cb_name}')(**self.state_dict, **kwargs) for cb in self.callbacks]
    215 
    216     def set_dl(self, dl:DataLoader):

/opt/conda/lib/python3.6/site-packages/fastai/callbacks/lr_finder.py in on_train_end(self, **kwargs)
     43         # restore the valid_dl we turned off on `__init__`
     44         self.data.valid_dl = self.valid_dl
---> 45         self.learn.load('tmp')
     46         if hasattr(self.learn.model, 'reset'): self.learn.model.reset()
     47         print('LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.')

/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py in load(self, name, device, strict, with_opt, purge)
    241     def load(self, name:PathOrStr, device:torch.device=None, strict:bool=True, with_opt:bool=None, purge:bool=True):
    242         ""Load model and optimizer state (if `with_opt`) `name` from `self.model_dir` using `device`.""
--> 243         if purge: self.purge(clear_opt=ifnone(with_opt, False))
    244         if device is None: device = self.data.device
    245         state = torch.load(self.path/self.model_dir/f'{name}.pth', map_location=device)

/opt/conda/lib/python3.6/site-packages/fastai/basic_train.py in purge(self, clear_opt)
    287         state['cb_state'] = {cb.__class__:cb.get_state() for cb in self.callbacks}
    288         if hasattr(self, 'opt'): state['opt'] = self.opt.get_state()
--> 289         torch.save(state, open(tmp_file, 'wb'))
    290         for a in attrs_del: delattr(self, a)
    291         gc.collect()

OSError: [Errno 30] Read-only file system: '../input/petfinder-adoption-prediction/train_images/purge-tmp.pkl'
```",thanks suggestion problem still remains used following line learn data accuracy still get error recent call last module learn learn learn learner dynamic clip fit self none fit self none wrapper try return except exception memory fit model opt data metric exception raise finally exception self exception self exception union bool exception none handle end training exception exception false training self class self call met met return self call met met return self self restore turned print finder complete type see graph load self name device strict purge load self name device strict purge load model state name device purge false device none device state name purge self state self state state open self file system,issue,positive,positive,neutral,neutral,positive,positive
469451599,"It's not a problem of general RAM but GPU RAM. This has nothing to do with your dataset, you should reduce your batch size by passing bs=... in the call to `TextClasDataBunch`",problem general ram ram nothing reduce batch size passing call,issue,negative,positive,neutral,neutral,positive,positive
469432182,Leaving it open till this is sorted out based on @sgugger's request.,leaving open till sorted based request,issue,negative,neutral,neutral,neutral,neutral,neutral
469431972,"OK, talking to @sgugger, this of course will make an unnecessary requirement for users who won't use any of the functions that do tmp writing. So his approach is a better design. And we will add automatic error handling like the recent change in purge, so it'll be doing self-diagnostic and not require reading docs.",talking course make unnecessary requirement wo use writing approach better design add automatic error handling like recent change purge require reading,issue,negative,positive,neutral,neutral,positive,positive
469426924,"@parthopdas, it looks like someone started a similar thread in the forums already:
https://forums.fast.ai/t/v1-api-changes-too-drastic/31903/
So perhaps proceed there - I will share my thoughts as well.",like someone similar thread already perhaps proceed share well,issue,positive,neutral,neutral,neutral,neutral,neutral
469399017,"Ok, you can know pass `db_kwargs` in that method that will be passed to the call to `databunch` internally. This way you can set `num_workers` to 0, or specify a `bs` for your test set.",know pas method call internally way set specify test set,issue,negative,neutral,neutral,neutral,neutral,neutral
469396215,"This all sounds great, and having `num_features` executed only if there is no custom head passed seems like a very good idea.
Thanks a lot!",great executed custom head like good idea thanks lot,issue,positive,positive,positive,positive,positive,positive
469394491,"Discussed it with Jeremy and we feel it's up to the user to squeeze according to the proper dim (you might get a batch size of 1 in your model independently of `learn.summary`), so closing this.",feel user squeeze according proper dim might get batch size model independently,issue,negative,positive,neutral,neutral,positive,positive
469392095,"If you're interested, [here](https://github.com/fastai/fastai/commit/d7bd9c8e6ae0de03e646eb82f24d725a94ec0062) is the bit of refactor I added. You can do both in a single event (since they are only reset at `on_batch_begin`) and no need to return `False`.",interested bit added single event since reset need return false,issue,negative,negative,neutral,neutral,negative,negative
469354095,"@maykulkarni 
In the training phase, I also set num_workers=0. It's ok.
But, In the deploy phase, I don't know how to set this value when the error happens again.",training phase also set deploy phase know set value error,issue,negative,neutral,neutral,neutral,neutral,neutral
469344562,I had a similar error in `ImageDataBunch` which I fixed by passing `num_workers=0`,similar error fixed passing,issue,negative,positive,neutral,neutral,positive,positive
469320185,"@sgugger, instead of documenting this for each method that uses tmp writing, and having it difficult for users to figure out, I suggest that Learner should run  `_get_writable_model_path` in its constructor as a check, which will instruct the user what to do to fix this for all such methods that later get called on that learn object. The function tries to create a tmp file in that folder and throws an exception with instructions on how to fix that.

I can add this if you think it's a good approach.",instead method writing difficult figure suggest learner run constructor check instruct user fix later get learn object function create file folder exception fix add think good approach,issue,negative,positive,neutral,neutral,positive,positive
469316012,It will use the same `model_dir` directory to save the temporary model. So pass an absolute `Path` object when creating your `Learner` with `model_dir` and you shouldn't have any problem.,use directory save temporary model pas absolute path object learner problem,issue,negative,positive,positive,positive,positive,positive
469299838,"Thanks for the reply.
No, I don't see any progress bars in this case. It happens before the progress bars. The RAM increase up-to 8 GB and then boom.

I will give your suggestion a try and report back here. @sgugger i can only find num_workers parameter, should i set this to 1? ([DataBunch](https://docs.fast.ai/basic_data.html#DataBunch))",thanks reply see progress case progress ram increase boom give suggestion try report back find parameter set,issue,positive,positive,neutral,neutral,positive,positive
469298947,"thanks, to copy the weight dictionary, which fastai api should i use?  i'm using resnet34 model.",thanks copy weight dictionary use model,issue,negative,positive,positive,positive,positive,positive
469281390,"I have never managed to reproduce those OOM errors, my first suggestion is to try without multiprocessing by setting `defaults.cpus=1` since python doesn't manage well the RAM usage with multiprocessing (copying the array over the processes).
Though from your stack trace, it looks like this is happening during the numericalization and not the tokenization (can you confirm you were done with the progress bars)?",never reproduce first suggestion try without setting since python manage well ram usage array though stack trace like happening confirm done progress,issue,positive,positive,positive,positive,positive,positive
469280420,"Thanks for doing this! There is a little problem with `skip_end`: you should aim for the same behavior as `learn.recorder.plot()` so it should be `-skip_end` if `skip_end>0`. Check [here](https://github.com/fastai/fastai/blob/94666ebe0b9f9b8c36d7cbcfc9376465650d56f2/fastai/basic_train.py#L505) for more details.

There is going to be a mismatch with the validation loss indeed, but I can deal with that once we have fixed the `skip_end` part and merged your PR.",thanks little problem aim behavior check going mismatch validation loss indeed deal fixed part,issue,negative,positive,neutral,neutral,positive,positive
469279047,"Looks like I forgot to update this one in my big changes yesterday! Thanks for flagging. Note that there is no need to return `False` since it's the default, only `True` is necessary. Will refactor later today.",like forgot update one big yesterday thanks flagging note need return false since default true necessary later today,issue,positive,positive,neutral,neutral,positive,positive
469278375,I'm not sure you have the latest version of fastai if AWD_LSTM doesn't work. It's not supposed to work with quotes.,sure latest version work supposed work,issue,negative,positive,positive,positive,positive,positive
469277980,I don't think there is an option to remove multiprocessing in `load_learner` yet. Will look today.,think option remove yet look today,issue,negative,neutral,neutral,neutral,neutral,neutral
469277680,"You can't without creating a new model and digging into the weight dictionary to copy what you can. You should retrain your model with the new classes, with transfer learning it's pretty fast in any case.",ca without new model digging weight dictionary copy retrain model new class transfer learning pretty fast case,issue,negative,positive,positive,positive,positive,positive
469277288,"Yes, you should subclass `ImageList` with your custom open function from now on.",yes subclass custom open function,issue,negative,neutral,neutral,neutral,neutral,neutral
469224474,"@sgugger I am not sure if the Validation plots are correct. Could you please review this PR and share your feedback.

Thank you so much.
 ",sure validation correct could please review share feedback thank much,issue,positive,positive,positive,positive,positive,positive
469171986,"Okay so I figured out, there is typo in that notebook,
""AWD_LSTM"" must be given in quotes otherwise we'll get keyerror: AWD_LSTM is not defined.",figured typo notebook must given otherwise get defined,issue,negative,neutral,neutral,neutral,neutral,neutral
469078283,"Thanks.
I will open a new issue since I can use the latest version 1.0.47 in my kaggle notebook.
",thanks open new issue since use latest version notebook,issue,negative,positive,positive,positive,positive,positive
469062529,It's more an issue of `self._path` not being a Path object. Will fix that.,issue path object fix,issue,negative,neutral,neutral,neutral,neutral,neutral
469056765,"I'm having a difficult time with this (mis-)communication. You opened a ticket with a problem in `purge`. I added a fix and requested that you validate it, and now 2 replies in a row, you're not validating the fix, but talking about other things. I'm not sure how to proceed.

Let's focus in this thread on `purge` and if there are sill problems with it, please re-open the ticket and we will continue solving it.

For other issues please open new tickets and we will sort them out.

Thank you.",difficult time communication ticket problem purge added fix validate row fix talking sure proceed let focus thread purge sill please ticket continue please open new sort thank,issue,positive,positive,neutral,neutral,positive,positive
469031109,"We keep the GitHub issues for standing bugs only, but the discussion can completely continue on the forum. Feel completely free to open a thread on this!",keep standing discussion completely continue forum feel completely free open thread,issue,positive,positive,positive,positive,positive,positive
469030864,"@sgugger should we at least keep this issue open.

Few reasons:
- We walk through prod deployment scenarios in the lessons, meaning we can 'go live' with v1
- It's certainly a pain to upgrade the library and find things broken, rather badly.
- My understanding is that we start this semver with v1 release in general 

Also do you recommend I initiate a forum thread asking for opinions? ",least keep issue open walk prod deployment meaning live certainly pain upgrade library find broken rather badly understanding start release general also recommend initiate forum thread,issue,negative,negative,negative,negative,negative,negative
469030325,"@sgugger possibly. Since the issue is exposed though fastai, I have filed it here.

I'll debug into create_cnn and report back with more info. ",possibly since issue exposed though report back,issue,negative,neutral,neutral,neutral,neutral,neutral
469030171,"This can be discussed more on the forum, but basically we don't follow semantic versioning for now. The API is only stabilizing and we may change when we release a stable v1.1, but we're not there yet ;)",forum basically follow semantic may change release stable yet,issue,negative,neutral,neutral,neutral,neutral,neutral
469030055,"If the freeze happens with pytorch 1.0.1 and not 1.0.0 it seems like a bug in pytorch, no? Could you maybe try to execute the code in `create_cnn` line by line to figure out which instruction is causing the freeze?",freeze like bug could maybe try execute code line line figure instruction causing freeze,issue,negative,neutral,neutral,neutral,neutral,neutral
469029818,"In single classification, the labels aren't one-hot encoded since because the loss function of pytorch (`F.cross_entropy` and `F.nll_loss`) expect it that way.",single classification since loss function expect way,issue,negative,negative,neutral,neutral,negative,negative
469029371,"It may also be the moms too low that breaks training. I had no issue training a model on WT103 to a very low perplexity.
I'd suggest keeping the conversation on the forum until we identify a clear bug (if there is one) and then open an issue when that's the case.",may also low training issue training model low perplexity suggest keeping conversation forum identify clear bug one open issue case,issue,negative,positive,neutral,neutral,positive,positive
469027338,"Fastai works well on Win10 + GPU. Here are the [informal instructions](https://github.com/parthopdas/c-fastai2019/blob/master/README.md).

Work is underway to formalize this, potentially into the fastai documentation itself. Please stay tuned. ",work well win informal work underway formalize potentially documentation please stay tuned,issue,positive,positive,positive,positive,positive,positive
469022560,"I get the latest version of 1.0.47 dev
I use learn.export(fname='/kaggle/working/export.pkl',destroy=True) to instead of learn.purge, but still returns an error:
DataLoader worker (pid 94) is killed by signal: Bus error.

[my notebook ver11](https://www.kaggle.com/liuyd2018/planet-multi-label-image-classification?scriptVersionId=11100303)
@stas00 

I decided to use learn2 as a new learn object and see what happens.",get latest version dev use instead still error worker signal bus error notebook decided use learn new learn object see,issue,negative,positive,positive,positive,positive,positive
468986786,"> conda install -c pytorch pytorch cuda100

You are right master @stas00 , thanks a lot !!",install right master thanks lot,issue,negative,positive,positive,positive,positive,positive
468982906,"> **Please use: pip install git+https://github.com/fastai/fastai to get the latest git and verify that the solution works for you, @CoderOverflow.**",please use pip install get latest git verify solution work,issue,positive,positive,positive,positive,positive,positive
468982276,"I have set the model_dir in learn.create_cnn but it seems doesn't work 
as [my notebook ver5](https://www.kaggle.com/liuyd2018/planet-multi-label-image-classification?scriptVersionId=11066484) Shows.

Lastest Kaggle notebook runs with version 1.0.45

and one more thing
```
del learn
gc.collect()
```
also failed
as [my notebook ver6](https://www.kaggle.com/liuyd2018/planet-multi-label-image-classification?scriptVersionId=11073163) shows

@stas00 
",set work notebook notebook version one thing learn also notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
468971726,"Apologies, there was a better solution to this issue - therefore, `tmppath` had a very short life and is now gone.

Instead set the model_dir attribute in Learner to a full libpath path that is writable (by setting learn.model_dir or passing model_dir argument in the Learner constructor).

As described in the now updated document: https://docs.fast.ai/basic_train.html#Learner.purge

Please use: `pip install git+https://github.com/fastai/fastai` to get the latest git and verify that the solution works for you, @CoderOverflow.",better solution issue therefore short life gone instead set attribute learner full path writable setting passing argument learner constructor document please use pip install get latest git verify solution work,issue,positive,positive,positive,positive,positive,positive
468945096,"This has now been fixed in master, by adding a new purge arg: `tmppath`, please see the updated doc
https://docs.fast.ai/basic_train.html#Learner.purge
",fixed master new purge please see doc,issue,negative,positive,positive,positive,positive,positive
468778321,"This has to do with this weird python feature:
https://github.com/encode/django-rest-framework/issues/2108#issuecomment-73504704
so basically, `self.data.loss_func` fails (no `train_ds.y`), and instead of giving the user the traceback for that failure, python falls back to `__getattr__` and fails there with a totally wrong error.
",weird python feature basically instead giving user failure python back totally wrong error,issue,negative,negative,negative,negative,negative,negative
468768041,"short term workaround: comment out this line

`self.loss_func = ifnone(self.loss_func, self.data.loss_func)` in `fastai/basic_train.py` 
",short term comment line,issue,negative,neutral,neutral,neutral,neutral,neutral
468760080,"Thank you, @bearpelican! Will be experimenting with it shortly and send feedback.",thank shortly send feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
468727464,"Hello!

I encounter this error when running through `lesson5-sgd-mnist.ipynb`.
My VM is running fastai v1.0.46 (anaconda), python 3.7.1

```python
# cell 18
loss_func = nn.CrossEntropyLoss()

# cell 34
learn = Learner(data, Mnist_NN(), loss_func=loss_func, metrics=accuracy)
```

```
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-34-cc98ebe3feca> in <module>
----> 1 learn = Learner(data, Mnist_NN(), loss_func=nn.CrossEntropyLoss, metrics=accuracy)

<string> in __init__(self, data, model, opt_func, loss_func, metrics, true_wd, bn_wd, wd, train_bn, path, model_dir, callback_fns, callbacks, layer_groups, add_time)

/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py in __post_init__(self)
    155         (self.path/self.model_dir).mkdir(parents=True, exist_ok=True)
    156         self.model = self.model.to(self.data.device)
--> 157         self.loss_func = ifnone(self.loss_func, self.data.loss_func)
    158         self.metrics=listify(self.metrics)
    159         if not self.layer_groups: self.layer_groups = [nn.Sequential(*flatten_model(self.model))]

/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_data.py in __getattr__(self, k)
    120         return cls(*dls, path=path, device=device, dl_tfms=dl_tfms, collate_fn=collate_fn, no_check=no_check)
    121 
--> 122     def __getattr__(self,k:int)->Any: return getattr(self.train_dl, k)
    123     def __setstate__(self,data:Any): self.__dict__.update(data)
    124 

/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_data.py in __getattr__(self, k)
     36 
     37     def __len__(self)->int: return len(self.dl)
---> 38     def __getattr__(self,k:str)->Any: return getattr(self.dl, k)
     39     def __setstate__(self,data:Any): self.__dict__.update(data)
     40 

/opt/anaconda3/lib/python3.7/site-packages/fastai/basic_data.py in DataLoader___getattr__(dl, k)
     18 torch.utils.data.DataLoader.__init__ = intercept_args
     19 
---> 20 def DataLoader___getattr__(dl, k:str)->Any: return getattr(dl.dataset, k)
     21 DataLoader.__getattr__ = DataLoader___getattr__
     22 

AttributeError: 'TensorDataset' object has no attribute 'loss_func'
```

Any advise on how I may resolve this? I am happy to raise a new issue if indeed this is a bug.

Thank you.",hello encounter error running running anaconda python python cell cell learn learner data recent call last module learn learner data string self data model metric path self self return self return self data data self self return self return self data data return object attribute advise may resolve happy raise new issue indeed bug thank,issue,positive,positive,positive,positive,positive,positive
468686028,"We need to think better about the serialization, that's a given, but we are also waiting for the API to have fully stabilized. I had given a load old to new script in the [developer chat](https://forums.fast.ai/t/developer-chat/22363/750?u=sgugger) that you might have missed, and it's not inside the library on purpose since its use is only temporary. Closing this as a result.",need think better serialization given also waiting fully given load old new script developer chat might inside library purpose since use temporary result,issue,negative,positive,positive,positive,positive,positive
468674795,"Hi there! Please use the [forum](https://forums.fast.ai/) for question around the library as we prefer to keep issues for bugs only.
The model is going to be downloaded automatically when you execute the instruction, like torchvision does. As for AWD_LSTM, it's an architecture so a class of nn.Module.",hi please use forum question around library prefer keep model going automatically execute instruction like architecture class,issue,positive,neutral,neutral,neutral,neutral,neutral
468618907,"I've added _version following the unpublished documentation of pytorch:
https://github.com/pytorch/pytorch/blob/master/torch/nn/modules/module.py#L50-L60
",added following unpublished documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
468419479,I think it can be documented in `core` when documenting `defaults` without confusing anyone. People won't know the option is available otherwise.,think core without anyone people wo know option available otherwise,issue,negative,positive,positive,positive,positive,positive
468366137,"@sgugger where exactly do you want more documentation?
I think the feature is small enough, the argument name `return_fig` good enough that it doesn't need more docs. I think it would actually hamper the readability of the docs (depending on where you put it).",exactly want documentation think feature small enough argument name good enough need think would actually hamper readability depending put,issue,negative,positive,positive,positive,positive,positive
468299481,"Thanks a lot, that's exactly what I had in mind! 
The example notebook is great, if you don't mind, you should take a few examples in it and add them to the docs notebook so that this new argument is properly documented.",thanks lot exactly mind example notebook great mind take add notebook new argument properly,issue,positive,positive,positive,positive,positive,positive
468176018,"Of course you're right, the current implementation breaks the workflow of many people. I'll create a new PR adjust the following:
- add a global `return_fig` to `defaults`
- add `return_fig` flag to all plot functions
- use the global `default.return_fig` if `return_fig is None` 

I did a test in a notebook and saw two plots, but added an `;` at the end of the line immediately without even thinking, just habit in these cases. Some people argue that showing every plot automatically in the notebook environment is a great feature, some people would prefer an explicit return :) I mostly work in IDEs/editors and the problem/the second plot is not visible there. 

Thanks @sgugger and @stas00!",course right current implementation many people create new adjust following add global add flag plot use global none test notebook saw two added end line immediately without even thinking habit people argue showing every plot automatically notebook environment great feature people would prefer explicit return mostly work second plot visible thanks,issue,positive,positive,positive,positive,positive,positive
468165171,"Perhaps, propose a PR that adjusts `export` to check whether the folder is writable, and if it's not to suggest to a user to use the `fname` argument instead? Thanks.",perhaps propose export check whether folder writable suggest user use argument instead thanks,issue,negative,positive,positive,positive,positive,positive
468164431,can use fname parameter to set the filename with full path,use parameter set full path,issue,negative,positive,positive,positive,positive,positive
468040376,"Ah, it didn't do what I thought it would. Yes returning the figure without a new flag won't work in notebooks, so I'll revert.
We can do this with an extra arg `return_fig:bool=None` that would default to `defaults.return_fig`, `False` by default. That way the user can easily control the default behavior globally but still override it when they want too. @sotte let me know if you want to do it.",ah thought would yes figure without new flag wo work revert extra would default false default way user easily control default behavior globally still override want let know want,issue,positive,positive,neutral,neutral,positive,positive
468038425,"Nope, this is not good at all.
e.g. this now prints 2 plots:
learn.recorder.plot()

It shouldn't return anything by default, and have an option to return the plot on demand. 

at least in the ipython env - probably a good default to return on console.",nope good return anything default option return plot demand least probably good default return console,issue,negative,positive,positive,positive,positive,positive
468026850,It was a pleasure! Keep up the good work!,pleasure keep good work,issue,positive,positive,positive,positive,positive,positive
468016122,"Eh, you write it, you name it ;) Thanks a lot, looks perfect!",eh write name thanks lot perfect,issue,positive,positive,positive,positive,positive,positive
468005802,"I also added the docs to the notebook.

The name of the function is ok then?",also added notebook name function,issue,negative,neutral,neutral,neutral,neutral,neutral
467976324,"Thank you so much for doing this! If you can, there are two little changes to add (one style and one that could be an issue for empty ItemLists).",thank much two little add one style one could issue empty,issue,negative,negative,neutral,neutral,negative,negative
467974960,"Yes, `unet_learner` is completely untested on something else than resnet bases, as it has been designed for that. You will need to tweak the code yourself for new models to work with it. Closing this issue, I suggest you create a new thread on the [forum](https://forums.fast.ai/) if you need help making those changes.",yes completely untested something else base designed need tweak code new work issue suggest create new thread forum need help making,issue,positive,negative,negative,negative,negative,negative
467907310,This looks like a bad manipulation (no file change) so I'm going to close. Don't hesitate to use the [forum](https://forums.fast.ai) if you need any help.,like bad manipulation file change going close hesitate use forum need help,issue,negative,negative,negative,negative,negative,negative
467597817,"Finally I got it to work with less data. Instead of using files, I have created the databunch from a preprocessed csv with about 80% of the wiki texts in spanish. ",finally got work le data instead,issue,negative,neutral,neutral,neutral,neutral,neutral
467469262,"It's a good feature to add, but it's a bit of a bummer if we have to reimplement for some new types of items. Maybe the basic method should check if the data is array-like or not? Also I think we should use torch for the test as it will likely be tensors by that time.
Also in hash, we should check if the obj attribute exists: a user that defines its custom ItemList might forget to implement that, and we could still fall back on the data attribute in that case.",good feature add bit bummer new maybe basic method check data also think use torch test likely time also hash check attribute user custom might forget implement could still fall back data attribute case,issue,negative,positive,positive,positive,positive,positive
467467738,It seems the test pass so I don't think this breaks any existing behavior. Thanks for the additional tests!,test pas think behavior thanks additional,issue,negative,positive,positive,positive,positive,positive
467411095,"I added these lines:
from fastai.callbacks import hooks
hooks.model_summary(learn)
and I also ran this separately
learn.summary()
and I got this error:
---------------------------------------------------------------------------
AttributeError                            Traceback (most recent call last)
<ipython-input-38-93c8a11c9ccf> in <module>
      1 from fastai.callbacks import hooks
      2 #hooks.model_summary(learn)
----> 3 learn.summary()

~/anaconda3/lib/python3.6/site-packages/fastai/callbacks/hooks.py in model_summary(m, n)
    165 def model_summary(m:Learner, n:int=70):
    166     ""Print a summary of `m` using a output text width of `n` chars""
--> 167     info = layers_info(m)
    168     header = [""Layer (type)"", ""Output Shape"", ""Param #"", ""Trainable""]
    169     res = ""="" * n + ""\n""

~/anaconda3/lib/python3.6/site-packages/fastai/callbacks/hooks.py in layers_info(m)
    156     func = lambda m:list(map(get_layer_name, flatten_model(m)))
    157     layers_names = func(m.model) if isinstance(m, Learner) else func(m)
--> 158     layers_sizes, layers_params, layers_trainable, hooks = params_size(m)
    159     for h1,h2 in hooks:
    160         h1.remove()

~/anaconda3/lib/python3.6/site-packages/fastai/callbacks/hooks.py in params_size(m, size)
    145     hooks = zip(hooks_outputs, hooks_params)
    146     x = m.eval()(*x) if is_listy(x) else m.eval()(x)
--> 147     output_size = [(o.stored.shape) for o in hooks_outputs]
    148     params = [o.stored for o in hooks_params]
    149     params, trainables = map(list,zip(*params))

~/anaconda3/lib/python3.6/site-packages/fastai/callbacks/hooks.py in <listcomp>(.0)
    145     hooks = zip(hooks_outputs, hooks_params)
    146     x = m.eval()(*x) if is_listy(x) else m.eval()(x)
--> 147     output_size = [(o.stored.shape) for o in hooks_outputs]
    148     params = [o.stored for o in hooks_params]
    149     params, trainables = map(list,zip(*params))

AttributeError: 'NoneType' object has no attribute 'shape'",added import learn also ran separately got error recent call last module import learn learner print summary output text width header layer type output shape param trainable lambda list map learner else size zip else map list zip zip else map list zip object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
467381523,@kmacmillan-ou did you figure out why processing hangs indefinitely? I'm facing the same issue.,figure indefinitely facing issue,issue,negative,neutral,neutral,neutral,neutral,neutral
467248418,See [this fast.ai forum post](https://forums.fast.ai/t/a-custom-itemlist-for-a-conditional-gan/37294/5?u=edave) for more background,see forum post background,issue,negative,neutral,neutral,neutral,neutral,neutral
467239668,"since there doesn't seem to be any traction here, let's close it for now. If the interests resumes please feel free to reopen.",since seem traction let close please feel free reopen,issue,positive,positive,positive,positive,positive,positive
467227702,"Thank you, @jeffrwells.

I think we messed up the changes and releases. OK sorted it out and adjusted changes accordingly",thank think sorted accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
467092373,"I asked on the PyTorch slack for any workaround and didn't get an answer, so I'm afraid this will stay like this. As I said before, using distributed training is a workaround that works (sadly not in a notebook but only in script).
Closing this issue, the known bug is documented in `unet_learner`.",slack get answer afraid stay like said distributed training work sadly notebook script issue known bug,issue,negative,negative,negative,negative,negative,negative
467087452,This behavior is inconsistent with the standards we set it the code of conduct. Please do not contribute any further to this community if you are not able to change your conduct in the future.,behavior inconsistent set code conduct please contribute community able change conduct future,issue,negative,positive,positive,positive,positive,positive
467076082,"Where did you find a `model_summary` method for `Learner`? You can use `model_summary(learn)` or `learn.summary()`, see the docs.
PS: you will want to do `print(learn.summary())` to have a clean output :)",find method learner use learn see want print clean output,issue,negative,positive,positive,positive,positive,positive
467040400,"Eh, the link to your code is dead. I am trying to reproduce the bug with a similar dataset (our COCO tiny dataset, but with only one bbox per image), I didn't get any error. Can you get me a link to a reproducible example?",eh link code dead trying reproduce bug similar coco tiny one per image get error get link reproducible example,issue,negative,negative,neutral,neutral,negative,negative
467033397,"Also, one thing I had to do for a wikipedia setting is to make sure I had deleted all the heavy objects used in pre-processing before making the call to the datablock API to avoid this.",also one thing setting make sure heavy used making call avoid,issue,negative,positive,positive,positive,positive,positive
467033054,Don't hesitate to add more like this ;) Thanks again!,hesitate add like thanks,issue,positive,positive,positive,positive,positive,positive
467016105,"The doc is horrible, any proper suggestion to build the dataloader using the fastai API keeping in mind that train, test and val data are in three different folders? I also want to apply a custom transformation to each dataloader. 

These operations are really easy with vanilla Pytorch, I have wasted two hours trying to understand how to do so.",doc horrible proper suggestion build keeping mind train test data three different also want apply custom transformation really easy vanilla wasted two trying understand,issue,negative,negative,negative,negative,negative,negative
466939216,"Actually, my probability is very low `min_p=0.1` 

```
learn = language_model_learner(data_lm, Transformer, drop_mult=0.5)
learn.fit_one_cycle(5, 1e-2)
learn.unfreeze()
learn.fit_one_cycle(5, 1e-3)
learn.predict(""how much baggage"", n_words=3, min_p=0.1)
```",actually probability low learn transformer much baggage,issue,negative,positive,neutral,neutral,positive,positive
466834190,"Looking good on CI - will retest shortly on gpu setup.

Thank you, @phenomax ",looking good retest shortly setup thank,issue,positive,positive,positive,positive,positive,positive
466833499,"can you git pull my changes in? otherwise every fix you commit, it recreates the conflict. thank you.",git pull otherwise every fix commit conflict thank,issue,negative,neutral,neutral,neutral,neutral,neutral
466833469,Ok. I have squashed our commits together. Would you like to move the init out of the `load_pynvml_env` function to avoid merge conflits?,together would like move function avoid merge,issue,negative,neutral,neutral,neutral,neutral,neutral
466833144,"ok, we shouldn't init inside the wrapper, since it loads w/o nvidia libs, but the init should only happens `if use_gpu`. thank you, CI
well, let's just check inside the wrapper.",inside wrapper since thank well let check inside wrapper,issue,positive,neutral,neutral,neutral,neutral,neutral
466831895,"And we don't know if and when your PR 1132719438/pynvx#3 gets merged, and that's not enough it has to be released on pypi too. So perhaps we hold off on those parts for when that happens?",know enough perhaps hold,issue,negative,neutral,neutral,neutral,neutral,neutral
466829736,"@stas00 You committed faster than me, thus the merge conflict :)
Do you want to squash our changed together? I also fixed `utils/collect_env.py` and `callbacks/mem.py`",faster thus merge conflict want squash together also fixed,issue,negative,positive,neutral,neutral,positive,positive
466806901,"I'm guessing your choice of `min_p` is too high (probabilities are very low usually) so everything has been ignored, which throws the error. Working on a fix that will give an appropriate warning.",guessing choice high low usually everything error working fix give appropriate warning,issue,negative,positive,positive,positive,positive,positive
466794997,"Thanks a lot, those are great examples! I just noticed one typo. If you can fix it before I merge this that would be great (follow the link to ReviewNB to see which cell).",thanks lot great one typo fix merge would great follow link see cell,issue,positive,positive,positive,positive,positive,positive
466794617,"Thanks! Don't forget the type annotation when adding an argument in a function(I added it in an additional commit).
For FP16, your fix puts everything in FP32 silently so I'd rather not do it this way. The user can always put it's `Learner` back to FP32 with `learn = learn.to_fp32()`.",thanks forget type annotation argument function added additional commit fix everything silently rather way user always put learner back learn,issue,negative,positive,neutral,neutral,positive,positive
466794253,Thanks a lot! A tiny thing to remember for the feature: please use backticks (see my additional commit) and not ' ' for function names.,thanks lot tiny thing remember feature please use see additional commit function,issue,positive,positive,neutral,neutral,positive,positive
466793533,Please refer to the [doc on Learner](https://docs.fast.ai/basic_train.html#Learner). What you are looking for is `model_dir`. Pass a Path object pointing to the directory you want.,please refer doc learner looking pas path object pointing directory want,issue,negative,neutral,neutral,neutral,neutral,neutral
466791633,"Also, this feature does not work with to_fp16().
I found a work around like following in function _cl_int_plot_top_losses

 ```
xb,_ = self.data.one_item(im, detach=False, denorm=False)
 xb = xb.float()
 model = self.learn.model.float()
 m = model.eval()
```

in place of 

 ```
xb,_ = self.data.one_item(im, detach=False, denorm=False)
 m = self.learn.model.eval()
```

Do you agree with this? Any better way of doing it?
Please suggest.
",also feature work found work around like following function model place agree better way please suggest,issue,positive,positive,positive,positive,positive,positive
466780944,"pip install pandas-summary
Just enter that it should work",pip install enter work,issue,negative,neutral,neutral,neutral,neutral,neutral
466555678,"Reopening so I don't forget to look at this (maybe sometime this weekend, maybe Monday).",forget look maybe sometime weekend maybe,issue,negative,neutral,neutral,neutral,neutral,neutral
466554899,"@sgugger Been trying to debug the exact same problem as is mentioned in this post. We're working with a custom dataset and getting the exact same error message still with fast.ai updated.

Our images are nested by label folder like:

images/
----->apple/
------------>000001.jpg
------------>000002.jpg
------------>000003.jpg
------------>.........
----->amazon/
------------>000001.jpg
------------>000002.jpg
------------>000003.jpg
------------>.........
----->bmw/
------------>000001.jpg
------------>000002.jpg
------------>000003.jpg
------------>.........

Many of the image files have the same filename, but are in different subdirectories.

So our annotations file is in the format (we're trying to replicate the Coco docs example):

` {'filename' : ['bboxes', 'labels']}`  

and looks like this: 


<img width=""506"" alt=""screen shot 2019-02-22 at 4 07 43 pm"" src=""https://user-images.githubusercontent.com/10041710/53271535-cb0eb100-36bc-11e9-9ee9-786567f12563.png"">

For example our annotated images look like:

<img width=""722"" alt=""screen shot 2019-02-22 at 4 16 03 pm"" src=""https://user-images.githubusercontent.com/10041710/53271687-335d9280-36bd-11e9-9859-a8d0177339f1.png"">


We cannot get the `label_from_func` to work when we initialize the databunch. All other steps — creating the objectItemList, creating the ItemList by splitting between train and valid sets, work fine. 

When we run `label_from_func` we repeatedly get this error message:

<img width=""629"" alt=""screen shot 2019-02-22 at 4 17 22 pm"" src=""https://user-images.githubusercontent.com/10041710/53271753-5ee07d00-36bd-11e9-8980-5832299043d0.png"">


Link to our code: https://github.com/fellowship/platform-demos2/blob/master/brands/notebooks/bboxes/fastai_bboxes.ipynb



Would very much appreciate direction on this. Thank you for your work, your posts in the forums usually save us from having to post questions like this.

Thanks!



",trying exact problem post working custom getting exact error message still label folder like many image different file format trying replicate coco example like screen shot example look like screen shot get work initialize splitting train valid work fine run repeatedly get error message screen shot link code would much appreciate direction thank work usually save u post like thanks,issue,positive,positive,positive,positive,positive,positive
466499006,You will only see other PRs from me if I have considerable timebudget at home to prep them and probably discussed all details on the forum :-) ,see considerable home prep probably forum,issue,negative,positive,neutral,neutral,positive,positive
466473167,"Thanks, @Benudek.

Sorry this was dragging too long, I made the last fixes and merged it - please review what I did so if you get inspired to send more PRs you will see what's required. 

There was a typo (missing closing bracket) in my tweaks, so fixed that in another commit later.",thanks sorry dragging long made last please review get inspired send see typo missing bracket fixed another commit later,issue,positive,negative,neutral,neutral,negative,negative
466410468,Thanks! I'll check how to update the docs and send usage examples in another PR.,thanks check update send usage another,issue,negative,positive,positive,positive,positive,positive
466408345,"Good to go, thanks! Don't forget to document this by updating the corresponding doc notebook.",good go thanks forget document corresponding doc notebook,issue,positive,positive,positive,positive,positive,positive
466405676,"Thanks! Just one change requested to make the generated docs clearer.
Btw don't forget to add another PR that document your new functionality by updating the doc notebooks ;)",thanks one change make clearer forget add another document new functionality doc,issue,negative,positive,positive,positive,positive,positive
466385950,"There is no bug here: we were informed of that bug recently, fixed it in master, and it will be in the next released version (v1.0.46) of fastai. In the meantime, you have to user master as @kechan pointed out if you want the fix.",bug informed bug recently fixed master next version user master pointed want fix,issue,negative,positive,neutral,neutral,positive,positive
466385173,Try to lower your number of CPUs used (with defaults.cpus). It's likely you get OOM because python copies the same things accross processes.,try lower number used likely get python,issue,negative,neutral,neutral,neutral,neutral,neutral
466305896,"I see. It is at least good to know it works with the GitHub version., so something is already fixed.",see least good know work something already fixed,issue,negative,positive,positive,positive,positive,positive
466305620,"Thanks I knew that and already done that but the intent was as to why pip install fastai or default fastai library at colab isn't working correctly.
It was a library bug so I posted it here.",thanks knew already done intent pip install default library working correctly library bug posted,issue,negative,positive,positive,positive,positive,positive
466302311,"i think colab is on 1.0.45  (!pip list |grep -i fast). Whats on GitHub is latest greatest breeding edge. 
if you really want that, you have to git clone to your colab local session, then do

!pip install -e {local_fastai_repos_path}

Warning: picking things directly up from GitHub is also hazardous as it isn't a release and maybe unstable. try and see if  this unblocks u.",think pip list fast whats latest breeding edge really want git clone local session pip install warning directly also hazardous release maybe unstable try see,issue,negative,positive,positive,positive,positive,positive
466298976,"think this is fine now, imho the report per line was ;-)
",think fine report per line,issue,negative,positive,positive,positive,positive,positive
466293020,"wow, why did I overlook that location attribute? That's much better indeed.",wow overlook location attribute much better indeed,issue,positive,positive,positive,positive,positive,positive
466265316,"Sure, it is just a proposal, and not very high priority one. 

I just posted this on dev forum:

https://forums.fast.ai/t/adding-a-template-image-as-part-of-the-library/38927
",sure proposal high priority one posted dev forum,issue,negative,positive,positive,positive,positive,positive
466263912,"As I mentioned earlier, it should be easy to add an image file to the library, but not before it's actually needed. So usually we do well with actionable PRs: here is a PR that adds/extends/improves feature 'foo', and it requires/uses/prefers a built-in image 'bar' instead of fetching it from somewhere. And if it's a good idea then chances are it'll be accepted. 

I hope this makes sense. And, yes, let's continue this discussion over at the forums.",easy add image file library actually usually well actionable feature image instead fetching somewhere good idea accepted hope sense yes let continue discussion,issue,positive,positive,positive,positive,positive,positive
466261984,"Here is a much simpler implementation (also rewrote it a bit - no need for --testapireg/individualtests check here, and the conditional shouldn't have included setup/teardown cases anyway - those should always run):
```
@pytest.hookimpl(tryfirst=True, hookwrapper=True)
def pytest_runtest_makereport(item, call):
    outcome = yield
    res = outcome.get_result()
    filename, lineno, testname = res.location
    if   res.when == ""setup"":    TestAPIRegistry.this_tests_flag_on(filename, testname)
    elif res.when == ""call"":     TestAPIRegistry.tests_failed(res.failed)
    elif res.when == ""teardown"": TestAPIRegistry.this_tests_flag_check(filename, testname)
```
Please test.

I got the object info here: https://docs.pytest.org/en/latest/_modules/_pytest/reports.html

Also please revisit my review from last PR of yours, we don't use `str + str`, but `f""{str} {str}""` style.

Thank you.",much simpler implementation also bit need check conditional included anyway always run item call outcome yield setup call teardown please test got object also please revisit review last use style thank,issue,positive,positive,neutral,neutral,positive,positive
466245923,"Thank you for your support.
I'm running `fastai 1.0.45`. Which I believe is the latest I can get from PyPI.
```python
import fastai
print(fastai.__version__)
```
==> `1.0.45`

I still face the problem. Either with `ImageDataBunch.from_folder` or `ImageItemList.from_folder`.
I also realized I have a `models` folder in the general `data` folder (not sure if that's relevant, but still, you never knows). So my file tree more looks like this:
```
.
|-- models (2 files -- no images)
|-- test (14957 files)
`-- train
    |-- models (0 file)
    |-- nok (920 files)
    |-- ok (1010 files)
    `-- unsure (646 files)

7 directories
```

Here are details:
- `path` is `PosixPath('data')`
- I runned 
```python
data = (ImageItemList.from_folder(path/'train')
                     .random_split_by_pct()
                     .label_from_folder()
                     .add_test_folder(path/'test')
                     .databunch(path=path))
```
- I get:
```
ImageDataBunch;

Train: LabelList (2061 items)
x: ImageItemList
Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280)
y: CategoryList
ok,ok,ok,ok,ok
Path: data/train;

Valid: LabelList (515 items)
x: ImageItemList
Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280)
y: CategoryList
ok,ok,unsure,ok,ok
Path: data/train;

Test: LabelList (0 items)
x: ImageItemList

y: EmptyLabelList

Path: data/train
```
That last line is confusing, though...

Bonus question: 
> Also, you should switch to the data block API to have more flexibility.

The output should look the same? It's only the way the data is processed, right?",thank support running believe latest get python import print still face problem either also folder general data folder sure relevant still never file tree like test train file unsure path python data get train image image image image image path valid image image image image image unsure path test path last line though bonus question also switch data block flexibility output look way data right,issue,negative,positive,positive,positive,positive,positive
466220187,"Now seems fine :-) pytest version 4.3.0 locally as here btw

Maybe we should have the string parse in try except and then call functions only when file and test name are found. Then again, in case pytest changes test report format it is probably best to know and not hide the exception.

So, hope its good t merge now ;-)


@pytest.hookimpl(tryfirst=True, hookwrapper=True)
def pytest_runtest_makereport(item, call):
    outcome = yield
    res = outcome.get_result()
    #individualtests = 0
    individualtests = [s for s in set(sys.argv) if re.match(r'.*test_\w+\.py',s)]    
    if pytest.config.getoption(""--testapireg"") and not individualtests:
        **filenameandmethod = str(res).split('\'', 1)[1].split('\'', 1)[0]  
        filename =  filenameandmethod.split('::::', 1)[0]   
        test_name =  filenameandmethod.split('::::', 1)[1]**       
        if res.when == ""setup"": TestAPIRegistry.this_tests_flag_on(filename, test_name)
        if res.when == ""call"" and res.failed:  TestAPIRegistry.tests_failed()
        if res.when == ""teardown"":  TestAPIRegistry.this_tests_flag_check(filename, test_name)",fine version locally maybe string parse try except call file test name found case test report format probably best know hide exception hope good merge item call outcome yield set setup call teardown,issue,positive,positive,positive,positive,positive,positive
466196845,"ok, I look at it when I find time too. 

As fallback: I would still regard report line per test as an option, as soon as we registered with this_tests.",look find time fallback would still regard report line per test option soon registered,issue,negative,neutral,neutral,neutral,neutral,neutral
466185284,"@stas00 Thanks for appreciation. Cats are cute too and would be great for color transform. I would just do both to get a feel what transforms are doing. 

This is the motivation why i suggested adding an embedded image that's available with the library itself, rather than some external URLs. It allows for quick call up for test images. It can even be used for training if you use heavy data aug for classification of ""R"" and no ""R"". 

I posted this on dev forum for feedback. A nicely designed ""F"" will do, if you want a logo for fastai. ",thanks appreciation cute would great color transform would get feel motivation image available library rather external quick call test even used training use heavy data classification posted dev forum feedback nicely designed want,issue,positive,positive,positive,positive,positive,positive
466169306,"> So this works locally for me when running make test-full. How do you test on github? Could try to reproduce locally.

You add some debug statements I guess. And I told you already the pytest versions azure CI (not github) is running, so you can match the version and check.

> But actually this issue shows parsing that report is too hacky. Rather from the string of the function we need to get to the object. Like you do in your str2obj function. Only, you need the fully qualified name and we just have the simple one here.

I've never done this before with pytest - I'll have a look when I get a chance.

your code fails on my setup too. 
",work locally running make test could try reproduce locally add guess told already azure running match version check actually issue report hacky rather string function need get object like function need fully qualified name simple one never done look get chance code setup,issue,positive,neutral,neutral,neutral,neutral,neutral
466162986,"So this works locally for me when running make test-full. How do you test on github? Could try to reproduce locally. 

But actually this issue shows parsing that report is too hacky. Rather from the string of the function we need to get to the object. Like you do in your str2obj function. Only, you need the fully qualified name and we just have the simple one here. 

Ideas welcome 
",work locally running make test could try reproduce locally actually issue report hacky rather string function need get object like function need fully qualified name simple one welcome,issue,positive,positive,positive,positive,positive,positive
466151661,"Please always follow these guidelines when filing bug reports: https://docs.fast.ai/support.html
Most likely your fastai needs updating. 

This particular var was added in git master and isn't yet in the release
https://github.com/fastai/fastai/blob/master/fastai/datasets.py#L44

so either please use the git version or wait till 1.0.46 gets released",please always follow filing bug likely need particular added git master yet release either please use git version wait till,issue,positive,positive,neutral,neutral,positive,positive
466123342,"Transforms should be implemented with pytorch tensors, not numpy - see the fastai code for examples. Please use the forums to discuss. Thanks!",see code please use discus thanks,issue,positive,positive,positive,positive,positive,positive
466122839,"If you want the same behavior as torch's, you should use it.",want behavior torch use,issue,negative,neutral,neutral,neutral,neutral,neutral
466122294,I'll close this now since it's not something we're committing to doing ourselves - if someone wants to add a PR then we'll certainly look,close since something someone add certainly look,issue,negative,positive,positive,positive,positive,positive
466117189,"Comment on your fix. I actually never done it in Python, but in Java, you can put the call stacks in a string and report it, rather than burying it with a generic message. This helps debugging and at same time not crashing things. Your output message is misleading if it crashes due to other reasons.",comment fix actually never done python put call string report rather burying generic message time output message misleading due,issue,negative,negative,neutral,neutral,negative,negative
466112848,"Love it, @kechan! I find that your use of a geometric image makes it easier to appreciate/understand the different transforms than an image of a cat. But that's just me. Thank you for sharing your nb.",love find use geometric image easier different image cat thank,issue,positive,positive,positive,positive,positive,positive
466112722,"FYI: This is a screenshot from his unpublished book. 

![img_0174](https://user-images.githubusercontent.com/122762/53192475-8ad80180-35dc-11e9-872b-8bb9fbe6fb6a.jpg)

So this plot can help you how your training set size vary with train/val metrics. Another thing, I sometimes found comparing the loss between train and val is apple and orange, and really hard to interprete. I thought I have seen ppl including vs excluding the weight decay loss. It is all just confusing. 

In all, the loss is sometimes considered as a proxy, to achieve good metrics. You only care about metrics at the end, not the loss, IMO. It's metrics that make you the $$.",unpublished book plot help training set size vary metric another thing sometimes found loss train apple orange really hard thought seen excluding weight decay loss loss sometimes considered proxy achieve good metric care metric end loss metric make,issue,negative,positive,positive,positive,positive,positive
466111196,"Sorry, I'm not understanding what you're saying. Your wrote in the new code:
```  
    test_name =  filenameandmethod.split('::::', 1)[1] 
```
the test suite failed telling you this is where the problem is, 
```
INTERNALERROR>     test_name =  filenameandmethod.split('::::', 1)[1]
INTERNALERROR> IndexError: list index out of range
```
That means that the split has failed, and there is no index [1].

FWIW, the CI is using:

pytest==4.3.0
pytest-runner==4.4

(from looking at its install logs)

Perhaps you're using a different version and the format of those strings isn't the same in those different versions?",sorry understanding saying wrote new code test suite telling problem list index range split index looking install perhaps different version format different,issue,negative,negative,neutral,neutral,negative,negative
466106037,"Note: If I remembered right, Andrew Ng has a book where plots of train and val metrics are used to determined data complexity vs. accuracy, this is important in determining what size of dataset you may need. This is often overlooked if you use other's people dataset 'cos they come for free (even if you steal it from web, it is still other ppl data). If you have to collect your own, this is mighty pain in the ass and expensive. 

I have been using Keras last yr, and that training accuracy never mislead me, and helped me in this data requirement thing.

If you have a quick workaround with the callback, pls let me know. I haven't done any real work 'cos of feature mismatch with Keras. I have been trying to run the same thing on fastai and do a comparison, this is taking a bit longer than i planned.",note right book train metric used determined data complexity accuracy important size may need often use people come free even steal web still data collect mighty pain as expensive last yr training accuracy never mislead data requirement thing quick let know done real work feature mismatch trying run thing comparison taking bit longer,issue,negative,positive,positive,positive,positive,positive
466100038,"I have written a notebook on 

GitHub: https://github.com/kechan/FastaiPlayground under ""Quick Tour of Data Augmentation.ipynb"". It is currently reachable if you search ""rot90 fastai"". I didn't end with just rot90 and attempt to try to highlight how easy it is to add your own. 

So if this isn't high priority, we can close this and come back to it later.",written notebook quick tour data currently reachable search rot end rot attempt try highlight easy add high priority close come back later,issue,positive,positive,positive,positive,positive,positive
466098280,"I understood fastai is a pretty opinionated framework. But I can tell you that metrics on training can help you work more efficiently. I used that as an indication if your model has high bias. Or to stop the training when your training accuracy hit a 100% and val accuracy diverges with it.

Of course this may confuse beginner, and shouldn't be the default. I am surprised that it just wasn't considered to be an option.",understood pretty opinionated framework tell metric training help work efficiently used indication model high bias stop training training accuracy hit accuracy course may confuse beginner default considered option,issue,positive,positive,positive,positive,positive,positive
466035762,"We know this is an issue. The problem comes from the hooks that save the intermediate features in the pretrained body. They only remember the features on one GPU instead of aggregating.
I'd suggest using distributed training (there is a fastai function to help) which works.",know issue problem come save intermediate body remember one instead suggest distributed training function help work,issue,negative,neutral,neutral,neutral,neutral,neutral
466023384,"@stas00 fails on ( I think) a maybe different reporting format of pytest - locally it works for me:

conftest.py / pytest_runtest_makereport
test_name =  filenameandmethod.split('::::', 1)[1]

It is a bit hacky to parse the test report like that. Other than that, this code should essentially be fine (report at the very end on missing this_tests calls). We could use more flexible regex here, still less than perfect to parse this to get to the filename.

Any other good ideas here, like some inspect magic to get all this via the method name only?",think maybe different format locally work bit hacky parse test report like code essentially fine report end missing could use flexible still le perfect parse get good like inspect magic get via method name,issue,positive,positive,positive,positive,positive,positive
466021039,"Not sure what could be the reason. Did you try to pass the `text_cols` and `label_cols`, just in case the default don't correspond to your table?",sure could reason try pas case default correspond table,issue,negative,positive,positive,positive,positive,positive
466020512,"There is still a bug with this, you're right. Thanks for your fix! We can do it more simply though, request a change before merging.",still bug right thanks fix simply though request change,issue,negative,positive,positive,positive,positive,positive
466013734,"Confirmed it now works in colab as expected. Note that it's only on master for now, so you will need to run
```
!pip install git+https://github.com/fastai/fastai
```
if you want to see the fix. Thanks for flagging!",confirmed work note master need run pip install want see fix thanks flagging,issue,negative,positive,positive,positive,positive,positive
466006041,"> > What version of fastai are you using??
> 
> I am using '1.0.45'.
> Actually, I am following this tutorial https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/
> 
> Thanks

In 1.0.45 there was a breaking change in the syntax of this function, to allow for different language model achitectures. See the [docs](https://docs.fast.ai/text.learner.html#language_model_learner) or an [example](https://github.com/fastai/fastai/blob/master/examples/text.ipynb)",version actually following tutorial thanks breaking change syntax function allow different language model see example,issue,positive,positive,neutral,neutral,positive,positive
465988869,"I think you should go ahead and make a PR out of your transform. It may not be used very often, but the next person that needs it will be glad to see it here.",think go ahead make transform may used often next person need glad see,issue,negative,positive,positive,positive,positive,positive
465988349,"Thanks a lot! This seems very useful.
I've made a few comments, mainly to conform to the fastai style guide. Please address them before we can merge.",thanks lot useful made mainly conform style guide please address merge,issue,positive,positive,positive,positive,positive,positive
465986143,"No metrics are computed on the validation set only as this is bad practice to compute them on the training set. This is a conscious choice on our side. 
There is probably a workaround using a Callback that can add a new metrics (see `LossMetrics` if interested) but this isn't something we want in the library.
You can also use the function `validate` at the end of training, that takes a dataloader. Again though, metrics on the training set really don't mean anything.",metric validation set bad practice compute training set conscious choice side probably add new metric see interested something want library also use function validate end training though metric training set really mean anything,issue,negative,negative,negative,negative,negative,negative
465937816,"> Can you try using 0.7.0. I used that and it worked for me. Let me know if it works for you.

if i use fastai version 0.7.0 , then i am gettign NameError: name 'TextLMDataBunch' is not defined
",try used worked let know work use version name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
465928826,"> Can you try using 0.7.0. I used that and it worked for me. Let me know if it works for you.

I tried the code 

`# http://pytorch.org/
from os.path import exists
from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag
platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())
cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\.\([0-9]*\)\.\([0-9]*\)$/cu\1\2/'
accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'
!pip install torch_nightly -f https://download.pytorch.org/whl/nightly/{accelerator}/torch_nightly.html
  
import torch
print(torch.__version__)
print(torch.cuda.is_available())
print(torch.backends.cudnn.enabled)

# !pip install fastai

# !pip uninstall fastai
!pip install ""fastai==0.7.0""

import fastai
# from fastai import *
# from fastai.text import * 
import pandas as pd
import numpy as np
from functools import partial
import io
import os`

and got the output 

> Looking in links: https://download.pytorch.org/whl/nightly/cu100/torch_nightly.html
Requirement already satisfied: torch_nightly in /usr/local/lib/python3.6/dist-packages (1.0.0.dev20190220)
0.3.1
True
True
Uninstalling fastai-0.7.0:
  Would remove:
    /usr/local/lib/python3.6/dist-packages/fastai-0.7.0.dist-info/*
    /usr/local/lib/python3.6/dist-packages/fastai/*
Proceed (y/n)? y
  Successfully uninstalled fastai-0.7.0
Collecting fastai==0.7.0
  Using cached https://files.pythonhosted.org/packages/50/6d/9d0d6e17a78b0598d5e8c49a0d03ffc7ff265ae62eca3e2345fab14edb9b/fastai-0.7.0-py3-none-any.whl
Requirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.1)
Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.0.0)
Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)
Requirement already satisfied: plotnine in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.5.1)
Requirement already satisfied: isoweek in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.3.3)
Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)
Requirement already satisfied: jupyter in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0.0)
Requirement already satisfied: cycler in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.0)
Requirement already satisfied: html5lib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.0.1)
Requirement already satisfied: sklearn-pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.8.0)
Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.1.7)
Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.5.3)
Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.5)
Requirement already satisfied: ptyprocess in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.6.0)
Requirement already satisfied: ipykernel in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.6.1)
Requirement already satisfied: pytz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.9)
Requirement already satisfied: certifi in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2018.11.29)
Requirement already satisfied: torch<0.4 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.1)
Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.14.6)
Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.7.1)
Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.1.0)
Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.5.20)
Requirement already satisfied: widgetsnbextension in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.4.2)
Requirement already satisfied: ipython in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (5.5.0)
Requirement already satisfied: jedi in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.13.2)
Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.13)
Requirement already satisfied: pandas-summary in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.0.6)
Requirement already satisfied: bcolz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.2.1)
Requirement already satisfied: simplegeneric in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.8.1)
Requirement already satisfied: traitlets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.3.2)
Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.5.1)
Requirement already satisfied: pyparsing in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.3.1)
Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.6.0)
Requirement already satisfied: feather-format in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.4.0)
Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.28.1)
Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.10.1)
Requirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3)
Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.2.0)
Requirement already satisfied: ipywidgets in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (7.4.2)
Requirement already satisfied: Jinja2 in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.10)
Requirement already satisfied: Pygments in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (2.1.3)
Requirement already satisfied: torchtext in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.3.1)
Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (3.0.2)
Requirement already satisfied: pyzmq in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (17.0.0)
Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.22.0)
Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (0.4.2)
Requirement already satisfied: tornado in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (4.5.3)
Requirement already satisfied: MarkupSafe in /usr/local/lib/python3.6/dist-packages (from fastai==0.7.0) (1.1.0)
Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision->fastai==0.7.0) (1.11.0)
Requirement already satisfied: olefile in /usr/local/lib/python3.6/dist-packages (from Pillow->fastai==0.7.0) (0.46)
Requirement already satisfied: statsmodels>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.8.0)
Requirement already satisfied: descartes>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (1.1.0)
Requirement already satisfied: patsy>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.1)
Requirement already satisfied: mizani>=0.5.2 in /usr/local/lib/python3.6/dist-packages (from plotnine->fastai==0.7.0) (0.5.3)
Requirement already satisfied: jupyter-console in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (6.0.0)
Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.4.1)
Requirement already satisfied: notebook in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (5.2.2)
Requirement already satisfied: qtconsole in /usr/local/lib/python3.6/dist-packages (from jupyter->fastai==0.7.0) (4.4.3)
Requirement already satisfied: scikit-learn>=0.15.0 in /usr/local/lib/python3.6/dist-packages (from sklearn-pandas->fastai==0.7.0) (0.20.2)
Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel->fastai==0.7.0) (5.2.4)
Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (1.0.15)
Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (40.8.0)
Requirement already satisfied: pexpect; sys_platform != ""win32"" in /usr/local/lib/python3.6/dist-packages (from ipython->fastai==0.7.0) (4.6.0)
Requirement already satisfied: parso>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from jedi->fastai==0.7.0) (0.3.4)
Requirement already satisfied: pyarrow>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from feather-format->fastai==0.7.0) (0.12.0)
Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets->fastai==0.7.0) (4.4.0)
Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from torchtext->fastai==0.7.0) (2.18.4)
Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->fastai==0.7.0) (1.0.1)
Requirement already satisfied: palettable in /usr/local/lib/python3.6/dist-packages (from mizani>=0.5.2->plotnine->fastai==0.7.0) (3.1.1)
Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (4.4.0)
Requirement already satisfied: mistune>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.8.4)
Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (0.5.0)
Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->jupyter->fastai==0.7.0) (1.4.2)
Requirement already satisfied: terminado>=0.3.3; sys_platform != ""win32"" in /usr/local/lib/python3.6/dist-packages (from notebook->jupyter->fastai==0.7.0) (0.8.1)
Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (1.22)
Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (2.6)
Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->torchtext->fastai==0.7.0) (3.0.4)
Installing collected packages: fastai
Successfully installed fastai-0.7.0
WARNING: The following packages were previously imported in this runtime:
  [fastai]
You must restart the runtime in order to use newly installed versions.

",try used worked let know work tried code import import platform accelerator else pip install import torch print print print pip install pip pip install import import import import import import partial import io import o got output looking link requirement already satisfied dev true true would remove proceed successfully uninstalled requirement already satisfied requirement already satisfied pillow requirement already satisfied decorator requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied cycler requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied torch requirement already satisfied requirement already satisfied requirement already satisfied bleach requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied jinja requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied tornado requirement already satisfied requirement already satisfied six requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied notebook requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied win requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied win requirement already satisfied requirement already satisfied requirement already satisfied collected successfully warning following previously must restart order use newly,issue,positive,positive,positive,positive,positive,positive
465925444,Can you try using 0.7.0. I used that and it worked for me. Let me know if it works for you.,try used worked let know work,issue,negative,neutral,neutral,neutral,neutral,neutral
465924793,"> What version of fastai are you using??

I am using '1.0.45'. 
Actually, I am following this tutorial https://www.analyticsvidhya.com/blog/2018/11/tutorial-text-classification-ulmfit-fastai-library/

Thanks ",version actually following tutorial thanks,issue,negative,positive,neutral,neutral,positive,positive
465910573,"Hi, when ever i tried to use 
`learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.3)`
I am getting the following error, can you please let me how to got the solution?

`---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-36-12780955049a> in <module>()
      1 
----> 2 learn = language_model_learner(data_lm, pretrained_model=URLs.WT103, drop_mult=0.3)

TypeError: language_model_learner() missing 1 required positional argument: 'arch'`

Thanks ",hi ever tried use learn getting following error please let got solution recent call last module learn missing positional argument thanks,issue,negative,neutral,neutral,neutral,neutral,neutral
465888636,"yeeah, its not yet great but I guess a start... I know. did it after 23h local time here or so ;-)

I want to help registering these tests with this_tests as soon as we are there. Other than, that dont get me wrong my preference would be to code all along but my timebudget is somewhat limited for now.

thx for all the tips, good learning curve",yet great guess start know local time want help soon dont get wrong preference would code along somewhat limited good learning curve,issue,positive,positive,positive,positive,positive,positive
465818212,"Perhaps the default should be on, with a very reasonable (high?) default threshold and also make the threshold configurable? Otherwise, if it's off by default, users will miss out on the feature that they may not even know exists?",perhaps default reasonable high default threshold also make threshold otherwise default miss feature may even know,issue,negative,positive,positive,positive,positive,positive
465817343,"I think it's a bit overcomplicated, but let's get it in and then improve from there.

Thank you for letting me know that you'll be doing some other things for a while, @Benudek. Please take your time.

Thank you for this collaboration so far. 

-------------

the problem with print as it happens is that pytest will hide the warnings by default  (without -v) I think, but let's experiment.

and yes, need to sort out the filename.",think bit let get improve thank know please take time thank collaboration far problem print hide default without think let experiment yes need sort,issue,positive,positive,neutral,neutral,positive,positive
465796456,"Neat. I'm actually running a customized ResNet model so I was able to modify it to get it to work by changing `self.avgpool = nn.AdaptiveAvgPool2d((1, 1))` to `self.avgpool = nn.AdaptiveAvgPool2d((7, 7))`.

(Unfortunately making that change hurt the accuracy of the model quite a bit)

![heatmap](https://user-images.githubusercontent.com/870796/53132026-05007b80-3534-11e9-82eb-0ea47ad382c9.png)
",neat actually running model able modify get work unfortunately making change hurt accuracy model quite bit,issue,negative,neutral,neutral,neutral,neutral,neutral
465792170,"Imho: I would give the warning right after the test ran (so my 1st version) ]. Since we should have very little warnings soon, that should be fine and is simpler for an end report, see my 2 below points.

However, made a small PR following your suggestion. The var failed_test was left over from * failed_tests where I was collecting all tests to deliver them once. But this set would need to be extended to a dictionary or rather we use some pytest object

1. when we collect missing this_tests for one go, we should identify the file name. As described above, how-to wasn't obvious even though there should be some way via inspect to go there from item.name (that's all we have in this event unless you want to dissect the item string, which could be instable over releases).
2. we could make a simple pretty print, but supposedly we should add such things to some pytest report I suppose, which gets listed automatically at the very end

Actually, I need to take a small fast.ai break for some days as I am trying to push this through here a little next to my normal live obligations. I hope this is good to merge, maybe with small additions, and we wait for Andrew and then resume?
",would give warning right test ran st version since little soon fine simpler end report see however made small following suggestion left deliver set would need extended dictionary rather use object collect missing one go identify file name obvious even though way via inspect go event unless want dissect item string could instable could make simple pretty print supposedly add report suppose listed automatically end actually need take small break day trying push little next normal live hope good merge maybe small wait resume,issue,positive,positive,neutral,neutral,positive,positive
465791897,"How about 3x3 or even 2x2?
I am struggling with kaggle Histopathology competition and they have image size of 96. I have feature matrix size of numberofChannelsx3x3 with resnet34 and resnet50. Having heat-map displayed with top losses was helpful. I guess same must be true for size of 64 as well.  
Even with 2x2, it will show very rough approximate location. 
If we turn it off below 4x4 then we may not be able use it with progressive resizing of image until we cross certain size threshold.


Also, @sgugger you caught one more issue. I did not anticipate rectangular images,
I will need to change following code as well 
```
 sz = im.shape[-1]
 axes.flat[i].imshow(mult, alpha =0.6, extent= (0,sz,sz,0), interpolation='bilinear', cmap='magma')

```",even struggling histopathology competition image size feature matrix size displayed top helpful guess must true size well even show rough approximate location turn may able use progressive image cross certain size threshold also caught one issue anticipate rectangular need change following code well mult alpha,issue,positive,positive,positive,positive,positive,positive
465784429,"I'll close the issue since it's not a bug in the library, and I think this should then be debated on the [forum](https://forums.fast.ai) so that anyone can weight in.",close issue since bug library think forum anyone weight,issue,negative,neutral,neutral,neutral,neutral,neutral
465783699,"Yes maybe the default for heatmap should be None, then we set it properly depending on the size. 4 by 4 seems like a good idea so let's test for the numel of the features to be >= 16 (since images can be rectangular)",yes maybe default none set properly depending size like good idea let test since rectangular,issue,positive,positive,positive,positive,positive,positive
465783125,"If @sgugger is in agreement, I'd say yes. 
We just need to decide on the threshold.",agreement say yes need decide threshold,issue,positive,neutral,neutral,neutral,neutral,neutral
465781760,"There is no problem adding such images to the repo, @kechan, if it helps our and users' cause. Let's just try to put it to use right away and then it'll be clear where and how to integrate it into the repo. Does it make sense?

I'm just not sure how a single image is going to be helpful, where DL always requires many images (other than for inference).  Hence once you show the use it'll be much easier to grasp.",problem cause let try put use right away clear integrate make sense sure single image going helpful always many inference hence show use much easier grasp,issue,positive,positive,positive,positive,positive,positive
465778451,"Well, a synthetic one is probably not necessary right now. You can just check in a static image into the library. A simple geometric one like this: 

![get_transforms](https://user-images.githubusercontent.com/122762/53128544-139a6300-3533-11e9-9ee1-fac9acd41733.jpg)

We may replace this with an official logo of fastai, maybe a version that make most data aug transform easy to spot. A bad example will be a cat, since you can't tell apart its mirror transform.

OpenCV, if i remembered right, did this:

cv::Mat img = cv::imread(""lenna.png"");

Where lenna.png is always available no matter what env you are, 'cos it is part of the library. This photo has become one of the most popular one in the history of CS (maybe on par with the ""tea pot"" in computer graphics). 

",well synthetic one probably necessary right check static image library simple geometric one like may replace official maybe version make data transform easy spot bad example cat since ca tell apart mirror transform right always available matter part library photo become one popular one history maybe par tea pot computer graphic,issue,positive,positive,positive,positive,positive,positive
465777779,"Yes. That makes sense. I liked idea. 
Does it need new PR?",yes sense idea need new,issue,negative,positive,positive,positive,positive,positive
465776497,"Almost right.

- except it's not `failed_test`, but `has_this_tests`.
- you don't really need to assign anything to `has_this_tests`, other than True/False. The flag goes to False, and `this_tests` puts it down to `True`, so the teardown call just needs to check if it's False. or may be start with None, have this_tests set it to True and the last bit just checks if it's True - sounds more intuitive/readable.
- and we don't want 100s of warnings, but to collect all missing ones and report them at the end of pytest in one go.
- and for now this feature should be off by default since it'll interfere with dev. once we instrument the remainder of the tests then yes, we will turn it on by default - i.e. the check will always run, regardless of how pytest is run, to catch newly written tests w/o `this_tests` early on.
- we use `f""string {var}""` and not `""string"" + var` in fastai code",almost right except really need assign anything flag go false true teardown call need check false may start none set true last bit true want collect missing report end one go feature default since interfere dev instrument remainder yes turn default check always run regardless run catch newly written early use string string code,issue,positive,positive,neutral,neutral,positive,positive
465774103,"I think we are just not clear on what you're proposing. Do you know of an existing implementation that you can point to? ideally one that's documented/demo'ed so it's easy to quickly see it in action.

So far I understand you're proposing for fastai to have a synthetic image generator.",think clear know implementation point ideally one easy quickly see action far understand synthetic image generator,issue,positive,positive,positive,positive,positive,positive
465773303,Perhaps the feature should be activated only on a reasonable image size? e.g. at least 4x4 feature?,perhaps feature reasonable image size least feature,issue,negative,negative,neutral,neutral,negative,negative
465773047,"A self-synthesize one from a function is even better than what I talked about. 
Basically, it's used for lowest # of code lines to reproduce data aug type of bug, where  you don't need a whole dataset.

This is not urgent, if this is not wanted by most, maybe we can have this issue closed.",one function even better basically used code reproduce data type bug need whole urgent maybe issue closed,issue,positive,positive,positive,positive,positive,positive
465769526,"We originally started with [several small datasets in the repo](https://github.com/fastai/fastai/tree/master/data), so that you won't need an internet connection, but then the needs for a variety of such datasets has grown, so we stopped adding those to the repo (as repo's size continually grows already).

But I understand that you're talking about images in the repo that can be fetched via a function, rather read from the disk. Kind of like the inlined images in the html.",originally several small wo need connection need variety grown stopped size continually already understand talking fetched via function rather read disk kind like,issue,positive,positive,positive,positive,positive,positive
465768620,"I wish we could, but we can't have that without breaking the multiprocessing part of the tokenizer. 
Also, please note you need to sign the CLA for us to merge your PR.",wish could ca without breaking part also please note need sign u merge,issue,positive,neutral,neutral,neutral,neutral,neutral
465767769,I don't understand the question. Obviously it requires an internet connection to be downloaded and it will be downloaded in .fastai/data/ like every dataset the library provides convenient links for. I'm just stating it can be used for the tests in the test suite since it's part of the four datasets downloaded when it's executed.,understand question obviously connection like every library convenient link used test suite since part four executed,issue,negative,neutral,neutral,neutral,neutral,neutral
465766939,"Yes, on MNIST, the images are too tiny and end up with just 1x1 feature after going through the pretrained model.",yes tiny end feature going model,issue,negative,neutral,neutral,neutral,neutral,neutral
465766672,@bearpelican we are mostly done with this json.db. Pls call make test_full to get the json. ,mostly done call make get,issue,negative,positive,positive,positive,positive,positive
465766261,Does this rely on network connection and a local working dir to work? ,rely network connection local working work,issue,negative,neutral,neutral,neutral,neutral,neutral
465766237,"After thought: we do this exercise only to throw a warning, when a test is not registered with this - should we not register the API name in the json db also and an entry to test registered with this_tests?

Note, there is a slight complication: In

@pytest.hookimpl(tryfirst=True, hookwrapper=True)
def pytest_runtest_makereport(item, call):

we just have the testmethodname as a string. I havent found an obvious way to get from that to the fullly qualified name, which we would need to enter this into the DB.

Actually, think the warning is sufficient ... entering all APIs even if not registered with this_tests would mean cluttering the json with irrelevant entries.

",thought exercise throw warning test registered register name also entry test registered note slight complication item call string havent found obvious way get qualified name would need enter actually think warning sufficient entering even registered would mean irrelevant,issue,negative,negative,negative,negative,negative,negative
465762316,Our sample at URLs.MNIST_TINY is downloaded during the test suite. Any image of it would be available for tests.,sample test suite image would available,issue,negative,positive,positive,positive,positive,positive
465757339,"This is a really neat feature!

Unfortunately it looks like it's not quite working properly. I've been trying to debug why and it looks like sometimes `mult` is ending up as a tensor of size [1, 1] containing just `[[0.]]` so it's just putting a black overlay over the image.

The `lesson1-pets.ipynb` notebook can demonstrate the issue. On the `PETS` dataset the heatmap shows up (`mult` is of size [10, 10]).

If you go to the end of the notebook and do `plot_top_losses` on the  model created for the `MNIST_SAMPLE` dataset the heatmap doesn't work (`mult` is of size [1, 1]).",really neat feature unfortunately like quite working properly trying like sometimes mult ending tensor size black overlay image notebook demonstrate issue mult size go end notebook model work mult size,issue,positive,negative,negative,negative,negative,negative
465723855,I have not tested the newer version but i think using multiple workers with single threads works fine. So we can close this issue. ,tested version think multiple single work fine close issue,issue,negative,positive,positive,positive,positive,positive
465721080,"Oops, I messed up the pull request... I'll open another one with both changes (AWD-LSTM patch and the TextClassificationInterpretation class)",pull request open another one patch class,issue,negative,neutral,neutral,neutral,neutral,neutral
465720662,Also: Please sign this CLA agreement https://www.clahub.com/agreements/fastai/fastai as explained [here](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md) before we can proceed.  Thank you.,also please sign agreement proceed thank,issue,positive,neutral,neutral,neutral,neutral,neutral
465720418,That doesn't look right. You probably need to rebase your fork.,look right probably need rebase fork,issue,negative,positive,positive,positive,positive,positive
465713582,"That would be an amazing contribution, @kechan. Currently, some of the testing is done by eye-ing the results which is very inefficient and error-prone. So it'd be of a huge value to be able to automate such tests.

Note, that we do have quite a few DL tests, where an expected range of prediction outcome is verified (that's why our CI occasionally fails - non-deterministic tests).

And, of course, it's better to start with a crude DL test, and over time improve upon it, than not to have none, because it's hard.",would amazing contribution currently testing done inefficient huge value able note quite range prediction outcome occasionally course better start crude test time improve upon none hard,issue,positive,positive,positive,positive,positive,positive
465709774,"Actually, writing tests for DL library may be trickier than traditional softwares where failure mode is very clear cut. For DL, it can be very subtle, and be hidden for a long while, just like the one I found on the uniform int for dihedral. I would happily contribute to improving this.

This is somewhat alarming, because it may affect reproducibility in the future, or accidental destroyed a good model by making it worse (Retraining using a buggier version). And u may waste a lot of GPU cycle to find out.

I probably will post on Twitter, or ask around (google, etc). what’s the current best practice. I am sure ppl maintaining tensorflow or Keras will have more mature thinking on this.",actually writing library may traditional failure mode clear cut subtle hidden long like one found uniform dihedral would happily contribute improving somewhat alarming may affect reproducibility future accidental good model making worse version may waste lot cycle find probably post twitter ask around current best practice sure mature thinking,issue,positive,positive,neutral,neutral,positive,positive
465680024,"Are you sure you are on the latest version? I just tried on something similar and your first instruction worked well.
Also, you should switch to the data block API to have more flexibility. In you care
```python
data = (ImageItemList.from_folder(path/'train')
                     .random_split_by_pct()
                     .label_from_folder()
                     .add_test_folder(path/'test')
                     .databunch(path=path))
```
should work (with path = Path(""Data"")).",sure latest version tried something similar first instruction worked well also switch data block flexibility care python data work path path data,issue,positive,positive,positive,positive,positive,positive
465676173,"Yes please, I'd like to make sure more people would benefit from this.",yes please like make sure people would benefit,issue,positive,positive,positive,positive,positive,positive
465675336,"Clearly they don't exist, or they would have caught it. What a great opportunity to write such tests. (hint, hint) :)",clearly exist would caught great opportunity write hint hint,issue,positive,positive,positive,positive,positive,positive
465668307,"Thanks for fixing this so quickly. Wonder if existing tests catch this. I have plans for a couple of new transforms, maybe will take that chance to add one if doesn't exist.",thanks fixing quickly wonder catch couple new maybe take chance add one exist,issue,positive,positive,positive,positive,positive,positive
465649485,"Yes, this used to work properly and I broke it when dealing with the resize in recent bugs. Thanks for flagging!",yes used work properly broke dealing resize recent thanks flagging,issue,negative,positive,neutral,neutral,positive,positive
465602752,"Not quite... for calculating the intrinsic attention (or input sensitivity, or part of the sequential Jacobian) I need to calculate the partial derivatives of the embedded sentence w.r.t. the particular classification's softmax score. To do that, I embed, detach and set require_grad to True, then forward the model up to classification, call backward() and then proceed calculating the intrinsic attention from the embedding's grad.

Do you think I should I copy this thread in the forums as well? Thanks in advance!",quite calculating intrinsic attention input sensitivity part sequential need calculate partial sentence particular classification score embed detach set true forward model classification call backward proceed calculating intrinsic attention grad think copy thread well thanks advance,issue,positive,positive,positive,positive,positive,positive
465445540,"aah sorry, think was my fault and indeed pip install -e "".[dev]"" solved it. Next time I know, usually I run this scripts after downloading a new branch indeed -forgot this time",sorry think fault indeed pip install dev next time know usually run new branch indeed time,issue,negative,negative,negative,negative,negative,negative
465439131,Thank you! I think I am not even watching the latest lesson!,thank think even watching latest lesson,issue,negative,positive,positive,positive,positive,positive
465407244,"Mmm, can you try to see if setting 
```
model.encoder_dp = noop
```
doesn't solve your issue? I'd rather not add a layer of complexity to an already fairly complex model.",try see setting noop solve issue rather add layer complexity already fairly complex model,issue,negative,negative,negative,negative,negative,negative
465406371,"Two changes (one cosmetic, one more important in on_step_end) and we'll be good to go, thanks again!",two one cosmetic one important good go thanks,issue,positive,positive,positive,positive,positive,positive
465404868,"Please use the [forum](https://forums.fast.ai/) for those discussions, issues should be kept for bugs in the library, thanks!",please use forum kept library thanks,issue,positive,positive,positive,positive,positive,positive
465385841,"Hello @sgugger and sorry for the really bad follow-up.
I still struggle to make `ImageDataBunch.from_folder` as I want. As you advised, I used the following:
```python
data = ImageDataBunch.from_folder(Path(""data"")/""train"",
                                  test=Path(""data"")/""test"",
                                  valid_pct=0.2)
```

And the output is:
```
ImageDataBunch;

Train: LabelList (2061 items)
x: ImageItemList
Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280)
y: CategoryList
ok,ok,ok,ok,ok
Path: data/train;

Valid: LabelList (515 items)
x: ImageItemList
Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280)
y: CategoryList
nok,unsure,nok,ok,nok
Path: data/train;

Test: LabelList (0 items)
x: ImageItemList

y: EmptyLabelList

Path: data/train
```

The only solution I found to get my dataset properly split is like this:
```python
data = ImageDataBunch.from_folder(path,
                                  train=""train"",
                                  test=""test"",
                                  valid_pct=0.2,
                                  classes=[""ok"", ""nok"", ""unsure""])
```
I then get the following warning:
```
~/.virtualenvs/fast_ai_course/lib/python3.6/site-packages/fastai/data_block.py:487: UserWarning: You are labelling your items with CategoryList.
Your train set contained the following unknown labels, the corresponding items have been discarded.
test
  if getattr(ds, 'warn', False): warn(ds.warn)
~/.virtualenvs/fast_ai_course/lib/python3.6/site-packages/fastai/data_block.py:487: UserWarning: You are labelling your items with CategoryList.
Your valid set contained the following unknown labels, the corresponding items have been discarded.
test
  if getattr(ds, 'warn', False): warn(ds.warn)
```
But then my dataset is correct:
```
ImageDataBunch;

Train: LabelList (2048 items)
x: ImageItemList
Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280)
y: CategoryList
ok,ok,ok,ok,ok
Path: data;

Valid: LabelList (528 items)
x: ImageItemList
Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280)
y: CategoryList
ok,nok,unsure,nok,ok
Path: data;

Test: LabelList (14957 items)
x: ImageItemList
Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280),Image (3, 960, 1280)
y: EmptyLabelList
,,,,
Path: data
```",hello sorry really bad still struggle make want advised used following python data path data train data test output train image image image image image path valid image image image image image unsure path test path solution found get properly split like python data path train test unsure get following warning train set following unknown corresponding test false warn valid set following unknown corresponding test false warn correct train image image image image image path data valid image image image image image unsure path data test image image image image image path data,issue,negative,negative,negative,negative,negative,negative
465370087,"this functionality was just added to git - are you using the dev install? Try again after `pip install -e "".[dev]""`?

but actually it shouldn't matter, since conftest change sys.path to use the checkout `fastai` folder.

but somehow your `fastai` subfolder checkout is outdated, have a look here:
https://github.com/fastai/fastai/blob/master/fastai/basic_train.py#L207
the `destroy` argument is there, check your local copy.",functionality added git dev install try pip install dev actually matter since change use folder somehow outdated look destroy argument check local copy,issue,negative,negative,negative,negative,negative,negative
465351689,"Some potential improvements to follow up:

* RegisterTestsPerAPI.some_tests_failed could go to conftest - but needs to be a class var, since is called on every test.
* I use inspect.currentframe while I seem to remember we want to just say currentframe and import inspect accordingly
* in this I use fastaimodule = re.match(r'^fastai..*',fq_apiname) to exclude non fastai APIs that were registered. Since we really do not want that in the code, could in full_name_with_qualname just raise an exception if that match isnt given. So, we force developers to revisit their code.",potential follow could go need class since every test use seem remember want say import inspect accordingly use exclude non registered since really want code could raise exception match given force revisit code,issue,negative,positive,neutral,neutral,positive,positive
465342746,"Ah, ok, I couldn't tell from looking at the diff. Will look closer once it's in. 

Let's do just FooBar to foo_bar, commit and then deal with the finetuning later.",ah could tell looking look closer let commit deal later,issue,negative,neutral,neutral,neutral,neutral,neutral
465338235,"think RegisterTestsPerAPI.some_tests_failed could go to conftest - but needs to be a class var, since is called on every test.

I am actually fine to go through these little improvements like naming conventions, if we make a list.

Some small things I saw (and we can extend the list and I can correct)
-  I use inspect.currentframe while I seem to remember we want to just say currentframe and import inspect accordingly
- in this I use fastaimodule = re.match(r'^fastai\..*',fq_apiname) to exclude non fastai APIs that were registered. Since we really do not want that in the code, could in full_name_with_qualname just raise an exception if that match isnt given. So, we force developers to revisit their code.",think could go need class since every test actually fine go little like naming make list small saw extend list correct use seem remember want say import inspect accordingly use exclude non registered since really want code could raise exception match given force revisit code,issue,positive,positive,neutral,neutral,positive,positive
465333022,"Thank you for testing, @phenomax.

>Nonetheless I am running into graphics memory leakage: without any processes active it fills up to 80%, but resets after I disconnect my monitors.

You mean physically disconnect a monitor? Some kinds of a bug in your OS?

In general have a look at this new work-in-progress tutorial for all things memory-reclaiming:
https://docs.fast.ai/tutorial.resources.html
and [ipyexperiments](https://github.com/stas00/ipyexperiments/) is very helpful at making it easy to watch real memory consumption.

Probably start a new thread at the forums, sharing as much as possible about your env, setup and sample code and someone will know what to recommend? I don't know anything about Mac.",thank testing nonetheless running graphic memory leakage without active disconnect mean physically disconnect monitor bug o general look new tutorial helpful making easy watch real memory consumption probably start new thread much possible setup sample code someone know recommend know anything mac,issue,positive,positive,neutral,neutral,positive,positive
465331551,"> If could please validate the auto-install is working after removing fastai/pynvx from your install and then installing just fastai and checking that pynvx gets in just right, that would be helpful.

I did it and everything is working like a charm. I think we can call that done :)

> Actually, `gpu_mem_restore` doesn't use/need gpu access. the nvml query functionality is used primarily for testing, memory profiling and already in fastai lessons where we try to help calibrate batch size and other hyperparameters based on available GPU RAM.

Yeah, I was a bit hasty about the so called fix. The function had nothing to do with it at all. Nonetheless I am running into graphics memory leakage: without any processes active it fills up to 80%, but resets after I disconnect my monitors. Do you have any advice regarding that?",could please validate working removing install right would helpful everything working like charm think call done actually access query functionality used primarily testing memory already try help calibrate batch size based available ram yeah bit hasty fix function nothing nonetheless running graphic memory leakage without active disconnect advice regarding,issue,positive,positive,positive,positive,positive,positive
465330473,"Is there something wrong with this line of code if you want zeros padding:

`get_sample_image().apply_tfms(tfms, size=224, padding_mode='zeros')`

I am on  1.0.45. For some reasons this didn't work, it is still showing reflect. I thought this had worked before?

Update: I also reproduced this on colab, filed https://github.com/fastai/fastai/issues/1681",something wrong line code want padding work still showing reflect thought worked update also,issue,negative,negative,negative,negative,negative,negative
465314461,"Thanks for suggestions :) I will update the PR as soon as possible, probably tonight.",thanks update soon possible probably tonight,issue,negative,positive,neutral,neutral,positive,positive
465314119,"Thanks a lot! There are a few style change to make and I made a suggestion to add an argument, then we'll be able to merge this.",thanks lot style change make made suggestion add argument able merge,issue,negative,positive,positive,positive,positive,positive
465311604,"I see @stas00 I just wanted to rebase and PR the sources following recommendations. But, no problem. next time I will do them properly. Thanks for the fix in the source",see rebase following problem next time properly thanks fix source,issue,negative,positive,neutral,neutral,positive,positive
465311020,"oops, I merged the html by mistake, I now fixed the source too:
https://github.com/fastai/fastai/commit/72fdc271693e9ec5f6898907b8e2ce43a56b949a
so nothing else needs to be done, @mohamedi.

Thanks again.",mistake fixed source nothing else need done thanks,issue,negative,positive,positive,positive,positive,positive
465308906,"Thanks a lot, I have agreed to license. Let me read the document and update correspondingly. 
",thanks lot agreed license let read document update correspondingly,issue,positive,positive,positive,positive,positive,positive
465300379,"Oh, I had forgotten that `get_preds` could return three elements sometimes, good catch.",oh forgotten could return three sometimes good catch,issue,negative,positive,positive,positive,positive,positive
465269429,"I haven't tried running it yet, but looking at the code - looks excellent, @Benudek.

I'd ask to only change:
```
  apiTestsMap = dict()
    oneOrMoreTestsfailed = False
```
we don't use CamelCase other than for class names.

So apiTestsMap => api_tests_map
oneOrMoreTestsfailed => some_tests_failed (some = one or more)

and later once it's all happy and working, we would need to go over and use consistent naming for the map/db/file, as now it's a bit all over. But will worry about it later.

So please make these 2 case renames and this is good to go.

Thank you.",tried running yet looking code excellent ask change false use class one later happy working would need go use consistent naming bit worry later please make case good go thank,issue,positive,positive,positive,positive,positive,positive
465256042,"> Thanks for the quick resolution. Your monkey patch is working fine!
> For convenience you may want to add `pynvx;platform_system==""Darwin""` to the `setup.py` core dependencies.

Done. Thank you for that and testing it.

If could please validate the auto-install is working after removing fastai/pynvx from your install and then installing just fastai and checking that pynvx gets in just right, that would be helpful.

Unfortunately, conda users will have to do it manually. or we could add it to the instructions if need be. And could also try to build a conda package, but it'll still need to be installed manually, since conda doesn't support run-time dependencies, only build time, and we would like to stick to `noarch` single release.

> Thanks for your explanation. I was missing the active usage of the `gpu_mem_restore` function, which led to cuda out of memory exceptions on my primal fix

Actually, `gpu_mem_restore` doesn't use/need gpu access. the nvml query functionality is used primarily for testing, memory profiling and already in fastai lessons where we try to help calibrate batch size and other hyperparameters based on available GPU RAM.
",thanks quick resolution monkey patch working fine convenience may want add core done thank testing could please validate working removing install right would helpful unfortunately manually could add need could also try build package still need manually since support build time would like stick single release thanks explanation missing active usage function led memory primal fix actually access query functionality used primarily testing memory already try help calibrate batch size based available ram,issue,positive,positive,neutral,neutral,positive,positive
465215308,"This is the result of show_install():


```text
=== Software === 
python       : 3.6.1
fastai       : 1.0.45
fastprogress : 0.1.19
torch        : 1.0.1
torch cuda   : None / is **Not available** 

=== Hardware === 
No GPUs available 

=== Environment === 
platform     : Windows-10-10.0.17134-SP0
conda env    : Unknown
python       : C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\python.exe
sys.path     : 
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\python36.zip
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\DLLs
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\lib
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3
C:\Users\ev3nicvivare\AppData\Roaming\Python\Python36\site-packages
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\lib\site-packages
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\lib\site-packages\Sphinx-1.5.6-py3.6.egg
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\lib\site-packages\win32
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\lib\site-packages\win32\lib
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\lib\site-packages\Pythonwin
C:\Users\ev3nicvivare\AppData\Local\Continuum\Anaconda3\lib\site-packages\IPython\extensions
C:\Users\ev3nicvivare\.ipython
no supported gpus found on this system
```

Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.",result text python torch torch none available hardware available environment platform unknown python egg found system please make sure include paste make appear code,issue,positive,positive,positive,positive,positive,positive
465207897,"> Not exactly: we don't want all the I to become TK_UP i for instance, it's not the same thing as when a person is writing in all caps. On the other hand I should be coded TK_MAJ i

```
if t[0].isupper() and t[1:].islower(): res.append(TK_MAJ)
```
When I deal with non-English,  array may be out of bounds.
I think:
`if t[0].isupper() and len(t) > 1 and t[1:].islower(): res.append(TK_MAJ)`",exactly want become instance thing person writing hand deal array may think,issue,positive,positive,positive,positive,positive,positive
465203627,"Not exactly: we don't want all the I to become TK_UP i for instance, it's not the same thing as when a person is writing in all caps. On the other hand I should be coded TK_MAJ i",exactly want become instance thing person writing hand,issue,positive,positive,positive,positive,positive,positive
465190123,"Just a few line breaks and no spaces between multiple assignments (a,b = bli,bla)
Thanks a lot for all your work!",line multiple thanks lot work,issue,negative,positive,neutral,neutral,positive,positive
465134897,Closing this since in a while. Feel free to reopen with an example I can reproduce!,since feel free reopen example reproduce,issue,positive,positive,positive,positive,positive,positive
465093331,"Thanks for the quick resolution. Your monkey patch is working fine!
For convenience you may want to add `pynvx;platform_system==""Darwin""` to the `setup.py` core dependencies.

> it's not relying on nvidia-smi.

> Here is what's happening: fastai requires pytorch which requires nvidia library and therefore needs to be able to query the gpu. Since pytorch doesn't provide this functionality we have to use another approach.

Thanks for your explanation. I was missing the active usage of the `gpu_mem_restore` function, which led to cuda out of memory exceptions on my primal fix",thanks quick resolution monkey patch working fine convenience may want add core happening library therefore need able query since provide functionality use another approach thanks explanation missing active usage function led memory primal fix,issue,positive,positive,positive,positive,positive,positive
465022984,ConvLearner is still in latest Lesson 1 then why isn't v1 updated for that!  Thank you very much by the way ,still latest lesson thank much way,issue,negative,positive,positive,positive,positive,positive
465000998,"I know it's a small correction, but you will probably be sending more contributions in the future, therefore:

1. Please sign this CLA agreement https://www.clahub.com/agreements/fastai/fastai as explained [here](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md) before we can proceed. 

2. Please refer to https://docs.fast.ai/gen_doc_main.html - autogenerated html files shouldn't be modified, only the originals

Thank you.",know small correction probably sending future therefore please sign agreement proceed please refer thank,issue,positive,negative,negative,negative,negative,negative
464978017,Please sign this CLA agreement https://www.clahub.com/agreements/fastai/fastai as explained [here](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md) before we can proceed.  Thank you.,please sign agreement proceed thank,issue,positive,neutral,neutral,neutral,neutral,neutral
464960549,"Thanks a lot! There are just a last few cosmetic changes to make, and one import to remove, then we'll be good to merge.",thanks lot last cosmetic make one import remove good merge,issue,positive,positive,positive,positive,positive,positive
464937021,"OK, please try the latest git and let me know whether it's a happy resolution. I added a little hack to have `pynvx` work as if it were `pynvml`.

```
use_gpu = torch.cuda.is_available()

GPUMemory = namedtuple('GPUMemory', ['total', 'free', 'used'])

is_osx = platform.system() == ""Darwin""

# transparently monkey patch pynvx as pynvml API on OSX (for the few funcs we use)
if use_gpu and is_osx:
    try:
        import pynvx
    except:
        print(""please install pynvx on OSX: pip install pynvx"")
        sys.exit(1)

    # missing function
    def cudaDeviceGetHandleByIndex(id): return pynvx.cudaDeviceGetHandles()[id]
    setattr(pynvx, 'cudaDeviceGetHandleByIndex', cudaDeviceGetHandleByIndex)

    # different named and return value needs be a named tuple
    def cudaDeviceGetMemoryInfo(handle):
        info = pynvx.cudaGetMemInfo(handle)
        return GPUMemory(*info)
    setattr(pynvx, 'cudaDeviceGetMemoryInfo', cudaDeviceGetMemoryInfo)

    # remap the other functions
    for m in ['Init', 'DeviceGetCount', 'DeviceGetHandleByIndex', 'DeviceGetMemoryInfo']:
        setattr(pynvx, f'nvml{m}', getattr(pynvx, f'cuda{m}'))
    pynvml = pynvx

```",please try latest git let know whether happy resolution added little hack work transparently monkey patch use try import except print please install pip install missing function id return id different return value need handle handle return remap,issue,positive,positive,positive,positive,positive,positive
464920777,"we should most likely try a different approach, please see https://forums.fast.ai/t/doc-test-project/38344/150",likely try different approach please see,issue,negative,neutral,neutral,neutral,neutral,neutral
464851910,"> **Expected behavior**
> FastAI should not rely on Nvidia-smi. It should either be made optional, or it's feature implemented platform-agnostic.

it's not relying on nvidia-smi.

Here is what's happening: fastai requires pytorch which requires nvidia library and therefore needs to be able to query the gpu. Since pytorch doesn't provide this functionality we have to use another approach. Currently, [python-nvml](https://pythonhosted.org/nvidia-ml-py) seems to be the best option. But as you're saying OSX is not supported.

I'm not an OSX user, so it's hard for me to tell where things are wrt nvidia on that platform. But a quick search resulted in: https://github.com/1132719438/pynvx, whose API seems to be very similar to nvml, so it should be easy to use that one on OSX - if you'd like to help to make the use of it on mac it'd be helpful. There are just a few API calls to pynvml in https://github.com/fastai/fastai/blob/master/fastai/utils/mem.py. So we would need some kind of a wrapper to use one library or the other.

So once that is supported we can load `pynvx` instead of `pynvml` on OSX, and if failed ask the user to: `pip install pynvx` - we could tweak fastai pip dependencies to install it automatically, but since there is no conda package the dynamic check will still be needed.

I'd be happy to support you in this porting if you'd like to help make a proper nvidia querying work.  

update: since pynvx works on linux, let me see if I can make a quick solution here, you will just need to test.",behavior rely either made optional feature happening library therefore need able query since provide functionality use another approach currently best option saying user hard tell platform quick search whose similar easy use one like help make use mac helpful would need kind wrapper use one library load instead ask user pip install could tweak pip install automatically since package dynamic check still happy support like help make proper querying work update since work let see make quick solution need test,issue,positive,positive,positive,positive,positive,positive
464832760,"Those seem pretty good, thanks!",seem pretty good thanks,issue,positive,positive,positive,positive,positive,positive
464832402,"Note that `TextDataBunch.load` is deprecated now, but it could also break with `from_ids`",note could also break,issue,negative,neutral,neutral,neutral,neutral,neutral
464828344,"Understood. This is an area where ability to customize is more important since many of them are task dependent. There are posts where people have already written gaussian blur operating directly on torch tensor. It is matter of testing them and integrating into fastai. 

But before jumping in, i want to see how bad the above code is and decide if i can procrastinate on this. I would like to move on other things as well.",understood area ability important since many task dependent people already written blur operating directly torch tensor matter testing want see bad code decide procrastinate would like move well,issue,positive,positive,neutral,neutral,positive,positive
464774230,"This should now work (note that it's not possible to pop up a new window in colab, but it will appear as the result of the cell). You will need to use master to see it until v1.0.46 is released, you can install it with:
```
!pip install git+https://github.com/fastai/fastai
```",work note possible pop new window appear result cell need use master see install pip install,issue,negative,positive,neutral,neutral,positive,positive
464752952,"That means you have a really old version of fastai, so update to the latest one first.",really old version update latest one first,issue,negative,positive,positive,positive,positive,positive
464744154,"Yes, I forgot to remove it from the docs, thanks!",yes forgot remove thanks,issue,positive,positive,positive,positive,positive,positive
464743831,"We didn't implement gaussian blur but that doesn't mean we wouldn't like to have it in the fastai library. I understand it's a convolution with a random kernel so we have the tool in pytorch to do this directly on a tensor. Implementing new transforms isn't high priority on our side, but if you want to dig in and suggest a PR, it would be very welcome.

Shear mapping in general isn't implemented but we have all kinds of perspective warping available. The pipeline is already there to treat transforms that operates on coordinates, so I don't think it would be too hard to implement more versions of shear.",implement blur mean would like library understand convolution random kernel tool directly tensor new high priority side want dig suggest would welcome shear general perspective warping available pipeline already treat think would hard implement shear,issue,positive,positive,neutral,neutral,positive,positive
464741477,"If you don't use the fastai library to build your `DataLoader` through the data block API, this functionality won't work, no.
You will have to create a `Learner` yourself at inference and load the model with `learn.load(...)`.",use library build data block functionality wo work create learner inference load model,issue,negative,neutral,neutral,neutral,neutral,neutral
464736015,Conv learner is not defined in V1. To use convLearner use the 0.7 version of the library.,learner defined use use version library,issue,negative,neutral,neutral,neutral,neutral,neutral
464661947,"Thanks for your reply. When I was doing the Deep Learning 2018 course installing fastai with cuda from source was still possible.
<img width=""699"" alt=""image"" src=""https://user-images.githubusercontent.com/12475496/52942037-6674ee80-336a-11e9-9026-7adcfb8aaba8.png"">

Although official mac support is none of your priority, breaking it with newly added features shouldn't be the way to go. When I find time, I'll work on a friendly workaround/fix for mac os.",thanks reply deep learning course source still possible image although official mac support none priority breaking newly added way go find time work friendly mac o,issue,positive,positive,positive,positive,positive,positive
464627477,"I'm using Jupyter Notebook, but strangely if I try to run your code i get 'No module named 'fastai.utils.show_install' ",notebook strangely try run code get module,issue,negative,negative,neutral,neutral,negative,negative
464553355,"Hi there. First things first, MacOs isn't officially supported (I think it is clearly stated on the installation page) and it's not a priority to change that. With this being said, a PR that would try/except this import nicely would definitely be accepted.",hi first first officially think clearly stated installation page priority change said would import nicely would definitely accepted,issue,positive,positive,positive,positive,positive,positive
464524673,Posted on dev forum to solicitate feedback. ,posted dev forum feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
464463116,"This is the best way to implement this transform, yes. You can definitely suggest a PR with this, it can probably be useful to other people too.",best way implement transform yes definitely suggest probably useful people,issue,positive,positive,positive,positive,positive,positive
464410220,"If np.rot90(...) can be achieved by calling whats already in fastai, it will be great. But it isn't too hard to create a new one. So if you happen to need it, here's the simple addition you can use as well.

```
def _rot90_affine(k:partial(uniform_int, 0, 3)):
    ""Randomly rotate `x` image based on `k` as in np.rot90""
    if k%2 == 0:
        x = -1. if k&2 else 1.
        y = -1. if k&2 else 1.
        
        return [[x, 0, 0.],
                [0, y, 0],
                [0, 0, 1.]]
    else:
        x = 1. if k&2 else -1.
        y = -1. if k&2 else 1.
        
        return [[0, x, 0.],
                [y, 0, 0],
                [0, 0, 1.]]

rot90_affine = TfmAffine(_rot90_affine)
tfms = [rot90_affine()]
get_ex().apply_tfms(tfms, size=224)
```

If this is indeed the best way, I will propose this in the fastai dev forum and see if this is common enough to be part of the library.

Note: for rot90 (TfmPixel):

```
def _rot90(x, k:partial(uniform_int,0,3)):
    ""Randomly flip `x` image based on `k` as in np.rot90""
    print(""k={}"".format(k))
    if k == 1:
        x = torch.flip(x, [2])
        x = x.transpose(1, 2)
    elif k == 2:
        x = torch.flip(x, [2, 1])
    elif k == 3:
        x = torch.flip(x, [1])
        x = x.transpose(1, 2)
    
    return x.contiguous()
    
rot90 = TfmPixel(_rot90)
```",calling whats already great hard create new one happen need simple addition use well partial randomly rotate image based else else return else else else return indeed best way propose dev forum see common enough part library note rot partial randomly flip image based print return rot,issue,positive,positive,neutral,neutral,positive,positive
464397339,"I suggest 1.15.0 - spacy indicated this dependency and I installed and tested - that version works.
And actually, exactly the previous version pip install numpy==1.14.6 does fail.

So there you go and have your min. dependency ;-)


pip install numpy==1.12.0

spacy 2.0.18 has requirement numpy>=1.15.0, but you'll have numpy 1.12.0 which is incompatible.
Installing collected packages: numpy
  Found existing installation: numpy 1.14.5
    Uninstalling numpy-1.14.5:
      Successfully uninstalled numpy-1.14.5
Successfully installed numpy-1.12.0
",suggest spacy dependency tested version work actually exactly previous version pip install fail go min dependency pip install spacy requirement incompatible collected found installation successfully uninstalled successfully,issue,negative,positive,positive,positive,positive,positive
464394288,"Please re-read the previous comment. We need to know the first lowest version where it doesn't fail. I asked you to find the last failing to make sure you actually find that transition. finding the first failing one does't help us.

Once we know the first **lowest** good version we can then set in the dependencies file: `numpy>=first_good_version`

And if you skip steps and tell me that `1.16.0` works, that's not good. Because we need to know the lowest version number at which it starts working. If we set to the highest, then users won't be able to install other software that may rely on a lower numpy version. I hope you understand now why the very specific request.

and skip the betas too, just normal releases

And bisect, rather than trying them all. i.e. 1.12, 1.16, good/bad -> 1.14 good/bad, etc.
",please previous comment need know first version fail find last failing make sure actually find transition finding first failing one help u know first good version set file skip tell work good need know version number working set highest wo able install may rely lower version hope understand specific request skip normal bisect rather trying,issue,negative,positive,positive,positive,positive,positive
464393645,"pip install numpy==1.12.0b1

this already fails ;-) with the error as described",pip install already error,issue,negative,neutral,neutral,neutral,neutral,neutral
464392881,"I have just written this quick guide: https://docs.fast.ai/dev/test.html#quick-guide
Let me know if you encounter any issues following it.

---------------------

> I can see 2 kinds of test (the latter one unique to deep learning).
> 
>   1. traditional test that test for programmatic correctness. In this case, it can be as simple as checking if ""8"" is indeed never sampled.
> 
>   2.  statistical test. i.e. a test for targeting the statistics ??

while general unit tests (correctness) are always welcome, you suggested a quality test - which is very important, precisely because it can detect regressions. So yes, to statistical test. Just give it some tolerance that is not huge (pointless test), but not too tight either because it'll lead to failures often. `math.isclose` is usually a good one, but there other tools. You will find quite a few different approaches in the existing tests.",written quick guide let know encounter following see test latter one unique deep learning traditional test test programmatic correctness case simple indeed never statistical test test statistic general unit correctness always welcome quality test important precisely detect yes statistical test give tolerance huge pointless test tight either lead often usually good one find quite different,issue,positive,positive,positive,positive,positive,positive
464390165,"Thank you.

Can you please try to do bisecting and find out at which version it breaks?

You can easily find which versions are available using this trick:

`$ pip install numpy==999999
  Could not find a version that satisfies the requirement numpy==999999 (from versions: 1.3.0, 1.4.1, 1.5.0, 1.5.1, 1.6.0, 1.6.1, 1.6.2, 1.7.0, 1.7.1, 1.7.2, 1.8.0, 1.8.1, 1.8.2, 1.9.0, 1.9.1, 1.9.2, 1.9.3, 1.10.0.post2, 1.10.1, 1.10.2, 1.10.4, 1.11.0b3, 1.11.0rc1, 1.11.0rc2, 1.11.0, 1.11.1rc1, 1.11.1, 1.11.2rc1, 1.11.2, 1.11.3, 1.12.0b1, 1.12.0rc1, 1.12.0rc2, 1.12.0, 1.12.1rc1, 1.12.1, 1.13.0rc1, 1.13.0rc2, 1.13.0, 1.13.1, 1.13.3, 1.14.0rc1, 1.14.0, 1.14.1, 1.14.2, 1.14.3, 1.14.4, 1.14.5, 1.14.6, 1.15.0rc1, 1.15.0rc2, 1.15.0, 1.15.1, 1.15.2, 1.15.3, 1.15.4, 1.16.0rc1, 1.16.0rc2, 1.16.0, 1.16.1)
No matching distribution found for numpy==999999`

then skipping rc releases, and starting probably around 1.12 (no need to go before that).
```
pip install numpy==version_num_to_try
pytest tests/test_text_data.py::test_should_load_backwards_lm_1 
```
so within just a few runs of the above you will find the problematic version. And the earliest version at which it starts working (not the latest one). Then we can pin to that earliest version in our dependencies.

Thank you.",thank please try find version easily find available trick pip install could find version requirement post matching distribution found skipping starting probably around need go pip install within find problematic version version working latest one pin version thank,issue,positive,positive,positive,positive,positive,positive
464389938,"I am actually investigating, and may propose adding a new transform thats not exactly available. I will take that chance to also write some test for this bug. 

I can see 2 kinds of test (the latter one unique to deep learning). 

1) traditional test that test for programmatic correctness. In this case, it can be as simple as checking if ""8"" is indeed never sampled. 

2) statistical test. i.e. a test for targeting the statistics ??

Since this is just a dead simple sampling (2) is not probably needed. I just thought it may actually be quite interesting if test accuracy for ML/DL tasks drop across the board after this fix. Then we may consider to do some research if this was indeed a feature (not a bug) fastai stumble upon and it's closer to the optimal value for generic scenarios.",actually investigating may propose new transform thats exactly available take chance also write test bug see test latter one unique deep learning traditional test test programmatic correctness case simple indeed never statistical test test statistic since dead simple sampling probably thought may actually quite interesting test accuracy drop across board fix may consider research indeed feature bug stumble upon closer optimal value generic,issue,negative,positive,neutral,neutral,positive,positive
464388809,"Thanks. Yup, I don't know what I need for now (2nd degree ignorance). But what you post will get me started, hopefully efficiently.

This is the blight of working for a company for too long that used proprietary everything (incl. source control).",thanks know need degree ignorance post get hopefully efficiently blight working company long used proprietary everything source control,issue,positive,positive,neutral,neutral,positive,positive
464388630,"Well, I don't know what you need to know. We have all kinds of tips here: https://docs.fast.ai/dev/test.html
but, really, look at the existing tests and modify/add to create this new one that measures quality. Most likely it should go here: https://github.com/fastai/fastai/blob/master/tests/test_vision_transform.py
From the git checkout 
```
pip install -e "".[dev]""
```
then to run the whole module.
```
pytest -sv tests/test_vision_transform.py
```
to run a specific test:
```
pytest -sv tests/test_vision_transform.py::test_points_data_aug
```",well know need know really look create new one quality likely go git pip install dev run whole module run specific test,issue,positive,positive,positive,positive,positive,positive
464388273,"Please post some pointers, I may come around and do this later. I will also post this on the fastai lesson forum, since a lot of them are simple recognition type tasks, to see if someone may want to try.",please post may come around later also post lesson forum since lot simple recognition type see someone may want try,issue,negative,neutral,neutral,neutral,neutral,neutral
464388030,"what a great opportunity to write a new fastai test to do just that, @kechan! and thank you!",great opportunity write new test thank,issue,positive,positive,positive,positive,positive,positive
464387489,It would be interesting to see if this change will make past results better or worse. ,would interesting see change make past better worse,issue,negative,positive,neutral,neutral,positive,positive
464361663,"My branch is kechan:bug-uniform-int-dihedral, I have created a PR but it seemed still to be running checks. Please let me know if there's any issues, or anything else I need to do.",branch still running please let know anything else need,issue,negative,neutral,neutral,neutral,neutral,neutral
464229147,Thanks! Just a few cosmetic changes and we should be good to merge.,thanks cosmetic good merge,issue,positive,positive,positive,positive,positive,positive
464151701,"No it's definitely a mistake (I asked Jeremy and he confirmed). We already have some bias toward doing nothing with the probability of the transform (default is 0.75 IIRC, so 25% of the time it does nothing plus all the times we pick 0).

Here is [our tutorial](https://docs.fast.ai/dev/git.html#how-to-make-a-pull-request-pr) to make a PR. It's a good occasion for you to learn how to do this ;)",definitely mistake confirmed already bias toward nothing probability transform default time nothing plus time pick tutorial make good occasion learn,issue,negative,positive,positive,positive,positive,positive
464124393,"> It's hard for me to decide what was the originally intended functionality

Well this function is originally designed for people using jupyter notebooks. `show_batch` is already using multiple axes, so I'm not sure it can plot on a given axe. A saved filename seems like a better option. 
In any case, we're happy to consider PRs improving this, but it's not a priority in the development.",hard decide originally intended functionality well function originally designed people already multiple ax sure plot given axe saved like better option case happy consider improving priority development,issue,positive,positive,positive,positive,positive,positive
464120574,"Just wanted to confirm that this happens to me as well. If someone could help point me in the right direction to fix that, I'd be more than happy to take a stab at it",confirm well someone could help point right direction fix happy take stab,issue,positive,positive,positive,positive,positive,positive
464117999,"Ok. If the ""uniform"" mean randint(...) as in numpy, then this will indeed be a uniform sampling of 0...8 including 8. Of course, this can be by design if you really want to bias towards no op in a simpler  (albert a bit arbitrary/adhoc) manner.

This bug may have subtle impact since it may affect accuracy/results of all trained vision models. Do we want more input from others before going ahead and ""fix"" this. I am totally new to fastai, and also new to git PR (if you have short concise tutorial, pls send), so this is an excuse for me to have more time. 

Now, if fastai has a philosophy of curating what work best across most cases (this is a tough one in my opinion) by providing that get_transforms(...), and if a bias towards no-op actually achieves this, then we should have a flexible way to spec the prob distribution for the 8-orientation, and then put in a sensible bias in that get_transform. Bias towards no-op actually make sense for many everyday object that ""stands"" up. 

So, we just may have stumble upon a good one here (a feature and not a bug). 

If you have easy access to Jeremy, would like to hear what he thinks.",uniform mean indeed uniform sampling course design really want bias towards simpler bit manner bug may subtle impact since may affect trained vision want input going ahead fix totally new also new git short concise tutorial send excuse time philosophy work best across tough one opinion providing bias towards actually flexible way spec prob distribution put sensible bias bias towards actually make sense many everyday object may stumble upon good one feature bug easy access would like hear,issue,positive,positive,positive,positive,positive,positive
464085337,"Arg, with all those different conventions in randint we sometimes get confused. It should be 0 to 7, the 8 wasn't supposed to be included. Since you found it, I'll let you do the honor of fixing it, if you don't mind?",different sometimes get confused supposed included since found let honor fixing mind,issue,negative,negative,negative,negative,negative,negative
464083336,"The issue seems to be with fastprogress. We'd need to know your installation details to help, and also what python you're using (jupyter notebook, console, other editor?) Please copy paste the result of
```
from fastai.utils.show_install import *
show_install()
```",issue need know installation help also python notebook console editor please copy paste result import,issue,positive,neutral,neutral,neutral,neutral,neutral
464071026,"Thanks!
For future reference, don't even put the parenthesis (I'll remove them, didn't want to bother you with this). If you catch other functions names in backticks with parenthesis, feel free to suggest a PR to remove them because it breaks the link toward them in the docs.",thanks future reference even put parenthesis remove want bother catch parenthesis feel free suggest remove link toward,issue,positive,positive,positive,positive,positive,positive
463946589,It's hard for me to decide what was the originally intended functionality. I just think the possibility to pass an axis object to plotting routines would enhance the flexibility of the library.,hard decide originally intended functionality think possibility pas axis object plotting would enhance flexibility library,issue,negative,positive,neutral,neutral,positive,positive
463895831,"Thank for catching it. I can see your comments so ReviewNB seems to be working well. I added backpacks around function name. I excluded ""()"" from backticks as you suggested but saw other function names have ""()"" in backticks in document.",thank catching see working well added around function name saw function document,issue,positive,positive,positive,positive,positive,positive
463868126,"It's in your domain, @bearpelican, so I trust it's how you always deliver. But otherwise looks great.

Thank you!",domain trust always deliver otherwise great thank,issue,positive,positive,positive,positive,positive,positive
463866438,Sorry tagged too early 😭 Should be stable now,sorry tagged early stable,issue,negative,negative,negative,negative,negative,negative
463812056,"Sounds like a good idea, thanks!",like good idea thanks,issue,positive,positive,positive,positive,positive,positive
463737643,"No, we want to take these gradients with respect to the log scale of the learning rates.",want take respect log scale learning,issue,positive,neutral,neutral,neutral,neutral,neutral
463684553,"Small question regarding the `np.gradient()`. 

When you pass just the function values (in this case `self.losses`), `np.gradient()` assumes that these are equally spaced. With lr_find(), that is not the case. Shouldn't we also pass `self.lrs`, i.e. `np.gradient(np.array([x.item() for x in losses]),lrs)` ?
",small question regarding pas function case equally spaced case also pas,issue,negative,negative,negative,negative,negative,negative
463677635,"OK thank you, now the PR is sent.

Please @sgugger take a look to avoid your changes to be overwritten. I think we were editing a previous version.",thank sent please take look avoid think previous version,issue,negative,negative,negative,negative,negative,negative
463668779,"you need to fork the repo, do the change on your forked branch and then submit pr. here is step by step instructions plus a helper app:
https://docs.fast.ai/dev/git.html#how-to-make-a-pull-request-pr",need fork change forked branch submit step step plus helper,issue,negative,neutral,neutral,neutral,neutral,neutral
463663257,"It seems i cannot send the PR, i receive this in Github Desktop:
Authentication failed. You may not have permission to access the repository or the repository may have been archived. Open preferences and verify that you're signed in with an account that has permission to access this repository.",send receive authentication may permission access repository repository may open verify account permission access repository,issue,negative,neutral,neutral,neutral,neutral,neutral
463660314,"Yes, that's why I removed the assert when the url isn't in the internal check dictionary.",yes removed assert internal check dictionary,issue,negative,neutral,neutral,neutral,neutral,neutral
463659203,"Thanks for the swift response, we added in our PR the rest of the Image Classification and NLP datasets that can be found here:
https://course.fast.ai/datasets

But anyway, there should be a way to untar external datasets (eg. from URLs or Github repositories) that are not included in the fastai registry, shouldn't it?",thanks swift response added rest image classification found anyway way untar external included registry,issue,positive,positive,neutral,neutral,positive,positive
463655552,"I'll also push a fix that ignores that test if the url isn't in the dictionary of checks, but that doesn't mean a PR with these missing datasets wouldn't be appreciated!",also push fix test dictionary mean missing would,issue,negative,negative,negative,negative,negative,negative
463654797,"Thanks. There is one problem with this PR outlined in the comments I left and a few things to tweak, but it seems like a useful functionality.",thanks one problem outlined left tweak like useful functionality,issue,positive,positive,positive,positive,positive,positive
463652005,"A few minor changes requested. This is the first time we use ReviewNB for this, so let me know if you have any trouble seeing them.",minor first time use let know trouble seeing,issue,negative,neutral,neutral,neutral,neutral,neutral
463560286,"Hey @stas00, here are what I have figured out so far:

* Whether `nbmerge` is practical to use without git integration.
  * It is really not. Unlike `nbdiff`, which in some sense looks for source control information automatically without git integration, `nbmerge` is oblivious of the source control context and would require three arguments to run:

   ```txt
  nbmerge: error: the following arguments are required: base, local, remote
   ```

   That is too much a hassle for the users.

  * However, `nbdime mergetool` is certainly practical to use even without git integration. Basically, when there is merge conflict, it would show a nice web-based interface similar to `nbdiff` to resolve the conflicts, and then save the merged result in a valid ipynb format to overwrite the original notebook.
* Whether `nbdime mergetool`, even without integration, breaks our setup.
  * It does not from my limited experience. Last time when I broke our setup by running on `jupyter-lab`, I fixed the problem using `nbdime mergetool`.

* What does `nbmerge` do if the files in question aren't notebooks.
  * They simply ignore them and print out

  ```txt
  No files need merging
  ```",hey figured far whether practical use without git integration really unlike sense source control information automatically without git integration oblivious source control context would require three run error following base local remote much hassle however certainly practical use even without git integration basically merge conflict would show nice interface similar resolve save result valid format overwrite original notebook whether even without integration setup limited experience last time broke setup running fixed problem question simply ignore print need,issue,negative,positive,neutral,neutral,positive,positive
463513912,"It's not really about markdown or headers, it's more about trying to look at words as data and try to organize them in logical way. and it's like the foundation of the grammar rules that they teach us in school, where to put or, where and and commas, etc. and first they teach you how to group parts of the sentence by similarity, opposition, sequence, etc. then md and headers are just the grammar equivalent. 

See you in the next PR.",really markdown trying look data try organize logical way like foundation grammar teach u school put first teach group sentence similarity opposition sequence grammar equivalent see next,issue,negative,positive,positive,positive,positive,positive
463509903,"Another lesson for me: how to better organize the logic in markdown without creating unnecessary headers.

As always, thank you, @stas00!",another lesson better organize logic markdown without unnecessary always thank,issue,negative,positive,neutral,neutral,positive,positive
463509474,"I understand why you won't care to sign CLA to change one letter - I will just fix it manually. thank you for the suggestion, @velaia.",understand wo care sign change one letter fix manually thank suggestion,issue,positive,neutral,neutral,neutral,neutral,neutral
463508376,"> > This is goodness, but let's not create new headers unnecessarily, see how I changed the last similar PR of yours I believe to this approach:
> 
> Gotcha. I thought that only changing header is not a good practice. If I understand you correctly, below is what I am going to do starting now:
> 
>     * For minor change, add bullet points instead of new headers.

No, that's not it.

I guess I failed to convey what I was trying to say, that wasn't it. I was talking about the logical placement of content and headers, and your suggestion was conflicting with several bits of already existing text. 

Your suggestion was creating a situation where:

1. Choice A foo
2. Choice B foo
3. Unrelated topic bar

see how item 3 isn't fitting there? A more logical way is to:

1. foo
  * choice A
  * choice B
2. bar

--------------

Your suggestion was taking:

1. Choice A foo
   ...
  and also see BAR
   ...
BAR

and turning it into:

   1. Choice A foo
      ...
      and also see BAR
   2. Choice B foo
      ...

BAR

do you see that 'and also see BAR' is missing from item 2, so instead of replicating it, we make bullets:

foo:
   * Choice A
      ...

   * Choice B
     ...

    and also see BAR

BAR

-----------

I hope that was a better demo of the logic I was talking about.

I edited your PR to perform that latter suggestion.",goodness let create new unnecessarily see last similar believe approach thought header good practice understand correctly going starting minor change add bullet instead new guess convey trying say talking logical placement content suggestion conflicting several already text suggestion situation choice foo choice foo unrelated topic bar see item fitting logical way foo choice choice bar suggestion taking choice foo also see bar bar turning choice foo also see bar choice foo bar see also see bar missing item instead make foo choice choice also see bar bar hope better logic talking perform latter suggestion,issue,positive,positive,positive,positive,positive,positive
463505864,"It's most likely because we haven't discussed what both of us mean by ""integration"". Let's not worry about it for now - we will sort it out on the way - it's just docs, so we can improve those gradually as we find a common language.

The rest looks perfect.

And yes, I am sure nbmerge-web is fantastic, how can it not be when nbdiff-web is :) Thank you for your vote of confidence, @odysseus0 ",likely u mean integration let worry sort way improve gradually find common language rest perfect yes sure fantastic thank vote confidence,issue,positive,positive,positive,positive,positive,positive
463504585,"> This is goodness, but let's not create new headers unnecessarily, see how I changed the last similar PR of yours I believe to this approach:

Gotcha. I thought that only changing header is not a good practice. If I understand you correctly, below is what I am going to do starting now:

- For minor change, add bullet points instead of new headers.",goodness let create new unnecessarily see last similar believe approach thought header good practice understand correctly going starting minor change add bullet instead new,issue,positive,positive,neutral,neutral,positive,positive
463504369,"> Actually, looking at this again:
https://github.com/fastai/fastai/blob/master/docs/gen_doc_main.md#testing-site-locally
does it not ask for a password on mac-os?

Mac OS is a bit strange. As long as you didn't run `sudo` and only tries to install the package on your local user, it would not prompt for a password.",actually looking ask password mac o bit strange long run install package local user would prompt password,issue,negative,negative,neutral,neutral,negative,negative
463503749,"Actually, looking at this again:
https://github.com/fastai/fastai/blob/master/docs/gen_doc_main.md#testing-site-locally
does it not ask for a password on mac-os, like in the ubuntu entry?",actually looking ask password like entry,issue,negative,neutral,neutral,neutral,neutral,neutral
463503403,"This is goodness, but let's not create new headers unnecessarily, see how I changed the last similar PR of yours I believe to this approach:
https://github.com/fastai/fastai/blob/master/docs/gen_doc_main.md#testing-site-locally

and in the case of this PR these headers don't fit with the following header, because they are 1 or 2 and 3 - see what I mean? and the comment after the first section applies to both sections, and you left it out in the second - hence merging them is better.
",goodness let create new unnecessarily see last similar believe approach case fit following header see mean comment first section left second hence better,issue,positive,positive,neutral,neutral,positive,positive
463503032,"Hey @stas00, thanks for the detailed reply. Here is what I will include in the instructions based on the feedback:

- Install `nbdime` out of the box with no `git` integration.
- Configure the `nbdime` setting according to your forum post and explains what it does.
- Briefly go over CLI `nbdiff`, then focus on `nbdiff-web`.
- Go over `nbmerge`, specifically the `nbmerge-web`.

Below are what I am going to figure out:

- Whether `nbmerge` is practical to use without git integration.
- Whether `nbmerge`, even without integration, breaks our setup.
- What does `nbmerge` do if the files in question aren't notebooks.

Below is what I can guarantee you:

- `nbmerge-web` is pretty fantastic, especially when used only for the source code like your forum post has shown

Below is what I, unfortunately, (again) failed to understand:

> Finally, remember we can't integrate anything on behalf of users due to git's security, so we can only give them instructions on how to do it and they have to activate them - well we can prep .gitconfig file and they still need to activate it. which will lead to another problem that while `fastai-nbstripout` is in the repo the integration rules will always work, and if the user doesn't have `nbdime` installed things would break badly if it's ""integrated"" - you will see what I mean once you start playing with it.

",hey thanks detailed reply include based feedback install box git integration configure setting according forum post briefly go focus go specifically going figure whether practical use without git integration whether even without integration setup question guarantee pretty fantastic especially used source code like forum post shown unfortunately understand finally remember ca integrate anything behalf due git security give activate well prep file still need activate lead another problem integration always work user would break badly see mean start,issue,positive,negative,neutral,neutral,negative,negative
463499937,"Thank you for asking for clarification.

I think let's start with first no integration in either situation. and just straightforward usage instructions.

For example, once nbdime is installed, you don't need to configure it to use it with git, because you can call it directly, e.g.  call `nbdiff` instead of `git diff`. we already have `git diff` using `fastai-nbstripout` for diff. 

sidenote: I like and dislike CLI `nbdiff` - like it for not dumping inlined images like normal diff does, but disliking that its diff shows cells separately so you can't really tell what's different. But its web nbdiff is fantastic, especially if you configure it as I shared in that forum post.

The same can be done for `nbmerge`, but I have only used it once long time ago, so I don't remember how to use it. Perhaps, it's not practical trying to use it w/o integration, unlike `nbdiff`, and then the user has to integrate it - but only for git merging and not diff. Once you will have that knowledge then we can figure out the answer to your question. But the bottom line it shouldn't interfere with the setup we have - which is only diff and filters, but I'm not sure how merge is impacted by filters, we only have them on the way out (git push), so perhaps it's not a problem.

Also we need to figure out what does nbmerge do if the files in question aren't notebooks, does it delegate them to something else? Most likely it uses the same gitattributes to be only run for `*.ipynb` and doesn't get invoked otherwise? and then it has the CLI and the web interface. Given that web nbdiff is a way more user-friendly, perhaps the same applies for nbmerge. 

Finally, remember we can't integrate anything on behalf of users due to git's security, so we can only give them instructions on how to do it and they have to activate them - well we can prep .gitconfig file and they still need to activate it. which will lead to another problem that while `fastai-nbstripout` is in the repo the integration rules will always work, and if the user doesn't have `nbdime` installed things would break badly if it's ""integrated"" - you will see what I mean once you start playing with it.

That's why my first sentence was - let's just give instructions on what one could do if they wanted to use nbmerge....",thank clarification think let start first integration either situation straightforward usage example need configure use git call directly call instead git already git sidenote like dislike like dumping like normal disliking separately ca really tell different web fantastic especially configure forum post done used long time ago remember use perhaps practical trying use integration unlike user integrate git knowledge figure answer question bottom line interfere setup sure merge impacted way git push perhaps problem also need figure question delegate something else likely run get otherwise web interface given web way perhaps finally remember ca integrate anything behalf due git security give activate well prep file still need activate lead another problem integration always work user would break badly see mean start first sentence let give one could use,issue,positive,positive,neutral,neutral,positive,positive
463497165,"You're correct, it's because they aren't in the fastai registry. 

So far we only have these: https://github.com/fastai/fastai/blob/master/fastai/datasets.py#L17

Would you be kind to add the missing ones via a PR? You will need to add them in the list at the location I listed above and also once again at https://github.com/fastai/fastai/blob/master/fastai/datasets.py#L45 with checksums, here is how you generate the checksums:

```
$ wget https://s3.amazonaws.com/fast-ai-imageclas/oxford-102-flowers.tgz
$ python -c 'import fastai.datasets; print(fastai.datasets._check_file(""oxford-102-flowers.tgz""))'
(345236087, '5666e01c1311b4c67fcf20d2b3850a88')
```

feel free to choose a good short name that fits for these, we may tweak them later.

and a bonus to fix that not so helpful assert by adding an earlier assert to check whether the dataset is registered and to give a user-friendly error if it's not.
```
 assert _check_file(fname) == _checks[url], f""Downloaded file {fname} does not match checksum expected! Remove that file from {data_dir} and try your code again.""
```

Thank you!",correct registry far would kind add missing via need add list location listed also generate python print feel free choose good short name may tweak later bonus fix helpful assert assert check whether registered give error assert file match remove file try code thank,issue,positive,positive,positive,positive,positive,positive
463496502,"Hey @stas00, here is my understanding of what you intend, please let me know if you find any misunderstanding:

- For library and docs developers, only integrate the merge driver of nbdime locally as we customized diff outselves.
- For the course notebook users and class takers, integrate both the merge and diff drivers, as there will be no customized diff.
- For both situations above, write instructions on integration and usage for both the CLI version and the web versions of the tools.",hey understanding intend please let know find misunderstanding library integrate merge driver locally course notebook class integrate merge write integration usage version web,issue,negative,neutral,neutral,neutral,neutral,neutral
463470978,@stas00 No problem. I will try to find a place in `git.md` to put down instructions about `nbdime`. Your forum post looks wonderful and I will certainly migrate it there.,problem try find place put forum post wonderful certainly migrate,issue,positive,positive,positive,positive,positive,positive
463460277,"Gotcha. I definitely should look into the website build process, especially the anchor. Thanks again, @stas00.",definitely look build process especially anchor thanks,issue,positive,positive,neutral,neutral,positive,positive
463415875,and remember to add `test_api_db.json` into MANIFEST.in when the integration is complete. Thanks.,remember add integration complete thanks,issue,negative,positive,positive,positive,positive,positive
463415515,"thank you, great team work @Benudek and @bearpelican!",thank great team work,issue,positive,positive,positive,positive,positive,positive
463414231,"@odysseus0, and as I mentioned earlier, if you're interested, it'd be helpful to add to git.md instructions on how to use nbmerge - in particular for users who edited their lessons and an update is breaking them. (w/o configuring nbdime to act globally). probably both, its normal method and the web one. I have only used it a few times so currently am not an expert.

and probably should migrate this entry as well https://forums.fast.ai/t/jupyter-notebook-enhancements-tips-and-tricks/17064/16 - I find that integration with jupyter notebook to be so helpful, especially with lesson notebooks. The trick is to configure it correctly to show you just the right bits as that section explains.",interested helpful add use particular update breaking act globally probably normal method web one used time currently expert probably migrate entry well find integration notebook helpful especially lesson trick configure correctly show right section,issue,positive,positive,positive,positive,positive,positive
463358409,"> Please sign the [Contributor Licence Agreement](https://www.clahub.com/agreements/fastai/fastai) before we can merge your PR, thanks!

This is done :) 
",please sign contributor agreement merge thanks done,issue,positive,positive,positive,positive,positive,positive
463316678,"OK, I tried to do that, but making a PR branch is a very different situation from https://docs.fast.ai/dev/release.html#quick-release-process.  The latter is a straight line with no conditional branches, the former has many branches, plus it can't be copy-n-pasted since it requires user-specific entries (ssh vs https, username, branchname, etc.). That's why I wrote the helper program - because I was getting lost in my own copy-n-paste notes. So while I'm with you that a condensed list of commands would be very useful, I fail to see how we could provide that in this particular case.

and, yes, please feel free to make any suggestions you feel would improve things. These are always very helpful from a user who is new, because the old timers often know too much to see what's  missing or not obvious. As you can tell some I'm happy to merge verbatim, others with changes, other don't quite fit and so we try to find a better way as this discussion shows. Slowly, slowly, things will get even better. 

Thank you for caring and brainstorming with me on how to improve our documentation, @odysseus0.",tried making branch different situation latter straight line conditional former many plus ca since wrote helper program getting lost condensed list would useful fail see could provide particular case yes please feel free make feel would improve always helpful user new old often know much see missing obvious tell happy merge verbatim quite fit try find better way discussion slowly slowly get even better thank improve documentation,issue,positive,positive,positive,positive,positive,positive
463279513,"In general please don't change header names w/o first checking that some other documentation is using its anchor and there are a few of those in this case. And then there are the fastai forums where those links are kind of stuck forever, so ideally header names shouldn't be changes after they have been set for a while - totally ok to change a lot when it's new. 

And we are a way behind of broken anchors in the documentation, see:
https://dev.azure.com/fastdotai/fastai/_build?definitionId=5

The reason it's experimental is also because we are trying to port it to python:
https://forums.fast.ai/t/port-fastai-make-pr-branch-from-bash-to-python/29853/29
and your proposed change is a bit too soon.
",general please change header first documentation anchor case link kind stuck forever ideally header set totally change lot new way behind broken documentation see reason experimental also trying port python change bit soon,issue,positive,positive,positive,positive,positive,positive
463276974,"Thank you for this suggestion, @odysseus0. We already have a dedicated section for it, so I amended it with the warning: https://github.com/fastai/fastai/commit/ae7210515decda31530078d6ef72bc2da707656b
The many ways it breaks do not matter, there is no point listing them all, since none of them works.

I haven't experimented with jupyterlab, but most likely it generates a different json file, that is still compliant with nbformat, but is different from the one generated by jupyter notebook. Our `fastai-nbstripout` is written to bypass `nbformat` and to manipulate json format directly, which made it
about 10-15 times faster than [nbstripout](https://github.com/kynan/nbstripout) which follows the rules and was too slow for our needs. So chances are that someone needs to look at the format generated by jupyterlab and adjust `fastai-nbstripout` to support that variation, and then most likely it should just work. If you'd like to have a look, `fastai-nbstripout` is a simple script that just traverses and manipulates the json file.",thank suggestion already section warning many way matter point listing since none work experimented likely different file still compliant different one notebook written bypass manipulate format directly made time faster slow need someone need look format adjust support variation likely work like look simple script file,issue,positive,positive,neutral,neutral,positive,positive
463267577,"I hadn't gotten to that point yet, but loading pretrained models for transformer and transformerXL should now work.",gotten point yet loading transformer work,issue,negative,neutral,neutral,neutral,neutral,neutral
463260037,"It was a tricky one, thanks for flagging it!",tricky one thanks flagging,issue,negative,positive,positive,positive,positive,positive
463242473,"This is subtle but the bug is in your code: you need to create your test `ItemList` with the factory method `from_df` (since you're using a `DataFrame`). Do
```
tabList = TabularList.from_df(df, cat_names=cat_names, cont_names=cont_names, procs=procs)
```
and it will work.",subtle bug code need create test factory method since work,issue,negative,negative,negative,negative,negative,negative
463232769,Looking good. There was a problem in v1.0.43 indeed that was fixed yesterday night.,looking good problem indeed fixed yesterday night,issue,negative,positive,positive,positive,positive,positive
463229672,"Looks all good, thanks a lot for your help!",good thanks lot help,issue,positive,positive,positive,positive,positive,positive
463228343,"Thanks! There is a little bit we can refactor, and we should move the docstring in the docs.",thanks little bit move,issue,negative,positive,neutral,neutral,positive,positive
463167143,"I figured out why the second last and my previous commits failed the CI.

It turned out that the current Jupyter Lab is not compatible with the workflow we have setup for the notebooks. GCP uses Jupyter Lab by default for its Deep Learning VM, so I used it when rerunning the notebook remotely. It failed the CI again. So I rerun the notebook again with Jupyter Notebook. That fixed the `nbstripout_config` CI like a charm.",figured second last previous turned current lab compatible setup lab default deep learning used notebook remotely rerun notebook notebook fixed like charm,issue,positive,negative,neutral,neutral,negative,negative
463130307,"I am not sure if it was just my illusion, but when I was using fast.ai 1.0.43.1, somehow the `fit` method does not work anymore. I updated the library and somehow it works again.

To fix the output returned by the malfunctioning `fit` method, I rerun the notebook to update the outputs. ",sure illusion somehow fit method work library somehow work fix output returned fit method rerun notebook update,issue,positive,positive,positive,positive,positive,positive
463086888,"> Perhaps what's is needed is to add a note that if you do get a merge conflict, check that you have your repo setup correctly?

Totally agree. Technically, the section about stripping notebook will do it. We just need to add some notes to point people with merge conflict to that section. If you are okay with it, I will add it.

> I'm not sure how that would work since you can't have explanations w/o instructions they explain. I think that perhaps what you are needing is to keep everything as it is, but also add a section with just one block of bash commands to run.
>
> We have something similar here: https://docs.fast.ai/dev/release.html#quick-release-process
There are just the commands in that section w/o explanations, and then they are repeated again and explained.
>
> Yes?

Exactly. That is what I mean. Make the explanations as detailed as we like, but create a separate section of just-type-these-bash-commands-in-order guide would be perfect. 

> On the other hand `./fastai-make-pr-branch` is all of those commands in one block and you don't even need to know what they are. I suppose we can have both.

Oh, I am totally with you. Don't get me wrong. It looks wonderful now I know what it does. I just somehow missed it. We definitely should keep it!
",perhaps add note get merge conflict check setup correctly totally agree technically section stripping notebook need add point people merge conflict section add sure would work since ca explain think perhaps needing keep everything also add section one block bash run something similar section repeated yes exactly mean make detailed like create separate section guide would perfect hand one block even need know suppose oh totally get wrong wonderful know somehow definitely keep,issue,positive,positive,positive,positive,positive,positive
463069768,"@sgugger Upgrading to 1.0.44.dev0 in Colab doesn't fix it for me. @jtrofe's code works for me, although I need to right click the source link and open it in a new tab for it to work.",dev fix code work although need right click source link open new tab work,issue,negative,positive,positive,positive,positive,positive
463038457,"With RELU, visualization is  even better . 

There is one more change from paper, I am pushing.
mult = F.relu(((acts*grad_chan[...,None,None])).**mean**(0))
to
mult = F.relu(((acts*grad_chan[...,None,None])).**sum**(0))",visualization even better one change paper pushing mult none none mean mult none none sum,issue,negative,positive,neutral,neutral,positive,positive
463036910,"Definitely, I will like to contribute for documentation. As you suggested, I will create separate PR for updating doc notebook.
",definitely like contribute documentation create separate doc notebook,issue,positive,neutral,neutral,neutral,neutral,neutral
462929930,"Please sign the [Contributor Licence Agreement](https://www.clahub.com/agreements/fastai/fastai) before we can merge your PR, thanks!",please sign contributor agreement merge thanks,issue,positive,positive,positive,positive,positive,positive
462927052,"You can't  test beam search like this for several reasons:
- we can't download the pretrained model in the tests because it takes too much time
- so it will never be deterministic, and you can't predict that will come out.

Good catch for the logs, I forgot to adapt the rest when I added this for numerical stability.",ca test beam search like several ca model much time never deterministic ca predict come good catch forgot adapt rest added numerical stability,issue,positive,positive,positive,positive,positive,positive
462923175,"I added a test in there.  I am not totally sure that it will be stable even though I am setting the numpy and torch random seed.  I am concerned that if weights are updated for the model, we will get a different prediction and the tests will all fail.

Open to any ideas about how to deal with this instability.  Should I mock the learner rather than using a pre-defined arch and weights?",added test totally sure stable even though setting torch random seed concerned model get different prediction fail open deal instability mock learner rather arch,issue,negative,negative,neutral,neutral,negative,negative
462885363,"then it can be very specific to this architecture. Any test is a great start, then it can evolve to better itself if possible, and if not it'll just test that very specific arch. Does it make sense?

and just to clarify, I'm in no way getting in the way of requiring it for @sgugger to fix it, but meanwhile creating a test would be a goodness. and I'm sure if there were to be a test it'd save him time.",specific architecture test great start evolve better possible test specific arch make sense clarify way getting way fix meanwhile test would goodness sure test save time,issue,positive,positive,positive,positive,positive,positive
462880223,"Sure @stas00 .
I guess the problem is `covert_weights()` is very specific to AWD LSTM and doesn't handle other architectures. ",sure guess problem specific awd handle,issue,negative,positive,positive,positive,positive,positive
462862807,"But even if you don't use `./fastai-make-pr-branch`, and just followed the the Doc Maintenance instructions, they include `tools/run-after-git-clone`, so really all bases are covered. 

Perhaps what's is needed is to add a note that if you do get a merge conflict, check that you have your repo setup correctly? since that's where your initial trouble started.

> I do have a suggestion. Could we separate the instructions to follow and the explanations of the details involved into separate documents? Maybe it is just me being a noob, but sometimes I always get mixed when reading both together.

I'm not sure how that would work, since you can't have explanations w/o instructions they explain. I think that perhaps what you are needing is to keep everything as it is, but also add a section with just one block of bash commands to run.

We have something similar here: https://docs.fast.ai/dev/release.html#quick-release-process
There are just the commands in that section w/o explanations, and then they are repeated again and explained.

Yes?

On the other hand `./fastai-make-pr-branch` is all of those commands in one block and you don't even need to know what they are. I suppose we can have both.",even use doc maintenance include really base covered perhaps add note get merge conflict check setup correctly since initial trouble suggestion could separate follow involved separate maybe sometimes always get mixed reading together sure would work since ca explain think perhaps needing keep everything also add section one block bash run something similar section repeated yes hand one block even need know suppose,issue,negative,negative,neutral,neutral,negative,negative
462859831,"May I suggest that you folks that work with text start helping out with the test suite a bit, by including a new fastai test whenever you report a bug (or expand an existing test if it fits) - we have a pretty good coverage for vision, but could use more tests for text. That will ensure that future improvements in the fastai text domain code will not break other previously working features. Thank you.",may suggest work text start helping test suite bit new test whenever report bug expand test pretty good coverage vision could use text ensure future text domain code break previously working thank,issue,positive,positive,positive,positive,positive,positive
462815006,"Ah yes, that's because the dataloaders are only passed to half precision at the beginning of training. I changed that.
Note that we can't really put those in tests as `learn.show_results` doesn't really work in console mode, though we could try with a predict I think.",ah yes half precision beginning training note ca really put really work console mode though could try predict think,issue,negative,positive,neutral,neutral,positive,positive
462788229,"In any case, `import cv2` is done in `imports.py`, so the first line (`from .imports import *`) will give it to you.",case import done first line import give,issue,negative,positive,positive,positive,positive,positive
462781076,"Yes, please try and unless it gives horrible results, we'll use the approach of the paper.
Also, if you can then update the doc notebook (vision.learner) with this new argument heatmap and explains it shows the grad CAM with a link to the paper, that would be awesome. (This can be a separate PR.)",yes please try unless horrible use approach paper also update doc notebook new argument grad cam link paper would awesome separate,issue,negative,positive,neutral,neutral,positive,positive
462777615,"I was reading grad-cam paper http://openaccess.thecvf.com/content_ICCV_2017/papers/Selvaraju_Grad-CAM_Visual_Explanations_ICCV_2017_paper.pdf

and they have applied relu to final computations
So do you think 

mult = F.relu(((acts*grad_chan[...,None,None])).mean(0))

is more appropriate?",reading paper applied final think mult none none appropriate,issue,negative,positive,positive,positive,positive,positive
462639513,"Let me clarify a bit. Sorry for the confusion.

1. The problem is on my part because I misunderstood the docs.

2. I definitely agree with you that just tell the users what to run would save all of us some troubles. More words leave more space for misunderstanding.

---

I did not realize that there is such a thing as `./fastai-make-pr-branch`. My bad. I just followed the [Doc Maintenance](https://docs.fast.ai/gen_doc_main.html) instructions, which lead me to [submit your pr](https://docs.fast.ai/dev/git.html#step-7-submit-your-pr) instruction; the latter did not mention running `./fastai-make-pr-branch`. For the previous few attempts where I did remember to run `tools/run-after-git-clone` after clone, there seems no issue. So here I believe the culprit is that I forgot to run `tools/run-after-git-clone` in my remote VM.

I do have a suggestion. Could we separate the instructions to follow and the explanations of the details involved into separate documents? Maybe it is just me being a noob, but sometimes I always get mixed when reading both together.",let clarify bit sorry confusion problem part misunderstood definitely agree tell run would save u leave space misunderstanding realize thing bad doc maintenance lead submit instruction latter mention running previous remember run clone issue believe culprit forgot run remote suggestion could separate follow involved separate maybe sometimes always get mixed reading together,issue,negative,negative,negative,negative,negative,negative
462635311,"I'm not quite following you - if you were to follow the link and run `./fastai-make-pr-branch` to create the PR branch, it runs `tools/run-after-git-clone` in the checked out branch - hence the note.

> I am not sure exactly which part of the comment should go to the forum. Since you are the author, would you mind pasting the part you desire to the forum?

I said that because I wasn't sure what we were trying to fix. But as you're clarifying there is nothing to fix, other than perhaps clarifying the docs.

You can always check whether you're set up by running:

```
$ tools/trust-origin-git-config -t
Executing: git config --list --show-origin
Check: repo's .gitconfig is trusted
```

to test it. Perhaps it's the easiest to just say to run `tools/run-after-git-clone` anyway?",quite following follow link run create branch checked branch hence note sure exactly part comment go forum since author would mind pasting part desire forum said sure trying fix nothing fix perhaps always check whether set running git list check test perhaps easiest say run anyway,issue,positive,positive,positive,positive,positive,positive
462629290,"Hey @stas00, I just realized that I did not run `tools/run-after-git-clone` on my remote VM after cloning the repo. 

The reason why I did not is because of the following passage in the [Doc Maintenance](https://docs.fast.ai/gen_doc_main.html#step-2-setup) article.

![image](https://user-images.githubusercontent.com/8635094/52615037-a8b3b100-2ece-11e9-80ab-8b159fba2f1a.png)

Somehow it gave me the illusion that you have now embedded it as a hook and skipped running `tools/run-after-git-clone`. For some noob like me, I did not manage to catch exactly what exactly are the 'specfic instructions'. So when I tried to merge commmits from the remote VM, naturally the post-merge hook broke. My fault.

---

We definitely should continue our discussion on the forum.

> 
> May be paste this comment there and follow up to it?
> 

I am not sure exactly which part of the comment should go to the forum. Since you are the author, would you mind pasting the part you desire to the forum?",hey run remote reason following passage doc maintenance article image somehow gave illusion hook running like manage catch exactly exactly tried merge remote naturally hook broke fault definitely continue discussion forum may paste comment follow sure exactly part comment go forum since author would mind pasting part desire forum,issue,positive,positive,positive,positive,positive,positive
462605512,Thank you for feedback. I will work on these suggested changes as soon as possible.,thank feedback work soon possible,issue,negative,neutral,neutral,neutral,neutral,neutral
462582595,"@sgugger one of these tests are still failing for me (even with the fix PR: https://github.com/fastai/fastai/commit/3985dc8e4ae86ea800df93193f1d1c46ad8e8c48)

In `tests/test_vision_training.py`
```python

def test_show_results(learn):
    learn.show_results()

def test_show_results_16bit_to_32bit(learn):
    learn.to_fp16()
    learn.to_fp32()
    learn.show_results()

def test_show_results_32bit(learn):
    learn.to_fp16()
    learn.show_results()
```

Maybe we should add these tests as well.

Error:
```
fastai/vision/learner.py:102: in _cl_int_from_learner
    preds = learn.TTA(ds_type=ds_type,with_loss=True) if tta else learn.get_preds(ds_type=ds_type, with_loss=True)
fastai/basic_train.py:278: in get_preds
    activ=_loss_func2activ(self.loss_func), loss_func=lf, n_batch=n_batch, pbar=pbar)
fastai/basic_train.py:40: in get_preds
    zip(*validate(model, dl, cb_handler=cb_handler, pbar=pbar, average=False, n_batch=n_batch))]
fastai/basic_train.py:54: in validate
    val_losses.append(loss_batch(model, xb, yb, loss_func, cb_handler=cb_handler))
fastai/basic_train.py:20: in loss_batch
    out = model(*xb)
../../../anaconda3/envs/fastai_dev/lib/python3.7/site-packages/torch/nn/modules/module.py:489: in __call__
    result = self.forward(*input, **kwargs)
../../../anaconda3/envs/fastai_dev/lib/python3.7/site-packages/torch/nn/modules/container.py:92: in forward
    input = module(input)
../../../anaconda3/envs/fastai_dev/lib/python3.7/site-packages/torch/nn/modules/module.py:489: in __call__
    result = self.forward(*input, **kwargs)
../../../anaconda3/envs/fastai_dev/lib/python3.7/site-packages/torch/nn/modules/container.py:92: in forward
    input = module(input)
../../../anaconda3/envs/fastai_dev/lib/python3.7/site-packages/torch/nn/modules/module.py:489: in __call__
    result = self.forward(*input, **kwargs)

self = Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)
input = tensor([[[[-0.4000, -0.4000, -0.4000,  ..., -0.4000, -0.4000, -0.4000],
          [-0.4000, -0.4000, -0.4000,  ..., -0..., -0.4000, -0.4000],
          [-0.4000, -0.4000, -0.4000,  ..., -0.4000, -0.4000, -0.4000]]]],
       device='cuda:0')

    @weak_script_method
    def forward(self, input):
        return F.conv2d(input, self.weight, self.bias, self.stride,
>                       self.padding, self.dilation, self.groups)
E       RuntimeError: Input type (torch.cuda.FloatTensor) and weight type (torch.cuda.HalfTensor) should be the same

../../../anaconda3/envs/fastai_dev/lib/python3.7/site-packages/torch/nn/modules/conv.py:320: RuntimeError
```

Seems it has to do something with `loss_batch()` being called with weights being in `half()` while the input being `float()`.",one still failing even fix python learn learn learn maybe add well error else zip validate model validate model model result input forward input module input result input forward input module input result input self input tensor forward self input return input input type weight type something half input float,issue,negative,negative,negative,negative,negative,negative
462422155,"And about doc PRs in general:

1. in the future please don't mix doc enhancements with ""functional"" changes, it makes it much more difficult to review PRs. So kindly stick to separating the two into separate PRs. Thank you.

2. please don't delete the vertical new lines, it's much easier to tell sections apart when editing when there is some breath space. it doesn't impact the final rendering in html. Thanks.",doc general future please mix doc functional much difficult review kindly stick separating two separate thank please delete vertical new much easier tell apart breath space impact final rendering thanks,issue,positive,positive,neutral,neutral,positive,positive
462402863,"Thank you for catching the overlap and proposing a better way, @odysseus0. I think new users will benefit from explicit instructions, so I merged the first section into the second and not the other way around, as your PR proposed, but otherwise the outcome is similar to what you suggested. there was also incorrect/oudated info in the sections which is now fixed. https://docs.fast.ai/dev/develop.html#unstripped-notebook-repair

Your style changes can't be easily merged, as I suggested in the other PR, please send such changes separately. Thank you.",thank catching overlap better way think new benefit explicit first section second way around otherwise outcome similar also fixed style ca easily please send separately thank,issue,positive,positive,positive,positive,positive,positive
462394162,"About nbdime:

this approach is problematic since it overrides our custom git diff settings, so now `git diff` will be showing `nbdime diff` and not the diff we need. `nbdime diff` skips `fastai-nbstripout` and doesn't show the user what is about to be committed. This is not good.  A user needs to see exact what git is about to commit.

---------------

In general merge conflict shouldn't happen if you did the setup right and nobody committed an unstripped out notebook. and when things break we have: https://docs.fast.ai/dev/develop.html#unstripped-notebook-repair.

So we can have an nbdime installed but not act globally. Also it will impact other projects a user may have, so perhaps not a great suggestion to install something globally.

So, in order not to confuse users, i reverted just that paragraph and pasted it below so it won't get lost, and let's sort out a better solution that won't get in a way of our setup.

    Since git's original `diff` and `merge` tools do not handle the special Jupyter Notebook formats well, we need to configure git to use notebook's customized `diff` and `merge` tools, [nbdime](https://nbdime.readthedocs.io/en/latest/):

    ```bash
    nbdime config-git --enable --global
    ```

--------------

The merge conflicts will happen if you are changing the content of the notebook and then yes, having a nicely documented way to handle that would be very useful. e.g. course notebooks.

Probably the best place to discuss this would be here:
https://forums.fast.ai/t/git-an-easier-jupyter-notebook-modification-commit-process/20355/134
and then once we have a good solution we will document it.

May be paste this comment there and follow up to it?

Thank you!",approach problematic since custom git git showing need show user good user need see exact git commit general merge conflict happen setup right nobody unstripped notebook break act globally also impact user may perhaps great suggestion install something globally order confuse paragraph pasted wo get lost let sort better solution wo get way setup since git original merge handle special notebook well need configure git use notebook merge bash enable global merge happen content notebook yes nicely way handle would useful course probably best place discus would good solution document may paste comment follow thank,issue,positive,positive,positive,positive,positive,positive
462380828,"Noted. I'll merge and take over then, thanks a lot!",noted merge take thanks lot,issue,negative,positive,positive,positive,positive,positive
462380657,"Thanks for the changes! There is one typo you left, then I dug a little bit more in the code to actually create the heatmap and there are a few things to change there.",thanks one typo left dug little bit code actually create change,issue,positive,positive,neutral,neutral,positive,positive
462347257,@stas00 I'll let you check this one since you were the one to write those.,let check one since one write,issue,negative,neutral,neutral,neutral,neutral,neutral
462267674,It turned out that somehow I forgot to run `tools/run-after-git-clone` in my VM. That is why two commits failed the CI. I simply followed the instruction here in the [docs](https://docs.fast.ai/dev/develop.html#stripping-out-jupyter-notebooks) and it fixed my problem.,turned somehow forgot run two simply instruction fixed problem,issue,negative,positive,neutral,neutral,positive,positive
462190262,"@sgugger Thank you.I agree with your suggestion about refactoring. I will fix it. I want to do it by myself because submitting PR and code refactoring is very good learning experience.

Thanks a lot! ",thank agree suggestion fix want code good learning experience thanks lot,issue,positive,positive,positive,positive,positive,positive
462177361,"Thank you for your feedback! Since you were already working on this, you probably know exactly where to go from here so feel free to continue from where I left of. I'm glad I could be of some help :)",thank feedback since already working probably know exactly go feel free continue left glad could help,issue,positive,positive,positive,positive,positive,positive
462170363,Many thanks for your help and guidance @stas00 !,many thanks help guidance,issue,positive,positive,positive,positive,positive,positive
462170022,I can't merge the 14 conflicts on basic_train.html and basic_train.ipynb. Can you pull them from master again?,ca merge pull master,issue,negative,neutral,neutral,neutral,neutral,neutral
462169757,"I don't know why you had an error, but this works too. Thanks!",know error work thanks,issue,negative,positive,positive,positive,positive,positive
462169695,"It's funny I was working on this specifically just yesterday! This looks great but I have a few things I'd like refactored and I also wanted to start high then diminish instead of rising the loss scale, providing the option to do a fix or dynamic loss scale.
Depending on the time you have to put on this, I can either merge and work from what you've done, or suggest changes in a code review, let me know what you prefer.",funny working specifically yesterday great like also start high diminish instead rising loss scale providing option fix dynamic loss scale depending time put either merge work done suggest code review let know prefer,issue,positive,positive,positive,positive,positive,positive
462168986,"Awesome work, @pouannes - thank you!

If you encounter that weird issue with md2html let's discuss it here: https://forums.fast.ai/t/documentation-improvements/32550

Same for:

> Also I didn't fix when the logs said 'list of duplicate or empty anchors' because I didn't figure out what it was about. 

As you will need to show what you did for me to reproduce it.",awesome work thank encounter weird issue let discus also fix said duplicate empty figure need show reproduce,issue,positive,positive,positive,positive,positive,positive
462166911,"All right I manually fixed it, should be all good now. 

I don't have nbextensions on the computer I used for this PR so no chance of this being caused by that. I think they happened because I executed some cells of that notebook. 

Also I didn't fix when the logs said ['list of duplicate or empty anchors'](https://dev.azure.com/fastdotai/fastai/_build/results?buildId=3222&view=logs&jobId=ab1d7d97-f2fc-5f83-3b83-0c83b70b5c97&taskId=25eeb179-0a91-54dd-3d6e-93ee7162a84d&lineStart=779&lineEnd=779&colStart=1&colEnd=36) because I didn't figure out what it was about.  And I didn't fix all the anchors that need to be fixed yet, this is only a first PR.",right manually fixed good computer used chance think executed notebook also fix said duplicate empty figure fix need fixed yet first,issue,negative,positive,positive,positive,positive,positive
462166498,"This was a tricky one but it's solved now. Thanks a lot for flagging, and for providing such an easy reproducible example!",tricky one thanks lot flagging providing easy reproducible example,issue,positive,positive,positive,positive,positive,positive
462165889,"> So I thought I fixed the mardown -> html bug but in fact I didn't... Any idea how I might fix this before I do it manually ?

I don't know how it came about, did you execute that notebook and the conversions happened?

Do you by chance have some notebook extension that is activated and it did markdown2html?

Perhaps try with another notebook, or save this one and start from scratch and give me instructions on how I can reproduce what you did.",thought fixed bug fact idea might fix manually know came execute notebook chance notebook extension perhaps try another notebook save one start scratch give reproduce,issue,positive,positive,neutral,neutral,positive,positive
462165481,"wrt kernelspec ""conflict"" I posted some ideas [here](https://forums.fast.ai/t/git-an-easier-jupyter-notebook-modification-commit-process/20355/134), ideally it should be transparent to the user.",conflict posted ideally transparent user,issue,negative,positive,positive,positive,positive,positive
462165033,So I thought I fixed the mardown -> html bug but in fact I didn't... Any idea how I might fix this before I do it manually ?,thought fixed bug fact idea might fix manually,issue,negative,positive,neutral,neutral,positive,positive
462163133,"Thanks Stas ! About the docs_src/train.ipynb file, the new cell is indeed intentional (`ClassificationInterpretation` was moved there recently, and the links were updated but there was no corresponding `show_doc`).

 I have no idea why the markdown got switched to html in metrics.ipynb, I didn't do it manually. I'll see what I can do. 

About the custom kernel it was my python  virtual env I needed to run the code and check it was working fine, I need to switch it back I suppose.

I'll fix the things you pointed out, thanks for the feedback !",thanks file new cell indeed intentional recently link corresponding idea markdown got switched manually see custom kernel python virtual run code check working fine need switch back suppose fix pointed thanks feedback,issue,positive,positive,positive,positive,positive,positive
462162735,Thanks a lot! I added a comment are there is a little bit to refactor.,thanks lot added comment little bit,issue,negative,positive,neutral,neutral,positive,positive
462161270,"Click on resolve conflicts, which takes you to:
 https://github.com/fastai/fastai/pull/1610/conflicts
and you can see what conflicts. Most likely you need to sync your branch with master (i.e. merge).

In docs_src/train.ipynb you added a new cell - probably unintentionally? or did you need it so that you could link to it?

Also you asked about the `<b>` replacing `**` earlier, but that was inside the generated html files, the docbuilder does the replacing automatically. In the markdown we must use `**`. why do you have those happen in `.ipynb` files? Did you do it manually? It seems to only affect docs_src/metrics.ipynb

Also I see in the same file you use a custom kernel spec, which conflicts with the default we all use (weird diff below, but it's the last bits of  docs_src/metrics.ipynb in your commit)
```
  ""kernelspec"": {
   ""display_name"": ""Python 3"",
   ""display_name"": ""Python (fastai-dev)"",
   ""language"": ""python"",
   ""language"": ""python"",
   ""name"": ""python3""
   ""name"": ""fastai-dev""
  }
```

Perhaps we need to instrument fastai-nbstripout to set this cell to a hardwired value, rather than pass through, but then it will probably break the notebook on your side if your kernel is named differently.

If I remember correctly we must keep that one in (can't strip out) so that jupyter will know which kernel to use.

The rest looks great!
",click resolve see likely need sync branch master merge added new cell probably unintentionally need could link also inside automatically markdown must use happen manually affect also see file use custom kernel spec default use weird last commit python python language python language python name python name perhaps need instrument set cell value rather pas probably break notebook side kernel differently remember correctly must keep one ca strip know kernel use rest great,issue,positive,positive,neutral,neutral,positive,positive
462158896,"I'm not really sure what the conflict is about, let me know if I need to change something.",really sure conflict let know need change something,issue,negative,positive,positive,positive,positive,positive
462100896,"Hey @sgugger, I just updated the notebook according to your requested changes. Could you please review it again?",hey notebook according could please review,issue,negative,neutral,neutral,neutral,neutral,neutral
462097659,"Loving your notebook! I'm sure @sgugger would love all bug reports to include one!

FYI, in 1.0.43 (or current git) we now have `URLs.MNIST_VAR_SIZE_TINY`, so there is a real dataset with variable size to test with. But I'm loving your creative use of `f'https://picsum.photos/{w}/{h}'`.

I added to your notebook:
```
!pip install git+https://github.com/fastai/fastai
```
so we test the latest code base, and reduced the problem to the `resize_method`.

it works if I use resize_method=ResizeMethod.PAD, it fails with SQUISH and CROP

For some reason the other two fail to resize to the requested dimension, getting the height right, but failing to get the width to match. Perhaps this has something to do with the type of the image? It fails to scale up in the same way. But no, I tested with:
```
path = untar_data(URLs.MNIST_VAR_SIZE_TINY)
item_list = ImageItemList.from_folder(path)
```
with the same issue.

Also this one is odd:
```
UserWarning: It's not possible to collate samples of your dataset together in a batch.
Shapes of the inputs/targets:
[[torch.Size([3, 68, 50]), torch.Size([3, 93, 50])], [(), ()]]
```
what's that odd empty image? (I changed the code to resize to 50x50)

I wrote a new test that reproduces the problem:
https://github.com/fastai/fastai/blob/35f7411c42585acf6c437d8f146c3f435f4eeab6/tests/test_vision_data.py#L79 (test_resize_data_block)

the failure happens with fixed size images too.",loving notebook sure would love bug include one current git real variable size test loving creative use added notebook pip install test latest code base reduced problem work use squish crop reason two fail resize dimension getting height right failing get width match perhaps something type image scale way tested path path issue also one odd possible collate together batch odd empty image code resize wrote new test problem failure fixed size,issue,negative,positive,positive,positive,positive,positive
462093707,"you never need to ask if you can re-open a closed issue, if you feel that you have the same issue you can always re-open it - or opening a new one - it is your call.",never need ask closed issue feel issue always opening new one call,issue,negative,positive,neutral,neutral,positive,positive
462092608,"I have this sort of problem in 1.0.41 / cpu / google colab ([notebook](https://colab.research.google.com/drive/1A9H-6QyS-NlTfZaNjCM2TbifODmvxOTG#scrollTo=_kuCPJS1r_rJ)).

@stas00 do you mind if I'll reopen this issue & look into getting it fixed?

It also leads to occasional hanging when multiple workers are used (~1/5 cases on 2 cpus).

Code and traceback are below just in case

```
transforms = None
batch_size = 2
num_workers = 1

import os
import requests
import contextlib
import tempfile
import shutil
import pdb

@contextlib.contextmanager
def tempdir():
    dirpath = tempfile.mkdtemp()
    try:
      yield dirpath
    finally:
      shutil.rmtree(dirpath)

def create_image(tmp_image, w, h):
  if not os.path.isfile(tmp_image):
    response = requests.get(f'https://picsum.photos/{w}/{h}')
    img = response.raw.read()
    with open(tmp_image, 'wb') as f:
        for chunk in response.iter_content(1024):
            f.write(chunk)
            
with tempdir() as tmp:
  if not os.path.exists(tmp):
    os.makedirs(tmp)
  for i in range(10):
    create_image(f'{tmp}/{i}.jpg', 300-i, 200+i)
  item_list = ImageItemList.from_folder(tmp)
  split_list = item_list.random_split_by_pct(0.5)
  labeled_list = split_list.label_from_folder()
  labeled_list = labeled_list.transform(tfms=None, size=10)
  
  # this spits warns
  data = labeled_list.databunch(bs=batch_size, num_workers=num_workers).normalize(imagenet_stats)

  # this breaks / hangs
  next(iter(data.train_dl))
```

```
RuntimeError: Traceback (most recent call last):
  File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 138, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File ""/usr/local/lib/python3.6/dist-packages/fastai/torch_core.py"", line 110, in data_collate
    return torch.utils.data.dataloader.default_collate(to_data(batch))
  File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 232, in default_collate
    return [default_collate(samples) for samples in transposed]
  File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 232, in <listcomp>
    return [default_collate(samples) for samples in transposed]
  File ""/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py"", line 209, in default_collate
    return torch.stack(batch, 0, out=out)
RuntimeError: invalid argument 0: Sizes of tensors must match except in dimension 0. Got 205 and 208 in dimension 2 at /pytorch/aten/src/TH/generic/THTensorMoreMath.cpp:1333
```",sort problem notebook mind reopen issue look getting fixed also occasional hanging multiple used code case none import o import import import import import try yield finally response open chunk chunk range data next iter recent call last file line file line return batch file line return file line return file line return batch invalid argument size must match except dimension got dimension,issue,negative,positive,neutral,neutral,positive,positive
462047799,Closing since no news in a week. Fell free to reopen but we can't merge your PR if you don't sign the CLA.,since news week fell free reopen ca merge sign,issue,positive,positive,positive,positive,positive,positive
462047377,"In your specific example, I'd leave it interactive: just mentions that the first number is the probability of being a 3 and the second the probability of being a 7, then let's check if it's right or wrong, without using the actual probabilities or the actual class.
In general, any code we don't want to be run should be embedded in a Mardown cell.",specific example leave interactive first number probability second probability let check right wrong without actual actual class general code want run cell,issue,negative,positive,neutral,neutral,positive,positive
462047100,"Closing since no answer in a while, please reopen to follow-up.",since answer please reopen,issue,negative,neutral,neutral,neutral,neutral,neutral
462030210,"@sgugger Hey Sylvain, I just updated the `train` notebook according to your feedback. There is one remaining question and it is asked in the comment on the specific block.

I also started working on adding content to the `basic_train` notebook. There is one specific thing that might need some minor adjustment to the notebook build workflow,  but I find it  a worthwhile feature to have on the documentation.

Currently, I believe that we rebuild the notebooks and the website after each modification from the contributors. So the exact outputs after the rebuild might be different from the ones I see when running the notebook locally. However, there are situations where pointing to the exact output might make the explanation more straightforward. Here is an example:

![image](https://user-images.githubusercontent.com/8635094/52519155-28087100-2c92-11e9-9fbe-83603aa95d6a.png)

The issue right now is that I am not sure what would be the best way to make such output-dependent documentation possible. I could set a random number seed for Python and PyTorch, but that would create an extra cell that is rather irrelevant to the documentation itself; so it probably needs to be stripped when building the notebook.

There is also an unofficial Jupyter Notebook extension called [Python Markdown](https://jupyter-contrib-nbextensions.readthedocs.io/en/latest/nbextensions/python-markdown/readme.html) that essentially creates a new syntax in the markdown cell that will be evaluated. Here is an example:

![image](https://user-images.githubusercontent.com/8635094/52520696-60ff1080-2ca7-11e9-87d6-c522d16c9960.png)

![image](https://user-images.githubusercontent.com/8635094/52520698-64929780-2ca7-11e9-9717-36d525d0a0fa.png)

This would probably be the better solution here, as certain variables and attributes could be system-dependent.",hey train notebook according feedback one question comment specific block also working content notebook one specific thing might need minor adjustment notebook build find feature documentation currently believe rebuild modification exact rebuild might different see running notebook locally however pointing exact output might make explanation straightforward example image issue right sure would best way make documentation possible could set random number seed python would create extra cell rather irrelevant documentation probably need stripped building notebook also unofficial notebook extension python markdown essentially new syntax markdown cell example image image would probably better solution certain could,issue,positive,positive,positive,positive,positive,positive
462016479,I see. Jupytext solves the diff problem on Github but adds another layer of complexities that might make users and future contributors' lives even harder. Totally with you. Thank you for your detailed reply.,see problem another layer might make future even harder totally thank detailed reply,issue,negative,positive,neutral,neutral,positive,positive
462009615,"Okay. Got it. Yes, and I will post future questions to the forum. 

One last thing if you don't mind,

Both 'ImageItemList.from_folder(path)' and 'ImageDataBunch.from_folder(PATH)' work well for creating data objects, train_ds, etc... How do you go between picking which one is more appropriate for the task? I checked their source code and even their options are about the same. 

I am new to this, your insights have been valuable. Thanks again.",got yes post future forum one last thing mind path path work well data go one appropriate task checked source code even new valuable thanks,issue,positive,positive,positive,positive,positive,positive
462006332,"It's because it's expecting an imagenet type of dataset by default which already has a valid folder, see:
https://docs.fast.ai/vision.data.html#ImageDataBunch.from_folder
please continue asking questions at forums.fast.ai where others can benefit from the answers and also provide answers.
Thanks.",type default already valid folder see please continue benefit also provide thanks,issue,positive,positive,positive,positive,positive,positive
462005569,"You are the man. Yes, it worked. Thanks.

One last question, a bit off from this discussion but would like to hear your insight please:

Why is it that running 'ImageDataBunch.from_folder' without valid_pct throws an error. I thought valid_pct is set by default to 0.2? I have to run ImageDataBunch.from_folder(PATH, valid_pct=0.2) instead of ImageDataBunch.from_folder(PATH). Just curious why? on the other hand 'ImageDataBunch.from_name_re' works without it.",man yes worked thanks one last question bit discussion would like hear insight please running without error thought set default run path instead path curious hand work without,issue,positive,positive,neutral,neutral,positive,positive
462004580,and the error msg has now been changed to indicate that it's just in the first batch to avoid confusion.,error indicate first batch avoid confusion,issue,negative,positive,positive,positive,positive,positive
462003334,"Thanks for prompt response. You are def on point, thanks for the clarification. Forgot that the warning is only for one batch, and there are elements on other batches that are also corrupted.

Instead of manually removing the images, there must be a command in Python that can scan the folders prior to feeding them to ImageDataBunch, removing all corrupt images by idx. Is it sanity_check? or you have other suggestions?",thanks prompt response point thanks clarification forgot warning one batch also corrupted instead manually removing must command python scan prior feeding removing corrupt,issue,positive,negative,neutral,neutral,negative,negative
462001914,"That won't work, since you're getting a warning only for one batch. Chances are that you have this problem all over the dataset. 

The only reason specific indices are returned is so that you could check what the problem is.

If you want to extract all the bad indices you can modify sanity_check to loop through all of the data and record bad ones.

But you really should pre-process your input data and throw out anything that's not right before you feed it to the dataloader.",wo work since getting warning one batch problem reason specific index returned could check problem want extract bad index modify loop data record bad really input data throw anything right feed,issue,negative,negative,negative,negative,negative,negative
462001547,"Hi Guys,
what if I simply want to remove the idx elements, produced by the warning, from training dataset. Would you happen to know the command? ",hi simply want remove produced warning training would happen know command,issue,negative,neutral,neutral,neutral,neutral,neutral
461999641,"It seems that the linked SO answer was talking about getting an error. I run the following test in a headless environment and received no error (nothing was printed).
```
from fastai.vision import *
path = untar_data(URLs.MNIST_TINY)
data = ImageDataBunch.from_folder(path)
data.show_batch()
```
So `show_batch` appears not to have a problem in the headless env.

If you want to generate plots rather than display them, perhaps you're expecting from `show_batch` something it wasn't designed to do?

My feeling is that you want another method that specifically creates an image to be saved and then viewed in whatever way you view images. So perhaps something like `render_batch(self, path=""/path/to/plot.png"", ...)`?

or perhaps `show_batch` can have a `save_path` argument and save to file if that's passed instead of displaying it?
```
def show_batch(self, rows:int=5, ds_type:DatasetType=DatasetType.Train, save_path=None, **kwargs)->None:
```",linked answer talking getting error run following test headless environment received error nothing printed import path data path problem headless want generate rather display perhaps something designed feeling want another method specifically image saved whatever way view perhaps something like self perhaps argument save file instead self none,issue,negative,neutral,neutral,neutral,neutral,neutral
461955756,Thanks for the feedback!  Very easy changes to make. ,thanks feedback easy make,issue,positive,positive,positive,positive,positive,positive
461954081,"Thanks! It looks like a useful feature, just requested a few changes.",thanks like useful feature,issue,positive,positive,positive,positive,positive,positive
461952671,"Close/reopen to trigger the tests. Sorry it took us so long to look at this PR, and thanks for the workaround!",trigger sorry took u long look thanks,issue,negative,negative,negative,negative,negative,negative
461951614,"It turns out I can, yes! 

When I first encountered this problem, one of the things I wanted to try was to simply use Jupyter Notebook instead, but I couldn't figure out, even after searching around, how to open the regular notebook window given that navigating to localhost:8080 automatically redirected me to localhost:8080/lab? every time...

Well, it works! Thanks for the workaround! ",turn yes first problem one try simply use notebook instead could figure even searching around open regular notebook window given automatically every time well work thanks,issue,positive,positive,neutral,neutral,positive,positive
461950614,"as this is not being followed up on, I'm closing this. If you have the problem still and have code to help us reproduce it please re-open.",problem still code help u reproduce please,issue,negative,neutral,neutral,neutral,neutral,neutral
461945860,"thanks for the note about .html files.  I will update just the .ipynb

I agree that returning a value from a `.plot()` call seems strange. If it is just printing/plotting, then making it default seems natural.  

I can make it a property of the `Recorder` and then it can be used if you wish.  

I will make those updates now and await any other suggestions.  Happy to make more changes. ",thanks note update agree value call strange making default natural make property recorder used wish make await happy make,issue,positive,positive,positive,positive,positive,positive
461943758,"I like the printing part under the plot, but not sure whether plot() should return any values, since it's a plot function. perhaps let's just start with just printing it out? and making it the default? if we don't return anything do we even need the option?

Also, returning ""random"" values would make things complicated down the road if we have other values we want to return. For getting the min gradient, perhaps, there should be a method that does just that instead? what do you think @sgugger?

p.s. you don't need to edit html files, just ipynb.",like printing part plot sure whether plot return since plot function perhaps let start printing making default return anything even need option also random would make complicated road want return getting min gradient perhaps method instead think need edit,issue,positive,negative,negative,negative,negative,negative
461940818,"@gurvindersingh, a lot has changed in 3 months - is this still a problem with the latest fastai and pytorch versions? ",lot still problem latest,issue,negative,positive,positive,positive,positive,positive
461940566,Hi! Running the widget in Jupyter Lab is not currently supported. Can you run it on Jupyter Notebook (localhost:8080/tree)?,hi running lab currently run notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
461908267,"Oops, I misunderstood what you were trying to achieve. We don't want to go with the error being silent here, since it'll make things fail later on. We want the user to clearly know the pattern wasn't found in res so they can adjust their regex (or use another labelling method, or get rid of the samples that don't work).
I reverted.",misunderstood trying achieve want go error silent since make fail later want user clearly know pattern found adjust use another method get rid work,issue,negative,negative,neutral,neutral,negative,negative
461891846,I can't reproduce that bug. Did you try on the latest version of fastai?,ca reproduce bug try latest version,issue,negative,positive,positive,positive,positive,positive
461869331,Good point. Maybe we can use the same assert as [here](https://github.com/fastai/fastai/blob/8a54d18ab21f9f60473a39927dd9c3b3397e8e95/fastai/data_block.py#L268) to make the behavior consistent?,good point maybe use assert make behavior consistent,issue,negative,positive,positive,positive,positive,positive
461867654,I believe this command is doing the same as displaying the output as markdown. What fails on colab is that it doesn't let the notebook open a new window like jupyter notebook. I think I've fixed it with this try and except block (on master) so after the next release it should work properly.,believe command output markdown let notebook open new window like notebook think fixed try except block master next release work properly,issue,negative,positive,neutral,neutral,positive,positive
461867510,"> I see. So currently the best way to go is to pull the PR locally and use nbdiff inside the Jupyter Notebook, at least until Github installs nbdime and uses it by default.

Probably users need to start asking github support to include it - otherwise it won't happen, why would MS bother to provide an enhancement for just a few millions of jupyter notebooks hosted on github. It has a bigger fish to fry.

> @stas00 Do you find the Jupytext thing to be a potentially useful interim solution? Love to hear your words of wisdom on that matter.

I'm yet to try Jupytext, but from the description of it, it solves some problems but introduces other problems, e.g. editing the same content from 2 different places (jupyter and editor) is surely not going to go smoothly. And then it adds even more complexity for users to figure out which files to edit and how to check they did it right. And if you want to have the final rendering of the notebook with outputs in github (.e.g as we have them for the lesson notebooks), then you have to source control the jupytext source and the synced .ipynb, and telling users not to edit .ipynb (kind of what we already with autogenerated .html). All that is doable, but overall IMHO it doesn't make things easier.

I think the best solution would be for github to make an effort to better support jupyter notebooks by providing custom tools for diffing, commenting, etc. But it probably will take a lot of support requests by users.",see currently best way go pull locally use inside notebook least default probably need start support include otherwise wo happen would bother provide enhancement million bigger fish fry find thing potentially useful interim solution love hear wisdom matter yet try description content different editor surely going go smoothly even complexity figure edit check right want final rendering notebook lesson source control source telling edit kind already doable overall make easier think best solution would make effort better support providing custom probably take lot support,issue,positive,positive,positive,positive,positive,positive
461853125,"I see. So currently the best way to go is to pull the PR locally and use nbdiff inside the Jupyter Notebook, at least until Github installs nbdime and uses it by default.

@stas00 Do you find the Jupytext thing to be a potentially useful interim solution? Love to hear your words of wisdom on that matter.",see currently best way go pull locally use inside notebook least default find thing potentially useful interim solution love hear wisdom matter,issue,positive,positive,positive,positive,positive,positive
461851531,"> @sgugger In terms of the current difficulty reviewing Jupyter Notebook on Github, this Github app called [ReviewNB](https://www.reviewnb.com) might help.

This app is not so useful as it could be, since you can't do it direclty from github, at least last time I tried it. nbdiff does that beautifully already. https://forums.fast.ai/t/jupyter-notebook-enhancements-tips-and-tricks/17064/16, either way you have to pull the PR locally to use it. github should really install nbdime and have it used internally.",current difficulty notebook might help useful could since ca least last time tried beautifully already either way pull locally use really install used internally,issue,positive,positive,positive,positive,positive,positive
461847652,[Jupytext](https://github.com/mwouts/jupytext) is another library that might be potentially useful in resolving the same problem.,another library might potentially useful problem,issue,negative,positive,positive,positive,positive,positive
461846718,"@sgugger In terms of the current difficulty reviewing Jupyter Notebook on Github, this Github app called [ReviewNB](https://www.reviewnb.com) might help.",current difficulty notebook might help,issue,negative,neutral,neutral,neutral,neutral,neutral
461840239,"Certainly, I will incorporate your comments in another commit. Many thanks for the detailed comments; these really help me understand the library better.",certainly incorporate another commit many thanks detailed really help understand library better,issue,positive,positive,positive,positive,positive,positive
461839407,"Thanks. It's not ideal with the jupyter notebook format, but this needs a few changes before merging if you can.",thanks ideal notebook format need,issue,positive,positive,positive,positive,positive,positive
461821790,"Yes, there was a breaking change mentioned on the [forum](https://forums.fast.ai/t/developer-chat/22363/750?u=sgugger), necessary to support the transformers architectures on top of the AWD LSTM. 
You can load your learner with `load_learner` by using a commit prior to [this one](https://github.com/fastai/fastai/commit/0a4aa56d247a079062a6eb5ec894d59a1bc349e6) or by using 1.0.42, then save your model with `learn.save()`. You will be able to load it again with the function I provide in the post in the new version.",yes breaking change forum necessary support top awd load learner commit prior one save model able load function provide post new version,issue,positive,positive,positive,positive,positive,positive
461727029,"Your patch looks perfect, and catches the exception where i got it as well. Issue fully resolved, thanks :)",patch perfect exception got well issue fully resolved thanks,issue,positive,positive,positive,positive,positive,positive
461620060,The changelog is [here](https://github.com/fastai/fastai/blob/master/CHANGES.md). The next version will be released sometime next week.,next version sometime next week,issue,negative,neutral,neutral,neutral,neutral,neutral
461590936,"I was testing with the most recent version from conda.  Updated fastai with conda this morning and the problem was still there.

But then setuped fastai from master with the dev instructions and it worked.  So I guess the problem will be resolved in the next release.

Where can we follow changelogs of fastai and when changes are released to conda?

Thanks,",testing recent version morning problem still master dev worked guess problem resolved next release follow thanks,issue,negative,positive,neutral,neutral,positive,positive
461461124,"So a `LabelList` will now uses its internal `__getitem__` to sample items for its representation, which means transforms will be applied. In your example, `data` will give the right sizes.
If one goes inside to grab the individual `ItemList`, `data.train_ds.x` for instance, the transforms won't be applied and we will see the original sizes.",internal sample representation applied example data give right size one go inside grab individual instance wo applied see original size,issue,negative,positive,positive,positive,positive,positive
461455765,I can't reproduce your bug. Can you try if you have it on master? It may have already been solved.,ca reproduce bug try master may already,issue,negative,neutral,neutral,neutral,neutral,neutral
461453699,"In this case, it's because you create a categorical column with `FillMissing` (it adds a column with True/False for when you had a NaN), this categorical column is then not properly treated because `Categorify` isn't executed.
If you don't add that column (using `partial(FillMissing, add_col=False)`) it works fine.",case create categorical column column nan categorical column properly executed add column partial work fine,issue,negative,positive,positive,positive,positive,positive
461451433,"Providing clear error messages is definitely something we want, hopefully this last commit should make it easier in your case (not entirely sure since you didn't provide a minimal example of the problem).",providing clear error definitely something want hopefully last commit make easier case entirely sure since provide minimal example problem,issue,positive,positive,neutral,neutral,positive,positive
461444060,"Mmm the type annotations are the one that are wrong: all those objects are supposed to be list of nn.Modules, not module lists, so the previous implementation was the right one, it's the two type annotations that need to be changed.
Tests pass, but sadly they're not very extensive yet and this specific part isn't really tested yet.",type one wrong supposed list module previous implementation right one two type need pas sadly extensive yet specific part really tested yet,issue,negative,negative,neutral,neutral,negative,negative
461391790,"I updated to current master.
I noticed that 'education-num' has NaN values. 

So I removed also this column and now the code is working.
I'm not sure if updating to current master is necessary.

BTW, I tried also to use FillMissing for this column (instead of deleting it), and it causes an error.
I'm opening a new issue.

Thanks a lot for your help.",current master nan removed also column code working sure current master necessary tried also use column instead error opening new issue thanks lot help,issue,positive,positive,positive,positive,positive,positive
461377799,"You can probably tell I spent a bit of time debugging :)

You are welcome to close the issue, if providing hypotheses for why the user is experiencing an error is not a standard that you strive in the exception handling across the fastai library.",probably tell spent bit time welcome close issue providing hypothesis user error standard strive exception handling across library,issue,negative,positive,positive,positive,positive,positive
461238427,"Thanks for the PR! It's very cool, but not a great fit with the functionality in the library, so it would be best if you put it in a separate repo.

To post on the forum, you simply need to read a few threads and wait a few mins after you first sign up.",thanks cool great fit functionality library would best put separate post forum simply need read wait first sign,issue,positive,positive,positive,positive,positive,positive
461227188,"> In the meantime, you can use a dev install.

The simplest way to accomplish that is with:
```
pip install git+https://github.com/fastai/fastai
```",use dev install way accomplish pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
461225026,"I think sometime next week. There has been a lot of changes with my digging-out of kwargs everywhere, so we want to make sure it's stable and nothing is broken before the next release.
In the meantime, you can use a dev install.",think sometime next week lot everywhere want make sure stable nothing broken next release use dev install,issue,positive,positive,neutral,neutral,positive,positive
461224503,Thanks @sgugger. Any estimates on the next release date?,thanks next release date,issue,negative,positive,neutral,neutral,positive,positive
461224277,This is different since it's not a label delimiter but a real character separator here.,different since label delimiter real character separator,issue,negative,positive,neutral,neutral,positive,positive
461224078,"It's only fixed in master, there hasn't been a new release yet.",fixed master new release yet,issue,negative,positive,positive,positive,positive,positive
461205745,"@sgugger 
Sorry, not `DeviceDataLoader.__init__` but `DeviceDataLoader.create`.
I use this class for those model that I create.

Dictionary is convenient and expository when handling multiple types of data, suitable for graph nn, multitask learning, and so on.",sorry use class model create dictionary convenient expository handling multiple data suitable graph learning,issue,negative,positive,neutral,neutral,positive,positive
461203401,"given (1.0.41 Changes):

- `sep` (in ImageDataBunch factory methods) is now called `label_delim`

should this arg name be consistent? ",given factory name consistent,issue,negative,positive,positive,positive,positive,positive
461199145,"I get this error with a simple example (and added this code to ""fix"" that problem.  Maybe I am going about it wrong or have some strange param setup?  When I stepped into that part of the code, it looks like one has a memory, but the other does not when `mem_len = 0` . What test should I be looking at?

```
from fastai import *
from fastai.text import *
path = untar_data(URLs.IMDB_SAMPLE)
data = TextLMDataBunch.from_csv(path, 'texts.csv')
vocab_size = len(data.vocab.itos)
transformer_model = get_transformerXL_lm(vocab_size,ctx_len=1,mem_len=0)
learn = LanguageLearner(data,transformer_model)
lr_find(learn)
```

Error:

```
~/fast_ai/fastai-fork/fastai/text/models/transformer.py in _apply_attention(self, x, r, u, v, mask, mem)
    112         AC = torch.matmul(wq+u,wk)
    113         BD = _line_shift(torch.matmul(wq+v, wkr))
--> 114         if self.scale: attn_score = (AC + BD).mul_(1/(self.d_head ** 0.5))
    115         if mask is not None:
    116             attn_score = attn_score.float().masked_fill(mask, -float('inf')).type_as(attn_score)

RuntimeError: The size of tensor a (70) must match the size of tensor b (140) at non-singleton dimension 3
```

",get error simple example added code fix problem maybe going wrong strange param setup stepped part code like one memory test looking import import path data path learn data learn error self mask mem mask none mask size tensor must match size tensor dimension,issue,negative,negative,negative,negative,negative,negative
461177500,"Yeah but if mem_len is 0 there is no hidden state, so the current tests should be enough.",yeah hidden state current enough,issue,negative,negative,neutral,neutral,negative,negative
461174530,"My understanding was `mem_len = 0` means that there is no memory, so you don't have anything to update to the hidden state.  What am I missing there?
When I ran with mem_len = 0 the first batch will run fine, but the second batch will have a ""memory"" that is not `None` and now you collide with the shape of the input and you throw an error.  Maybe I was calling it wrong? 
",understanding memory anything update hidden state missing ran first batch run fine second batch memory none collide shape input throw error maybe calling wrong,issue,negative,negative,neutral,neutral,negative,negative
461162950,I see the use of your first change (pos.float()) but what about the other two? I don't see how you could have a hidden size if mem_len is set to 0.,see use first change two see could hidden size set,issue,negative,positive,neutral,neutral,positive,positive
461160591,I think this has been fixed in master (when solving a similar issue not so long ago). Can you check with a developer install? I can't reproduce your bug on my side.,think fixed master similar issue long ago check developer install ca reproduce bug side,issue,negative,positive,neutral,neutral,positive,positive
461152031,"@Benudek, perhaps as you receive feedback on your proposed tests you could start compiling guidelines for test writing? How does that sound? If you are interested in doing that perhaps starting a wiki post at https://forums.fast.ai/t/improving-expanding-functional-tests/32929/ would be a good start, and then later we can add it to https://docs.fast.ai/dev/test.html

So you have feedback from this PR and the previous one: https://github.com/fastai/fastai/pull/1524 and https://github.com/fastai/fastai/commit/2517aa80bfc0b243e7020d464aa1537bc4e3257c#comments",perhaps receive feedback could start test writing sound interested perhaps starting post would good start later add feedback previous one,issue,positive,positive,positive,positive,positive,positive
461151627,"also test function names are self-documenting and require no declaration unless it's not so, so let's not have unnecessary noise. https://github.com/fastai/fastai/commit/4097b1474810f11c8645108d83c82e7dd7d03e0f",also test function require declaration unless let unnecessary noise,issue,negative,negative,negative,negative,negative,negative
461150296,"a consistent syntax for assert() needs to be enforced - this PR uses assert(...), whereas we don't use parentheses anywhere else in the tests.https://github.com/fastai/fastai/commit/7deb6c07b73a09b5f91103c82b31f6b20370d6d4",consistent syntax assert need enforced assert whereas use parenthesis anywhere else,issue,negative,positive,positive,positive,positive,positive
461147384,This is more in the data that the problem lies. We can't add this line as there are situations where the target must be float.,data problem ca add line target must float,issue,negative,neutral,neutral,neutral,neutral,neutral
461103309,The test suite is non-deterministic and occasionally fails on one of the tests. I have re-run the failing CI instance and all is good.,test suite occasionally one failing instance good,issue,negative,positive,positive,positive,positive,positive
461063815,I don't know why this Linux_PyPI Python37 test is failing when others are passing.  Is that something I can fix on my side?  I can't find more details about that failure.,know python test failing passing something fix side ca find failure,issue,negative,negative,negative,negative,negative,negative
461047152,"A `DeviceDataLoader` doesn't take a DataSet but a `DataLoader`, so I don't think there is a bug there. I'm not sure the fastai library handles inputs for models that are dictionaries. What is your use case?",take think bug sure library use case,issue,negative,positive,positive,positive,positive,positive
461045850,"It was a typo indeed, thanks for fixing!",typo indeed thanks fixing,issue,negative,positive,positive,positive,positive,positive
461045478,"Ah yes, that's because it defaults to the classes of the input `ItemList` when there is one. Will fix.",ah yes class input one fix,issue,negative,neutral,neutral,neutral,neutral,neutral
461002781,"Additionally, the behaviour changes when one does not provide categorical parameters. In this case, `.classes` works as expected.",additionally behaviour one provide categorical case work,issue,negative,neutral,neutral,neutral,neutral,neutral
460847632,"So we need to put something else to add this comma. I haven't looked at it in depth, but please make sure that the tests in `test_callbacks_hooks.py` are passing.

In this PR the line `res += f""{layer:<20} {size:<20} {params:<10,} {trainable:<10}\n` throws the error
` ValueError: Cannot specify ',' with 's'.`

It's the good idea though, so if you can fix it I'd definitely merge it!",need put something else add comma depth please make sure passing line layer size trainable error specify good idea though fix definitely merge,issue,positive,positive,positive,positive,positive,positive
460541445,"1. you're running an old fastai version
2. you're not using a dedicated card, so your memory goes wasted by other processes - switch those to igpu if you have 2 gpus https://askubuntu.com/questions/1061551/how-to-configure-igpu-for-xserver-and-nvidia-gpu-for-cuda-work
3. or consider using cloud gpus (free for lessons), the course site explains how - you will need 8GB RAM available for most lessons. 
4. look up CUDA out of memory on forums.fast.ai - you basically need to reduce bs and sometimes other parameters when you have little ram. 
 
as far as telling, you will know over time which is which. fastai is a library running on top of pytorch, so the line is thin.

Use forums and you will find lots of threads discussing this.",running old version card memory go wasted switch consider cloud free course site need ram available look memory basically need reduce sometimes little ram far telling know time library running top line thin use find lot,issue,negative,positive,neutral,neutral,positive,positive
460534257,"Thanks @stas00 I got it pass there (probably stupid question but it is possible to know a pytorch error from a fastai one???). If I run the whole notebook I get

```
RuntimeError: CUDA out of memory. Tried to allocate 4.32 GiB (GPU 0; 7.76 GiB total capacity; 1.71 GiB already allocated; 4.32 GiB free; 48.06 MiB cached)
```

on 

```
learn.lr_find()
learn.recorder.plot()
```

seems that running the lines manually works on second time of run the cell I dont get the error.... (dont know why on first not, anyway seems somewhat correct)


```
LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-30-c7a9c29f9dd1> in <module>
----> 1 learn.lr_find()
      2 learn.recorder.plot()

~/anaconda3/lib/python3.7/site-packages/fastai/train.py in lr_find(learn, start_lr, end_lr, num_it, stop_div, **kwargs)
     29     cb = LRFinder(learn, start_lr, end_lr, num_it, stop_div)
     30     a = int(np.ceil(num_it/len(learn.data.train_dl)))
---> 31     learn.fit(a, start_lr, callbacks=[cb], **kwargs)
     32 
     33 def to_fp16(learn:Learner, loss_scale:float=512., flat_master:bool=False)->Learner:

~/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
    164         callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)
    165         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,
--> 166             callbacks=self.callbacks+callbacks)
    167 
    168     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

~/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)
     92     except Exception as e:
     93         exception = e
---> 94         raise e
     95     finally: cb_handler.on_train_end(exception)
     96 

~/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)
     82             for xb,yb in progress_bar(data.train_dl, parent=pbar):
     83                 xb, yb = cb_handler.on_batch_begin(xb, yb)
---> 84                 loss = loss_batch(model, xb, yb, loss_func, opt, cb_handler)
     85                 if cb_handler.on_batch_end(loss): break
     86 

~/anaconda3/lib/python3.7/site-packages/fastai/basic_train.py in loss_batch(model, xb, yb, loss_func, opt, cb_handler)
     16     if not is_listy(xb): xb = [xb]
     17     if not is_listy(yb): yb = [yb]
---> 18     out = model(*xb)
     19     out = cb_handler.on_loss_begin(out)
     20 

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py in forward(self, input)
     90     def forward(self, input):
     91         for module in self._modules.values():
---> 92             input = module(input)
     93         return input
     94 

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py in forward(self, input)
     90     def forward(self, input):
     91         for module in self._modules.values():
---> 92             input = module(input)
     93         return input
     94 

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/container.py in forward(self, input)
     90     def forward(self, input):
     91         for module in self._modules.values():
---> 92             input = module(input)
     93         return input
     94 

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

~/anaconda3/lib/python3.7/site-packages/torchvision/models/resnet.py in forward(self, x)
     74         residual = x
     75 
---> 76         out = self.conv1(x)
     77         out = self.bn1(out)
     78         out = self.relu(out)

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    487             result = self._slow_forward(*input, **kwargs)
    488         else:
--> 489             result = self.forward(*input, **kwargs)
    490         for hook in self._forward_hooks.values():
    491             hook_result = hook(self, input, result)

~/anaconda3/lib/python3.7/site-packages/torch/nn/modules/conv.py in forward(self, input)
    318     def forward(self, input):
    319         return F.conv2d(input, self.weight, self.bias, self.stride,
--> 320                         self.padding, self.dilation, self.groups)
    321 
    322 

RuntimeError: CUDA out of memory. Tried to allocate 4.32 GiB (GPU 0; 7.76 GiB total capacity; 1.71 GiB already allocated; 4.32 GiB free; 48.06 MiB cached)
```",thanks got pas probably stupid question possible know error one run whole notebook get memory tried allocate gib gib total capacity gib already gib free mib running manually work second time run cell dont get error dont know first anyway somewhat correct finder complete type see graph recent call last module learn learn learn learner learner fit self self fit self none fit model opt data metric except exception exception raise finally exception fit model opt data metric loss model opt loss break model opt model self input result input else result input hook hook self input result forward self input forward self input module input module input return input self input result input else result input hook hook self input result forward self input forward self input module input module input return input self input result input else result input hook hook self input result forward self input forward self input module input module input return input self input result input else result input hook hook self input result forward self residual self input result input else result input hook hook self input result forward self input forward self input return input memory tried allocate gib gib total capacity gib already gib free mib,issue,positive,positive,positive,positive,positive,positive
460523182,"It's a pytorch/cuda issue, and not fastai's. I'd say try installing cuda10 pytorch version, since you are using a cutting edge NVIDIA driver:
```
conda install -c pytorch pytorch cuda100
```
It seems to work for people: https://discuss.pytorch.org/t/cuda-runtime-error-11/30080/8.

If the problem persists see if you can run a basic straight pytorch example, e.g. https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html (there is a nb at the bottom of the page), and if you can't - sort it out with the pytorch issue.

If you can and indeed there is a problem with fastai please reopen this ticket.

And I recommend googling any such errors first before opening an Issue. Often, you will find that it was both reported and solved.",issue say try version since cutting edge driver install work people problem see run basic straight example bottom page ca sort issue indeed problem please reopen ticket recommend first opening issue often find,issue,negative,negative,neutral,neutral,negative,negative
460479182,"Good point, it's not convenient if it's hidden in `train.py` because that's what people are actually using... ",good point convenient hidden people actually,issue,negative,positive,positive,positive,positive,positive
460407404,"Ok, just made the methods private before the monkey-patch. Thanks a lot!",made private thanks lot,issue,negative,positive,neutral,neutral,positive,positive
460351702,"Looking forward to the new release! I'l update Render's starter repo as soon as it's out.

On Mon, Feb 04, 2019 at 7:27 AM, Legrand Thomas < notifications@github.com > wrote:

> 
> 
> 
> Nice catch!
> It works when I save after removing.cuda() for the metrics.
> Thank you for your help.
> 
> 
> 
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub (
> https://github.com/fastai/fastai/pull/1502#issuecomment-460290212 ) , or mute
> the thread (
> https://github.com/notifications/unsubscribe-auth/AADqATDZUNinHdTrdKXOwFmhGpuwVaHhks5vKFFugaJpZM4aNsb_
> ).
> 
> 
>",looking forward new release update render starter soon mon wrote nice catch work save metric thank help thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
460290212,"Nice catch! 
It works when I save after removing `.cuda()` for the metrics.
Thank you for your help.",nice catch work save removing metric thank help,issue,positive,positive,positive,positive,positive,positive
460270537,"Ok, so it's the weights of your loss function that are the culprit. I'll try to find a more general fix that will go through everything in the state and save it on the CPU.

In the meantime, pushed a fix that will load the Learner on cpu if that's the default device. Since I had reports that the map_location wasn't working before (though I couldn't reproduce) it may not work in 100% of the cases.",loss function culprit try find general fix go everything state save fix load learner default device since working though could reproduce may work,issue,negative,positive,neutral,neutral,positive,positive
460090786,"There is problem with the solution above. The problem is that when you run create_cnn, it downloads the model to train folder and in re-run of the code, it can categorize models as separate category",problem solution problem run model train folder code categorize separate category,issue,negative,neutral,neutral,neutral,neutral,neutral
460023981,"The problem has been solved.
Thank you for your kind reply!",problem thank kind reply,issue,negative,positive,positive,positive,positive,positive
460001917,"I'm afraid there is nothing we can do for this. The serialization uses pytorch, which uses pickle behind the scenes, which doesn't compile the source code of the functions used, just serialize their names. 
It's the same if you have custom layers in your model for instance, you'll need to redefine them at inference time.",afraid nothing serialization pickle behind compile source code used serialize custom model instance need redefine inference time,issue,negative,negative,negative,negative,negative,negative
460001461,"You didn't specify a vocab when creating your second `DataBunch` so it didn't use the same one as you were using before. This is probably why you get different results (also I don't know why you say it doesn't evaluate on another dataset, it is clearly doing so since it's not giving the same results).
You should add `vocab = old_data.vocab`.",specify second use one probably get different also know say evaluate another clearly since giving add,issue,positive,positive,neutral,neutral,positive,positive
460000897,"I'll implement the dynamic loss scaling sometime soon, it's in my TODO. In the meantime, a warning would be fine, yes.",implement dynamic loss scaling sometime soon warning would fine yes,issue,negative,positive,positive,positive,positive,positive
460000125,Setting it to 1 (or using amp) fixes the issue. Maybe there should be warning printed when calculated loss is nan in fp16 mode?,setting issue maybe warning printed calculated loss nan mode,issue,negative,neutral,neutral,neutral,neutral,neutral
459977099,"Oh good point! Although we'd like to stop hiding things in kwargs to make it easier for users to follow what arguments a function takes (in the docs + with tab completion), but that will be for later.",oh good point although like stop make easier follow function tab completion later,issue,positive,positive,positive,positive,positive,positive
459976461,"Hi @sgugger, currently these arguments are passed by the ""kwargs"" in `fit_one_cycle` of `train.py` so it's working as I tested, I was thinking about making minimal changes... Let me know whether I'd like to add that, thanks for checking! ",hi currently working tested thinking making minimal let know whether like add thanks,issue,positive,positive,neutral,neutral,positive,positive
459975201,"Looks great, thanks a lot! Can you also change the function in `train.py` to use those new arguments you added?",great thanks lot also change function use new added,issue,positive,positive,positive,positive,positive,positive
459968156,"The training dataloader is always loaded with `drop_last=True` to avoid having a last batch with few elements (a size 1 will throw an error if you have BathNorm layers and in general a too small size will be unstable for training). That may be the reason you see one less than the right reason.
Otherwise, please provide us a minimal code that reproduce the bug.",training always loaded avoid last batch size throw error general small size unstable training may reason see one le right reason otherwise please provide u minimal code reproduce bug,issue,negative,negative,neutral,neutral,negative,negative
459963383,"I have also come across this error, with 1.0.43. The only solution I found so far was to revert to a known good version. 1.0.9. The following code works as expected in 1.0.9 but fails with a MemoryError in 1.0.43:

```
from fastai.text import *
from pathlib import Path
import spacy
! python -m spacy download en
spacy.load('en')

DATA_PATH=Path('text_class/data/')
DATA_PATH.mkdir(exist_ok=True)

! curl -O http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz
! tar xzfv aclImdb_v1.tar.gz -C {DATA_PATH}

# Language model data
data_lm = TextLMDataBunch.from_folder(DATA_PATH/'aclImdb')
```",also come across error solution found far revert known good version following code work import import path import spacy python spacy en curl tar language model data,issue,negative,positive,positive,positive,positive,positive
459942562,"I was thinking of cutting it by a much larger factor, back to 1 or so. You can move back up if it fixes the problem.

Apex/amp is a NVIDIA plugin for pytorch that has dynamic loss scaling, it might be worth a try and seeing if it works instead of fastai's to_fp16. You can then print what factor it selected. ",thinking cutting much factor back move back problem dynamic loss scaling might worth try seeing work instead print factor selected,issue,negative,negative,neutral,neutral,negative,negative
459918581,"I tried halving and doubling the `loss_scale`, but still got nan",tried doubling still got nan,issue,negative,neutral,neutral,neutral,neutral,neutral
459906501,"Here is a reproducible notebook that shows the problem automatically:
https://github.com/fastai/fastai_docs/blob/master/dev_nb/autoreload/fastai-fail.ipynb

and then I managed to reduce it to any module - i.e. not fastai-related:
https://github.com/fastai/fastai_docs/blob/master/dev_nb/autoreload/any-module-fail.ipynb",reproducible notebook problem automatically reduce module,issue,negative,neutral,neutral,neutral,neutral,neutral
459891423,"Yes it does inference, which i also the point of the test set (again unlabeled data). fit can't call the `test_dl` since it is unlabeled, so loss/metrics on it would have no meaning.",yes inference also point test set unlabeled data fit ca call since unlabeled would meaning,issue,positive,positive,positive,positive,positive,positive
459890189,"`get_preds` does inference. It is a shame that `.fit` does not call the `test_dl`, if exist, after all the epochs as I would expecting. What about implementing this feature, what do you think?",inference shame call exist would feature think,issue,negative,neutral,neutral,neutral,neutral,neutral
459823862,"In both those situations, the predictions are ordered like the labels. It's only in text that the predictions are in a different order because we sort them by lengths before batching them.",ordered like text different order sort,issue,negative,neutral,neutral,neutral,neutral,neutral
459823117,"I no longer can find that code where I was having this issue, and perhaps @xnutsive solution fixed it since my report predates his post, so I will close it for now and if others encounter the same issue please reopen it ideally with a full example to reproduce, which I failed to provide in first place.",longer find code issue perhaps solution fixed since report post close encounter issue please reopen ideally full example reproduce provide first place,issue,positive,positive,positive,positive,positive,positive
459783941,"You'll have a déjà-vu, it's based on your DeepFrench notebook ;)

```
import fastai
import torch
print(fastai.__version__) # 1.0.43.dev0
print(torch.__version__) # 1.0.0

from fastai import *
from fastai.text import *
import pandas as pd

lang = ""en"" 
if lang == ""fr"":
  weights_pretrained = 'wref30k'
  itos_pretrained = 'itosref30k'
  pretained_data = (weights_pretrained, itos_pretrained)
if lang == ""es"":
  weights_pretrained = 'model-30k-vocab-noqrnn'
  itos_pretrained = 'itos_pretrained'
if lang != ""en"":
  pretained_data = (weights_pretrained, itos_pretrained)

PATH_LM = Path(f'data/{lang}')
PATH_CS = Path(f'data/{lang}')

train_df = pd.read_csv(f""{PATH_LM}/train.csv"")
valid_df = pd.read_csv(f""{PATH_LM}/valid.csv"")
test_df = pd.read_csv(f""{PATH_LM}/test.csv"")

tokenizer = Tokenizer(lang=f'{lang}', n_cpus=8)
data_lm = TextLMDataBunch.from_df(PATH_LM, tokenizer=tokenizer, bs=32, train_df=train_df, valid_df=valid_df, test_df=test_df)

""""""# Fine tuning LM""""""

if lang == ""en"":
  learn = language_model_learner(data_lm, pretrained_model=URLs.WT103_1, drop_mult=0)
else:
  learn = language_model_learner(data_lm, pretrained_fnames=pretained_data, drop_mult=0)
learn.freeze()

learn.lr_find()
learn.recorder.plot(skip_start=0)
learn.fit_one_cycle(1, 1e-2)
learn.save(f'{lang}_head_pretrained')

learn.unfreeze()
learn.fit_one_cycle(2, 1e-3, moms=(0.8,0.7))
learn.save(f'{lang}_lm_fine_tuned')
learn.save_encoder(f'{lang}_ft_enc')

""""""# Classification task""""""

train_df = pd.read_csv(f""{PATH_CS}/train.csv"", names=[""label"", ""text""])
valid_df = pd.read_csv(f""{PATH_CS}/valid.csv"")
test_df = pd.read_csv(f""{PATH_CS}/test.csv"")

labelcounts = train_df.groupby([""label""]).size()
label_sum = len(train_df[""label""])
class_imbalance = [(count/label_sum) for count in labelcounts]
print(class_imbalance)

data_clas = TextClasDataBunch.from_df(PATH_CS, train_df=train_df, valid_df=valid_df, test_df=test_df, tokenizer=tokenizer, vocab=data_lm.train_ds.vocab, bs=32)

learn = text_classifier_learner(data_clas, drop_mult=0.3)
learn.load_encoder(f'{lang}_ft_enc')
learn.freeze()

""""""## Take class imbalance into account""""""

weights_balance = [(1-count/label_sum) for count in labelcounts]
loss_weights = torch.FloatTensor(weights_balance).cuda()
learn.crit = partial(F.cross_entropy, weight=loss_weights)

""""""## Train classifier""""""

learn.lr_find()
learn.recorder.plot(skip_start=0)

starting_lr = 1e-2

learn.fit_one_cycle(2, starting_lr, moms=(0.8,0.7))

learn.freeze_to(-2)
learn.fit_one_cycle(1, slice(starting_lr/(2.6**4),1e-2), moms=(0.8,0.7))

learn.freeze_to(-3)
lr = starting_lr/2
learn.fit_one_cycle(1, slice(lr/(2.6**4),5e-3), moms=(0.8,0.7))

learn.unfreeze()
lr = starting_lr/10
learn.fit_one_cycle(2, slice(lr/(2.6**4),1e-3), moms=(0.8,0.7))
learn.fit_one_cycle(2, slice(lr/(2.6**4),1e-3), moms=(0.8,0.7))

learn.save(f'{lang}_ulmfit')
learn.export(f'{lang}_ulmfit.pkl') 
```",based notebook import import torch print dev print import import import en e en path path fine tuning en learn else learn classification task label text label label count print learn take class imbalance account count partial train classifier slice slice slice slice,issue,negative,positive,positive,positive,positive,positive
459755866,"This is a bit tricky, but when you use `ImageDataBunch.from_folder` with `valid_pct`, it grabs all the images in your directory (it doesn't look for train/valid/text etc). So you should use `path/'train'` instead of path to avoid grabbing the images in the test set.
Then, when you want to add your test set, make sure to pass a `Path` object that points to `path/'test'` and it should work.",bit tricky use directory look use instead path avoid test set want add test set make sure pas path object work,issue,negative,positive,positive,positive,positive,positive
459747764,Sounds right. Would you be willing to suggest a PR to address this? ,right would willing suggest address,issue,negative,positive,positive,positive,positive,positive
459745514,"You don't need to pass again the metrics is they are in your `Learner` object. Note that in fastai the test set is unlabeled (your labels, if you had some, were all thrown away), it is intended to make predictions on some new data (think test set as in a Kaggle competition). For this you would do
```
preds,_ = learn.get_preds(ds_type=DatasetType.Test)
```
If you want to validate on another set, you should create a second DataBunch that has it as its validation set and do
```
learn.data = data2
learn.validate()
```",need pas metric learner object note test set unlabeled thrown away intended make new data think test set competition would want validate another set create second validation set data,issue,positive,positive,neutral,neutral,positive,positive
459743750,"The boolean cpu wasn't working: there was still an error on some machines with CPU only, that's why it was removed. If you still get the error, it means you have some tensors on the GPU saved, and they shouldn't really be there. Sharing your code would help us debug this.",working still error removed still get error saved really code would help u,issue,negative,positive,positive,positive,positive,positive
459672147,"I have installed the last version of fastai with `pip install git+https://github.com/fastai/fastai.git`, so I have version 1.0.43.dev0 for training, ran all the pipeline again and save the classifier.
The inference is still version 1.0.42, but I still have the problem:

> If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU.

I think it's more flexible to be able to choose while loading rather than at saving.",last version pip install version dev training ran pipeline save classifier inference still version still problem running machine please use map think flexible able choose loading rather saving,issue,positive,positive,positive,positive,positive,positive
459628931,"> great, btw. If there is sth around PR etiquette to do better, I am all ears: https://forums.fast.ai/t/developer-chat/22363/715?u=benudek

https://forums.fast.ai/t/developer-chat/22363/720

> Overall, I hope this is useful (and not causing too much effort to review) for the library, for me it's a useful learning curve ;-)

We have all been sorting it out, it's a normal process when a library goes from 1-2 developers to many. So over time I'm sure better guidelines will be created. Until then watching the common style and using common sense will lead you far.",great around etiquette better overall hope useful causing much effort review library useful learning curve normal process library go many time sure better watching common style common sense lead far,issue,positive,positive,positive,positive,positive,positive
459627724,"great, btw. If there is sth around PR etiquette to do better, I am all ears: https://forums.fast.ai/t/developer-chat/22363/715?u=benudek

Overall, I hope this is useful (and not causing too much effort to review) for the library, for me it's a useful learning curve ;-)",great around etiquette better overall hope useful causing much effort review library useful learning curve,issue,positive,positive,positive,positive,positive,positive
459563646,I see the issue. `_learner_interpret` had a TTA call in it and I removed that temporarily from `ClassificationInterpretation`,see issue call removed temporarily,issue,negative,neutral,neutral,neutral,neutral,neutral
459497701,"I took a go at the monkey-patching, not sure if it's exactly what you were imagining. Tests ran ok - here is a [gist](https://gist.github.com/jchaykow/b0e970867ca4e9e51808986a81ea1d2d). One thing I was unsure of is how you want to integrate the TTA functionality in `ClassificationInterpretation` for `vision`, I did not reimplement TTA so may have to consider where to place that in `from_learner`.",took go sure exactly ran gist one thing unsure want integrate functionality vision may consider place,issue,negative,positive,positive,positive,positive,positive
459419040,"You'll need to install fastai from master if you want this fix, as it's not in a release yet. (assuming you have the same issue with fp16) 

It was removed because the logic was changed to always save models for CPU. ",need install master want fix release yet assuming issue removed logic always save,issue,positive,neutral,neutral,neutral,neutral,neutral
459413715,"Hello.
Both machines have fastai 1.0.42 installed.
I have retrained my model with last version, but I still have this issue too.
Why was the boolean cpu removed for the loading function from the commit `a92d6c6` ?",hello model last version still issue removed loading function commit,issue,negative,neutral,neutral,neutral,neutral,neutral
459389682,Ah yes. In the data block API they'll be Path objects but not necessarily in the factory method in data.vision. Will add a check.,ah yes data block path necessarily factory method add check,issue,negative,neutral,neutral,neutral,neutral,neutral
459388911,"Thanks for that.

I'm not sure if `as_posix` work if input is `str` and not `pathlib.Path`. Do those functions accept `str`?",thanks sure work input accept,issue,positive,positive,positive,positive,positive,positive
459383325,Good point! Changed the default from 2 to 3 as a consequence.,good point default consequence,issue,negative,positive,positive,positive,positive,positive
459381207,"Changed the places I could think of, let me know if you see other ones missing.",could think let know see missing,issue,negative,negative,negative,negative,negative,negative
459288731,"For example `fastai/vision/data.py` # line 300

from

    def _get_label(fn): return pat.search(str(fn)).group(1)

to

    from pathlib import WindowsPath as _WindowsPath # line 2

    def _get_label(fn): # line 301
        if isinstance(fn, _WindowsPath):
            fn = fn.as_posix()
        return pat.search(str(fn)).group(1)",example line return import line line return,issue,negative,neutral,neutral,neutral,neutral,neutral
459258281,">I don't know if this is on purpose, but you have parameters without gradients so they won't be trained (the fix doesn't address that, it just checks for nonexistent gradients).

I understand this, but I don't understand where they could come from, or why adding a second loss component makes that go away. But that's more of a PyTorch than a fastai issue.

Thanks for the quick turnaround times.",know purpose without wo trained fix address nonexistent understand understand could come second loss component go away issue thanks quick turnaround time,issue,negative,positive,positive,positive,positive,positive
459182252,"I got a similar error when running lesson3.

```
learn.load('fit_head');

learn.unfreeze()
```

https://nbviewer.jupyter.org/github/fastai/course-v3/blob/master/nbs/dl1/lesson3-imdb.ipynb

In this notebook results in a runtime error:

```
---------------------------------------------------------------------------
RuntimeError                              Traceback (most recent call last)
<ipython-input-36-e9ed8beef70a> in <module>
----> 1 learn.unfreeze()

~/SageMaker/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py in unfreeze(self)
    203     def unfreeze(self):
    204         ""Unfreeze entire model.""
--> 205         self.freeze_to(0)
    206         self.create_opt(defaults.lr)
    207 

~/SageMaker/envs/fastai/lib/python3.7/site-packages/fastai/basic_train.py in freeze_to(self, n)
    192             for l in g:
    193                 if not self.train_bn or not isinstance(l, bn_types): requires_grad(l, False)
--> 194         for g in self.layer_groups[n:]: requires_grad(g, True)
    195         self.create_opt(defaults.lr)
    196 

~/SageMaker/envs/fastai/lib/python3.7/site-packages/fastai/torch_core.py in requires_grad(m, b)
    115     if not ps: return None
    116     if b is None: return ps[0].requires_grad
--> 117     for p in ps: p.requires_grad=b
    118 
    119 def trainable_params(m:nn.Module)->ParamList:

RuntimeError: you can only change requires_grad flags of leaf variables.

```

My installation details are as follows:
```text
=== Software === 
python        : 3.7.2
fastai        : 1.0.42
fastprogress  : 0.1.18
torch         : 1.0.0
nvidia driver : 396.44
torch cuda    : 9.0.176 / is available
torch cudnn   : 7401 / is enabled

=== Hardware === 
nvidia gpus   : 1
torch devices : 1
  - gpu0      : 11441MB | Tesla K80

=== Environment === 
platform      : Linux-4.14.77-70.82.amzn1.x86_64-x86_64-with-glibc2.10
distro        : #1 SMP Mon Dec 3 20:01:27 UTC 2018
conda env     : fastai
python        : /home/ec2-user/SageMaker/envs/fastai/bin/python
sys.path      : /home/ec2-user/SageMaker/course-v3/nbs/dl1
/home/ec2-user/src/cntk/bindings/python
/home/ec2-user/SageMaker/envs/fastai/lib/python37.zip
/home/ec2-user/SageMaker/envs/fastai/lib/python3.7
/home/ec2-user/SageMaker/envs/fastai/lib/python3.7/lib-dynload

/home/ec2-user/SageMaker/envs/fastai/lib/python3.7/site-packages
/home/ec2-user/SageMaker/envs/fastai/lib/python3.7/site-packages/IPython/extensions
/home/ec2-user/.ipython

Thu Jan 31 01:39:31 2019       
+-----------------------------------------------------------------------------+
| NVIDIA-SMI 396.44                 Driver Version: 396.44                    |
|-------------------------------+----------------------+----------------------+
| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |
| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |
|===============================+======================+======================|
|   0  Tesla K80           On   | 00000000:00:1E.0 Off |                    0 |
| N/A   80C    P0   139W / 149W |   6942MiB / 11441MiB |     98%      Default |
+-------------------------------+----------------------+----------------------+
                                                                               
+-----------------------------------------------------------------------------+
| Processes:                                                       GPU Memory |
|  GPU       PID   Type   Process name                             Usage      |
|=============================================================================|
|    0      8721      C   ...2-user/SageMaker/envs/fastai/bin/python   317MiB |
|    0      9011      C   ...2-user/SageMaker/envs/fastai/bin/python  6295MiB |
|    0     14514      C   ...2-user/SageMaker/envs/fastai/bin/python   317MiB |
+-----------------------------------------------------------------------------+

```",got similar error running lesson notebook error recent call last module unfreeze self unfreeze self unfreeze entire model self false true return none none return change leaf installation text python torch driver torch available torch hardware torch environment platform mon python driver version name volatile fan temp compute mib mib default memory type process name usage mib mib mib,issue,negative,positive,neutral,neutral,positive,positive
459165078,"Ok, the problem was different: `to_fp32` doesn't properly remove the MixedPrecision callback, and even if you don't call it, the `MixedPrecision` callback saves some stuff on the GPU. Both should be fixed now.",problem different properly remove even call stuff fixed,issue,negative,positive,neutral,neutral,positive,positive
459148741,"Double checked both machines. Both running 1.0.42.

Code used to generate model:
```python3
from fastai import *
from fastai.vision import *

# Loading data
bs = 32
df = pd.read_csv('./labels.csv', header='infer')
data = (ImageItemList.from_df(df, path='.', folder='train')
        .random_split_by_pct()
        .label_from_df(label_cls=FloatList)
        .transform(get_transforms(), size=299)
        .databunch(bs=bs).normalize(imagenet_stats))

# Create model
learn = create_cnn(data, models.resnet101)

# Use mixed precision
learn.to_fp16()

# Find Learning Rate
learn.lr_find()
learn.recorder.plot()

# Fit
learn.fit_one_cycle(10)
learn.save('stage-1-101')

# Prep for fine tuning
learn.unfreeze()
learn.lr_find()
learn.recorder.plot()

# Fine Tuning
learn.fit_one_cycle(10, max_lr=slice(1e-6, 3e-4))
learn.save('stage-2-101')

# Export
learn.to_fp32()
learn.export('prod-101.pkl')
```",double checked running code used generate model python import import loading data data create model learn data use mixed precision find learning rate fit prep fine tuning fine tuning export,issue,positive,positive,positive,positive,positive,positive
459139376,You should check your version on the machine you export your 'export.pkl' file then provide us with the code you're running. Just confirmed I had no problem loading an exported file on a CPU-only instance.,check version machine export file provide u code running confirmed problem loading file instance,issue,negative,positive,positive,positive,positive,positive
459131056,"Before making my comment I trained a `Learner` from scratch with 1.0.42 and master to make sure. It's still happening for me.

```
Jan 30 09:24:39 PM  Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU.
Jan 30 09:24:39 PM  Traceback (most recent call last):
  File ""app/server.py"", line 31, in setup_learner
    learn = load_learner(path, export_file_name, True)
  File ""/usr/local/lib/python3.7/site-packages/fastai/basic_train.py"", line 469, in load_learner
    state = torch.load(open(Path(path)/fname, 'rb'))
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 367, in load
    return _load(f, map_location, pickle_module)
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 538, in _load
    result = unpickler.load()
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 504, in persistent_load
    data_type(size), location)
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 113, in default_restore_location
    result = fn(storage, location)
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 94, in _cuda_deserialize
    device = validate_cuda_device(location)
  File ""/usr/local/lib/python3.7/site-packages/torch/serialization.py"", line 78, in validate_cuda_device
    raise RuntimeError('Attempting to deserialize object on a CUDA '
RuntimeError: Attempting to deserialize object on a CUDA device but torch.cuda.is_available() is False. If you are running on a CPU-only machine, please use torch.load with map_location='cpu' to map your storages to the CPU.
```",making comment trained learner scratch master make sure still happening object device false running machine please use map recent call last file line learn path true file line state open path path file line load return file line result file line size location file line result storage location file line device location file line raise object object device false running machine please use map,issue,positive,positive,neutral,neutral,positive,positive
459126409,You have to re-export any previously saved `Learner` with fastai v1.0.42 (or later) but the bug isn't there anymore normally.,previously saved learner later bug normally,issue,negative,negative,neutral,neutral,negative,negative
459115985,@sgugger The changes you made after this merge have broken this again. Trying to load an exported model on cpu-only machines get the cuda error in 1.0.42 and master.,made merge broken trying load model get error master,issue,negative,negative,negative,negative,negative,negative
458973787,"I tried a fix, mostly to check that the gradients are not None. I don't know if it works since I can't reproduce your bug.
I don't know if this is on purpose, but you have parameters without gradients so they won't be trained (the fix doesn't address that, it just checks for nonexistent gradients).",tried fix mostly check none know work since ca reproduce bug know purpose without wo trained fix address nonexistent,issue,negative,positive,positive,positive,positive,positive
458967170,"This is a great idea! But there is nothing in your code that limits this to tabular, it would work in all the applications. So I think this should go in train.py, to be accessible from every application, then in vision we can monkey-patch the specific methods (mostly the plot_losses one). 

Can you make the move to train, and add the most_confused method? Then I can do the monkey-patching for the ` ClassificationInterpration` in `vision.learner` if you're not comfortable with that.",great idea nothing code tabular would work think go accessible every application vision specific mostly one make move train add method comfortable,issue,positive,positive,positive,positive,positive,positive
458965645,"Hi @stas00 big fan :). I though I would dig into this. 

I was experimenting with the MNIST sample dataset.

It seems when one tries to get `repr` for  `data.train_ds[0]`, the `__getitem__` method from `fastai/data_block.py/LabelList` is called: [data_block.py#L565](https://github.com/fastai/fastai/blob/master/fastai/data_block.py#L565)

And as you can note that the x and y are transformed on-demand and then returned.

But when we call `repr` on the `data` itself, it calls the `repr` methods of individual datasets, and finally the `repr` method is called for x directly without transforming it. [data_block.py#L539](https://github.com/fastai/fastai/blob/master/fastai/data_block.py#L539).

Hence the inconsistency in the output.

But, I am not sure how to correct this, I thought of multiple approaches like 
* transforming `self.x` and `self.y` somehow. But I guess this would make things slow.

Maybe we can take some inspiration from how `data.show_batch()` works. I guess it's a visual version of what we need. But I am not sure how to proceed, any suggestions?
",hi big fan though would dig sample one get method note returned call data individual finally method directly without transforming hence inconsistency output sure correct thought multiple like transforming somehow guess would make slow maybe take inspiration work guess visual version need sure proceed,issue,positive,positive,neutral,neutral,positive,positive
458958950,"Not yet. In the meantime a few people have started discussing it on the [forum](https://forums.fast.ai/), you should check there.
I'm closing this issue since we know it's a desired feature and it's on our TODO before the second part of the course, but it won't come before end of February/beginning of March.",yet people forum check issue since know desired feature second part course wo come end march,issue,negative,neutral,neutral,neutral,neutral,neutral
458864407,"Yeah, for new users it can be nice for conda environments to just show up magically but last time I tried it there was no way to prevent it or select environments so it was a non-starter for me.

With the new [enhanced pip-interoperability](https://www.anaconda.com/blog/developer-blog/conda-4-6-release/) it's probably feasible to use pip in the interim.",yeah new nice show magically last time tried way prevent select new enhanced probably feasible use pip interim,issue,positive,positive,positive,positive,positive,positive
458852075,"I added it since so many people had issues as you can see from https://stackoverflow.com/questions/39604271/conda-environments-not-showing-up-in-jupyter-notebook and several threads on https://forums.fast.ai/ and which this package resolved.

But you're correct that this shouldn't be in the core dependencies since fastai should work w/o jupyter environment. It just didn't seem to be a harmless bonus dependency to add to aid the users. But as you are saying this is not the case. So I'm in agreement with your proposed change, @dhirschfeld.

Instead, we should document that some people may need nb_conda if they have issues with their jupyter/conda env.

p.s. until then you may use the pip fastai package, which doesn't have this dependency.",added since many people see several package resolved correct core since work environment seem harmless bonus dependency add aid saying case agreement change instead document people may need may use pip package dependency,issue,positive,positive,positive,positive,positive,positive
458576368,"You're right, works like a charm. Thanks!",right work like charm thanks,issue,positive,positive,positive,positive,positive,positive
458573810,"Thanks for reviewing. I've tested `can_use_gpu()` locally with this:
```console
$ CUDA_VISIBLE_DEVICES='' python -c ""import torch; print(torch.cuda.is_available())""
False
$ python -c ""import torch; print(torch.cuda.is_available())""
True
```
and then, to make sure, checked it here: https://github.com/pytorch/pytorch/blob/2235fb256e9e58050585a1bd0342de599570fcce/torch/cuda/__init__.py#L50",thanks tested locally console python import torch print false python import torch print true make sure checked,issue,positive,positive,positive,positive,positive,positive
458570433,"Thanks a lot for cleaning the mess I made when moving the models. Just restored the `can_use_gpu` function as it's useful for tests to sometime masks an existing GPU, but will test locally if your claim is right and it can be simplified as you did before putting it back potentially.",thanks lot cleaning mess made moving function useful sometime test locally claim right simplified back potentially,issue,positive,positive,neutral,neutral,positive,positive
458568464,"This was solved yesterday in master. Note that if you don't specify a `fname` argument, the compressed file will still be downloaded in the default data directory.",yesterday master note specify argument compressed file still default data directory,issue,negative,neutral,neutral,neutral,neutral,neutral
458272250,"@kdorichev the github differ has trouble with long lines + text, that's what you're seeing (or lack thereof).
@sgugger okay, will do a pass on the fastai folder files when I get a chance.",differ trouble long text seeing lack thereof pas folder get chance,issue,negative,negative,negative,negative,negative,negative
458213527,"Can you open an issue on their side then? I'm closing this here.
Thanks for digging!",open issue side thanks digging,issue,negative,positive,neutral,neutral,positive,positive
458212857,"Wow, it's `import spacy`, so seems fastai is not at fault here :)",wow import spacy fault,issue,negative,positive,neutral,neutral,positive,positive
458203760,I'm also on a jupyter notebook with a ssh tunnel but I can't reproduce the bug. So I'll need your help figuring out which import breaks it for you. Could you try to see which one of the imports in fastai/imports/core.py or fastai/imports/torch_core.py is at fault? Thanks,also notebook tunnel ca reproduce bug need help import could try see one fault thanks,issue,negative,positive,positive,positive,positive,positive
458189144,"After this step, there is no error.
![image](https://user-images.githubusercontent.com/14188757/51848508-c4478500-232e-11e9-9799-78b9e489264b.png)

An aside: I run jupyter on a remote machine using ssh.",step error image aside run remote machine,issue,negative,negative,neutral,neutral,negative,negative
458185454,"I think the bug is linked to the IPython you're using (QT console?) could you try to replace from
```
fastai.text import *
```
with
```
from IPython.display import clear_output, display, HTML
```
then tell me if you have the same problem?",think bug linked console could try replace import import display tell problem,issue,negative,neutral,neutral,neutral,neutral,neutral
458178697,"Thanks for the big proofread! 
I think you used something to directly change the underlying JSONs of the notebook(for some typo fixes in the 1-liners of the docs), note that as long as the corresponding line isn't fixed in the code, they'll get regenerated with the typo each time we run the scripts to build the docs ;)",thanks big proofread think used something directly change underlying notebook typo note long corresponding line fixed code get typo time run build,issue,negative,positive,neutral,neutral,positive,positive
458175676,"You can pass an argument called `model_path` to your `Learner` (and in `create_cnn` in particular) to indicate where you want your models saved. If you pass a `Path` object pointing to the exact directory you want to use, it will replace the default of `learn.path/'models'`.
I think that solves your problem.",pas argument learner particular indicate want saved pas path object pointing exact directory want use replace default think problem,issue,negative,positive,positive,positive,positive,positive
458174510,"There was a problem with the fix proposed by @kdorichev  so I changed it. Note that as he pointed out, you will still get the structure
```
└── pets
    └── oxford-iiit-pet
        ├── annotations
        │   ├── trimaps
        │   └── xmls
        └── images
```
What the function returns in this case is `Path(""pets/oxford-iii-pet"")`.",problem fix note pointed still get structure function case path,issue,negative,neutral,neutral,neutral,neutral,neutral
458173159,"This is breaking the function when no `dest` is passed, so we have to fix it another way ;)",breaking function fix another way,issue,negative,neutral,neutral,neutral,neutral,neutral
458167049,"Fixed, but I think your bug may lay elsewhere, as I never had a problem with those additional dots.",fixed think bug may lay elsewhere never problem additional,issue,negative,positive,neutral,neutral,positive,positive
458097846,"Thank you Sylvain!

On Sun, Jan 27, 2019 at 10:13 PM Sylvain Gugger <notifications@github.com>
wrote:

> Merged #1521 <https://github.com/fastai/fastai/pull/1521> into master.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1521#event-2099521902>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AhqNqnqEsuWy0WLNXNHt3JDtgDXAw-quks5vHhZzgaJpZM4aUdR7>
> .
>
",thank sun wrote master thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
458050891,"@jiata Note, that the untarred file will have the structure of the tar file, including `oxford-iiit-pet`, namely:
```
└── pets
    └── oxford-iiit-pet
        ├── annotations
        │   ├── trimaps
        │   └── xmls
        └── images
```",note untarred file structure tar file namely,issue,negative,neutral,neutral,neutral,neutral,neutral
458048586,"As of now, on `fastai v.1.0.43.dev0`, the file is downloaded with correct, specified name -- `pets-tar.tgz` in this case, but is untarred into data.**parent** directory -- `/mnt/data/fastai/`.  
```
tarfile.open(fname, 'r:gz').extractall(dest.parent)
```
`untar_data` returns unexisting path.

With a simple fix 
```
tarfile.open(fname, 'r:gz').extractall(dest)
```
I was able to acheve expected behavior -- the tar was untarred into `/mnt/data/fastai/pets` directory.

I will now submit a pull request.",dev file correct name case untarred data parent directory unexisting path simple fix able behavior tar untarred directory submit pull request,issue,negative,positive,positive,positive,positive,positive
457954861,Sorry I misread... Thanks a lot!,sorry misread thanks lot,issue,negative,negative,negative,negative,negative,negative
457954581,Thanks a lot (failing test is a random one with no link)!,thanks lot failing test random one link,issue,negative,negative,negative,negative,negative,negative
457954513,"Seems like a sound suggestion, thanks!",like sound suggestion thanks,issue,positive,positive,positive,positive,positive,positive
457954400,"Thanks! There are a few things I think we can make a little bit better here, added some comments.",thanks think make little bit better added,issue,positive,positive,positive,positive,positive,positive
457953307,"So I was thinking about this and I'm not sure about something. 
If there's no object in the image at all because of transforms this fix handles it. However I'm not sure of the behaviour if and when the whole image is inside an object BBox. The correct behaviour (IMHO) would be to assign the class of the overall object that got zoomed into to the whole image, and the BBox should then be the whole image. I don't think that's what it's doing right now.
Maybe it's such a corner case it doesn't matter that much.",thinking sure something object image fix however sure behaviour whole image inside object correct behaviour would assign class overall object got whole image whole image think right maybe corner case matter much,issue,positive,positive,positive,positive,positive,positive
457949687,"Check manually the device of any parameter of the model (`one_param(learn.model).device`) if you're unsure, but the bottleneck might be the CPU (with loading images and applying data augmentation). I've read that the pytorch DataLoader isn't as efficient on Windows, which would probably only worsen that bottleneck.",check manually device parameter model unsure bottleneck might loading data augmentation read efficient would probably worsen bottleneck,issue,negative,neutral,neutral,neutral,neutral,neutral
457944456,"Thank you!  I spent all morning making this work.  I think my anaconda installation was broken because once I uninstalled anaconda and reisntalled everything it worked first shot...  The model seems to be training now, but I think it is using the CPU even though torch.cuda.is_available() returns true...  Why would that be?

![image](https://user-images.githubusercontent.com/265924/51805496-f2986800-223b-11e9-97e7-54bd56fa9d27.png)
",thank spent morning making work think anaconda installation broken uninstalled anaconda everything worked first shot model training think even though true would image,issue,negative,positive,neutral,neutral,positive,positive
457887597,"I think you have an installation problem then. There's nothing even specific to windows in this line, but it may be the first time something is put on your GPU (here, the model).",think installation problem nothing even specific line may first time something put model,issue,negative,positive,positive,positive,positive,positive
457887088,"Trying to run the course version 3 on my machine. [Link to my thread in the forums](https://forums.fast.ai/t/trying-to-run-lesson-1-on-windows/35985/2), but basically trying to run this line, the notebook start executing and never returns.  No error messages in the command line where the notebook was started.  The line in question from lesson 1 which is pretty basic:

learn = create_cnn(data, models.resnet34, metrics=error_rate)",trying run course version machine link thread basically trying run line notebook start never error command line notebook line question lesson pretty basic learn data,issue,positive,positive,positive,positive,positive,positive
457886521,"fastai 1 works fully on Windows, not sure why the problem is.",work fully sure problem,issue,negative,positive,positive,positive,positive,positive
457886437,"Just wondering why this was closed?  I did the 2018 edition of the fastiai course on my windows machine and it worked great.  Anything we can do to make it work on windows?  Anything the community can do to help?

Thanks,",wondering closed edition course machine worked great anything make work anything community help thanks,issue,positive,positive,positive,positive,positive,positive
457870173,"Thanks.

It actually uses the tiny dataframe from text_df(), the imdb_sample path is just to provide a path. I followed the example of other tests in that file",thanks actually tiny path provide path example file,issue,negative,positive,neutral,neutral,positive,positive
457861577,Good idea! Can you just amend your test to use a tiny dataframe and not the whole IMDB sample? I'd like it to be as fast as possible.,good idea amend test use tiny whole sample like fast possible,issue,positive,positive,positive,positive,positive,positive
457848972,"Sure! I'll start a fresh one at once!

On Sat, Jan 26, 2019 at 3:59 PM Sylvain Gugger <notifications@github.com>
wrote:

> Thanks! Can you possibly start a fresh new PR from master? This one has
> conflicts and I can't see what you added /changed in plot_multi_top_losses.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1517#issuecomment-457837664>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AhqNqtF0COgI0GG-hZlk1nqC7NYSpFs4ks5vHG1BgaJpZM4aT4fo>
> .
>
",sure start fresh one sat wrote thanks possibly start fresh new master one ca see added thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
457837664,Thanks! Can you possibly start a fresh new PR from master? This one has conflicts and I can't see what you added /changed in plot_multi_top_losses.,thanks possibly start fresh new master one ca see added,issue,positive,positive,positive,positive,positive,positive
457811802,"OK this can be achieved with `from_name_func`

using:
```python
def get_labels(file_path : str):
    pattern = re.split('/', file_path)[-2]
    match = re.search(pattern, file_path)
    return match.group()
```",python pattern match pattern return,issue,negative,neutral,neutral,neutral,neutral,neutral
457694498,The developer chat on the [forum](https://forums.fast.ai/t/developer-chat/22363/699) is where we post changes in the API.,developer chat forum post,issue,negative,neutral,neutral,neutral,neutral,neutral
457694029,Thanks! Is there a place I can keep up with the API dev? an IRC/slack or something? ,thanks place keep dev something,issue,negative,positive,positive,positive,positive,positive
457643628,my mistake i cannot reproduce af latest update on dev,mistake reproduce latest update dev,issue,negative,positive,positive,positive,positive,positive
457615027,"Ah yes, the first value recorded should be the max divided by the div_factor. Let me check if it's used by the optimizer or not.",ah yes first value divided let check used,issue,positive,positive,positive,positive,positive,positive
457613801,"ok so may not a bug in the last value but certainly in the first. Surely OptimWrapper is not using the max learningrate (0.003) in the first epoch ?
[0.003,
0.0008945512935455861,
",may bug last value certainly first surely first epoch,issue,positive,positive,positive,positive,positive,positive
457603997,"It looks like the problem comes from your feather package? Note that the save to feather format is optional. In any case, you can use the [forum](https://forums.fast.ai/) to get help.",like problem come feather package note save feather format optional case use forum get help,issue,positive,neutral,neutral,neutral,neutral,neutral
457593103,"It is missing that last value, but that last value was also never used (since it's on the last on_batch_end). I'm not sure why you think there is a bug?",missing last value last value also never used since last sure think bug,issue,positive,positive,neutral,neutral,positive,positive
457428650,"@sgugger  This starts happening in the same code when switching from 1.0.33 to 1.0.34 version of fast ai. Below is the code to reproduce:

```
from fastai import *
from fastai.vision import *

# create sample data
df = pd.DataFrame({""fn"": [""a.jpg"", ""b.jpg"", ""c.jpg"", ""d.jpg"", ""e.jpg""], ""lbl"": [True,False,True,False,True]})
df.to_csv(""tst_tmp.csv"", index=False, header=False)
Path(""fastai_dbg"").mkdir(exist_ok = True)

import imageio
imageio.imwrite('fastai_dbg/a.jpg', np.random.rand(64, 64))
imageio.imwrite('fastai_dbg/b.jpg', np.random.rand(64, 64))
imageio.imwrite('fastai_dbg/c.jpg', np.random.rand(64, 64))
imageio.imwrite('fastai_dbg/d.jpg', np.random.rand(64, 64))
imageio.imwrite('fastai_dbg/e.jpg', np.random.rand(64, 64))

tfms = get_transforms()

data = ImageDataBunch.from_df(""."", df, folder=""fastai_dbg"",valid_pct = 0.5, ds_tfms=tfms, size=32)

learn = create_cnn(data, models.resnet18, metrics=error_rate)
learn.fit_one_cycle(cyc_len=2) 
```
",happening code switching version fast ai code reproduce import import create sample data true false true false true path true import data learn data,issue,positive,positive,positive,positive,positive,positive
457333246,"Here https://pytorch.org/get-started/locally/ it says:
```
conda install pytorch torchvision -c pytorch
# MacOS Binaries dont support CUDA, install from source if CUDA is needed
```
Looking at https://www.google.com/search?q=pytorch+macos+cuda the install from source works. and that pytorch has [no intention currently to support binaries](https://github.com/pytorch/pytorch/issues/7960).

But what I meant in my original reply is that fastai-v1 has no direct dependency on cuda.

fastai-v1 supports whatever pytorch supports (with windows support catching up that is). FWIW, we run a 100% success test suite on CI for MacOS/conda for cpu. MacOS/pip has incompatibility issues between pytorch and numpy. https://github.com/pytorch/pytorch/issues/14359. We have no CI w/ GPU capacity to test with.

If, however, you're referring to fastai-0.7x, then I don't know. I doubt this will ever change since pytorch-0.3 is not being in active development.
",install dont support install source looking install source work intention currently support meant original reply direct dependency whatever support catching run success test suite incompatibility capacity test however know doubt ever change since active development,issue,negative,positive,positive,positive,positive,positive
457326760,@stas00 Good to hear. Any idea how to get around cuda90 not being available on MacOS? It's a dependency in the fastai env and it's not supported on MacOS. ,good hear idea get around available dependency,issue,negative,positive,positive,positive,positive,positive
457318837,"This is a year old thread, and this information is no longer correct. 

MacOS is partially supported, i.e. not 100% mainly due to issues in pytorch for which fastai has no control over. e.g, this one: https://github.com/pytorch/pytorch/issues/14359",year old thread information longer correct partially mainly due control one,issue,negative,negative,neutral,neutral,negative,negative
457313687,"Ran into a similar issue for MacOS. Cuda90 is not supported on Mac, only on Windows and Linux. You can verify package compatibility by searching [https://anaconda.org/](url)",ran similar issue mac verify package compatibility searching,issue,negative,neutral,neutral,neutral,neutral,neutral
457216166,I think you may be using a version of pytorch that is too recent for the old course (it runs with 0.3 normally). Could you check your install?,think may version recent old course normally could check install,issue,negative,positive,neutral,neutral,positive,positive
457215641,"Yes, this is because of the random split: sometimes your validation set ends up with labels that aren't present in your training data. Note that those will be discarded in recent versions.",yes random split sometimes validation set present training data note recent,issue,negative,negative,negative,negative,negative,negative
457047531,master branch please. thank you.,master branch please thank,issue,positive,neutral,neutral,neutral,neutral,neutral
457046249,Yeah  later i will submit a PR to master branch? or any other branch?,yeah later submit master branch branch,issue,negative,neutral,neutral,neutral,neutral,neutral
456829461,"I think I fixed the issue by avoiding serializing the path (since it behaves differently on different systems), let me know if it works now (note that you'll need to recreate the export file on Windows before trying to load it on your linux container).",think fixed issue path since differently different let know work note need recreate export file trying load container,issue,negative,positive,neutral,neutral,positive,positive
456822395,"Good suggestion. I mayo change it a little bit because I'm not sure what happens if we put a GPU as a device (since there are other things than the model in the state), so it may end up just being a flag `cpu=True` if `device` doesn't work for any device.
Thanks a lot!",good suggestion change little bit sure put device since model state may end flag device work device thanks lot,issue,positive,positive,positive,positive,positive,positive
456668161,"I'd say at the very least it should match [transforms.Resize(size)](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.Resize), support (w,h) that is.

For channels I'd say a different transform would be the best. And surely, this feature does need attention. For example, currently if you have a 1 channel image, it gets silently upgraded to 3 if you apply `normalize(imagenet)`.

I see pytorch doesn't 1->3 transform, other than the other way around [to_grayscale](https://pytorch.org/docs/stable/torchvision/transforms.html#torchvision.transforms.functional.to_grayscale).

But I will let captain @sgugger follow up.",say least match size support say different transform would best surely feature need attention example currently channel image silently apply normalize see transform way around let captain follow,issue,positive,positive,positive,positive,positive,positive
456663277,"I fixed a related issue with passing 2dim sizes instead of 3dim, I can take on that and fix it tomorrow. 

Do you think databunch should support both `size=(h,w)` and `size=(channels, h, w)` and not raise a warning on `(h,w)`? 

It's cool to provide a very flexible API, my question is more about would it still be consistent across other parts of fastai and other DL libraries, is it a good practice to accept different shapes of arguments and fix them on the fly without providing feedback to the user? 
",fixed related issue passing dim size instead dim take fix tomorrow think support raise warning cool provide flexible question would still consistent across good practice accept different fix fly without providing feedback user,issue,positive,positive,positive,positive,positive,positive
456661804,"Yes, there should be a new line. Would you mind submitting a PR to add it?",yes new line would mind add,issue,negative,positive,positive,positive,positive,positive
456631742,"Sorry, I thought you were mixing the two of them, I don't know why.
So the error comes because Path doesn't handle a change of system... lovely. Will try to address.",sorry thought two know error come path handle change system lovely try address,issue,negative,neutral,neutral,neutral,neutral,neutral
456627345,"I'm not sure I fully understand, this is my model / data folder:

```
standford_data_make:
    models:
        carmakemodelclassifiermodel.pth
    export.pkl
```

From my understanding, `ImageDataBunch.load_empty` is loading from `export.pkl` to get trained data property or metadata:

```
  modelPath = Path('/app/src/standford_data_make')
  empty_data = ImageDataBunch.load_empty(modelPath)
  learn = create_cnn(empty_data, models.resnet152)
  model = learn.load(modelPath/'carmakemodelclassifiermodel') 
  model.predict(im)
```

This actually works on my windows machine, it fails when I try to deploy with a linux container.
",sure fully understand model data folder understanding loading get trained data property path learn model actually work machine try deploy container,issue,negative,positive,positive,positive,positive,positive
456620895,"I use `data.export` to create the `export.pkl` and also yes this is done in windows, which seems to give me some idea why the error. But is there a fix for this? How can I export `export.pkl` in windows and then load it back up in a linux system?

```
data = ImageDataBunch.from_folder('./standford_data/', ds_tfms=get_transforms(), size=224, bs=8)
data.normalize(imagenet_stats)
data.export()
```",use create also yes done give idea error fix export load back system data,issue,negative,neutral,neutral,neutral,neutral,neutral
456517829,"Ok, it was just the batch_first thing that made the merge fail, thanks for your contribution!",thing made merge fail thanks contribution,issue,negative,negative,negative,negative,negative,negative
456516883,I'll finish to fix the potential failing tests after merging.,finish fix potential failing,issue,negative,neutral,neutral,neutral,neutral,neutral
456453837,"Ok, so it can open it but not unpickle it. Could you share the code you used to create that `export.pkl` file?",open could share code used create file,issue,positive,neutral,neutral,neutral,neutral,neutral
456453477,Put an assert at the beginning of fit to catch that empty dataloader and throw a clear error message. Also changes the warning message in `DataBunch` to make it clearer.,put assert beginning fit catch empty throw clear error message also warning message make clearer,issue,negative,positive,positive,positive,positive,positive
456450084,Now it silently falls back to maximum batch size elements.,silently back maximum batch size,issue,negative,neutral,neutral,neutral,neutral,neutral
456402132,"Oh, yes. Thanks, with a lower number of rows it's working.",oh yes thanks lower number working,issue,positive,positive,positive,positive,positive,positive
456400639,`rows=16` will try to make 16 by 16 images which is probably greater than your batch size? I'll put an assert there as this error comes often.,try make probably greater batch size put assert error come often,issue,negative,positive,positive,positive,positive,positive
456387821,"@daleevans I ran into this as well - in my case, it was because I had less than a single batch's worth of data. Decreasing my batch size **or** increasing the amount of data fixed the issue.

FWIW, two tweaks that would have helped me chase this down faster:

#### 1. a better small-batch-size error message
I was getting a warning:
> Your training dataloader is empty, you have only 63 items in your training set

I'm a beginner, so it took me a bit to figure out that the *reason* my 63 items weren't making it into my data loader was because of my batch size (64). Seems like this warning could be improved by maybe just including the current batch size.

#### 2. a better crash location
The crash that occurs is a missing positional argument, which IIUC happens because `smooth_loss` isn't present on `CallbackHandler.state_dict` when `basic_train.Recorder.on_epoch_end` is called. I'm not totally clear on why a too-small batch size causes this, but it seems like there are probably better places for this error to surface than the epoch end callback!",ran well case le single batch worth data decreasing batch size increasing amount data fixed issue two would chase faster better error message getting warning training empty training set beginner took bit figure reason making data loader batch size like warning could maybe current batch size better crash location crash missing positional argument present totally clear batch size like probably better error surface epoch end,issue,negative,positive,positive,positive,positive,positive
456281527,"For me, the cause was having too few samples in my training data.  I also got this warning:

```
/usr/local/lib/python3.6/site-packages/fastprogress/fastprogress.py:95: UserWarning: Your generator is empty.
  warn(""Your generator is empty."")
```

But simply cloning my data a bunch until I got 32 (non-unique) samples solved it.",cause training data also got warning generator empty warn generator empty simply data bunch got,issue,negative,negative,neutral,neutral,negative,negative
456223559,"Yes. `open(path/'export.pkl', 'rb')` works fine:

```
>>> modelPath = Path('/app/src/standford_data_make')
>>> open(modelPath/'export.pkl','rb')
```

> <_io.BufferedReader name='/app/src/standford_data_make/export.pkl'>",yes open work fine path open,issue,positive,positive,positive,positive,positive,positive
456223429,"It doesn't give as good results in our experience, which is why this is the default value in the library. You can change it by passing `padding_mode=zeros` for the cases where it gives a bug, but we'd like to keep the best default for most cases.
(Note that this is more of a pytorch bug, numpy can do reflection padding even for wide images IIRC.)",give good experience default value library change passing bug like keep best default note bug reflection padding even wide,issue,positive,positive,positive,positive,positive,positive
456219204,"More related issues:

If I pass:

size=(224,224)

```data = ImageDataBunch.from_name_re(path_img, fnames, pat, ds_tfms=None, size=(224,224), bs=bs).normalize(imagenet_stats)```

I get this:
```
fastai/basic_data.py:234: UserWarning: It's not possible to collate samples of your dataset together in a batch.
Shapes of the inputs/targets:
[[torch.Size([3, 356, 500]), torch.Size([3, 375, 500]),
```

this doesn't happen w size=224.",related pas data pat get possible collate together batch happen,issue,negative,neutral,neutral,neutral,neutral,neutral
456167342,"Yes, the fail happens in the pickle.load but it may be the `open(path/fn, 'rb')` that causes it. Can you do open(path/'export.pkl','rb') without error?",yes fail may open open without error,issue,negative,negative,negative,negative,negative,negative
456134370,"Basically I tried these two ways to pass in the model path:

```
>>> modelPath = Path('/app/src/standford_data_make')
>>> empty_data = ImageDataBunch.load_empty(modelPath)
```

> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/usr/local/lib/python3.7/site-packages/fastai/data_block.py"", line 649, in _databunch_load_empty
>     sd = LabelLists.load_empty(path, fn=fname)
>   File ""/usr/local/lib/python3.7/site-packages/fastai/data_block.py"", line 513, in load_empty
>     state = pickle.load(open(path/fn, 'rb'))
>   File ""/usr/local/lib/python3.7/pathlib.py"", line 997, in __new__
>     % (cls.__name__,))
> NotImplementedError: cannot instantiate 'WindowsPath' on your system

```
>>> modelPath = '/app/src/standford_data_make'
>>> empty_data = ImageDataBunch.load_empty(modelPath)
```

> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/usr/local/lib/python3.7/site-packages/fastai/data_block.py"", line 649, in _databunch_load_empty
>     sd = LabelLists.load_empty(path, fn=fname)
>   File ""/usr/local/lib/python3.7/site-packages/fastai/data_block.py"", line 513, in load_empty
>     state = pickle.load(open(path/fn, 'rb'))
> TypeError: unsupported operand type(s) for /: 'str' and 'str'",basically tried two way pas model path path recent call last file line module file line path file line state open file line system recent call last file line module file line path file line state open unsupported operand type,issue,negative,neutral,neutral,neutral,neutral,neutral
456132508,I did some simple debug; the fail actually happens at `pickle.load` and I have tried to use either a string or a Path for the `modelPath` and both not working. I am not sure if there's an option for me to pass in the path parameter in a different way.,simple fail actually tried use either string path working sure option pas path parameter different way,issue,negative,neutral,neutral,neutral,neutral,neutral
456090475,"It worked for me on changing 
`from fastai.structured import *`
to
`from fastai.tabular import *`
thanks @Ace139 ",worked import import thanks ace,issue,negative,positive,positive,positive,positive,positive
456081171,Sorry I mixed the method with another one. This is indeed a front-end function that needs fixing. Will do in a bit.,sorry mixed method another one indeed function need fixing bit,issue,negative,negative,negative,negative,negative,negative
456073029,It seems to be linked to multi-processing. Try to set `num_workers=0` when you create your `DataBunch`.,linked try set create,issue,negative,neutral,neutral,neutral,neutral,neutral
456072511,"It seems it's linked to the pathlib library, can you use it properly?",linked library use properly,issue,negative,neutral,neutral,neutral,neutral,neutral
456072169,This is not an issue with the fastai library. Please use the [forum](https://forums.fast.ai/) to ask for help.,issue library please use forum ask help,issue,positive,neutral,neutral,neutral,neutral,neutral
455988094,"Update, same error on running cell `learn.fit_one_cycle(4)`",update error running cell,issue,negative,neutral,neutral,neutral,neutral,neutral
455951693,"Ah, you’re right, and it should eat up less memory that way. Thanks!

On Sun, Jan 20 2019 at 5:55 PM, < notifications@github.com > wrote:

> 
> 
> 
> Thanks a lot for implementing it!
> 
> 
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub (
> https://github.com/fastai/fastai/pull/1489#issuecomment-455925734 ) , or mute
> the thread (
> https://github.com/notifications/unsubscribe-auth/AACqcbSZHQ5PTqsY9phxXsDUye7CoOduks5vFR4ogaJpZM4aJ221
> ).
> 
> 
>",ah right eat le memory way thanks sun wrote thanks lot thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
455941436,"thanks for the fix. after running the following command it started working, the version installed now is fastai-1.0.41.dev0

pip install git+https://github.com/fastai/fastai.git 
",thanks fix running following command working version dev pip install,issue,negative,positive,neutral,neutral,positive,positive
455927192,"For the lengths, I'd really like not to use a functionality that was existing, even if its benefit is slim.
I prefer the version in comments for the `fill_row` function.
Good question for the pytorch dataloader: maybe it would be best to fill the needed row in getitem and get rid of fill_batch altogether?",really like use functionality even benefit slim prefer version function good question maybe would best fill row get rid altogether,issue,positive,positive,positive,positive,positive,positive
455877235,Is it the only thing necessary to make it work properly?,thing necessary make work properly,issue,negative,neutral,neutral,neutral,neutral,neutral
455811903,"Yes, and as is indicated on each notebook, you need to install v0.7 for this course.",yes notebook need install course,issue,negative,neutral,neutral,neutral,neutral,neutral
455810707,"In the machine learning course, we import
from fastai.imports import *
from fastai.structured import *
In the module, I don't find the structured file
I am using fastai 1.0.38 on windows",machine learning course import import import module find structured file,issue,negative,neutral,neutral,neutral,neutral,neutral
455771558,"Please do suggest if any rephrasing is required. I think `to_data` docs seems a overkill, but I was unable to come up with something better. Any feedback is welcome :)",please suggest think unable come something better feedback welcome,issue,positive,positive,positive,positive,positive,positive
455715321,"**here is my sampe test code**

common part:
`images = dataset[:, url_idx] # array(['/home/....68708.jpg', '/home/..91083.jpg', ........
labels = dataset[:, category_idx] # array(['graceland', 'puma', 'nike', 'converse' ........`

this code doesent work:
`path = Path(""/home/andras/datasets/"")
data = ImageDataBunch.from_lists(path, images, labels, ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)
data.show_batch(rows=4, figsize=(14, 12)) # this shows the first wrong figure`

![figure_1](https://user-images.githubusercontent.com/28984142/51417148-f7468780-1b7c-11e9-9ba4-50e96b6be207.png)



Here is my fix:
`with open('a.csv', 'w') as f:
    for i in range(len(images)):
        f.write(f'{images[i]},{labels[i]}\n')

data = ImageDataBunch.from_csv('/', csv_labels='/home/andras/......../a.csv',
                              ds_tfms=get_transforms(), size=224).normalize(imagenet_stats)
data.show_batch(rows=4, figsize=(14, 12))`

![figure_2](https://user-images.githubusercontent.com/28984142/51417178-1ba26400-1b7d-11e9-9d47-8a94fa2dc95c.png)

",test code common part array array code work path path data path first wrong figure fix open range data,issue,negative,negative,negative,negative,negative,negative
455708058,I didn't find any reference for `ImageDataBunch.from_lists` in the whole source code. It must be a font end function.,find reference whole source code must font end function,issue,negative,positive,positive,positive,positive,positive
455706810,"I will show you the code, but it really easy to test. it would be really useful to have a function like this in the front end.",show code really easy test would really useful function like front end,issue,positive,positive,positive,positive,positive,positive
455695068,"`ImageDataBunch.from_lists` is more intended to be used behind the scenes than in front end, so I'm not sure you used it properly. In any case there is nothing we can do without at least seeing the code you tried...",intended used behind front end sure used properly case nothing without least seeing code tried,issue,negative,negative,neutral,neutral,negative,negative
455541615,"Hi Sylvain. I have implemented your reguest except the use of lengths.

**Lenghsh:** I did make a full implementation using length i have however reverted to not using it. As shown in previous communication we improve, all thing equal, performance by about 1.5 seconds pr epoch. and possibly by 1.7s if there was a length for both training and validation. I do not think this justifies the extra complexity of the interface and the code, but i can reimplement it if you insist.

**combine fill forward and backwards - or not**: I have provided 2 working versions for you to chose between: 1) that is now active with separate fill_forward and fill_backwards. I included this version in the last minut to spare an if statement in the inner loop and because i found that i made more +-1 mistakes  with the combined version than working with forward and backwards separately. 2) the combine version in comments. 

**The pytorch dataloader:** I build an entire batch when row zero in the batch is requested. I sometimes had doubts about that strategy in case pytorch starts the forward propagation of the first row while loading the nest. In that case it would be better to fill batch row by row. 

By the way the new testcase ""test_text_languagemodelpreloader"" has been invaluable at catching error during refactoring. There is just something about testing against randomly varying data:)

so this is it",hi except use make full implementation length however shown previous communication improve thing equal performance epoch possibly length training validation think extra complexity interface code insist combine fill forward backwards provided working chose active separate included version last spare statement inner loop found made combined version working forward backwards separately combine version build entire batch row zero batch sometimes strategy case forward propagation first row loading nest case would better fill batch row row way new invaluable catching error something testing randomly data,issue,positive,positive,neutral,neutral,positive,positive
455271354,"Thanks, that's looking far better. Added a few more comments on refactoring possibilities and we should be ready to merge.",thanks looking far better added ready merge,issue,positive,positive,positive,positive,positive,positive
455252887,Used the usual `data_collate` when in this case. Thanks for flagging!,used usual case thanks flagging,issue,negative,negative,neutral,neutral,negative,negative
455242739,"Oh, it must be from before we changed the function. Thanks for flagging and feel free to suggest a PR to amend that!",oh must function thanks flagging feel free suggest amend,issue,positive,positive,positive,positive,positive,positive
455242205,@sgugger Thanks! You might want to update [this](https://github.com/fastai/course-v3/blob/master/nbs/dl1/lesson3-camvid-tiramisu.ipynb) course notebook to include the `print` statement - it's where I pulled that line of code from,thanks might want update course notebook include print statement line code,issue,negative,positive,positive,positive,positive,positive
455238844,"You should print it to have it readable (we prefer fastai functions not to print anything when possible), so the use is `print(learn.summary())`.
As for text learners, you will have to ask the author of `model_summary` on the [forum](https://forums.fast.ai/t/model-summary-implementation/31193).",print readable prefer print anything possible use print text ask author forum,issue,negative,neutral,neutral,neutral,neutral,neutral
455206214,"Ok, I made the requested changes, also edited the documentation notebook accordingly. Thanks!",made also documentation notebook accordingly thanks,issue,negative,positive,positive,positive,positive,positive
454919763,"Possible fix:

```
def bb_pad_collate(samples:BatchSamples, pad_idx:int=0) -> Tuple[FloatTensor, Tuple[LongTensor, LongTensor]]:
    ""Function that collect `samples` of labelled bboxes and adds padding with `pad_idx`.""
    # Find max number of objects in a sample, 0 if no bbox/label info
    max_len = max([0 if s[1] == 0 else len(s[1].data[1]) for s in samples])
    bboxes = torch.zeros(len(samples), max_len, 4)
    labels = torch.zeros(len(samples), max_len).long() + pad_idx
    imgs = []
    for i,s in enumerate(samples):
        imgs.append(s[0].data[None])
        # Are we doing inference?
        if s[1] != 0:
            bbs, lbls = s[1].data
            bboxes[i,-len(lbls):] = bbs
            labels[i,-len(lbls):] = tensor(lbls)
    return torch.cat(imgs,0), (bboxes,labels)
```",possible fix function collect padding find number sample else enumerate none inference tensor return,issue,negative,neutral,neutral,neutral,neutral,neutral
454914649,"I'll review the tests later, for now I'd like us to refactor and clean up the main bit.",review later like u clean main bit,issue,positive,positive,positive,positive,positive,positive
454565026,Very happy to be helping out in a small way.,happy helping small way,issue,positive,positive,positive,positive,positive,positive
454561789,"All is well. I'm just still sorting out how to with github PRs w/o using its online interface.

Everything has been merged.

Thank you for sorting it out and very importantly the test that tests this improvement, @bfarzin ",well still interface everything thank importantly test improvement,issue,positive,positive,positive,positive,positive,positive
454556394,"hmm, looks like I messed something up bypassing the github interface and merging from shell. Give me a few minutes to sort it out.",like something interface shell give sort,issue,negative,neutral,neutral,neutral,neutral,neutral
454553942,"Well, my emacs is set to remove any extraneous spaces, and adding new lines at the end of the file. I don't think the other developers have that, but their editors aren't set to add empty whitespace, so these occasionally leak into the code here and there.

I usually try to make a separate commit when I see a lot of non-code-related changes happen, so it's easy to see the actual code change.

Also, your PR got out of sync and needed a merge, so that was my last commit I pushed into this PR.

Just waiting on CI's confirmation and will merge then.",well set remove extraneous new end file think set add empty occasionally leak code usually try make separate commit see lot happen easy see actual code change also got sync merge last commit waiting confirmation merge,issue,positive,positive,neutral,neutral,positive,positive
454545902,"in your last commit you're trying to call .exists on a string, so it fails, give me a few minutes to sort it out.
```
fname = datapath4file(f'{url2name(url)}.tgz')
```
fixes it.

And also getting a lot of trailing whitespace, is your editor configured to insert whitespace at the end of the lines?",last commit trying call string give sort also getting lot trailing editor insert end,issue,negative,neutral,neutral,neutral,neutral,neutral
454391082,"I will remove the `save_notebook()` call.  I agree, it should be everywhere or nowhere.  
And I will address the user config rather than default for the data directory.  Be back with a new PR very soon.",remove call agree everywhere nowhere address user rather default data directory back new soon,issue,negative,positive,neutral,neutral,positive,positive
454256769,"Hey, thanks for the pull request! 

You might want to look at #1382 (or lookup `fastai.widgets.image_downloader`), and see if there's a good way to make those two play together? ",hey thanks pull request might want look see good way make two play together,issue,positive,positive,positive,positive,positive,positive
454182113,"I'm not sure this PR should add `IPython.notebook.save_notebook()` - we either need to add it to all docs, or none. This is unrelated to the issue this PR is fixing.

Looking good otherwise, with the only minor tweak required is that the location of `~/.fastai/data` is user configurable, so it should report the actual user configuration and not the default.",sure add either need add none unrelated issue fixing looking good otherwise minor tweak location user report actual user configuration default,issue,positive,positive,positive,positive,positive,positive
454161664,I will try to come up with a reproducible example to help debug the actual problem.,try come reproducible example help actual problem,issue,negative,neutral,neutral,neutral,neutral,neutral
454037449,"On further investigation, the error came while building a warning for the user, I just added the labeling class to it.",investigation error came building warning user added class,issue,negative,neutral,neutral,neutral,neutral,neutral
454033128,"Changed for the first point. For the second, I'd need more details and a reproducible bug, thanks!",first point second need reproducible bug thanks,issue,negative,positive,positive,positive,positive,positive
454028002,"Thanks!

Le lun. 14 janv. 2019 à 15:34, Sylvain Gugger <notifications@github.com> a
écrit :

> Closed #1466 <https://github.com/fastai/fastai/issues/1466> via 896f0fb
> <https://github.com/fastai/fastai/commit/896f0fbbf2f588be84180cd4916f814a738c194d>
> .
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/1466#event-2071918803>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AEtv1kyH5fe1PQUEfFb2bOYURJSESGcEks5vDJVygaJpZM4Z9_Vf>
> .
>
",thanks closed via thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
454025692,This may be linked to Windows 7. Did you try it on another machine?,may linked try another machine,issue,negative,neutral,neutral,neutral,neutral,neutral
454024961,"Done. Note that if you don't want to split your data, you should use `no_split`.",done note want split data use,issue,negative,neutral,neutral,neutral,neutral,neutral
453887744,"> how did you solve that? @cindyll00

modify code like this:

rnn_enc = RNN_Encoder(n_tok, em_sz, nhid=nhid, nlayers=nlayers, pad_token=pad_token,
",solve modify code like,issue,positive,neutral,neutral,neutral,neutral,neutral
453876852,"Not sure what you expected to get, `one_item` is a convenience method to replace the content of the dataset by what you pass for predicting a single item.
If you want to look at some elements, it's `data.train_ds[0]` (or valid_ds), the dataloaders are `data.train_dl` and `data.valid_dl`.",sure get convenience method replace content pas single item want look,issue,negative,positive,positive,positive,positive,positive
453860316,"Fixed 1, I forgot to adapt when we moved to batch first. For 2, the paper mentions the L2 norm (which is a mean) and the authors' implementation uses the mean too: https://github.com/salesforce/awd-lstm-lm/blob/32fcb42562aeb5c7e6c9dec3f2a3baaaf68a5cb5/main.py#L201 so I'm leaving it as is.
For 3, I removed the adjust parameter since we're now using a constant bptt (we shuffle the texts at each epoch so it doesn't help anymore).

The correct behavior with padding would be a great addition if it's not slower (there has been an attempt, but it was really slower).
",fixed forgot adapt batch first paper norm mean implementation mean leaving removed adjust parameter since constant shuffle epoch help correct behavior padding would great addition attempt really,issue,positive,positive,positive,positive,positive,positive
453857216,"Thanks, I believe you wanted to pass **params and not **kwargs, and I refactored a little bit.",thanks believe pas little bit,issue,negative,positive,neutral,neutral,positive,positive
453851221,"Thanks. I did this:
```
class ImageNpList(ImageItemList):
    def __init__(self, items, **kwargs):
        super().__init__(items, **kwargs)
    
    def new(self, items, **kwargs):
        return super().new(items, **kwargs)
    
    def get(self, i):
        return Image(Tensor(self.items[i]))
    
    def reconstruct(self, t:Tensor): 
        return Image(t)

data = ImageNpList(ix).random_split_by_pct().label_from_list(yc).transform().databunch()
```
but when I do `data.one_item(0)` I get:

`(tensor([0], device='cuda:0'), tensor([0], device='cuda:0'))`

Any ideas?",thanks class self super new self return super get self return image tensor reconstruct self tensor return image data get tensor tensor,issue,positive,positive,positive,positive,positive,positive
453848172,"Hi again,

After running more tests, I realised that I have another torch version install (torch-nightly) and it was causing the error.

torch version 0.3.1 the other dependencies install with pip install fastai==0.7.0 works without error.
I'm sorry for the false alarm.

Regards",hi running another torch version install causing error torch version install pip install work without error sorry false alarm,issue,negative,negative,negative,negative,negative,negative
453835123,"Yes it doesn't work. This is fully documented [here](https://docs.fast.ai/basic_data.html#Using-a-custom-Dataset-in-fastai). If you aren't using a fastai Dataset, don't expect the library to fully work.
You should use the [data block API](https://docs.fast.ai/data_block.html) and [build your custom `ItemList`](https://docs.fast.ai/tutorial.itemlist.html) if you want the full range of possibility of the library.",yes work fully expect library fully work use data block build custom want full range possibility library,issue,negative,positive,positive,positive,positive,positive
453834910,"It's impossible to help you if you don't post your full code. It's looking like an installation issue, so it would be best to go on the [forum](https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111).",impossible help post full code looking like installation issue would best go forum,issue,positive,positive,positive,positive,positive,positive
453814847,"I've tried to address the issues. I think now the `create_cnn` should look better. How do you think, should we change anything else? Are these changes are still relevant to the library? Also, I've included the following test:
```python
@pytest.mark.slow
@pytest.mark.parametrize('arch', [models.resnet18, models.squeezenet1_1])
def test_models_meta(mnist_tiny, arch, zero_image):
    learn = create_cnn(mnist_tiny, arch, metrics=[accuracy, error_rate])
    pred = learn.predict(zero_image)
    assert pred is not None
```
Note the last line. I am not really sure what to assert here so I am just making sure that the output is not `None`. The main goal of this test is to make sure that architectures are instantiated correctly. Actually, the test has passed if we just don't get any exception so it could be `assert True` as well.",tried address think look better think change anything else still relevant library also included following test python arch learn arch accuracy assert none note last line really sure assert making sure output none main goal test make sure correctly actually test get exception could assert true well,issue,positive,positive,positive,positive,positive,positive
453777323,"@sgugger I thought it would be helpful to see the function signature right there; I now see how that could be confusing.
@stas00 Thank you for pointing out the error that is on my side.  I will post in the forum on how this occured.  I have fixed and will re-submit PR  Thank you so much for your patience and help with resolving this!  I learned a lot and will not make this error again.
",thought would helpful see function signature right see could thank pointing error side post forum fixed thank much patience help learned lot make error,issue,positive,positive,positive,positive,positive,positive
453769141,"Hi, 
Thank you for the feedback.

I have followed the instructions on 
https://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652 to install fast.ai for the course:
pip install fastai==0.7.0
pip install torchtext==0.2.3
Which installs torch 0.3.1
And I now have the following error:
module 'torch.nn.init' has no attribute 'kaiming_normal_
as in this thread:
https://forums.fast.ai/t/attributeerror-module-torch-nn-init-has-no-attribute-kaiming-normal/29278

With the patch I proposed everything seemed to run fine, what would you recommend? I can run more tests if needed.

Regards",hi thank feedback install course pip install pip install torch following error module attribute thread patch everything run fine would recommend run,issue,negative,positive,positive,positive,positive,positive
453764685,"> I no longer see this problem on my local version. All tests pass for me in the `docs_src` and the `make test`
> Are you testing on your local system? Could it be that you have a Numpy difference/conflict there?
> How can I replicate the error you are seeing? (I will post on the dev forum also, hoping to get some more input)

It's not on my system, but yours: It's in your commit, see:
https://github.com/fastai/fastai/pull/1457/commits/7b1a79665d05655ddc66f2013ef3d42bf2695d39",longer see problem local version pas make test testing local system could replicate error seeing post dev forum also get input system commit see,issue,negative,neutral,neutral,neutral,neutral,neutral
453761248,Thanks for looking into this! I’ll try to do some testing to see if your fix resolves the error I was getting. ,thanks looking try testing see fix error getting,issue,negative,positive,positive,positive,positive,positive
453760198,"agree, tests are not yet perfect. lets call it incremental ;-)

Will look at your comments",agree yet perfect call incremental look,issue,positive,positive,positive,positive,positive,positive
453750839,"Note that those lessons are supposed to be used with fastai 0.7 and torch 0.3, it doesn't support torch 1.0. fastai v1 and the third version of the MOOC (to be released soon) do.",note supposed used torch support torch third version soon,issue,negative,neutral,neutral,neutral,neutral,neutral
453750641,"Thanks for your PR. Concerning the tests for fit_one_cycle and lr_find, can we had a little bit more to check the learning rates (and momentums for 1cycle) behaved properly? For now you just test the output which doesn't tell us if everything went well or not.",thanks concerning little bit check learning cycle properly test output tell u everything went well,issue,positive,positive,neutral,neutral,positive,positive
453750434,"Thanks. Why are you using help? The documentation of the functions is shown with the command `show_doc(func_name)` in a hidden cell. I'd remove the three corresponding cells.
All the examples seem pretty good, otherwise.",thanks help documentation shown command hidden cell remove three corresponding seem pretty good otherwise,issue,positive,positive,positive,positive,positive,positive
453744687,"I no longer see this problem on my local version.  All tests pass for me in the `docs_src` and the `make test`
Are you testing on your local system?  Could it be that you have a Numpy difference/conflict there?
How can I replicate the error you are seeing? (I will post on the dev forum also, hoping to get some more input)",longer see problem local version pas make test testing local system could replicate error seeing post dev forum also get input,issue,negative,neutral,neutral,neutral,neutral,neutral
453721784,"The numpy issue (https://github.com/fastai/fastai/pull/1448#issuecomment-453265239) is still there, please have a look at the diff.   

which of these 2 generates this?
```
from fastai.gen_doc.nbdoc import *
from fastai.core import *
```

and perhaps go into the imports and try to reduce it to a small code sample that reproduces the problem?

And until then perhaps manually remove that error cell via editor, so that your PR could be merged and we can continue sorting out the numpy issue in parallel. Probably again take it to the forums dev chat probably would fit the best: https://forums.fast.ai/t/developer-chat/22363/625",issue still please look import import perhaps go try reduce small code sample problem perhaps manually remove error cell via editor could continue issue parallel probably take dev chat probably would fit best,issue,positive,positive,positive,positive,positive,positive
453663808,"Thank you for the report. I will investigate and follow up there. 

FYI, I split the 2nd part of your post to https://forums.fast.ai/t/developer-chat/22363/623 where it belongs as it's not an install issue.",thank report investigate follow split part post install issue,issue,negative,neutral,neutral,neutral,neutral,neutral
453657345,"I posted to that thread and now have a version that passes all tests.  
I will submit a new PR passing all the tests.  Not sure how you want to handle the details about the latest install and conflict between Bottleneck and Numpy, but if there is a way I can help with that I am happy to do it. 

",posted thread version submit new passing sure want handle latest install conflict bottleneck way help happy,issue,positive,positive,positive,positive,positive,positive
453626104,"The same thread further down suggests to install the latest numpy 1.16.0rc1 to solve the numpy issue
https://forums.fast.ai/t/productionizing-models-thread/28353/83
I looked through some similar reports, there is quite a flurry of those on github in the last few weeks. But none give a definitive way.

Why are you trying to download http://files.fast.ai/data/examples/coco_tiny? The url is:
http://files.fast.ai/data/examples/coco_tiny.tgz
I just removed `~/.fastai/data/coco_tiny.tgz` and `~/.fastai/data/coco_tiny` and when I run:

```
pytest tests/test_vision_data.py
```
it downloads it just fine and the test suceeds. 

Yes, let's close this, and continue over at: https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111/261 so it may benefit others down the road. And once we sort out your setup then do another PR if this plan is agreeable with you, @bfarzin.

and please post show_install output there so we know more about your env. https://docs.fast.ai/support.html",thread install latest solve issue similar quite flurry last none give definitive way trying removed run fine test yes let close continue may benefit road sort setup another plan agreeable please post output know,issue,positive,positive,positive,positive,positive,positive
453612944,"If you have any concrete ideas I can try making a PR. My time is a bit.. unstable, but I want to help, and it might be good to get my hands dirty with something simple.",concrete try making time bit unstable want help might good get dirty something simple,issue,negative,positive,neutral,neutral,positive,positive
453605007,"I just pushed a fix but I'm not too sure it will work since I don't have the bug and your code snippet doesn't reproduce it for me. Thinking it comes from pytorch that doesn't want to give a length to tensors with only a scalar, so I put labels as numpy arrays.",fix sure work since bug code snippet reproduce thinking come want give length scalar put,issue,negative,positive,positive,positive,positive,positive
453600800,"I have been think that it would be better to move all graphics to a separate graphics module with sub- modules like :
.general confusion matrix etc
.text
.vision
..
that would make it easier to use different graphic libraries. I do admit though that the bulding has a convinving simplicityt to it for first time users 
just a thought?",think would better move graphic separate graphic module like confusion matrix would make easier use different graphic admit though first time thought,issue,positive,positive,positive,positive,positive,positive
453590484,Thanks for flagging! I also added a test so that we see if regression suddenly fails in the future.,thanks flagging also added test see regression suddenly future,issue,negative,positive,neutral,neutral,positive,positive
453579739,"`error_rate` can't work for multi-classification problems, that's the whole source of the error.",ca work whole source error,issue,negative,positive,positive,positive,positive,positive
453577649,This fails in the case of multi-classification since the target is then an array (and not just a tensor). Working on another fix.,case since target array tensor working another fix,issue,negative,neutral,neutral,neutral,neutral,neutral
453575412,"From [this forum post](https://forums.fast.ai/t/productionizing-models-thread/28353/78), I found that rolling back Bottleneck version worked.
`pip install Bottleneck==1.2.0`

I still have failing tests.  And I think that is associated (strangely) with a bad URL:

```
>                   raise ReadError(""empty file"")
E                   tarfile.ReadError: empty file

../../anaconda3/envs/fai_v1_dev/lib/python3.7/tarfile.py:2304: ReadError
========================== 6 failed, 171 passed, 7 skipped, 4 xfailed in 114.05 seconds ==========================
Makefile:169: recipe for target 'test' failed
make: *** [test] Error 1
```
when I try to `curl` to the URL, I get this:

```
farzin@lincoln:~/fast_ai/fastai-fork/tests$ curl http://files.fast.ai/data/examples/coco_tiny
<!DOCTYPE HTML PUBLIC ""-//IETF//DTD HTML 2.0//EN"">
<html><head>
<title>404 Not Found</title>
</head><body>
<h1>Not Found</h1>
<p>The requested URL /data/examples/coco_tiny was not found on this server.</p>
<p>Additionally, a 404 Not Found
error was encountered while trying to use an ErrorDocument to handle the request.</p>
</body></html>
```

This is what I am seeing as failing tests:
```
(fai_v1_dev) farzin@lincoln:~/fast_ai/fastai-fork$ make test
python setup.py --quiet test
warning: no files found matching 'HISTORY.md'
warning: no previously-included files matching '__pycache__' found under directory '*'
warning: no files found matching 'conf.py' under directory 'docs'
warning: no files found matching 'Makefile' under directory 'docs'
warning: no files found matching 'make.bat' under directory 'docs'
============================================== test session starts ===============================================
platform linux -- Python 3.7.1, pytest-4.1.0, py-1.7.0, pluggy-0.8.1
rootdir: /home/farzin/fast_ai/fastai-fork, inifile: setup.cfg
collected 188 items                                                                                              

tests/test_basic_data.py ....                                                                              [  2%]
tests/test_batchnom_issue_minimal.py s.                                                                    [  3%]
tests/test_callback_fp16.py ...                                                                            [  4%]
tests/test_callbacks_csv_logger.py .                                                                       [  5%]
tests/test_callbacks_hooks.py .x....                                                                       [  8%]
tests/test_collab_train.py .                                                                               [  9%]
tests/test_core.py ...............................                                                         [ 25%]
tests/test_data_block.py ........                                                                          [ 29%]
tests/test_datasets.py .                                                                                   [ 30%]
tests/test_metrics.py ...............                                                                      [ 38%]
tests/test_tabular_train.py .....                                                                          [ 40%]
tests/test_tabular_transform.py ....                                                                       [ 43%]
tests/test_text_data.py ........                                                                           [ 47%]
tests/test_text_train.py ..ss..s.                                                                          [ 51%]
tests/test_text_transform.py ..                                                                            [ 52%]
tests/test_torch_core.py ...............                                                                   [ 60%]
tests/test_utils.py ..                                                                                     [ 61%]
tests/test_utils_fastai.py .                                                                               [ 62%]
tests/test_utils_links.py s........s.                                                                      [ 68%]
tests/test_utils_mem.py ....                                                                               [ 70%]
tests/test_utils_mod_independency.py .s                                                                    [ 71%]
tests/test_vision_data.py .............FFFF.F.F...                                                         [ 84%]
tests/test_vision_image.py ........                                                                        [ 88%]
tests/test_vision_train.py .........x                                                                      [ 93%]
tests/test_vision_transform.py ........                                                                    [ 97%]
tests/test_widgets_image_cleaner.py x.x.                                                                   [100%]

==================================================== FAILURES ====================================================
___________________________________________________ test_multi ___________________________________________________
```
",forum post found rolling back bottleneck version worked pip install still failing think associated strangely bad raise empty file empty file recipe target make test error try curl get curl public head title found body found found additionally found error trying use handle seeing failing make test python quiet test warning found matching warning matching found directory warning found matching directory warning found matching directory warning found matching directory test session platform python collected,issue,negative,negative,negative,negative,negative,negative
453575262,"Googling its name might help to begin with: https://www.cs.toronto.edu/~kriz/cifar.html. Also there is a helper function in fastai that will download it for you:
`untar_data(URLs.CIFAR)`",name might help begin also helper function,issue,positive,neutral,neutral,neutral,neutral,neutral
453566478,"No problem, we will figure it out from here.  Not sure this is the best place to debug this, please advise if I should move this discussion about install problems to the fasta.ai forums.

I could not recover my environment that was working.  I started a new conda environment that is clean and went into my fork of the repo:

```
$conda create --name fai_v1_dev python=3.7
$conda activate fai_v1_dev
$pip install -e "".[dev]""
```
Then to test out, I tried:
`jupyter nbconvert --execute --ExecutePreprocessor.timeout=600 --to notebook examples/tabular.ipynb`

That fails with:
```
from fastai.tabular import *  # Quick accesss to tabular functionality
------------------

---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
ModuleNotFoundError: No module named 'numpy.core._multiarray_umath'
```

However, I am able to go into a REPL and then import numpy, torch, etc. with no trouble.  Any ideas what is going on here?

```
Python 3.7.1 | packaged by conda-forge | (default, Nov 13 2018, 18:15:35) 
[GCC 4.8.2 20140120 (Red Hat 4.8.2-15)] :: Anaconda, Inc. on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import numpy as np
>>> np.__version__
'1.15.4'
>>> import torch
>>> torch.__version__
'1.0.0'
```",problem figure sure best place please advise move discussion install could recover environment working new environment clean went fork create name activate pip install dev test tried execute notebook import quick tabular functionality recent call last module module however able go import torch trouble going python default red hat anaconda type help copyright license information import import torch,issue,positive,positive,positive,positive,positive,positive
453539016,"Maybe an option here is to print out to the user what the library automatically infers? At least in case of exceptions?

If it did it'd be pretty easy to spot that it's picking a classification problem with a few million classes.",maybe option print user library automatically least case pretty easy spot classification problem million class,issue,positive,positive,positive,positive,positive,positive
453528888,I close this because stas's performance work is probably the best way to progress on these issues ,close performance work probably best way progress,issue,positive,positive,positive,positive,positive,positive
453508083,"Hello, I get the same error even with a simple multilabel classification problem. 
Exactly the same problem described in the fast.ai forum [link ](https://forums.fast.ai/t/error-pytorch-expected-object-of-scalar-type-long-but-got-scalar-type-float-for-argument-2-other/33778) above.

`learn = create_cnn(data=data, arch=models.resnet34, metrics=error_rate)`

If I omit `, metrics=error_rate` I don't get the error, but this couldn't be the solution.",hello get error even simple classification problem exactly problem forum link learn omit get error could solution,issue,negative,positive,positive,positive,positive,positive
453488540,I have tested the fix with  categories target values and it seems to have no side effect and to work,tested fix target side effect work,issue,negative,neutral,neutral,neutral,neutral,neutral
453437391,"Thank you for confirming that only those with commit rights can re-run the tests, @Benudek. Perhaps it'd be a good suggestion for github to allow PR submitters to re-run the tests too. Especially when it's not their fault that the test suite has failed. I hit re-run for this one.

All is good wrt to PRs, I was just sharing how every commit to an existing PR commit sends a notice to all, that's why grouping those together is a goodness. No damage done.",thank confirming commit perhaps good suggestion allow especially fault test suite hit one good every commit commit notice grouping together goodness damage done,issue,positive,positive,positive,positive,positive,positive
453425182,"I do not have option [Rerun all] in the upper left corner.

Yes, I will make larger PRs with less commits next time. It's a learning journey but I want to avoid being a burden of course.
",option rerun upper left corner yes make le next time learning journey want avoid burden course,issue,negative,neutral,neutral,neutral,neutral,neutral
453316406,"we have some non-deterministic tests that fail 1% of the time or so, so if you get 1 out of 6 CIs fail, you can usually pretty safely ignore it. Are you able to trigger a rebuild of the PR on your own or is it only those with commit rights have that option? If you click on the details of failure: https://github.com/fastai/fastai/pull/1453/checks?check_run_id=48690922 Do you have the option [Rerun all] in the upper left corner? I thought that perhaps PR submitters have this option too.

And another suggestion, is to not push so many tiny changes in the PR, or you will quickly start to get ignored - who can look at so many tiny changes. Please work in your own branch and when you have a significant case to review only then make a PR. And if you already made a PR and you plan to do lots of tweaks, close the PR, tweak as much as you would like to and create a new PR when you're ready for review. I hope it makes sense.",fail time get fail usually pretty safely ignore able trigger rebuild commit option click failure option rerun upper left corner thought perhaps option another suggestion push many tiny quickly start get look many tiny please work branch significant case review make already made plan lot close tweak much would like create new ready review hope sense,issue,positive,positive,positive,positive,positive,positive
453314066,"ok, took out the prints, adjusted the assert and with small change in string to fit: I have a working (?) version without -s option. But there seems to be a different error on one kernel:

https://dev.azure.com/fastdotai/fastai/_build/results?buildId=2753

This here: 

> fit and fit_one_cycle are almost identical, so probably the best to test most of their features together and not duplicate the same test in different files. Here is an example:
> https://github.com/fastai/fastai/blob/master/tests/test_callback.py#L65

looks indeed much better, thx for the tip and I logged as to do (next step). Hopefully, if this (not my code?) error is fixed, we can merge this one and I improve this then incrementally starting with following your example code

thx for your help @stas00 more than I can expect  and can learn",took assert small change string fit working version without option different error one kernel fit almost identical probably best test together duplicate test different example indeed much better tip logged next step hopefully code error fixed merge one improve starting following example code help expect learn,issue,positive,positive,positive,positive,positive,positive
453301111,"Oh, very sorry about that. I guess I shouldn't have added -y to the conda uninstall instructions and, of course, conda happily uninstalled everything that depended on numpy. Ouch. Hopefully you still have the log and can just conda install what it uninstalled, which will quickly restore the original state.

`conda uninstall -y numpy --force` would have been a better one to use, which would have uninstalled just that package, but then numpy has a few sub-packages.

Apologies, again.",oh sorry guess added course happily uninstalled everything ouch hopefully still log install uninstalled quickly restore original state force would better one use would uninstalled package,issue,positive,positive,positive,positive,positive,positive
453299843,"I can see that. Your test works fine on my setup too.

* My recommendation is whenever you add an assert you add the last part where you show the expected and received parts you want to make sure are there. In this case we need to see the output to decipher why it behaves differently on CI. Here:
```
assert match_hundperc, f""expecting to find '100%' in output: f{captured.out}
```
and parametrize all strings, so you only need to enter those once

You will definitively need to apply apply_print_resets if you print it out, since there will be a progress bar there. So just as well use CaptureStdout instead of capsys.
* fit and fit_one_cycle are almost identical, so probably the best to test most of their features together and not duplicate the same test in different files. Here is an example: 
https://github.com/fastai/fastai/blob/master/tests/test_callback.py#L65

* and please don't leave debug prints, (at least comment them out), tests' output should be clean by default.
```
print ('a: ' + str(a[1]))
```
and if you follow my first recommendation, the assert will give you the debug printout automatically on failure.",see test work fine setup recommendation whenever add assert add last part show received want make sure case need see output decipher differently assert find output need enter definitively need apply print since progress bar well use instead fit almost identical probably best test together duplicate test different example please leave least comment output clean default print follow first recommendation assert give automatically failure,issue,positive,positive,positive,positive,positive,positive
453294625,"@stas00 this below line fails, even though locally it works.

pytest tests/test_train.py -s

this way, without the s

pytest tests/test_train.py

Fails locally too

so, I suppose with your new class, should solve it: https://github.com/fastai/fastai/blob/master/tests/utils/text.py#L18

thx

2019-01-10T23:09:37.7319000Z         match_hundperc = re.findall(r'100.00%', captured.out) ## finds 100% progress
2019-01-10T23:09:37.7319120Z >       assert match_hundperc",line even though locally work way without locally suppose new class solve progress assert,issue,positive,positive,neutral,neutral,positive,positive
453294211,"the uninstall seems to have broken everything on my side.  let me try a fresh environment with the latest dev release, then copy the file over and see if my tests still fail.
FYI, numpy was 1.15.0 version.
",broken everything side let try fresh environment latest dev release copy file see still fail version,issue,negative,negative,neutral,neutral,negative,negative
453292322,"@stas00 this works locally. There was an error (not sure why) in previous branch on the asserts over UI in the azure pipelines with all tests


",work locally error sure previous branch azure,issue,negative,positive,positive,positive,positive,positive
453287512,"True, we just don't need ""harmless"" warnings in the documentation. It's possible that you identified a bug though in the code. That's the difficulty with writing documentation and tests, often these efforts lead to a lot more work, as inconsistencies and bugs get uncovered.

Which test is it coming from?

I've just retested the fastai test suite w/ py3.7.1 - no warnings were emitted. But I do remember seeing some warning in the past. 

As @mattip kindly shared, perhaps try:

```
pip uninstall -y numpy
pip uninstall -y numpy # 2nd time in case you also had ""-e ."" install
conda uninstall -y numpy
```
and then install just one of them? (if that's the culprit)

Otherwise, please help us to reproduce the warning, then we can fix it.",true need harmless documentation possible bug though code difficulty writing documentation often lead lot work get uncovered test coming test suite remember seeing warning past kindly perhaps try pip pip time case also install install one culprit otherwise please help u reproduce warning fix,issue,positive,positive,positive,positive,positive,positive
453285097,"I think the problem is coming from tarfile.py but I am really not sure.  I feel a bit out of place commenting on this.  How can I determine the source or the error?

```
../../anaconda3/envs/fastaiv1_dev/lib/python3.7/tarfile.py:2302: ReadError
=============================== warnings summary ===============================
/home/farzin/anaconda3/envs/fastaiv1_dev/lib/python3.7/importlib/_bootstrap.py:219
  /home/farzin/anaconda3/envs/fastaiv1_dev/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
    return f(*args, **kwds)

-- Docs: https://docs.pytest.org/en/latest/warnings.html
=== 6 failed, 171 passed, 7 skipped, 4 xfailed, 1 warnings in 198.01 seconds ===
Makefile:169: recipe for target 'test' failed
make: *** [test] Error 1

```
",think problem coming really sure feel bit place determine source error summary size may indicate binary incompatibility got return recipe target make test error,issue,negative,positive,positive,positive,positive,positive
453277595,"@stas00 adjusted to utils.fakes import * 

Seems some error with screen output, works locally though. I will close this PR and check with your suggestion: https://github.com/fastai/fastai/blob/master/tests/utils/text.py#L18",import error screen output work locally though close check suggestion,issue,negative,neutral,neutral,neutral,neutral,neutral
453276094,"Hi. NumPy developer here, come to comment about the ""changed size"" warning. This happens when you have cythonized files with one version of NumPy, but at runtime are using another, later version of NumPy. Which library is emitting the warning? Does it have generated C files or binary shared objects from Cython checked into the repository? It would seem this is the case, since Cython 0.29 and up print a slightly different error `size changed, may indicate binary incompatibility. Expected %zd from C header, got %zd from PyObject`",hi developer come comment size warning one version another later version library warning binary checked repository would seem case since print slightly different error size may indicate binary incompatibility header got,issue,negative,neutral,neutral,neutral,neutral,neutral
453266510,"Thank you for pointing this out.  I am still new to PRs. How do I debug this?
When I google the error, it seems to indicate this type of error is ""harmless"" but I don't want to ignore something that would cause a problem.
https://github.com/numpy/numpy/issues/11788
",thank pointing still new error indicate type error harmless want ignore something would cause problem,issue,negative,positive,positive,positive,positive,positive
453265239,"FYI, your pr includes errors, e.g.:

""/home/farzin/anaconda3/envs/fastaiv1_dev/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n"",",size may indicate binary incompatibility got,issue,negative,neutral,neutral,neutral,neutral,neutral
453264376,please note fakes moved to tests/utils/fakes.py so please adjust the import to utils.fakes thanks.,please note please adjust import thanks,issue,positive,positive,positive,positive,positive,positive
453217686,"I'll look at the latest tonight.

I think it may also be related to the processing code running on GPU #0
even though I've told pytorch to use GPU #1 ... and that it may be related
to their not being enough GPU memory on #0 (its actually used by another
developer).  I would have expected an OOM error in that case, but I may be
wrong.

See:
https://forums.fast.ai/t/gpu-leakage-when-training-lm-or-text-classification-models/34553?u=wgpubs

Thanks

On Thu, Jan 10, 2019 at 6:40 AM Sylvain Gugger <notifications@github.com>
wrote:

> I pushed a tentative fix by casting the texts to str before processing
> them, but without a reproducible example, I can't be sure it will work.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/1449#issuecomment-453118338>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAA2sMr1-M-_AXLS0YIG_PKFKh-JBz7Oks5vB1D6gaJpZM4Z4nuR>
> .
>
",look latest tonight think may also related code running even though told use may related enough memory actually used another developer would error case may wrong see thanks wrote tentative fix casting without reproducible example ca sure work thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
453185064,@sgugger Thank you for your help! I didn't have my data in correct format. Anywhere can I look at the documentation about text_cols and lable_cols? ,thank help data correct format anywhere look documentation,issue,positive,neutral,neutral,neutral,neutral,neutral
453161096,"I'm not sure what the issue is. The factory methods are very basic way to quickly get started for beginner in classification problems, so don't expect them to work all the time. For the highest flexibility, you should use the data block API where you can force the library to acknowledge this is a regression problem by passing `label_cls=FloatList`.

With the factory method, the library tries its best to guess what the problem is, which is why you have no problem when casting your target to float (on master, there were bugs recently corrected). If the target is an int, the default is classification and it won't change.",sure issue factory basic way quickly get beginner classification expect work time highest flexibility use data block force library acknowledge regression problem passing factory method library best guess problem problem casting target float master recently corrected target default classification wo change,issue,negative,positive,positive,positive,positive,positive
453150466,"Having problems reproducing this, will do another round from disk just to ensure my report isn't incorrect...

//edit, updated description. Cast order was incorrect. Casting from int64 -> float makes it work in git head.",another round disk ensure report incorrect description cast order incorrect casting float work git head,issue,negative,negative,negative,negative,negative,negative
453118338,"I pushed a tentative fix by casting the texts to str before processing them, but without a reproducible example, I can't be sure it will work.",tentative fix casting without reproducible example ca sure work,issue,negative,positive,positive,positive,positive,positive
453105485,"```
import fastai
fastai.torch_core.defaults.device = torch.device('cuda',1)
defaults.device
```
Will set the default for this session and then allow you to use just that single GPU for training and `LR_find()`
Does this resolve the issue, or after setting this you still find that you use both GPUs?
",import set default session allow use single training resolve issue setting still find use,issue,positive,negative,neutral,neutral,negative,negative
453097557,Will you post a complete example that replicates this error so we can further debug it?,post complete example error,issue,negative,positive,neutral,neutral,positive,positive
452849062,"Please try to follow the guidelines to file an issue, there is nothing we can do without knowing which version of fastai you're using, or with a minimal reproducible example. This error is generic in multiprocessing, you should try without the multiprocessing to get an error message more understandable.",please try follow file issue nothing without knowing version minimal reproducible example error generic try without get error message understandable,issue,negative,negative,neutral,neutral,negative,negative
452848427,"This specific bug has been fixed in master already. For the second one (the error with _th_cat not implement for half tensors), you should put your learner back to FP32 before using TTA (with learn = learn.to_fp32()).",specific bug fixed master already second one error implement half put learner back learn,issue,negative,negative,neutral,neutral,negative,negative
452722932,Just one note: the function had been renamed `flatten_model` so I changed a little bit your notebook to reflect this.,one note function little bit notebook reflect,issue,negative,negative,negative,negative,negative,negative
452688046,"Thanks! If you properly ran tools/run-after-git-clone, the stripping should be done automatically from now on.",thanks properly ran stripping done automatically,issue,negative,positive,neutral,neutral,positive,positive
452578068,"Alright I think I fixed it, fixed the keyboard interrupt and moved the undocumented functions in the hidden section.

Most of them are for image cleaner. I’ll open an issue for Francisco and if his busy, I’ll write some docs in the weekend. Would that be ok?

On Mon, Jan 7 2019 at 10:01 PM, Nate Gadzhibalaev < nate@respawn.io > wrote:

> 
> 
> Sorry for the delay, yep, I’ll clean things up and commit on Tuesday.
> 
> 
> 
> On Fri, Jan 4 2019 at 1:43 PM, < notifications@github.com > wrote:
> 
>> 
>> 
>> I have an output error in the cell after learn.fit_one_cycle(3) (keyboard
>> interrupt, not the end of the word, but if you could commit a clean file,
>> it'd be best).
>> Also, the cell with show_doc doesn't seem to be hidden (it may be nbdiff
>> not catching it though).
>> 
>> 
>> 
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub (
>> https://github.com/fastai/fastai/pull/1427#issuecomment-451577274 ) , or mute
>> the thread (
>> https://github.com/notifications/unsubscribe-auth/AACqcSFZuX6jwg49lWN0YyeXOV7aPq8iks5u_8sTgaJpZM4ZpESX
>> ).
>> 
>> 
>> 
> 
>",alright think fixed fixed keyboard interrupt undocumented hidden section image cleaner open issue busy write weekend would mon wrote sorry delay yep clean commit wrote output error cell keyboard interrupt end word could commit clean file best also cell seem hidden may catching though thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
452512083,"> If you didn't do the setup correctly right away before committing, and enabled local .gitconfig afterwards, you need to repair the committed nb first:
> https://docs.fast.ai/dev/develop.html#unstripped-notebook-repair

I did the run-after-git-clone step months ago to set the proper permissions, which is why I am surprised. I will go ahead and do the repair though and see if the problem persists afterwards. ",setup correctly right away local afterwards need repair first step ago set proper go ahead repair though see problem afterwards,issue,negative,positive,positive,positive,positive,positive
452510796,"If you didn't do the setup correctly right away before committing, and enabled local .gitconfig afterwards, you need to repair the committed nb first:
https://docs.fast.ai/dev/develop.html#unstripped-notebook-repair
",setup correctly right away local afterwards need repair first,issue,negative,positive,positive,positive,positive,positive
452510007,"> https://docs.fast.ai/dev/develop.html#things-to-run-after-git-clone

I already seem to have the correct entries in my .git/config file. Will update if I find anything that looks amiss. ",already seem correct file update find anything amiss,issue,negative,neutral,neutral,neutral,neutral,neutral
452506822,"Seems there was some issue with ""unstripped out notebook commits."" Looking through the build pipeline to see what went wrong. ",issue unstripped notebook looking build pipeline see went wrong,issue,negative,negative,negative,negative,negative,negative
452436436,"I just dug into the code, and it looks like my past self had already foreseen we'd need to pass this. There is no need to subclass `PointsItemList`, it's inside your transform call: normally
```
.transform(get_transforms(), tfm_y=True, size=(120,160), remove_out=False)
```
should work. Please let me know if it does!",dug code like past self already need pas need subclass inside transform call normally work please let know,issue,positive,negative,neutral,neutral,negative,negative
452302168,"> Your fastai version is several months old, @CaesarLuvAI
> 
> Please follow the instructions at https://github.com/fastai/fastai#installation and make sure you're running the latest version: 1.0.39 as of this writing.
> 
> If after installing the latest version you have a problem still please refer to [this](http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111)

thank u for your attention  i tried but failed to update my fastai perhaps because i am on windows,it remains 1.0.6",version several old please follow make sure running latest version writing latest version problem still please refer thank attention tried update perhaps remains,issue,positive,positive,positive,positive,positive,positive
452287958,"Yes, it's linked to tabular data and the model requiring a list of inputs (and not just one input). Will fix soon.",yes linked tabular data model list one input fix soon,issue,negative,neutral,neutral,neutral,neutral,neutral
452287667,"No, this is standard python module structure. When importing a module in the same directory, it's always 
.{module_name}",standard python module structure module directory always,issue,negative,neutral,neutral,neutral,neutral,neutral
452286952,"It seems the model didn't download properly, it should be in your home directory/.fastai/models/wt103 (or something like that). Remove the files wt103.tgz and the wt103 directory to trigger a new download.",model properly home something like remove directory trigger new,issue,negative,positive,neutral,neutral,positive,positive
452185371,"Sorry for the delay, yep, I’ll clean things up and commit on Tuesday.

On Fri, Jan 4 2019 at 1:43 PM, < notifications@github.com > wrote:

> 
> 
> 
> I have an output error in the cell after learn.fit_one_cycle(3) (keyboard
> interrupt, not the end of the word, but if you could commit a clean file,
> it'd be best).
> Also, the cell with show_doc doesn't seem to be hidden (it may be nbdiff
> not catching it though).
> 
> 
> 
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub (
> https://github.com/fastai/fastai/pull/1427#issuecomment-451577274 ) , or mute
> the thread (
> https://github.com/notifications/unsubscribe-auth/AACqcSFZuX6jwg49lWN0YyeXOV7aPq8iks5u_8sTgaJpZM4ZpESX
> ).
> 
> 
>",sorry delay yep clean commit wrote output error cell keyboard interrupt end word could commit clean file best also cell seem hidden may catching though thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
452182855,"Your fastai version is several months old, @CaesarLuvAI 

Please follow the instructions at https://github.com/fastai/fastai#installation and make sure you're running the latest version: 1.0.39 as of this writing.

If after installing the latest version you have a problem still please refer to [this](http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111) 


",version several old please follow make sure running latest version writing latest version problem still please refer,issue,negative,positive,positive,positive,positive,positive
451948848,"> What is this ""Quick Start: Training an IMDb sentiment model with ULMFiT"", could you link to the file?
> The line you're quoting doesn't exist in the fastai library (v1), are you sure you aren't trying to use the old version of the library? Could you show us the result of
> 
> ```
> from fastai.utils.show_install import *
> show_install()
> ```

thank u sir for your reply, i tried your code 'from fastai.utils.show_install import *
show_install()', but sadly it reported no module named fastai.utils.show_ and its version is 1.0.6 . And here is the link where i follow the tutorial : https://docs.fast.ai/text.html, i am truly looking forward to your help",quick start training sentiment model could link file line exist library sure trying use old version library could show u result import thank sir reply tried code import sadly module version link follow tutorial truly looking forward help,issue,positive,positive,positive,positive,positive,positive
451776702,"What is this ""Quick Start: Training an IMDb sentiment model with ULMFiT"", could you link to the file?
The line you're quoting doesn't exist in the fastai library (v1), are you sure you aren't trying to use the old version of the library? Could you show us the result of
```
from fastai.utils.show_install import *
show_install()
```
",quick start training sentiment model could link file line exist library sure trying use old version library could show u result import,issue,negative,positive,positive,positive,positive,positive
451707418,"I am getting this error while predicting with ds_type=DatasetType.Test, prediction on train and validation set is working fine. ",getting error prediction train validation set working fine,issue,negative,positive,positive,positive,positive,positive
451674967,"import fastai
fastai.__version__ 
>> '1.0.40.dev0'
torch.__version__
'1.0.0.dev20190103'

I'm playing with the Microsoft Malware prediction dataset 
[https://www.kaggle.com/c/microsoft-malware-prediction](url) 
I selected these fields for my model 
as part of the cat_names
['EngineVersion',
 'AppVersion',
 'AvSigVersion',
 'IsSxsPassiveMode',
 'AVProductStatesIdentifier',
 'AVProductsInstalled',
 'HasTpm',
 'CountryIdentifier',
 'OrganizationIdentifier',
 'GeoNameIdentifier',
 'LocaleEnglishNameIdentifier',
 'Processor',
 'OsBuild',
 'OsSuite',
 'OsPlatformSubRelease',
 'OsBuildLab',
 'SkuEdition',
 'SMode',
 'IeVerIdentifier',
 'SmartScreen',
 'Firewall',
 'UacLuaenable',
 'Census_MDC2FormFactor',
 'Census_OEMNameIdentifier',
 'Census_ProcessorCoreCount',
 'Census_ProcessorManufacturerIdentifier',
 'Census_ProcessorModelIdentifier',
 'Census_PrimaryDiskTotalCapacity',
 'Census_PrimaryDiskTypeName',
 'Census_SystemVolumeTotalCapacity',
 'Census_HasOpticalDiskDrive',
 'Census_TotalPhysicalRAM',
 'Census_ChassisTypeName',
 'Census_InternalPrimaryDiagonalDisplaySizeInInches',
 'Census_InternalPrimaryDisplayResolutionHorizontal',
 'Census_InternalPrimaryDisplayResolutionVertical',
 'Census_PowerPlatformRoleName',
 'Census_InternalBatteryNumberOfCharges',
 'Census_OSVersion',
 'Census_OSArchitecture',
 'Census_OSBranch',
 'Census_OSBuildNumber',
 'Census_OSBuildRevision',
 'Census_OSEdition',
 'Census_OSSkuName',
 'Census_OSInstallTypeName',
 'Census_OSInstallLanguageIdentifier',
 'Census_OSUILocaleIdentifier',
 'Census_OSWUAutoUpdateOptionsName',
 'Census_GenuineStateName',
 'Census_ActivationChannel',
 'Census_FirmwareManufacturerIdentifier',
 'Census_IsSecureBootEnabled',
 'Census_IsTouchEnabled',
 'Wdft_IsGamer',
 'Wdft_RegionIdentifier']

cont_names =[]
target='HasDetection'

Pretty much standard tabular implementation 
`
data = (TabularList.from_df(train, path='.', cat_names=cat_names, cont_names=cont_names, procs=procs)
                           .random_split_by_pct(0.3)
                           .label_from_df(cols=target)
                           .databunch( num_workers=0))

learn = tabular_learner(data, layers=[200,100], metrics=accuracy, emb_drop=0.1)
#learn.model = nn.DataParallel(learn.model, device_ids=[0,1,2,3])    
#learn.model.to(""cuda:0"")
learn.to_fp16()
learn.fit_one_cycle(3, 1e-2, wd=0.1)

`




",import prediction selected model part pretty much standard tabular implementation data train learn data,issue,negative,positive,positive,positive,positive,positive
451655769,"Aah sorry, I had pulled but probably made a copy & paste error then. Next time... 🙂 ",sorry probably made copy paste error next time,issue,negative,negative,negative,negative,negative,negative
451655516,"You're removing all the restyle I had done on the tests to save vertical space (see [here](https://docs.fast.ai/dev/style.html)), plus some commented printed statements are back.
Don't forget to start on a clean git pull!",removing restyle done save vertical space see plus printed back forget start clean git pull,issue,positive,positive,positive,positive,positive,positive
451642775,"@sgugger Yes, this thing was tested against the quite old version of the library so I believe that now everything should be fine.",yes thing tested quite old version library believe everything fine,issue,positive,positive,positive,positive,positive,positive
451641839,Closing this since it has been a while with no news. Feel free to reopen with a gist reproducing the bug!,since news feel free reopen gist bug,issue,positive,positive,positive,positive,positive,positive
451641795,"Your pytorch version isn't 1.0, that's why it's not working. See the installation instructions and the [installation thread](https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111) on the forum.",version working see installation installation thread forum,issue,negative,neutral,neutral,neutral,neutral,neutral
451641687,"Closing this since it's been a while with no news, please reopen if needed.",since news please reopen,issue,negative,neutral,neutral,neutral,neutral,neutral
451639458,Can you tell us a bit more about your code? What data do you have? What is your model? I'm not sure it's linked to Windows specifically.,tell u bit code data model sure linked specifically,issue,negative,positive,positive,positive,positive,positive
451639393,"Looks good, just clean up your file before making a PR next time (commented printing statements). Thanks!",good clean file making next time printing thanks,issue,positive,positive,positive,positive,positive,positive
451639138,"It's the line after with the append that was False, thanks for flagging!",line append false thanks flagging,issue,negative,negative,negative,negative,negative,negative
451577748,Great!  I am so excited to contribute!! I wanted to be sure the process worked. I will continue to document the other functions including `has_arg`,great excited contribute sure process worked continue document,issue,positive,positive,positive,positive,positive,positive
451577274,"I have an output error in the cell after `learn.fit_one_cycle(3)` (keyboard interrupt, not the end of the word, but if you could commit a clean file, it'd be best).
Also, the cell with show_doc doesn't seem to be hidden (it may be nbdiff not catching it though).",output error cell keyboard interrupt end word could commit clean file best also cell seem hidden may catching though,issue,positive,positive,positive,positive,positive,positive
451575615,"When you click on the failure details: https://github.com/fastai/fastai/pull/1427/checks?check_run_id=46187666 Do you get the option to Re-run all?

![screenshot_6](https://user-images.githubusercontent.com/10676103/50712208-80aa7580-1025-11e9-9332-54c6a2b9369b.png)

It shouldn't be there for anybody but those with commit rights, but perhaps the PR submitter has that option too? Let us know if you don't and we will re-run it. I am asking because I'd like to know for the future whether PR submitters have these extra capabilities or not.
",click failure get option anybody commit perhaps submitter option let u know like know future whether extra,issue,negative,negative,negative,negative,negative,negative
451575348,I'd just add something to explain the result of `has_arg`. Having a markdown cell showing the basic documentation of the two functions would help for instance.,add something explain result markdown cell showing basic documentation two would help instance,issue,negative,neutral,neutral,neutral,neutral,neutral
451574601,Looks good! Will check locally before updating the docs and tell you if I have more comments.,good check locally tell,issue,negative,positive,positive,positive,positive,positive
451544251,"@sgugger seems that CI adult dataset was broken at the time of the CI run, can I re-run the pipelines for that commit manually somehow? ",adult broken time run commit manually somehow,issue,negative,negative,negative,negative,negative,negative
451489415,"comment see here: https://forums.fast.ai/t/improving-expanding-tests/32929

open for feedback",comment see open feedback,issue,negative,neutral,neutral,neutral,neutral,neutral
451468231,Why are you using `sep=' '` if it's a single classification problem? `accuracy` won't work in this case since the library will return float targets one-hot encoded (which is what the loss function for multilabel problems expect). Just removing that `sep=' '` should fix your problem.,single classification problem accuracy wo work case since library return float loss function expect removing fix problem,issue,negative,negative,neutral,neutral,negative,negative
450885123,I also encountered this problem when running fastai code from pure python (rather than Jupyter). From my perspective the cleanest solution would be to allow to pass a matplotlib axis object to all plotting routines. In case None is passed it would fall back to the present behavior. This would give the user the full flexibility to handle the plotting. What do you guys think?,also problem running code pure python rather perspective solution would allow pas axis object plotting case none would fall back present behavior would give user full flexibility handle plotting think,issue,negative,positive,positive,positive,positive,positive
450857096,"In fastai, all categorical variables go from 0 (nan), 1 (first value) to n (last value), even if you don't have nans (because in most cases, users have nans). You need to set +1 in your embedding sizes in your model (this is automatically done in the fastai models) to account for that.",categorical go nan first value last value even need set size model automatically done account,issue,positive,positive,positive,positive,positive,positive
450687305,"Thanks for the quick response!  your change addressed it and all runs fine now.
",thanks quick response change fine,issue,positive,positive,positive,positive,positive,positive
450673390,"It was due to LMDataLoader being a bit different from a classic dataloader, thanks for spotting this!",due bit different classic thanks spotting,issue,negative,positive,neutral,neutral,positive,positive
450664336,"Sure, will do.

On Mon, Dec 31 2018 at 2:44 AM, < notifications@github.com > wrote:

> 
> 
> 
> One last problem @xnutsive ( https://github.com/xnutsive ) : the doc
> notebook widget.image_cleaner can't be executed automatically now, which
> breaks our expanded test suite (all the doc notebooks are run when we
> launch the tests before a release). I've fixed it by moving some cells in
> markdown code, but you may want to have a second look.
> 
> 
> 
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub (
> https://github.com/fastai/fastai/pull/1382#issuecomment-450631557 ) , or mute
> the thread (
> https://github.com/notifications/unsubscribe-auth/AACqcf0kUv3kZzepMyRbabm6cG8XOA8oks5u-ep4gaJpZM4Zftpg
> ).
> 
> 
>",sure mon wrote one last problem doc notebook ca executed automatically expanded test suite doc run launch release fixed moving markdown code may want second look reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
450631557,"One last problem @xnutsive : the doc notebook widget.image_cleaner can't be executed automatically now, which breaks our expanded test suite (all the doc notebooks are run when we launch the tests before a release). I've fixed it by moving some cells in markdown code, but you may want to have a second look.",one last problem doc notebook ca executed automatically expanded test suite doc run launch release fixed moving markdown code may want second look,issue,negative,positive,neutral,neutral,positive,positive
450631121,"Can confirm that git head now works, thanks :smiley: ",confirm git head work thanks,issue,negative,positive,positive,positive,positive,positive
450594678,"@sgugger, FYI, you don't need to reopen the issue to rerun the PR build azure check. You can just go to the report on azure and request a rebuild, in this case:
https://dev.azure.com/fastdotai/fastai/_build/results?buildId=2620
clicking on [...] in the right upper corner and choosing Rebuild.
If you don't have the right permissions to do that please ask Jeremy to add you to azure's fastai account managers.",need reopen issue rerun build azure check go report azure request rebuild case right upper corner choosing rebuild right please ask add azure account,issue,negative,positive,positive,positive,positive,positive
450581943,"@stas00, thanks for the nudge ;-)You're right, I did set it up (the first time), and it does work automatically.

@sgugger, thanks for restyling and merging! ",thanks nudge right set first time work automatically thanks,issue,positive,positive,positive,positive,positive,positive
450575887,(close and reopen is just to re-trigger the test suite),close reopen test suite,issue,negative,neutral,neutral,neutral,neutral,neutral
450552921,"Sorry for the slow reply.  This is the output:

````text
=== Software === 
python version : 3.6.7
fastai version : 1.0.36.post1
torch version  : 0.4.1
torch cuda ver : 9.2.148
torch cuda is  : **Not available** 

=== Hardware === 
No GPUs available 

=== Environment === 
platform       : Linux-4.4.0-17134-Microsoft-x86_64-with-debian-buster-sid
distro         : #471-Microsoft Fri Dec 07 20:04:00 PST 2018
conda env      : fastai
python         : /home/michael/anaconda3/envs/fastai/bin/python
sys.path       : 
/home/michael/anaconda3/envs/fastai/lib/python36.zip
/home/michael/anaconda3/envs/fastai/lib/python3.6
/home/michael/anaconda3/envs/fastai/lib/python3.6/lib-dynload
/home/michael/anaconda3/envs/fastai/lib/python3.6/site-packages
/home/michael/anaconda3/envs/fastai/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg
/home/michael/anaconda3/envs/fastai/lib/python3.6/site-packages/IPython/extensions
/home/michael/.ipython
no supported gpus found on this system
```

Please make sure to include opening/closing ``` when you paste into forums/github to make the reports appear formatted as code sections.

Optional package(s) to enhance the diagnostics can be installed with:
pip install distro
Once installed, re-run this utility to get the additional information`",sorry slow reply output text python version version post torch version torch torch available hardware available environment platform pst python egg found system please make sure include paste make appear code optional package enhance diagnostics pip install utility get additional information,issue,positive,positive,neutral,neutral,positive,positive
450551745,"Thanks for taking care of the TODOs. Is there any chance you can put those changes on the metrics module that is on master? You're using the one from your last PR so the merge I did is ignored (and I'd rather not to do it again as I may mess something up).
If it's easier to close this PR and start a fresh one, please do so.",thanks taking care chance put metric module master one last merge rather may mess something easier close start fresh one please,issue,positive,positive,neutral,neutral,positive,positive
450547566,Just made a little bit of restyle to save vertical space which shouldn't change anything.,made little bit restyle save vertical space change anything,issue,negative,negative,negative,negative,negative,negative
450547055,"You're putting in transforms `rand_pad(2,28)` (so padding of 2 then resize to 28x28 for the training set, crop center). Since this only one set of transforms, there is no validation transforms so you get the original image.
This is consistent behavior from the library, not a bug. You should put other transforms for `ds_tfms`.",padding resize training set crop center since one set validation get original image consistent behavior library bug put,issue,negative,positive,positive,positive,positive,positive
450530987,"Commenting just on:
> ran nbstripout as well

You mentioned this several times, so I thought the following will simplify your life - you do not need to run nbstripout manually. It's done automatically for you, you just need to follow the instructions [here](https://docs.fast.ai/dev/develop.html#things-to-run-after-git-clone) to set it up.",ran well several time thought following simplify life need run manually done automatically need follow set,issue,negative,neutral,neutral,neutral,neutral,neutral
450523888,Thanks for the tips! Updated the code styles and used the defaults you pointed out. LGTM or should I do a full example notebook in `examples` to show the all the way from an idea to serving? ,thanks code used pointed full example notebook show way idea serving,issue,negative,positive,positive,positive,positive,positive
450510346,This usually happens when the texts aren't properly loaded. Are you sure you have labels in column 0 and texts in column 1 (default)? Otherwise you can pass yours with `text_cols` and `label_cols`.,usually properly loaded sure column column default otherwise pas,issue,negative,positive,positive,positive,positive,positive
450477606,"Seems good, I've just a added a few comments on style + defaults. Thanks a lot for this!",good added style thanks lot,issue,positive,positive,positive,positive,positive,positive
450477119,"Code style is great and fits perfectly with ours. Seems fine to me, we'll see if it breaks things by using it a little bit.",code style great perfectly fine see little bit,issue,positive,positive,positive,positive,positive,positive
450476910,"The problem is that currently, the get method assumes the data has already been preprocessed (which is when it gains all those attributes). I've added a test to return the line of the dataframe if it hasn't been preprocessed.",problem currently get method data already gain added test return line,issue,negative,neutral,neutral,neutral,neutral,neutral
450447794,"I see the stupidity of my previous questions...seems to me now that `self.codes` should actually be the values of the categorical columns for the given row, and similar for `self.conts` and `self.classes`(?). I'm still not sure what `self.col_names` should be, though.",see stupidity previous actually categorical given row similar still sure though,issue,negative,negative,neutral,neutral,negative,negative
450416454,"@stas00, thank you for pointing me to the build pipelines and nbstripout problem. 

@sgugger, I think it's ready for review. I'll do a couple examples myself and if anything breaks I'll add more tests here. 

@fpingham, I merger `master` into this and updated `widgets.image_cleaner.ipynb`.",thank pointing build problem think ready review couple anything add merger master,issue,negative,positive,positive,positive,positive,positive
450403265,"Not until a new release is made. Until then follow [this](https://github.com/fastai/fastai/blob/master/README.md#developer-install). Or you can install directly from github i.e. 
```
pip install git+https://github.com/fastai/fastai.git
```",new release made follow install directly pip install,issue,negative,positive,positive,positive,positive,positive
450402819,"But please let's continue at the forums, so that others can benefit from the answers. 
Perhaps [here](http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111).",please let continue benefit perhaps,issue,positive,neutral,neutral,neutral,neutral,neutral
450402241,"Yes. I have few more questions now. But, Let me read about this and the torch backend implementation and come back. Thank you.",yes let read torch implementation come back thank,issue,positive,neutral,neutral,neutral,neutral,neutral
450401525,"And this is always true, no matter whether you're on CPU or GPU. It's not cuda, it's cudnn.
torch.backends.cudnn.enabled - True",always true matter whether true,issue,positive,positive,positive,positive,positive,positive
450392137,"Ugh, since everything is of the same size, I'm guessing numpy wants to make a proper array of the items and fails. Will try to look at this.",ugh since everything size guessing make proper array try look,issue,negative,neutral,neutral,neutral,neutral,neutral
450391955,"This model isn't supported with `create_cnn`. Supported models are resnet only until someone else develops that feature. In the meantime, you can always pass your pytorch model to a `Learner` with your data.",model someone else feature always pas model learner data,issue,negative,neutral,neutral,neutral,neutral,neutral
450391553,"That's a question for the pytorch forum, no link to fastai (and no idea why it shows this).",question forum link idea,issue,negative,neutral,neutral,neutral,neutral,neutral
450391432,"We can't help you without more code or the data you're using, otherwise we can't reproduce the bug (and even less fix it).",ca help without code data otherwise ca reproduce bug even le fix,issue,negative,neutral,neutral,neutral,neutral,neutral
450382747,"sorry, accidentally posted before adding the information, will open a new issue",sorry accidentally posted information open new issue,issue,negative,negative,negative,negative,negative,negative
450352123,Would I get this fixes by `pip install --upgrade fastai` ?,would get pip install upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
450327111,"Thanks a lot, this looks great! Just added a few TODO on some metrics that aren't averages over batches (two of yours and one that was already there).",thanks lot great added metric two one already,issue,positive,positive,positive,positive,positive,positive
450319143,"The current setup is temporary before the new MOOC is released in January. The new version of the library is using pytorch 1.0, but there are a lot of breaking changes with the old one, which is why you should use 0.7 for the current public version MOOC.
Once the new MOOC is released, this will all go in a separate repo, and since it's temporary we didn't bother making it super clean. `pandas_summary` is in the old requirements, you should use the conda from git source install. 
Optionally, just wait for two weeks to use fastai v1 with the new version of the MOOC.",current setup temporary new new version library lot breaking old one use current public version new go separate since temporary bother making super clean old use git source install optionally wait two use new version,issue,positive,positive,positive,positive,positive,positive
450318314,"I actually cloned the master git repo as I didn't find any ""courses"" branch or ""0.7"".

That's probably why.

But now I wonder; why do the dev team rely on ""old packages"" for courses, ( e.g. torch 0.3.1 instead of 1.0.0 ) and keep saying that the framework is based on the latest advances in ML or so?
I absolutely don't want to be offending, it's a simple open question as on the link you shared it's written ""outdated"" on the pip installation section:

![untitled](https://user-images.githubusercontent.com/19967599/50508593-d362bb00-0a82-11e9-88e9-973e1185808d.png)
**Fig.2.** _Documentation from https://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652 for installing with pip._

Do you also know is they planned to open a dedicated git branch for courses?    
When I begin to read suffixes like ""_old"" or ""v3"" it's not a sign of a homogeneous development to me, branches should do the job instead (but I'm not a dev at all).

But still, installing `fastai==0.7.0` leads to:
`ModuleNotFoundError: No module named 'pandas_summary'`",actually master git find branch probably wonder dev team rely old torch instead keep saying framework based latest absolutely want simple open question link written outdated pip installation section untitled fig also know open git branch begin read like sign homogeneous development job instead dev still module,issue,negative,positive,neutral,neutral,positive,positive
450315216,"Actually, this was on purpose, since we may need to do it twice in some cases. Added this in the comment.",actually purpose since may need twice added comment,issue,negative,neutral,neutral,neutral,neutral,neutral
450313843,"They are all in the requirements.txt file of old fastai, so I'm not sure what is the issue here. Are you sure you followed the steps [here](https://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652)?",file old sure issue sure,issue,positive,positive,positive,positive,positive,positive
450193022,Hey @sgugger. Thank you for your feedback. Well I did something similar. There were some issues related to the averaging functions (setting average to micro or weighted was not working properly for FBeta) so I came up with a little workaround using another subclass 'CMScores'. ,hey thank feedback well something similar related setting average micro weighted working properly came little another subclass,issue,positive,negative,neutral,neutral,negative,negative
450123642,Does this still happen with the latest PR from @PiotrCzapla that removes cyclical references? Plus previous commits that make sure all the stats are recorded on GPU.,still happen latest cyclical plus previous make sure,issue,negative,positive,positive,positive,positive,positive
450123461,Did it solve your problem? Can I close this issue?,solve problem close issue,issue,negative,neutral,neutral,neutral,neutral,neutral
450120513,"Be careful, you forgot to normalize in your section 1 (you also save the file dataset.csv not in path, but that doesn't change the results if I save it properly). Since you normalize your data in section 2, the results are of course very different. When I add normalization in section 1 (or remove it in section 2), the bug disappears.",careful forgot normalize section also save file path change save properly since normalize data section course different add normalization section remove section bug,issue,positive,negative,neutral,neutral,negative,negative
450109695,"No worries, from the look of it, you should pass some values to `text_cols` and `label_cols` as the defaults don't seem to be what you have ;). Closing this, see you on the [forum](https://forums.fast.ai/) if you're still stuck. ",look pas seem see forum still stuck,issue,negative,neutral,neutral,neutral,neutral,neutral
450108488,"Thanks for the inputs. This is not a multi label classification - seems i have messed up the input X, i am passing a list. I will change this and try again. 

Thanks for highlighting this issue",thanks label classification input passing list change try thanks issue,issue,positive,positive,positive,positive,positive,positive
450093594,"Your labels are really weird: I see 35035 for instance, do you really have that many labels? Looking back at your code, I don't even get how the API understands it's a multilabel problem. Where do you pass the list of label columns or the sep argument? (first for one-hot encoded multi-label, second to split tags in a row). 
The bug comes because you have None in your lists. Those come from labels in your validation data that aren't present on the training data, which isn't a bug in the library but something you need to fix in your data.",really weird see instance really many looking back code even get problem pas list label argument first second split row bug come none come validation data present training data bug library something need fix data,issue,negative,positive,neutral,neutral,positive,positive
450092243,"A topic on the forum would be best for this, thanks!",topic forum would best thanks,issue,positive,positive,positive,positive,positive,positive
450088425,"You new implementation is a very big improvement. I am cleaning up my nlp repository and have further optimisations. 
Should we create a subject in the forum to discus them or how do you prefer to do it ?",new implementation big improvement cleaning repository create subject forum discus prefer,issue,positive,negative,neutral,neutral,negative,negative
450061293,"Hi
  I have run it again with exactly the same code as the problem report (the previous debug output was with some minor change by including the test df)

Here is the output
```
ipdb> print (x)
[27867, 1549, 24655, 6059, 28744, 11970, 2780, 25911, 2378, 32596, 5387, 12090, 5054, 15445, 7342, 13569, 12227, 12218, 35912, 13335, 13974, 875, 1, 14185, 22298, 15986, 33978, 1, 4170, 35912, 1, 20254, 14601, 1, 7276, 5405, 18948, 20254, 1, 7276, 14710, 1, 4170, 35883, 1, 20254, 34768, 35883, 1, 7276, 1874, 1, 4170, 35915, 1, 20254, 18948, 20254, 36566, 7276, 15596, 24657, 19353, 27867, 23113, 34293, 27867, 1338, 22729, 31081, 34941, 4684, 5005, 29536, 21029, 3205, 34293, 6539, 13781, 32626, 34293, 21002, 27027, 34293, 25170, 1, 7687, 20423, 34293, 20995, 5020, 34293, 27714, 30752, 34959, 5966, 28818, 31680, 5755, 21029, None, 25911, 29154, 26448, None, 33984, 12909, 1, 23893, 28340, 30794, 33034, 9143, 31680, 30355, 5054, 22573, 28455, 31816, 12090, 10469, 22562, 13641, 35174, 29154, 26448, 32590, 16866, 34282, 34959, 21812, 2780, 29154, 26448, 5054, 16866, 22573, 11736, 26620, 2780, 2885, 28455, 32210, 5054, 31816, 25911, 2378, 16866, 9682, 32016, 2780, 31816, 12090, 16866, 23582, 17349, 22562, 5054, 3205, 3037, 6189, 23823, 22562, 2763, 13641, 3526, 21768, 22733, 2476, 26620, 22447, 22447, 22447, 21624, 36566, 2780, 29154, 26448, 5787, 5387, 1874, 25911, 2378, 31825, 16866, 1874, 24553, 34959, 6059, 28744, 23668, 15986, 34831, 34901, 28637, 22405, 6189, 30319, 14564, 3205, 26754, 20601, 9691, 26310, 3300, 24206, 22562, 23800, 2586, 31825, 3526, 21768, 3300, 2885, 26319, 15986, 34831, 22626, 18288, 32210, 5020, 27027, 11065, 14492, 25944, 12090, 22360, 25502, 1, 6343, 29112, 17655, 30593, 36566, 20982, 1874, 17444, 7268, 36566, 20982, 1874, 18632, 27688, 12645, 21029, 7541, 1874, 12090, 36580, 1874, 8349, 15913, 3188, 2780, 9866, 23874, 12076, 11171, 22360, 21671, 22405, 28602, 34934, 4482, 8999, 32210, 8349, 1, 15913, 32210, 8349, 17597, 22405, 28602, 1, 35035, 3205, 25911, 5054, 26448]
```

<img width=""1117"" alt=""screen shot 2018-12-27 at 10 51 09"" src=""https://user-images.githubusercontent.com/24820914/50463218-676e4d00-09c5-11e9-8bc5-f95ab0cb1a53.png"">
",hi run exactly code problem report previous output minor change test output print none none screen shot,issue,negative,positive,neutral,neutral,positive,positive
450034535,"Here is the output

```
ipdb> print (x)
[25956, 18839, 20679, 22934, 31261, 18839, 18839, 22406, 7961, 10737, 2855, 24655, 15975, 5633, 22288, 21849, 33408, 1, 22406, 1, 4029, 13061, 9966, 26557, 31546, 10971, 20679, 13313, 25083, 7560, 32102, 25083, 7560, 23821, 20876, 25083, 26016, 7560, 24535, 19028, 31944, 25087, 31171, 11093, 10863, 4029, 13061, 9966, 26557, 11093, 535, 18527, 28732, 12964, 1, 4029, 18609, 13061, 15975, 34034, 18520, 22406, 27757, 32102, 7541, 11093, 535, 14133, 28732, 12966, 1, 6262, 30179, 13313, 30468, 32102, 11920, 4429, 22288, 4031, 13061, 18160, 32102, 31546, 28531, 15333, 36383, 3657, 14608, 35012, 3472, 23573, 28543, 28864, 18160, 32102, 26557, 15333, 36383, 3657, 14608, 35012, 3472, 23573, 28543, 28864, 18160, 32102, 31546, 18609, 15333, 36383, 3657, 3473, 399, 28552, None, 28531, None]
```

Screenshot
<img width=""1126"" alt=""screen shot 2018-12-27 at 06 18 43"" src=""https://user-images.githubusercontent.com/24820914/50458631-7c37ea00-099f-11e9-96b0-eb3050ba81b7.png"">
",output print none none screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
449985467,"This looks great, thanks a lot! I'm just thinking we could refactor the common bits between Recall, Precision and FBeta. Maybe Recall and Precision could be subclasses of FBeta, where all the work would be done? (a bit like you made them subclass ConfusionMatrix)",great thanks lot thinking could common recall precision maybe recall precision could work would done bit like made subclass,issue,positive,positive,positive,positive,positive,positive
449980902,"Merging as it's a first step in the right direction, and I'd like to play with this a bit.",first step right direction like play bit,issue,positive,positive,positive,positive,positive,positive
449975632,"It looks nicer that way. Let's try on the docs and maybe revert if it's ugly in HTML, but I don't think so.",way let try maybe revert ugly think,issue,negative,negative,negative,negative,negative,negative
449974669,"I haven't looked at your notebook since I also add an idea to reduce memory usage for huge datasets and wanted to implement mine independently. The final idea is to have such a big dataset stored in some kind of database and only access the texts when necessary. For now, it's still in the items of a `LabelList` but there are no more copies made since texts are accessed when building a batch. As far as I can tell, it has the same functionalities as before.
The downside is that it's a tiny bit slower, but I'm not sure it's really an issue since the GPU is going to be the bottleneck. I'm closing this issue, but please let us know if you find problems with the new implementation, and if you have suggestions to make it even more memory-efficient.",notebook since also add idea reduce memory usage huge implement mine independently final idea big kind access necessary still made since building batch far tell downside tiny bit sure really issue since going bottleneck issue please let u know find new implementation make even,issue,positive,positive,positive,positive,positive,positive
449966360,"Before anything else, please sign the [Contributor Licence Agreement](https://www.clahub.com/agreements/fastai/fastai) before we can merge your PR, thanks!",anything else please sign contributor agreement merge thanks,issue,positive,positive,positive,positive,positive,positive
449946765,Closing this since there is no news and we can't reproduce the bug on our side.,since news ca reproduce bug side,issue,negative,neutral,neutral,neutral,neutral,neutral
449946654,You can't customize the behavior of the factory methods of `ImageDataBunch` but you can completely customize what happens if you use the data block API. Please use the [forum](https://forums.fast.ai/) if you have any questions about it.,ca behavior factory completely use data block please use forum,issue,negative,positive,neutral,neutral,positive,positive
449946220,Could you use %debug after that bug appears then print(x) in the debugger console? I need to know what type of object x is.,could use bug print console need know type object,issue,negative,neutral,neutral,neutral,neutral,neutral
449859187,"> so how to do that?

Just type 
`import matplotlib as mpl
mpl.use('Agg')`
at the beginning of your script.",type import beginning script,issue,negative,neutral,neutral,neutral,neutral,neutral
449726730,"ok, thx. will close this PR here then and see if I can come up with a better test.",close see come better test,issue,negative,positive,positive,positive,positive,positive
449719697,"With the new fake data object, show_batch prints something that can be intercepted by stdout if we want a basic of if show_batch works.",new fake data object something want basic work,issue,negative,negative,negative,negative,negative,negative
449703434,"I can't reproduce your bug on master. Can you check your installation with:
```
from fastai.utils.show_install import show_install
show_install(1)
```
in a jupyter cell?",ca reproduce bug master check installation import cell,issue,negative,neutral,neutral,neutral,neutral,neutral
449702787,"Good catch! There is something else to make it work right though: the reconstruct method (which transforms a tensor to the initial object) needs to be different for Collab (which it was, but there was a bug there). Will commit the fix in a few secs.",good catch something else make work right though reconstruct method tensor initial object need different bug commit fix,issue,positive,positive,positive,positive,positive,positive
449679636,"You admit yourself that you don't know what you're talking about, and then you go on to make a totally inappropriate recommendation and an offensive and wrong assertion. How can you possibly think that is in any way helpful? I honestly can't begin to imagine what you were thinking when you decided to post this here.",admit know talking go make totally inappropriate recommendation offensive wrong assertion possibly think way helpful honestly ca begin imagine thinking decided post,issue,negative,positive,neutral,neutral,positive,positive
449620612,"You can see the failing tests in the CI logs:
https://dev.azure.com/fastdotai/fastai/_build/results?buildId=2535
You didn't strip the notebooks. See:
https://docs.fast.ai/dev/develop.html#things-to-run-after-git-clone
https://docs.fast.ai/dev/develop.html#unstripped-notebook-repair
",see failing strip see,issue,negative,neutral,neutral,neutral,neutral,neutral
449615168,"🧐 looks like I broke the build somewhere, but I'm not sure how to get to the build log, and at least the unit tests pass. Probably broke something in the docs (?).

I'll take a look tomorrow. ",like broke build somewhere sure get build log least unit pas probably broke something take look tomorrow,issue,negative,positive,neutral,neutral,positive,positive
449609174,"> Did you try this? https://stackoverflow.com/questions/4931376/generating-matplotlib-graphs-without-a-running-x-server
in fastai doucmentaion, i failed to find any plt referencte to handle that. all relate fuction are packaged like:
show_batch
plot_lr
so how to do that?",try find handle relate like,issue,negative,neutral,neutral,neutral,neutral,neutral
449551146,"This has been referenced as an issue [here](https://github.com/fastai/fastprogress/issues/21) with a possible fix. It's compeltely linked to fastprogress and not fastai in any case, so please comment on that topic if the fix doesn't work for you (and tell us what your setup is).",issue possible fix linked case please comment topic fix work tell u setup,issue,negative,neutral,neutral,neutral,neutral,neutral
449550827,"Please don't change the html directly as they are auto-generated (so your fix will be erased later). It's the corresponding notebook that needs change. I'm closing this PR but you can open a new one that addresses the same problem in the notebook.
Also please note we need you to sign the CLA to accept your PRs.",please change directly fix erased later corresponding notebook need change open new one problem notebook also please note need sign accept,issue,positive,positive,neutral,neutral,positive,positive
449540708,"Let's continue in the thread dedicated to this topic:
https://forums.fast.ai/t/documentation-improvements/32550/41
",let continue thread topic,issue,negative,neutral,neutral,neutral,neutral,neutral
449539958,"Do you have any recommendations on where in the forum to look into? I would be more than willing to migrate them to fitting places, either here or in the docs.fast.ai.",forum look would willing migrate fitting either,issue,negative,positive,positive,positive,positive,positive
449537368,"the test is failing with `assert 101 < 100`:

should this test line have been:
```
assert gc_collected < 102
```
but then you comment says there should be 100 of those - we get 101.",test failing assert test line assert comment get,issue,negative,neutral,neutral,neutral,neutral,neutral
449501323,"I see that the issue in that is causing the problem above is already fixed in 8f52f4a7efd424c10839586c94095508a689159f . 
But you will mostlikely run in to another issue when training RNN's. The backprop won't work as there is a mixture between fp16 and fp32, but I have a fix for that #1374, please try it and let Sylvain know if it is worth merging. ",see issue causing problem already fixed run another issue training wo work mixture fix please try let know worth,issue,negative,positive,positive,positive,positive,positive
449486720,"No, data forwad any unknown attriute to its train_ds. You get this bug because your data isn't properly defined (it's looking for the module data of torch.utils instead of an actual DataBunch here).",data unknown get bug data properly defined looking module data instead actual,issue,negative,negative,neutral,neutral,negative,negative
449438911,"Ok I assume it should work now. Some of the implementations are very similar to the ones provided before but now using the Callback class.

I added different averaging options to the metrics which rely on the computation of a confusion matrix. Those are inline with the ones provided by sklearn (""binary"", ""micro"", ""macro"", ""weighted"" or None for no averaging at all). ",assume work similar provided class added different metric rely computation confusion matrix provided binary micro macro weighted none,issue,negative,neutral,neutral,neutral,neutral,neutral
449144192,"I think it's a good idea to migrate some of the notes in forums to corresponding fastai docs, often it's very difficult to find some of those gems in the forums.",think good idea migrate corresponding often difficult find,issue,negative,positive,neutral,neutral,positive,positive
449128654,Rewrote similarity code to improve speed (used code on the web). Recreated notebook to include duplicate widget and keep fastai format.,similarity code improve speed used code web notebook include duplicate keep format,issue,negative,neutral,neutral,neutral,neutral,neutral
448980597,"Looks like someone forgot to adjust those when they changed the behavior of apply_tfms (used to be inplace)!
Thanks for spotting and fixing this, just be sure to run the command tools/run-after-git-clone so that your notebooks are automatically stripped (for this one, have a look [here](https://docs.fast.ai/dev/develop.html#unstripped-notebook-repair) to force the stripping). That's why tests are failing.",like someone forgot adjust behavior used thanks spotting fixing sure run command automatically stripped one look force stripping failing,issue,positive,positive,positive,positive,positive,positive
448785162,"Yes, you made the PR before I fixed that test. Thanks!",yes made fixed test thanks,issue,positive,positive,positive,positive,positive,positive
448765153,"This PR affects exclusively docs. 
I believe that the failed check, in ` tests/test_callbacks_csv_logger.py:47`, is unrelated",exclusively believe check unrelated,issue,negative,neutral,neutral,neutral,neutral,neutral
448660455,"> Thanks for the encouragement Sylvain ! I thought I ran tools/run-after-git-clone but I must have forgotten after another clone. Hopefully it's all good now :)

In the future use the helper program `tools/fastai-make-pr-branch` that will clone, branch and set it all up, including running  `tools/run-after-git-clone` automatically for you: https://docs.fast.ai/dev/git.html#helper-program",thanks encouragement thought ran must forgotten another clone hopefully good future use helper program clone branch set running automatically,issue,positive,positive,positive,positive,positive,positive
448654904,"Thanks thats very helpful.  In several talks Jeremy talks about using pytorch datasets, but after looking into things more I can see that this is only true in some cases and it seems that most require additions, in particular the use of the ItemList.  I was struggling to see how to do all of this and your article helps",thanks thats helpful several looking see true require particular use struggling see article,issue,positive,positive,positive,positive,positive,positive
448636634,"I'm not too fond on going back to FP32 behind the user. My fix for this is to leave the issue (TTA isn't working in FP16 because torch.stack isn't, which may very well change in the future) but offer the ability to quickly switch back to FP32 with a new `Leaner.to_fp32`  method.
So you should do:
``` 
learn.to_fp32()
preds, targs = learn.TTA()
```",going back behind user fix leave issue working may well change future offer ability quickly switch back new method,issue,negative,positive,neutral,neutral,positive,positive
448635556,Took me a while to address it but it's fixed. Note that you can also go back to FP32 at any time with the new command `learn.to_fp32()`.,took address fixed note also go back time new command,issue,negative,positive,neutral,neutral,positive,positive
448630692,It's another one but I pushed a fix. I've documented [here](https://docs.fast.ai/basic_data.html#Using-a-custom-Dataset-in-fastai) what you should expect to work or not work with a pytorch Dataset and what attributes you can implement to help.,another one fix expect work work implement help,issue,negative,neutral,neutral,neutral,neutral,neutral
448556077,"I added the typos you corrected to [my PR ](https://github.com/fastai/fastai/pull/1361), I hope that's all right with you :)",added corrected hope right,issue,negative,positive,positive,positive,positive,positive
448547393,Thanks for the encouragement Sylvain ! I thought I ran tools/run-after-git-clone but I must have forgotten after another clone. Hopefully it's all good now :) ,thanks encouragement thought ran must forgotten another clone hopefully good,issue,positive,positive,positive,positive,positive,positive
448513747,"Hi @PiotrCzapla,
Thanks for the answer. Yes, sure, please send me a link. Still, I would like to try it on modified LSTM.",hi thanks answer yes sure please send link still would like try,issue,positive,positive,positive,positive,positive,positive
448495001,"Now it seems that [#1341](https://github.com/fastai/fastai/issues/1341) is back:

```
AttributeError                            Traceback (most recent call last)
<ipython-input-12-b76c7f7a7986> in <module>
----> 1 learn.fit_one_cycle(6, max_lr=3e-2)

~/anaconda3/envs/pytorch/lib/python3.7/site-packages/fastai/train.py in fit_one_cycle(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)
     19     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,
     20                                         pct_start=pct_start, **kwargs))
---> 21     learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)
     22 
     23 def lr_find(learn:Learner, start_lr:Floats=1e-7, end_lr:Floats=10, num_it:int=100, stop_div:bool=True, **kwargs:Any):

~/anaconda3/envs/pytorch/lib/python3.7/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
    164         callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)
    165         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,
--> 166             callbacks=self.callbacks+callbacks)
    167 
    168     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

~/anaconda3/envs/pytorch/lib/python3.7/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)
     92     except Exception as e:
     93         exception = e
---> 94         raise e
     95     finally: cb_handler.on_train_end(exception)
     96 

~/anaconda3/envs/pytorch/lib/python3.7/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)
     85                 if cb_handler.on_batch_end(loss): break
     86 
---> 87             if hasattr(data,'valid_dl') and data.valid_dl is not None and len(data.valid_ds.items) > 0:
     88                 val_loss = validate(model, data.valid_dl, loss_func=loss_func,
     89                                        cb_handler=cb_handler, pbar=pbar)

AttributeError: 'CustomDataset' object has no attribute 'items'
```",back recent call last module learn learn learn learner fit self self fit self none fit model opt data metric except exception exception raise finally exception fit model opt data metric loss break data none validate model object attribute,issue,positive,positive,positive,positive,positive,positive
448488006,"Unfortunately I can't sign the CLA since this requires a lengthy process within my company. 
I'm allowed to do minor fixes without a CLA though.
I'll leave it up to you to either merge it without or close the PR. Sorry for the inconvenience.",unfortunately ca sign since lengthy process within company minor without though leave either merge without close sorry inconvenience,issue,negative,negative,negative,negative,negative,negative
448395179,"@rpowalski I've fixed the issues some time ago, but the LSTM isn't much faster on fp 16 and QRNN does not work due to cupy, so I haven't bothered to create the pull request. But if you wish to give it another shot your self I can send you a patch. You would have to test it as I don't have access to GPU anymore.",fixed time ago much faster work due create pull request wish give another shot self send patch would test access,issue,positive,positive,neutral,neutral,positive,positive
448395094,"Yes, you forgot to strip them, look at [this page](https://docs.fast.ai/dev/develop.html#unstripped-notebook-repair), specifically 
```
tools/fastai-nbstripout -d docs_src/*ipynb
```
should do the trick.

If you have run tools/run-after-git-clone it should be done automatically, so remember to run this for next time. Congrats on your first PR, you're almost there! :)",yes forgot strip look page specifically trick run done automatically remember run next time first almost,issue,negative,positive,positive,positive,positive,positive
448382131,"I thought I ran the stripper tool, I'll double check thanks",thought ran stripper tool double check thanks,issue,negative,positive,neutral,neutral,positive,positive
448379878,"Not really sure why the check failed, I only went through some cells checking ""hide input"" when necessary",really sure check went hide input necessary,issue,negative,positive,positive,positive,positive,positive
448348835,"Nope :(

```
Traceback (most recent call last):
  File ""test.py"", line 31, in <module>
    data = ImageDataBunch.create(tr_dataset, val_dataset)
  File ""~/repos/fastai/fastai/basic_data.py"", line 117, in create
    return cls(*dls, path=path, device=device, tfms=tfms, collate_fn=collate_fn, no_check=no_check)
  File ""~/repos/fastai/fastai/basic_data.py"", line 90, in __init__
    if fix_dl is None: fix_dl = train_dl.new(shuffle=False, drop_last=False)
  File ""~/repos/fastai/fastai/basic_data.py"", line 20, in DataLoader___getattr__
    def DataLoader___getattr__(dl, k:str)->Any: return getattr(dl.dataset, k)
AttributeError: 'CustomDataset' object has no attribute 'new'
```",nope recent call last file line module data file line create return file line none file line return object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
448316383,Should be fixed by [this commit](https://github.com/fastai/fastai/commit/95097a408944094626a6c93da33ea8eba5edde1f). We only operate the conversion before collating for a batch.,fixed commit operate conversion batch,issue,negative,positive,neutral,neutral,positive,positive
448263000,"**Description: Simple test with assert for show batch method.** 

Check manually e.g. with: pytest -k 'show_batch' tests/test_text_data.py

Potential Follow Ups:
- Test method could be extended to try to reproduce error, e.g. issue here: https://forums.fast.ai/t/getting-cuda-oom-on-lesson3-imdb-notebook-with-a-bs-8/30080/14

- Object _captured.out_ delivers on IPython notebook _IPython.core.display.HTML_ object. If we had a way to get to the HTML body (see some failed attempts below), we could assert over string 'label' e.g.
-- sys.stdout.write(captured.out)
-- print(captured.out)
-- print(HTML(captured.out).data)
-- display(HTML(captured.out))
-- print(str(captured.out))
-- print(str(HTML(captured.out)))
-- print(str(HTML(captured.out).data))
",description simple test assert show batch method check manually potential follow test method could extended try reproduce error issue object notebook object way get body see could assert string print print display print print print,issue,negative,neutral,neutral,neutral,neutral,neutral
448157629,I ran into the same problem - the original problem has been solved but it has not moved to the class initiation as above.,ran problem original problem class initiation,issue,negative,positive,positive,positive,positive,positive
448126608,"Not quite:

```
Traceback (most recent call last):
  File ""/tmp/pycharm_project_189/test.py"", line 31, in <module>
    data = ImageDataBunch.create(tr_dataset, val_dataset)
  File ""../fastai/fastai/basic_data.py"", line 117, in create
    return cls(*dls, path=path, device=device, tfms=tfms, collate_fn=collate_fn, no_check=no_check)
TypeError: __init__() missing 1 required positional argument: 'fix_dl'
```",quite recent call last file line module data file line create return missing positional argument,issue,negative,negative,neutral,neutral,negative,negative
448106545,This has been fixed a few hours ago. `git pull` should take care of this.,fixed ago git pull take care,issue,negative,positive,neutral,neutral,positive,positive
448063964,"Thank you for the link, @odysseus0, and re-initiating this change (which we have tried before).

Since your proposed change has been applied to all tools/* already I'm closing this PR. but if someone has issue with the change please don't hesitate to comment, including posting the error messages and information about your setup if you do.",thank link change tried since change applied already someone issue change please hesitate comment posting error information setup,issue,negative,neutral,neutral,neutral,neutral,neutral
448063289,"I believe that [PEP 394 -- The ""python"" Command on Unix-Like Systems](https://www.python.org/dev/peps/pep-0394/) will shed some light on this issue. Here are some relevant information I found.

> - for the time being, all distributions should ensure that `python`, if installed, refers to the same target as `python2`, unless the user deliberately overrides this or a virtual environment is active.
>
> - however, end users should be aware that `python` refers to `python3` on at least Arch Linux (that change is what prompted the creation of this PEP), so python should be used in the shebang line only for scripts that are source compatible with both Python 2 and 3.
>
> - In order to tolerate differences across platforms, all new code that needs to invoke the Python interpreter should not specify `python`, but rather should specify either `python2` or `python3` (or the more specific `python2.x` and `python3.x` versions; see the Migration Notes). This distinction should be made in shebangs, when invoking from a shell script, when invoking via the `system()` call, or when invoking in any other context.

",believe pep python command shed light issue relevant information found time ensure python target python unless user deliberately virtual environment active however end aware python python least arch change creation pep python used shebang line source compatible python order tolerate across new code need invoke python interpreter specify python rather specify either python python specific see migration distinction made shell script via system call context,issue,positive,positive,positive,positive,positive,positive
448060101,Thank you again for writing the detailed and thorough guide! Sorry that I could not reply in a timely fashion due to the time zone difference.,thank writing detailed thorough guide sorry could reply timely fashion due time zone difference,issue,negative,negative,neutral,neutral,negative,negative
448049708,I will take another look based on this example: https://github.com/fastai/fastai/blob/master/tests/test_utils.py#L9,take another look based example,issue,negative,neutral,neutral,neutral,neutral,neutral
448008570,"I'm glad you sorted it out, @Benudek! Looking forward to your PRs.",glad sorted looking forward,issue,negative,positive,positive,positive,positive,positive
448007722,"great section on the virtual env!

When running through section 'Editable Install Explained' the below section with .[ indeed works. So I guess as you said before I must be cding once too often into the directory fastai

Anyways, good learning curve for me - thx for helping out

_cd ~/github
git clone https://github.com/fastai/fastai
cd fastai
pip install -e "".[dev]""_",great section virtual running section install section indeed work guess said must often directory anyways good learning curve helping git clone pip install dev,issue,positive,positive,positive,positive,positive,positive
447949772,"Thank you for the suggestions, @odysseus0 - I have applied them all with extra prose and tweaks. If anything else needs to be done, please let me know.",thank applied extra prose anything else need done please let know,issue,positive,neutral,neutral,neutral,neutral,neutral
447940216,"> this new section https://docs.fast.ai/dev/develop.html#editable-install-explained looks helpful! thx
> 
> Couldn't execute the conda activate step though:
> _(base) bherudek-ltm1:fastai-fork bherudek$ conda activate fastai Could not find conda environment: fastai You can list all discoverable environments with `conda info --envs`._
> 
> Will need to study that a little more though to understand the context and where it comes into the picture when working with the fast.ai code locally

I added a new section: https://docs.fast.ai/install.html#virtual-environment
If there are questions still please ask.",new section helpful could execute activate step though base activate could find environment list discoverable need study little though understand context come picture working code locally added new section still please ask,issue,positive,negative,negative,negative,negative,negative
447920377,"All good, thx! Should Start with the issue description indeed",good start issue description indeed,issue,negative,positive,positive,positive,positive,positive
447918727,"> **Error Message**:
> Directory '.' is not installable. File 'setup.py' not found.
> **Steps to reproduce:**
> execute Step 3. Prepare Your Checkout (https://docs.fast.ai/dev/git.html)
> 
> _(base) bherudek-ltm1:fastai-fork bherudek$ cd fastai (base) bherudek-ltm1:fastai bherudek$ pip install -e .[dev] Directory '.' is not installable. File 'setup.py' not found. (base) bherudek-ltm1:fastai bherudek$_
> 
> Resolution:
> (1) cd - before pip install
> or go in below directory
> (2) pip install -e ..[dev]
> 
> or (as I understood from your comment): ' ... add that path to the python libs path ... '

That's better, thank you. As I suspected you are executing `cd fastai` twice and ending up inside `fastai` modules folder instead of the `fastai` project folder. I know it's confusing (the github user is `fastai` too!)
Have a look at the updated instructions, I used `fastai-fork` as a name for a checkout folder. 
Let me know if all is good now. https://docs.fast.ai/dev/git.html#step-3-prepare-your-checkout
",error message directory file found reproduce execute step prepare base base pip install dev directory file found base resolution pip install go directory pip install dev understood comment add path python path better thank suspected twice ending inside folder instead project folder know user look used name folder let know good,issue,positive,negative,negative,negative,negative,negative
447911528,"> @stas00 I think that was the script changed because of Windows, correct me if I'm wrong. Is there some way to make it both Linux and Windows compatible?

No, I have already changed that to python3 and then rolled back to python, because you said windows doesn't have python3.exe and you couldn't figure out how to symlink (or if it's even possible - no idea).

Absolutely no to 2 separate scripts with identical content.

And yes, changing the instruction to `python3 tools/run-after-git-clone` is one way (and backslash on windows).

Another way is require python3 at the top of the script, since fastai requires python 3.6+

```
import sys; 
if sys.version_info < (3,6): sys.exit(""Python 3.6+ is required.\n"")
```
though it doesn't seem to help with the parser - it still fails with ""invalid syntax"" syntax error

most recent systems still use python2 as python, it's the same on Ubuntu-18.04. 

**update**: It appears that `#!/usr/bin/env python3` shouldn't be a problem on windows, since the shebang line is ignored on windows. But since Sylvain had a problem with this setup, I will let him comment on this.

update2: changed the main repo tools/* to python3 shebang - take 2 - let's see if it works on windows. (someone needs to validate it on windows that is).",think script correct wrong way make compatible already python rolled back python said could figure even possible idea absolutely separate identical content yes instruction python one way another way require python top script since python import python though seem help parser still invalid syntax syntax error recent still use python python update python problem since shebang line since problem setup let comment update main python shebang take let see work someone need validate,issue,negative,positive,neutral,neutral,positive,positive
447864148,"Well, technically we can just change the instruction and ask Linux users to run `python3 tools/run-after-git-clone`. It will certainly be less elegant and more verbose, but will solve the problem.

Alternatively, we can distribute two separate set of scripts for Windows and Linux. Like `tools/win/run-after-gitclone` and `tools/linux/run-after-gitclone`.",well technically change instruction ask run python certainly le elegant verbose solve problem alternatively distribute two separate set like,issue,positive,positive,positive,positive,positive,positive
447854151,"That's because you didn't use `drop_last=True` for your training dataloader (now default in fastai) and ran in a batch of size 1, which causes error with BatchNorm during training (that's not us, it's on pytorch). You should use that option (or update your library).",use training default ran batch size error training u use option update library,issue,negative,neutral,neutral,neutral,neutral,neutral
447853585,"@stas00 I think that was the script changed because of Windows, correct me if I'm wrong. Is there some way to make it both Linux and Windows compatible?",think script correct wrong way make compatible,issue,negative,negative,negative,negative,negative,negative
447772986,"this new section https://docs.fast.ai/dev/develop.html#editable-install-explained looks helpful! thx 

Couldn't execute the conda activate step though:
_(base) bherudek-ltm1:fastai-fork bherudek$ conda activate fastai
Could not find conda environment: fastai
You can list all discoverable environments with `conda info --envs`._

Will need to study that a little more though to understand the context and where it comes into the picture when working with the fast.ai code locally


",new section helpful could execute activate step though base activate could find environment list discoverable need study little though understand context come picture working code locally,issue,negative,negative,negative,negative,negative,negative
447771051,"**Error Message**: 
Directory '.' is not installable. File 'setup.py' not found.
**Steps to reproduce:**
execute Step 3. Prepare Your Checkout (https://docs.fast.ai/dev/git.html)

_(base) bherudek-ltm1:fastai-fork bherudek$ cd fastai
(base) bherudek-ltm1:fastai bherudek$ pip install -e .[dev]
Directory '.' is not installable. File 'setup.py' not found.
(base) bherudek-ltm1:fastai bherudek$_ 

Resolution:
(1) cd - before pip install
or go in below directory
(2) pip install -e ..[dev]

or (as I understood from your comment): ' ... add that path to the python libs path ... '",error message directory file found reproduce execute step prepare base base pip install dev directory file found base resolution pip install go directory pip install dev understood comment add path python path,issue,negative,negative,negative,negative,negative,negative
447737375,"@stas00 Thank you for the appreciation! =) 

Ok, great! Sure, let's do as you've proposed then.",thank appreciation great sure let,issue,positive,positive,positive,positive,positive,positive
447727382,"OK, I just merged it and let's tweak it if needed in the master.

I only did a few basic tests and wiil test more in the next few days.",let tweak master basic test next day,issue,negative,neutral,neutral,neutral,neutral,neutral
447727232,"Great work, @devforfu!

It's odd, I pushed a small fix into your branch, but for some reason it didn't show up in the PR. 

https://github.com/fastai/fastai/compare/devforfu-fastai-make-pr-branch-to-python?expand=1",great work odd small fix branch reason show,issue,negative,positive,positive,positive,positive,positive
447700783,"@KaiLicht I am looking into it! There have been several vocal proposals on the forum, but the proposers somehow all missed each other. If you are still interested, we can start building one for fast.ai v1.",looking several vocal forum somehow still interested start building one,issue,negative,positive,positive,positive,positive,positive
447678729,"I started the documentation for the old version and wanted to propose it again when the new one is ready for documentation which I did in the forums. Since there was no comment I never looked into it again, just forgot to delete it.",documentation old version propose new one ready documentation since comment never forgot delete,issue,negative,positive,positive,positive,positive,positive
447674917,"The difficultly with this conversation is that you're not telling us what the problem is. You suggested a fix to a problem, but didn't explain what the problem is.

However, please, have a look at this new section I have just added. I have a feeling you were hit by a double installation problem discussed in that section.

https://docs.fast.ai/dev/develop.html#editable-install-explained",difficultly conversation telling u problem fix problem explain problem however please look new section added feeling hit double installation problem section,issue,negative,negative,negative,negative,negative,negative
447654977,"Sorry I do not mean to confront your authority, but the approach recommended in #596 does seem to have many advantages. What is the reason why we are taking the current approach?

I did find your [post](https://forums.fast.ai/t/documentation-for-fastai-v1/20735).

You mentioned that no documentation generator library incorporates Jupyter notebook directly, but [nbsphinx](https://nbsphinx.readthedocs.io/en/0.3.4/installation.html) does exactly that, as pointed out by Kai Lichtenberg in his [post](https://forums.fast.ai/t/documentation-for-fastai-v1/20735/3?u=pegasuswithoutwinds).",sorry mean confront authority approach seem many reason taking current approach find post documentation generator library notebook directly exactly pointed kai post,issue,negative,negative,neutral,neutral,negative,negative
447653041,We have used a different approach to build the [docs](https://docs.fast.ai/).,used different approach build,issue,negative,neutral,neutral,neutral,neutral,neutral
447648066,"partial is a python function, not a fastai function. `create_cnn` is a function, you shouldn't add attributes to it. In this case, it seems you want to pass `loss_func` or `opt_func` as arguments in your call.
Again, please use the [forum](https://forums.fast.ai/) to debug your code.",partial python function function function add case want pas call please use forum code,issue,negative,negative,neutral,neutral,negative,negative
447647943,"We can't help without seeing your code. To help to debug your code, please use [the forum](https://forums.fast.ai/). If you're sure it's fastai bug, please include a minimal example of reproduction when you open a new issue.",ca help without seeing code help code please use forum sure bug please include minimal example reproduction open new issue,issue,positive,positive,positive,positive,positive,positive
447624659,"Hmm, I really did try to follow the instructions step by step on the cmd and ran into this issue. What do I miss - I don't seem to find a comment on adding sth in the path?

It's a super minor thing really, no blocker or alike - so I mute myself here :-)",really try follow step step ran issue miss seem find comment path super minor thing really blocker alike mute,issue,positive,positive,positive,positive,positive,positive
447623389,"Please refer to https://pip.pypa.io/en/stable/reference/pip_install/#editable-installs
and https://pip.pypa.io/en/stable/reference/pip_install/#examples

You don't need to do anything, just follow the instructions - it will just work.",please refer need anything follow work,issue,negative,neutral,neutral,neutral,neutral,neutral
447610225,"Understand, thx ! Maybe good to also add this '**... add that path to the python libs path ...**' in the doc then. When I just followed the cmd steps (see below) I needed the .. ;-) And for those for whom the syntax '**.[dev]**' is somewhat unfamiliar (like for me) it takes a moment to figure out.

**> git clone https://github.com/fastai/fastai
> cd fastai**
--> add here sth like ... add a path to the python libs 
**> pip install -e .[dev]**",understand maybe good also add add path python path doc see syntax dev somewhat unfamiliar like moment figure git clone add like add path python pip install dev,issue,positive,positive,positive,positive,positive,positive
447589578,"If you want it on the fly, this may do the trick (installing a subdir `old`, where v0.7 currently lives - in the same repo as v1.0):
```
pip install git+https://github.com/fastai/fastai.git#subdirectory=old
```
but otherwise you follow the normal instructions:
https://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652

the problem is that currently it's not setup for having both versions in the same environment, so probably some path manipulation will be required. so if you switch to fastai-v1 as normal, then install fastai v0.7 into a hidden path, and prepend it onto sys.path before loading it in kernels that rely on fastai-0.7:
```
sys.path.insert(0, ""/path/to/fastai/v.0.7"")
import fastai
```",want fly may trick old currently pip install otherwise follow normal problem currently setup environment probably path manipulation switch normal install hidden path onto loading rely import,issue,negative,positive,positive,positive,positive,positive
447588178,"Thank you. Is it possible to clone v0.7?  Tried doing pip install, but that doesn't work.",thank possible clone tried pip install work,issue,negative,neutral,neutral,neutral,neutral,neutral
447584588,fastai v1 is very incompatible with v0.7. You will need to either rewrite your code to use the v1 API (https://docs.fast.ai/) or to carry both versions and load v0.7 for the old kernels and v1 for the new ones.,incompatible need either rewrite code use carry load old new,issue,negative,positive,positive,positive,positive,positive
447584358,"The current instructions are correct, @Benudek.

You 'cd' into the git checkout and then add that path to the python libs path. If you were to add "".."" you'd add the parent directory, which would be wrong.",current correct git add path python path add add parent directory would wrong,issue,negative,negative,negative,negative,negative,negative
447561450,"just a . ... the name of the branch is a little confusing (so ignore), it's just about the directory .. after the cd fast.ai in previous step",name branch little ignore directory previous step,issue,negative,negative,negative,negative,negative,negative
447439494,Is there a standard way used to implement the items? This seems like a new concept that doesn't show up anywhere else in the library (that I can find). Seems like `len(self.train_ds.items)` is trying to accomplish the same thing as what a `DataSet`'s `__len__` does? Is that wrong?,standard way used implement like new concept show anywhere else library find like trying accomplish thing wrong,issue,positive,negative,negative,negative,negative,negative
447417662,"Just pushed a fix. Don't expect anything apart training to work though, if you don't use fastai datasets.",fix expect anything apart training work though use,issue,negative,neutral,neutral,neutral,neutral,neutral
447408518,"The changes says ""DataBunch now has fix_dl attr, which is same data as train_dl but without shuffle or train tfms"", but this doesn't seem to match with the implementation. 

",data without shuffle train seem match implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
447339035,"That isn't a bug, and this is the intended behavior as labels in a multiclassification problem may be one-hot encoded as floats.
Factory methods are for beginners and can only deal with simple data, you should use the [data block API](https://docs.fast.ai/data_block.html) for such a problem, where you can pass the `label_cls` of your choice. ",bug intended behavior problem may factory deal simple data use data block problem pas choice,issue,negative,neutral,neutral,neutral,neutral,neutral
447272088,@sgugger Could you please tell us the meaning of fix_dl. We are very confunsed for that is not used but is required param. Thank you very much.,could please tell u meaning used param thank much,issue,positive,positive,positive,positive,positive,positive
447251330,"well, column B suffers the same transformation than the column B (`.round(2)`) but it doesn't display the floating point conversion problem (check the screenshot). this is why I believe, that the target variable is being processed / converted furthermore (check the output of the `show_batch()` command, index = 9)",well column transformation column display floating point conversion problem check believe target variable converted furthermore check output command index,issue,negative,neutral,neutral,neutral,neutral,neutral
447156916,"No need to be sorry, @pouannes, it's normal to not know from the get going how some project runs - we are a friendly bunch and are very happy to receive PRs, so please don't hesitate to ask if something is unclear. And once you learn something important/useful please add it to the documentation to help others.",need sorry normal know get going project friendly bunch happy receive please hesitate ask something unclear learn something please add documentation help,issue,positive,positive,positive,positive,positive,positive
447156140,"As it's my first PR ever I was wondering if those were normal or not... Sorry about that, I'll correct it !",first ever wondering normal sorry correct,issue,negative,negative,neutral,neutral,negative,negative
447155640,"Your editor is inserting/removing a bunch of whitespaces and new lines, so it first makes it almost impossible to even see what your real change is as you correctly noticed that it made dozens of changes, and of course, we don't need all those changes. I see also it changes *'s into _'s.

Please, try again starting with a fresh checkout and tune up your editor so that it doesn't add anything to the existing file. Just making the change you're trying to contribute.

Before committing, do `git diff` and check what you're changing. That will help you to tune up your editor to be less forceful and more accepting of other people's styles.",editor bunch new first almost impossible even see real change correctly made course need see also please try starting fresh tune editor add anything file making change trying contribute git check help tune editor le forceful people,issue,positive,positive,neutral,neutral,positive,positive
447132871,"Another approach to adding test folder 
https://docs.fast.ai/data_block.html#Add-a-test-set",another approach test folder,issue,negative,neutral,neutral,neutral,neutral,neutral
447132580,"@carbocation One way to use test set is 
```
src = (ImageItemList.from_csv(path, 'train_labels.csv', folder='', suffix='.tif',test = path2)
       .random_split_by_pct(0.2)
       .label_from_df())
```
```
data = (src.transform(tfms, size=128)
        .add_test_folder()
        .databunch().normalize(imagenet_stats))
```
```
print('Train size:', len(data.train_ds))
print('Valid size:', len(data.valid_ds))
print('Test size:', len(data.test_ds))
```
But in this method the CSV file has names of files in the train folder only. ",one way use test set path test path data print size print size print size method file train folder,issue,negative,neutral,neutral,neutral,neutral,neutral
447081455,"The target being modified is just a floating conversion, I believe. Will fix the list of cat_names being modified.",target floating conversion believe fix list,issue,negative,neutral,neutral,neutral,neutral,neutral
447080540,We have decided to stick with the order split then label (note that you can do no_split) and there is now an assertion error when you don't respect it. Closing this issue.,decided stick order split label note assertion error respect issue,issue,negative,neutral,neutral,neutral,neutral,neutral
447015300,"There was a bug with this function due to some changes in the library, but it has been fixed in 1.0.37.",bug function due library fixed,issue,negative,negative,neutral,neutral,negative,negative
447014570,"I'm suspecting you're passing lists for `trn` and `val`, when it should be `ItemList` object. This is more of an internal method, you should be using `split_by_files` if you want to pass a list of filenames for the validation set.",passing object internal method want pas list validation set,issue,negative,neutral,neutral,neutral,neutral,neutral
447007498,"Datasets have all been removed from the library, yes. Use the docs on the [data block API](https://docs.fast.ai/data_block.html) to see how to get your data in the more recent versions.",removed library yes use data block see get data recent,issue,negative,neutral,neutral,neutral,neutral,neutral
447006883,"Please use the [forum](https://forums.fast.ai/) for those questions. We keep issues for bugs in the library only, thanks!",please use forum keep library thanks,issue,positive,positive,positive,positive,positive,positive
447006195,"Please ask questions around the library on the [forum](https://forums.fast.ai/), issues are for bugs only, thanks!",please ask around library forum thanks,issue,positive,positive,positive,positive,positive,positive
446770597,This bit of code works perfectly for me. Are you sure you didn't do a developer install and changed something in the code of fastprogress? Or that you are in the right conda environment?,bit code work perfectly sure developer install something code right environment,issue,positive,positive,positive,positive,positive,positive
446765419,"Its a notebook specific thing, works in ipython terminal",notebook specific thing work terminal,issue,negative,neutral,neutral,neutral,neutral,neutral
446764716,"Yes, I do. I noticed that its only 8 days old, i wondered if there was a problem with it. An older version didnt' work either. managed to replicate with . 

```
from fastprogress import master_bar, progress_bar
from time import sleep
mb = master_bar(range(10))
for i in mb:
    for j in progress_bar(range(100), parent=mb):
        sleep(0.01)
        mb.child.comment = f'second bar stat'
    mb.first_bar.comment = f'first bar stat'
    mb.write(f'Finished loop {i}.')
```",yes day old problem older version didnt work either replicate import time import sleep range range sleep bar bar loop,issue,negative,positive,positive,positive,positive,positive
446724911,"Hi @sgugger, Thanks for pointing me to the proper forum. I posted it here: https://forums.fast.ai/t/can-i-use-fine-tuned-lms-to-generate-text/32548

However, if any of my scenarios is not implemented in fastai, it can be considered as a feature to include.",hi thanks pointing proper forum posted however considered feature include,issue,negative,positive,neutral,neutral,positive,positive
446714965,"Note: This may or may not be related to https://forums.fast.ai/t/recursion-error-fastai-v1-0-27-windows-10/30673 — I found this during my own bug hunt, but can't test due to not having Windows.",note may may related found bug hunt ca test due,issue,negative,negative,neutral,neutral,negative,negative
446682096,"Yes I will. But there was a family situation, thus I was and still am a little bit busy. I will try to look into this over the next week. Did some metrics implementations using Callback but didn't test them yet.",yes family situation thus still little bit busy try look next week metric test yet,issue,negative,negative,neutral,neutral,negative,negative
446605469,I'll close this PR since we can't merge until 2.0.18 is out on the main anaconda channel.,close since ca merge main anaconda channel,issue,negative,positive,positive,positive,positive,positive
446594986,"Ah, that's it, sorry I did not get that the main function signature silently changed after 1.0.22",ah sorry get main function signature silently,issue,negative,negative,negative,negative,negative,negative
446441793,"Hi, please use the [forum](https://forums.fast.ai) for those questions. We want to keep the issues are limited to bugs in the library, thanks!",hi please use forum want keep limited library thanks,issue,positive,positive,neutral,neutral,positive,positive
446253241,Many thanks - fixed in master using an alternative approach.,many thanks fixed master alternative approach,issue,negative,positive,positive,positive,positive,positive
446162445,This error only occurs when `num_workers!=0` which does not currently work on windows anyway.  I am not sure if this change will still need to be made when `num_workers!=0` works on windows so I have left it open.,error currently work anyway sure change still need made work left open,issue,negative,positive,positive,positive,positive,positive
446154137,"Hi, that has been fixed with the latest changes, thank you.",hi fixed latest thank,issue,negative,positive,positive,positive,positive,positive
446052751,"If you had a minimal repro of the bug in a gist, that would help us fix it!",minimal bug gist would help u fix,issue,negative,negative,neutral,neutral,negative,negative
446051245,"I ran into the same issue. Even when I created the train/validation set carefully (I created them at the label level) it I did not solve the error. Oddly enough, when I tried the same exact thing with from_folder instead of from_csv it worked fine. I am reusing code from other competitions that have worked fine with the csv option (I create the csv file from the folder structure) since from_folder caused me other issues in the past with OOM. Just adding this note in case there is something else to look into.",ran issue even set carefully label level solve error oddly enough tried exact thing instead worked fine code worked fine option create file folder structure since past note case something else look,issue,positive,positive,positive,positive,positive,positive
446010587,@jph00 has made a lof of changes to support Windows with the release of pytorch v1. Is this fix still necessary? Can you show it to us with a test that fails without it? Thanks!,made lof support release fix still necessary show u test without thanks,issue,negative,positive,neutral,neutral,positive,positive
445804552,I think I finally got it. Still feels weird.,think finally got still weird,issue,negative,negative,negative,negative,negative,negative
445707164,"You think we should recreate Imagenet mean and std and feed that data to model. I believe this is not true. An Imagenet model was trained and expects data with mean = 0 and std = 1. In order to get those you should calc mean and std from your own dataset and normalise it. imagenet_stats usefull for Imagenet subsample, so you don't need to recalc mean and std for it. 

Look to the code

```
def _normalize_batch(b:Tuple[Tensor,Tensor], mean:FloatTensor, std:FloatTensor, do_x:bool=True, do_y:bool=False)->Tuple[Tensor,Tensor]:
 ….
 x = normalize(x,mean,std)

def normalize(x:TensorImage, mean:FloatTensor,std:FloatTensor)->TensorImage:
""Normalize `x` with `mean` and `std`.""
return (x-mean[...,None,None]) / std[...,None,None]
```

This means we don’t recreate the original mean and std with out code. This is the formula to make it 0 and 1.
",think recreate mean feed data model believe true model trained data mean order get mean subsample need mean look code tensor tensor mean tensor tensor normalize mean normalize mean normalize mean return none none none none recreate original mean code formula make,issue,positive,negative,negative,negative,negative,negative
445572179,"No, it should be imagenet stats because we use a model pretrained on imagenet. Note that the small improvement in accuracy may very well come from the randomness of training.",use model note small improvement accuracy may well come randomness training,issue,positive,negative,negative,negative,negative,negative
445565628,"Will do. Being lazy plus overconfident has been my downfall before ... eventually I'll learn.

Thanks.",lazy plus overconfident downfall eventually learn thanks,issue,negative,negative,neutral,neutral,negative,negative
445558996,"And PRs to make fastai work better on windows are very welcome, @mengjiexu.",make work better welcome,issue,positive,positive,positive,positive,positive,positive
445556285,"Please be mindful that this is an open-source project. We know that pytorch v1 is out, we know Windows doesn't fully work with it (there are open issues and known bugs in the forum), and we will work on it at our pace in the next weeks.
Closing this in the meantime.",please mindful project know know fully work open known forum work pace next,issue,negative,neutral,neutral,neutral,neutral,neutral
445555135,Right. I'm afraid it's going to be in the next release (PS: this is why we need a test when adding a PR that fixes a bug ;) ),right afraid going next release need test bug,issue,negative,negative,negative,negative,negative,negative
445555000,"No, you need to update your fastprogress (pip install fastprogress --upgrade I believe).",need update pip install upgrade believe,issue,negative,neutral,neutral,neutral,neutral,neutral
445554521,"That's correct, @honnibal.

This is on purpose, since when there was the trouble with spacy's dependencies some weeks back, we found this pinned set to work everywhere and since we recommend to have a fastai-dedicated conda environment, in theory these should cause no conflicts. 

We are waiting for spacy 2.0.18 to become available on conda's main channel (currently it's only on conda-forge) and once this happens we will switch to depending on just `spacy==2.0.18` and remove its dependencies.",correct purpose since trouble spacy back found pinned set work everywhere since recommend environment theory cause waiting spacy become available main channel currently switch depending remove,issue,negative,positive,neutral,neutral,positive,positive
445508008,"Thanks!

But I solved the issue long ago: I just wasn't installing the proper way. I
was used to doing just ""git pull"" (the way to do it before 1.0) and didn't
realize everything changed with fast.ai 1.0.



On Thu, Dec 6, 2018 at 3:52 AM Dang Nguyen Anh Khoa <
notifications@github.com> wrote:

> @mraggi <https://github.com/mraggi> you could try doing pip install
> dataclasses
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/867#issuecomment-444813597>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AIAeboaiwSXlxTS60FTY7XqDZdrWlF16ks5u2OjfgaJpZM4XN1a5>
> .
>
",thanks issue long ago proper way used git pull way realize everything dang wrote could try pip install reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
445490650,"@jph00 :  if possible, can you merge this into v 1.0.35 release as a hotfix?  if not, i'm sure we're fine waiting for 1.0.36.",possible merge release sure fine waiting,issue,negative,positive,positive,positive,positive,positive
445467382,"@ohmeow @sgugger please always include tests with your bug-fix PRs - a test that would fail without your fix, and a test that should pass with the previous approach (if we don't already have a test for it). In this case, this PR refers to `monitor` instead of `self.monitor` so it causes the callback to fail in all cases. I've fixed it in master now - this is just a reminder that fixing broken code often takes longer than writing the code in the first place, since we have to get up to speed with the code and then fix it. So it's worth being careful that your PR really works the way you think. :) ",please always include test would fail without fix test pas previous approach already test case monitor instead fail fixed master reminder fixing broken code often longer writing code first place since get speed code fix worth careful really work way think,issue,negative,negative,neutral,neutral,negative,negative
445447791,"Thanks for the fix.
The second issue was a false alarm. While debugging I've changed the callback module without restarting the kernel, which then led to the issue of the two CallBack classes not being the same.",thanks fix second issue false alarm module without kernel led issue two class,issue,negative,negative,neutral,neutral,negative,negative
445397962,"Ok, closing this here and let's go on the forum to debug your code more as it seems the issue is there.",let go forum code issue,issue,negative,neutral,neutral,neutral,neutral,neutral
445395749,"Thanks for reaching out, I ran both the [Datablock API Notebook](https://github.com/gshashank84/learn-pytorch/blob/master/data_block.ipynb) and the [Lesson-3 Planet Notebook](https://github.com/gshashank84/learn-pytorch/blob/master/lesson3-planet%20(1).ipynb) and It works totally fine. I am using GCP as my current environment.",thanks reaching ran notebook planet notebook work totally fine current environment,issue,positive,positive,positive,positive,positive,positive
445387515,"Fixed the clas thing, not really sure what the problem is in the second point. The `Callback` class is loaded at this point.",fixed thing really sure problem second point class loaded point,issue,negative,positive,positive,positive,positive,positive
445386249,This is weird as your data is exactly as it should be. Can you run the planet example in this [doc notebook](https://github.com/fastai/fastai/blob/master/docs_src/data_block.ipynb) so that I see if the issue comes from your environment?,weird data exactly run planet example doc notebook see issue come environment,issue,negative,negative,negative,negative,negative,negative
445381639,Thanks for flagging and offering a fix!,thanks flagging offering fix,issue,negative,positive,positive,positive,positive,positive
445375687,"Do you mind looking at my [Jupyter Notebook](https://github.com/gshashank84/learn-pytorch/blob/master/Text_Tagging.ipynb) , what I am trying to do is Text Tagging with a given Dataset, where there are Multiple tags for a row of text.

It will be extremely helpful for me if you can suggest where I am doing wrong or their must be changes in code of FASTAI for MultiLabelCategoryList",mind looking notebook trying text given multiple row text extremely helpful suggest wrong must code,issue,negative,negative,negative,negative,negative,negative
445373866,"Which also supports fancy indexing, the problem you are facing probably comes from your data as I said in the issue.",also fancy indexing problem facing probably come data said issue,issue,negative,neutral,neutral,neutral,neutral,neutral
445372512,"Please fix the widget tests before we can merge, thanks!",please fix merge thanks,issue,positive,positive,positive,positive,positive,positive
445372265,"But the one hot encoding part is being done in Numpy, not Pytorch I guess",one hot part done guess,issue,negative,positive,positive,positive,positive,positive
445371734,"Please sign the CLA so that we can merge your PR, thanks!",please sign merge thanks,issue,positive,positive,positive,positive,positive,positive
445371465,"When you use that method, the labels are expected to be in the form of list of tags (see the planet example for instance), not one-hot encoded. Here the data object only finds two tags 0 and 1. ",use method form list see planet example instance data object two,issue,negative,neutral,neutral,neutral,neutral,neutral
445370659,"It is impossible to know what the problem is without seeing how you create your data, which is probably where the bug comes from. Please provide us more information, and ideally a minimal example of your bug.",impossible know problem without seeing create data probably bug come please provide u information ideally minimal example bug,issue,negative,negative,negative,negative,negative,negative
445370433,"x is always an array of indexes at this stage, and res[x] = 1. works because pytorch support fancy-indexing. ",always array stage work support,issue,negative,neutral,neutral,neutral,neutral,neutral
445325715,"Or I do think that at the one_hot method creates error due to multiple integers in the 'o'.
Here res[x] =1 raises IndexError because the x contains multiple integers. So I think there must be change in the code for **get** method in  **MultiCategoryList** Class for Multi-Labels.
```
def one_hot(x:Collection[int], c:int):
    ""One-hot encode `x` with `c` classes.""
    res = np.zeros((c,), np.float32)
    res[x] = 1.
    return res
```",think method error due multiple multiple think must change code get method class collection encode class return,issue,negative,negative,neutral,neutral,negative,negative
445172502,"> If you need more details, I documented @sgugger's suggestion above here:
> https://docs.fast.ai/data_block.html#LabelLists.add_test_folder

thank you,  this is helpful. ",need suggestion thank helpful,issue,positive,neutral,neutral,neutral,neutral,neutral
445153770,"ok, I have find it in the source code ,should be used with:
learn.TTA(ds_type=DatasetType.TEST)",find source code used,issue,negative,neutral,neutral,neutral,neutral,neutral
444947183,closed as this is issue using wrong metrics. My mistake.,closed issue wrong metric mistake,issue,negative,negative,negative,negative,negative,negative
444944813,"Yes, and we had a bug in the build which appeared when the wheel was built with py3.7, which is fixed now and will be made into a new release shortly.",yes bug build wheel built fixed made new release shortly,issue,negative,positive,neutral,neutral,positive,positive
444938000,"Thank you, @Lothiraldan. I will complete the cleanup shortly and make a new release.",thank complete cleanup shortly make new release,issue,negative,positive,neutral,neutral,positive,positive
444912052,"It looks like you want to validate on a different dataset. You should do `data_test=...` command that creates a DataBunch where your validation set is this labelled test. When you're done training, you can type `learn.data = data_test` then `learn.validate()`.",like want validate different command validation set test done training type,issue,positive,neutral,neutral,neutral,neutral,neutral
444910063,"I encountered this when training a supervised text classifier, inspired by the text example.  
I wanted to keep a subset of labeled data as test set while iterating over the dev set.  Is this not a valid way of using the test set?  ",training text classifier inspired text example keep subset data test set dev set valid way test set,issue,negative,neutral,neutral,neutral,neutral,neutral
444813597,@mraggi you could try doing `pip install dataclasses`,could try pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
444796169,This looks identical to  #1292 .  Feel free to merge my comments in with that one. ,identical feel free merge one,issue,positive,positive,positive,positive,positive,positive
444742114,Is it possible to load a custom pre-trained language model?,possible load custom language model,issue,negative,neutral,neutral,neutral,neutral,neutral
444671486,"Thank you for having pointed the example to me, exactly what I was looking for! Thx.",thank pointed example exactly looking,issue,negative,positive,positive,positive,positive,positive
444626111,"That looks great, thanks!  I'll take a look.",great thanks take look,issue,positive,positive,positive,positive,positive,positive
444585111,"Not sure this should be an issue, usually python handles Windows \ pretty well when with string filenames. We'll keep this issue for when we delve in Windows support for fastai, probably in a couple of weeks.",sure issue usually python pretty well string keep issue delve support probably couple,issue,positive,positive,positive,positive,positive,positive
444584073,"This issue doesn't really come from fastai AFAICT but more from the way you structure your data: you have labels in your validation set that aren't present in your training set. You shouldn't use a random split for your validation set when dealing with a very unbalanced dataset (like the whale competition), but create your validation set carefully.
I've changed the code so that the error is raised at the creation of the data with a clear message.",issue really come way structure data validation set present training set use random split validation set dealing unbalanced like whale competition create validation set carefully code error raised creation data clear message,issue,positive,negative,neutral,neutral,negative,negative
444559653,"If you're using fastai v1, you should check the [v1 docs](https://docs.fast.ai/). There is full support for ULMfit and a complete [overview here](https://docs.fast.ai/text.html).",check full support complete overview,issue,negative,positive,positive,positive,positive,positive
444537746,"I am also working with exact data set but i am getting IndexError instead of TypeError after one cycle fit. I guess JTunis's guess could be true. This data set have one example for most classes. Here is error: 

```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-18-be1ab4476b35> in <module>
----> 1 learn.fit_one_cycle(5, slice(lr))

/opt/anaconda3/lib/python3.6/site-packages/fastai/train.py in fit_one_cycle(learn, cyc_len, max_lr, moms, div_factor, pct_start, wd, callbacks, **kwargs)
     19     callbacks.append(OneCycleScheduler(learn, max_lr, moms=moms, div_factor=div_factor,
     20                                         pct_start=pct_start, **kwargs))
---> 21     learn.fit(cyc_len, max_lr, wd=wd, callbacks=callbacks)
     22 
     23 def lr_find(learn:Learner, start_lr:Floats=1e-7, end_lr:Floats=10, num_it:int=100, stop_div:bool=True, **kwargs:Any):

/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
    164         callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)
    165         fit(epochs, self.model, self.loss_func, opt=self.opt, data=self.data, metrics=self.metrics,
--> 166             callbacks=self.callbacks+callbacks)
    167 
    168     def create_opt(self, lr:Floats, wd:Floats=0.)->None:

/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)
     92     except Exception as e:
     93         exception = e
---> 94         raise e
     95     finally: cb_handler.on_train_end(exception)
     96 

/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in fit(epochs, model, loss_func, opt, data, callbacks, metrics)
     87             if hasattr(data,'valid_dl') and data.valid_dl is not None and data.valid_ds is not None:
     88                 val_loss = validate(model, data.valid_dl, loss_func=loss_func,
---> 89                                        cb_handler=cb_handler, pbar=pbar)
     90             else: val_loss=None
     91             if cb_handler.on_epoch_end(val_loss): break

/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_train.py in validate(model, dl, loss_func, cb_handler, pbar, average, n_batch)
     47     with torch.no_grad():
     48         val_losses,nums = [],[]
---> 49         for xb,yb in progress_bar(dl, parent=pbar, leave=(pbar is not None)):
     50             if cb_handler: xb, yb = cb_handler.on_batch_begin(xb, yb, train=False)
     51             val_losses.append(loss_batch(model, xb, yb, loss_func, cb_handler=cb_handler))

/opt/anaconda3/lib/python3.6/site-packages/fastprogress/fastprogress.py in __iter__(self)
     63         self.update(0)
     64         try:
---> 65             for i,o in enumerate(self._gen):
     66                 yield o
     67                 if self.auto_update: self.update(i+1)

/opt/anaconda3/lib/python3.6/site-packages/fastai/basic_data.py in __iter__(self)
     66         ""Process and returns items from `DataLoader`.""
     67         assert not self.skip_size1 or self.batch_size > 1, ""Batch size cannot be one if skip_size1 is set to True""
---> 68         for b in self.dl:
     69             y = b[1][0] if is_listy(b[1]) else b[1]
     70             if not self.skip_size1 or y.size(0) != 1: yield self.proc_batch(b)

/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py in __next__(self)
    635                 self.reorder_dict[idx] = batch
    636                 continue
--> 637             return self._process_next_batch(batch)
    638 
    639     next = __next__  # Python 2 compatibility

/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py in _process_next_batch(self, batch)
    656         self._put_indices()
    657         if isinstance(batch, ExceptionWrapper):
--> 658             raise batch.exc_type(batch.exc_msg)
    659         return batch
    660 

IndexError: Traceback (most recent call last):
  File ""/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py"", line 138, in _worker_loop
    samples = collate_fn([dataset[i] for i in batch_indices])
  File ""/opt/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py"", line 138, in <listcomp>
    samples = collate_fn([dataset[i] for i in batch_indices])
  File ""/opt/anaconda3/lib/python3.6/site-packages/fastai/data_block.py"", line 480, in __getitem__
    if self.item is None: x,y = self.x[idxs],self.y[idxs]
  File ""/opt/anaconda3/lib/python3.6/site-packages/fastai/data_block.py"", line 92, in __getitem__
    if isinstance(try_int(idxs), int): return self.get(idxs)
  File ""/opt/anaconda3/lib/python3.6/site-packages/fastai/data_block.py"", line 329, in get
    return MultiCategory(one_hot(o, self.c), [self.classes[p] for p in o], o)
  File ""/opt/anaconda3/lib/python3.6/site-packages/fastai/core.py"", line 210, in one_hot
    res[x] = 1.
IndexError: arrays used as indices must be of integer (or boolean) type

```",also working exact data set getting instead one cycle fit guess guess could true data set one example class error recent call last module slice learn learn learn learner fit self self fit self none fit model opt data metric except exception exception raise finally exception fit model opt data metric data none none validate model else break validate model average none model self try enumerate yield self process assert batch size one set true else yield self batch continue return batch next python compatibility self batch batch raise return batch recent call last file line file line file line none file line return file line get return file line used index must integer type,issue,positive,positive,positive,positive,positive,positive
444531889,"Looking at the data it appears that many of the categories only have one or two images. My guess would be that when the data is split for training and validation, all of the images for a respective category may be in the validation set and that may be causing issues. ",looking data many one two guess would data split training validation respective category may validation set may causing,issue,negative,positive,positive,positive,positive,positive
444508342,Sounds like an installation issue (also you might have to remove the .fp16() call). You should check the [forum]() and ask your question with more details in the [troubleshooting page](https://forums.fast.ai/).,like installation issue also might remove call check forum ask question page,issue,negative,neutral,neutral,neutral,neutral,neutral
444498417,Please fill in the template and give more information.,please fill template give information,issue,negative,neutral,neutral,neutral,neutral,neutral
444497383,Seems like it would fix this. Would you mind making a PR for this?,like would fix would mind making,issue,negative,neutral,neutral,neutral,neutral,neutral
444452515,"The exception is in the default_collate function of PyTorch's dataloader.py: it checks type of first item in provided batch and decides what to do next. It fails to determine the right type if first entry is None.

In case that first element is not None, it will fail at torch.LongTensor() constructor if one of the values in the batch is None.
So, that's the reason for two different error messages, but kind of the same root cause.

Just for test, I replaced all None values with zero and also located first not None element in batch and epoch completes successfully, but it probably produces completely wrong model (output of accuracy was ~0.01)

Not sure what is the origin of those None-s. Is it because a lot of values in original data are NaN or maybe there is some mismatch with categorical buckets? didn't have more time to research...",exception function type first item provided batch next determine right type first entry none case first element none fail constructor one batch none reason two different error kind root cause test none zero also first none element batch epoch successfully probably completely wrong model output accuracy sure origin lot original data nan maybe mismatch categorical time research,issue,positive,positive,positive,positive,positive,positive
444452328,"+1
I'm getting the error at the end of the first fit cycle as well.",getting error end first fit cycle well,issue,negative,positive,positive,positive,positive,positive
444340106,"Oh this is legacy code that we forgot to remove. Just did, thanks for flagging!",oh legacy code forgot remove thanks flagging,issue,negative,positive,positive,positive,positive,positive
444330565,"All datasets have been removed and replaced by the data block API. You can find an example of use with object detection in the [ docs](https://docs.fast.ai/data_block.html#Examples-of-use) (you'll have to scroll down a bit, there's no direct link to this specific example).",removed data block find example use object detection scroll bit direct link specific example,issue,negative,positive,neutral,neutral,positive,positive
444102595,Great! Can you just remove commented code that was probably there for debugging?,great remove code probably,issue,positive,positive,positive,positive,positive,positive
444101742,"I'm unsure which silent error you are referring to. The test set is supposed to be a set of unlabeled data, and the load function doesn't look for test labels, or the `from_ids` function that is ultimately called doesn't take a test_lbl argument.",unsure silent error test set supposed set unlabeled data load function look test function ultimately take argument,issue,negative,neutral,neutral,neutral,neutral,neutral
443865140,"Getting `TypeError: get_preds() got an unexpected keyword argument 'ordered' ;`

```
path = untar_data(URLs.MNIST_SAMPLE)
data = ImageDataBunch.from_folder(path)
learn = create_cnn(data, models.resnet18, metrics=accuracy)
learn.fit(1)

preds_train = learn.get_preds(ds_type = DatasetType.Train, ordered=True)
```
seems only implemented in _fastai/text/learner.py_ yet but not in  _fastai/vision/learner.py_ or _fastai/basic_train.py_ ; 

* torch-nightly-1.0.0.dev20181202
* fastai-1.0.31",getting got unexpected argument path data path learn data yet dev,issue,negative,positive,neutral,neutral,positive,positive
443746354,"The current version of the course is built on top of fastai v0.7 which isn't compatible with python 3.7 (and we have no plan to make it so because...)
fastai v1 and the new version of the course (to come in January) will fully be. That's why the other PR was closed and I'm closing this one too.",current version course built top compatible python plan make new version course come fully closed one,issue,negative,positive,positive,positive,positive,positive
443705657,"hey, you're my first customer :) I actually didn't expect anyone to use this metric, which originated as a callback.

1. You're right. It's missing a `self.clas`

2. I suspect it being a callback, you would likely have to do it this way to use it immediately:

```
learn = text_classifier_learner(data_clas, drop_mult=0.5)
learn.load_encoder('fine_tuned_enc')
learn.metrics=[accuracy, Fbeta_binary(beta2=1,clas = 1)]
``` 
Or if you want F1 for label 0

```
learn = text_classifier_learner(data_clas, drop_mult=0.5)
learn.load_encoder('fine_tuned_enc')
learn.metrics=[accuracy, Fbeta_binary(beta2=1,clas = 0)]
```",hey first customer actually expect anyone use metric right missing suspect would likely way use immediately learn accuracy want label learn accuracy,issue,negative,positive,neutral,neutral,positive,positive
443610770,"Hi,
I got a similar issue with the 'House Price' Kaggle Competition. I posted it on the forums [here](https://forums.fast.ai/t/kernel-interrupt-on-learn-fit/31665), but no one answered yet. 
Weird thing is, that the error varies. Sometimes it will raise 
`TypeError: batch must contain tensors, numbers, dicts or lists; found <class 'NoneType>.`
and sometimes it will show the error mentioned by you. 

Looking forward to a solution!
Greetings,
Maik",hi got similar issue price competition posted one yet weird thing error sometimes raise batch must contain found class sometimes show error looking forward solution,issue,negative,negative,negative,negative,negative,negative
443589343,"Here is another related problem along the same issue (not checking folder exists/has items):

```
data = (ImageItemList.from_folder(mnist)
        .split_by_folder()          
        .label_from_folder()
        .transform(tfms, size=32)
        .databunch()
        .normalize(imagenet_stats)) 
```
if 'valid' folder doesn't exist, the user gets:

""IndexError: index 0 is out of bounds for axis 0 with size 0""

instead of ""'valid' folder is missing from {path}"" or something like that.

to reproduce, delete `fastai/data/mnist_tiny/valid`.

And of course, I was using a different dataset, not mnist, which originally had no 'valid' folder. I am just using 'mnist' in the code as an example.
",another related problem along issue folder data folder exist user index axis size instead folder missing path something like reproduce delete course different originally folder code example,issue,negative,positive,neutral,neutral,positive,positive
443533762,You have to pass `ordered=True` to get your predictions ordered like the items.,pas get ordered like,issue,negative,neutral,neutral,neutral,neutral,neutral
443525767,"Hi, 

I get the very same error at ""lern.fit(1)"" when I run the code from ""https://docs.fast.ai/vision.html"" (with dogscats).
I then changed ""data = ImageDataBunch.from_folder(path)"" to ""data = ImageDataBunch.from_folder(path, size=224)"" but the error stays.

Where do I have to put the ""size""?

",hi get error run code data path data path error stay put size,issue,negative,neutral,neutral,neutral,neutral,neutral
443507270,Note that the recommended behavior is to split then label. The other way is completely untested and fixing it isn't a priority.,note behavior split label way completely untested fixing priority,issue,negative,positive,neutral,neutral,positive,positive
443461805,"Thanks. Fbeta_binary, still doesn't work. There are other issues with it. Will create a related issue.",thanks still work create related issue,issue,positive,positive,neutral,neutral,positive,positive
443458617,Thanks for all of this! I also added a reset of the hidden state.,thanks also added reset hidden state,issue,negative,positive,neutral,neutral,positive,positive
443457152,"You forgot to use the factory method:
```
data_lm = TextLMDataBunch.from_csv(path, 'texts.csv')
```",forgot use factory method path,issue,negative,neutral,neutral,neutral,neutral,neutral
443386431,"Many thanks for noticing this - the issue is the missing `.view(-1, 1)` in our code. We'll fix it. And you temperature suggestion seems reasonable too.",many thanks issue missing code fix temperature suggestion reasonable,issue,negative,positive,positive,positive,positive,positive
443380030,"I think the current implementation of the metric implies that we can only have two classes at max as it first takes argmax along the class dim then uses element-wise multiplication to calculate the overlap. But in that case, could someone help me understand why a single class won't suffice for the task?",think current implementation metric two class first along class dim multiplication calculate overlap case could someone help understand single class wo suffice task,issue,negative,positive,neutral,neutral,positive,positive
443295380,"You have to explicitely pass a test argument (test='test' in this case, but check the [docs](https://docs.fast.ai/)).",pas test argument case check,issue,negative,neutral,neutral,neutral,neutral,neutral
443285460,Thanks @navjotts . There's currently a test failing in test_text_train . Could you take a look?,thanks currently test failing could take look,issue,negative,positive,neutral,neutral,positive,positive
443277017,"@jph00 : the multi-label classification test we had before was failing, but it was commented out

**old:**
```
def test_classifier():
    for n_labels in [1]: # , 8 - does not work for multilclass yet
    ...
```

In the current PR, I have switched it back on to `for n_labels in [1, 8]:`",classification test failing old work yet current switched back,issue,negative,positive,neutral,neutral,positive,positive
443218960,"Could you please also add a test that fails without your fix, and passes with it, so we can be sure there aren't regressions in the future?",could please also add test without fix sure future,issue,negative,positive,positive,positive,positive,positive
443218307,Since internally you have the GIL I don't see that this is actually useful on Windows.,since internally see actually useful,issue,negative,positive,positive,positive,positive,positive
443216212,"As you can see from the test, this change breaks many things.",see test change many,issue,negative,positive,positive,positive,positive,positive
443187309,"Facing the same issue, I am not sure but maybe the error is data dependent. ",facing issue sure maybe error data dependent,issue,negative,positive,positive,positive,positive,positive
443023686,"To add to the discussion, the `TextDataBunch.from_df` has a different API that takes the `test_df` into account: https://docs.fast.ai/text.data.html#TextDataBunch.from_df",add discussion different account,issue,negative,neutral,neutral,neutral,neutral,neutral
443010164,Are you sure you have the right version of fastai? I just ran the notebook without any issue. Please use the [forum](https://forums.fast.ai/) for installation troubleshooting.,sure right version ran notebook without issue please use forum installation,issue,negative,positive,positive,positive,positive,positive
442554127,"conda is failing to install `jupyter-contrib-nbextension`, so you probably need to report this in https://github.com/ipython-contrib/jupyter_contrib_nbextensions.

The only other reference to this issue I found is: https://github.com/IRkernel/IRkernel/issues/581

But first I'd recommend updating your conda to the latest:

    conda install conda",failing install probably need report reference issue found first recommend latest install,issue,negative,positive,positive,positive,positive,positive
442551003,"FYI, I have the same issue. I'll look around, but here is my information:
```
[ ... Snip ... ]
    from . import (constants, error, message, context,
ImportError: /home/nmvega/ANACONDA3.d/lib/python3.6/site-packages/zmq/backend/cython/utils.cpython-36m-x86_64-linux-gnu.so: undefined symbol: zmq_curve_public
```
My environment ...
```
     active environment : None
       user config file : /home/nmvega/.condarc
 populated config files : /home/nmvega/.condarc
          conda version : 4.5.11
    conda-build version : 3.16.3
         python version : 3.6.7.final.0
       base environment : /home/nmvega/ANACONDA3.d  (writable)
           channel URLs : https://conda.anaconda.org/conda-forge/linux-64
                          https://conda.anaconda.org/conda-forge/noarch
                          https://repo.anaconda.com/pkgs/main/linux-64
                          https://repo.anaconda.com/pkgs/main/noarch
                          https://repo.anaconda.com/pkgs/free/linux-64
                          https://repo.anaconda.com/pkgs/free/noarch
                          https://repo.anaconda.com/pkgs/r/linux-64
                          https://repo.anaconda.com/pkgs/r/noarch
                          https://repo.anaconda.com/pkgs/pro/linux-64
                          https://repo.anaconda.com/pkgs/pro/noarch
          package cache : /home/nmvega/ANACONDA3.d/pkgs
                          /home/nmvega/.conda/pkgs
       envs directories : /home/nmvega/ANACONDA3.d/envs
                          /home/nmvega/.conda/envs
               platform : linux-64
             user-agent : conda/4.5.11 requests/2.20.1 CPython/3.6.7 Linux/4.19.2-200.fc28.x86_64 fedora/28 glibc/2.27
                UID:GID : 1000:1000
             netrc file : None
           offline mode : False
```",issue look around information snip import error message context undefined symbol environment active environment none user file version version python version final base environment writable channel package cache platform gid file none mode false,issue,negative,negative,negative,negative,negative,negative
442486862,Thanks for flagging this! The docs were wrong and the code was right.,thanks flagging wrong code right,issue,negative,negative,neutral,neutral,negative,negative
442471893,You want to be able to create empty ItemList (for inference for instance) so it can't be checked in the __init__ method. Let me think about this.,want able create empty inference instance ca checked method let think,issue,negative,positive,positive,positive,positive,positive
442445075,never mind. I was just confused by the name. ,never mind confused name,issue,negative,negative,negative,negative,negative,negative
441843894,"I'll push a fix to override the default metrics. Note that fbeta is intended for multiclass problems, there is another implementation for classification (fbeta_something, the name escapes me right now).",push fix override default metric note intended another implementation classification name right,issue,negative,positive,positive,positive,positive,positive
441843656,Docs run without any problem here. Are you sure you have the latest version of fastai?,run without problem sure latest version,issue,negative,positive,positive,positive,positive,positive
441843593,Doc notebooks run without any issue here. Are you sure it's not an install issue?,doc run without issue sure install issue,issue,negative,positive,positive,positive,positive,positive
441833313,"I am facing the same issue. Here is a minimal code for a CharRNN https://gist.github.com/meghprkh/faeba5aefd460ecede7337f7e2096bd3

In this, the data is a 25 length character string of ""a-z"" vocabulary mapping to another 25 length character string",facing issue minimal code data length character string vocabulary another length character string,issue,negative,negative,neutral,neutral,negative,negative
441717903,"Thanks for pointing this out. The torchvision files are from another non-fastai project - we're just keeping a copy. And we kept the other models using a consistent filename.

For fastai v1 all model files now use .pth as the extension. I don't want to rename stuff in old versions since it'll break anything that relies on them.",thanks pointing another project keeping copy kept consistent model use extension want rename stuff old since break anything,issue,negative,positive,positive,positive,positive,positive
441667250,This might happen because the class 1 doesn't appear in your validation set: by default there is a random split and maybe you were unlucky and it wasn't picked. You can pass classes=bla if you want to fix the classes to use.,might happen class appear validation set default random split maybe unlucky picked pas want fix class use,issue,negative,negative,negative,negative,negative,negative
441666193,"I can't reproduce this with your code, it run fines, not fitting on the test set, and I can call `y_test = learn.get_preds(ds_type=DatasetType.Test)`.
Maybe this was solved by something else, but if the bug persists, please reopen with a minimal example in a gist.",ca reproduce code run fitting test set call maybe something else bug please reopen minimal example gist,issue,negative,positive,positive,positive,positive,positive
441655320,"Closing this for now. You can use the [forum](https://forums.fast.ai) to get some help to debug your code. If this is an issue with fastai, we can't do anything to fix it without a minimal example that reproduces the bug in a gist.",use forum get help code issue ca anything fix without minimal example bug gist,issue,negative,negative,neutral,neutral,negative,negative
441654777,"Your link is pointing toward the function needed to generate a new notebook. We'll remove the mentions of the old script, thanks for flagging!",link pointing toward function generate new notebook remove old script thanks flagging,issue,negative,positive,positive,positive,positive,positive
441645937,"Same problem here, but I'm getting a different error message.

Here's my code that leads to the error:
```python
tokenizer = Tokenizer(lang=tokenizer_lang, n_cpus=cpu_count())
data = TextClasDataBunch.from_csv(data_root,
                                  classifier_feedbacks_file,
                                  tokenizer=tokenizer,
                                  bs=batch_size,
                                  label_cols=list(range(n_labels)),
                                  text_cols=n_labels,
                                  classes=list(range(n_labels)),
                                  vocab=lm_vocab)

next(iter(data.valid_dl)) # works fine

data.save('classifier_data_cache')
data = TextClasDataBunch.load(data_root, 'classifier_data_cache')

next(iter(data.valid_dl)) # fails
```
Error:
```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-37-a07817f16b7f> in <module>
----> 1 next(iter(data.valid_dl))

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/basic_data.py in __iter__(self)
     45     def __iter__(self):
     46         ""Process and returns items from `DataLoader`.""
---> 47         for b in self.dl:
     48             y = b[1][0] if is_listy(b[1]) else b[1]
     49             if not self.skip_size1 or y.size(0) != 1: yield self.proc_batch(b)

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/dataloader.py in __next__(self)
    579     def __next__(self):
    580         if self.num_workers == 0:  # same-process loading
--> 581             indices = next(self.sample_iter)  # may raise StopIteration
    582             batch = self.collate_fn([self.dataset[i] for i in indices])
    583             if self.pin_memory:

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/torch/utils/data/sampler.py in __iter__(self)
    158     def __iter__(self):
    159         batch = []
--> 160         for idx in self.sampler:
    161             batch.append(idx)
    162             if len(batch) == self.batch_size:

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/data.py in __iter__(self)
     59     def __len__(self) -> int: return len(self.data_source)
     60     def __iter__(self):
---> 61         return iter(sorted(range_of(self.data_source), key=self.key, reverse=True))
     62 
     63 class SortishSampler(Sampler):

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/text/data.py in <lambda>(t)
    244         dataloaders = [train_dl]
    245         for ds in datasets[1:]:
--> 246             sampler = SortSampler(ds.x, key=lambda t: len(ds[t][0].data))
    247             dataloaders.append(DataLoader(ds, batch_size=bs, sampler=sampler, **kwargs))
    248         return cls(*dataloaders, path=path, collate_fn=collate_fn)

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in __getitem__(self, idxs)
    413     def __getitem__(self,idxs:Union[int,np.ndarray])->'LabelList':
    414         if isinstance(try_int(idxs), int):
--> 415             if self.item is None: x,y = self.x[idxs],self.y[idxs]
    416             else:                 x,y = self.item   ,0
    417             if self.tfms:

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in __getitem__(self, idxs)
     80 
     81     def __getitem__(self,idxs:int)->Any:
---> 82         if isinstance(try_int(idxs), int): return self.get(idxs)
     83         else: return self.new(self.items[idxs], xtra=index_row(self.xtra, idxs))
     84 

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/data_block.py in get(self, i)
    276         o = self.items[i]
    277         if o is None: return None
--> 278         return self._item_cls(one_hot(o, self.c), [self.classes[p] for p in o], o)
    279 
    280     def reconstruct(self, t):

/usr/local/miniconda3/envs/fastai/lib/python3.7/site-packages/fastai/core.py in one_hot(x, c)
    191     ""One-hot encode the target.""
    192     res = np.zeros((c,), np.float32)
--> 193     res[x] = 1.
    194     return res
    195 

IndexError: arrays used as indices must be of integer (or boolean) type
```
It seems like it calls one_hot on x that already is a one-hot encoded ndarray.",problem getting different error message code error python data range range next iter work fine data next iter error recent call last module next iter self self process else yield self self loading index next may raise batch index self self batch batch self self return self return iter sorted class sampler lambda sampler return self self union none else self self return else return get self none return none return reconstruct self encode target return used index must integer type like already,issue,negative,positive,neutral,neutral,positive,positive
441603482,"The support for text model will be added in future PR, I think this one is ok to be merged",support text model added future think one,issue,negative,neutral,neutral,neutral,neutral,neutral
441490780,"We had some git issues during collaboration, so this includes a copy of @fpingham's duplicate detector, but does not include his branch.",git collaboration copy duplicate detector include branch,issue,negative,neutral,neutral,neutral,neutral,neutral
441487693,"I changed the name for that reason exactly, but forgot to change it in \_\_all\_\_, thanks for flagging!
",name reason exactly forgot change thanks flagging,issue,negative,positive,positive,positive,positive,positive
441481618,"@sgugger I will add it to the same PR  #1239. As we have it already merged to our version of fastai and I would like to avoid future conflicts. 
Btw TextClasDataBunch was not using tokenizer parameter I've fixed it as well and added a test to show that it is fixed.",add already version would like avoid future parameter fixed well added test show fixed,issue,negative,positive,neutral,neutral,positive,positive
441443155,"Maybe do the conversion to object in from_ids, no need for a preprocessor I think. Can you add your unit test in the same PR?",maybe conversion object need think add unit test,issue,negative,neutral,neutral,neutral,neutral,neutral
441435544,same exercise but getting this in the end. RuntimeError: you can only change requires_grad flags of leaf variables. If you want to use a computed variable in a subgraph that doesn't require differentiation use var_no_grad = var.detach(). ,exercise getting end change leaf want use variable require differentiation use,issue,negative,neutral,neutral,neutral,neutral,neutral
441429235,"@pvcastro yes, in my situation, it's before it even gets to the CUDA; purely in the tokenization stage",yes situation even purely stage,issue,negative,positive,positive,positive,positive,positive
441415906,"There's a bigger issue with the Windows 10 compatibility that will need to be resolved for this to work.
",bigger issue compatibility need resolved work,issue,negative,neutral,neutral,neutral,neutral,neutral
441399616,"Although the scripts are tokenizing wikipedia articles with Moses Tokenizer and there is a chance that it is causing low downstream task performance.
",although chance causing low downstream task performance,issue,negative,neutral,neutral,neutral,neutral,neutral
441399524,"@nathanvl  this is old code and it is going to be replaced by something that works with fastai v1. If you need some scripts to fetch and transform wikipedia you can fetch them from here: https://github.com/n-waves/ulmfit-multilingual
",old code going something work need fetch transform fetch,issue,negative,positive,neutral,neutral,positive,positive
441389280,Haven't figure out how to make text model work.,figure make text model work,issue,negative,neutral,neutral,neutral,neutral,neutral
441385385,"@sgugger Data was loaded correctly into the data-frame as far as I saw, visualization steps were taken out of the given example for brevity.  Visualizing x and y looked fine too, other than the data types being inconsistent.  While seq2seq may not be supported, I do think this is a legitimate bug that will pop up again in the future.",data loaded correctly far saw visualization taken given example brevity fine data inconsistent may think legitimate bug pop future,issue,negative,positive,positive,positive,positive,positive
441384692,"There's no seq2seq implemented in fastai yet, that's in development. If your inputs and/or targets aren't loaded as you wish it's probably because you didn't load your data properly. It's very likey that TextLMDataBunch or TextClasDataBunch won't work for seq2seq, you should use the data block API.
In any case, this will be better discussed on the [forum](https://forums.fast.ai).",yet development loaded wish probably load data properly wo work use data block case better forum,issue,negative,positive,positive,positive,positive,positive
441374724,"Just use the block api. Create a custom ImageItemList. For instance, I have a custom one for opening 4 channel images:
```
class MyImageItemList(ImageItemList):
    def open(self, fn:PathOrStr)->Image:
        image = open_image4d(fn)
        return image
```
and then you use the block API:
```
src = (MyImageItemList.from_df(df=seg, path=PATH, folder=TRAIN)
           .random_split_by_pct(pct)
           .label_from_df(sep=' ')
```",use block create custom instance custom one opening channel class open self image image return image use block,issue,negative,neutral,neutral,neutral,neutral,neutral
441363602,Progress: work for standard pytorch module and most fastai Learner except Text now.,progress work standard module learner except text,issue,negative,neutral,neutral,neutral,neutral,neutral
441342741,"Right, the only issue is that I am using a custom dataset class and wanted to build `ImageDataBunch` manually :) However, as I can see, it is not supported since `1.0.22`.",right issue custom class build manually however see since,issue,negative,positive,positive,positive,positive,positive
441332390,"Have checked and you are correct the recorder train loss tensor is on cpu.
The problem is that the train loss is a tensor and the validation loss is
not a tensor but a list. So to get the max of train/valid losses together
you  need to convert them to same format. So at train.py/57 a new tensor is
created for the validation loss. As I have default tensor type set to cuda
then that is what is created.

y_bounds = (0, max((max(Tensor(rec.losses)), max(Tensor(rec.val_losses)))))


It would be more consistent to set both train and valid loss to same format
in the first place. No need to pass tensors to the progress bar; and only a
single max could be used here.

On Fri, 23 Nov 2018 at 22:54, Sylvain Gugger <notifications@github.com>
wrote:

> Ah interesting point. I'll make timing tests of training with/without
> .item() to see if this is correct.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1228#issuecomment-441327048>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABJN6fgVOLHLDdDMoF3EaIYfF8kuRWNvks5uyHyrgaJpZM4Yv36p>
> .
>
",checked correct recorder train loss tensor problem train loss tensor validation loss tensor list get together need convert format new tensor validation loss default tensor type set tensor tensor would consistent set train valid loss format first place need pas progress bar single could used wrote ah interesting point make timing training see correct thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
441327048,Ah interesting point. I'll make timing tests of training with/without .item() to see if this is correct.,ah interesting point make timing training see correct,issue,negative,positive,positive,positive,positive,positive
441326987,"Please provide us with more information, we can't help without more code/context.",please provide u information ca help without,issue,positive,neutral,neutral,neutral,neutral,neutral
441317504,"There is a comment in pytorch issues re speed of ""item()"". Says that it
shows up on profilers as slow because GPU calls are async. So it may be
that ""item()"" is not actually slowing things down or triggering a sync.
Instead it is waiting for a sync but other code carries on in parallel.
Hence it just looks slow.

On Fri, 23 Nov 2018 at 20:51, simon mackenzie <simonm3@gmail.com> wrote:

> It is because I have default tensor type of cuda. And they are not put on
> the CPU by the CallbackHandler - I agree they should be!
>
> torch.set_default_tensor_type(torch.cuda.FloatTensor) => Now all new
> tensors are created cuda by default.
> basic_train/25 => loss = cb_handler.on_backward_begin(loss) => this is a
> cuda tensor
> basic_train/302 is Recorder.on_backward_begin. This does NOT put the
> tensor on the CPU.
>
> If not item() then perhaps just use .cpu()? There does not seem to be any
> logic in having training losses stored as tensors nor in passing tensors to
> the progress bar. Especially as validation losses are already just stored
> as list of floats not as tensors.
>
>
>
>
>
> On Fri, 23 Nov 2018 at 19:56, Sylvain Gugger <notifications@github.com>
> wrote:
>
>> Again, I'm not sure how you manage to get CUDA tensors recorded there
>> since they are put on the CPU by the CallbackHandler.
>> The .item() method is very slow because it triggers a CUDA
>> synchronization, which is why we don't use it for the losses.
>>
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/fastai/fastai/pull/1228#issuecomment-441310477>, or mute
>> the thread
>> <https://github.com/notifications/unsubscribe-auth/ABJN6WkgBamiSeBVCgizFwdTODF5FLNHks5uyFLQgaJpZM4Yv36p>
>> .
>>
>
",comment speed item slow may item actually sync instead waiting sync code parallel hence slow wrote default tensor type put agree new default loss loss tensor put tensor item perhaps use seem logic training passing progress bar especially validation already list wrote sure manage get since put method slow synchronization use thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
441317355,"At line 25, the loss that is passed is on the GPU, as it can still be modified by other callbacks. At line 309, the loss that is given back by the callback handler is on the CPU, as it was sent to the Smoothener like this by the callback handler [here][https://github.com/fastai/fastai/blob/17ab600b4d530bca07e12100470fde9f505fdf38/fastai/callback.py#L227). 

Again, if I do any training (on the GPU), then ask for learn.recorder.losses, everything is on the CPU (as tensors, but sadly .item() seems to make a big loss in efficiency). I just retested it on master.",line loss still line loss given back handler sent like handler training ask everything sadly make big loss efficiency master,issue,negative,negative,negative,negative,negative,negative
441316310,"It is because I have default tensor type of cuda. And they are not put on
the CPU by the CallbackHandler - I agree they should be!

torch.set_default_tensor_type(torch.cuda.FloatTensor) => Now all new
tensors are created cuda by default.
basic_train/25 => loss = cb_handler.on_backward_begin(loss) => this is a
cuda tensor
basic_train/302 is Recorder.on_backward_begin. This does NOT put the tensor
on the CPU.

If not item() then perhaps just use .cpu()? There does not seem to be any
logic in having training losses stored as tensors nor in passing tensors to
the progress bar. Especially as validation losses are already just stored
as list of floats not as tensors.





On Fri, 23 Nov 2018 at 19:56, Sylvain Gugger <notifications@github.com>
wrote:

> Again, I'm not sure how you manage to get CUDA tensors recorded there
> since they are put on the CPU by the CallbackHandler.
> The .item() method is very slow because it triggers a CUDA
> synchronization, which is why we don't use it for the losses.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1228#issuecomment-441310477>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABJN6WkgBamiSeBVCgizFwdTODF5FLNHks5uyFLQgaJpZM4Yv36p>
> .
>
",default tensor type put agree new default loss loss tensor put tensor item perhaps use seem logic training passing progress bar especially validation already list wrote sure manage get since put method slow synchronization use thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
441312798,"Just reviewed this, with the last changes in fastai, you shouldn't need this change anymore if you write your metric/validation loss as callbacks (see the [doc page of metrics](https://docs.fast.ai/metrics.html#Creating-your-own-metric) for an example).
",last need change write loss see doc page metric example,issue,negative,neutral,neutral,neutral,neutral,neutral
441311344,"Thanks for this work. There's one main issue IMO for metrics that are not an average over batches (recall, precision for instance). If they are used as a metric by the a fastai user, they will return a wrong result if you code them like this, which can be very misleading.

That's why metrics are Callback behind the scenes, to allow to an exact computation. There is an example  with an Fbeta class in the last version of metrics.py, and another one in the [doc page of metrics](https://docs.fast.ai/metrics.html).",thanks work one main issue metric average recall precision instance used metric user return wrong result code like misleading metric behind allow exact computation example class last version another one doc page metric,issue,negative,negative,neutral,neutral,negative,negative
441310625,"It's not a unit test to add, it's to add a test in the function to separate BatchNorm layers and Bias parameters from the rest (so that we don't apply weight decay to them).",unit test add add test function separate bias rest apply weight decay,issue,negative,neutral,neutral,neutral,neutral,neutral
441310477,"Again, I'm not sure how you manage to get CUDA tensors recorded there since they are put on the CPU by the CallbackHandler.
The `.item()` method is very slow because it triggers a CUDA synchronization, which is why we don't use it for the losses.",sure manage get since put method slow synchronization use,issue,negative,positive,neutral,neutral,positive,positive
441264783,It's not supposed to. If you aren't using the factory methods `from_xxx` you should use the data block API.,supposed factory use data block,issue,negative,neutral,neutral,neutral,neutral,neutral
441263566,"Yeah, this line doesn't work:
```python
ImageDataBunch.create(trn_ds, val_ds, tst_ds, ds_tfms=get_transforms())
```",yeah line work python,issue,negative,neutral,neutral,neutral,neutral,neutral
441253310,"All annealing functions, the GeneralScheduler and OneCycleScheduler can handle arrays of learning rates, as long as you pass them as numpy arrays and not lists.",handle learning long pas,issue,negative,negative,neutral,neutral,negative,negative
441252280,"Thanks, I'm merging mostly for the test as I don't like to pass needless kwargs around. Will change that little bit ;)",thanks mostly test like pas needle around change little bit,issue,positive,positive,positive,positive,positive,positive
441184235,"Hi there @matiu2 ! 

Your suggestion applies only to RAM consumption, right? My scenario is regarding the GPU, I'm running out of CUDA memory. I had no problems with RAM.
Yesterday I tried running the ULMFiT pre-training with the same dataset, using a batch size of 80 on a Tesla P100 with 16Gb of memory, but I got the CUDA error: out of memory right in the second epoch:

```
1      1.659578    2.702391    0.505284                                                                      
Traceback (most recent call last):███---------------------------| 47.90% [24138/50393 1:48:07<1:57:37 1.6910]
  File ""legal_docs_preprocessing.py"", line 37, in <module>
    if __name__ == '__main__': fire.Fire(pretrain)
  File ""/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/fire/core.py"", line 127, in Fire
    component_trace = _Fire(component, args, context, name)
  File ""/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/fire/core.py"", line 366, in _Fire
    component, remaining_args)
  File ""/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/fire/core.py"", line 542, in _CallCallable
    result = fn(*varargs, **kwargs)
  File ""legal_docs_preprocessing.py"", line 26, in pretrain
    learn.fit(epochs=epochs, lr=lr, wd=1e-7)
  File ""/home/ubuntu/repositorios/fastai/fastai/basic_train.py"", line 137, in fit
    callbacks=self.callbacks+callbacks)
  File ""/home/ubuntu/repositorios/fastai/fastai/basic_train.py"", line 89, in fit
    raise e
  File ""/home/ubuntu/repositorios/fastai/fastai/basic_train.py"", line 79, in fit
    loss = loss_batch(model, xb, yb, loss_func, opt, cb_handler)[0]
  File ""/home/ubuntu/repositorios/fastai/fastai/basic_train.py"", line 26, in loss_batch
    loss.backward()
  File ""/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/tensor.py"", line 102, in backward
    torch.autograd.backward(self, gradient, retain_graph, create_graph)
  File ""/home/ubuntu/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/autograd/__init__.py"", line 90, in backward
    allow_unreachable=True)  # allow_unreachable flag
RuntimeError: CUDA error: out of memory
```
",hi suggestion ram consumption right scenario regarding running memory ram yesterday tried running batch size memory got error memory right second epoch recent call last file line module pretrain file line fire component context name file line component file line result file line pretrain file line fit file line fit raise file line fit loss model opt file line file line backward self gradient file line backward flag error memory,issue,negative,positive,positive,positive,positive,positive
441158547,"Did you manage to upload the dataset to the _fast.ai_ S3 cloud storage? I am trying to do the same thing for lesson 5, but did not know how to upload the dataset there.",manage cloud storage trying thing lesson know,issue,negative,neutral,neutral,neutral,neutral,neutral
441150633,"Pytorch will return an error with a batch size of 1 if you're using batchnorm in your model, so the option is there to skip the last batch if it's of size 1.
You're welcome to make a PR to suggest an appropriate warning or error message.",return error batch size model option skip last batch size welcome make suggest appropriate warning error message,issue,negative,positive,positive,positive,positive,positive
441116061,"I've seen a similar thing, but during the tokenization `process` phase. I got around it by tokenizing it myself, and not using numpy arrays; just using plain old python lists actually halved the memory usage.

After tokenizing, you can call 'TextDataBunch.from_tokens'.

Without that work around, the process grew up to 24 GB within about an hour of going through the full aclImdb.

I don't know how related this is.

@pvcastro you might try using a [python memory profiler](https://stackoverflow.com/questions/110259/which-python-memory-profiler-is-recommended) to find the source of the bad behaviour: ",seen similar thing process phase got around plain old python actually halved memory usage call without work around process grew within hour going full know related might try python memory profiler find source bad behaviour,issue,negative,negative,neutral,neutral,negative,negative
441109523,"The line you quote is adding losses to the smoothener. The losses are
separately added to the LossRecorder without forcing to cpu. My
learn.recorder has losses as a list of cuda tensors and val losses as just
a list of floats. I guess the training losses should also be a list of
floats. Will give it a try and resubmit.



On Thu, 22 Nov 2018 at 18:04, simon mackenzie <simonm3@gmail.com> wrote:

> The line I changed creates a new Tensor. If the default tensor type is set
> to cuda.FloatTensor then it creates a new cuda tensor and the progress bar
> fails. It is useful to set the default tensor type to cuda as it avoids
> having to pass a device parameter around and litter your code with
> .to(device). In virtually all applications I either want to run on cuda or
> cpu rather than mixing them
>
> On Thu, 22 Nov 2018 at 14:55, Sylvain Gugger <notifications@github.com>
> wrote:
>
>> I'm not sure why this is useful as losses are put on the cpu before being
>> recorded on this line
>> <https://github.com/fastai/fastai/blob/3079d077d4af83824839923210c332451250362f/fastai/callback.py#L221>.
>> To double-check, after a training, type learn.recorder.losses gives me
>> only CPU tensors.
>>
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/fastai/fastai/pull/1225#issuecomment-441053950>, or mute
>> the thread
>> <https://github.com/notifications/unsubscribe-auth/ABJN6ZcLOnRuVBOg-J8H49ahvotFnlJRks5uxrrZgaJpZM4YvTxq>
>> .
>>
>
",line quote separately added without forcing list list guess training also list give try resubmit wrote line new tensor default tensor type set new tensor progress bar useful set default tensor type pas device parameter around litter code device virtually either want run rather wrote sure useful put line training type thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
441108341,"Hey,
glad you like it. I'm currently on a business trip. I will check it/add them when I'm back.",hey glad like currently business trip check back,issue,positive,positive,positive,positive,positive,positive
441096883,"The line I changed creates a new Tensor. If the default tensor type is set
to cuda.FloatTensor then it creates a new cuda tensor and the progress bar
fails. It is useful to set the default tensor type to cuda as it avoids
having to pass a device parameter around and litter your code with
.to(device). In virtually all applications I either want to run on cuda or
cpu rather than mixing them

On Thu, 22 Nov 2018 at 14:55, Sylvain Gugger <notifications@github.com>
wrote:

> I'm not sure why this is useful as losses are put on the cpu before being
> recorded on this line
> <https://github.com/fastai/fastai/blob/3079d077d4af83824839923210c332451250362f/fastai/callback.py#L221>.
> To double-check, after a training, type learn.recorder.losses gives me
> only CPU tensors.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1225#issuecomment-441053950>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABJN6ZcLOnRuVBOg-J8H49ahvotFnlJRks5uxrrZgaJpZM4YvTxq>
> .
>
",line new tensor default tensor type set new tensor progress bar useful set default tensor type pas device parameter around litter code device virtually either want run rather wrote sure useful put line training type thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
441053950,"I'm not sure why this is useful as losses are put on the cpu before being recorded on [this line](https://github.com/fastai/fastai/blob/3079d077d4af83824839923210c332451250362f/fastai/callback.py#L221). To double-check, after a training, type `learn.recorder.losses` gives me only CPU tensors.",sure useful put line training type,issue,positive,positive,positive,positive,positive,positive
440943612,"Hey Sven,
These metrics would be really nice addition to the library, please consider adding/updating the docs as well. 
I used the link provided for my scenario as well. Happy that I could use readymade solution by you.
Thanks a lot for this 👍 ",hey metric would really nice addition library please consider well used link provided scenario well happy could use solution thanks lot,issue,positive,positive,positive,positive,positive,positive
440917741,Hey thanks man. That was really quick response. Fastest I have ever got. Thank you .,hey thanks man really quick response ever got thank,issue,positive,positive,positive,positive,positive,positive
440914972,"Currently, there is no dedicated thread for v1/windows, since it's not quite supported (until pytorch releases windows packages), but some people did report success, search for ""windows"" in this thread: https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111",currently thread since quite people report success search thread,issue,positive,positive,positive,positive,positive,positive
440914106,"How to start with fast ai on windows machine ? I have a good GPU on my windows QuadroM4000 ? I can build from source but I don't know where to get the source and what sources to use ?
",start fast ai machine good build source know get source use,issue,negative,positive,positive,positive,positive,positive
440852744,"@oostopitre @pouannes
Discussion of adding feature are better on forum as other may contribute to this too. 
Thank for your input. 
https://forums.fast.ai/t/keras-like-summary-of-a-model/28845/14?u=nok",discussion feature better forum may contribute thank input,issue,positive,positive,positive,positive,positive,positive
440673405,Also maybe the ability to see what's the core of the architecture and where's the head ?,also maybe ability see core architecture head,issue,negative,neutral,neutral,neutral,neutral,neutral
440508438,"Not ideal, but this should work until this issue reviewed: 
```
learn.model=learn.model.float()
interp = ClassificationInterpretation.from_learner(learn,ds_type=DatasetType.Single)
```

This has not been fully tested and coverts your model back to fp32",ideal work issue learn fully tested model back,issue,positive,positive,positive,positive,positive,positive
440447142,"Feels good to contribute. My first Pull request ever and that too for FASTAI.
I am going through the lectures by myself so I should be able to contribute more.",good contribute first pull request ever going able contribute,issue,negative,positive,positive,positive,positive,positive
440399242,"also for the record, since I mentioned it on the forum, it would be very useful to add `layer group` and if the layer current state is `trainable` columns to the summary.  Thanks for the feature @noklam",also record since forum would useful add layer group layer current state trainable summary thanks feature,issue,positive,positive,positive,positive,positive,positive
440286539,"@sgugger Sorry I have done a force-pushed, as I accidentally bring in a lot of commits when I merge from master.
I saw the ImageDeleter and ImageRelabeler is combine into ImageCleaner, so seems that I do not have to change anything and unit tests are fine.
 I combine 2  length assertion tests into 1,  found there is a missing import for display as well.
",sorry done accidentally bring lot merge master saw combine change anything unit fine combine length assertion found missing import display well,issue,negative,negative,neutral,neutral,negative,negative
440276946,"@sgugger I will start looking at the lesson for text & tabular, see if I can add a few unit tests and make it work for text & tabular along the way.",start looking lesson text tabular see add unit make work text tabular along way,issue,negative,neutral,neutral,neutral,neutral,neutral
440216392,"Sharing this for the benefit of FastAI users on Windows.  This happened to me as well tonight, Windows 10 fresh install, most up-to-date Anaconda3 as of 11/20/18.  Fastai is the only env I've installed so far, but like stas00 said, it will probably affect others as well.  I have **not** had this issue on Mac nor on EC2 Ubuntu. In the kernel.json there was an extra ""/bin"" in the path before python, which caused jupyter to be unable to start a notebook kernel.

I changed my kernel.json to look like this and it works, i.e. remove the offending /bin before the python.
`{
 ""argv"": [
  ""C:/Users/MyUserName/AppData/Local/conda/conda/envs/fastai/python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""Python 3"",
 ""language"": ""python""
}` ",benefit well tonight fresh install anaconda far like said probably affect well issue mac extra path python unable start notebook kernel look like work remove python python language python,issue,positive,negative,neutral,neutral,negative,negative
440132357,"@sgugger Seems like there is a timeout issue, however, I don't train any model in the tests I've added. Do you think it is worth to change something in the tests to decrease CI execution time?",like issue however train model added think worth change something decrease execution time,issue,positive,positive,positive,positive,positive,positive
440125890,It's a pleasure to be able to contribute to the fastai library.,pleasure able contribute library,issue,positive,positive,positive,positive,positive,positive
440102442,"hello, I'm trying to import fwd_wt103.h5  in language_model_learner() with pretrained_fnames[]. It seems to only accept .pth and pkl. 

do you know a way to change this .h5 file to a .pth? Do I just change the extension? 

thank you!",hello trying import accept know way change file change extension thank,issue,positive,neutral,neutral,neutral,neutral,neutral
440015410,"Just ran a few tests, it works great on vision model. On text or tabular model that expect a different kind of input... not so much. If you have time to look at this issue, I think maybe the dummy should be inferred from the dataloader, so this function should take a learner and not a model.",ran work great vision model text tabular model expect different kind input much time look issue think maybe dummy function take learner model,issue,positive,positive,positive,positive,positive,positive
439908607,Please use the [forum](https://forums.fast.ai/) for questions around the library. ,please use forum around library,issue,negative,neutral,neutral,neutral,neutral,neutral
439905158,"I tried in Ipython notebook from the terminal, that is working for import the library, rest of methods are still failing
In [12]: data = (ImageItemList.from_folder(PATH) #Where to find the data? -> in path and its subfolders 
    ...:         .split_by_folder()              #How to split in train/valid? -> use the folders 
    ...:         .label_from_folder()            #How to label? -> depending on the folder of the filenames 
    ...:         .add_test_folder(f'{PATH}/test')              #Optionally add a test set (here default name is tes
    ...: t) 
    ...:         .transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64 
    ...:         .databunch())                                                                                     
---------------------------------------------------------------------------
NameError                                 Traceback (most recent call last)
<ipython-input-12-2a3731f53300> in <module>
----> 1 data = (ImageItemList.from_folder(PATH) #Where to find the data? -> in path and its subfolders
      2         .split_by_folder()              #How to split in train/valid? -> use the folders
      3         .label_from_folder()            #How to label? -> depending on the folder of the filenames
      4         .add_test_folder(f'{PATH}/test')              #Optionally add a test set (here default name is test)
      5         .transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64

NameError: name 'ImageItemList' is not defined

In [13]: from fastai.vision import ImageItemList                                                                   
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-13-35003d83c618> in <module>
----> 1 from fastai.vision import ImageItemList

ImportError: cannot import name 'ImageItemList'

In [14]: from fastai.vision import ItemList                                                                        
---------------------------------------------------------------------------
ImportError                               Traceback (most recent call last)
<ipython-input-14-1d8f73f0eb33> in <module>
----> 1 from fastai.vision import ItemList

ImportError: cannot import name 'ItemList'

In [15]:                                                                                                           

In [15]: import fastai.vision                                                                                      

In [16]:                                                                                                           ",tried notebook terminal working import library rest still failing data path find data path split use label depending folder path optionally add test set default name data augmentation use size recent call last module data path find data path split use label depending folder path optionally add test set default name test data augmentation use size name defined import recent call last module import import name import recent call last module import import name import,issue,negative,neutral,neutral,neutral,neutral,neutral
439886099,"I tried  the following,
data = (ImageItemList.from_folder(PATH) #Where to find the data? -> in path and its subfolders
        .split_by_folder()              #How to split in train/valid? -> use the folders
        .label_from_folder()            #How to label? -> depending on the folder of the filenames
        .add_test_folder(f'{PATH}/test')              #Optionally add a test set (here default name is test)
        .transform(tfms, size=64)       #Data augmentation? -> use tfms with a size of 64
        .databunch()) 
from fastai.vision import *
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
<ipython-input-160-05c4443cffd4> in <module>
      2 import fastai
      3 from fastai.imports import *
----> 4 from fastai.vision import *

ModuleNotFoundError: No module named 'fastai.vision'
I am using the docker image of paperspace
>>> print(fastai.__version__)
1.0.12.dev0
>>> ",tried following data path find data path split use label depending folder path optionally add test set default name test data augmentation use size import recent call last module import import import module docker image print dev,issue,negative,neutral,neutral,neutral,neutral,neutral
439790523,"could you please point to a document, or piece of code, so that I can follow, I am unsure where to search this.",could please point document piece code follow unsure search,issue,negative,neutral,neutral,neutral,neutral,neutral
439763184,"Seems there is a bug in tests, going to fix soon.",bug going fix soon,issue,negative,neutral,neutral,neutral,neutral,neutral
439715096,"Thanks! I just added a clas argument that defaults to 1, to make it usable if we want the fbeta of a given class in a problem with more than two classes.",thanks added argument make usable want given class problem two class,issue,negative,positive,positive,positive,positive,positive
439706897,"Can you please explain how to convert the v3-lesson3-imdb?

When I run 

```data_lm = TextDataBunch.from_folder('chatdata')```

I get the error about the TextList, but that is within fastai, not my code.  ",please explain convert run get error within code,issue,negative,neutral,neutral,neutral,neutral,neutral
439701211,Thanks a lot! Can you please sign the [Contributor Licence Agreement](https://www.clahub.com/agreements/fastai/fastai) before we can merge your PR?,thanks lot please sign contributor agreement merge,issue,positive,positive,positive,positive,positive,positive
439700949,This would be better discussed on the [forum](https://forums.fast.ai) where you'll more easily find people to help!,would better forum easily find people help,issue,positive,positive,positive,positive,positive,positive
439700787,"We'll remove this line soon, but it appears that no modification in the model is required for regression problems. Just use `label_cls = FloatList` when using the data block API if it doesn't automatically recognize that your data is linked to a regression problem.
There should be more examples on the [forum](https://forums.fast.ai).",remove line soon modification model regression use data block automatically recognize data linked regression problem forum,issue,negative,neutral,neutral,neutral,neutral,neutral
439689710,"I have figured out, we have to set `create_func` for each ItemsList, train, valid and test.
example:
```
src.train.x.create_func=open_rgby
src.valid.x.create_func=open_rgby
src.test.x.create_func=open_rgby
```
But looks little bit redundant.",figured set train valid test example little bit redundant,issue,negative,negative,negative,negative,negative,negative
439681517,"It seems that I've fixed it (the test that failed is in a part of the codebase not relevant to this PR and looks like it could be flaky - correct me if I'm mistaken). 

I'm still not sure if there's a better way to decouple batching + masking from `NumericalizeProcessor`. What do you think?",fixed test part relevant like could flaky correct mistaken still sure better way think,issue,positive,positive,positive,positive,positive,positive
439680729,"The model_summary sit inside callbacks module, you will need to import it from `callbacks` module feel free to move it to a more appropriate location. Please review it.

Example of usage:
https://gist.github.com/noklam/bdb4e6e3a73f89c7cbbbef7d42140a0b

Trial on vision.learner.ipynb
![image](https://user-images.githubusercontent.com/18221871/48672245-6ba97e00-eb6e-11e8-97cd-e3e265427dd0.png)

",sit inside module need import module feel free move appropriate location please review example usage trial image,issue,positive,positive,positive,positive,positive,positive
439679840,@sgugger Removed all training from the tests except one place with `simple_cnn` and merged with the most recent `master`. Now should be better.,removed training except one place recent master better,issue,negative,positive,positive,positive,positive,positive
439663890,Not sure where the problem lies. I've loaded and processed the imdb dataset without any issue. Could you share more about your steup on the [forum](https://forums.fast.ai/)?,sure problem loaded without issue could share forum,issue,negative,positive,positive,positive,positive,positive
439663802,Just ran the notebook without any problem. Please use the [forum](https://forums.fast.ai/) and add a little more information about your hardware and if you made any changes to the code. Thanks!,ran notebook without problem please use forum add little information hardware made code thanks,issue,negative,positive,neutral,neutral,positive,positive
439649133,"Thanks for your contribution. docs_src is just for docs, so please don't add a nb there. Instead, please write some tests to show the need for this - i.e. the tests would fail without your change, and pass with them.

Also, please remove the extra 2 notebook changes that you seem to have accidentally included in your PR.",thanks contribution please add instead please write show need would fail without change pas also please remove extra notebook seem accidentally included,issue,negative,negative,neutral,neutral,negative,negative
439644583,"Hi @jph00 and @sgugger, I rebased this PR on the latest refactor and addressed all comments (removed duplicate code, adhere to the style guide and added docstrings). If hope these changes are sufficient for the PR to be merged into the master. Then I will also make sure to add some documentation to the fastai_docs repo.",hi latest removed duplicate code adhere style guide added hope sufficient master also make sure add documentation,issue,positive,positive,positive,positive,positive,positive
439642986,"It's fully documented now here:
https://docs.fast.ai/install.html#custom-dependencies

Please experiment and let us know whether this approach is working. I will close this issue for now - please re-open it if you encounter any issues with it.

Thank you.",fully please experiment let u know whether approach working close issue please encounter thank,issue,positive,neutral,neutral,neutral,neutral,neutral
439640973,"Ok, here is the update - I have discussed this more with @jph00 and here is what we will do for now and you're invited to help with this process.

1. both pypi and conda fastai packages will remain as they are now, since most people won't mind to have it all. But primarily, because it's too complicated for an average user to figure out such complexities, and we want simple things to be easy and complicated things to be possible.

2. for the advanced users in order to avoid installing all dependencies, the approach would be to install `fastai` w/o its dependencies, and then installing the dependencies that you need directly:

```
pip install --no-deps fastai
pip install spacy fastprogress numpy ...
```
this will work with conda too:
```
conda install --no-deps fastai
conda install spacy fastprogress numpy ...
```
we will maintain a document that will list dependency groups for each of the domains:

```
fastai.base = fasprogress numpy ...
fastai.text = spacy ...
fastai.vision = torchvision ...
```
so it'll be easy to compile your custom list.

3. we need to make sure that the bare `import fastai` loads without needing any extra dependencies, beyond its base list. And the same for each of the domain-specific gateways, e.g. `fastai.text` - so it requires only its extra dependencies.",update help process remain since people wo mind primarily complicated average user figure want simple easy complicated possible advanced order avoid approach would install need directly pip install pip install spacy work install install spacy maintain document list dependency spacy easy compile custom list need make sure bare import without needing extra beyond base list extra,issue,positive,negative,neutral,neutral,negative,negative
439633420,"have a little blocker,  `model_sizes` does not work on a nn.Module but Sequential only, need to find a way to record the all shape of a Block instead of input and output only.

`def model_sizes(m:nn.Module, size:tuple=(64,64), full:bool=True) -> Tuple[Sizes,Tensor,Hooks]`",little blocker work sequential need find way record shape block instead input output size full size tensor,issue,negative,positive,neutral,neutral,positive,positive
439632625,"First, that would mean that you won't be able to install the default `pip install fastai` anymore, it'll have to become `pip install fastai[all]`, as w/o `[all]` it'll be just base dependencies. And perhaps it's ok.

Second, I haven't looked at the specifics of the code, but I think it'll be more work than just `try: import spacy` - as I suggested it'll most likely take some re-thinking of making each of these functionalities, like `nlp` separate entry points, so that `import fastai` will not attempt to load them at all, but `import fastai.nlp` will need to be called explicitly, and the latter will do all the dep-loading. This will need to be done no matter how we decide to go about the packaging.

But I already shared my thoughts about this and what we need to finish this discussion and to plan action is to have @jph00 to chime in so that we are in agreement.",first would mean wo able install default pip install become pip install base perhaps second code think work try import spacy likely take making like separate entry import attempt load import need explicitly latter need done matter decide go already need finish discussion plan action chime agreement,issue,positive,negative,neutral,neutral,negative,negative
439631280,"I mean assuming that we leave out the requirement that ""we want fastai to work identically in both"", i.e. the optional dependency install would be available exclusively via pip as you suggested(makes sense as there are different install instructions for conda and pip anyway), is this what needs to be done or is there more to it?",mean assuming leave requirement want work identically optional dependency install would available exclusively via pip sense different install pip anyway need done,issue,negative,positive,neutral,neutral,positive,positive
439631061,Please re-read my first comment - conda is the issue.,please first comment issue,issue,negative,positive,positive,positive,positive,positive
439622257,"Oh, forgot to mention it but it's normally fixed now.",oh forgot mention normally fixed,issue,negative,positive,neutral,neutral,positive,positive
439616137,"I'll fix this, you're right it should have been adapted since our recent breaking changes.
For your second questions, the filenames are the raw items (before opening) and you can always access those with the `items` attribute: `data.train_ds.x.items` for instance will give you the filenames in the training set.",fix right since recent breaking second raw opening always access attribute instance give training set,issue,negative,positive,neutral,neutral,positive,positive
439607685,"To support optional dependencies via pip install, is this just a matter of:

1. changing `setup.py` 
2. go through all imports and make sure they are optional (runtime try except imports) with proper informative Exceptions

or is there something else that has to be considered?",support optional via pip install matter go make sure optional try except proper informative something else considered,issue,positive,positive,positive,positive,positive,positive
439585450,"That makes sense to me. I will start experimenting with it.

However, another issue here is that the setup of `untar_data` the `URLs` class gives people the misconception that it can take any url that represents compressed file as an argument. For the very minimum, we can add some more notes to the `untar_data`, but more ideally, we should also name `URLs` class instead as `FastaiDatasets`, so that it is clear it is only an internal function for now and should only be used with Fastai Datasets.

I know this is really minuscule and you probably have way more important things to look after. In such case, should I simply start a PR for it?",sense start however another issue setup class people misconception take compressed file argument minimum add ideally also name class instead clear internal function used know really minuscule probably way important look case simply start,issue,positive,positive,positive,positive,positive,positive
439578561,"Initially one more Import needs to be done.
Renames for Harmonization is missing here.
@sgugger 
You already have updated this file as https://github.com/fastai/fastai/blob/master/docs_src/tabular.ipynb ",initially one import need done harmonization missing already file,issue,negative,negative,neutral,neutral,negative,negative
439553840,"Personally, I don't think that splitting fastai into multiple packages, to support conda's lack of optional dependencies, is the best idea. Other than making the maintenance more complicated, the main issue I see is that it'd create a confusion with different non-matching version numbers for each sub-package and the main package, as most of the time those sub-packages will not be updated. 

I see that with `jupyter` sub-packages where people list in their notebook issue bug reports that they have `jupyter=1.0.0` which is bogus, since `jupyter` is just a virtual package. Instead, they need to report their `jupyter` `notebook` which is at `5.0.7` as of this writing. And I myself got confused between the other of their package versions not once, since they are similar but not the same. But their sub-packages are there for a reason - as they are actually different pieces of software - whereas creating sub-packages just to manage dependencies is not the same.

So my personal preference is to keep a single `fastai` package, and have the conda `fastai` package fetch all the dependencies, and if you want the refinements - then use pip, with refinements suggested by @elyase.",personally think splitting multiple support lack optional best idea making maintenance complicated main issue see create confusion different version main package time see people list notebook issue bug bogus since virtual package instead need report notebook writing got confused package since similar reason actually different whereas manage personal preference keep single package package fetch want use pip,issue,positive,positive,neutral,neutral,positive,positive
439548674,"Yes, we are aware of this issue. And we have been discussing possible solutions for quite some time now.

There are 2 issues at this moment, preventing this from happening:

1. The problem with pypi's dependency grouping feature you suggested - conda doesn't have such a feature. And we want fastai to work identically in both, so these package managers are interchangeable. I wish conda had a similar feature. So one possible solution would be to create sub-packages, similar to how  `jupyter` packages are implemented, except all of them but one will be virtual packages, just dispatching dependencies. 

2. currently you won't be able to load `fastai` w/o some (all?) of those dependencies installed - it first needs to be split into ""subprojects"" so that `import fastai` doesn't pull them all in.

Once `fastai` gets ""untangled"" from importing all dependencies (issue 2), you initially will have a simple workaround for reaching your goals, where you install `fastai` w/o any of its dependencies (`--no-deps`) and then you can choose which dependencies to install. I suppose we could make this into documented recipes, like:

To get fastai NLP support, do:
```
pip install --no-deps fastai
pip install spacy fastprogress numpy ...
```
etc.

The full dep list can be extracted programmatically and then filtered out to remove undesired deps, by tapping into the `setup.py` data, as it can be seen [here](https://github.com/fastai/fastai/blob/master/tests/test_mod_independency.py), or via `conda search --info fastai==1.0.25`.

And some time later, probably after course-v3 part1 is finished, we will find an easier way to resolve that.",yes aware issue possible quite time moment happening problem dependency grouping feature feature want work identically package interchangeable wish similar feature one possible solution would create similar except one virtual currently wo able load first need split import pull untangled issue initially simple reaching install choose install suppose could make like get support pip install pip install spacy full list extracted programmatically remove undesired tapping data seen via search time later probably part finished find easier way resolve,issue,positive,positive,positive,positive,positive,positive
439444253,"`untar_data` is supposed to be an internal function with the fastai datasets. 
Maybe you could create a new function that will be more general? `download_url` will work for everything already, I guess it's mostly having a `uncompress` function that would deal with any format that's missing, but that's not an easy feature.",supposed internal function maybe could create new function general work everything already guess mostly function would deal format missing easy feature,issue,negative,positive,positive,positive,positive,positive
439442387,"@sgugger Do you think that there is any need to make changes to the fact that `URLs` class actually does not contain full urls, and the fact that `untar_data` only supports `tgz` file url in a non-intuitive way?

Should I create a PR for such feature recommendation?

Sorry. I am still not very familiar with the general guidelines of contributing to open source.",think need make fact class actually contain full fact file way create feature recommendation sorry still familiar general open source,issue,negative,positive,neutral,neutral,positive,positive
439424571,"Great.. 
I think you might have noticed the parameter name as 'col' in 'split_from_df'. If not it should be cols as per my understanding.",great think might parameter name per understanding,issue,positive,positive,positive,positive,positive,positive
439417172,"Thank you for this!

I just tested: That does indeed work for `ImageDataBunch.from_folder()` (the minimal example I posted) but it does not work for `ImageDataBunch.create()` which is what my actual use case is.

Regardless, this is good to know.

I've solved my specific `create()` use case with `Image.apply_tfms()` in my custom `Dataset` classes.",thank tested indeed work minimal example posted work actual use case regardless good know specific create use case custom class,issue,positive,positive,positive,positive,positive,positive
439414043,This has been announced in the developer chat and the corresponding notebook will be updated as we do the next release. You should now use `TextList` in every situation.,developer chat corresponding notebook next release use every situation,issue,negative,neutral,neutral,neutral,neutral,neutral
439408273,"As it has been the case since the very beginning, in `ImageDataBunch.from_folder`, the tfms argument is for the *dataloader* transforms. The dataset transforms (so your data augmentaiton) have to be passed to the argument ds_tfms.",case since beginning argument data argument,issue,negative,neutral,neutral,neutral,neutral,neutral
439408183,Great! Did not know this... then it's a mute point anyway I guess,great know mute point anyway guess,issue,positive,positive,positive,positive,positive,positive
439407320,"You have to use the data block API for this, which has the option `recurse` (default True) to look into subdirectorires.",use data block option recurse default true look,issue,negative,positive,positive,positive,positive,positive
439407051,"This should work, but there was a problem with `create_func` not being properly passed in the latest release. This is fixed in master normally, are you running this code on it?",work problem properly latest release fixed master normally running code,issue,negative,positive,positive,positive,positive,positive
439406386,Just need to assign enough space for the panel to show the whole bar.,need assign enough space panel show whole bar,issue,negative,positive,neutral,neutral,positive,positive
439406374,"I think an assertion may be better yes. Ideally then, I should remove those two arguments and have something called `y_range` instead that is a tuple, so it would be clearer this way, but since it changes the API for the lesson notebooks, I'll check with Jeremy.",think assertion may better yes ideally remove two something instead would clearer way since lesson check,issue,positive,positive,positive,positive,positive,positive
439405889,"When you call your label function, you can pass `classes=...` as kwarg.",call label function pas,issue,negative,neutral,neutral,neutral,neutral,neutral
439405588,"No worries. How would I pass the list of classes with the new API?
",would pas list class new,issue,negative,positive,positive,positive,positive,positive
439405207,"Not sure what the problem is with that line. `set(df)` returns the set of the names of the columns.

The problem is that you're not passing the arguments expected by the function: `from_df(cls, path, df, dep_var,...)` in your error message. So dep_var is here what you called valid_df, and I expect that is a dataframe, so the error is thrown by {dep_var}.",sure problem line set set problem passing function path error message expect error thrown,issue,negative,positive,positive,positive,positive,positive
439404499,"Thanks, but I'm not sure this is the right fix for this. `get_files` is already very slow compared to old fastai and I'm afraid a sort will only add to it. Closing this, but you can open a new PR if you think of a better way. 
Note that in the meantime, you can always pass your list of classes to override the default behavior.",thanks sure right fix already slow old afraid sort add open new think better way note always pas list class override default behavior,issue,positive,positive,neutral,neutral,positive,positive
439398659,"I meet the same problem, thanks for pointing out how to work around@iamkissg",meet problem thanks pointing work around,issue,negative,positive,positive,positive,positive,positive
439342483,"Yes, I had a similar issue. It seems that a lot of things changed recently. So I've decided to roll-back to earlier versions. ",yes similar issue lot recently decided,issue,negative,neutral,neutral,neutral,neutral,neutral
439313180,"@sgugger  thanks for your reply. Sounds better to have it our self whenever needed.
Will close this.",thanks reply better self whenever close,issue,positive,positive,positive,positive,positive,positive
439241527,"No problem,  totally understandable you guys are busy on the lesson as we move to text and tabular.  Thanks for the comment @sgugger.

I can explain a little bit.  I think the test for too long and short may combine to 1 test,  but it is still need.

For ImageCleaner,  I add an assert len statement,  which prevent user pass in unmatched dataset/indexes pair.  For example,  if I pass in indexes for validation set and training dataset,  the class will have no problem to accept that,  as long as _get_item does not throws an error.  The result is user deleting the wrong files and probably unaware of it,  as we use the ipython widget to click only.

There is also a test fail case for a more complicated problem. As the FileDeleter change to ImageDeleter,  the api has slightly changed. In course-v3, there is a time where ImageDeleter swap with FileDeleter but the argument was not update. So the situation is databunch and indexes for validation dataset get passed in to ImageDeleter.

 Due to the fact that I have an assert statement in ImageCleaner,  it will throws Databunch does not have attribute len error,  so I think I need a fail case test just to not mixing with the wrong dataset problem.

In short,  test unmatched length for the assertion error correctly thrown.  And a expect fail case for wrong input type.  ",problem totally understandable busy lesson move text tabular thanks comment explain little bit think test long short may combine test still need add assert statement prevent user pas unmatched pair example pas validation set training class problem accept long error result user wrong probably unaware use click also test fail case complicated problem change slightly time swap argument update situation validation get due fact assert statement attribute error think need fail case test wrong problem short test unmatched length assertion error correctly thrown expect fail case wrong input type,issue,negative,negative,negative,negative,negative,negative
439199137,"@sgugger good point! it can be also like RELU but `max(self.min_score, res)` but also throwing from the constructor and give explanation that both argument should be given or None should be given would be helpful don't you think ?",good point also like also throwing constructor give explanation argument given none given would helpful think,issue,negative,positive,positive,positive,positive,positive
439197851,"Would it?  I didn't mean that it would add list inside the list but add all values and keep the list flat. Something like:

```
m = met.metric
if is_listy(m): self.state_dict['last_metrics'] += m
else: self.state_dict['last_metrics'].append(m)
```",would mean would add list inside list add keep list flat something like else,issue,negative,negative,negative,negative,negative,negative
439196562,"I think you should test if the `lbls` are not None before converting them to a tensor, but you're right, this conversion to data is necessary. Do you mind making a PR to fix this?",think test none converting tensor right conversion data necessary mind making fix,issue,negative,positive,positive,positive,positive,positive
439196019,"Yes this is a small helper function, and like `show_batch()`, it won't show you more than one batch. You have to write your own function if you want to get something different.
Note that ` y.reconstruct_output(preds, x)` will work to get your final object from the predictions.",yes small helper function like wo show one batch write function want get something different note work get final object,issue,positive,negative,neutral,neutral,negative,negative
439195510,Note that your final result can be positive or negative. I'm not too sure about the expected behavior of having a min_score alone...,note final result positive negative sure behavior alone,issue,negative,positive,positive,positive,positive,positive
439195203,"You can just add them on their own: there is metada to add so that the library knows where to cut to put its custom layer and how to discriminative learning rates, otherwise they won't work in a cnn_learner.",add add library cut put custom layer discriminative learning otherwise wo work,issue,negative,neutral,neutral,neutral,neutral,neutral
439194820,That would mess up the recorder then. I'll think about it.,would mess recorder think,issue,negative,negative,negative,negative,negative,negative
439182473,Very interesting! I've tried the same in three different machines and always get the error. I'm going to close the issue for now if you're not able to reproduce though. Will reopen when I have some concrete steps to reproduce,interesting tried three different always get error going close issue able reproduce though reopen concrete reproduce,issue,negative,positive,positive,positive,positive,positive
439181910,"Yea I've noticed the callback change. It seems an elegant approach!

That original approach doesn't work as the callbacks are expected to return a single value. Of course its possible to create function for all the extra metrics but its a bit complicated approach..

Then again if callbackhandler (these two lines) would accept a tuple in the return. Then all callback metrics could return multiple values if they want to do so. 

- https://github.com/fastai/fastai/blob/master/fastai/callback.py#L251
- https://github.com/fastai/fastai/blob/master/fastai/callback.py#L193

That could be easy approach but is there some downside and do others need that kind of features?",yea change elegant approach original approach work return single value course possible create function extra metric bit complicated approach two would accept return metric could return multiple want could easy approach downside need kind,issue,positive,positive,positive,positive,positive,positive
439180797,"Another option is to be more specific in the docs using data = ImageDataBunch.from_folder(path, train='...
so that people learn this.",another option specific data path people learn,issue,negative,neutral,neutral,neutral,neutral,neutral
439167898,inception_v3 architecture alone fails with current code base,architecture alone current code base,issue,negative,negative,negative,negative,negative,negative
439150797,"Ah, I see it in the code - thank you for the link. It's not documented though in the section of `~/.fastai/config.yml`of https://docs.fast.ai/datasets.html, probably under `modelpath4file`, which is not there either?

Or perhaps we add a new section for `~/.fastai/config.yml` and put all those user-configurable variables in one place?
",ah see code thank link though section probably either perhaps add new section put one place,issue,negative,positive,positive,positive,positive,positive
439148565,You can configure models_pah in your config file too: as seen on [this line](https://github.com/fastai/fastai/blob/075b6582042588d026ebf32c1c457413d0cec0db/fastai/datasets.py#L41). Unless there is something I'm missing?,configure file seen line unless something missing,issue,negative,negative,negative,negative,negative,negative
439147052,"Thanks, @sgugger.
And please note somewhere that we are missing a user-configurable `models_path` (see my previous comment).",thanks please note somewhere missing see previous comment,issue,negative,negative,neutral,neutral,negative,negative
439146586,"Thanks! Note that now that metrics are callbacks, the `add_metrics` will probably be deprecated in a future version. Can you try to implement your example from the forum as a metric now and see if we need to keep this alternative?",thanks note metric probably future version try implement example forum metric see need keep alternative,issue,negative,positive,neutral,neutral,positive,positive
439145928,The intention is to have the models save in `~/.fastai/models`. I've fixed the code accordingly.,intention save fixed code accordingly,issue,negative,positive,neutral,neutral,positive,positive
439109702,@sgugger Should there be a more helpful exception indicating that?  To me that wasn't an obvious thing to try.,helpful exception obvious thing try,issue,negative,neutral,neutral,neutral,neutral,neutral
439072202,"Sorry it took me a bit of time to get to this. First let's not change __all__ in image_cleaner, you can manually import ImageCleaner for your test with
```
from fastai.widgets.image_cleaner import ImageCleaner
```
Then, I think only the succeding test with the right length is necessary. Could you amend your PR for this? Thanks!",sorry took bit time get first let change manually import test import think test right length necessary could amend thanks,issue,negative,positive,neutral,neutral,positive,positive
439067027,I just ran this code after removing the imdb dataset and didn't get any issue. Are you getting this on master?,ran code removing get issue getting master,issue,negative,neutral,neutral,neutral,neutral,neutral
439066043,I just tried your code and got a databunch without any error. Was this on master?,tried code got without error master,issue,negative,neutral,neutral,neutral,neutral,neutral
439064900,The problem is that your `data_len` is too small to be able to make a batch: a language model has a default bs of 64 and a default bptt of 70 so it takes more than 100 tokens to make something. Trying with 2500 doesn't give me an error.,problem small able make batch language model default default make something trying give error,issue,negative,positive,positive,positive,positive,positive
439063356,"The separator is not the csv separator, but a separator for your labels in the label columns (if you had things lie 'cat,dog' to multi-label one image.
That's probably why you get the issue, here you want to let sep be None.",separator separator separator label lie dog one image probably get issue want let none,issue,negative,neutral,neutral,neutral,neutral,neutral
438949832,"In my view, then naming inconsistency between MNIST_SAMPLE and MNIST_TINY compared to the full dataset is an incentive for a change. 
As Fred mentioned, people will look up the documentation and see 


```
path = untar_data(URLs.MNIST_SAMPLE) 
data = ImageDataBunch.from_folder(path)
```

working out of the box. After doing some experiments, they might want to switch to the full dataset, only to  run into an error because the folder names are different. 

I see how it's useful to learn the methods parameters, but inconsistent behavior should not be the way we teach new users. ",view naming inconsistency full incentive change people look documentation see path data path working box might want switch full run error folder different see useful learn inconsistent behavior way teach new,issue,negative,positive,positive,positive,positive,positive
438906966,"Why would we change an academic dataset? There are methods in the library to open it properly, and it's useful to learn them since your data will not always be in folders named train and valid.",would change academic library open properly useful learn since data always train valid,issue,negative,positive,neutral,neutral,positive,positive
438871810,"Not sure why this now failing. It did pass initially, I think. I configured `nbstripout` and it appears to have stripped some output of some jupyter notebooks in `old/tutorials/...` based on the cell execution counts.",sure failing pas initially think stripped output based cell execution,issue,negative,positive,positive,positive,positive,positive
438858453,"Hi I have a working prototype for this at the moment. For my use case I had BOW, TF-IDF ish representation of my data which was in scipy.sparse format and then i wrote a custom `collate_fn` for indexing sparse data, stack it and turn it into a batch. Also you need to be aware that autograd doesn't fully support all operations but it does support some which can be found here: https://github.com/pytorch/pytorch/issues/9674. With this in mind if you try `.backward()` on `nn.Linear`  after moving the parameters to a GPU it will fail since an intermediate variable is created (at least that's what i can remember from the Pytorch forums), so i ended writing a custom `nn.LinearSparse` which will allow moving variables as the module is created and uses `torch.mm` . If there is really a need for sparse support at least what can be done at the moment i would be happy to contribute what i developed so far. :)",hi working prototype moment use case bow representation data format wrote custom indexing sparse data stack turn batch also need aware fully support support found mind try moving fail since intermediate variable least remember ended writing custom allow moving module really need sparse support least done moment would happy contribute far,issue,positive,positive,neutral,neutral,positive,positive
438802159,Yes. It looks like the fastest way would be if someone from fastai could change the names of the folders on their servers. ,yes like way would someone could change,issue,positive,neutral,neutral,neutral,neutral,neutral
438800819,"I got it.  I already knew how to solve it, but the problem is not that.  We have to change MNIST dataset, so that others do not get this error.",got already knew solve problem change get error,issue,negative,neutral,neutral,neutral,neutral,neutral
438785888,"You're right. That is the problem. 

As I see it, you have two options:

1. Rename the folders themselves. 
On Linux you find them in your home directory under
 `~/.fastai/data/mnist_png`. 

2. Use the functions arguments as Sylvain mentioned above. 
Your call would look similar to
 `data = ImageDataBunch.from_folder(path, train='training', valid='testing')`
(I did not test this. But I hope you get the gist of it)


",right problem see two rename find home directory use call would look similar data path test hope get gist,issue,negative,positive,positive,positive,positive,positive
438769890,"I tried the same thing today without knowledge of this issue.  
I got an error: index 0 is out of bounds for axis 0 with size 0

I guess the problem is that MNIST folders are named wrongly, they should be `train` and `valid`, not `training` and `testing`, right?

Where can this be changed?
",tried thing today without knowledge issue got error index axis size guess problem wrongly train valid training testing right,issue,negative,negative,negative,negative,negative,negative
438769731,"example of usage (note call to transform_labels and do_y in normalize)
```

def open_grayscale(fn):
    x = PIL.Image.open(fn)
    return Image(pil2tensor(x,np.float32).div_(255)[0:1])   

class SuperResLabelList(ImageItemList):
    def __init__(self, items:Iterator, **kwargs):
        super().__init__(items, **kwargs)
        self.loss_func,self.create_func = combo_loss,open_grayscale
        

    def new(self, items, classes=None, **kwargs):
        return self.__class__(items, **kwargs)


class SuperResItemList(ImageItemList):
    def __post_init__(self):
        super().__post_init__()
        self._label_cls = SuperResLabelList
        self.loss_func = combo_loss
        self.create_func = open_grayscale

valid_pct = 0.10
src = (SuperResItemList(lr_names_full).
       random_split_by_pct(valid_pct).
       label_from_func(match_hr_fn))
      

def get_data(src, bs, sz_lr, scale=4, tfms=None, **kwargs):
    sz_hr = sz_lr*scale
    salk_stats = ( [0.10], [0.20])
    if tfms is None: tfms = get_transforms() 
    data = (src.transform(tfms, size=sz_lr)
            .transform_labels(size=sz_hr)
            .databunch(bs=bs, **kwargs) #, num_workers=0)
            .normalize(salk_stats, do_y=True)
           )
    return data
```",example usage note call normalize return image class self super new self return class self super scale none data return data,issue,positive,positive,positive,positive,positive,positive
438743857,Also you might want to use our processor to handle the tokenization and numericalization so that we avoid dupe code.,also might want use processor handle avoid dupe code,issue,negative,neutral,neutral,neutral,neutral,neutral
438742850,Thanks. I'll try to do it by the end of the week.,thanks try end week,issue,negative,positive,positive,positive,positive,positive
438732749,@sgugger Have created another PR with suggested changes at #1163. Hope I got the details right this time.,another hope got right time,issue,negative,positive,positive,positive,positive,positive
438716541,"Ahh ok, thanks. I made the mistake of the different losses not accepting the same type of parameters.

This worked for me:
```
    def loss_ctx(self, inps, _):
        inp_vecs, ctx_vecs, neg_vecs = inps
        return self.cosine_sim_loss(inp_vecs, ctx_vecs)
    def loss_neg(self, inps, _):
        inp_vecs, ctx_vecs, neg_vecs = inps
        return self.cosine_sim_loss(inp_vecs, neg_vecs)
    def loss(self, inps, _):
        loss_all = self.loss_ctx(inps,_) + self.loss_neg(inps,_)
        return loss_all
```

Thanks!",thanks made mistake different type worked self return self return loss self return thanks,issue,negative,positive,positive,positive,positive,positive
438714190,"As this argument is called by name in all the tests (and probably a few users), this can't be changed easily now. Closing this as I feel it's more the notebook that should be fixed than the code.",argument name probably ca easily feel notebook fixed code,issue,negative,positive,positive,positive,positive,positive
438707335,"Yeah, it doesn't properly work. I'll edit and change soon-ish, I'm currently fixing the tests.",yeah properly work edit change currently fixing,issue,negative,neutral,neutral,neutral,neutral,neutral
438704650,"> I tried to move the reset call in post_init of Sequential as it would be cleaner to do it there. I'll try and revert if that breaks anything. Thanks for your PR!

I've thought that `__post_init__` works only in `dataclasses` and `nn.Module` is not one of them, or maybe I'm missing something. But either way, since the reset call is fixed I can run it if needed my self.",tried move reset call sequential would cleaner try revert anything thanks thought work one maybe missing something either way since reset call fixed run self,issue,negative,positive,neutral,neutral,positive,positive
438692437,The data block API is new and changing fast. Closing this issue as it's not relevant anymore.,data block new fast issue relevant,issue,negative,positive,positive,positive,positive,positive
438692047,Not sure why this is an issue: your model can return a list of outputs but it's always treated as one argument in the rest of the code. Why not adapt your function to extract the things you want from this list of outputs?,sure issue model return list always one argument rest code adapt function extract want list,issue,negative,positive,positive,positive,positive,positive
438690107,"Not sure this is the right way to do it. I think the reduction attribute should be passed to the loss function inside MixupLoss instead. Closing this, the issue is there and I'll try to solve it today or tomorrow.",sure right way think reduction attribute loss function inside instead issue try solve today tomorrow,issue,negative,positive,positive,positive,positive,positive
438689000,I tried to move the reset call in post_init of Sequential as it would be cleaner to do it there. I'll try and revert if that breaks anything. Thanks for your PR!,tried move reset call sequential would cleaner try revert anything thanks,issue,positive,positive,positive,positive,positive,positive
438685706,"tools/update-nb was what I was using all the time so having it changed to build-docs seems clearer.
Merging this so I can test today, but if one of you can update the docs to reflect the change, that would be great.",time clearer test today one update reflect change would great,issue,positive,positive,positive,positive,positive,positive
438683133,"Thanks, tests failing are indeed flaky ones.",thanks failing indeed flaky,issue,negative,positive,positive,positive,positive,positive
438681521,"Yes, sorry, thought this was such a fresh addition I didn't check for any other open PRs for this :)

Will close this one.",yes sorry thought fresh addition check open close one,issue,positive,negative,neutral,neutral,negative,negative
438542856,"The other failure doesn't look like it calls `add_test`, so I can't see why it would fail with my change:
```
2018-11-14T05:13:23.4038970Z     def test_multi():
2018-11-14T05:13:23.4039200Z         path = untar_data(URLs.PLANET_TINY)
2018-11-14T05:13:23.4040690Z         data = (ImageItemList.from_csv(path, 'labels.csv', folder='train', suffix='.jpg')
2018-11-14T05:13:23.4041230Z             .random_split_by_pct().label_from_df(sep=' ').databunch())
2018-11-14T05:13:23.4042210Z         x,y = data.valid_ds[0]
2018-11-14T05:13:23.4042330Z         assert x.shape[0]==3
2018-11-14T05:13:23.4042740Z >       assert data.c==len(y.data)==14
2018-11-14T05:13:23.4042870Z E       assert 13 == 14
2018-11-14T05:13:23.4042990Z E        +  where 13 = len(array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32))
2018-11-14T05:13:23.4043160Z E        +    where array([1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.], dtype=float32) = MultiCategory clear;primary;road.data
```",failure look like ca see would fail change path data path assert assert assert array array clear primary,issue,negative,negative,neutral,neutral,negative,negative
438542457,"Started looking into the failing tests, this first one just seems flaky, didn't quite make it to 0.3:
```
2018-11-14T05:14:05.4474529Z     def test_val_loss(learn):
2018-11-14T05:14:05.4474691Z >       assert learn.validate()[1] > 0.3
2018-11-14T05:14:05.4474852Z E       assert tensor(0.2964) > 0.3
```",looking failing first one flaky quite make learn assert assert tensor,issue,negative,positive,positive,positive,positive,positive
438534773,"With fastai 1.0.22, can not create a databunch anymore:

codes = np.loadtxt(path/'codes.txt', dtype=str)
df_fn_labels=pd.read_csv(path/'labels.csv', index_col=None)
fnames=list(df_fn_labels['Image'])
labels=list(df_fn_labels['Id'])
data = (ImageFileList.from_folder(path) .label_from_df(df_fn_labels, fn_col=0, label_col=1) .split_by_folder() .datasets(ImageClassificationDataset, fns=fnames, labels=labels, classes=codes) .transform(get_transforms(), size=128) .databunch() .normalize(imagenet_stats))

Error says:
NameError: name 'ImageFileList' is not defined

If I use ImageItemList  and follow it up with .label_from_df(df_fn_labels, fn_col=0, label_col=1)  it leads to error:

AttributeError: 'NoneType' object has no attribute 'iloc'
",create data path error name defined use follow error object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
438530245,"I'm not sure I understand the question. You are following the old course, that is meant to work with the old (aka 0.7) library. It's not fixable with the new library.",sure understand question following old course meant work old aka library fixable new library,issue,negative,positive,positive,positive,positive,positive
438529748,so how to fix that problem with the new version?,fix problem new version,issue,negative,positive,positive,positive,positive,positive
438469023,"exploring some more, is the intention to have both `~/.torch/models/`and `~/.fastai/models/`? In which case the language model should not be saved under `~/.fastai/data`, but `~/.fastai/models`.

Except we don't have `~/.fastai/models`, even though the future telling lesson3-imdb says so.

Currently I only see ~/.fastai/data in datasets.py and only `data_path` is configurable via `~/.fastai/config.yml`, documented [here](https://docs.fast.ai/datasets.html).  

So I suppose we need to add a configurable `models_path`, with default to `~/.fastai/models`, and make the model downloads go there instead.",exploring intention case language model saved except even though future telling currently see via suppose need add default make model go instead,issue,negative,neutral,neutral,neutral,neutral,neutral
438436618,"Please amend this PR to work with the latest big refactor and adapt to the comment above. I'm closing this for now, thanks",please amend work latest big adapt comment thanks,issue,positive,positive,positive,positive,positive,positive
438436133,"There has been a very big change under the hood with how those factory methods work. Can you tell us if the issue is still there by reopening if necessary?
Thanks!",big change hood factory work tell u issue still necessary thanks,issue,negative,positive,neutral,neutral,positive,positive
438435536,"Please amend your PR to be able to merge with the latest big refactor. If it's easiest, close this one and reopen another. Also, don't forget to sign the CLA or we won't be able to merge, thanks!",please amend able merge latest big easiest close one reopen another also forget sign wo able merge thanks,issue,positive,positive,positive,positive,positive,positive
438435247,"Please amend your PR to be able to merge with the latest big refactor. If it's easiest, close this one and reopen another.",please amend able merge latest big easiest close one reopen another,issue,positive,positive,positive,positive,positive,positive
438435031,"Please amend your PR to be able to merge with the latest big refactor. If it's easiest, close this one and reopen another.
Note that there a no datasets anymore.",please amend able merge latest big easiest close one reopen another note,issue,positive,positive,positive,positive,positive,positive
438383142,"It so happened that this exact topic's discussion was initiated a few days ago, so I'll close this ticket and let's discuss it there. https://forums.fast.ai/t/getting-the-most-out-of-your-gpu-ram-in-jupyter-notebook/30145/6",exact topic discussion day ago close ticket let discus,issue,negative,positive,positive,positive,positive,positive
438323058,"Fixed earlier typo,  use fixture to initialize databunch for all test,  not sure if this is the best way assert fail case. ",fixed typo use fixture initialize test sure best way assert fail case,issue,negative,positive,positive,positive,positive,positive
438310393,"It would be nice to write a function that automatically determine the appropriate batch size based on the stats of the dataset, the specs of the GPU as obtainable from `nvidia-smi`, and other related information.",would nice write function automatically determine appropriate batch size based spec obtainable related information,issue,negative,positive,positive,positive,positive,positive
438291253,Even better would be to determine an optimal batchsize before the training starts....,even better would determine optimal training,issue,positive,positive,positive,positive,positive,positive
438285842,"The course uses the old version of fastai, you're using the new one, which is why you have a problem.",course old version new one problem,issue,negative,positive,positive,positive,positive,positive
438285518,"This will be changed in the refactor we are currently doing, I saw that typo too yesterday. Thanks for flagging!",currently saw typo yesterday thanks flagging,issue,negative,positive,neutral,neutral,positive,positive
438285151,"Thanks!
Concerning your tests, please leave the full training only for one integration test with the simple CNN. Tests are also run on CPU and we can't have too many that are to slow (so only one training per application).",thanks concerning please leave full training one integration test simple also run ca many slow one training per application,issue,positive,positive,positive,positive,positive,positive
438274818,Dont think this is adding much value. Closing it.,dont think much value,issue,negative,positive,positive,positive,positive,positive
438248679,"I _think_ I am seeing the same with simple_cnn:
```
data = ImageDataBunch.from_folder(""./fastdata"")
model = simple_cnn((3,16,16,2))
learn = Learner(data, model)
learn.metrics=[accuracy]
learn.fit(50)

img = open_image("".01.png"")
learn.predict(img)
```
   learn.predict(img)
AttributeError: 'Learner' object has no attribute 'predict'

```
python -c ""import fastai;print(fastai.__version__)""
1.0.22
```",seeing data model learn learner data model accuracy object attribute python import print,issue,negative,neutral,neutral,neutral,neutral,neutral
438156385,"**What is going on here**

Here I will explain the current behavior of `untar_data`. As for if such behavior is desirable, people who have an opinion can express it here.

Here is an example of the use of `untar_data` in the lesson 1 notebook:

```python
path = untar_data(URLs.PETS)
```

From the naming of the variable, it is common to assume that `URLs.PETS` is an actual url. Looking at the documentation of `untar_data`, it shows that

```python
untar_data(url:str, fname:PathOrStr=None, dest:PathOrStr=None, data=True)

""Download url if it doesn't exist to fname and un-tgz to folder dest""
```

So it also suggests that the first argument of `untar_data` is a url.

If you look into the exact content of `URLs.PETS`, which is simply a constant field of the class `URLs`, you will find that it is defined as

```
'https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet'
```

However, if you try to visit that url or download the file using command like `wget`, you will find that this url is invalid. Indeed, the actual address is

```
'https://s3.amazonaws.com/fast-ai-imageclas/oxford-iiit-pet.tgz'
```

with `.tgz` added at the end.

What I do find confusing here is that, though both the naming `URLs` and the docs of `untar_data` suggest that its first argument is a url, `URLs.PETS` is actually not a valid url. Digging a bit deeper, we found in the source code of `download_data` function called by `untar_url` function the following lines

```python
if not fname.exists():
    print(f'Downloading {url}')
    download_url(f'{url}.tgz', fname)
```

So it is clear that the `url` variable here is actually not a true url, but one with `.tgz` missing at the end. We can also infer that the `url` parameter `untar_data` takes and every field of `URLs` class is actually the true url with `.tgz` removed from the end.

Now going back to your post, to download any dataset ending with `.tgz`, simply remove the `.tgz` and throw it into `untar_data` and it should work. For datasets with other formats, currently it is not supported with `untar_data`, because regardless of your dataset `url` and its file format, it always appends `.tgz` when downloading the data.",going explain current behavior behavior desirable people opinion express example use lesson notebook python path naming variable common assume actual looking documentation python exist folder also first argument look exact content simply constant field class find defined however try visit file command like find invalid indeed actual address added end find though naming suggest first argument actually valid digging bit found source code function function following python print clear variable actually true one missing end also infer parameter every field class actually true removed end going back post ending simply remove throw work currently regardless file format always data,issue,positive,positive,neutral,neutral,positive,positive
438138691,"Let's wait a little bit with merging this, since I hear @sgugger is busy rewriting all of the docs, so we don't want to drop a potential surprise if suddenly it works differently, or even unfamiliar, since he probably is using this functionality a lot as we speak.",let wait little bit since hear busy want drop potential surprise suddenly work differently even unfamiliar since probably functionality lot speak,issue,negative,negative,neutral,neutral,negative,negative
438138244,"> @stas00 by pinning the version, do you mean setting it ==5.4 instead of >=5.4?

I meant `nbconvert>=5.4` in requirements in setup.py and conda/meta.yml ",pinning version mean setting instead meant,issue,negative,negative,negative,negative,negative,negative
438137949,"> Awesome. Thanks for the feedback!
> 
> Totally right about too many flags. Old build-docs script has been changed to:
> tools/build-docs --html-only
> 
> I combined --update-line-num and --update-nb-links into one flag because it seemed like they would always be run together. I can change it back though if that's not the case.

And I'd add `-h` to make it even shorter, as a short alias, e.g. in `tools/trust-origin-git-config` we have:

```
parser = argparse.ArgumentParser()
parser.add_argument('-e', '--enable',  action=""store_true"", help=""Trust repo-wide .gitconfig (default action)"")
parser.add_argument('-d', '--disable', action=""store_true"", help=""Distrust repo-wide .gitconfig"")
parser.add_argument('-t', '--test',    action=""store_true"", help=""Validate repo-wide .gitconfig config"")
```",awesome thanks feedback totally right many old script combined one flag like would always run together change back though case add make even shorter short alias parser enable trust default action disable distrust test validate,issue,positive,positive,positive,positive,positive,positive
438134062,"That's not a bug, you should use `flip_affine` for bounding boxes and points [see here in the docs](https://docs.fast.ai/vision.transform.html#flip_affine).",bug use bounding see,issue,negative,neutral,neutral,neutral,neutral,neutral
438133807,This is an area of heavy refactor for now. Closing this issue as we're aware of it and it should be fixed tomorrow.,area heavy issue aware fixed tomorrow,issue,negative,positive,neutral,neutral,positive,positive
438102191,"@stas00 by pinning the version, do you mean setting it ==5.4 instead of >=5.4?",pinning version mean setting instead,issue,negative,negative,negative,negative,negative,negative
438101931,"Awesome. Thanks for the feedback!

Totally right about too many flags. Old build-docs script has been changed to:
tools/build-docs --html-only

I combined --update-line-num and --update-nb-links into one flag because it seemed like they would always be run together. I can change it back though if that's not the case.",awesome thanks feedback totally right many old script combined one flag like would always run together change back though case,issue,positive,positive,positive,positive,positive,positive
438066754,"@sgugger  Thanks for the update, Interesting I was convinced fastai v1 uses pytorch v1/ where do you report the v1 issues? ",thanks update interesting convinced report,issue,positive,positive,positive,positive,positive,positive
438059822,"Your version of pytorch is v1.0 if you have this error. fastai doesn't support pytorch 0.4, see the [forum](https://forums.fast.ai/) for more details.",version error support see forum,issue,negative,neutral,neutral,neutral,neutral,neutral
438056915,"and thank you for tracking that nbconvert version issue, @bearpelican! I have now updated mine. Perhaps we need to pin that version instead (if it's on pypi and conda).",thank version issue mine perhaps need pin version instead,issue,negative,neutral,neutral,neutral,neutral,neutral
438055946,"looking good @bearpelican, thank you!

Here are some nuances to discuss:

I'm not sure about:

```
previous build-docs command becomes -
tools/build-docs --no-update-line-num --no-update-nb-links
```
That's too much to type. Can we have one letter flag that combines both options? But let's ask the main user first of his needs:

@sgugger - which of the current scripts `build-docs`, `update-nbs` do you use most of the time? I think the default (no flags) should be for the setup used most of the time, the second most used setup should have a single short flag, and then we have the long options for the rest of the rare cases.

This is also a good moment to rename the combined script if you feel that `build-docs` is not it.

We can also keep the 2 scripts, one being just a thin wrapper for the main one, so it's easier to use and no need to remember any flags.

It's your call @sgugger.",looking good thank discus sure previous command becomes much type one letter flag let ask main user first need current use time think default setup used time second used setup single short flag long rest rare also good moment rename combined script feel also keep one thin wrapper main one easier use need remember call,issue,positive,positive,positive,positive,positive,positive
438041526,"until then you can always:
```
! unzip file.zip
```
replace 'unzip' with whatever app you normally use on your system to unzip files.",always replace whatever normally use system,issue,negative,positive,positive,positive,positive,positive
438007887,"yes it would certainly not have been named 'untar_data' then, its just that I could not able to find a Notebook friendly module to unzip file...",yes would certainly could able find notebook friendly module file,issue,positive,positive,positive,positive,positive,positive
438001955,"And if it does that, I can't help to notice that it's already not an un**tar** - as it handles .tgz, .tar.gz - so probably it needs to be renamed to something more honest to what it does, no?

and then we have 7zip that is becoming much more common, and bz2. 

May be there is a python module that already handles all of those formats transparently so that we don't have to reinvent the wheel. Do you mind researching that @gshashank84? The only requirement is that it either has to be a python core module or if it's an external module it has to be both on pypi and conda's main channel (not conda-forge).",ca help notice already un tar probably need something honest zip becoming much common may python module already transparently reinvent wheel mind requirement either python core module external module main channel,issue,positive,positive,positive,positive,positive,positive
437981096,Please discuss install issues on the [forum](https://forums.fast.ai).,please discus install forum,issue,negative,neutral,neutral,neutral,neutral,neutral
437974920,Closing now since I have discovered that codes.csv should only contain classes that are common to train and valid directories. ,since discovered contain class common train valid,issue,negative,negative,negative,negative,negative,negative
437968674,"Probably you're using an old version of `fastai` package? As soon as I know, `fastai.nlp` was renamed into `fastai.text` in `v1`.",probably old version package soon know,issue,negative,positive,neutral,neutral,positive,positive
437966560,"Thanks for the response.  I installed fastai on python 3.6.6 as well. It allows me to do `import fastai` but doesn't allow me to `import fastai.dataset`. It says the package `dataset` does not exist. The same thing happens for `import fastai.nlp`, `import fastiai.models`. 
",thanks response python well import allow import package exist thing import import,issue,positive,positive,positive,positive,positive,positive
437923550,"Hello,

I have also found the same bug. I have written a patch that fix it and made a PR",hello also found bug written patch fix made,issue,negative,neutral,neutral,neutral,neutral,neutral
437831525,"Yes, you're right, the problem is that you're using a too old version of Python. As I can see from your shell's output, you're using Python 2.7 but strings interpolation (strings starting with `f` symbol) were introduced in Python 3.5 only. That's why this line fails on your machine with `SyntaxError` exception:
```python
 if os.path.isdir(path): paths=glob(f'{path}/*.*')
```
You need to update your interpreter to 3.7.",yes right problem old version python see shell output python interpolation starting symbol python line machine exception python path path need update interpreter,issue,negative,positive,positive,positive,positive,positive
437744637,You can specify the name of the train folder with an argument called (very unoriginal) train.,specify name train folder argument unoriginal train,issue,negative,negative,negative,negative,negative,negative
437720234,"Reopening.

len(data.train_ds) and len(data.valid_ds) are wrong following my process. They both report 9850.
Whereas I expected the split datasets to have 7880 and 1970 records respectively. ",wrong following process report whereas split respectively,issue,negative,negative,negative,negative,negative,negative
437708648,"Thank you for your patience !

Finally my databunch is ready and a learner based on resnet34 is finding the lr.

Here is what I had to do.

1. move 1970 random images (out of 9850 i.e. apprx 20%) from train directory to valid directory

1. built a labels.csv with two columns containing path+image_name & class name

1. create a codes file containing unique class names from the labels.csv

1. Build databunch using:

codes = np.loadtxt(path/'codes.txt', dtype=str)
df_fn_labels=pd.read_csv(path/'labels.csv', index_col=None)
fnames=list(df_fn_labels['Image'])
labels=list(df_fn_labels['Id'])
`data = (ImageFileList.from_folder(path)
        .label_from_df(df_fn_labels, fn_col=0, label_col=1)
        .split_by_folder()
        .datasets(ImageClassificationDataset, fns=fnames, labels=labels, classes=codes)
        .transform(get_transforms(), size=128)
        .databunch()
        .normalize(imagenet_stats))`

There maybe opportunity to get the fastai library itself to do some of this stuff",thank patience finally ready learner based finding move random train directory valid directory built two class name create file unique class build data path maybe opportunity get library stuff,issue,positive,positive,neutral,neutral,positive,positive
437694004,"@devforfu,
I don't think so. Using pdb.set_trace() I see that somewhere len(self.classes) < unique class names in train.csv. I thought there is a problem with the train.csv file from kaggle (whitespace etc.). But the file opens very well in pandas dataframe. So I am at a loss. Can you try downloading the dataset from kaggle:

! kaggle competitions download -c whale-categorization-playground -p {path}

and try 

data = (ImageFileList.from_folder(path)           
        .label_from_csv(path/'train.csv', folder='train') 
        .random_split_by_pct(0.2)
        .datasets()  
        .transform(get_transforms(), size=128)             
        .databunch()
        .normalize(imagenet_stats))


It is likely that we may have found a bug ???

**Please keep it on the back-burner but keep it alive.**",think see somewhere unique class thought problem file file well loss try path try data path likely may found bug please keep keep alive,issue,negative,positive,positive,positive,positive,positive
437673026,Thanks @sgugger . I thought that it just imported pytorch core stuff; I didn't think it imported fastai.core,thanks thought core stuff think,issue,negative,positive,positive,positive,positive,positive
437641963,It should be because the most recent version of the package shows [a deprecation warning](https://github.com/fastai/fastai/blob/8b9eb88f9581b5e897b7f04d466e0a2debe6e14b/fastai/vision/data.py#L87) if you use old methods to create data bunch. The warning says old factory methods will be removed in the next release. Probably you're providing wrong arguments to one of the calls.,recent version package deprecation warning use old create data bunch warning old factory removed next release probably providing wrong one,issue,negative,negative,neutral,neutral,negative,negative
437636654,"Thanks for you comment.
Remove the brackets and fixed.",thanks comment remove fixed,issue,negative,positive,positive,positive,positive,positive
437633835,Looking at other possible solutions I have stumbled upon this: https://docs.python.org/3/library/imghdr.html which seems to be the perfect solution and it's a core python library.,looking possible upon perfect solution core python library,issue,positive,positive,positive,positive,positive,positive
437631459,"Good suggestions, thanks Stas! So considering that python-magic is not on conda do you think its ok if we leave it as is? Or is there some better way that does not conflict with the current installation process?",good thanks considering think leave better way conflict current installation process,issue,positive,positive,positive,positive,positive,positive
437630442,"and the solution based on the advertised file extension, is good, but could be improved, as many online files carry invalid extensions. A better solution would be to use https://github.com/ahupp/python-magic (a wrapper around libmagic), except it would create a dependency on another external library. `file(1)` would work w/o creating such dependency, but it'd be much slower and will only work on unix-based environments.

update: I checked python-magic is on pypi, but on conda it's only on conda-forge for linux/osx - and windows is more complicated. https://github.com/ahupp/python-magic#windows

so it won't quite work unless a special case is made to do a better identification when fastai is run on linux/osx.",solution based file extension good could many carry invalid better solution would use wrapper around except would create dependency another external library file would work dependency much work update checked complicated wo quite work unless special case made better identification run,issue,positive,positive,positive,positive,positive,positive
437630393,"@lesscomfortable, the new test for download_images rendered the test suite dependent on the Internet connection. Would it be less of a test if it were to use file:// url instead of http://files.fast.ai, by fetching the images from the local fs, rather than online?",new test test suite dependent connection would le test use file instead fetching local rather,issue,negative,positive,neutral,neutral,positive,positive
437628365,"What's the loss function you are using? If it returns a rank 0 tensor, you shouldn't have that error.
Look at the result of one of your losses, and it should look like:
`tensor(0.7161, device='cuda:0')` 
not 
`tensor([0.7161], device='cuda:0')`",loss function rank tensor error look result one look like tensor tensor,issue,negative,negative,negative,negative,negative,negative
437627906,Please use the [forum](https://forums.fast.ai/) for this and be sure to put your code. We can't help you without it.,please use forum sure put code ca help without,issue,positive,positive,positive,positive,positive,positive
437530069,"Yea, knew it would be a bit of re-structuring - and wasn't sure of the best route

couldn't get Sylvain's attention on forum chat - so tried here 😬 ",yea knew would bit sure best route could get attention forum chat tried,issue,positive,positive,positive,positive,positive,positive
437527137,Thanks for the patch - this isn't quite right; lemme think about this for a bit...,thanks patch quite right think bit,issue,negative,positive,positive,positive,positive,positive
437524006,"Saw one, missed the other. Thanks for flagging!",saw one thanks flagging,issue,negative,positive,positive,positive,positive,positive
437517756,"Ah, you're definitely on to something. I think there needs to be a `learn.model.reset()` *before* the optimizer is created.
Will look into this.",ah definitely something think need look,issue,negative,neutral,neutral,neutral,neutral,neutral
437506865,"To be exact, second run to create_opt fixes the issue 
<img width=""947"" alt=""screenshot 2018-11-09 at 22 53 18"" src=""https://user-images.githubusercontent.com/340180/48290200-53e94000-e472-11e8-9940-0e8b12874296.png"">
",exact second run issue,issue,negative,positive,positive,positive,positive,positive
437503416,"Unfortunately, it isn't fixed yet. If you run `fit` twice the issue disappears for the second run. I think the issue was there from the start, but in old fastai fit was working a bit differently. 
Have a look at the screenshot below. It is on current fastai (updated 10 min ago)
<img width=""689"" alt=""screenshot 2018-11-09 at 22 38 27"" src=""https://user-images.githubusercontent.com/340180/48289596-50ed5000-e470-11e8-9cc8-fa46001fbb02.png"">

",unfortunately fixed yet run fit twice issue second run think issue start old fit working bit differently look current min ago,issue,negative,positive,positive,positive,positive,positive
437382355,"Normally this is fixed now. Your gist still has an error, but it comes from the empty validation data, so it should work okay on a real case.
Thanks for flagging!",normally fixed gist still error come empty validation data work real case thanks flagging,issue,negative,positive,neutral,neutral,positive,positive
437374499,"Thanks. Note that this is still a work in progress, but those are steps in the right direction indeed!",thanks note still work progress right direction indeed,issue,positive,positive,positive,positive,positive,positive
437371391,Can you add the test that show it works with the three images I added yesterday on files.fast.ai? Thanks!,add test show work three added yesterday thanks,issue,negative,positive,positive,positive,positive,positive
437370482,"To check the batch size, type `data.train_dl.batch_size`. Let me know by reopening this issue if it doesn't give you the expected result.",check batch size type let know issue give result,issue,negative,neutral,neutral,neutral,neutral,neutral
437369697,"Can you open this issue on the [course repo](https://github.com/fastai/course-v3)? This isn't linked to the library.
Thanks!",open issue course linked library thanks,issue,negative,positive,neutral,neutral,positive,positive
437357793,"I didn't implement the unet, Jeremy did, but when doing a Feature pyramid network (which is the same thing in principle) I had an nasty bug with a ReLU(inplace=True): it turns out the inplace was modifying the tensor that was stored for the lateral connections.
There might be the same problem here. I'll close this PR and I encourage you to continue the discussion on the [forum](https://forums.fast.ai/) as it might interest more people!",implement feature pyramid network thing principle nasty bug turn tensor lateral might problem close encourage continue discussion forum might interest people,issue,negative,negative,negative,negative,negative,negative
437315476,"It really just depends on if the in-place operation is overwriting a variable that is used to compute a gradient for back propagation. 

So...
```
input = torch.rand(3,4,4)-0.5
F.relu(input) #does not overwrite input
F.relu(input, inplace=True) #overwrites input
```

If `input` was used in the computation of a gradient then you would get the ""RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation"" error from the above `F.relu(input, inplace=True)` operation, during back propagation. If a COPY of the `input` tensor  is passed to `F.relu` you would not get an error. 

Does that help to explain the issue? ",really operation variable used compute gradient back propagation input input overwrite input input input input used computation gradient would get one gradient computation operation error input operation back propagation copy input tensor would get error help explain issue,issue,negative,positive,neutral,neutral,positive,positive
437299598,"Interesting. Thanks. I appreciate the response. I think I get it but I have
a couple other questions. This one I hope actually misses the point. I'm
looking at alexnet. It does not have batchnorm, but it does have inplace
relus. Why? Does the incompatibility have to do with hooks for dynamic net?

Also I am somewhat familiar with in place abn.
https://github.com/mapillary/inplace_abn

Based on what you are saying, is batchnorm with in place relu parameter is
equivalent to this?

On Fri, Nov 9, 2018, 1:03 AM Marii <notifications@github.com wrote:

> It works for resnet because you are guaranteed to have a batchnorm before
> the inplace relu.
> class DynamicUnet(nn.Sequential): ""Create a U-Net from a given
> architecture."" def __init__(self, encoder:nn.Module, n_classes:int): #
> --stuff here--- layers = [encoder, nn.ReLU(inplace=True), middle_conv]
> DynamicUnet allows you to pass in the encoder, which does not necessarily
> have a batchnorm. In-place ReLU is architecture specific and therefore
> cannot go here. If you try running this using a network without batch norm
> you will get this error:
>
> RuntimeError: one of the variables needed for gradient computation has
> been modified by an inplace operation
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1115#issuecomment-437294946>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACpS3SNxAGlkWSyj_FnroTPBm8674chFks5utUT-gaJpZM4YV9fP>
> .
>
",interesting thanks appreciate response think get couple one hope actually point looking incompatibility dynamic net also somewhat familiar place based saying place parameter equivalent wrote work class create given architecture self stuff pas necessarily architecture specific therefore go try running network without batch norm get error one gradient computation operation thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
437295231,I think you need to update to at least v. 1.0.21 (look at the CHANGES.md) ,think need update least look,issue,negative,negative,negative,negative,negative,negative
437294946,"It works for resnet because you are guaranteed to have a batchnorm before the inplace relu. 
```
class DynamicUnet(nn.Sequential):

    #""Create a U-Net from a given architecture.""
    def __init__(self, encoder:nn.Module, n_classes:int):
    # --stuff here---
    layers = [encoder, nn.ReLU(inplace=True), middle_conv]
```
DynamicUnet allows you to pass in the encoder, which does not necessarily have a batchnorm. In-place ReLU is architecture specific and therefore cannot go here. If you try running this using a network without batch norm you will get this error: 

RuntimeError: one of the variables needed for gradient computation has been modified by an inplace operation

In place Relu, and in-place in general is not ""deprecated"", it is just that the performance benefits you get from doing it in place have potential drawbacks, and are only worth when performance is especially important. ",work class create given architecture self stuff pas necessarily architecture specific therefore go try running network without batch norm get error one gradient computation operation place general performance get place potential worth performance especially important,issue,negative,positive,positive,positive,positive,positive
437284183,"On that note, pytorch is being a bit contradictory. Their resnet code all
uses in place relus. Some for other architectures. Is this now depricated?

On Fri, Nov 9, 2018, 12:13 AM Erik Gaasedelen <erikgaas@gmail.com wrote:

> This is really interesting. Has this changed in v1? Has inplace ever been
> recommended?
>
> On Fri, Nov 9, 2018, 12:03 AM Marii <notifications@github.com wrote:
>
>> For referencee:
>> https://pytorch.org/docs/master/notes/autograd.html#in-place-operations-on-variables
>>
>> Pytorch generally recommends against using in place operations.
>>
>> —
>> You are receiving this because you authored the thread.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/fastai/fastai/pull/1115#issuecomment-437280602>, or mute
>> the thread
>> <https://github.com/notifications/unsubscribe-auth/ACpS3foe7A7WI07K56tijxNmcUhxvRiEks5utTazgaJpZM4YV9fP>
>> .
>>
>
",note bit contradictory code place wrote really interesting ever wrote generally place thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
437283056,"This is really interesting. Has this changed in v1? Has inplace ever been
recommended?

On Fri, Nov 9, 2018, 12:03 AM Marii <notifications@github.com wrote:

> For referencee:
> https://pytorch.org/docs/master/notes/autograd.html#in-place-operations-on-variables
>
> Pytorch generally recommends against using in place operations.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1115#issuecomment-437280602>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ACpS3foe7A7WI07K56tijxNmcUhxvRiEks5utTazgaJpZM4YV9fP>
> .
>
",really interesting ever wrote generally place thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
437266645,"Changes include adding new line to show the names properly. As the names/categories could be large as it is in case of Cars Dataset. Also little formatting has been done to present the data properly. I think the figsize=(15,15) could be also added to show the text and images properly.",include new line show properly could large case also little done present data properly think could also added show text properly,issue,negative,positive,neutral,neutral,positive,positive
437196172,"Funny enough the same code that does not work from console works fine in jupyter notebook :), and QRNN trains properly.
<img width=""940"" alt=""screenshot 2018-11-09 at 00 35 36"" src=""https://user-images.githubusercontent.com/340180/48233902-6c485480-e3b7-11e8-857e-cfa7472f56ab.png"">
",funny enough code work console work fine notebook properly,issue,positive,positive,positive,positive,positive,positive
437184589,"<details>
  <summary>QRNN after 80 epochs train_loss 3.458618</summary>
<pre>
python -m ulmfit.pretrain_lm data/en/wikitext-2 --qrnn=True --cuda-id=1 --name=wt-2-qrrn --num_epochs=100 --ds-pct 0.1
Batch size: 70
Max vocab: 60000
Using QRNNs...
Limiting data set to 0.1
Size of vocabulary: 15246
First 10 words in vocab: the, <pad>, ,, ., of, <unk>, and, in, to, <eos>
Saving vocabulary...
epoch  train_loss  valid_loss  accuracy
1      9.589046    9.525568    0.054306
2      9.424072    9.135739    0.054414
3      9.018161    8.359212    0.055189
4      8.346138    7.305996    0.053968
5      7.580266    6.492858    0.055856
6      7.169321    6.493022    0.054306
7      6.987562    6.489878    0.054160
8      6.907942    6.492623    0.053957
9      6.873025    6.489362    0.055335
10     6.859171    6.484140    0.054791
11     6.853229    6.491655    0.054306
12     6.848705    6.489232    0.054306
13     6.845232    6.473944    0.055195
14     6.842732    6.485246    0.062665
15     6.839021    6.484037    0.054306
16     6.830321    6.465160    0.071581
17     6.818776    6.452264    0.075586
18     6.800464    6.431604    0.087741
19     6.767688    6.376600    0.095410
20     6.724560    6.318267    0.103209
21     6.671863    6.255381    0.115368
22     6.606373    6.166226    0.132358
23     6.535790    6.103925    0.138655
24     6.459231    6.043802    0.149233
25     6.385064    6.010012    0.152178
26     6.301238    5.932988    0.160843
27     6.211205    5.891285    0.165704
28     6.124407    5.835395    0.176596
29     6.032049    5.793059    0.174895
30     5.943070    5.763924    0.180171
31     5.846730    5.705569    0.190848
32     5.744658    5.666500    0.192437
33     5.650591    5.643042    0.194758
34     5.554672    5.609411    0.199240
35     5.447789    5.580114    0.201429
36     5.351630    5.552900    0.202304
37     5.273030    5.564426    0.203850
38     5.174746    5.534225    0.205236
39     5.078378    5.522253    0.207350
40     5.000897    5.530851    0.206839
41     4.921390    5.521262    0.207447
42     4.841522    5.530956    0.207143
43     4.763840    5.558990    0.206618
44     4.686889    5.555052    0.206436
45     4.606619    5.539403    0.207801
46     4.535450    5.544782    0.206550
47     4.471734    5.551255    0.208156
48     4.413557    5.582464    0.205978
49     4.357163    5.581117    0.205876
50     4.293034    5.580110    0.207778
51     4.246437    5.609156    0.204474
52     4.227892    5.614207    0.203901
53     4.167626    5.608902    0.205067
54     4.098423    5.591347    0.206855
55     4.051802    5.634832    0.201623
56     4.025866    5.644625    0.202950
57     3.960732    5.628582    0.203588
58     3.919922    5.643956    0.204407
59     3.871385    5.649668    0.203597
60     3.863034    5.665218    0.204186
61     3.822766    5.656523    0.203662
62     3.784243    5.667356    0.205397
63     3.758609    5.682689    0.202189
64     3.752130    5.687783    0.202890
65     3.725233    5.684005    0.204711
66     3.680005    5.693838    0.202549
67     3.644393    5.680868    0.202727
68     3.612632    5.688258    0.201240
69     3.618646    5.703245    0.202049
70     3.579999    5.689683    0.200999
71     3.552939    5.712533    0.199179
72     3.531558    5.715834    0.200253
73     3.515812    5.735734    0.196589
74     3.515083    5.728702    0.198401
75     3.520288    5.731945    0.199544
76     3.485003    5.731506    0.200362
77     3.478617    5.735614    0.198884
78     3.469165    5.737576    0.200473
79     3.476101    5.741198    0.199635
80     3.458618    5.726952    0.200059
</details>

<details>
  <summary>LSTM after 80 epochs train_loss  0.057178</summary>
<pre>
time python -m ulmfit.pretrain_lm data/en/wikitext-2 --qrnn=False --name=wt-2 --num_epochs=100 --ds-pct=0.1
Batch size: 70
Max vocab: 60000
Limiting data set to 0.1
Size of vocabulary: 15246
First 10 words in vocab: the, <pad>, ,, ., of, <unk>, and, in, to, <eos>
Saving vocabulary...
epoch  train_loss  valid_loss  accuracy
1      8.149413    6.625456    0.062006
2      7.230876    6.325223    0.099559
3      6.830673    6.125136    0.144649
4      6.551603    5.952240    0.173658
5      6.325869    5.836593    0.185208
6      6.125107    5.735621    0.195029
7      5.946550    5.717289    0.202178
8      5.771859    5.629531    0.199899
9      5.599160    5.556547    0.207811
10     5.419254    5.529798    0.209928
11     5.225041    5.507531    0.213010
12     5.034083    5.549269    0.205559
13     4.824013    5.621671    0.199627
14     4.613435    5.691539    0.196902
15     4.409591    5.702592    0.193010
16     4.195541    5.784494    0.195985
17     4.038594    5.646560    0.203244
18     3.841888    5.732875    0.195725
19     3.608887    6.036916    0.180364
20     3.372380    6.232230    0.168756
21     3.128355    6.262933    0.176038
22     2.909338    6.441030    0.171536
23     2.674638    6.417610    0.171429
24     2.433226    6.704102    0.169098
25     2.277819    6.463394    0.169116
26     1.988678    7.060129    0.154458
27     1.784888    7.097499    0.155542
28     1.557777    7.144700    0.156282
29     1.406564    7.181555    0.152254
30     1.199157    7.481484    0.152097
31     1.035858    7.643167    0.130978
32     0.892027    7.752474    0.135309
33     0.734421    7.835570    0.148244
34     0.650520    7.789397    0.144553
35     0.535672    7.819457    0.145871
36     0.479333    7.990303    0.147565
37     0.445199    8.043110    0.142208
38     0.372400    8.086502    0.136321
39     0.362246    8.095461    0.138166
40     0.297715    8.294946    0.137842
41     0.269403    8.398767    0.140062
42     0.231488    8.379242    0.137079
43     0.328645    8.302129    0.138708
44     0.301683    8.359775    0.135945
45     0.228592    8.246195    0.139716
46     0.187372    8.308817    0.139564
47     0.235492    8.342047    0.139108
48     0.196987    8.322741    0.140780
49     0.164636    8.369329    0.144128
50     0.132969    8.272486    0.142918
51     0.130011    8.361520    0.137639
52     0.109054    8.150353    0.147692
53     0.112340    8.291537    0.139260
54     0.277651    7.856262    0.147011
55     0.171290    8.075988    0.146454
56     0.114004    8.053049    0.146480
57     0.092124    8.044921    0.146701
58     0.088315    8.128678    0.145542
59     0.075355    8.009786    0.148571
60     0.081272    7.991426    0.145947
61     0.085800    8.081589    0.142396
62     0.069526    7.963127    0.141535
63     0.062828    7.908299    0.148162
64     0.069758    7.912842    0.147163
65     0.070617    7.826627    0.151533
66     0.057702    7.805183    0.149255
67     0.052341    7.751988    0.150462
68     0.047684    7.770833    0.150185
69     0.047177    7.793154    0.149032
70     0.047017    7.764704    0.151601
71     0.062799    7.766047    0.153231
72     0.057702    7.762446    0.152229
73     0.047140    7.732766    0.152135
74     0.042476    7.683928    0.154945
75     0.048810    7.631882    0.154481
76     0.107342    7.568276    0.155231
77     0.073181    7.645492    0.154205
78     0.049275    7.666656    0.153749
79     0.060635    7.702621    0.152312
80     0.057178    7.706323    0.151134
</details>",summary python batch size limiting data set size vocabulary first pad saving vocabulary epoch accuracy summary time python batch size limiting data set size vocabulary first pad saving vocabulary epoch accuracy,issue,negative,positive,positive,positive,positive,positive
437012160,Merging this first step. You should also update the sidebar to show your new page (see [here](https://docs.fast.ai/gen_doc.html#Updating-sidebar)) for doc on this.,first step also update show new page see doc,issue,negative,positive,positive,positive,positive,positive
437011497,"Hey Francisco, there seems to be some merge problems and you sill show commits from a while ago. I'd suggest updating your fastai repo before redoing those changes in a clean PR.
Closing this in the meantime.",hey merge sill show ago suggest clean,issue,negative,positive,positive,positive,positive,positive
436680783,Please only use github issues for issues with the library. The [forum](https://forums.fast.ai) is there for all other questions!,please use library forum,issue,negative,neutral,neutral,neutral,neutral,neutral
436680392,"You still have tabular.ipynb deleted.
Maybe close this PR and paste your code in a new one?",still maybe close paste code new one,issue,negative,positive,positive,positive,positive,positive
436650229,"Mmmm, what version of the library are you using? I just tested some similar code and the batch size seemed to be set properly with `.databunch(bs=32)`.",version library tested similar code batch size set properly,issue,negative,neutral,neutral,neutral,neutral,neutral
436401274,This is my first PR - could you please make those last corrections. I tried to do it but have again run into this infernal synching with master and updating the PR. I am back to  The flow of syncing with the master and updating the PR has gone wrong again.  Would be really nice with a recipe  for dummies (like myself) on how to update a PR when master has moved one. I will leave the PR here for somebody more skilled with git,first could please make last tried run infernal master back flow master gone wrong would really nice recipe like update master one leave somebody skilled git,issue,positive,positive,positive,positive,positive,positive
436377392,"@jph00 Hi I am using a code which used ModelData.
But it seems like fastai does not have module ModelData.
This is the code and log

```

#import text module from fastai 
from fastai.text import *
model_data = ModelData(SAMPLE_DATA_PATH, trn_dl=train_iter_tuple, val_dl=val_iter_tuple)
```
and log:
```
NameError                                 Traceback (most recent call last)
<ipython-input-21-d9f2674be36f> in <module>()
      3 #from fastai import ModelData
      4 
----> 5 model_data = ModelData(SAMPLE_DATA_PATH, trn_dl=train_iter_tuple, val_dl=val_iter_tuple)
      6 
      7 #number of batches in training & validation set and number of tokens in vocabulary

NameError: name 'ModelData' is not defined
```",hi code used like module code log import text module import log recent call last module import number training validation set number vocabulary name defined,issue,negative,neutral,neutral,neutral,neutral,neutral
436360849,Closing this since the option apparently works to fix the bug.,since option apparently work fix bug,issue,negative,positive,neutral,neutral,positive,positive
436322230,"No need, I've done it [here](https://github.com/fastai/fastai/commit/c00d576cba1e3970959f1f71cc3ca707473aa276) ;)
Thanks for offering though!",need done thanks offering though,issue,negative,positive,positive,positive,positive,positive
436321158,"Sorry, this was my fault.

I will check it and propose a fix (if still needed).",sorry fault check propose fix still,issue,negative,negative,negative,negative,negative,negative
436300640,"Oh, see what you mean! It should only use that argument when using `normalize=True`, otherwise show ints. Will push a fix.",oh see mean use argument otherwise show push fix,issue,negative,negative,negative,negative,negative,negative
436295045,"This is a known issue but I don't think you're addressing it the right way. For one, we don't need to do this on the validation and the test set because the problem only comes during training.
Then we only need to remove the last batch if it's of size 1, not all the time. I'm also working on a fix for this so closing this.",known issue think right way one need validation test set problem come training need remove last batch size time also working fix,issue,negative,positive,positive,positive,positive,positive
436285951,"This is a good idea but your PR
- deletes one example
- doesn't convert `y1` to float as well",good idea one example convert float well,issue,positive,positive,positive,positive,positive,positive
436284994,"Thanks a lot, I'll work on this later today",thanks lot work later today,issue,negative,positive,neutral,neutral,positive,positive
436284239,"Thanks! Last step is to clean up the docs a bit. You have deleted cells that are weird compared to the current doc. Also, you should use different cells and markdown to comment instead of putting everything in one big cell, it would be more readable on the web version.",thanks last step clean bit weird current doc also use different markdown comment instead everything one big cell would readable web version,issue,positive,positive,neutral,neutral,positive,positive
436280813,"That's not the right way to do it: you should put your `mask_opener` function to `partial(open_mask_rle, args)` for now. I'm looking at a way to pass the size of x to `_get_y` which would support the case where all images aren't the same size.
Closing this, feel free to open a new one for just the str conversion.",right way put function partial looking way pas size would support case size feel free open new one conversion,issue,positive,positive,positive,positive,positive,positive
436275997,"I believe that you have mistaken the point here. I am not complaining that they are displaying too much digits. Instead, I am referring to the abnormality that the numbers that should and can only be integer to have meaning are somehow displayed in float format.",believe mistaken point much instead abnormality integer meaning somehow displayed float format,issue,negative,positive,positive,positive,positive,positive
436275296,You can pass an `norm_dec` argument to show less digits.,pas argument show le,issue,negative,neutral,neutral,neutral,neutral,neutral
436271882,"This isn't a bug: `fbeta` is intended for multiclassification problems where the target are one-hot encoded, which isn't the case in the example you give. If you really want to use it there, you'll have to modify the current implementation to add that one-hot encoding step.",bug intended target case example give really want use modify current implementation add step,issue,negative,positive,neutral,neutral,positive,positive
436130626,"Thanks for the information, was working on the notebook too.",thanks information working notebook,issue,negative,positive,positive,positive,positive,positive
436124890,"@jph00 @sgugger I updated the PR, incorporating your feedback. The test runs now in about a second on my CPU. The pr contains one failing and and one succeeding test, illustrating the issue. 

@sgugger It doesn't matter what resnet is used, in fact the only important thing is the occurrence of a BatchNorm2d layer. ",feedback test second one failing one succeeding test issue matter used fact important thing occurrence layer,issue,negative,positive,positive,positive,positive,positive
436061427,"> Actually you should be able to do it without a for loop using something like `torch.all()`.

I spent a bit of time checking for this myself, and was not able to find anything of this nature. I will implement your other suggestions though. ",actually able without loop something like spent bit time able find anything nature implement though,issue,negative,positive,positive,positive,positive,positive
435998185,"No problem. I wasn't very clear.
It works perfectly with all my metrics.
Thank you very much!",problem clear work perfectly metric thank much,issue,positive,positive,positive,positive,positive,positive
435972390,"Apologies, I didn't realize you had a custom metric function. Can you try [this commit](https://github.com/fastai/fastai/commit/2ae9b4dc5a0fbf7d628e7866470ee53b0b882225) and see if it fixes your problem?",realize custom metric function try commit see problem,issue,negative,neutral,neutral,neutral,neutral,neutral
435938976,"Thank you for your answer.
I see that AverageMetric is a wrapper for metric functions, called when the metric is not a Callback.
```python
    def __post_init__(self)->None:
        ""Initialize smoother and learning stats.""
        self.callbacks = ifnone(self.callbacks, [])
        self.metrics = ifnone(self.metrics, [])
        self.metrics = [(met if isinstance(met, Callback) else AverageMetric(met)) for met in self.metrics]
        self.callbacks = sorted(self.callbacks, key=lambda o: getattr(o, '_order', 0))
        self.smoothener = SmoothenValue(self.beta)
        self.state_dict:Dict[str,Union[int,float,Tensor]]=_get_init_state()
```
Why not adapting AverageMetric for any shape of target?
I guess the alternative is to wrap my metric function in a custom Callback.",thank answer see wrapper metric metric python self none initialize smoother learning met met else met met sorted union float tensor shape target guess alternative wrap metric function custom,issue,negative,neutral,neutral,neutral,neutral,neutral
435931375,"ok

On Mon, Nov 5, 2018 at 4:43 PM Sylvain Gugger <notifications@github.com>
wrote:

> Oh, boy, I don't know how you merged to the current branch but your PR
> modifies 253 files which is a bit too much! I can't review everything and
> merge and there are probably some messy things there.
> I think we need to close this one and open a fresh one if that's okay with
> you ;)
>
> —
> You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/1063#issuecomment-435922055>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AApeNxv3E517rTTx8J92xlSgwZG1xEB1ks5usFyXgaJpZM4YL1vl>
> .
>


-- 
Med venlig hilsen
Kaspar Lund
Tel: 2982 1734
Projekt og proces -ledelse
",mon wrote oh boy know current branch bit much ca review everything merge probably messy think need close one open fresh one state reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
435924001,"Hi there, it's only for computation of metrics such as accuracy that this is assumed (to get the batch size). This would bug anyway if you have a target that is a list as you'd need to implement your custom metric. List of targets as tensors is fully supported otherwise.",hi computation metric accuracy assumed get batch size would bug anyway target list need implement custom metric list fully otherwise,issue,negative,neutral,neutral,neutral,neutral,neutral
435922055,"Oh, boy, I don't know how you merged to the current branch but your PR modifies 253 files which is a bit too much! I can't review everything and merge and there are probably some messy things there.
I think we need to close this one and open a fresh one if that's okay with you ;)",oh boy know current branch bit much ca review everything merge probably messy think need close one open fresh one,issue,negative,positive,neutral,neutral,positive,positive
435876796,"ok i am done. it has been a messy process but now origin/pil2tensor are finally in sync. Tests passes and documentation is updated.
github says All checks have failed but i have signed the cla. which github/clahub confirmes ?

please review,  ",done messy process finally sync documentation please review,issue,negative,negative,neutral,neutral,negative,negative
435873293,"Thanks for the fix and the test. I just think one little thing can be refactored (left a comment), if you could make that modification and test it doesn't break anything, that'd be great. ",thanks fix test think one little thing left comment could make modification test break anything great,issue,positive,positive,positive,positive,positive,positive
435723528,"I think you are confusing validation and test set. In fastai, the test set is intended for unlabeled data, like in a Kaggle competition. This is also the case with the URLs.MNIST_TINY dataset (at least the latest version of it) where there is a valid dataset with labelled data in folders and unlabelled data in a test folder.

Thanks for your concerns but I work closely with Jeremy to know how he wants the library to be and I ask for his advice when in doubt. This specific topic has been discussed twice already on the [forum](https://forums.fast.ai/) and Jeremy is the one who wrote that specific bit of code, so I'm sure it's how he intended it.",think validation test set test set intended unlabeled data like competition also case least latest version valid data data test folder thanks work closely know library ask advice doubt specific topic twice already forum one wrote specific bit code sure intended,issue,positive,positive,positive,positive,positive,positive
435686689,Should be fixed now. Note that using path objects in your dataframe is incompatible with suffix not None (path objects have the extension in any case).,fixed note path incompatible suffix none path extension case,issue,negative,positive,neutral,neutral,positive,positive
435676973,I added it in [this commit](https://github.com/fastai/fastai/commit/d5eef11e7f38066ed45439519ca38d9ffeb63179) accidentally. Let me know if I can close this PR.,added commit accidentally let know close,issue,negative,neutral,neutral,neutral,neutral,neutral
435668438,You need to update your version of the library. Please look at the [forum](https://forums.fast.ai/) for more help.,need update version library please look forum help,issue,positive,neutral,neutral,neutral,neutral,neutral
435667957,"Sorry, I don't follow where you're suggesting to make the change.

The root problem is that `Path` is ubiquitous in fastai, and it's really hard for end users to work out what they did wrong from this error.

Some possible fixes:
1. Allow `Path` by changing the code in `_df_to_fns_labels`
2. Allow `Path` by changing the code in `ImageDataBunch.from_df` (and potentially any other callers of `_df_to_fns_labels`)
3. Disallow `Path` with an assertion in `ImageDataBunch.from_df`, giving clear feedback that you need to pass strings (or something that `pandas.Series.str` can handle)
4. Dissalow `Path` with an assertion in `_df_to_fns_labels`, giving clear feedback that you need to pass strings (or something that `pandas.Series.str` can handle)

I'm not sure what sort of fix best fits here, but something like this would be really helpful.",sorry follow suggesting make change root problem path ubiquitous really hard end work wrong error possible allow path code allow path code potentially disallow path assertion giving clear feedback need pas something handle path assertion giving clear feedback need pas something handle sure sort fix best something like would really helpful,issue,positive,positive,neutral,neutral,positive,positive
435667184,Cool notebook! However we just want one example for each of fastai's main applications.,cool notebook however want one example main,issue,negative,positive,positive,positive,positive,positive
435644061,"Thank you for your comment but I don't understand it fully.
 
You said that the test data should be unlabeled. That doesn't make much sense to me as you need to know the label of the test data to be able to produce an accuracy result.

On top of that, the dataset I used for my test is a fastai one (URLs.MNIST_TINY) and the test data for MNIST arranged with subfolders. 

I think that you should consider discussing the issue of how the data is supposed to be laid out on disk with Jeremy.
",thank comment understand fully said test data unlabeled make much sense need know label test data able produce accuracy result top used test one test data think consider issue data supposed laid disk,issue,positive,positive,positive,positive,positive,positive
435640268,"Updated @sgugger 

(the `test_from_csv_and_from_df ()` does become a bit heavy [harder to read] for the text - but we did get rid of the common code)",become bit heavy harder read text get rid common code,issue,negative,negative,negative,negative,negative,negative
435633832,"You should unwatch the repo then (at the right of the repo name, three buttons, it's the left one).

Not that watching the repo is a personal action from yourself, we didn't add you to anything.",right name three button left one watching personal action add anything,issue,negative,positive,neutral,neutral,positive,positive
435633733,"That's possible without breaking anything, it that helps you.",possible without breaking anything,issue,negative,neutral,neutral,neutral,neutral,neutral
435629426,"I have repeatedly tried to stop receiving notices about this if anyone can please remove me from all and any posts, notices, invites, etc...",repeatedly tried stop anyone please remove,issue,negative,neutral,neutral,neutral,neutral,neutral
435629186,"Also, if you can add a quick test that fails if the test dl doesn't load properly when your fix isn't there, that would be the cherry on the top!",also add quick test test load properly fix would cherry top,issue,negative,positive,positive,positive,positive,positive
435629132,"Good catch! Yes a PR would be appreciated as in multiple instances, is not None seems to work better.",good catch yes would multiple none work better,issue,negative,positive,positive,positive,positive,positive
435628463,"It's a model save, so you should specify a correct `models_path` for this (and saving your future models). It should work as the tmp_path you've be using.",model save specify correct saving future work,issue,negative,neutral,neutral,neutral,neutral,neutral
435614383,"I was just reminded by @sgugger  that `item()` triggers a CUDA sync, which slows things down a lot. So we can't add this here. Are there other approaches that may work for you?

At worse, you could always just replace that one method by monkey-patching it in your code.",item sync slows lot ca add may work worse could always replace one method code,issue,negative,negative,negative,negative,negative,negative
435611759,That's really interesting. Just checking on this - will get back to you asap.,really interesting get back,issue,negative,positive,positive,positive,positive,positive
435599892,"Not a bug, I was using pip installed fast.ai library - but updating the installed source and expecting it to work. After updating the fast.ai version to latest using pip - imports are working. ",bug pip library source work version latest pip working,issue,negative,positive,positive,positive,positive,positive
435596315,"Thanks for the notebook. I tried and it does seem to be faster this way, so let's do this.

Before merging though, here are a few thoughts:
- I think all the images should go in a folder images/tests/, also maybe rename them test_fmt.fmt so that anyone knows why there are here.
- NDArray should be named NPArray to be consistent with the other names. Please don't import ndarray from numpy but just use np.ndarray when you need it
- All the commented part of pil2tensor should be removed, and put in the doc instead. Now that the docs are in the same folder, you can include a change to them in the same PR ;)
- In your tests, I'd remove the print statement when all goes well. Having something when it goes wrong is good though",thanks notebook tried seem faster way let though think go folder also maybe rename anyone consistent please import use need part removed put doc instead folder include change remove print statement go well something go wrong good though,issue,positive,positive,positive,positive,positive,positive
435593613,"Please ignore, it was an issue with my custom loss function. Sorry!",please ignore issue custom loss function sorry,issue,negative,negative,negative,negative,negative,negative
435574170,"Sorry I didn't notice it accumulate previous commit, I think I need to create a new branch instead.",sorry notice accumulate previous commit think need create new branch instead,issue,negative,negative,negative,negative,negative,negative
435552337,"It's not broken as it is right now. Currently the callback.py file is almost completely decoupled from pytorch except in 2 places:
https://github.com/fastai/fastai/blob/master/fastai/callback.py#L221
https://github.com/fastai/fastai/blob/master/fastai/callback.py#L270

This change would allow me to easily use everything in callback.py in the https://github.com/fastai/tf-fit project by adding 2 functions to tensorflow tensors
tf.Tensor.detach = lambda x: x
tf.Tensor.item = lambda x: x.numpy()",broken right currently file almost completely except change would allow easily use everything project lambda lambda,issue,negative,positive,neutral,neutral,positive,positive
435539613,"> Ok, I changed the labels in the csv file (you may need to redownload the mnist_tiny example to see it). Can you amend this PR to take it into account?

PR ready",file may need example see amend take account ready,issue,negative,positive,positive,positive,positive,positive
435504927,"For images read from disk: One my mac it is 20-30% faster, on my gaming/DL box is  10% faster:
measure like this: %timeit -r 50 pil2tensor_new_argtype(Image.open(""dog.47.jpg"").convert(""RGB""), np.float32).div_(255)
and like this: %timeit -r 50 pil2tensor_new_argtype(Image.open(""dog.47.jpg""), np.float32).div_(255)

For in memory images : on my mac it is 40% and on my gamin PC 50% (ie half the time)
mesured like this: %timeit -r 20 pil2tensor_new_argtype(img,np.float32).div_(255)

For in memory numpy.array: it is almost instant:
arrfloat  = np.random.rand(224,224,3).astype(np.float32)
%timeit -r 50 pil2tensor_new_argtype(arrfloat,np.float32)

I know speed is important and have therefore created this notebook: The difference in speed varies a lot from machine to machine so i prefer that you checkout the notebook from this repository: https://github.com/kasparlund/fastaiNotebooks.git

The new method is called pil2tensor_new_argtype in the notebook and the current version pil2tensor",read disk one mac faster box faster measure like dog like dog memory mac gamin ie half time like memory almost instant know speed important therefore notebook difference speed lot machine machine prefer notebook repository new method notebook current version,issue,positive,positive,neutral,neutral,positive,positive
435488313,"Ok, I changed the labels in the csv file (you may need to redownload the mnist_tiny example to see it). Can you amend this PR to take it into account?",file may need example see amend take account,issue,negative,neutral,neutral,neutral,neutral,neutral
435483460,As discussed on the [forum](https://forums.fast.ai/t/segmentation-dataset-for-run-length-encoding/28967/4) there's no need for a special class now.,forum need special class,issue,negative,positive,positive,positive,positive,positive
435482133,"@sgugger agreed, made changes for it in latest commit",agreed made latest commit,issue,positive,positive,positive,positive,positive,positive
435481282,"This is not a bug: the test folder should have the images directly inside it, not inside other folders, since it's supposed to be unlabeled data. ",bug test folder directly inside inside since supposed unlabeled data,issue,negative,positive,neutral,neutral,positive,positive
435480647,"Thanks! I have just one little comment: if path is set to the default '.', resume should default to False as the idea is to overwrite current images.",thanks one little comment path set default resume default false idea overwrite current,issue,negative,negative,neutral,neutral,negative,negative
435479732,"Hi there! Thanks for this PR. We had actually coded `open_image` this way because it used to be faster. Could you give us a little benchmark of how fast your function is compared the current implementation?

We just added a new functionality so that users can pass their own function to open images, so I'm thinking that if this `pil2tensor` is slower, we could use it in an `open_image_slow` function that would be more general.",hi thanks actually way used faster could give u little fast function current implementation added new functionality pas function open thinking could use function would general,issue,negative,positive,neutral,neutral,positive,positive
435422381,"Fixed, but note that if you don't pass that size argument when creating a DataBunch or a DataLoader, images won't be able to be stacked together.",fixed note pas size argument wo able together,issue,negative,positive,positive,positive,positive,positive
435379449,"Yes, those API have been changed. We need to update the example notebooks accordingly.",yes need update example accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
435333837,"I think a simpler solution is to read the df outside of the argument,  make it a str first or whatever processing you need to do.

Can you just do this transformation outside and just pass the processed df? 
",think simpler solution read outside argument make first whatever need transformation outside pas,issue,negative,positive,neutral,neutral,positive,positive
435271924,"Ups, for some reason github didnt understand conflict resolution. However now it should be trivial: just take confusion_matrix_iterative_computations version. Please let me know if you need any help",reason didnt understand conflict resolution however trivial take version please let know need help,issue,positive,neutral,neutral,neutral,neutral,neutral
435271623,"Hi, I've just resolved a conflict and squashed commits to a single one. It looks like it is ready to be merged. thanks!",hi resolved conflict single one like ready thanks,issue,positive,positive,positive,positive,positive,positive
435257963,I'm not sure what the problem is as you didn't give much details. I don't really see why having only zero-labels when you didn't specify any is a non-intended behavior. I'm closing this here as it should be discussed on the [forum](https://forums.fast.ai/). Please explain to us more in detail what your problem is.,sure problem give much really see specify behavior forum please explain u detail problem,issue,negative,positive,positive,positive,positive,positive
435190972,I thought about this PR a bit more (and also got very helpful feedback from @sgugger :slightly_smiling_face:) - I don't like my proposed way of fixing this. I provide further commentary in the [forum thread](https://forums.fast.ai/t/pr-1050-add-sorting-in-uniqueify/28908/5).,thought bit also got helpful feedback like way fixing provide commentary forum thread,issue,positive,neutral,neutral,neutral,neutral,neutral
435148536,"I am not familiar with the PR process, would love to know more how to keep my fork sync while not adding a lot of merge commit especially fastai library update very frequently.

A notebook showing how does it work:
https://github.com/noklam/log/blob/master/nbs/Open_mask_rle.ipynb

I try my best to build the example, advice are welcome. For the data only exist on my local computer, as there is no existing data in this format in the current fastai/data. I try to follow the lesson 3 notebook, no clue how can I build a cleaner method with something like ImageDataBunch.from_xxx for this custom dataset.

Sorry I notice that I should start a forum thread before creating this PR. I open a thread now, as I feel it still need to be polished a bit.
https://forums.fast.ai/t/segmentation-dataset-for-run-length-encoding/28967
",familiar process would love know keep fork sync lot merge commit especially library update frequently notebook showing work try best build example advice welcome data exist local computer data format current try follow lesson notebook clue build cleaner method something like custom sorry notice start forum thread open thread feel still need polished bit,issue,positive,positive,positive,positive,positive,positive
435115653,"I just had a case where max_workers=0 got `download_images` to work, where it wasn't working before (default settings). Haven't tested it thoroughly, but popped up just now (going through lesson2-download notebook).",case got work working default tested thoroughly going notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
435048015,"For a huge amount of data, you probably need to modify the existing code to save the processed tokens as they go instead of accumulating them in RAM. Closing this here as it should be discussed on the [forum](https://forums.fast.ai/).",huge amount data probably need modify code save go instead ram forum,issue,positive,positive,positive,positive,positive,positive
435042933,"I'm getting together some reproducible code, and data about the environments I have tested. Should have an update in a few days.",getting together reproducible code data tested update day,issue,negative,neutral,neutral,neutral,neutral,neutral
435001448,Will make the test so that it tries to convert any image you put in the test folder. the it easier to test conversion of any image for the users ,make test convert image put test folder easier test conversion image,issue,negative,neutral,neutral,neutral,neutral,neutral
434943269,"> > I am working on documentation within fastai_docs branch. Do you need to see them before accepting this PR?
> 
> It would be best to see the docs PR as well since that will show us the example usage you're suggesting.

I've created a pull request https://github.com/fastai/fastai_docs/pull/37
I've tried to keep it simple and informative. I would appreciate your comments on my doc changes, writing docs is not my strongest skill.",working documentation within branch need see would best see well since show u example usage suggesting pull request tried keep simple informative would appreciate doc writing skill,issue,positive,positive,positive,positive,positive,positive
434933200,"sure will have a look at how you build the test. which image formats are relevant rgb, 16bit grayscale ?  ?",sure look build test image relevant bit,issue,negative,positive,positive,positive,positive,positive
434929832,"> I am working on documentation within fastai_docs branch. Do you need to see them before accepting this PR?

It would be best to see the docs PR as well since that will show us the example usage you're suggesting.",working documentation within branch need see would best see well since show u example usage suggesting,issue,positive,positive,positive,positive,positive,positive
434929601,"Thanks - I think this seems like a useful thing to have. You've got quite a bit of duplicate code in there - could you please try to make this more concise? Also, see if you can make it a bit more consistent with our style guide: https://docs-dev.fast.ai/style.html . And add some docstrings (see other fastai modules for examples).

In a future PR perhaps you could also add docs for your class (fastai_docs repo)?",thanks think like useful thing got quite bit duplicate code could please try make concise also see make bit consistent style guide add see future perhaps could also add class,issue,positive,positive,positive,positive,positive,positive
434928809,"Thanks for the contribution! I'd been thinking that we'd use this algorithm for that purpose:

http://topepo.github.io/caret/pre-processing.html#zero--and-near-zero-variance-predictors

I've found it's pretty reliable. Have you compared these approaches?

(Note that it's generally a good idea to raise an idea in the forum first, so we can agree on an approach, before you jump in to coding. That way, you know you're working on something that's likely to fit with our plans!)",thanks contribution thinking use algorithm purpose found pretty reliable note generally good idea raise idea forum first agree approach jump way know working something likely fit,issue,positive,positive,positive,positive,positive,positive
434926828,Can you also please add a test for your new functionality? And please update your PR description (currently it's showing the template text).,also please add test new functionality please update description currently showing template text,issue,positive,positive,neutral,neutral,positive,positive
434926595,"I don't think there's anything wrong with unet training. It's working fine for us. If you have found a bug, please submit with a failing test, and check on the forum first. We can't accept PRs without tests.",think anything wrong training working fine u found bug please submit failing test check forum first ca accept without,issue,negative,positive,neutral,neutral,positive,positive
434903582,"I think overriding get_preds with a new argument `ordered=True` sounds like the best idea. Also, use the current `get_preds` method as base.",think new argument like best idea also use current method base,issue,positive,positive,neutral,neutral,positive,positive
434901124,"Ah, I see now. All the `DataBunch` take dataloaders, you have to use the `.create` method if you want to pass datasets.",ah see take use method want pas,issue,negative,neutral,neutral,neutral,neutral,neutral
434900771,It's not an issue per se: a lot of the modules in the library don't have test yet. This is something we are working on.,issue per se lot library test yet something working,issue,negative,neutral,neutral,neutral,neutral,neutral
434899879,The dice test seems a bit weird for a non-segmentation task. Ok for the error rate.,dice test bit weird task error rate,issue,negative,negative,negative,negative,negative,negative
434897520,"_Do trn_dataset[0]/val_dataset[0] return what is expected?_
Returns list of tuples containing token ids with a label=0.

_Same for x,y = next(iter(data.train_dl))?_
Returns `AttributeError: 'int' object has no attribute 'to'`  on
torch_core.py line 86:
`return b.to(device)`

_Lastly, what is you version of fastai?_
I've followed the installation guide of this repository. I believe it's the latest version.
```
conda install -c pytorch pytorch-nightly cuda80
conda install -c fastai torchvision-nightly
conda install -c fastai fastai
```",return list token next iter object attribute line return device version installation guide repository believe latest version install install install,issue,negative,positive,positive,positive,positive,positive
434862068,"> Thanks for your contribution. Please use the documentation style of fastai (as discussed on the forum). Also note that we'd like a notebook with an example of use of your new functionality.

I've added an issue for tests: https://github.com/fastai/fastai/issues/1046 i can work on this as well.
I am working on documentation within fastai_docs branch. Do you need to see them before accepting this PR?",thanks contribution please use documentation style forum also note like notebook example use new functionality added issue work well working documentation within branch need see,issue,positive,positive,positive,positive,positive,positive
434825245,"Sure. I couldn't find guidelines to how we're supposed to write test, is there a link that explains how it should look like? Concerning the fix, should i add a get_preds_ordered method to RNNLearner.classifier, or override the get_preds method for RNNLearner, and if I override it, should i make ""ordered"" a parameter of the get_preds or just make it return ordered prediction in all cases?",sure could find supposed write test link look like concerning fix add method override method override make ordered parameter make return ordered prediction,issue,positive,positive,positive,positive,positive,positive
434820156,issue should probably be considered resolved @lesscomfortable,issue probably considered resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
434803493,"Thanks for flagging this @discdiver !

It looks like this error is a more general issue in Jupyter that gets triggered by the existence of a custom widget.

Labs offers a solution here: https://github.com/jupyterlab/jupyterlab/issues/4855
More info: https://github.com/jupyterlab/jupyterlab/issues/4127 https://github.com/jupyter-widgets/ipywidgets/issues/1981",thanks flagging like error general issue triggered existence custom solution,issue,positive,positive,positive,positive,positive,positive
434789366,Great idea! Anyone interested in submitting a test and fix as a PR?,great idea anyone interested test fix,issue,positive,positive,positive,positive,positive,positive
434789033,Can you try with max_workers=0 and show what error you get?,try show error get,issue,negative,neutral,neutral,neutral,neutral,neutral
434788707,"using `cls.create(*datasets, path, **kwargs)` breaks the subclassing in `TextLMDataBunch` or `TextClasDataBunch`.
Not too sure why we would want to create a `TextDataBunch` and not one of the above, but we never know.",path sure would want create one never know,issue,positive,positive,positive,positive,positive,positive
434788679,"Thanks for the analysis of this! Any chance you could provide a PR, including a couple of tests of a variety of formats (you can either add some small images to the data/ folder, or create them in the test)?",thanks analysis chance could provide couple variety either add small folder create test,issue,positive,negative,neutral,neutral,negative,negative
434787719,That's true! Would you like to do a PR to fix that?,true would like fix,issue,positive,positive,positive,positive,positive,positive
434787116,Can you please update your notebook to show how to actually use these to create a DataBunch? I'm guessing you'll need to create or modify a dataset class to do so.,please update notebook show actually use create guessing need create modify class,issue,positive,neutral,neutral,neutral,neutral,neutral
434786490,"Actually you should be able to do it without a for loop using something like `torch.all()`.

Please either name your tests with a full name of exactly what's being tested, or add a 2nd string argument to have your assertions explain exactly what they're testing.",actually able without loop something like please either name full name exactly tested add string argument explain exactly testing,issue,negative,positive,positive,positive,positive,positive
434785507,"Please explain what bug you're fixing, and include the tests requested in the PR template.",please explain bug fixing include template,issue,negative,neutral,neutral,neutral,neutral,neutral
434785183,"Oh also, when contributing a failing test, please mark them with the pytest skip flag so they don't trigger the CI.",oh also failing test please mark skip flag trigger,issue,negative,neutral,neutral,neutral,neutral,neutral
434784947,"We can't have tests that download all of resnet pretrained weights every time - so please use pretrained=False.

Also, a test needs to run in no more than a second or so on CPU, except for one integration fixture per application.

So this test probably needs to be updated to use a dummy dataset that's created of the right size to trigger the error, and a network that does the same thing.

Let me know if you have any questions.",ca every time please use also test need run second except one integration fixture per application test probably need use dummy right size trigger error network thing let know,issue,negative,positive,positive,positive,positive,positive
434782990,"I don't think we needed a separate function for this (or I am missing something)

just changing this `cls.create(datasets, path, **kwargs)` to `cls.create(*datasets, path, **kwargs)` in the original function should be it, right?
(and looks like the former exists at many places text/data.py)

> Now some of the text examples and documentation are starting to work for
me.

@matiu2 : I ll put some tests for this - can you post an example what didn't work for you, so that we cover whatever you saw",think separate function missing something path path original function right like former many text documentation starting work put post example work cover whatever saw,issue,negative,positive,positive,positive,positive,positive
434736705,"have done some more optimisation. The following delivers the same function but is 20% faster because the actual conversion is postpone until all dimension are in place:

#The proposed method - fastest
def allPil2tensor2(image:NPImage)->TensorImage:
    arr = np.asarray(image)
    if arr.ndim==2 : arr = np.expand_dims(arr,2) 
    #transpose width, height to height,width
    arr = np.transpose(arr, (1,0,2))
    #move channels to the first position
    arr = np.transpose(arr, (2, 1, 0))
    return torch.from_numpy(arr)",done following function faster actual conversion postpone dimension place method image image transpose width height height width move first position return,issue,negative,positive,neutral,neutral,positive,positive
434693833,"Okay, thanks. I've seen the pre-trained models being downloaded to, for example, `/root/.torch/models/resnet34-333f7ec4.pt` rather than this `/.fastai/models` though?",thanks seen example rather though,issue,negative,positive,positive,positive,positive,positive
434693223,"Thanks for the quick response @sgugger . I accidentally deleted size =224 when I deleted   tfms=imagenet_norm because that was throwing an error.
",thanks quick response accidentally size throwing error,issue,negative,positive,positive,positive,positive,positive
434690769,You have to specify a size in your method creating data.,specify size method data,issue,negative,neutral,neutral,neutral,neutral,neutral
434690438,"That is strange. Have you tested your datasets and your data object? Do trn_dataset[0]/val_dataset[0] return what is expected? Same for x,y = next(iter(data.train_dl))?
Lastly, what is you version of fastai?",strange tested data object return next iter lastly version,issue,negative,negative,neutral,neutral,negative,negative
434689376,"Hey, thanks a lot for your PR. Can you share a notebook with an example of use of this new functionality? Also some unit tests would be most appreciated. Lastly, don't forget to type-annotate the return of your functions.",hey thanks lot share notebook example use new functionality also unit would lastly forget return,issue,negative,positive,positive,positive,positive,positive
434687734,Thanks for your contribution. Please use the documentation style of fastai (as discussed on the forum). Also note that we'd like a notebook with an example of use of your new functionality.,thanks contribution please use documentation style forum also note like notebook example use new functionality,issue,positive,positive,positive,positive,positive,positive
434685805,Thanks! Does it need to be resnet34? resnet18 would be a little faster for our tests.,thanks need would little faster,issue,negative,positive,neutral,neutral,positive,positive
434684911,"Thanks a lot. I'm closing this here though, as this tutorial would be best on https://github.com/fastai/course-v3 (in the nbs directory). Sorry if we were unclear on the forum.",thanks lot though tutorial would best directory sorry unclear forum,issue,positive,positive,positive,positive,positive,positive
434626343,excellent idea. I will se if i can optimize the code further,excellent idea se optimize code,issue,positive,positive,positive,positive,positive,positive
434543745,Same issue on mac. Same manual fix worked.,issue mac manual fix worked,issue,negative,neutral,neutral,neutral,neutral,neutral
434537949,It also fails on the azure test integration (as it should),also azure test integration,issue,negative,neutral,neutral,neutral,neutral,neutral
434529668,"Also 
```
(fastaiv3dev) b1@b1-desktop ~/fastaiv3/fastai/tests $ 
python
Python 3.6.6 |Anaconda, Inc.| (default, Oct  9 2018, 12:34:16) 
[GCC 7.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> import fastai
>>> fastai.__version__
'1.0.19.dev0'
```",also python python default type help copyright license information import,issue,negative,neutral,neutral,neutral,neutral,neutral
434484293,"Hi @sgugger, thanks for your feedback. I agree with all your points and consequentially adapted the code. Let me know if further changes are needed. Cheers",hi thanks feedback agree consequentially code let know,issue,positive,positive,positive,positive,positive,positive
434475818,"Well I tried to work out a solution myself, would have never guessed that https://github.com/fastai/fastai/commit/7986f5a81a60f60af017dfc5c0c1e729e67eaf4a would be the solution.",well tried work solution would never would solution,issue,positive,neutral,neutral,neutral,neutral,neutral
434322503,Closing this as a lot of tests have been added in another PR and files were changed. Please make a new one with appropriate changes if some of the tests were missing. Thanks!,lot added another please make new one appropriate missing thanks,issue,negative,positive,positive,positive,positive,positive
434317387,"Only a problem on release tagged `1.0.16.dev`, not an issue on `1.0.15`.

NB: Looks like the tests do not catch this error.",problem release tagged dev issue like catch error,issue,negative,neutral,neutral,neutral,neutral,neutral
434311459,"I think this is explained in the corresponding course video. If you have any other questions after watching it, you should ask them on the [forum](https://forums.fast.ai/)",think corresponding course video watching ask forum,issue,negative,neutral,neutral,neutral,neutral,neutral
434168161,"Thats actually a terrible typo from 1 of my changes :/
updated tests 
https://github.com/fastai/fastai/pull/1013",thats actually terrible typo,issue,negative,negative,negative,negative,negative,negative
434035504,"I don't have that issue when running the test locally. I think it's a random issue and you were out of luck, but the thresholds probably need to be a bit more loose. Will update.",issue running test locally think random issue luck probably need bit loose update,issue,negative,negative,negative,negative,negative,negative
434034739,Should be fixed in the latest version of master. Please reopen if it's not the case.,fixed latest version master please reopen case,issue,negative,positive,positive,positive,positive,positive
433986431,"> I've added a test folder in mnist_tiny with 20 new images. Could you amend your PR to use that real data?

👍 updating ",added test folder new could amend use real data,issue,negative,positive,positive,positive,positive,positive
433970757,"@StatisticDean 
Thx for solving this!
Just had the same issue:
This should be working code:

    sort_sample_mapping = {}
    for count, i in enumerate(rnnlearner.data.valid_dl.sampler):
        sort_sample_mapping[i] = count

    tmp_pred = rnnlearner.get_preds()

    y_predicted_unsorted = []
    y_gt_unsorted = []
    for idx in range(0, len(tmp_pred[0])):
        pred = [x.tolist() for x in list(tmp_pred[0][idx])]
        max_val = max(pred)
        y_true_i = tmp_pred[1].tolist()[idx]
        y_pred_i = pred.index(max_val)
        y_predicted_unsorted.append(y_pred_i)
        y_gt_unsorted.append(y_true_i)

    y_predicted_sorted = []
    y_gt_sorted = []

    for i in range(0, len(y_predicted_unsorted)):
        y_predicted_sorted.append(y_predicted_unsorted[sort_sample_mapping[i]])
        y_gt_sorted.append(y_gt_unsorted[sort_sample_mapping[i]])",issue working code count enumerate count range list range,issue,negative,neutral,neutral,neutral,neutral,neutral
433927187,"I agree it's should belong to the Image Class instead, I have updated my PR. I have no experience amending PR before, please let me know if I did something wrong. Thx!",agree belong image class instead experience please let know something wrong,issue,negative,negative,negative,negative,negative,negative
433917579,"Be careful that in fastai, as in pytorch, the convention is to have the batch size in the second dimension and the sequence in the first. Your input should be transposed, I think that's what is causing the issue.
The [forum](https://forums.fast.ai/) is a better place to discuss this, so I'm closing the issue, but you're welcome to open a topic there.",careful convention batch size second dimension sequence first input think causing issue forum better place discus issue welcome open topic,issue,positive,positive,positive,positive,positive,positive
433915748,Thanks a lot for your contribution. Could you adjust it to fit the usual fastai style? That means removing the empty lines. Then I have a few comments/suggestions of thins to add if you can that I'll put directly in the code.,thanks lot contribution could adjust fit usual style removing empty add put directly code,issue,positive,positive,neutral,neutral,positive,positive
433914789,Thanks for your contribution. I've added a few comments and suggestions of things to add if you can.,thanks contribution added add,issue,negative,positive,positive,positive,positive,positive
433843850,"I had the same issue. If you want your data in the right order, you just need to get the sampler. Fortunately, it is saved during the creation of your TextClasDataBunch. If data_clas is the name of your TextClasDataBunch, 

    data_class.valid_dl.sampler 

gives you the sampler for the validation set (replace valid_dl by test_dl if you want sampler for the test). If you want the sampler in the form of a list, do 

    sampler = [i for i in data_class.valid_dl.sampler]

This will give you the order in which your predictions are. The i-th element of sampler is the position of the i-th row of predictions in the original order.",issue want data right order need get sampler fortunately saved creation name sampler validation set replace want sampler test want sampler form list sampler give order element sampler position row original order,issue,positive,positive,positive,positive,positive,positive
433825508,"```
m = simple_cnn([3,6,6],bn=True)
m.half().forward(torch.ones([1,3,3,3]).half())
```
when run on cpu errors with: 
```RuntimeError: thnn_conv2d_forward is not implemented for type torch.HalfTensor```

After looking around fp16 does not seem to be supported on CPUs, at least on intel, I did not bother checking AMD.  

I will probably be working on this in the study group tomorrow. ",run type looking around seem least bother probably working study group tomorrow,issue,negative,negative,negative,negative,negative,negative
433810842,"@sgugger Got it.

I was thinking can we throw an exception from 

https://github.com/fastai/fastai/blob/0d8fcf88b51136d33c14149b0697935d75479f9f/fastai/basic_data.py#L106

```
def holdout(self, is_test:bool=False)->DeviceDataLoader:
      ""Returns correct holdout `Dataset` for test vs validation (`is_test`).""
      return self.test_dl if is_test else self.valid_dl
```

if test_dl is None

I can send PR if this is fine.",got thinking throw exception holdout self correct holdout test validation return else none send fine,issue,negative,positive,positive,positive,positive,positive
433779332,"For fastai 0.7.x installation see [here](http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652) 

For fastai 1.0.x - in general fastai 1.x can't be used on windows until pytorch-1. is released on windows, but if you build your own then you can. Read posts here: https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111/84

Good luck, @chengerr.",installation see general ca used build read good luck,issue,positive,positive,positive,positive,positive,positive
433760386,"@anishpdalal : I think these tests (apart from `test_from_name_re`) do belong in the `test_vision.py` file -- we didn't have a `test_vision_data.py` as we didn't have any particular **data_loading** tests for vision
(infact I was working on creating some currently on a `test_vision_data.py` file)

I would suggest moving `test_from_name_re` to a new `test_vision_data.py` file - and have rest in the original `test_vision.py` file
(`test_vision.py` is analogous to `test_text.py`)",think apart belong file particular vision working currently file would suggest moving new file rest original file analogous,issue,positive,positive,positive,positive,positive,positive
433758178,Thanks for your contribution! I think it would be best if it was a method from the Image class: `Image.save(fname)`. Can you amend your PR to do this?,thanks contribution think would best method image class amend,issue,positive,positive,positive,positive,positive,positive
433720617,"Better still would be to use the `simple_cnn` function.

Also note that we can't rely on cuda in tests, since they run on a CI server without a GPU. Does this test run OK if we use cpu() instead? I suspect it might not, since CPU doesn't support half precision.

If that's the case, you'll probably need to check if cuda is available and skip otherwise:

https://docs.pytest.org/en/latest/skipping.html#id1
",better still would use function also note ca rely since run server without test run use instead suspect might since support half precision case probably need check available skip otherwise,issue,positive,positive,positive,positive,positive,positive
433707801,"Ah, I didn't know that new() command. Much better now. Thank you",ah know new command much better thank,issue,positive,positive,positive,positive,positive,positive
433706239,"You can be shorter with the magic command new:
```
x = next(m.parameters()).new(1,ch_in,*size)
``` 
will create a tensor on the same device as the m.parameters()",shorter magic command new next size create tensor device,issue,negative,positive,positive,positive,positive,positive
433705950,"Thanks @sgugger , you're right. I have fixed it in the new commit. pls check if it is ok ",thanks right fixed new commit check,issue,positive,positive,positive,positive,positive,positive
433701101,That's not the right answer either since it's now going to bug every time the model is not on the GPU ;). You have to put x to the same device as the model.,right answer either since going bug every time model put device model,issue,negative,positive,positive,positive,positive,positive
433701048,"Great idea! Just two little things:
1. can you create this in a new file test_callback_fp16 ? Even if the method you're testing is in torch_core, it would be better there.
2. can you use the function `conv_bn_relu` to create your model? It's in the layers module.",great idea two little create new file even method testing would better use function create model module,issue,positive,positive,positive,positive,positive,positive
433672604,"It looks like the lack of an error is causing this; as if `ProcessPoolExecutor` needs something to hit it to wake up.

I made another notebook gist: [nbviewer link](https://nbviewer.jupyter.org/gist/WNoxchi/952a85be92619f3358341ca74f153a12) to try and document & reproduce this from start to end.

What happens is I run `download_image` with `overwrite=True`, and a folder (not filename) passed as `dest`. This throws a directory error which I catch. _Then_ `ProcessPoolExecutor` does its job. Though not in the notebook, I tested that adding this try/except to the source code function works.

What I haven't tested is more of what's going on with `download_url`. I'll check it out more. It confused me for a bit when I was trying to replicate the bug/fix by returning NoneType to an assignment... but `download_image` calls it with `overwrite=True` so that shouldn't be it.

I also noticed after importing * from fastai and fastai.vision,`download_image` and `as_completed` (from concurrent.futures) are not available, and have to be imported to be used in the notebook -- I don't know if that has any effect.

---

Update: every run is a `BrokenProcessPool`:

In fastai.vision.data.download_images, printing `as_completed(futures)`:
<img width=""384"" alt=""screen shot 2018-10-27 at 23 36 20"" src=""https://user-images.githubusercontent.com/16154304/47611713-1d0e3580-da41-11e8-90cf-1fbc2ea222e3.png"">
<img width=""411"" alt=""screen shot 2018-10-27 at 23 35 08"" src=""https://user-images.githubusercontent.com/16154304/47611701-f2bc7800-da40-11e8-9359-bc1e5cfd2771.png"">

---

Update 2: `download_images` will also start working after a successful call to `download_image`. So instead of a try/except to catch a directory error, you can also attempt to download the first url on its own, then call `ProcessPoolExecutor`.
",like lack error causing need something hit wake made another notebook gist link try document reproduce start end run folder directory error catch job though notebook tested source code function work tested going check confused bit trying replicate assignment also available used notebook know effect update every run printing screen shot screen shot update also start working successful call instead catch directory error also attempt first call,issue,negative,positive,positive,positive,positive,positive
433656088,Rebased on master and started to squash commits out of habit - hoping changing history did not mess anything up with the workflow on github.,master squash habit history mess anything,issue,negative,negative,negative,negative,negative,negative
433646630,This is an issue that we will address in the future (when the course turns toward NLP probably).,issue address future course turn toward probably,issue,negative,neutral,neutral,neutral,neutral,neutral
433637344,"@navjotts If there is anything else you need besides the test I submitted, lmk.  I'm actively working on some multilabel datasets at work so glad to help.",anything else need besides test actively working work glad help,issue,positive,positive,positive,positive,positive,positive
433636096,"@jph00 I am not familiar with the codebase yet. I thought it's easy for someone who knows about it do that change.

And I'm new to python.",familiar yet thought easy someone change new python,issue,negative,positive,positive,positive,positive,positive
433634198,I assumed you were going to do a PR so we can move the discussion there. ,assumed going move discussion,issue,negative,neutral,neutral,neutral,neutral,neutral
433628721,"@jph00 Why did you close this issue?
Not exactly sure how we manage issues here, but I think the issue should be opened until the issue resolves.

BTW: Here's the pseudo code which works for almost all the datasets:

```python
import os
import subprocess

def exec(commands, cwd=None, show_output=False):
  FNULL = open(os.devnull, 'w')
  if show_output == True:
    cp = subprocess.run(commands, cwd=cwd, universal_newlines=True)
  else:
    cp = subprocess.run(commands, cwd=cwd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, universal_newlines=True)
  
  if cp.returncode != 0:
    raise Exception(cp.stdout)

def get_data(name, url):
  homedir = os.getenv('HOME')
  datadir = f'{homedir}/userdata'
  tmpdir = f'/tmp/{name}'
  tarfile = f'{tmpdir}/data.tgz'
  finaldir = f'{datadir}/{name}'

  if os.path.exists(finaldir):
    return Path(finaldir)

  exec(['rm', '-rf', tmpdir])
  exec(['mkdir', '-p', tmpdir])
  exec(['curl', '-L', url, '--output', tarfile], show_output=True)
  exec(['tar', 'xzf', tarfile], cwd=tmpdir)
  exec(['rm', tarfile])

  exec(['rm', '-rf', finaldir])
  exec(['mkdir', '-p', datadir])
  exec(['mv', tmpdir, datadir])
  
  return Path(finaldir)
```",close issue exactly sure manage think issue issue pseudo code work almost python import o import open true else raise exception name name name return path output return path,issue,positive,positive,positive,positive,positive,positive
433624545,Well that's odd! Not sure what's going on there. Try using a debugger and removing the use of the process pool to if you can find the actual error that's causing this.,well odd sure going try removing use process pool find actual error causing,issue,negative,positive,positive,positive,positive,positive
433624018,"> @sgugger but follow redirects could be something simple to add.

Would you be able to provide a PR with this functionality? That would be great!",follow could something simple add would able provide functionality would great,issue,positive,positive,positive,positive,positive,positive
433620990,"> I'm not sure we can cover all cases of downloads

Oh yes. I agree.

@sgugger but follow redirects could be something simple to add. 

I hope `untar_data` has `fname` and `dest`. So we can use them to save the file and extract without looking at the URL.",sure cover oh yes agree follow could something simple add hope use save file extract without looking,issue,positive,positive,positive,positive,positive,positive
433619901,"Closing this as @navjotts has added a lot of tests. If some of yours are missing, you should make a new PR with them so that we can merge easily, thanks!",added lot missing make new merge easily thanks,issue,negative,positive,neutral,neutral,positive,positive
433617685,I'm not sure we can cover all cases of downloads. `untar_data` is primarily intended for the fastai datasets and its behavior elsewhere is untested. Can you use `download_url` to download your dataset?,sure cover primarily intended behavior elsewhere untested use,issue,negative,positive,positive,positive,positive,positive
433575072,"updated @sgugger : so a single test now (1 each for from_csv and from_df) - tests for both single and multilabel 
(also made the helper functions generic for a given `n_labels`)",single test single also made helper generic given,issue,negative,negative,neutral,neutral,negative,negative
433525913,"because the bug/issue is in the learner part @sgugger (not the DataBunch/Dataset creations)
(i m working on fixing that on a separate branch)",learner part working fixing separate branch,issue,negative,neutral,neutral,neutral,neutral,neutral
433504190,"@sgugger : done 
Have added support for `multilabel` tests 
(moving towards the area around which there is an issue and a PR being discussed)
https://github.com/fastai/fastai/issues/946
https://github.com/fastai/fastai/pull/974
https://forums.fast.ai/t/fastai-rnnlearner-classifier-wrong-size-of-head-of-classifier/27960",done added support moving towards area around issue,issue,negative,neutral,neutral,neutral,neutral,neutral
433454106,Just letting you know that I've tried out the update in a Colab notebook and it looks great. Thanks for the new feature! 🍻 ,know tried update notebook great thanks new feature,issue,positive,positive,positive,positive,positive,positive
433382280,"Thanks @sgugger , I add the last line checking for the others columns' types. This is the first time I make a test so if there are something not ok, please tell me. Do you think in this case I need to add more types (with string for example) or it is enough ?",thanks add last line first time make test something please tell think case need add string example enough,issue,positive,positive,positive,positive,positive,positive
433379741,"Sorry, I misread. Again please [use the forum](https://forums.fast.ai/) where this kind of error has also been discussed. Can't help you without the code as it likely comes from a bad index error of a tensor on the GPU. While posting on the forum, please try to have the same thing run on the CPU as it'll return a clearer error message.",sorry misread please use forum kind error also ca help without code likely come bad index error tensor posting forum please try thing run return clearer error message,issue,negative,negative,negative,negative,negative,negative
433379180,Thanks! Can you add a last line to check 'col3' is still numeric?,thanks add last line check still,issue,negative,positive,neutral,neutral,positive,positive
433378488,"I don't think that this is a memory issue since PyTorch throws a different runtime error for that and I have 16GB of GPU memory...(but, I tried anyways lowering the bs and got the same error obviously). I understand that this is not an issue strictly due to fastai, but it is somehow related and I never encountered this with PyTorch before.",think memory issue since different error memory tried anyways lowering got error obviously understand issue strictly due somehow related never,issue,negative,negative,neutral,neutral,negative,negative
433238013,"@ohmeow : noting that this test should probably be added to `test_text_train.py`, instead of a new file
(I think that was the purpose of `test_xxx_train` files - training/learning tests)

For reference: there is a `RNNLearner.language_model` test in `test_text_train.py`",test probably added instead new file think purpose reference test,issue,negative,positive,positive,positive,positive,positive
433236315,"👍 

Yea, something s up with 1 of the deployment machines I think (noticed the same happened on all past few commits from everyone) - all tests seem to be passing, but the build is failing

<I verified: not the same machine each time (not sure whats up)>",yea something deployment think past everyone seem passing build failing machine time sure whats,issue,negative,positive,positive,positive,positive,positive
433231632,"It looks good (test failed because of bad luck on something else, nothing you did). Just tell me when you're done adding tests!",good test bad luck something else nothing tell done,issue,negative,positive,neutral,neutral,positive,positive
433061627,"Please search the [forum](https://forums.fast.ai/) before posting this issue. You have to lower the batch size to fit the model in your GPU, this is not due to the library.",please search forum posting issue lower batch size fit model due library,issue,negative,positive,positive,positive,positive,positive
433049447,"Following your recommendation, i made a post on the forums and a notebook to explain my issue more precisely : https://forums.fast.ai/t/fastai-rnnlearner-classifier-wrong-size-of-head-of-classifier/27960",following recommendation made post notebook explain issue precisely,issue,negative,positive,positive,positive,positive,positive
432905695,"Could you show code and timings for keras and fastai for this example please? I haven't seen any documented examples of pytorch being slower than keras, so I'm sure the pytorch team would be very interested to see if that's the case.

Also, when providing timings, also mention what BLAS you're using for each library, what keras backend you're using, and what CPU you have. On CPU the main source of speed differences tends to be from the BLAS lib you've linked with.

There may also be a problem with num OPENMP threads being set incorrectly leading to only one CPU getting used.

Anyway - certainly interested in digging in to this question with you! :)",could show code example please seen sure team would interested see case also providing also mention blas library main source speed blas linked may also problem set incorrectly leading one getting used anyway certainly interested digging question,issue,positive,positive,positive,positive,positive,positive
432904905,"This is a very useful issue to fix, but we need tests, an example we can experiment with (preferably as a notebook using real data), and to have a broad discussion about possible approaches on the forum.

https://github.com/fastai/fastai/blob/master/.github/pull_request_template.md

If you have time to do this, please do at-mention me in a forum thread so I don't miss it!",useful issue fix need example experiment preferably notebook real data broad discussion possible forum time please forum thread miss,issue,positive,positive,positive,positive,positive,positive
432904415,"Unfortunately there's not enough here for us to be able to accept this PR. I added this template today that might help explain what we need:

https://github.com/fastai/fastai/blob/master/.github/pull_request_template.md

If you can provide a notebook demonstrating the issue you're facing, using real data, that would be really helpful for ensuring a good discussion on the forum, so we can all agree on a good solution.",unfortunately enough u able accept added template today might help explain need provide notebook issue facing real data would really helpful good discussion forum agree good solution,issue,positive,positive,positive,positive,positive,positive
432904020,"I'm going to close this PR since it's not desired behaviour. Note also that a PR that changes such a low level function also needs to contain tests of everything that the change might impact (which currently would be a *lot* of work!) So probably better to wait for better test coverage until changing something with such wide impact.

If there is something which has a bug or problematic behaviour, we'd welcome a PR that includes a failing test and a minimal fix for it (including tests for any impacted code).",going close since desired behaviour note also low level function also need contain everything change might impact currently would lot work probably better wait better test coverage something wide impact something bug problematic behaviour welcome failing test minimal fix impacted code,issue,negative,positive,positive,positive,positive,positive
432892871,"Just bumping this because I think it's pretty important. @ranihorev's proposed changes broke a lot of the language model, so there should be a better way.

@sebastianruder suggestion of the short term fix of using _difference to the average document length in the training data_ is difficult too, because that isn't actually recorded anywhere at the moment. 

I follow the `pack_padded_sequence` [post](https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e) mentioned above up to trick 3, but I need to think about that some more. 

What is the approach in FastAI 1.0 here? Is it fixed somehow?",bumping think pretty important broke lot language model better way suggestion short term fix average document length training difficult actually anywhere moment follow post trick need think approach fixed somehow,issue,negative,positive,neutral,neutral,positive,positive
432838673,Added an argument `stop_div` in `lr_find()`. Put it to False and the function won't abort. ,added argument put false function wo abort,issue,negative,negative,negative,negative,negative,negative
432812015,"The conda is not the problem, the problem is that some package that fastai relies on has a pinned (forced) dependency that prevents your setup from installing it - i.e. a dependency conflict. conda is not user friendly about it. Instead of telling you that so and so prevent it from installing the desired version, it picks the lowest version which avoids the conflict.

@wAuner, please let's move this discussion [here](http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111).  The 1.0.12 should have fixed that problem, but clearly it didn't. So please post the summary of the issue and the output of `python -c ""import fastai; fastai.show_install()""` in that thread and we will take it from there.

update: please see: https://forums.fast.ai/t/fastai-v1-install-issues-thread/24111/153",problem problem package pinned forced dependency setup dependency conflict user friendly instead telling prevent desired version version conflict wauner please let move discussion fixed problem clearly please post summary issue output python import thread take update please see,issue,negative,positive,neutral,neutral,positive,positive
432785731,"well that's the point. when you install the package via conda you don't get the most recent version. I installed today and got 1.0.6. When I try to update with `conda update -c fastai fastai`, I always get it is already up to date. Although it shows that there are newer version available on conda.

```
conda search -c fastai fastai
Loading channels: done
# Name                  Version           Build  Channel
fastai                    1.0.2            py_1  fastai
fastai                    1.0.3            py_1  fastai
fastai                    1.0.4            py_1  fastai
fastai                    1.0.5            py_1  fastai
fastai                    1.0.6            py_1  fastai
fastai                    1.0.7            py_1  fastai
fastai                    1.0.9            py_1  fastai
fastai                   1.0.10            py_1  fastai
fastai                   1.0.11            py_1  fastai
fastai                   1.0.12            py_1  fastai
```

I guess there is something wrong with the upload to conda?",well point install package via get recent version today got try update update always get already date although version available search loading done name version build channel guess something wrong,issue,negative,negative,neutral,neutral,negative,negative
432766673,"Unless I'm missing something, wouldn't this work ...

```
n_class = ( len(ds.classes) if (len(lbl) == 1) else len(lbl) ) 
```

For multiclass, there is a SINGLE label (column in our dataframe) ... whereas for multilabel, there will be  MULTIPLE labels (columns in your dataframe).",unless missing something would work else single label column whereas multiple,issue,negative,negative,neutral,neutral,negative,negative
432765495,"You should update your conda since the last version is 1.0.12, then 
`conda update fastai`.
There are more instructions [here](http://course-v3.fast.ai/) depending on your platform.",update since last version update depending platform,issue,negative,neutral,neutral,neutral,neutral,neutral
432762616,so what's the best way to get the most up to date version? I installed today via conda and got version 1.0.6. Just cloning the repo and then link to it? or does that limit some functionality?,best way get date version today via got version link limit functionality,issue,positive,positive,positive,positive,positive,positive
432752579,"This is intentional: the last activation of the model Jeremy implements there is softmax, not relu then softmax.",intentional last activation model,issue,negative,neutral,neutral,neutral,neutral,neutral
432740021,I think the right way to address that is to add a parameter that prevents that early stopping. Will code this sometimes today.,think right way address add parameter early stopping code sometimes today,issue,negative,positive,positive,positive,positive,positive
432719429,"You don't have the latest version of fastai, this is why you see a different behavior.",latest version see different behavior,issue,negative,positive,positive,positive,positive,positive
432689435,"This is certainly a problem worth solving! But I don't think this is the right solution - it gives an incorrect measure of accuracy. Let's move this discussion to the forum - can you open a thread at https://forums.fast.ai/c/fastai-users/fastai-dev . Generally it's best to discuss changes to functionality there first BTW, so we can all agree on an approach. Also, please include a test in your PRs that fail without your code, and pass with it, as well as a test of a case that already worked without your code (and still works with it).",certainly problem worth think right solution incorrect measure accuracy let move discussion forum open thread generally best discus functionality first agree approach also please include test fail without code pas well test case already worked without code still work,issue,positive,positive,positive,positive,positive,positive
432681621,"Maybe the ""good"" solution to this would be to change the code of RNNLearner.classifier to be able to accept array of label (Which is the kind of label you get from a TextClasDataBunch.from_id_files).",maybe good solution would change code able accept array label kind label get,issue,positive,positive,positive,positive,positive,positive
432649374,"This situation can occur for multilabel datasets with a large number of unbalanced labels and/or with a heavy tail. A real example is [deepfashion](http://mmlab.ie.cuhk.edu.hk/projects/DeepFashion/AttributePrediction.html) dataset's attributes data. 

When passing a multilabel df to `ImageDataBunch.from_df`, `ImageMultiDataset.from_folder` will `random_split` the examples, and some infrequent labels may end up only in the validation set. (of course, some may be only in the training set.)

Typically we use a smaller sample of the data to develop the model before running it on all the data. The sampling can make this situation more likely to occur. 
",situation occur large number unbalanced heavy tail real example data passing infrequent may end validation set course may training set typically use smaller sample data develop model running data sampling make situation likely occur,issue,negative,positive,neutral,neutral,positive,positive
432579132,"I have fastai installed via PyPi and I have the same problem:

fastai                          1.0.12
torch                           0.4.1     
torchvision                  0.2.1     
torchvision-nightly      0.2.1

also I had 1.013dev install before, also didn't work.

@dwbressler so I guess you could reopen this issue?",via problem torch also install also work guess could reopen issue,issue,negative,neutral,neutral,neutral,neutral,neutral
432493650,This works but I'm wondering in what situation you'd have a label in your validation set that wasn't in your training set.,work wondering situation label validation set training set,issue,negative,neutral,neutral,neutral,neutral,neutral
432474668,Thanks for the quick response. Additional information: the MemoryError happened when pickling the arrays. I'm giving HDF5 a try instead.,thanks quick response additional information giving try instead,issue,positive,positive,positive,positive,positive,positive
432464756,"@ohmeow : got it, thanks (my earlier post went at the same time as yours)",got thanks post went time,issue,negative,positive,positive,positive,positive,positive
432463742,I already submitted the PR after posting the issue ... the one that is under review at the moment.  I'm glad to follow-up on this given some direction about how to submit such unit tests.,already posting issue one review moment glad given direction submit unit,issue,negative,positive,positive,positive,positive,positive
432463357,"Adding ndarray to `is_listy` definitely breaks this function
```
def tensor(x:Any)->Tensor:
    ""Like `torch.as_tensor`, but handle lists too""
    return torch.tensor(x) if is_listy(x) else as_tensor(x)
```
(which is the cause of the failing test)

yea, I don't think `is_listy` should be changed - its behaving as expected (and is used heavily across the code base in its current definition)

@ohmeow : best would be to detail out the steps of the issue/bug",definitely function tensor tensor like handle return else cause failing test yea think used heavily across code base current definition best would detail,issue,positive,neutral,neutral,neutral,neutral,neutral
432463312,"@jph00 This is my fear as well.  This utility function is probably used throughout the codebase and even though the notebooks I'm testing against work, it may break something else.

To be honest, I'd rather the API be updated to require the developer to be explicit about the number of labels they are using rather than attempting to infer it with methods like ""is_listy()"".  I find the latter approach to be fragile, problematic, and generally difficult to refactor going forward.  I kinda feel like the code is trying to do too much here.

In this case, if instead of inferring the final linear layer's activations that was made an argument to `RNNLearnder.classifier` in the form of something like `n_out`, the problem would be no more.

@navjotts ... here are the steps:
```
data_clas = TextClasDataBunch.from_df(Path(CLS_PATH), train_df, valid_df, tokenizer=tokenizer, vocab=vocab,  txt_cols=corpus_cols, label_cols=LABELS_SENT[1:], bs=bsz,  clear_cache=True)

print(data_clas.train_ds.labels.shape, data_clas.valid_ds.labels.shape)
# (13692, 8) (1522, 8)

learn = RNNLearner.classifier(data_clas, drop_mult=0.9, bptt=bptt, emb_sz=em_sz, nh=nh, nl=nl,
                             lin_ftrs=[50], ps=[0.1],
                             alpha=2., beta=1.)
learn.clip = 25.
learn.metrics = [opt_th, fscore, multilbl_accuracy]
learn.model_dir = 'models'
learn.callback_fns.append(RocAucEvaluation)
learn.load_encoder(f'{lm_pre}lm_enc')
learn.fit_one_cycle(1, 1e-2)
```",fear well utility function probably used throughout even though testing work may break something else honest rather require developer explicit number rather infer like find latter approach fragile problematic generally difficult going forward feel like code trying much case instead final linear layer made argument form something like problem would path print learn,issue,negative,positive,neutral,neutral,positive,positive
432458251,Yea I take the iterable suggestion back (even dicts are iterable) - and we are specifically looking for `listy` as the function name suggests ,yea take iterable suggestion back even iterable specifically looking function name,issue,negative,neutral,neutral,neutral,neutral,neutral
432456609,"Thanks for bringing this to our attention. How about this for a deal then: you submit a PR of a failing test (marked with the pytest 'skip' flag) that shows an example of the failure, and we'll make it pass... :)",thanks attention deal submit failing test marked flag example failure make pas,issue,negative,negative,neutral,neutral,negative,negative
432456267,"looks good to me! thanks for looking in to this. as long as you can confirm that you've tested these changes result in at least as good results as before, feel free to send a PR, including removing the '_foo'",good thanks looking long confirm tested result least good feel free send removing,issue,positive,positive,positive,positive,positive,positive
432455542,Have a look see where the function is used now. Is there anywhere that using an ndarray or more general Iterable could break the code? Does it make sense semantically to allow iterables in general?,look see function used anywhere general iterable could break code make sense semantically allow general,issue,negative,positive,neutral,neutral,positive,positive
432453652,"@ohmeow: can you list down the exact steps which are causing the issue for you?

I m not sure if its the best idea to bring in a `np.ndarray` for the listy check - was discussing about this function today only with @jph00

<I take the iterable suggestion back - we don't really want iterable, we are specifically looking for `listy` as the function suggests>",list exact causing issue sure best idea bring check function today take iterable suggestion back really want iterable specifically looking function,issue,positive,positive,positive,positive,positive,positive
432443889,I don't think it's meant to be used with fastai v1 yet.,think meant used yet,issue,negative,neutral,neutral,neutral,neutral,neutral
432397443,"I didn't realize that could be done with a `Callback` ... but unless I'm wrong and/or this can be improved, yah ...

```
class PredictionsFromTupleCallback(Callback):
    def on_loss_begin(self, **kwargs:Any)->None:
        ""Useful for cleaning up things and saving files/models.""
        #pdb.set_trace()
        return kwargs['last_output'][0]
    
cbh = CallbackHandler(callbacks=[PredictionsFromTupleCallback()], metrics=None)
basic_train.get_preds(learn.model, learn.data.valid_dl, cb_handler=cbh)
```",realize could done unless wrong yah class self none useful cleaning saving return,issue,negative,negative,neutral,neutral,negative,negative
432383561,"You will need to write your own script for production anyway ;). You can pass callbacks to get_preds, so if you really need that function, just add a callback that treats your output to keep only the first element.",need write script production anyway pas really need function add output keep first element,issue,negative,positive,positive,positive,positive,positive
432382594,"Ah ok ... that works.

But shouldn't the behavior be the same in terms of reducing the output?  If I deploy my model into production, I imagine I won't need/want a `Learner` for inference and would want to use the `basic_train.get_preds()` against it.",ah work behavior reducing output deploy model production imagine wo learner inference would want use,issue,negative,neutral,neutral,neutral,neutral,neutral
432377805,You should use learn.get_preds so that the callbacks of the learner get passed (and the output be reduced).,use learner get output reduced,issue,negative,neutral,neutral,neutral,neutral,neutral
432266086,"Thanks, I can confirm that this did the trick! I was also trying to figure out the solution but was miles off.",thanks confirm trick also trying figure solution,issue,positive,positive,positive,positive,positive,positive
432265549,"Actually it's where there is `drops` that it's inconsistent. `ps` is used in the ConvLearner and RNN.classifier so we want to stick with those.
The docs need to be corrected if they talk about drops.",actually inconsistent used want stick need corrected talk,issue,negative,neutral,neutral,neutral,neutral,neutral
432259504,"There might have been some issue with the way TextDataSet decides is loss function. I pushed a fix, but I'm not sure it's going to work. Please reopen if it doesn't!",might issue way loss function fix sure going work please reopen,issue,negative,positive,positive,positive,positive,positive
432254727,The fail comes from the fact you have an empty test set.,fail come fact empty test set,issue,negative,negative,negative,negative,negative,negative
432254529,"It sounds like you are training with a learning rate too high. In any case, this isn't an issue with the library so please use the [forum](https://forums.fast.ai/).",like training learning rate high case issue library please use forum,issue,positive,positive,positive,positive,positive,positive
432249464,"I'm closing this issue. Fastai_v1 doesn't support Colab as long as Colab doesn't support pytorch. It's not helpful to beginners to have to worry about those things so please continue exchanging tricks to make it work on one of the advanced forums.
Thanks!",issue support long support helpful worry please continue make work one advanced thanks,issue,positive,positive,positive,positive,positive,positive
432225706,"@zzzhacker 

```
data = ImageDataBunch.from_folder(
    path, 
    ds_tfms=get_transforms(), 
    tfms=imagenet_norm, 
    size=224,
    num_workers=0,
)

```
You may need to run it once first without num_workers = 0 and then set num_workers=0.",data path may need run first without set,issue,negative,positive,positive,positive,positive,positive
432159763,Whats changed between when it was working fine and throwing error?,whats working fine throwing error,issue,negative,positive,positive,positive,positive,positive
432106561,"Just noticed something weird ...

When I run ""learn.loss_fn"" it returns:

<function torch.nn.functional.binary_cross_entropy_with_logits(input, target, weight=None, size_average=None, reduce=None, reduction='elementwise_mean', pos_weight=None)>

That is unexpected as I'm not setting this anywhere and was expecting the default loss function of cross entropy for the LM",something weird run function input target unexpected setting anywhere default loss function cross entropy,issue,negative,negative,negative,negative,negative,negative
432083894,"@discdiver in which code line should I add this num_workers = 0 , I am having the same problem",code line add problem,issue,negative,neutral,neutral,neutral,neutral,neutral
432037745,"@fryng, please do this with Keras:

`K.clear_session()
K.set_learning_phase(1)
model = load_model('your_model')
model.evaluate(inputs)`

With your backend `K`, you set the learning phase to training (1), then the evaluation of your inputs will push the update of the params in the batchnorm layers.  ",please model set learning phase training evaluation push update,issue,negative,neutral,neutral,neutral,neutral,neutral
431965653,"I'd suggest writing your own dataset, copying the `ImageDataset`. Instead of `open_image` at the end, use `open_dcm_image` (that you would have to write). You can inspire yourself with the code of `open_image`, but will need to figure out how to transform you .dcm file in an array of pixels before passing it to the `Image` class.

Closing this here as it should be discussed on the [forum](https://forums.fast.ai).",suggest writing instead end use would write inspire code need figure transform file array passing image class forum,issue,positive,neutral,neutral,neutral,neutral,neutral
431942005,"Thanks Sylvain, can you please suggest me a workaround, i really like the way v1 is organized compare to the previous version. Or should i fall back to the previous version until .dcm support is added?",thanks please suggest really like way organized compare previous version fall back previous version support added,issue,positive,positive,neutral,neutral,positive,positive
431903786,This appears to be due to GitHub pages being down and not necessarily related to the documentation. Closing this.,due necessarily related documentation,issue,negative,negative,neutral,neutral,negative,negative
431885837,"Very good idea. I just put back the kwargs (true ones this time) and passed them to the dataloaders, is someone wants to add num_workers=something or other things that could get passed to pytorch.",good idea put back true time someone add could get,issue,positive,positive,positive,positive,positive,positive
431800568,"We can't put a warning in each notebook because of this bug that should be resolved on the pytorch side at some point before v1 is officially out. Adding num_workers=0 would slow down the notebook for every user, which isn't what we want either.
So I don't see an ideal solution and think the best place to warn users would be a pinned thread on the forum.
",ca put warning notebook bug resolved side point officially would slow notebook every user want either see ideal solution think best place warn would pinned thread forum,issue,positive,positive,positive,positive,positive,positive
431707202,"These models are now not exported, to make it clear that they're not supported. For help adding new models, please discuss on fastai-dev on the forum.",make clear help new please discus forum,issue,positive,positive,positive,positive,positive,positive
431668688,"Old fastai is bound to get more and more deprecation warnings. Feel free to propose a PR fixing this, but we only maintain the new version now.",old bound get deprecation feel free propose fixing maintain new version,issue,positive,positive,positive,positive,positive,positive
431667084,"I read the source code of learner.py, and found that parameter, ""arch"",  should be models.resnet101 instead of models.resnet101() (they are different!!!)",read source code found parameter arch instead different,issue,negative,neutral,neutral,neutral,neutral,neutral
431620996,"fbeta is going to disappear for the class Fbeta that is going to give the true value. The previous approach was to average the fbetas over batches, but this will compute the real score. Fbeta has been tested over training, just pass it like a metric: `metrics=[accuracy_thresh, Fbeta(beta=2)]` for instance.",going disappear class going give true value previous approach average compute real score tested training pas like metric instance,issue,positive,positive,neutral,neutral,positive,positive
431613864,"Hi @sgugger!
With the changes from 2c9bc0c8c902ee158c03ccf04a5eb9ace914a09f this breaks:
```python
y_pred = Tensor([[0, 1], [0, 1], [0, 1]])
y_true = Tensor([[0, 1], [0, 1], [0, 1]])
fbeta(y_pred, y_true)
```

with error

```
---------------------------------------------------------------------
RuntimeError                        Traceback (most recent call last)
<ipython-input-101-03d98cc6777e> in <module>
      1 y_pred = Tensor([[0, 1], [0, 1], [0, 1]])
      2 y_true = Tensor([[0, 1], [0, 1], [0, 1]])
----> 3 fbeta(y_pred, y_true)

<ipython-input-60-76cf21da1a1a> in fbeta(y_pred, y_true, thresh, beta, eps, sigmoid)
      6     y_true = y_true.float()[:,None]
      7     TP = (y_pred*y_true).sum(dim=1)
----> 8     prec = TP/(y_pred.sum(dim=1)+eps)
      9     rec = TP/(y_true.sum(dim=1)+eps)
     10     res = (prec*rec)/(prec*beta2+rec+eps)*(1+beta2)

RuntimeError: The size of tensor a (2) must match the size of tensor b (3) at non-singleton dimension 1
```

As a consequence, multilabel training is currently not working. If there is additional complexity here because of batching, I suggest adding a couple of test cases. 
",hi python tensor tensor error recent call last module tensor tensor thresh beta sigmoid size tensor must match size tensor dimension consequence training currently working additional complexity suggest couple test,issue,negative,neutral,neutral,neutral,neutral,neutral
431572926,"> Apologies, this issue was due to incorrect installation.

Can you describe how you fixed your incorrect installation? What did you change to make it work? I'm facing the same issue.

Edit: I set up a fresh conda environment and installed fastai GPU via conda. The example still fails.",issue due incorrect installation describe fixed incorrect installation change make work facing issue edit set fresh environment via example still,issue,negative,positive,neutral,neutral,positive,positive
431571330,"Done.
Apologize for the delay - I was waiting on my employers to review the CLA and come up with a policy. 
Keep up the good work!",done apologize delay waiting review come policy keep good work,issue,negative,positive,positive,positive,positive,positive
431534238,@jph00 currently having a mental block on how to tests default paths and not screw up all the other tests. But putting this PR up for now if this is something more urgent,currently mental block default screw something urgent,issue,negative,negative,neutral,neutral,negative,negative
431498807,"Just pushed a fix, Jeremy forgot to change this one when he changed this API. It should work properly now so I'm closing this.",fix forgot change one work properly,issue,negative,neutral,neutral,neutral,neutral,neutral
431496732,"I just ran into I believe this same issue trying to run the text example notebook. I used the Developer Install instructions to install the most current code in this repo and I see my current version as `'1.0.8.dev0'`.

I resolved the issue by changing `datasets.download_wt103_model()` to `datasets.URLs.download_wt103_model()`. I think that's required since `download_wt103_model()` is now a class method on `URLs`, not at the `datasets` level. I believe this is the commit that caused that disconnect: https://github.com/fastai/fastai/commit/95f44e82b589c6985dcbe1178f144a0e36d36f0d#diff-48c59c669c350e1289260f46840bab8a

After that change the remainder of the notebook worked great.

I'm happy to submit that one-line change to fix this example notebook, but I'm not sure if that is the right fix, or if that method (and the other download methods) would be better moved back to `datasets.download_*` vs. `datasets.URLs.download_*`. I suspect there are other examples out there using `datasets.download_*` directly - this was my first test using fastai v1.",ran believe issue trying run text example notebook used developer install install current code see current version dev resolved issue think since class method level believe commit disconnect change remainder notebook worked great happy submit change fix example notebook sure right fix method would better back suspect directly first test,issue,positive,positive,positive,positive,positive,positive
431471935,"Thank you for the report, it was fixed just as you were sending the report in :) it does't show the updated files right away due to github caching policy.",thank report fixed sending report show right away due policy,issue,negative,positive,neutral,neutral,positive,positive
431415702,"It's just running ` tools/build-docs` inside fastai_docs repo and committing the results. We should update http://docs.fast.ai/gen_doc.html

It shouldn't happen on release but much more often than that, since release doesn't freeze the docs.fast.ai website.",running inside update happen release much often since release freeze,issue,negative,positive,positive,positive,positive,positive
431411893,"Ok, I just wanted to let you all know. 

If there's a git tagging script per release then maybe it could also have ""generate documentation"" step so it's part of the process.

If that's the case, would I be able to contribute something like that?

I looked around at how the documentation is being used and saw that it uses [sphinx](http://www.sphinx-doc.org/en/master/index.html), but when I ran `sphinx-build` to try it out, there wasn't a `conf.py` and so I was thinking that it's an external process to the repo.

Thanks",let know git script per release maybe could also generate documentation step part process case would able contribute something like around documentation used saw sphinx ran try thinking external process thanks,issue,positive,positive,positive,positive,positive,positive
431378331,This comes when we change the source code but forget to run the script to update those links. It's been corrected now.,come change source code forget run script update link corrected,issue,negative,neutral,neutral,neutral,neutral,neutral
431372482,"This might have been on github's side since the links properly point to the correct target (i.e. line in source). Now, some target seem to not be pointing to the right line. This is a different issue it seems.",might side since link properly point correct target line source target seem pointing right line different issue,issue,negative,positive,neutral,neutral,positive,positive
431193622,"Yes, the test set is intended for predictions, the base example being a Kaggle competition where you don't have the labels. If you have a second test set with labels, you should can validate your model on it by using `learn.validate(test_dl)`, `test_dl` being a dataloader that will iterate through it.",yes test set intended base example competition second test set validate model iterate,issue,positive,negative,negative,negative,negative,negative
431192712,"Hey, thanks for your help.

I am happy to provide more information, but I think we found the problem. My images in `test` are in sub-folders (for the classes) similar to the training and validation folders.

I don't understand your concept of 'test set' in the library. Normally, you indeed have the labels for the test set. [Some background about the split into train, val and test sets.](https://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set)

Does fastai mean 'predict' when you 'test'?",hey thanks help happy provide information think found problem test class similar training validation understand concept set library normally indeed test set background split train test mean,issue,positive,positive,positive,positive,positive,positive
431187025,"Will change vision init since the convention will be to do from fastai.vision import models.
Then models.wrn22 or models.Darknet...",change vision since convention import,issue,negative,neutral,neutral,neutral,neutral,neutral
431184157,We can't help you without an error message and a bit more about the structure of your folders. Note that the images are expected directly in the test folder and not in subclasses folders (since we don't know the labels of the test set).,ca help without error message bit structure note directly test folder since know test set,issue,positive,positive,neutral,neutral,positive,positive
431134277,"If it doesn't take any time, it means the files are there (it tests to see if they exist and downloads only if they're not there). Can you try to remove the models folder, make sure you have the latest version of fastai, then run the notebook again?",take time see exist try remove folder make sure latest version run notebook,issue,negative,positive,positive,positive,positive,positive
431125532,"![error](https://user-images.githubusercontent.com/5922231/47177455-12afb580-d336-11e8-891f-e47386f319a2.JPG)
This was the error I faced.
`datasets.download_wt103_model() ` executes successfully but the ""models"" folder remain empty.
But now something strange is happening,
Previously  `datasets.download_wt103_model() `took some time to execute, now it's executing in an instant when I try it again.",error error faced successfully folder remain empty something strange happening previously took time execute instant try,issue,negative,positive,neutral,neutral,positive,positive
431038908,I just ran the notebook on a new clone and it did download the files. Could you give us the error message you saw?,ran notebook new clone could give u error message saw,issue,negative,positive,positive,positive,positive,positive
431037108,Please let us know when you've signed the CLA. Thanks for your contribution!,please let u know thanks contribution,issue,positive,positive,positive,positive,positive,positive
431036664,We may change this again before we get to the tabular lesson in a couple of weeks. We'll do some more testing.,may change get tabular lesson couple testing,issue,negative,neutral,neutral,neutral,neutral,neutral
431033326,"i tried this as well, but discarded this solution: keep in mind that with a small epsilon all values in the column will become huge (e.g. 1e12 or whatver), which is a big contrast to the other values. for example, my validation loss would be something like 2384589345 for a few training iterations because of the small epsilon.

edit: actually, i'm unsure why this happened, as (self.conts - means[None]) should have been 0.",tried well solution keep mind small epsilon column become huge big contrast example validation loss would something like training small epsilon edit actually unsure none,issue,positive,negative,neutral,neutral,negative,negative
431029161,"After discussion with Jeremy, we decided to fix this not with a test, but by adding a small epsilon to the stds.",discussion decided fix test small epsilon,issue,negative,negative,negative,negative,negative,negative
431022390,"There is an AttributeError coming while running examples, which is given below
`AttributeError: module 'PIL' has no attribute 'Image'`

The installed package is 
`!pip show Pillow`
~~~
Name: Pillow
Version: 5.3.0
Summary: Python Imaging Library (Fork)
Home-page: http://python-pillow.org
Author: Alex Clark (Fork Author)
Author-email: aclark@aclark.net
License: Standard PIL License
Location: /usr/local/lib/python3.6/dist-packages
Requires: 
Required-by: fastai
~~~
It seems like the Pillow package of 5.3.0 does not support the Fastai V1 

I checked for previous packages, the 4.1.1 Pillow package is working fine with all the examples",coming running given module attribute package pip show pillow name pillow version summary python library fork author clark fork author license standard license location like pillow package support checked previous pillow package working fine,issue,positive,positive,neutral,neutral,positive,positive
431018586,Thanks for spotting that! Any chance you could submit a PR with that change?,thanks spotting chance could submit change,issue,positive,positive,positive,positive,positive,positive
431005424,Thanks for flagging this. Just changed to the way we usually add dims in the library.,thanks flagging way usually add library,issue,negative,negative,neutral,neutral,negative,negative
430793793,"fastai 1.0.x installation issues should be reported/discussed [here](http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111) instead. Thank you.

When you do:

Please send the output of:
`python -c ""import fastai; fastai.show_install()""
`

and the exact installation steps you did (since they are several ways).
",installation instead thank please send output python import exact installation since several way,issue,positive,positive,positive,positive,positive,positive
430734518,"Also found this issue from a year ago, https://github.com/jupyter/notebook/issues/3035, and someone suggested the size could be a problem, but as I tested going back a few weeks none of them renders.

You can experiment yourself, but clicking on History, going to a prior commit, and then clicking View - it'll show you how it was after that older commit. I can't get any of them to render. That's why I think it's github's bug.
",also found issue year ago someone size could problem tested going back none experiment history going prior commit view show older commit ca get render think bug,issue,negative,positive,neutral,neutral,positive,positive
430732864,"It looks like a github issue. I confirm that I get the same. But if I try a version from 2 weeks ago [1] it doesn't render either, so it's not the file, but github - I suggest to report this to support. Thank you.

[1] https://github.com/fastai/fastai/blob/bc84f8fd4c42a6423a6f814c2b6129b43930c8c3/examples/cifar.ipynb",like issue confirm get try version ago render either file suggest report support thank,issue,positive,neutral,neutral,neutral,neutral,neutral
430685903,"Thanks @sgugger, @melikovk  
Meanwhile could you please help with suggestions on how to make squeezenet work? 
I'm trying to build a model for mobile platforms.",thanks meanwhile could please help make work trying build model mobile,issue,positive,positive,positive,positive,positive,positive
430644433,"`validate` then `loss_batch` are called without a `loss_fn` so we stop at [this line](https://github.com/fastai/fastai/blob/ba616ed2b8e132e446fb88d7d8acff7a38dd04e0/fastai/basic_train.py#L22) by returning `out` and `y`.

Closing this here as questions about the code should be asked on the [forum](https://forums.fast.ai/).",validate without stop line code forum,issue,positive,neutral,neutral,neutral,neutral,neutral
430642565,"Thank you for your reply. It seems that I passed a loss_fn to it by mistake.
Going to close this thread",thank reply mistake going close thread,issue,negative,neutral,neutral,neutral,neutral,neutral
430636145,"Not sure I follow. `get_preds(is_test=True)` returns `[outputs, fake_label]` where the `fake_label` are what was given with the test set (usually a bunch of zeros) and `outputs` the outputs of the model on the test set. Depending on your loss function, you then have to apply a softmax/sigmoid to get your predictions from the outputs, but I don't see the bug.",sure follow given test set usually bunch model test set depending loss function apply get see bug,issue,negative,positive,positive,positive,positive,positive
430508933,"Apologies, this issue was due to incorrect installation. ",issue due incorrect installation,issue,negative,negative,negative,negative,negative,negative
430248952,"Nice, thanks for your hard work! I look forward to the pretty progress bars!

I think that check is fine, maybe one level up in case the submodules are shuffled around? 
```python
from google import colab
```
But that's more or less what you suggested. ;]",nice thanks hard work look forward pretty progress think check fine maybe one level case around python import le,issue,positive,positive,positive,positive,positive,positive
430245678,"Thanks for your suggestion. I'll indeed write a colab version of the bar when I have a bit of time. I did notice the ouput option, but there is also some way to make it a bit prettier: ipywidgets don't work fully but I found some HTML progress bars that rendered well on colab.

One thing that would be useful is to already have a test of whether or not the notebook is executed in colab (like IS_NOTEBOOK but IS_COLAB). For now I'm thinking to try 
```
from google.colab import output
```
to determine if I should set it True or False, but if you think of a better way, I'm all ears.",thanks suggestion indeed write version bar bit time notice option also way make bit work fully found progress well one thing would useful already test whether notebook executed like thinking try import output determine set true false think better way,issue,positive,positive,positive,positive,positive,positive
430243462,"Hi @sgugger , from googlecolab/colabtools#166, it appears that the behaviour of the carriage return in Colab also clears any output back to the newline, so... one solution could be a new subclass of ProgressBar that uses the output utilities provided by colabtools.

```python
# When on Google Colab, import the output utilities
try:
  from google.colab import output as colab_output
except ImportError:
    pass

# This is just a minimally modified version of ConsoleProgressBar
class ColabProgressBar(ProgressBar):
    length:int=50
    fill:str='█'

    def __init__(self, gen, total=None, display=True, leave=True, parent=None, auto_update=True):
        self.max_len,self.prefix = 0,''
        super().__init__(gen, total, display, leave, parent, auto_update)

    def on_iter_end(self):
        if not self.leave and printing():
            # On Google Colab, printed outputs can be marked with tags
            # using a (non-thread safe) context manager. Output can then
            # be selectively cleared by their tags. The clear() function can
            # also wait to clear output, deferring action until there is new output.
            # The following three lines first clears output tagged as 'fastprogress',
            # if any, and then prints output under that same tag. Note that the call
            # to print no longer terminates the line with a carriage return (end='\r')
            # because Colab would otherwise clear the contents we want to print.
            colab_output.clear(output_tags='fastprogress', wait=True)
            with colab_output.use_tags('fastprogress'):
                print(f'\r{self.prefix}' + ' ' * (self.max_len - len(f'\r{self.prefix}')))

    def on_update(self, val, text):
        if self.display:
            filled_len = int(self.length * val // self.total)
            bar = self.fill * filled_len + '-' * (self.length - filled_len)
            to_write = f'\r{self.prefix} |{bar}| {text}'
            if len(to_write) > self.max_len: self.max_len=len(to_write)
            if printing():
                # The same construct as above appears here as well,
                # and that's all of the modifications needed to get
                # a passable progress bar to show up on Colab
                colab_output.clear(output_tags='fastprogress', wait=True)
                with colab_output.use_tags('fastprogress'):
                    print(to_write)
```

If such a class were added to the fastprogress module, the `isnotebook()` function might need to be modified because when the module checks for the shell environment on Colab the value of `get_ipython().__class__.__name__` is just `'Shell'`, so it returns False rather than True. In any case, `IN_NOTEBOOK` would need to be True in order for `printing()` to return True when using Colab, otherwise the progress bar isn't printed.

This solution isn't perfect though, because some output lingers after the last iteration. For example, when I run the simple example featured in the README of fastprogress, I see the following output on Colab:
```
Finished loop 7.
Finished loop 8.
Epoch 10/10 :                                                                                                   
Finished loop 9.
```

The ""Epoch 10/10"" goes away if another call to `clear()` any outputs tagged as `'fastprogress'` is added just before the master bar writes out which loop it finished.

Hope this was helpful, cheers!",hi behaviour carriage return also output back one solution could new subclass output provided python import output try import output except pas minimally version class length fill self gen super gen total display leave parent self printing printed marked safe context manager output selectively clear function also wait clear output action new output following three first output tagged output tag note call print longer line carriage return would otherwise clear content want print print self text bar bar text printing construct well get passable progress bar show print class added module function might need module shell environment value false rather true case would need true order printing return true otherwise progress bar printed solution perfect though output last iteration example run simple example featured see following output finished loop finished loop epoch finished loop epoch go away another call clear tagged added master bar loop finished hope helpful,issue,positive,positive,positive,positive,positive,positive
430241586,"The old version of fastai doesn't support python 3.7, yes. The new version v1 does.
I've update the requirements file of old fastai accordingly.",old version support python yes new version update file old accordingly,issue,positive,positive,positive,positive,positive,positive
430174401,"This can also happen in a case where one is trying something out on a subset of data, which is not representative of the entire dataset. ",also happen case one trying something subset data representative entire,issue,negative,neutral,neutral,neutral,neutral,neutral
430034761,"@WizardOfAus, apologies I pasted the wrong URL, it should have been http://forums.fast.ai/c/part1-v2.

So yes, start a new thread (unless there is one already for colab, I haven't checked, then add to it) at http://forums.fast.ai/c/part1-v2, post it there, and then link to it from the top post at http://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652/30 - it's a wiki now so you can edit it yourself. Add it towards the end of the first post, where links to related posts are.

Thank you!",pasted wrong yes start new thread unless one already checked add post link top post edit add towards end first post link related thank,issue,negative,positive,neutral,neutral,positive,positive
430032540,@stas00 sounds good! #892 has been closed. Should I still post there as in the comments and then ping you? ,good closed still post ping,issue,negative,positive,positive,positive,positive,positive
429949421,"Thank you, @cesare-montresor. 

Apologies for the false alarm, we are working on a better validation.",thank false alarm working better validation,issue,negative,positive,neutral,neutral,positive,positive
429771920,"The failed test looks unrelated to the patch I'm proposing:

2018-10-15T09:10:41.4905230Z path = PosixPath('/Users/vsts/agent/2.140.2/work/1/s/fastai/../data/mnist_tiny')
2018-10-15T09:10:41.4905390Z 
2018-10-15T09:10:41.4906120Z     def test_normalize(path):
2018-10-15T09:10:41.4906970Z         data = ImageDataBunch.from_folder(path, ds_tfms=(rand_pad(2, 28), []))
2018-10-15T09:10:41.4937210Z         x,y = data.train_dl.one_batch()
2018-10-15T09:10:41.4937350Z         m,s = x.mean(),x.std()
2018-10-15T09:10:41.4937410Z         data.normalize()
2018-10-15T09:10:41.4937730Z         x,y = data.train_dl.one_batch()
2018-10-15T09:10:41.4938380Z >       assert abs(x.mean()) < abs(m)
2018-10-15T09:10:41.4938590Z E       assert tensor(0.1254) < tensor(0.1231)
2018-10-15T09:10:41.4939340Z E        +  where tensor(0.1254) = abs(tensor(-0.1254))
2018-10-15T09:10:41.4939900Z E        +    where tensor(-0.1254) = <built-in method mean of Tensor object at 0x1237f2090>()
2018-10-15T09:10:41.4940750Z E        +      where <built-in method mean of Tensor object at 0x1237f2090> = tensor([[[[-0.4745, -0.4745, -0.4745,  ..., -0.4745, -0.4745, -0.4745],\n          [-0.4745, -0.4745, -0.4745,  ..., -0..., -0.4745,  ..., -0.4745, -0.4745, -0.4745],\n          [-0.4745, -0.4745, -0.4745,  ..., -0.4745, -0.4745, -0.4745]]]]).mean
2018-10-15T09:10:41.4940980Z E        +  and   tensor(0.1231) = abs(tensor(0.1231))
2018-10-15T09:10:41.4941050Z 
2018-10-15T09:10:41.4941100Z tests/test_vision.py:36: AssertionError
2018-10-15T09:10:41.4941710Z ------ generated xml file: /Users/vsts/agent/2.140.2/work/1/s/result.xml -------
2018-10-15T09:10:41.4941800Z ===================== 1 failed, 37 passed in 7.70 seconds ======================",test unrelated patch path path data path assert assert tensor tensor tensor tensor tensor method mean tensor object method mean tensor object tensor tensor tensor file,issue,negative,negative,negative,negative,negative,negative
429701084,"Alright thanks, just let me know if a workaround for this is found, since it would be nice to see live updates while waiting for the model to train.",alright thanks let know found since would nice see live waiting model train,issue,positive,positive,positive,positive,positive,positive
429694891,"Thanks for your reports. The basic issue is
1. ipywidgets isn't supported on colab so we can't have the pretty progress bar
2. for the console behavior, print('foo', end='\r') doesn't behave as in any other terminal and erases the output instantly after printing it, which is why you don't see the console progress bar.

I'll try to see how to get around that (I see that tqdm works properly for instance) but there is a lot to do for the release of the course, so it might not be soon... ",thanks basic issue ca pretty progress bar console behavior print behave terminal output instantly printing see console progress bar try see get around see work properly instance lot release course might soon,issue,positive,positive,neutral,neutral,positive,positive
429691896,"Running the fast progress example repo with a pip install fastprogress at the top of the notebook results in just text being printed saying “Finished loop x”
Here the notebook for reference https://colab.research.google.com/drive/1SuMS0UDi0g50fRFsHwYf4_IakNxSiI2S",running fast progress example pip install top notebook text printed saying finished loop notebook reference,issue,positive,positive,positive,positive,positive,positive
429691358,"Sorry I only catch up now on this. I just ran a similar example without problems, so I'm guessing this has been fixed in a later version. Let me know if you still have the problem, but the expected behavior is as you thought: when passing cat_names and cont_names, other columns should be ignored.",sorry catch ran similar example without guessing fixed later version let know still problem behavior thought passing,issue,negative,negative,neutral,neutral,negative,negative
429688149,"That last error comes from your version yes, it'll be fixed in a more recent one.
Can you try the basic example that is shown on the [fastpogress repo](https://github.com/fastai/fastprogress#usage) and tell me what you see?",last error come version yes fixed recent one try basic example shown tell see,issue,negative,positive,neutral,neutral,positive,positive
429675605,"I have tried adding `import fastai` alone as well as adding an `import fastai` call after my `from fastai import *` call, both tries still result in no statistics being shown.
I am unable to access the __version__ property for fastprogress, but I'm installing fastai from the recommended steps in the readme, and the setup.py lists the fastprogress version requirements as >=0.1.10. It turns out the version of fastai I have installed is 1.0.5, would that cause the error?
If I let it run, at the end of the epoch, it does print the statistics epoch by epoch, example (for dogs vs cats): https://i.imgur.com/dYRYLt6.png.

Running the vision example results in an undefined function error, again would this be because I'm running fastai v1.0.5?:
```
name 'untar_data' is not defined
```",tried import alone well import call import call still result statistic shown unable access property version turn version would cause error let run end epoch print statistic epoch epoch example dog running vision example undefined function error would running name defined,issue,negative,negative,negative,negative,negative,negative
429672960,"Hum, if Google Colab doesn't support ipywidget, it should default automatically to the console behavior. What version of fastprogress do you have?
And yes, you should add `import fastai` before executing the block of three lines, if you didn't do it before. The fact it doesn't print anything is weird. Can you try running the basic vision example (that should be fast) to see if it's just waiting for the end of an epoch to print anything? ",hum support default automatically console behavior version yes add import block three fact print anything weird try running basic vision example fast see waiting end epoch print anything,issue,negative,negative,neutral,neutral,negative,negative
429669097,"Hi @sgugger ,
I'm importing fastai in my code as 
```
from fastai import *
```
and if I try running fastai.basic_train.master_bar, etc, i get the following error: 
```
NameError                                 Traceback (most recent call last)
<ipython-input-15-1b7fc7d5e975> in <module>()
      1 from fastprogress import force_console_behavior
      2 master_bar, progress_bar = force_console_behavior()
----> 3 fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar

NameError: name 'fastai' is not defined
```

I've tried modifying my code to just
```
import fastai
```
but it still doesn't show any statistics https://i.imgur.com/thjyvdt.png.
From what I've read online, I don't think Google Colab supports ipywidgets, but if I'm wrong, how would I enable it?",hi code import try running get following error recent call last module import name defined tried code import still show statistic read think wrong would enable,issue,negative,negative,negative,negative,negative,negative
429667877,"If the stats aren't showing, it's because you don't have ipywidgets properly installed. You should check you enabled it properly. For the workaround, I think it doesn't work because you should type
```
from fastprogress import force_console_behavior
master_bar, progress_bar = force_console_behavior()
fastai.basic_train.master_bar, fastai.basic_train.progress_bar = master_bar, progress_bar
```",showing properly check properly think work type import,issue,negative,neutral,neutral,neutral,neutral,neutral
429624454,"The vision example is the one working. Note that there was a change in the fastai library removing the docs module, so you should update to the last version (or do a developer install from master) to run it.
Thanks for flagging the index of the docs is now outdated, will change this one ASAP.",vision example one working note change library removing module update last version developer install master run thanks flagging index outdated change one,issue,positive,negative,neutral,neutral,negative,negative
429596565,"Sorry for the late response. 
It does break the language model (I updated the classifier but forgot about the LM...). Would you prefer a different input format that supports both versions? e.g. set the text lengths input as optional?
Anyway, I'll post my notebook sometime this week.",sorry late response break language model classifier forgot would prefer different input format set text input optional anyway post notebook sometime week,issue,negative,negative,negative,negative,negative,negative
429505251,"I'm not sure I follow you. Using this method, you can't expect the library to iterate other files found in `folder`: it's supposed to have a list of filenames in the csv fil that all are in `folder`. 
Note that ìmage_data_from_csv` doesn't support test datasets yet.
Going on, please use the [forum](http://forums.fast.ai/) for this, as it'll reach a larger audience, thanks!",sure follow method ca expect library iterate found folder supposed list folder note support test yet going please use forum reach audience thanks,issue,positive,positive,positive,positive,positive,positive
429497519,"Thanks so much for this really interesting contribution! :) As @sgugger mentioned, it is breaking existing code, so we're not going to accept it in this state - and we'd like to be able to play around with your code in a notebook environment so we can fully understand it.

Therefore, would you be able to create a notebook which contains your implementation, along with examples showing how it works with language model and classification training and fine-tuning? Please create a gist and post it at forums.fast.ai so we can discuss.

Many thanks!",thanks much really interesting contribution breaking code going accept state like able play around code notebook environment fully understand therefore would able create notebook implementation along showing work language model classification training please create gist post discus many thanks,issue,positive,positive,positive,positive,positive,positive
429475804,"I don't see where the bug is:
- learner has a default wd of 1e-2 if you don't specify anything
- if you specify learner.wd = something, it changes it
- in a fit or fit_one_cycle function, if you specify a wd, it overrides learn.wd, but learn.wd keeps its value.

Please note that there is a [forum](http://forums.fast.ai/) to ask those questions, and that many more would benefit from the answers there than here ;)",see bug learner default specify anything specify something fit function specify value please note forum ask many would benefit,issue,positive,positive,positive,positive,positive,positive
429452713,"They are two separate git repos, so the script can't do it for both since it doesn't know where the other one is. I will update the documents to make it clear. Thank you for your feedback, @ohmeow ",two separate git script ca since know one update make clear thank feedback,issue,positive,positive,positive,positive,positive,positive
429443430,"Will do.

I thought I only had to run that once after cloning my fork of the repo
based on the docs.

Thanks much

On Fri, Oct 12, 2018, 9:08 AM Stas Bekman <notifications@github.com> wrote:

> @ohmeow <https://github.com/ohmeow>, please make sure to follow the guide
> for contributing. You must run
>
> tools/run-after-git-clone
>
> before making a commit. otherwise your notebooks aren't stripped and your
> PR cannot be accepted. Thank you.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/891#issuecomment-429377725>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAA2sABgQq3HZulWulaMxWOKTut01T1Nks5ukL54gaJpZM4XZsyG>
> .
>
",thought run fork based thanks much wrote please make sure follow guide must run making commit otherwise stripped accepted thank reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
429403886,"All the platform-specific guides are on the forums at the moment. For now, I think it'd be much simpler to post your guide to a new thread at  http://forums.fast.ai/c/part1-v2 and then we can link to it from http://forums.fast.ai/t/fastai-v0-7-install-issues-thread/24652/30 - just ping me when you posted it and I will link it to it.

Would that work, @WizardOfAus? Apologies for the confusing messages, as in the other post @jph00 did suggest you make a PR out of it.

Perhaps, for course v3 we will start making documents that will come together with course files and the any improvements over PR will be the way to go.",moment think much simpler post guide new thread link ping posted link would work post suggest make perhaps course start making come together course way go,issue,negative,positive,positive,positive,positive,positive
429400746,"There are several notebooks posted here, @d-henderson:
http://forums.fast.ai/t/corporacion-favorita-grocery-sales-forecasting/8359/82
Please continue a discussion over at that forum. Thank you.",several posted please continue discussion forum thank,issue,positive,neutral,neutral,neutral,neutral,neutral
429378981,"> Add to do a new branch then a new PR for that, so closing this one.

Not sure what you mean by that.

I merged your deletion of cifar.ipynb into my forked repo (in addition to the latest in fastai). Is there anything else I need to do besides run the ""tools/run-after-git-clone"" script before I do the PR?",add new branch new one sure mean deletion forked addition latest anything else need besides run script,issue,negative,positive,positive,positive,positive,positive
429377725,"@ohmeow, please make sure to follow the guide for contributing. You must run

`tools/run-after-git-clone`

once when you first close the repo. It has to happen before you're making the first commit. otherwise your notebooks aren't stripped and your PR cannot be accepted. Thank you.

I can see that @sgugger is reworking this particular PR any way, so it'll be OK this time, but in future PRs please remember to follow the guide. Thanks.",please make sure follow guide must run first close happen making first commit otherwise stripped accepted thank see particular way time future please remember follow guide thanks,issue,positive,positive,positive,positive,positive,positive
429367266,"Yes, we don't support those models in ConvLearner yet. We'll work on this soon.",yes support yet work soon,issue,positive,neutral,neutral,neutral,neutral,neutral
429366129,PS: remember to execute tool/run-after-git so that your notebooks are properly stripped.,remember execute properly stripped,issue,negative,neutral,neutral,neutral,neutral,neutral
429366015,"Add to do a new branch then a new PR for that, so closing this one.",add new branch new one,issue,negative,positive,positive,positive,positive,positive
429329967,"it could be a continuous variable.
an example for a technical process would be a temperature measurement, which could be 20.0 in a controlled environment but vary in some samples (e.g. 19.9 or 25.1). If a small data set is used it could appear to be a constant but vary in other data sets. ",could continuous variable example technical process would temperature measurement could environment vary small data set used could appear constant vary data,issue,negative,negative,neutral,neutral,negative,negative
429038549,"When you use a tabular model for regression, you should change the loss function (cross_entropy won't help you there).
You should also specify a y_range to help the model make better predictions.
Note that there is an example with Rossman [here](https://github.com/fastai/fastai_docs/blob/master/dev_nb/009_rossmann.ipynb) in the development notebooks.",use tabular model regression change loss function wo help also specify help model make better note example development,issue,positive,positive,positive,positive,positive,positive
428960310,"User is supposed to pass np arrays, but it's a nice check to make their life easier, thanks!",user supposed pas nice check make life easier thanks,issue,positive,positive,positive,positive,positive,positive
428959995,"You made changes to RNNCore, so I expect it's going to break the language model (EDIT: it does break the language model). Did you test you could run the text example notebook entirely? In any case I'll need to check it doesn't change the final result of ULMFiT on IMDB.

For the future, please note that we prefer to get significant changes in the form of a new notebook like [the development notebooks](https://github.com/fastai/fastai_docs/tree/master/dev_nb) used to create the library, so we can easily refactor/check it works properly.",made expect going break language model edit break language model test could run text example notebook entirely case need check change final result future please note prefer get significant form new notebook like development used create library easily work properly,issue,positive,positive,positive,positive,positive,positive
428956809,"If you want to do a classification with three values, you should convert them as categories, otherwise it won't work yes (unless your three values are the integers 0, 1 and 2).
If you want to do a regression, you should specify y_range = (min,max) so that the data object knows it.",want classification three convert otherwise wo work yes unless three want regression specify min data object,issue,positive,neutral,neutral,neutral,neutral,neutral
428925667,"From #852 i gathered that maybe `train_df.loc[10, "">=50k""] = -1` does not work because the loss function is incorrect for 3 classes? Although i really only want one of the three possibilities as a result.

if i change the loss to `F.binary_cross_entropy_with_logits` in the tabular example, it gives another error:

> ---------------------------------------------------------------------------
> ValueError                                Traceback (most recent call last)
> <ipython-input-25-57f0e4930b1d> in <module>
>       1 learn = get_tabular_learner(data, layers=[200,100], metrics=accuracy)
>       2 learn.loss_fn = F.binary_cross_entropy_with_logits
> ----> 3 learn.fit(1, 1e-2)
> 
> ~/PythonProjects/fastai/fastai/basic_train.py in fit(self, epochs, lr, wd, callbacks)
>     133         callbacks = [cb(self) for cb in self.callback_fns] + listify(callbacks)
>     134         fit(epochs, self.model, self.loss_fn, opt=self.opt, data=self.data, metrics=self.metrics,
> --> 135             callbacks=self.callbacks+callbacks)
>     136 
>     137     def create_opt(self, lr:Floats, wd:Floats=0.)->None:
> 
> ~/PythonProjects/fastai/fastai/basic_train.py in fit(epochs, model, loss_fn, opt, data, callbacks, metrics)
>      86     except Exception as e:
>      87         exception = e
> ---> 88         raise e
>      89     finally: cb_handler.on_train_end(exception)
>      90 
> 
> ~/PythonProjects/fastai/fastai/basic_train.py in fit(epochs, model, loss_fn, opt, data, callbacks, metrics)
>      76             for xb,yb in progress_bar(data.train_dl, parent=pbar):
>      77                 xb, yb = cb_handler.on_batch_begin(xb, yb)
> ---> 78                 loss = loss_batch(model, xb, yb, loss_fn, opt, cb_handler)
>      79                 if cb_handler.on_batch_end(loss): break
>      80 
> 
> ~/PythonProjects/fastai/fastai/basic_train.py in loss_batch(model, xb, yb, loss_fn, opt, cb_handler, metrics)
>      19     out = cb_handler.on_loss_begin(out)
>      20     if not loss_fn: return out.detach(),yb[0].detach()
> ---> 21     loss = loss_fn(out, *yb)
>      22     mets = [f(out,*yb).detach().cpu() for f in metrics] if metrics is not None else []
>      23 
> 
> ~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py in binary_cross_entropy_with_logits(input, target, weight, size_average, reduce, reduction, pos_weight)
>    1740         reduction = _Reduction.legacy_get_string(size_average, reduce)
>    1741     if not (target.size() == input.size()):
> -> 1742         raise ValueError(""Target size ({}) must be the same as input size ({})"".format(target.size(), input.size()))
>    1743 
>    1744     max_val = (-input).clamp(min=0)
> 
> ValueError: Target size (torch.Size([64])) must be the same as input size (torch.Size([64, 2]))

i'm sorry for the inconvenience as i cannot really understand at this point if it's a bug in the library or a user (my) error.",maybe work loss function incorrect class although really want one three result change loss tabular example another error recent call last module learn data fit self self fit self none fit model opt data metric except exception exception raise finally exception fit model opt data metric loss model opt loss break model opt metric return loss metric metric none else input target weight reduce reduction reduction reduce raise target size must input size target size must input size sorry inconvenience really understand point bug library user error,issue,negative,positive,positive,positive,positive,positive
428766807,"I personally learned a few things from it (that other projects use a different style), so all is good. I'm glad this has come to a satisfactory resolution. Some of the developers may experiment with these other two styles and perhaps they will become more favorable for them. Let's see. I appreciate the inquisition, @ncihnegn, and am looking forward to more contributions ;)",personally learned use different style good glad come satisfactory resolution may experiment two perhaps become favorable let see appreciate inquisition looking forward,issue,positive,positive,positive,positive,positive,positive
428764339,"I agree there is nothing substantial. Two commits vs one, that is it.

I was mistaken at the beginning.
As I said, I mentioned this merging style just as my personal preference.
Then the thread is extended around how to enable such a style and the benefits.
Definitely not my intention to waste anyone's time.
Thank you for your patience.",agree nothing substantial two one mistaken beginning said style personal preference thread extended around enable style definitely intention waste anyone time thank patience,issue,negative,negative,neutral,neutral,negative,negative
428757987,"Thank you for clarifying the difference, @aimran. 

Basically the other two options replace 1+ contributor commits and 1 merge commit with a single commit, which happens to result in a slightly different message in github logs (and makes no difference what-so-ever on the git-level, other than the total number of commits).

I still fail to see the practical difference between:

```
commit message...
ncihnegn committed ...
```

and:

```
commit message...
ncihnegn authored ...
```

can you enlighten me of how these two are different? surely 'committed' == 'authored' in any developer's mind, otherwise any commits I make of my own direct contributions (not PR) and which say 'committed' don't mean that I authored them?

Please bear with me, as I'm new to the github culture, do you feel that you're short-changed when the merge style is used instead of the other two? do you get less brownie points this way? And I'm not being sarcastic, just trying to find a way to give the contributors as much fame as it's possible w/o hampering the workflow.

I have a feeling that this is just a matter of preference, since the contributors always get the full credit due either way.

Thinking some more about it, actually, with the merge style if your PR was comprised of several commits, you get all of them to your name! with the other two styles you always get 1 commit. So, the merge style gives more contribution points! It's silly I know, but it's true.",thank difference basically two replace contributor merge commit single commit result slightly different message difference total number still fail see practical difference commit message commit message enlighten two different surely developer mind otherwise make direct say mean please bear new culture feel merge style used instead two get le brownie way sarcastic trying find way give much fame possible feeling matter preference since always get full credit due either way thinking actually merge style comprised several get name two always get commit merge style contribution silly know true,issue,positive,positive,neutral,neutral,positive,positive
428754087,"I'm closing this for now as I answered on the forum. I'm not sure there are any cases where we actually need this. I could be wrong of course, in which case we can reopen this PR ;)",forum sure actually need could wrong course case reopen,issue,negative,neutral,neutral,neutral,neutral,neutral
428750452,"Ultimately its a choice for devs+community but I can confirm that using _either_ the `Squash & merge` or  `Rebase and merge` gives you that ""X authored and Y committed"" message where X is the original PR author and Y is the committer (typically bot/admin etc)

But the extra merge buttons have to be enabled first.

E.g, https://blog.github.com/2016-09-26-rebase-and-merge-pull-requests/",ultimately choice confirm squash merge rebase merge message original author committer typically extra merge button first,issue,negative,positive,positive,positive,positive,positive
428738310,"Now I lost you, @ncihnegn. Your name already appears on the commit you contributed via PR. I'm not sure how the choice of the merge style will make any difference. It will still say [the same](https://github.com/fastai/fastai/pull/861#issuecomment-428031778).

Can you show us another project where you contributed a PR and it appears there any different than your commit here? Other than facebook-owned projects, which use facebook-github-bot, to which we don't have access to. Once I have a reference point, it's easy to evaluate how to get there. At this moment I no longer understand your needs and therefore don't now how to we could meet them.",lost name already commit via sure choice merge style make difference still say show u another project different commit use access reference point easy evaluate get moment longer understand need therefore could meet,issue,positive,positive,positive,positive,positive,positive
428735430,"We decided to [document this issue](https://github.com/fastai/fastai/commit/c81e1e4ddc45c3f35a0289bf879cdc3e5c27cbf3), warn users about the bug in fastText and close this ticket, since there is no reaction on the fastText side.

",decided document issue warn bug close ticket since reaction side,issue,negative,neutral,neutral,neutral,neutral,neutral
428730217,"Github button has three merging options: create a merging commit, squash and merge, rebase and merge. I think the rebasing merge will work as I expect. You may want to check if rebasing merge is enabled for the repo.",button three create commit squash merge rebase merge think merge work expect may want check merge,issue,positive,neutral,neutral,neutral,neutral,neutral
428655779,"As said in #878 this has been solved yesterday.
I'm closing this, but in general, sending us a minimal script that reproduces the bug is great, thanks a lot!",said yesterday general sending u minimal script bug great thanks lot,issue,positive,positive,positive,positive,positive,positive
428654160,"This has been raised yesterday [here](http://forums.fast.ai/t/cant-optimize-non-leaf-tensor-error-with-learn-fit-one-cycle-after-running-plotting-lr-find-a-second-time/24875) and should have been fixed (don't forget to seach the forum when you have an error as the message is the same ;) ).
With the latest version of fastai (ideally a developer install) you shouldn't have this anymore.",raised yesterday fixed forget forum error message latest version ideally developer install,issue,negative,positive,positive,positive,positive,positive
428633165,"Thanks for the thoughtful PR. I don't really like the idea of behaviour changing if someone hasn't installed correctly - it means that they're using an unsupported platform or unsupported install process, which isn't suitable for beginners. If they're not a beginner, then they'll know what a missing module means and how to fix it. Also, it's important that the steps shown in the course result in the behaviour shown in the course (we can't edit the videos).

Missing bcolz is a common problem on Windows. I think a good approach would be to leave in the try/catch for importing it, but in the case of failure, raise an exception with something like ""You don't have bcolz installed. That means that you haven't installed the fast.ai course environment fully, or are on an unsupported platform. If you are a python expert, you can fix this by installing the bcolz module. Otherwise please refer to the instructions at {link} for step by step installation steps"". {link} could go for instance to the excellent tutorials from Reshemas, or a separate README-course.md file that could be created.

I'm open to increasing the version number dependency for pytorch, but I'd want to see someone confirm that they've run all the notebooks without warnings or errors on Linux with 0.4 first. I suspect it's OK, but I'm not sure I've seen confirmation.

I'll close this PR now - if you're interested in contributing either of the above suggestions, please open a new PR with them separately (it's easier to handle a PR that only contains one feature, rather than combining them).",thanks thoughtful really like idea behaviour someone correctly unsupported platform unsupported install process suitable beginner know missing module fix also important shown course result behaviour shown course ca edit missing common problem think good approach would leave case failure raise exception something like course environment fully unsupported platform python expert fix module otherwise please refer link step step installation link could go instance excellent separate file could open increasing version number dependency want see someone confirm run without first suspect sure seen confirmation close interested either please open new separately easier handle one feature rather combining,issue,positive,positive,positive,positive,positive,positive
428624660,The same error is happening when I run `lr_find` then `fit_one_cycle`.  My guess is that lr_find is changing the learner.  ,error happening run guess learner,issue,negative,neutral,neutral,neutral,neutral,neutral
428610613,"oob_score=True is causing that. Jeremy talks about in in lesson 3, as it's not fully integrated with sklearn the oob_score is calculated using the whole data set which takes long time.
if using set_rf_samples() set oob_score=False",causing lesson fully calculated whole data set long time set,issue,negative,positive,neutral,neutral,positive,positive
428577486,"@sgugger you're correct. I was thinking that `x1,y1` and `x2,y2` should be `0.25` apart but it's actually `x1,x2` and `y1,y2` that should be and are `0.25` apart, which they are indeed. I plotted the points out now in a scatter plot. I'll close the issue. Sorry about that.",correct thinking apart actually apart indeed plotted scatter plot close issue sorry,issue,negative,negative,negative,negative,negative,negative
428427751,"not answering the PR, just commenting on a technical issue on our side: please ignore the 'failed' report, it's unrelated, I'm trying to figure out how to get CI to re-run the build check, but I was experimenting and deleted the build, now I know not to do that in the future, as it won't let me re-do it. you don't need to change anything, @kevinlu1211.",technical issue side please ignore report unrelated trying figure get build check build know future wo let need change anything,issue,negative,neutral,neutral,neutral,neutral,neutral
428403455,"Not sure what the bug is supposed to be. In your example, you show the coordinates are 0.25 apart (since its `y1` then `x1` then `y2` then `x2`). Could you precise a little bit more?
And glad I met you too :)",sure bug supposed example show apart since could precise little bit glad met,issue,positive,positive,positive,positive,positive,positive
428383607,"It's not core github, it's some kind of facebook bot pytorch is using. Can you help us find out how we go about doing the same? We sure thing would like to give as much fame as possible to the contributors.

I only found this https://github.com/facebook-github-bot, but it's a username. It appears to be some facebook internal thing as I can tell from https://hhvm.com/blog/5399/faster-github-commits. I can't find anything that is available outside of facebook.

Let us know what you find and let's take it from there. Thank you for investigating this.",core kind bot help u find go sure thing would like give much fame possible found internal thing tell ca find anything available outside let u know find let take thank investigating,issue,positive,positive,positive,positive,positive,positive
428359240,"I think it is well supported in github. See this screenshot.
<img width=""1036"" alt=""screen shot 2018-10-09 at 2 27 02 pm"" src=""https://user-images.githubusercontent.com/12021721/46699729-8d0e6600-cbcf-11e8-8b2a-a9046d8fe177.png"">
",think well see screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
428349598,"Please see and comment:
* fastai 0.7.x installation issues  [here](http://forums.fast.ai/t/fastai-v0-install-issues-thread/24652) .
* fastai 1.0.x installation issues   [here](http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111). ",please see comment installation installation,issue,negative,neutral,neutral,neutral,neutral,neutral
428336206,"I am getting the same error as mutcato, i have tried pip, conda, git but none of them worked.  is there a simple step by step installation for installing fastai on CPU?",getting error tried pip git none worked simple step step installation,issue,negative,neutral,neutral,neutral,neutral,neutral
428326548,"You need to add a few lines of code, yes, though you can refactor quite a bit your code:
`learn.get_preds()` would give you the outputs of the model concatenated. Then `F.softmax` can be used to compute the softmax before putting everything in results.
Please switch to the [forum](http://forums.fast.ai) if you have more questions.",need add code yes though quite bit code would give model used compute everything please switch forum,issue,positive,neutral,neutral,neutral,neutral,neutral
428321346,"Maybe the same for the vision classifier, in the MNIST and Cats or Dogs examples?",maybe vision classifier dog,issue,negative,neutral,neutral,neutral,neutral,neutral
428300485,"Wow, I'm glad to hear that it was so helpful :)",wow glad hear helpful,issue,positive,positive,positive,positive,positive,positive
428290278,"Good find! Your fix was causing a bug since we didn't update the content of __all__ (that wasn't throwing any errors since it was misspelled), which is why I added a commit.",good find fix causing bug since update content throwing since added commit,issue,positive,positive,positive,positive,positive,positive
428269410,"This may not be an issue as I've just seen that it takes 539 ms when you train on a subsample of the data and 3.49 s when you use set_rf_samples, as can be see in [Jeremy's notebook](https://github.com/fastai/fastai/blob/master/courses/ml1/lesson1-rf.ipynb).

 Why does this happen, anyway?",may issue seen train subsample data use see notebook happen anyway,issue,negative,neutral,neutral,neutral,neutral,neutral
428256641,"No, not even an acknowledgement. Neither for the original issue poster, nor for mine addition. The link is there in the first post so you can tell whether it was responded to or not.",even neither original issue poster mine addition link first post tell whether,issue,negative,positive,positive,positive,positive,positive
428195206,"It shouldn't necessarily be a mandatory param as sometimes, you might want to not validate. Though it's not best practice, so a simple warning should be enough.",necessarily mandatory param sometimes might want validate though best practice simple warning enough,issue,positive,positive,positive,positive,positive,positive
428190883,"No, that's because path is supposed to be Path object but we forgot the conversion. Solved [here](https://github.com/fastai/fastai/commit/448724df39923e70489ca4b9b980cd217bb527c9). Thanks for pointing the bug!",path supposed path object forgot conversion thanks pointing bug,issue,negative,positive,positive,positive,positive,positive
428171142,"It has been fixed recently (can't remember the number of the commit). If you install fastai in development mode and use the latest version you won't have that bug anymore. Otherwise, you'll have to wait for our next conda/pip release (try to update as well as it might already have been incorporated in the last version).",fixed recently ca remember number commit install development mode use latest version wo bug otherwise wait next release try update well might already incorporated last version,issue,positive,positive,positive,positive,positive,positive
428166544,@sgugger This should also crash fastai `tabular_data_from_df` function since `val_df` is a mandatory param. What do you think?,also crash function since mandatory param think,issue,negative,neutral,neutral,neutral,neutral,neutral
428073257,"Please suggest this idea to the github support. When we merge through github we only can press the [merge] button, there are no other options. See [Contact GitHub] link at the bottom of this page.
",please suggest idea support merge press merge button see contact link bottom page,issue,positive,neutral,neutral,neutral,neutral,neutral
428072011,"Alright, my bad. Somehow didn't see it. I still prefer the ""authored by .. and committed by .."" way of merging.",alright bad somehow see still prefer way,issue,negative,negative,negative,negative,negative,negative
428031778,"
@ncihnegn, your name is on it: https://github.com/fastai/fastai/commits?author=ncihnegn

![snap](https://user-images.githubusercontent.com/10676103/46642110-2c791d80-cb2a-11e8-8026-452c9ce9ac83.png)

it's just the way github does/shows PR merges - it shows a merge commit by the person who merged, and yet another commit with the original contribution. 

The snapshot is from [here](https://github.com/fastai/fastai/commits?after=8243143182cc60f2fac7cec122471b57f5192f92+34).",name snap way merge commit person yet another commit original contribution snapshot,issue,positive,positive,positive,positive,positive,positive
428029658,I can't continue to contribute if you don't even keep my name in the commit.,ca continue contribute even keep name commit,issue,negative,neutral,neutral,neutral,neutral,neutral
428014342,"It sounds like you have an incomplete install. dataclasses is installed automatically either via pip or conda dependencies. (unless it's python3.7 where it's built-in)

Make sure you follow the exact instructions at https://github.com/fastai/fastai/blob/master/README.md#installation

If the issue persists fastai v1 installation issues should be reported [here](http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111) instead. Thank you.",like incomplete install automatically either via pip unless python make sure follow exact issue installation instead thank,issue,positive,positive,positive,positive,positive,positive
427948898,"Done.

Yah, you are clear to fix the pad_collate unless you need anything else from me.",done yah clear fix unless need anything else,issue,negative,positive,positive,positive,positive,positive
427945761,That would be `pad_collate` messing around I guess. I can handle it when you're finished.,would messing around guess handle finished,issue,negative,neutral,neutral,neutral,neutral,neutral
427944667,"Makes sense.

Let me change that real quick and add that to the PR.

Also, any idea on why the batches returned from the DataLoader cast the floats back to ints?",sense let change real quick add also idea returned cast back,issue,negative,positive,positive,positive,positive,positive
427942469,"Clear_cache is nice. 
For the type, I'd rather have the dataset infer itself if it's a single class (n_labels=1) or multiclassification problem (n_labels >1), then cast the labels to the right type, than add yet another argument to the function. (This is to be consistent with tabular and vision.)
",nice type rather infer single class problem cast right type add yet another argument function consistent tabular vision,issue,negative,positive,positive,positive,positive,positive
427921409,Your change happens in line 362 because you didn't have my latest version of image.py (I did it this morning) so you overwrote it. Will fix that.,change line latest version morning fix,issue,negative,positive,positive,positive,positive,positive
427814173,"Bug is fixed [here](https://github.com/fastai/fastprogress/commit/e1951c2ae02d63a15c65130f4a406e3fcf4d52df). In the new version of fastprogress, there'll be a warning for empty generators instead of it crashing like this.",bug fixed new version warning empty instead like,issue,negative,positive,neutral,neutral,positive,positive
427810816,I didn't have the bug (which may due to the fact my pytorch is 0.4) but I think the fix from @ncihnegn  should work. Please reopen if it's not the case.,bug may due fact think fix work please reopen case,issue,negative,negative,negative,negative,negative,negative
427755634,"Found the issue. My `val_df` was empty. That's why `self.total` in `progress_bar` is 0. 

We should handle empty `dataframe` better to avoid such scenario. Basically if val_df is mandatory param, we should also make sure that its length is not zero.",found issue empty handle empty better avoid scenario basically mandatory param also make sure length zero,issue,negative,positive,positive,positive,positive,positive
427680048,"Oh, you're right! Thanks for pointing this out and finding the bug!",oh right thanks pointing finding bug,issue,negative,positive,positive,positive,positive,positive
427609054,"Sorry we overlapped on this one - just pushed the same feature! :) My approach doesn't make it part of `__init__`, but instead class authors override `_order` as needed. Not well tested at all (just check at least LRFinder still works), so do let us know if you see problems, or have ideas for improvements (preferably on the forums).",sorry one feature approach make part instead class override well tested check least still work let u know see preferably,issue,negative,negative,negative,negative,negative,negative
427604593,"Thanks for the idea; we're trying to keep the examples notebooks as simple as possible, so could you instead add this example to the docs (fastai_docs repo)?",thanks idea trying keep simple possible could instead add example,issue,negative,positive,neutral,neutral,positive,positive
427593006,"I have just made a new release to reflect the introduction of pytorch-nightly-cpu, please see [this](
https://github.com/fastai/fastai/blob/master/README.md#conda-install). It should solve this issue.
",made new release reflect introduction please see solve issue,issue,negative,positive,positive,positive,positive,positive
427591135,"BTW, CPU version of fastai/pytorch 1.0 is possible to install on Windows easily:

1) Install WSL with Ubuntu 18.04
2) Install Anaconda for Linux 
3) And then in bash made all the needed steps - install pytorch, fastai
4) start jupyter notebook
5) Use it anythere with any browser, even from outside with DDNS!

Unfortunately, GPU is not working this way as Cuda from WSL is not possible to access Nvidia driver in Windows (should be done soon)",version possible install easily install install anaconda bash made install start notebook use browser even outside unfortunately working way possible access driver done soon,issue,negative,negative,neutral,neutral,negative,negative
427590213,"Thank you for giving the exact context for the problem, @AirVetra. I now understand your report.

So as you discovered the problem is that your anaconda + jupyter set incorrectly the path to python in `jupyter\kernels\python3\kernel.json`. I'm pretty sure that if you repeat the same setup and don't involve fastai at all (i.e. just install anaconda + jupyter) you will have exactly the same issue. fastai is just a pure python module that can run on top of jupyter notebook but otherwise it doesn't touch the jupyter setup at all.

So you probably need to take this to jupyter team, and a quick search shows that other people have similar issues, e.g. [this](https://github.com/jupyter/notebook/issues/2563) - there are a few proposed solutions in there.",thank giving exact context problem understand report discovered problem anaconda set incorrectly path python pretty sure repeat setup involve install anaconda exactly issue pure python module run top notebook otherwise touch setup probably need take team quick search people similar,issue,positive,positive,positive,positive,positive,positive
427589702,"I've tried a few implementations but this one seems to change the whole file structure the least, and to define a callback with some priority still seems easy enough for the user. E.g. `NewCallback(priority=CallbackPriority.HIGH)`

I haven't included the `priority` argument in any of the `Callback` classes in the `fastai` folder, but rather the priority is set through the `super().__init__()`, though I'm not sure if this is correct, would be willing to change it if needed.",tried one change whole file structure least define priority still easy enough user included priority argument class folder rather priority set super though sure correct would willing change,issue,positive,positive,positive,positive,positive,positive
427586732,"@stas00
I've just installed latest Anaconda x64 for ""just me"", add Path... 
Launch once Anaconda to generate Anaconda prompt, 
launch Anaconda prompt as admin,  
cd fastai, 
git pull, 
conda env update (form my gpu PC), and conda env update -f environment-cpu.yml (for my CPU-only laptop) - I need to do it twice or three time as fiona and some other package failed scripto to be launched fully and when it completed successfully
conda activate fastai (fastai-cpu)
jupyter notebook
open some notebook from browser window with the list of the files

And both failed with kernel error (pls. see first message)

The log of the error is available on pressing red Kernel error button on the right upper corner of the window...
",latest anaconda add path launch anaconda generate anaconda prompt launch anaconda prompt git pull update form update need twice three time package fully successfully activate notebook open notebook browser window list kernel error see first message log error available pressing red kernel error button right upper corner window,issue,negative,positive,positive,positive,positive,positive
427585304,I've refactored a bit because there was no use keeping this n_labels parameter. Creating a label_cols and text_cols fields cover both use cases. It's testes on examples/text.ipynb but could you check it works on your examples of dataframes? I want to be sure I didn't break anything accidentally before merging.,bit use keeping parameter cover use testis could check work want sure break anything accidentally,issue,negative,positive,positive,positive,positive,positive
427582102,"Thanks for all the details. I'm afraid this won't be fixed in 0.7 as we've moved on to v1. You already have the language models there (a bit of rewrite is necessary since v1 isn't backward compatible) and SWA will soon be implemented (I think it's also a pytorch optimizer now, if that helps).",thanks afraid wo fixed already language bit rewrite necessary since backward compatible swa soon think also,issue,negative,negative,neutral,neutral,negative,negative
427579255,"Since it's a deep copy I realized might be worth copying whole stacktrace: https://pastebin.com/3yW7mi1A

Moreover, it seems to appear from here https://github.com/pytorch/pytorch/blob/5760b036fb338eacd641418321f23aee51b1aee9/torch/autograd/variable.py#L89-L97",since deep copy might worth whole moreover appear,issue,negative,positive,positive,positive,positive,positive
427546979,"Ah, I see.  After I changed it worked.  I made the change by `learner.loss_fn = nn.BCEWithLogitsLoss()` after creating a Convlearner object.  Is this the way it should be done, or is there a better way to do it?",ah see worked made change object way done better way,issue,negative,positive,positive,positive,positive,positive
427544155,"Thanks that looks on the right track. There is a list of setup resources here: https://github.com/reshamas/fastai_deeplearn_part1 .

It would be best to have the main ones (AWS, GCP, Colab, Paperspace, Crestle) all in one place, rather than only discussing Crestle here. Also, best not using imgur - instead, create a course/images/ folder and put your images there. Thanks!",thanks right track list setup would best main one place rather also best instead create folder put thanks,issue,positive,positive,positive,positive,positive,positive
427543861,"Hi there, this is because you shouldn't use F.cross_entropy for multi-label problems (since it has a softmax that will tend to make one activation 1 and all the others 0) but F.binary_cross_with_logits (since it has a sigmoid that can make any final activation 0 or 1).
The latter expects float.",hi use since tend make one activation since sigmoid make final activation latter float,issue,negative,neutral,neutral,neutral,neutral,neutral
427492579,@stas00 your commit fixed conda env update again ! thanks ,commit fixed update thanks,issue,positive,positive,positive,positive,positive,positive
427490019,"Thank you for the heads up and the patch, @wontheone1.

Indeed conda doesn't yet have 0.4.2 (pip does), so we have to downgrade it instead until the fixed testpath is released on conda. There is a big problem with 0.4.1. I applied the correct fix https://github.com/fastai/fastai/commit/f221e72ed97d86cfd3bc4f1bfbd9800121116ce7

",thank patch indeed yet pip downgrade instead fixed big problem applied correct fix,issue,negative,positive,neutral,neutral,positive,positive
427447257,Just made a few stylistic changes but it seems to work well. Thanks!,made stylistic work well thanks,issue,positive,positive,positive,positive,positive,positive
427439393,"@king-menin The lib is rapidly developed :) However, the code is quite modular and could be replaced with a custom solution if there is a need.",rapidly however code quite modular could custom solution need,issue,negative,neutral,neutral,neutral,neutral,neutral
427425540,The scripts are for the old version of the library (0.7) so you should use that version. Installation instructions are [here](https://github.com/fastai/fastai/tree/master/old).,old version library use version installation,issue,negative,positive,neutral,neutral,positive,positive
427425022,"Yes, we can do that for old fastai. Feel free to propose a PR with your fix!",yes old feel free propose fix,issue,positive,positive,positive,positive,positive,positive
427422682,"@AirVetra, it's hard to tell what you were doing when you encountered this error. Can you please paste the complete set of commands you executed when installing fastai-0.7.x and also where is this stack trace coming from, jupyter logs? were you just starting `jupyter notebook` or running a specific notebook (which then). Thanks.",hard tell error please paste complete set executed also stack trace coming starting notebook running specific notebook thanks,issue,negative,positive,neutral,neutral,positive,positive
427403931,"Is right, that imdb_scripts have already useless? In this case I could not find LanguageModelData and LanguageModel if fastai files :(.",right already useless case could find,issue,negative,negative,negative,negative,negative,negative
427388564,"I had a similar error when I tried to download spacy from the web and run in windows. 

I downloaded the English version using the below command and it works fine now. 
python -m spacy download en",similar error tried spacy web run version command work fine python spacy en,issue,negative,positive,positive,positive,positive,positive
427385670,"I think you need to wrap your data into `TextDataset` class, as constructor's type annotation suggests.",think need wrap data class constructor type annotation,issue,negative,neutral,neutral,neutral,neutral,neutral
427361415,"I made it!!!

in C:\Users\airve\Anaconda3\envs\fastai-cpu\share\jupyter\kernels\python3\kernel.json

there was a misleading path to python!!! Made it bold - just deleted it and everything works!!!
So, seems someone changed it in the script and not right path is written... 

Pls. check my solution...

{
 ""argv"": [
  ""C:/Users/airve/Anaconda3/envs/fastai-cpu/**bin/**python"",
  ""-m"",
  ""ipykernel_launcher"",
  ""-f"",
  ""{connection_file}""
 ],
 ""display_name"": ""Python 3"",
 ""language"": ""python""
}
",made misleading path python made bold everything work someone script right path written check solution python python language python,issue,negative,positive,positive,positive,positive,positive
427355269,"~~It seems like you're running `fastai <= 1.0`, I think that new RNN base class should appropriately initialize hidden state?~~

Ah, though you mean, you would like to access hidden state _right after_ object initialization. However, this attribute is created after the very first `forward()` call, right? Do we really need to access this attribute before the very first pass through model is completed?",like running think new base class appropriately initialize hidden state ah though mean would like access hidden state object however attribute first forward call right really need access attribute first pas model,issue,positive,positive,neutral,neutral,positive,positive
427352796,"I have the same issue when I am trying to build Dockerfile provided by nji-syd
[https://github.com/nji-syd/fastai-docker/blob/master/fastai.latest.cuda9](url)
The error is on line `RUN cd /usr/local/fastai && conda env update -f environment.yml `
",issue trying build provided error line run update,issue,negative,neutral,neutral,neutral,neutral,neutral
427236656,"As explained in the [forum](http://forums.fast.ai/t/moving-the-fastai-0-7-folder-do-not-use-pip-for-the-course/23667/9) if you want to have access to the old library to do the old courses, you shouldn't pip install. ",forum want access old library old pip install,issue,negative,positive,neutral,neutral,positive,positive
427211971,"Python 3.6 actually. `learn.metrics = []` works, but then I don't get nice metrics... and if I try and use metrics, it fails. ",python actually work get nice metric try use metric,issue,negative,positive,positive,positive,positive,positive
427161998,I have just updated https://github.com/fastai/fastai/blob/master/README.md to separate pytorch installation from fastai - so it'll be much easier to debug the issue.,separate installation much easier issue,issue,negative,positive,positive,positive,positive,positive
427158700,"fastai is pure python. Once you have pytorch installed, you can install fastai both from source or prepackaged via conda/pip, please see:  https://github.com/fastai/fastai/blob/master/README.md",pure python install source via please see,issue,negative,positive,positive,positive,positive,positive
427157798,Aah. I will try to build from source then. I believe I will need to build both pytorch preview version and fast AI build from source right?,try build source believe need build preview version fast ai build source right,issue,negative,positive,positive,positive,positive,positive
427141179,"Apparently it may take a few months. Or you can build it from source.
",apparently may take build source,issue,negative,positive,neutral,neutral,positive,positive
427140422,Thanks. My platform is windows. So I guess I will have to wait until pytorch preview is supported in Windows. ,thanks platform guess wait preview,issue,negative,positive,positive,positive,positive,positive
427137798,"@faizan2786, I addressed this issue here http://forums.fast.ai/t/fastai-v1-install-issues-thread/24111
Please follow up in the thread. Thank you.
",issue please follow thread thank,issue,positive,neutral,neutral,neutral,neutral,neutral
427046424,"This is intended, since you shouldn't use nll_loss/cross_entropy for multiclassification (it's a softmax) but binary_cross_entropy_with_logits (to have the sigmoid). This one won't give you an error.
See the [pascal dev notebook](https://github.com/fastai/fastai_docs/blob/master/dev_nb/005b_planet.ipynb).",intended since use sigmoid one wo give error see dev notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
427035053,"I had the same problem when trying to import fastai. Actually you have to update your ipython:

- conda update ipython",problem trying import actually update update,issue,negative,neutral,neutral,neutral,neutral,neutral
427010628,"hi, that is because almost all the pretrained models provided by PyTorch are trained by 3-channel images.",hi almost provided trained,issue,negative,neutral,neutral,neutral,neutral,neutral
426947379,Just saw that the courses use the 0.7 version and the conda update install method. Should have read the Readme properly. Sorry.,saw use version update install method read properly sorry,issue,negative,negative,negative,negative,negative,negative
426941287,"What happens if you add `log_output=True` to `tabular_data_from_df` and change `layers` argument to `[200, 1]`?

**Edit:**

Or if you don't want `log_output=True`, you can hack at it this way:

    def myloss(input, target): return F.mse_loss(input, target.float())
    learn.loss_fn = myloss

Not sure where to tell the learner that it is a regression model.",add change argument edit want hack way input target return input sure tell learner regression model,issue,negative,positive,positive,positive,positive,positive
426885110,"It should be installed without the version number.

`conda install -c pytorch -c fastai fastai pytorch-nightly-cpu`",without version number install,issue,negative,neutral,neutral,neutral,neutral,neutral
426852577,Please post it in another issue with the exact steps you did and the outputs/errors you received and we will debug that. Thank you.,please post another issue exact received thank,issue,positive,positive,positive,positive,positive,positive
426852185,"By the way, when using pip and following the instructions to install dev, there are errors running
`tools/run-after-git-clone` because, with pip install, python is not in `#!/usr/bin/env python`.  Even if you remove the line in all scripts, it still does not work. But this is another issue ;-)

",way pip following install dev running pip install python python even remove line still work another issue,issue,negative,neutral,neutral,neutral,neutral,neutral
426851895,"Yay, thank you very much for helping to debug it, Fred. I will fix the doc shortly.",thank much helping fix doc shortly,issue,positive,positive,neutral,neutral,positive,positive
426851113,"I guess it did the trick, I don't see torch in this install:

```
Successfully installed MarkupSafe-1.0 Send2Trash-1.5.0 backcall-0.1.0 bleach-3.0.0 certifi-2018.8.24 chardet-3.0.4 cycler-0.10.0 cymem-1.31.2 cytoolz-0.9.0.1 dataclasses-0.6 decorator-4.3.0 defusedxml-0.5.0 dill-0.2.8.2 entrypoints-0.2.3 fastai-1.0.3 fastprogress-0.1.9 idna-2.7 ipykernel-5.0.0 ipython-7.0.1 ipython-genutils-0.2.0 ipywidgets-7.4.2 jedi-0.13.1 jinja2-2.10 jsonschema-2.6.0 jupyter-1.0.0 jupyter-client-5.2.3 jupyter-console-6.0.0 jupyter-core-4.4.0 kiwisolver-1.0.1 matplotlib-3.0.0 mistune-0.8.3 msgpack-0.5.6 msgpack-numpy-0.4.4.1 murmurhash-0.28.0 nbconvert-5.4.0 nbformat-4.4.0 notebook-5.7.0 numpy-1.15.2 pandas-0.23.4 pandocfilters-1.4.2 parso-0.3.1 pexpect-4.6.0 pickleshare-0.7.5 pillow-5.3.0 plac-0.9.6 preshed-1.0.1 prometheus-client-0.4.0 prompt-toolkit-2.0.5 ptyprocess-0.6.0 pygments-2.2.0 pyparsing-2.2.2 python-dateutil-2.7.3 pytz-2018.5 pyzmq-17.1.2 qtconsole-4.4.1 regex-2017.4.5 requests-2.19.1 scipy-1.1.0 setuptools-40.4.3 simplegeneric-0.8.1 six-1.11.0 spacy-2.0.12 terminado-0.8.1 testpath-0.4.2 thinc-6.10.3 toolz-0.9.0 torchvision-0.2.1.post1 tornado-5.1.1 tqdm-4.26.0 traitlets-4.3.2 typing-3.6.6 ujson-1.35 urllib3-1.23 wcwidth-0.1.7 webencodings-0.5.1 widgetsnbextension-3.4.2 wrapt-1.10.11

```

",guess trick see torch install successfully post,issue,negative,positive,positive,positive,positive,positive
426850993,"OK, added the extra `.` in the torchvision version. Please try with:

    pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ torchvision==0.2.1.post2
    pip install fastai

Thank you.
",added extra version please try pip install post pip install thank,issue,positive,neutral,neutral,neutral,neutral,neutral
426848668,"Awesome!

So it's fastai's dependencies try to get torchvision>=0.2.1, even though it's already installed. 

```
Collecting torchvision>=0.2.1 (from fastai)
  Using cached https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl
```

Unless it thinks torchvision-0.2.1post1 < torchvision-0.2.1.
I see, I most likely need to make it into torchvision-0.2.1.post1 (extra dot)
https://www.python.org/dev/peps/pep-0440/#version-matching

I suppose that if you were to do:

    pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ torchvision==0.2.1.post1 fastai

it'd still try to fetch torchvision==0.2.1 too (which would trigger torch-0.4.1)? Can you give it a try please?

Meanwhile I will research how to get the exact deps from pip's server, in pre-installed stage.

",awesome try get even though already unless post see likely need make post extra dot suppose pip install post still try fetch would trigger give try please meanwhile research get exact pip server stage,issue,positive,positive,positive,positive,positive,positive
426847058,"I guess it got the right torchvision version, the problem was afterwards in `pip install fastai` which fetched torch-0.4.1.

I surely can copy paste the result here:
`$ pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ torchvision==0.2.1.post1`
```
Collecting torchvision==0.2.1.post1
  Using cached https://test-files.pythonhosted.org/packages/4f/55/0c30e6f6ba5073bf48b69e286540b56a82751275624da10f184c10cf972c/torchvision-0.2.1.post1-py2.py3-none-any.whl
Collecting tqdm (from torchvision==0.2.1.post1)
  Using cached https://files.pythonhosted.org/packages/79/43/19c9fee28110cd47f73e6bc596394337fe9f3e5825b4de402bbf30b3beb5/tqdm-4.26.0-py2.py3-none-any.whl
Collecting numpy (from torchvision==0.2.1.post1)
  Using cached https://files.pythonhosted.org/packages/22/02/bae88c4aaea4256d890adbf3f7cf33e59a443f9985cf91cd08a35656676a/numpy-1.15.2-cp36-cp36m-manylinux1_x86_64.whl
Collecting six (from torchvision==0.2.1.post1)
  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl
Collecting pillow>=4.1.1 (from torchvision==0.2.1.post1)
  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl
Installing collected packages: tqdm, numpy, six, pillow, torchvision
Successfully installed numpy-1.15.2 pillow-5.3.0 six-1.11.0 torchvision-0.2.1.post1 tqdm-4.26.0

```
Then:
`$ pip install fastai`
```
Collecting fastai
  Using cached https://files.pythonhosted.org/packages/50/8d/ce3b0649528942c537219a8bcea2edc5e2c057298c6796d4af6d3c1821e9/fastai-1.0.3-py3-none-any.whl
Collecting fastprogress>=0.1.9 (from fastai)
  Using cached https://files.pythonhosted.org/packages/ff/26/489ef5d95de3983edf89a646ceb32d9746ad56f074194349e1d1a974c17d/fastprogress-0.1.9-py3-none-any.whl
Collecting scipy (from fastai)
  Using cached https://files.pythonhosted.org/packages/a8/0b/f163da98d3a01b3e0ef1cab8dd2123c34aee2bafbb1c5bffa354cc8a1730/scipy-1.1.0-cp36-cp36m-manylinux1_x86_64.whl
Collecting spacy (from fastai)
Collecting matplotlib (from fastai)
  Using cached https://files.pythonhosted.org/packages/ed/89/dd823436a5f8d5ca9304b51b554863bfd366ca84708d5812f5ee87c923bc/matplotlib-3.0.0-cp36-cp36m-manylinux1_x86_64.whl
Collecting dataclasses (from fastai)
  Using cached https://files.pythonhosted.org/packages/26/2f/1095cdc2868052dd1e64520f7c0d5c8c550ad297e944e641dbf1ffbb9a5d/dataclasses-0.6-py3-none-any.whl
Collecting typing (from fastai)
  Using cached https://files.pythonhosted.org/packages/4a/bd/eee1157fc2d8514970b345d69cb9975dcd1e42cd7e61146ed841f6e68309/typing-3.6.6-py3-none-any.whl
Collecting torchvision>=0.2.1 (from fastai)
  Using cached https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl
Collecting Pillow (from fastai)
  Using cached https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl
Collecting ipython (from fastai)
  Using cached https://files.pythonhosted.org/packages/a0/27/29d66ed395a5c2c3a912332d446a54e2bc3277c36b0bbd22bc71623e0193/ipython-7.0.1-py3-none-any.whl
Collecting requests (from fastai)
  Using cached https://files.pythonhosted.org/packages/65/47/7e02164a2a3db50ed6d8a6ab1d6d60b69c4c3fdf57a284257925dfc12bda/requests-2.19.1-py2.py3-none-any.whl
Collecting pandas (from fastai)
  Using cached https://files.pythonhosted.org/packages/e1/d8/feeb346d41f181e83fba45224ab14a8d8af019b48af742e047f3845d8cff/pandas-0.23.4-cp36-cp36m-manylinux1_x86_64.whl
Collecting numpy>=1.12 (from fastai)
  Using cached https://files.pythonhosted.org/packages/22/02/bae88c4aaea4256d890adbf3f7cf33e59a443f9985cf91cd08a35656676a/numpy-1.15.2-cp36-cp36m-manylinux1_x86_64.whl
Collecting jupyter (from fastai)
  Using cached https://files.pythonhosted.org/packages/83/df/0f5dd132200728a86190397e1ea87cd76244e42d39ec5e88efd25b2abd7e/jupyter-1.0.0-py2.py3-none-any.whl
Collecting cymem<1.32,>=1.30 (from spacy->fastai)
Collecting preshed<2.0.0,>=1.0.0 (from spacy->fastai)
Collecting thinc<6.11.0,>=6.10.3 (from spacy->fastai)
Collecting plac<1.0.0,>=0.9.6 (from spacy->fastai)
  Using cached https://files.pythonhosted.org/packages/9e/9b/62c60d2f5bc135d2aa1d8c8a86aaf84edb719a59c7f11a4316259e61a298/plac-0.9.6-py2.py3-none-any.whl
Collecting regex==2017.4.5 (from spacy->fastai)
Collecting murmurhash<0.29,>=0.28 (from spacy->fastai)
Collecting ujson>=1.35 (from spacy->fastai)
Collecting dill<0.3,>=0.2 (from spacy->fastai)
Collecting python-dateutil>=2.1 (from matplotlib->fastai)
  Using cached https://files.pythonhosted.org/packages/cf/f5/af2b09c957ace60dcfac112b669c45c8c97e32f94aa8b56da4c6d1682825/python_dateutil-2.7.3-py2.py3-none-any.whl
Collecting cycler>=0.10 (from matplotlib->fastai)
  Using cached https://files.pythonhosted.org/packages/f7/d2/e07d3ebb2bd7af696440ce7e754c59dd546ffe1bbe732c8ab68b9c834e61/cycler-0.10.0-py2.py3-none-any.whl
Collecting pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 (from matplotlib->fastai)
  Using cached https://files.pythonhosted.org/packages/2b/4a/f06b45ab9690d4c37641ec776f7ad691974f4cf6943a73267475b05cbfca/pyparsing-2.2.2-py2.py3-none-any.whl
Collecting kiwisolver>=1.0.1 (from matplotlib->fastai)
  Using cached https://files.pythonhosted.org/packages/69/a7/88719d132b18300b4369fbffa741841cfd36d1e637e1990f27929945b538/kiwisolver-1.0.1-cp36-cp36m-manylinux1_x86_64.whl
Collecting six (from torchvision>=0.2.1->fastai)
  Using cached https://files.pythonhosted.org/packages/67/4b/141a581104b1f6397bfa78ac9d43d8ad29a7ca43ea90a2d863fe3056e86a/six-1.11.0-py2.py3-none-any.whl
Collecting torch (from torchvision>=0.2.1->fastai)
  Using cached https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl
Collecting jedi>=0.10 (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/7a/1a/9bd24a185873b998611c2d8d4fb15cd5e8a879ead36355df7ee53e9111bf/jedi-0.13.1-py2.py3-none-any.whl
Collecting simplegeneric>0.8 (from ipython->fastai)
Collecting backcall (from ipython->fastai)
Collecting pickleshare (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/9a/41/220f49aaea88bc6fa6cba8d05ecf24676326156c23b991e80b3f2fc24c77/pickleshare-0.7.5-py2.py3-none-any.whl
Collecting traitlets>=4.2 (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/93/d6/abcb22de61d78e2fc3959c964628a5771e47e7cc60d53e9342e21ed6cc9a/traitlets-4.3.2-py2.py3-none-any.whl
Collecting pygments (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/02/ee/b6e02dc6529e82b75bb06823ff7d005b141037cb1416b10c6f00fc419dca/Pygments-2.2.0-py2.py3-none-any.whl
Collecting prompt-toolkit<2.1.0,>=2.0.0 (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/e5/c5/f1ee6698bdcf615f171a77e81ca70293b16a6d82285f1760b388b4348263/prompt_toolkit-2.0.5-py3-none-any.whl
Collecting setuptools>=18.5 (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/96/06/c8ee69628191285ddddffb277bd5abdf769166e7a14b867c2a172f0175b1/setuptools-40.4.3-py2.py3-none-any.whl
Collecting pexpect; sys_platform != ""win32"" (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/89/e6/b5a1de8b0cc4e07ca1b305a4fcc3f9806025c1b651ea302646341222f88b/pexpect-4.6.0-py2.py3-none-any.whl
Collecting decorator (from ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/bc/bb/a24838832ba35baf52f32ab1a49b906b5f82fb7c76b2f6a7e35e140bac30/decorator-4.3.0-py2.py3-none-any.whl
Collecting certifi>=2017.4.17 (from requests->fastai)
  Using cached https://files.pythonhosted.org/packages/df/f7/04fee6ac349e915b82171f8e23cee63644d83663b34c539f7a09aed18f9e/certifi-2018.8.24-py2.py3-none-any.whl
Collecting urllib3<1.24,>=1.21.1 (from requests->fastai)
  Using cached https://files.pythonhosted.org/packages/bd/c9/6fdd990019071a4a32a5e7cb78a1d92c53851ef4f56f62a3486e6a7d8ffb/urllib3-1.23-py2.py3-none-any.whl
Collecting chardet<3.1.0,>=3.0.2 (from requests->fastai)
  Using cached https://files.pythonhosted.org/packages/bc/a9/01ffebfb562e4274b6487b4bb1ddec7ca55ec7510b22e4c51f14098443b8/chardet-3.0.4-py2.py3-none-any.whl
Collecting idna<2.8,>=2.5 (from requests->fastai)
  Using cached https://files.pythonhosted.org/packages/4b/2a/0276479a4b3caeb8a8c1af2f8e4355746a97fab05a372e4a2c6a6b876165/idna-2.7-py2.py3-none-any.whl
Collecting pytz>=2011k (from pandas->fastai)
  Using cached https://files.pythonhosted.org/packages/30/4e/27c34b62430286c6d59177a0842ed90dc789ce5d1ed740887653b898779a/pytz-2018.5-py2.py3-none-any.whl
Collecting ipykernel (from jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/ec/19/b18f4c48ea6043921fe1b689ff0a912e066927b25bb0c17a58f7274f4880/ipykernel-5.0.0-py3-none-any.whl
Collecting notebook (from jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/44/16/9f108b675828c4117cfe72d8d0f97094163c40584e40c46ec48a1e862693/notebook-5.7.0-py2.py3-none-any.whl
Collecting nbconvert (from jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/b5/bb/94c493051d60e5b9c0f7f9a368b324201818c1b1c4cae85d1e49a41846c7/nbconvert-5.4.0-py2.py3-none-any.whl
Collecting jupyter-console (from jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/cb/ee/6374ae8c21b7d0847f9c3722dcdfac986b8e54fa9ad9ea66e1eb6320d2b8/jupyter_console-6.0.0-py2.py3-none-any.whl
Collecting ipywidgets (from jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/30/9a/a008c7b1183fac9e52066d80a379b3c64eab535bd9d86cdc29a0b766fd82/ipywidgets-7.4.2-py2.py3-none-any.whl
Collecting qtconsole (from jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/ff/1f/b340d52dee46fbbe8a097dce76d1197258bb599692159d94c80921fef9eb/qtconsole-4.4.1-py2.py3-none-any.whl
Collecting wrapt<1.11.0,>=1.10.0 (from thinc<6.11.0,>=6.10.3->spacy->fastai)
Collecting tqdm<5.0.0,>=4.10.0 (from thinc<6.11.0,>=6.10.3->spacy->fastai)
  Using cached https://files.pythonhosted.org/packages/79/43/19c9fee28110cd47f73e6bc596394337fe9f3e5825b4de402bbf30b3beb5/tqdm-4.26.0-py2.py3-none-any.whl
Collecting cytoolz<0.10,>=0.9.0 (from thinc<6.11.0,>=6.10.3->spacy->fastai)
Collecting msgpack<1.0.0,>=0.5.6 (from thinc<6.11.0,>=6.10.3->spacy->fastai)
  Using cached https://files.pythonhosted.org/packages/22/4e/dcf124fd97e5f5611123d6ad9f40ffd6eb979d1efdc1049e28a795672fcd/msgpack-0.5.6-cp36-cp36m-manylinux1_x86_64.whl
Collecting msgpack-numpy<1.0.0,>=0.4.1 (from thinc<6.11.0,>=6.10.3->spacy->fastai)
  Using cached https://files.pythonhosted.org/packages/bb/a9/2a28ef55c9b2c197d8531bb9c05adce2ba454d37ca8d26c1d421c4945b0d/msgpack_numpy-0.4.4.1-py2.py3-none-any.whl
Collecting parso>=0.3.0 (from jedi>=0.10->ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/09/51/9c48a46334be50c13d25a3afe55fa05c445699304c5ad32619de953a2305/parso-0.3.1-py2.py3-none-any.whl
Collecting ipython-genutils (from traitlets>=4.2->ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/fa/bc/9bd3b5c2b4774d5f33b2d544f1460be9df7df2fe42f352135381c347c69a/ipython_genutils-0.2.0-py2.py3-none-any.whl
Collecting wcwidth (from prompt-toolkit<2.1.0,>=2.0.0->ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/7e/9f/526a6947247599b084ee5232e4f9190a38f398d7300d866af3ab571a5bfe/wcwidth-0.1.7-py2.py3-none-any.whl
Collecting ptyprocess>=0.5 (from pexpect; sys_platform != ""win32""->ipython->fastai)
  Using cached https://files.pythonhosted.org/packages/d1/29/605c2cc68a9992d18dada28206eeada56ea4bd07a239669da41674648b6f/ptyprocess-0.6.0-py2.py3-none-any.whl
Collecting tornado>=4.2 (from ipykernel->jupyter->fastai)
Collecting jupyter-client (from ipykernel->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/94/dd/fe6c4d683b09eb05342bd2816b7779663f71762b4fa9c2d5203d35d17354/jupyter_client-5.2.3-py2.py3-none-any.whl
Collecting nbformat (from notebook->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/da/27/9a654d2b6cc1eaa517d1c5a4405166c7f6d72f04f6e7eea41855fe808a46/nbformat-4.4.0-py2.py3-none-any.whl
Collecting prometheus-client (from notebook->jupyter->fastai)
Collecting pyzmq>=17 (from notebook->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/48/93/59592cb294761aaa40589b544eaa5175446d687ff95beeeb666de60f3274/pyzmq-17.1.2-cp36-cp36m-manylinux1_x86_64.whl
Collecting terminado>=0.8.1 (from notebook->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/2e/20/a26211a24425923d46e1213b376a6ee60dc30bcdf1b0c345e2c3769deb1c/terminado-0.8.1-py2.py3-none-any.whl
Collecting jupyter-core>=4.4.0 (from notebook->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/1d/44/065d2d7bae7bebc06f1dd70d23c36da8c50c0f08b4236716743d706762a8/jupyter_core-4.4.0-py2.py3-none-any.whl
Collecting jinja2 (from notebook->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/7f/ff/ae64bacdfc95f27a016a7bed8e8686763ba4d277a78ca76f32659220a731/Jinja2-2.10-py2.py3-none-any.whl
Collecting Send2Trash (from notebook->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/49/46/c3dc27481d1cc57b9385aff41c474ceb7714f7935b1247194adae45db714/Send2Trash-1.5.0-py3-none-any.whl
Collecting testpath (from nbconvert->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/be/a4/162f9ebb6489421fe46dcca2ae420369edfee4b563c668d93cb4605d12ba/testpath-0.4.2-py2.py3-none-any.whl
Collecting entrypoints>=0.2.2 (from nbconvert->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/cc/8b/4eefa9b47f1910b3d2081da67726b066e379b04ca897acfe9f92bac56147/entrypoints-0.2.3-py2.py3-none-any.whl
Collecting bleach (from nbconvert->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/dc/c3/e5390ba91caf85350abedefdb11bc5fee00d7081b61909122c2d408cd6e4/bleach-3.0.0-py2.py3-none-any.whl
Collecting pandocfilters>=1.4.1 (from nbconvert->jupyter->fastai)
Collecting defusedxml (from nbconvert->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/87/1c/17f3e3935a913dfe2a5ca85fa5ccbef366bfd82eb318b1f75dadbf0affca/defusedxml-0.5.0-py2.py3-none-any.whl
Collecting mistune>=0.8.1 (from nbconvert->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/c8/8c/87f4d359438ba0321a2ae91936030110bfcc62fef752656321a72b8c1af9/mistune-0.8.3-py2.py3-none-any.whl
Collecting widgetsnbextension~=3.4.0 (from ipywidgets->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/8a/81/35789a3952afb48238289171728072d26d6e76649ddc8b3588657a2d78c1/widgetsnbextension-3.4.2-py2.py3-none-any.whl
Collecting toolz>=0.8.0 (from cytoolz<0.10,>=0.9.0->thinc<6.11.0,>=6.10.3->spacy->fastai)
Collecting jsonschema!=2.5.0,>=2.4 (from nbformat->notebook->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/77/de/47e35a97b2b05c2fadbec67d44cfcdcd09b8086951b331d82de90d2912da/jsonschema-2.6.0-py2.py3-none-any.whl
Collecting MarkupSafe>=0.23 (from jinja2->notebook->jupyter->fastai)
Collecting webencodings (from bleach->nbconvert->jupyter->fastai)
  Using cached https://files.pythonhosted.org/packages/f4/24/2a3e3df732393fed8b3ebf2ec078f05546de641fe1b667ee316ec1dcf3b7/webencodings-0.5.1-py2.py3-none-any.whl
Installing collected packages: fastprogress, numpy, scipy, cymem, preshed, wrapt, dill, tqdm, toolz, cytoolz, plac, murmurhash, six, msgpack, msgpack-numpy, thinc, regex, ujson, certifi, urllib3, chardet, idna, requests, spacy, python-dateutil, cycler, pyparsing, setuptools, kiwisolver, matplotlib, dataclasses, typing, Pillow, torch, torchvision, parso, jedi, simplegeneric, backcall, pickleshare, ipython-genutils, decorator, traitlets, pygments, wcwidth, prompt-toolkit, ptyprocess, pexpect, ipython, pytz, pandas, tornado, pyzmq, jupyter-core, jupyter-client, ipykernel, jsonschema, nbformat, testpath, entrypoints, webencodings, bleach, pandocfilters, defusedxml, MarkupSafe, jinja2, mistune, nbconvert, prometheus-client, terminado, Send2Trash, notebook, jupyter-console, widgetsnbextension, ipywidgets, qtconsole, jupyter, fastai
Successfully installed MarkupSafe-1.0 Pillow-5.3.0 Send2Trash-1.5.0 backcall-0.1.0 bleach-3.0.0 certifi-2018.8.24 chardet-3.0.4 cycler-0.10.0 cymem-1.31.2 cytoolz-0.9.0.1 dataclasses-0.6 decorator-4.3.0 defusedxml-0.5.0 dill-0.2.8.2 entrypoints-0.2.3 fastai-1.0.3 fastprogress-0.1.9 idna-2.7 ipykernel-5.0.0 ipython-7.0.1 ipython-genutils-0.2.0 ipywidgets-7.4.2 jedi-0.13.1 jinja2-2.10 jsonschema-2.6.0 jupyter-1.0.0 jupyter-client-5.2.3 jupyter-console-6.0.0 jupyter-core-4.4.0 kiwisolver-1.0.1 matplotlib-3.0.0 mistune-0.8.3 msgpack-0.5.6 msgpack-numpy-0.4.4.1 murmurhash-0.28.0 nbconvert-5.4.0 nbformat-4.4.0 notebook-5.7.0 numpy-1.15.2 pandas-0.23.4 pandocfilters-1.4.2 parso-0.3.1 pexpect-4.6.0 pickleshare-0.7.5 plac-0.9.6 preshed-1.0.1 prometheus-client-0.4.0 prompt-toolkit-2.0.5 ptyprocess-0.6.0 pygments-2.2.0 pyparsing-2.2.2 python-dateutil-2.7.3 pytz-2018.5 pyzmq-17.1.2 qtconsole-4.4.1 regex-2017.4.5 requests-2.19.1 scipy-1.1.0 setuptools-40.4.3 simplegeneric-0.8.1 six-1.11.0 spacy-2.0.12 terminado-0.8.1 testpath-0.4.2 thinc-6.10.3 toolz-0.9.0 torch-0.4.1 torchvision-0.2.1.post1 tornado-5.1.1 tqdm-4.26.0 traitlets-4.3.2 typing-3.6.6 ujson-1.35 urllib3-1.23 wcwidth-0.1.7 webencodings-0.5.1 widgetsnbextension-3.4.2 wrapt-1.10.11

```

",guess got right version problem afterwards pip install fetched surely copy paste result pip install post post post post six post pillow post collected six pillow successfully post pip install spacy pillow dill cycler six torch win decorator notebook win tornado jinja bleach collected dill six spacy cycler pillow torch decorator tornado bleach jinja notebook successfully post,issue,positive,positive,positive,positive,positive,positive
426846046,"Thank you for the clarification, @fredguth.

You mean, you did:

    pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ torchvision==0.2.1.post1

and it ignored the fact that it was told to install specifically this version of the package? Can you please show the full output of that command above?

oh, wait, I see from your logs that it did install torchvision==0.2.1.post1, yet it fetched torch-0.4.1 - odd - I removed torch from its requirements, so it shouldn't want that dependecy at all... perhaps some previous uninstalls were incomplete?
",thank clarification mean pip install post fact told install specifically version package please show full output command oh wait see install post yet fetched odd removed torch want perhaps previous incomplete,issue,negative,negative,neutral,neutral,negative,negative
426845286,"Sorry, I understood you wrongly.  Yes I did this step. No problem, it ""worked"" (in the sense it didn't brake). After installation of `torchvision` it says:  

> Successfully installed ... torch-0.4.1 torchvision-0.2.1.post1

But as it shows it installed torch-0.4.1, I then proceed to the other option:
`pip uninstall torchvision fastai` and then `pip install --no-deps torchvision`, which finishes with: 

> Successfully installed torchvision-0.2.1

Then `pip install fastai`
> Successfully installed ... fastai-1.0.3 fastprogress-0.1.9 idna-2.7 ... torch-0.4.1 torchvision-0.2.1 tornado-5.1.1

I understood that this is wrong, isn't  it?
",sorry understood wrongly yes step problem worked sense brake installation successfully post proceed option pip pip install successfully pip install successfully understood wrong,issue,positive,positive,positive,positive,positive,positive
426844011,"That's not what the documentation says, the 2nd step is:

     pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org/simple/ torchvision==0.2.1.post1

Any change if you do that?

The ""normal"" `torchvision` will always try to fetch torch-0.4.1. Hence we released that hacked version which has the dependency adjusted. ",documentation step pip install post change normal always try fetch hence hacked version dependency,issue,negative,positive,positive,positive,positive,positive
426843178,"That is exactly what I did, the only difference is that I have cuda 9.0 installed, so I changed to:
`pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html`
Important notice, everything installed ok.  The only ""problem"" is that I saw that fastai installation used torch-0.4.1.

I did the 2nd step as well, uninstalling torchvision and installing with no-deps.

Let me point out again that everything worked, also in this second step. The only thing that I guessed was wrong was that when installed fastai, it got torch-0.4.1.

I am going to try installing via conda now. ",exactly difference pip install important notice everything problem saw installation used step well let point everything worked also second step thing wrong got going try via,issue,negative,positive,neutral,neutral,positive,positive
426838941,"Do you mean that you followed the [documentation](https://github.com/fastai/fastai/blob/master/README.md#pypi-install) exactly, and successfully installed pytorch-nightly with pip and then torchvision as the docs say and when you went to install fastai it fetched torch-0.4.1?

The problem is torchvision, and the 2nd step in the docs should have worked around it.

If you weren't following the docs, please list the exact commands you executed.

Thanks.",mean documentation exactly successfully pip say went install fetched problem step worked around following please list exact executed thanks,issue,positive,positive,positive,positive,positive,positive
426787572,"I got fastai v1 working on my Mac by following the instructions on pytorch/pytorch to install pytorch from source.

I managed to also address this issue by reducing the image size from 228 to 60 pixels :( ... I might just have been running out of memory.",got working mac following install source also address issue reducing image size might running memory,issue,negative,neutral,neutral,neutral,neutral,neutral
426753419,"Sorry we don't support fastai on Mac. If you find and fix issues we're happy to merge a PR, however.",sorry support mac find fix happy merge however,issue,positive,positive,positive,positive,positive,positive
426715834,"According to https://pytorch.org/get-started/locally/ 
### Preview Build Not Yet Available on Windows. 
When **stable** is selected, it wanted to install pytorch-cpu-0.4.1",according preview build yet available stable selected install,issue,negative,positive,positive,positive,positive,positive
426697807,"@ewjordan, try:

    conda search -c pytorch ""pytorch-nightly[subdir=osx-64]""

According to https://pytorch.org/get-started/locally/, it's cpu-only for mac at the moment.",try search according mac moment,issue,negative,neutral,neutral,neutral,neutral,neutral
426682796,"Hi there, I have no idea what BasicIntro.ipynb is. You should share a little bit more about your problem but use the [forum](http://forums.fast.ai/).",hi idea share little bit problem use forum,issue,negative,negative,negative,negative,negative,negative
426682051,"Hi there, we need a tiny little bit more detail to figure out what your problem is (which version of the fastai library are you running? What code? Your editor?) and you should use the [forum](http://forums.fast.ai/) as you'll get more people responding to you there.",hi need tiny little bit detail figure problem version library running code editor use forum get people,issue,negative,negative,neutral,neutral,negative,negative
426681314,"The doc says to do it in terminal ;).
You're right `!python -m spacy download en` should work in the notebook, will change that later today.",doc terminal right python spacy en work notebook change later today,issue,negative,positive,positive,positive,positive,positive
426679599,"We'll probably change the function to download a model in the future, but in the meantime, you should put the two files in project_path/models/ . I'll make sure to document this in `load_pretrained`.",probably change function model future put two make sure document,issue,negative,positive,positive,positive,positive,positive
426678248,Good point. I changed them again to point the docs.fast.ai but thanks for pointing this out!,good point point thanks pointing,issue,positive,positive,positive,positive,positive,positive
426612565,"Here's what I got for conda install (no GPU). I can see the packages listed at https://anaconda.org/fastai and https://anaconda.org/pytorch - may be a config file is causing this (fastai listed twice below). This is for Win 10 (1803) 17134.285 OS build.
--------------------------------------------------------------
E:\software\anaconda351\Scripts>conda install -c pytorch -c fastai fastai pytorch-nightly==1.0.0.dev20180928=py3.6_cpu_0
Solving environment: failed
PackagesNotFoundError: The following packages are not available from current channels:
  - fastai
  - pytorch-nightly
  - fastai
  - torchvision==0.2.1=py_0
  - pytorch-nightly==1.0.0.dev20180928=py3.6_cpu_0
Current channels:
  - https://conda.anaconda.org/pytorch/win-64
  - https://conda.anaconda.org/pytorch/noarch
  - https://conda.anaconda.org/fastai/win-64
  - https://conda.anaconda.org/fastai/noarch
  - https://conda.anaconda.org/conda-forge/win-64
  - https://conda.anaconda.org/conda-forge/noarch
  - https://conda.anaconda.org/anaconda-fusion/win-64
  - https://conda.anaconda.org/anaconda-fusion/noarch
  - https://repo.anaconda.com/pkgs/main/win-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/free/win-64
  - https://repo.anaconda.com/pkgs/free/noarch
  - https://repo.anaconda.com/pkgs/r/win-64
  - https://repo.anaconda.com/pkgs/r/noarch
  - https://repo.anaconda.com/pkgs/pro/win-64
  - https://repo.anaconda.com/pkgs/pro/noarch
  - https://repo.anaconda.com/pkgs/msys2/win-64
  - https://repo.anaconda.com/pkgs/msys2/noarch
To search for alternate channels that may provide the conda package you're
looking for, navigate to
    https://anaconda.org
and use the search bar at the top of the page.",got install see listed may file causing listed twice win o build install environment following available current current search alternate may provide package looking navigate use search bar top page,issue,positive,positive,positive,positive,positive,positive
426551965,"On OS X, `conda search -c pytorch ""pytorch-nightly[build=py3*_cpu_0]""` didn't show any results for me. Is this possibly a result of the package names being different on that platform, perhaps all are CPU-only?",o search show possibly result package different platform perhaps,issue,negative,neutral,neutral,neutral,neutral,neutral
426506680,"You need to have a data folder in '../data', this why you have an error (as in the fastai_docs repo), that was you had an error when it tried to download the mnist data.
We'll fix this to create that data folder automatically if there is none.",need data folder error error tried data fix create data folder automatically none,issue,negative,neutral,neutral,neutral,neutral,neutral
426494546,"@rushtehrani, please try:

     conda search -c pytorch ""pytorch-nightly[build=py3*_cpu_0]""

this is where I got the specific version from.

The reason it was written this way is because other users reported that what you used above got them the non-cpu-only pytorch fetched (despite not having cudaXX installed).
",please try search got specific version reason written way used got fetched despite,issue,negative,neutral,neutral,neutral,neutral,neutral
426465969,"To get a working example I went here  [http://files.fast.ai/data/examples/](http://files.fast.ai/data/examples/) and downloaded the file to my working directory and expanded it. 

Then 
```
data = image_data_from_folder(""mnist_sample"")
```

Then we're good to follow the [docs](http://docs.fast.ai/vision.html).
``` 
learn = ConvLearner(data, tvm.resnet18, metrics=accuracy)
learn.fit(1)
```

Results:

```
Total time: 04:49
epoch  train loss  valid loss  accuracy
0      0.083482    0.038387    0.987733  (04:49)
```
",get working example went file working directory expanded data good follow learn data total time epoch train loss valid loss accuracy,issue,negative,positive,positive,positive,positive,positive
426436484,"The following worked for me as well:

```
conda install pytorch-nightly -c pytorch
conda install -c fastai fastai
```

Note that https://docs.fast.ai doesn't mention the first command and running the second one by itself gives an error. ",following worked well install install note mention first command running second one error,issue,negative,positive,neutral,neutral,positive,positive
426428643,"It couldn't find the package. 
``` 
Solving environment: failed

PackagesNotFoundError: The following packages are not available from current channels:

  - pytorch-nightly==1.0.0.dev20180928=py3.6_cpu_0

Current channels:

  - https://conda.anaconda.org/pytorch/osx-64
  - https://conda.anaconda.org/pytorch/noarch
  - https://conda.anaconda.org/fastai/osx-64
  - https://conda.anaconda.org/fastai/noarch
  - https://repo.anaconda.com/pkgs/main/osx-64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/free/osx-64
  - https://repo.anaconda.com/pkgs/free/noarch
  - https://repo.anaconda.com/pkgs/r/osx-64
  - https://repo.anaconda.com/pkgs/r/noarch
  - https://repo.anaconda.com/pkgs/pro/osx-64
  - https://repo.anaconda.com/pkgs/pro/noarch
  - https://conda.anaconda.org/conda-forge/osx-64
  - https://conda.anaconda.org/conda-forge/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page. 
```",could find package environment following available current current search alternate may provide package looking navigate use search bar top page,issue,negative,positive,positive,positive,positive,positive
426419245,"I just tried that on a cpu-only machine and conda said:
```
pytorch-nightly: 1.0.0.dev20181002-py3.6_cuda9.0.176_cudnn7.1.2_0 pytorch
```

Did it install the cpu version correctly for you? Or did it install the cuda version? If the latter, did that work ok on cpu?",tried machine said install version correctly install version latter work,issue,negative,neutral,neutral,neutral,neutral,neutral
426239297,"Ok.  I signed the agreement, so there will be no problem next time",agreement problem next time,issue,negative,neutral,neutral,neutral,neutral,neutral
426138581,"You are trying to use version 1.0 of fastai, which requires pytorch 1.0. There are no more Variable objects in pytorch 1.0 so that's why it's not supported.
If you want to use the old fastai 0.7, you should follow the instruction [here](https://github.com/fastai/fastai/tree/master/old).",trying use version variable want use old follow instruction,issue,negative,positive,neutral,neutral,positive,positive
426138186,Could you propose a PR to change the notebook so that it works? Thanks in advance.,could propose change notebook work thanks advance,issue,negative,positive,positive,positive,positive,positive
426138005,"You are trying to load a fastai v0.7 file with a pip installation that has probably installed v1.0. If you are looking to use the old version of the library, be sure to follow the instructions [here](https://github.com/fastai/fastai/tree/master/old) for installation.",trying load file pip installation probably looking use old version library sure follow installation,issue,negative,positive,positive,positive,positive,positive
426137799,"The library imports separately imports.core and imports.torch in core and torch_core, that's why. Though with [this commit](https://github.com/fastai/fastai/commit/fce6f2c399e4bb6eb4447ec7beae0d4f2f9d2c1d), you should be able to do from fastai.import import * if you want.",library separately core though commit able import want,issue,negative,positive,positive,positive,positive,positive
426116833,Did **structured** got moved to **tabular** ? Can someone confirm? The source methods looks similar.,structured got tabular someone confirm source similar,issue,negative,neutral,neutral,neutral,neutral,neutral
426114488,"Thank you for this report, @Ace139 

I'm glad to hear pip build works.

Any reason why you weren't following the conda installation [instructions](https://github.com/fastai/fastai/blob/master/README.md#conda-install)? And if you did, could you paste all of the conda-related steps you executed, including successful ones.

Please note, I'm asking this question not to chastise you, but to understand how we could improve the documentation so that others won't have the same issue. .e.g did you not think of looking for instructions? And if you did, where did you find this particular instruction (so that we could fix it).

What you shared you did will work out of the box once pytorch 1.0.0 builds are available in the near future, until then it's following the precise instructions.

Thanks.",thank report ace glad hear pip build work reason following installation could paste executed successful please note question chastise understand could improve documentation wo issue think looking find particular instruction could fix work box available near future following precise thanks,issue,positive,positive,positive,positive,positive,positive
426083905,"Ah, that's it then. Only linux packages are available from pytorch.org at the moment. I have no idea whether you could build it from source on windows. 

Please either wait till pytorch makes a windows release, or install on linux if you have access to it. 

I will make sure the README file is updated with this info.

Thank you for your feedback, @markb-trustifi.
",ah available moment idea whether could build source please either wait till release install access make sure file thank feedback,issue,positive,positive,positive,positive,positive,positive
426083265,Preview Build Not Yet Available on Windows.,preview build yet available,issue,negative,positive,positive,positive,positive,positive
426082868,"Thank for your feedback, @markb-trustifi. Let's continue debugging this then.

Please go to https://pytorch.org/get-started/locally/ and choose the right setup for your system. Make sure to pick Preview in the first row. What install command do you get and what do you get when you run it (installing `pytorch-nightly` that is). Please paste both of them. Thank you.

Actually, let's first debug each component separately. conda client is not very user-friendly to tell the user which dependency is missing. And it complains about them all together, which is wrong most of the time.

$ conda install -c pytorch  pytorch-nightly
$ conda install -c pytorch -c fastai torchvision==0.2.1=py_0
$ conda install -c pytorch -c fastai fastai 

",thank feedback let continue please go choose right setup system make sure pick preview first row install command get get run please paste thank actually let first component separately client tell user dependency missing together wrong time install install install,issue,positive,positive,neutral,neutral,positive,positive
426081471,"It is better, but there is still missing pytorch-nightly package.

```JS
$ conda install -c pytorch -c fastai fastai pytorch-nightly
Solving environment: failed
PackagesNotFoundError: The following packages are not available from current channels:
  - fastai
  - pytorch-nightly
  - fastai
  - torchvision==0.2.1=py_0
  - pytorch-nightly
```
",better still missing package install environment following available current,issue,negative,positive,positive,positive,positive,positive
426053808,"`fastprogress` was hidden in the test label. Please try again, it should work now.",hidden test label please try work,issue,negative,negative,negative,negative,negative,negative
425880407,"Yes, version 1 is coming. You need to reconfigure your fastai symlink to ../../old/fastai in the meantime. See http://forums.fast.ai/t/moving-the-fastai-0-7-folder/23667",yes version coming need see,issue,negative,neutral,neutral,neutral,neutral,neutral
425846462,"Yeah, this is quite weird. I didn't look into this before as I thought we were already ignoring padding using [`pack_padded_sequence`](https://pytorch.org/docs/stable/nn.html?highlight=pack_padded_sequence#torch.nn.utils.rnn.pack_padded_sequence) (see [here](https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e) for an explanation).
In the code, the padding is done [here](https://github.com/fastai/fastai/blob/master/old/fastai/dataloader.py#L59) and the number of padding tokens is the difference of the current document length to the length of the largest document in the batch (see [here](https://github.com/fastai/fastai/blob/master/old/fastai/dataloader.py#L55)).
As a short-term measure, for padding individual examples at test time, you could thus use something like the difference to the average document length in the training data.
In the mid-term, we should use `pack_padded_sequence` and `pad_packed_sequence` as described [here](https://towardsdatascience.com/taming-lstms-variable-sized-mini-batches-and-why-pytorch-is-good-for-your-health-61d35642972e).
cc @jph00 @sgugger ",yeah quite weird look thought already padding see explanation code padding done number padding difference current document length length document batch see measure padding individual test time could thus use something like difference average document length training data use,issue,negative,negative,negative,negative,negative,negative
425829783,"Getting the same error. I was able to solve it by updating the repo on my local machine and set `learn.metrics = []
`
The relevant discussion and answer by fizx is here
http://forums.fast.ai/t/typeerror-on-the-first-exemple-in-lesson-1-no-loop-matching-the-specified-signature-and-casting/22403/5",getting error able solve local machine set relevant discussion answer,issue,negative,positive,positive,positive,positive,positive
425792697,Should be fixed in [this commit](https://github.com/fastai/fastai/commit/7cf2f19193a313f0d2a03d8448489d140667c8dc) and [this one](https://github.com/fastai/fastai/commit/74da9714ac936daf649451dafd7c882b9307a1ea). Thanks for pointing it out!,fixed commit one thanks pointing,issue,positive,positive,positive,positive,positive,positive
425792125,"Hi, I will delete this if my post is inappropriate. I am also running into the same problem however, it is not related to fastai directly. I apologize if this is inappropriate place to post this question, if you let me know, i will delete it. but i was out of options so I decided to ask here. I am trying to set up conda environment and running `conda env update -f environment-cpu.yml` gives me the following error. 


0. set up config: ubuntu 16.04 running conda 4.5.11 with python 3.7.0
1. Using this version: https://github.com/udacity/CarND-Term1-Starter-Kit/blob/master/environment-gpu.yml
2. The above doesn't have `conda-forge::jupyter_contrib_nbextensions` , so I didn't try removing this line from the yml file.
3. I tried `conda env remove -n carnd-term1` and then again `conda env create -f environment-gpu.yml`. 

Even after this, I am still getting the same error message:

```
Exception:
Traceback (most recent call last):
  File ""/home/dorandoran_hk/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pip/_vendor/pkg_resources/__init__.py"", line 2869, in _dep_map
    return self.__dep_map
  File ""/home/dorandoran_hk/miniconda3/envs/carnd-term1/lib/python3.5/site-packages/pip/_vendor/pkg_resources/__init__.py"", line 2663, in __getattr__
    raise AttributeError(attr)
AttributeError: _DistInfoDistribution__dep_map

During handling of the above exception, another exception occurred:
```
Any help will be appreciated!",hi delete post inappropriate also running problem however related directly apologize inappropriate place post question let know delete decided ask trying set environment running update following error set running python version try removing line file tried remove create even still getting error message exception recent call last file line return file line raise handling exception another exception help,issue,negative,positive,neutral,neutral,positive,positive
425772323,"Excellent. Thank you, @fredguth . I [applied](https://github.com/fastai/fastai/commit/1084bcc6987163a35d7eba44416e328ec37db08d#diff-04c6e90faac2675aa89e2176d2eec7d8) the suggested changes directly as it wasn't signed, but time is of an issue.

For the future PRs please sign this CLA agreement https://www.clahub.com/agreements/fastai/fastai as explained [here](https://github.com/fastai/fastai/blob/master/CONTRIBUTING.md) and we would be happy to accept and merge them directly. Thank you.",excellent thank applied directly time issue future please sign agreement would happy accept merge directly thank,issue,positive,positive,positive,positive,positive,positive
425743563,"In my case, It seems like the package named `nbconvert` is the problem.
When installing it with `conda install` it breaks pip o_O
So i just install it will `pip install` instead.

For more details see https://github.com/jupyter/notebook/pull/4036/commits/4c1d62f3b21af6f139d8396081578d0c1646a632

Cheers",case like package problem install pip install pip install instead see,issue,negative,neutral,neutral,neutral,neutral,neutral
425742787,"Please see also:

```
ag ""def do_transform"" .
old/fastai/transforms.py
245:    def do_transform(self, x, is_y): raise NotImplementedError
286:    def do_transform(self, im, is_y):
304:    def do_transform(self, x, is_y):
327:    def do_transform(self, x, is_y):
338:     def do_transform(self, x, is_y):
354:    def do_transform(self, x, is_y):
372:    def do_transform(self, x, is_y):
405:    def do_transform(self, x, is_y):
433:    def do_transform(self, x, is_y):
449:    def do_transform(self, x, is_y):
460:    def do_transform(self, x, is_y): return np.fliplr(x).copy() if self.store.do_flip else x
472:    def do_transform(self, x, is_y):
507:    def do_transform(self, x, is_y): return self.store.trans.do_transform(x, is_y)
517:    def do_transform(self, x, is_y):
529:    def do_transform(self, x, is_y):
535:    def do_transform(self, x, is_y):
558:    def do_transform(self, x, is_y):
578:    def do_transform(self, img, is_y):
610:    def do_transform(self, x, is_y):
```
noting `338:     def do_transform(self, x, is_y):` is overindented.",please see also self raise self self self self self self self self self self return else self self return self self self self self self self,issue,negative,neutral,neutral,neutral,neutral,neutral
425739407,"Changes happening in the fastai repo also to deal with the broken jupyter packages, see for instance commit 7528b2af1b7a0224225082e69f2b019209ffc1cd 

My workaround is now obsolete. Happy to see that I seem to have been 1h before Borz tho! 😸",happening also deal broken see instance commit obsolete happy see seem tho,issue,negative,positive,positive,positive,positive,positive
425735902,"@phromo thanks. I didn't think the env was successfully created...after I removed it the env builds fine. 

@prithvihv, add twisted and mkl-random to your environment.yml dependencies and rerun `conda env update` or pip install like ^ 
",thanks think successfully removed fine add twisted rerun update pip install like,issue,positive,positive,positive,positive,positive,positive
425734371,The corresponding changes have been pushed to the old library in [this commit](https://github.com/fastai/fastai/commit/23398043f9a33466a9daa880e721a2cb03310fea),corresponding old library commit,issue,negative,positive,neutral,neutral,positive,positive
425734319,"I'd rather not add more params to the old training loop - the new v1 library has a much better callback system that will allow you to do this easily there. Would you mind adding it there instead, if that's of interest?",rather add old training loop new library much better system allow easily would mind instead interest,issue,positive,positive,positive,positive,positive,positive
425734182,I'd rather link to this hosted externally if possible - maybe instead add a URL to one of the notebooks where we discuss numpy?,rather link externally possible maybe instead add one discus,issue,negative,neutral,neutral,neutral,neutral,neutral
425733972,Closing this since new doc framework and docs are done now (see http://docs.fast.ai).,since new doc framework done see,issue,negative,positive,positive,positive,positive,positive
425731433,"Here I am pasting the [answer from the forum](http://forums.fast.ai/t/conda-env-update-error-on-ubuntu-16-04/23570/7?u=brismith), related to Ubuntu 16.04 installation. I believe the issue on 18.04 could be solved the same way

At first I just removed fastai repository, cloned it and the same error reappeared.

Then I ran conda env remove -y -n fastai before conda env update and there were no errors (haven’t modified environment.yml file as there have been already changes pushed to fastai repository).

Now the only warnings are the following:

> twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.
> mkl-random 1.0.1 requires cython, which is not installed.
> spacy 2.0.12 has requirement regex==2017.4.5, but you’ll have regex 2018.7.11 which is incompatible.

Afterward,s I have installed mkl-random and twisted with pip:
```
pip install twisted
pip install mkl-random
```",pasting answer forum related installation believe issue could way first removed repository error ran remove update file already repository following twisted spacy requirement incompatible afterward twisted pip pip install twisted pip install,issue,negative,negative,negative,negative,negative,negative
425722428,"@phromo Any idea how to solve the issue if it happends with the appveyor tests?
https://github.com/jupyter/notebook/pull/4036
Thanks!",idea solve issue thanks,issue,positive,positive,positive,positive,positive,positive
425718965,"
still not completely fixed, could somebody help me out ?
```Requirement already satisfied: click<8,>=4.0 in /home/prithvihv/anaconda3/envs/fastai-cpu/lib/python3.6/site-packages (from cligj>=0.4->fiona->geopandas>=0.3.0->plotnine->-r /home/prithvihv/AI/fastai/condaenv.6f2se111.requirements.txt (line 10)) (6.7)
twisted 18.7.0 requires PyHamcrest>=1.9.0, which is not installed.
mkl-random 1.0.1 requires cython, which is not installed.
spacy 2.0.12 has requirement regex==2017.4.5, but you'll have regex 2018.7.11 which is incompatible.
kaggle-cli 0.12.13 has requirement lxml<4.1,>=4.0.0, but you'll have lxml 4.2.5 which is incompatible.
```",still completely fixed could somebody help requirement already satisfied click line twisted spacy requirement incompatible requirement incompatible,issue,positive,positive,neutral,neutral,positive,positive
425696890,"@shan224 did you remove your broken environment first? trying update on an already broken env won't work.
I just verified that my workaround does what's intended on a fresh ubuntu 1804, also verified that an unmodified fastai repo breaks with the error message above.",remove broken environment first trying update already broken wo work intended fresh also unmodified error message,issue,negative,negative,neutral,neutral,negative,negative
425694235,"Thanks @phromo but removing `conda-forge::jupyter_contrib_nbextensions` doesn't fix the issue for me. Has this fixed the issue for anyone else? 

The issue seems to be associated with the pip dependencies specifically in the environment.yml ( I deleted everything except for a single pip dep and it failed)",thanks removing fix issue fixed issue anyone else issue associated pip specifically everything except single pip,issue,negative,positive,neutral,neutral,positive,positive
425676304,"It's the `conda-forge::jupyter_contrib_nbextensions` line in `environment.yml` causing this. comment it out or remove it.
If you had a previous broken env, remove that first (`conda env remove -n fastai`). Then run `conda env update`.

You can add `jupyter_contrib_nbextensions` to the the list of pip-installed packages at the end of the environmnet file instead.",line causing comment remove previous broken remove first remove run update add list end file instead,issue,negative,negative,negative,negative,negative,negative
425670416,"Also have the same issue on 
Ubuntu 18.04.1 LTS and macos mojave 10.14
when running `conda env update`

Using
pip 18.0 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)
conda 4.5.11 from /home/user/anaconda3/bin/conda",also issue running update pip python,issue,negative,neutral,neutral,neutral,neutral,neutral
425665925,"same issue here pip 18.0, conda 4.5.11, Ubuntu 18.04 (upgrade from 16.04),Python 3.6.6
conda env update -f environment.yml",issue pip upgrade python update,issue,negative,neutral,neutral,neutral,neutral,neutral
425656875,"I have the same issue with `environment.yml` using fully upgraded ubuntu 16.04 running conda 4.5.11 with python 3.6.6

It seems the pip installed into the fastai environment somehow is broken (any pip command or install attempt of any package fails with the same error as the original report). Setuptools is version 40.4.0 (conda-forge), pip is 18.0 (conda-forge)

Also uninstalled anaconda, reinstalled a fresh version and tried initializing the env again -- same result.",issue fully running python pip environment somehow broken pip command install attempt package error original report version pip also uninstalled anaconda fresh version tried result,issue,negative,positive,neutral,neutral,positive,positive
425553436,I would suggest reading the guides on [style](https://github.com/fastai/fastai/blob/master/docs/style.md) and [abbreviation](https://github.com/fastai/fastai/blob/master/docs/abbr.md). This has also been debated a lot on the [forum](http://forums.fast.ai/).,would suggest reading style abbreviation also lot forum,issue,negative,neutral,neutral,neutral,neutral,neutral
424718905,"Please move this discussion to the [forum](http://forums.fast.ai/). This is a problem with your pytorch installation, not fastai.",please move discussion forum problem installation,issue,negative,neutral,neutral,neutral,neutral,neutral
424717745,"Automatic testing sometimes randomly fails, it's not you.",automatic testing sometimes randomly,issue,negative,negative,negative,negative,negative,negative
424607552,"https://github.com/notifications/unsubscribe-auth/AkEVr4NHDWSlslBL1aVMwajhH9RASdgMks5ueyVEgaJpZM4W4b1O



发自我的小米手机
在 KaitouKK <notifications@github.com>，2018年9月26日 下午2:57写道：

@KaitouKK<https://github.com/KaitouKK> Give more details and screenshot of error here.

[qq 20180926145142]<https://user-images.githubusercontent.com/18696649/46062429-5a5e7980-c19c-11e8-9a0f-bacb4b9a5dea.png>

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub<https://github.com/fastai/fastai/issues/794#issuecomment-424606306>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AkEVr4NHDWSlslBL1aVMwajhH9RASdgMks5ueyVEgaJpZM4W4b1O>.
",give error thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
424305154,Hi may I know how did you solve this problem? just encountered the same problem. Thanks!,hi may know solve problem problem thanks,issue,negative,positive,positive,positive,positive,positive
424238491,"Hi, the build failed when updating conda environment, which I think is not related to my commit. What should I do to merge my pull request? Thanks!

$ conda env update -f environment-cpu.yml
Solving environment: done

...

CondaHTTPError: HTTP 502 BAD GATEWAY for url <https://conda.anaconda.org/conda-forge/noarch/jupyter-1.0.0-py_1.tar.bz2>
Elapsed: 00:04.460611
CF-RAY: 45f5ab150994551c-ORD
An HTTP error occurred when trying to retrieve this URL.
HTTP errors are often intermittent, and a simple retry will get you on your way.
The command ""conda env update -f environment-cpu.yml"" failed and exited with 1 during .
Your build has been stopped.",hi build environment think related commit merge pull request thanks update environment done bad gateway error trying retrieve often intermittent simple retry get way command update build stopped,issue,negative,negative,negative,negative,negative,negative
424138867,"Never mind, looks like this was defined earlier in the lesson, but I must have reloaded it after running that bit. My bad!",never mind like defined lesson must running bit bad,issue,negative,negative,negative,negative,negative,negative
423788190,"https://github.com/notifications/unsubscribe-auth/AkEVr0YPXRgmfqfrPw7HGBUfenC90N1lks5uduz9gaJpZM4W1hcG



发自我的小米手机
在 Masaki Kozuki <notifications@github.com>，2018年9月23日 上午10:07写道：

Path instance does not have endswith.

________________________________
You can view, comment on, or merge this pull request online at:

  https://github.com/fastai/fastai/pull/787

Commit Summary

  *   fix isdicom

File Changes

  *   M fastai/dataset.py<https://github.com/fastai/fastai/pull/787/files#diff-0> (1)

Patch Links:

  *   https://github.com/fastai/fastai/pull/787.patch
  *   https://github.com/fastai/fastai/pull/787.diff

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub<https://github.com/fastai/fastai/pull/787>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AkEVr0YPXRgmfqfrPw7HGBUfenC90N1lks5uduz9gaJpZM4W1hcG>.
",path instance view comment merge pull request commit summary fix file patch link thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
423309179,There is someone who had the same error on the forum and gave a solution in [this topic](http://forums.fast.ai/t/jupyter-notebook-fails-to-start/8370/5).,someone error forum gave solution topic,issue,negative,neutral,neutral,neutral,neutral,neutral
422846036,"Do you mean this change in `lm_rnn.py`?

```
class MultiBatchRNN(RNN_Encoder):
    def __init__(self, bptt, max_seq, *args, **kwargs):
        self.max_seq,self.bptt = max_seq,bptt
        super().__init__(*args, **kwargs)
        self.reset()    #reset here?
```

Thank you!",mean change class self super reset thank,issue,positive,positive,neutral,neutral,positive,positive
422248178,"https://github.com/notifications/unsubscribe-auth/AkEVr6WxscD3S1BAJBU78j82ZHeps14yks5ucFv-gaJpZM4Ws_4G



发自我的小米手机
在 Sylvain Gugger <notifications@github.com>，2018年9月18日 上午10:35写道：

Not sure I understand the question, which should be asked on the forum<http://forums.fast.ai/> anyway. You'll get more answers there!

—
You are receiving this because you were mentioned.
Reply to this email directly, view it on GitHub<https://github.com/fastai/fastai/issues/782#issuecomment-422233976>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AkEVr6WxscD3S1BAJBU78j82ZHeps14yks5ucFv-gaJpZM4Ws_4G>.
",sure understand question forum anyway get reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
422233976,"Not sure I understand the question, which should be asked on the [forum](http://forums.fast.ai/) anyway. You'll get more answers there!",sure understand question forum anyway get,issue,negative,positive,positive,positive,positive,positive
422233819,As it has been discussed on the [forum](http://forums.fast.ai/t/unofficial-pytorch-0-4-support/16285) the support for pytorch 0.4 isn't official and there are probably multiple bugs. Fastai_v1 will use the latest version of pytorch but 0.7 will stick to pytorch 0.3.,forum support official probably multiple use latest version stick,issue,negative,positive,positive,positive,positive,positive
422222101,"mute the thread<https://github.com/notifications/unsubscribe-auth/AkEVr-6VgVLkIzf2FxBjDBMD--G8RwOJks5ucEodgaJpZM4Ws_4G>

________________________________
发件人: kclch <notifications@github.com>
发送时间: 2018年9月18日 9:19
收件人: fastai/fastai
抄送: Subscribed
主题: [fastai/fastai] gender recognition based on the whole body (#782)


Can I use it for gender recognition based on the whole body?

―
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub<https://github.com/fastai/fastai/issues/782>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AkEVr-6VgVLkIzf2FxBjDBMD--G8RwOJks5ucEodgaJpZM4Ws_4G>.
",mute thread gender recognition based whole body use gender recognition based whole body thread reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
422221924,"mute the thread<https://github.com/notifications/unsubscribe-auth/AkEVr7Q5RG23i1RQC8T95SK7-oqqWwgdks5ubxbtgaJpZM4WrI9w>
________________________________
发件人: Sylvain Gugger <notifications@github.com>
发送时间: 2018年9月17日 21:55
收件人: fastai/fastai
抄送: Subscribed
主题: Re: [fastai/fastai] DicomSupport has broken lesson1 (#779)


Thanks for taking care of this, the fix works for me.

―
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub<https://github.com/fastai/fastai/issues/779#issuecomment-422026037>, or mute the thread<https://github.com/notifications/unsubscribe-auth/AkEVr40tiEoD6qp38xxXRuyVGl7_enckks5ub6nrgaJpZM4WrI9w>.
",mute thread broken lesson thanks taking care fix work thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
422217229,"It seems like support for PyTorch `0.4.x` isn't being added because [fastai_v1](https://github.com/fastai/fastai_v1) is being developed, so future versions of PyTorch will be supported by that library?",like support added future library,issue,positive,neutral,neutral,neutral,neutral,neutral
422026480,"Not sure I can help without more information. Also, please use the [forum](http://forums.fast.ai/) for this as you'll get more people to answer you.",sure help without information also please use forum get people answer,issue,negative,positive,positive,positive,positive,positive
422026037,"Thanks for taking care of this, the fix works for me.",thanks taking care fix work,issue,positive,positive,positive,positive,positive,positive
421883274,"Oops, indeed my mistake. I'm still using python2 too much. :-( Should have been:

```
    with open(fn,'rb') as fh:
        fh.seek(0x80)
        return fh.read(4)==b'DICM'
```
But I'm now confused as `git fetch` shows that fastai master is at cb12199 but the web interface sais it is after my pull request at b48711ab. I'll add another pull request on top of b48711ab. ",indeed mistake still python much open return confused git fetch master web interface pull request add another pull request top,issue,negative,positive,neutral,neutral,positive,positive
421607442,Ok. Opened a pull request in https://github.com/fastai/fastai/pull/777 . (And also fixed a few bugs in the patch I attached in the initial issue.),pull request also fixed patch attached initial issue,issue,negative,positive,neutral,neutral,positive,positive
421371477,This is to have both get_rnn_classifer and get_rnn_classifier available since we changed the name of this function and didn't want to break existing code.,available since name function want break code,issue,negative,positive,positive,positive,positive,positive
421371108,"Not sure, you should use the [forum](http://forums.fast.ai/) to get more people to see your problem and help.",sure use forum get people see problem help,issue,negative,positive,positive,positive,positive,positive
421370888,"This has been corrected a long time ago, you should update your version ;).",corrected long time ago update version,issue,negative,negative,neutral,neutral,negative,negative
421370592,"Bug is mostly coming from the tqdm side AFAICT, so we can't do much about it. In fastai_v1, we'll be using our own implementation for progress bars so this won't happen anymore.",bug mostly coming side ca much implementation progress wo happen,issue,negative,positive,positive,positive,positive,positive
421354971,"> with ThreadPoolExecutor

making num workers =0  will execute the code that you are putting there is a if condition in a dataloader...
so that we dont have to modify the loader at all",making execute code condition dont modify loader,issue,negative,neutral,neutral,neutral,neutral,neutral
421261158,@dov Probably you could open a PR for convenience :),probably could open convenience,issue,negative,neutral,neutral,neutral,neutral,neutral
421008130,"As it has already been stated, fastai doesn't officially support pytorch 0.4. It may work but it hasn't been thoroughly tested and there might be some bugs.
fastai_v1 will support the latest version of pytorch.",already stated officially support may work thoroughly tested might support latest version,issue,positive,positive,positive,positive,positive,positive
420985895,"The problem is I can not determine how many 1s should i pad, and different 1s will give different results. It's confusing.",problem determine many pad different give different,issue,negative,positive,positive,positive,positive,positive
420947553,"You could be right. 

I remember looking at the padding issues some, but when I was testing it I don't think I found any difference. There's no difference in behavior here between the scripts and the notebook is there?

I don't have the code to retest that, and if you are seeing a difference then it is likely you are correct. I'm sure a patch would be welcomed!",could right remember looking padding testing think found difference difference behavior notebook code retest seeing difference likely correct sure patch would,issue,negative,positive,positive,positive,positive,positive
420930866,"I think this code doesn't pad any ""padding index"" so the result will be different from which is computed by constructing DataLoader. 

For my own test:
```
encoded text is: [3, 4, 5, 6, 303, 10, 11, 2, 73, 24, 72, 27, 15, 32, 46, 22, 16, 2, 25, 7]
I 
result： [-0.74961,  0.71659]

encoded text for dataloader:
[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 3, 4, 5, 6, 303, 10, 11, 2, 73, 24, 72, 27, 15, 32, 46, 22, 16, 2, 25, 7]
result : [ 0.31941, -0.15691]
```

@nlothian @sebastianruder @jph00  Any idea?  
",think code pad padding index result different test text text result idea,issue,negative,neutral,neutral,neutral,neutral,neutral
420337612,"I installed fastai by using `pip install fastai` version ==0.7.0
![screen shot 2018-09-11 at 10 05 25 pm](https://user-images.githubusercontent.com/17096858/45374127-d7bbb300-b60e-11e8-9264-4bcf730bbc71.png)
",pip install version screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
420269762,RNN_Encoder takes n_hid and n_layers as an argument (line 40 of lm_rnn.py) so I don't think there is a typo.,argument line think typo,issue,negative,neutral,neutral,neutral,neutral,neutral
420269242,"Thanks for sharing, but we prefer installation problems to be discussed on the [forum](http://forums.fast.ai). I think your version of pytorch isn't recent enough, a conda env update should solve this.",thanks prefer installation forum think version recent enough update solve,issue,positive,positive,neutral,neutral,positive,positive
419987854,"Let me know if you want any tweaks on: https://github.com/fastai/fastai/pull/767
And whether the new cell I added to save sr-samp0 is technically correct (i.e. where I placed it).",let know want whether new cell added save technically correct,issue,positive,positive,neutral,neutral,positive,positive
419984853,"I am not sure why you'd call it mean, but it surely is not clear from the video what needs to be done. 

I mean, what is the real reason why is it not saved in first place, before it being used, I fail to see how this can be of any help to a student.

There are quite a few other issues with this notebook, I will submit a PR, but I also have one more question - I needed to do this as well:

```
## modified /cells/53/source:
@@ -1,3 +1,3 @@
-conv_shuffle = m.features[10][2][0]
+conv_shuffle = m.features[10][0][0]
 kernel = icnr(conv_shuffle.weight, scale=scale)
 conv_shuffle.weight.data.copy_(kernel);
```
`m.features[10][2][0]` fails saying there is no such thing  - is it related to multiple GPUs?

`m.features[10][0][0]` works. I guess this is related to a change:

+m = nn.DataParallel(m, [0])
+#m = nn.DataParallel(m, [0,2])",sure call mean surely clear video need done mean real reason saved first place used fail see help student quite notebook submit also one question well kernel kernel saying thing related multiple work guess related change,issue,positive,negative,neutral,neutral,negative,negative
419971071,Did you try to reduce the batch size from the 52 to lower value i.e 30?,try reduce batch size lower value,issue,negative,neutral,neutral,neutral,neutral,neutral
419919264,Please use the [forum](http://forums.fast.ai/) for errors like this. Sharing the image that opencv can't open would also be helpful.,please use forum like image ca open would also helpful,issue,positive,neutral,neutral,neutral,neutral,neutral
419918779,"Please use the [forum](http://forums.fast.ai/). You should also share more of your code to give more information to the people that will help you, from what I see here it looks like you created a variable named np (which is supposed to be the module numpy).",please use forum also share code give information people help see like variable supposed module,issue,positive,neutral,neutral,neutral,neutral,neutral
419918107,"The second part course notebooks aren't working when you just execute the cells in order, which I think is half on purpose. Yet if you feel this one is really mean, feel free to create a PR ;)",second part course working execute order think half purpose yet feel one really mean feel free create,issue,positive,negative,neutral,neutral,negative,negative
419917474,Please use the [forum](http://forums.fast.ai/) to ask any questions regarding installation. Also fastai doesn't support pytorch 0.4 officially.,please use forum ask regarding installation also support officially,issue,positive,neutral,neutral,neutral,neutral,neutral
419741187,"I found a workaround of adding:

    learn.save('sr-samp0')

at the end of ## Pixel loss, just before ## Perceptual loss starts. But I have no way of telling whether this is the intended way, or whether something else should be there. The video mentions that one needs to go back and forth in the notebook to make this work, but if you look at the code, that suggestion only works when waving hands ;) and not talking to a computer. ",found end loss perceptual loss way telling whether intended way whether something else video one need go back forth notebook make work look code suggestion work waving talking computer,issue,negative,neutral,neutral,neutral,neutral,neutral
419666240,"grr, it seems that the previous fix waiting for another PR merge got tagged alone. let me know if you'd like this cleaned up. or just merge both fixes... sorry about that.",grr previous fix waiting another merge got tagged alone let know like merge sorry,issue,negative,negative,negative,negative,negative,negative
419619405,"Do not ever buy anything of importance from pdd
千万不要在拼多多买任何重要一点的东西",ever buy anything importance,issue,negative,neutral,neutral,neutral,neutral,neutral
419589180,"@geekan .  Translate into english:
   The issue could not be the 550 watts' power supplies. 
    GPU's peak power could be 1.5x to 3x of TDP or average.  if nvidia-smi reports 300 watts, the peak power could be 450wats with 1.5x.  plus the other components' power , CPU, motherboard, disk, and etc, the peak power of whole system could exceeds 600 watts.  if the peak power is 3x of TDP,   the whole system even needs 1000 watts . 

other brands' power supplies may not solve the issue.  The good solution is to buy 800 watts to 1000 watts's power supply.  If you want  to use 2 GPU cards for AI trainning, 1500 watts are better. 4 GPUs,  3000 watts are suggested ",translate issue could power peak power could average peak power could plus power disk peak power whole system could peak power whole system even need power may solve issue good solution buy power supply want use ai better,issue,positive,positive,positive,positive,positive,positive
419389547,Towering genius disdains a beaten path,towering genius beaten path,issue,negative,neutral,neutral,neutral,neutral,neutral
419386023,"我来解释一下, 这款电源的名字就叫550W, 但是实际功率为200W, 哈哈哈哈, 编不下去了, 哈哈哈
Let me explain, the name of this power supply is called 550W, but the actual power is 200W, hahahaha, can't be edited, hahaha",let explain name power supply actual power ca,issue,negative,neutral,neutral,neutral,neutral,neutral
419342271,"I tried changing cycle_len = value>1 , Problem still exist
I am able to train the model , When i  pad the sentence to length of 250",tried value problem still exist able train model pad sentence length,issue,negative,positive,positive,positive,positive,positive
419319808,"我大致翻译一下吧：

首先是有个同学在电脑上运行了一个叫做 fastai 的项目，而这个程序偶尔会导致系统死机(halt)。

于是这个同学去 GitHub issues 反馈了这个问题：

每当我训练模型时，系统就会死机重启。
whenever I tried to train a model(calling fit method), 
the system halted and then rebooted.

https://github.com/fastai/fastai/issues/751

同时，这位同学也提供了充分的材料表明这个问题绝对是 fastai 的 bug，
因为在运行 tensorflow 时就完全没有这个问题。

https://github.com/fastai/fastai/issues/751#issuecomment-419026267

几个小时后这位同学终于找到了问题原因：

https://github.com/fastai/fastai/issues/751#issuecomment-419053678

After debugging for around 8 hours, I found the root cause:
我鼓捣了 8 个多小时，终于找到原因了：

* TensorFlow and PyTorch's examples use only ~100W power.
* TensorFlow 和 PyTorch's 的例子大概消耗 ~100W 左右的电力.
* Fastai's example (lesson1) use 80~300W power (not stable, changing fast).
* Fastai's example (lesson1) 使用大概 80~300W 电力 (不稳定，变化比较大).
* While monitoring nvidia-smi, it seems like when power usage reach 200W, the system halted and rebooted.
* 直到我监控 nvidia-smi, 这个破玩意最多竟然可以干到 200W, 然后我的系统就挂了QAQ
* The power supply was bought from PinDuoDuo (Nasdaq: PDD), it says it support 550W, but it may only support ~200W, I doubt it's a fake one.
* 我现在使用的电源适配器是从「拼夕夕」买的 (Nasdaq: PDD), 他说能支持 550W, 但实际上最多只有 ~200W 左右, 这TM一定是假的吧。
* After changing the power supply, the issue has been solved.
* 反正我换一个就好了（手动微笑）。

***版权声明：原文归作者所有，翻译版本免费授权，随意转载。***
",halt whenever tried train model calling fit method system around found root cause use power example lesson use power stable fast example lesson like power usage reach system power supply bought support may support doubt fake one power supply issue,issue,positive,positive,neutral,neutral,positive,positive
419179498,"@geekan Unless you post the power supply's rating label, its hard to say whether this is a problem with power supply or user error. No 550w power supply on the market for general use are rated to supply 550w on the 12v rail, power must be split amongst other sources: 3.3v, 5v, -12v..etc. Some cheap psu may even split the 12v into 2 power rails. Thus single 12v power rail with ~200w could just be the power supply's actual rating. I.e Nothing is wrong with the power supply and it halted due to exceeding power rating (which is rather good behavior). 

Example: a typical 550w power supply label: http://www.legitreviews.com/images/reviews/348/ultra_label.jpg
As you can see, the power supply is rated for 204w on 12v1 and 216w on 12v2 and a combined 408w on 12v1 and 12v2. Exceeding this amount is undefined behavior. Halting is a very good solution to prevent further damage from exceeding the power ratings.
",unless post power supply rating label hard say whether problem power supply user error power supply market general use rated supply rail power must split amongst cheap may even split power thus single power rail could power supply actual rating nothing wrong power supply due exceeding power rating rather good behavior example typical power supply label see power supply rated combined exceeding amount undefined behavior halting good solution prevent damage exceeding power,issue,negative,positive,neutral,neutral,positive,positive
419136573,"@geekan  Amazing that the PSU doesn't get self-ignition, may the force be with you.
",amazing get may force,issue,positive,positive,positive,positive,positive,positive
419096426,"I very well use Python 3.6
Pip install fastai dsnt completes without error

On Tuesday, September 4, 2018, Sylvain Gugger <notifications@github.com>
wrote:

> Closed #742 <https://github.com/fastai/fastai/issues/742>.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/742#event-1825582946>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AkZW5Ek1MygMupzp1PW_1c2Moh1Slxkmks5uXpmGgaJpZM4WWOKm>
> .
>
",well use python pip install without error wrote closed thread reply directly view mute thread,issue,positive,neutral,neutral,neutral,neutral,neutral
419091019,"Fixed, thanks for letting us know.",fixed thanks u know,issue,negative,positive,positive,positive,positive,positive
419087873,"I hadn't fully thought about this issue at first, but as you say, the key point is that we need the inverse transformation of what was applied to the image. This isn't implemented in fastai and would require a profound change in the transforms.py module, which is why this functionality won't be developed for fastai, only for fastai_v1.
I'm keeping this closed for that reason.",fully thought issue first say key point need inverse transformation applied image would require profound change module functionality wo keeping closed reason,issue,negative,positive,neutral,neutral,positive,positive
419026267,"BTW, tensorflow and pytorch both work fine. I use the below two cases to verify:
1. tensorflow: https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/01_Simple_Linear_Model.ipynb
2. pytorch: https://github.com/pytorch/examples/blob/master/mnist/main.py",work fine use two verify,issue,negative,positive,positive,positive,positive,positive
418993591,"Hey,

Apologies for reopening this if there should already be changes made in FastAI 1. Recently, I was facing the same problem though and was not entirely sure what the best way of tackling it is. 

@sgugger, from how I interpret your answer it would seem to suggest the images are not being transformed in the TTA. The problem I think both the topic opener and myself share I think is that you indeed the function returns the transformed images and perhaps you can score them individually. What you cannot do however is do the inverse transformation. The latter would be necessary if, in the segmentation case you want to average the pixel-wise predictions of each case.

If I have time I could also try having a look at it. Could you give some hints perhaps as to whether the inverse transformation is somehow easily accessible in FastAI? Thanks!",hey already made recently facing problem though entirely sure best way tackling interpret answer would seem suggest problem think topic opener share think indeed function perhaps score individually however inverse transformation latter would necessary segmentation case want average case time could also try look could give perhaps whether inverse transformation somehow easily accessible thanks,issue,positive,positive,positive,positive,positive,positive
418618160,"If the first diff part is commented out then the following cell fails:

    ssd_loss(batch, y, True)

```
RuntimeError                              Traceback (most recent call last)
<ipython-input-57-0b3e91fc3fa0> in <module>()
----> 1 ssd_loss(batch, y, True)

<ipython-input-52-9420521a9bbe> in ssd_loss(pred, targ, print_it)
     36     lcs,lls = 0.,0.
     37     for b_c,b_bb,bbox,clas in zip(*pred,*targ):
---> 38         loc_loss,clas_loss = ssd_1_loss(b_c,b_bb,bbox,clas,print_it)
     39         lls += loc_loss
     40         lcs += clas_loss

<ipython-input-52-9420521a9bbe> in ssd_1_loss(b_c, b_bb, bbox, clas, print_it)
     21 def ssd_1_loss(b_c,b_bb,bbox,clas,print_it=False):
     22     bbox,clas = get_y(bbox,clas)
---> 23     a_ic = actn_to_bb(b_bb, anchors)
     24     overlaps = jaccard(bbox.data, anchor_cnr.data)
     25     gt_overlap,gt_idx = map_to_ground_truth(overlaps,print_it)

<ipython-input-52-9420521a9bbe> in actn_to_bb(actn, anchors)
      6 def actn_to_bb(actn, anchors):
      7     actn_bbs = torch.tanh(actn)
----> 8     actn_centers = (actn_bbs[:,:2]/2 * grid_sizes) + anchors[:,:2]
      9     actn_hw = (actn_bbs[:,2:]/2+1) * anchors[:,2:]
     10     return hw2corners(actn_centers, actn_hw)

RuntimeError: Expected object of type Variable[torch.cuda.FloatTensor] but found type Variable[torch.FloatTensor] for argument #1 'other'
```

So you must be referring to the 2nd diff part, correct? I added that to the PR as you suggested.

The rest remains.",first part following cell batch true recent call last module batch true zip return object type variable found type variable argument must part correct added rest remains,issue,negative,positive,positive,positive,positive,positive
418603309,"Those `cpu()` cells aren't meant to be run - they're just there to allow you to move things to the CPU if you want to debug stuff more easily (many problems have better error msgs on CPU than GPU with pytorch).

So probably the better fix here is simply to add a comment explaining what's going on.",meant run allow move want stuff easily many better error probably better fix simply add comment explaining going,issue,positive,positive,positive,positive,positive,positive
418447497,I was trying to use the MultiBatchRNN class outside of the fastai training system. I added the reset call in and it's working fine. Thanks.,trying use class outside training system added reset call working fine thanks,issue,positive,positive,positive,positive,positive,positive
418411572,"Closing this as, for one support will stay unofficial for fastai, two, tips and tricks to make the installation work should be discussed on the [forum](http://forums.fast.ai/).",one support stay unofficial two make installation work forum,issue,negative,neutral,neutral,neutral,neutral,neutral
418409840,"My guess is that your dataset is too small so that you have only one iteration per epoch, which launched a training with cut_pt = 0. I would add more data or launch a training with more epochs (cycle_len = something more than 1), so that there are more iterations. With just one iteration you won't go far otherwise.",guess small one iteration per epoch training would add data launch training something one iteration wo go far otherwise,issue,negative,negative,neutral,neutral,negative,negative
418407018,fastai is not installable via conda. Please refer to the README or to the [forum](http://forums.fast.ai/) for different ways to install.,via please refer forum different way install,issue,negative,neutral,neutral,neutral,neutral,neutral
418406677,"Not sure we'll change the requirements on this one, it's minimally maintained while we move to fastai_v1 where we'll have more recent requirements.
I'll keep that in mind for the new version!",sure change one minimally move recent keep mind new version,issue,negative,positive,positive,positive,positive,positive
418267036,What python version do you use? If it is 3.4 I would suggest switching to 3.6,python version use would suggest switching,issue,negative,neutral,neutral,neutral,neutral,neutral
417903691,"Try this:
```
conda config --add channels conda-forge
conda install shapely
conda env update
```
If your situation matches mine you will then experience an issue building fiona (wheel). I did:
```
pip install scipy
pip install plotnine
conda install fiona
conda env update
```
",try add install shapely update situation mine experience issue building wheel pip install pip install install update,issue,negative,neutral,neutral,neutral,neutral,neutral
417697557,"Pytorch can now be installed on Windows, there is also a [thread on the forum](http://forums.fast.ai/t/howto-installation-on-windows/10439) on how to install fastai on Windows. ",also thread forum install,issue,negative,neutral,neutral,neutral,neutral,neutral
417695221,You should use the [forums](http://forums.fast.ai/) for this. Are you sure you have a simlink to the fastai folder in your workind directory?,use sure folder directory,issue,negative,positive,positive,positive,positive,positive
417694944,Could you share a bit more about when you get the error? Normally there has been a call to the reset method of MultiBatchRNN (which is the same as RNN_Encoder) that creates this hidden state.,could share bit get error normally call reset method hidden state,issue,negative,negative,neutral,neutral,negative,negative
417359331,I'm not sure why the redundancy exists in the first place. Perhaps the idea was to have more friendlier messages that would clearly identify the erring variable?,sure redundancy first place perhaps idea would clearly identify erring variable,issue,positive,positive,positive,positive,positive,positive
416970674,I ran the notebook out of the box. I didn't change a line of code other than the input directories. The error was within the classes...,ran notebook box change line code input error within class,issue,negative,neutral,neutral,neutral,neutral,neutral
416889535,"**Worked for me in windows 10 after the same error, but gets too complicated**

Download the Python 3.6 version of Shapely from https://www.lfd.uci.edu/~gohlke/pythonlibs/#shapely

Install the wheel file with pip **and remember to activate the anaconda environment beforehand**

(source: https://stackoverflow.com/questions/43182999/issue-installing-shapely-python-package)

After you should get another error with installing Fiona. I ran this command ""conda install -c conda-forge fiona"".

Now there should be problems with the jupyter notebook, since the symbolic links will not work. 
",worked error complicated python version shapely install wheel file pip remember activate anaconda environment beforehand source get another error ran command install notebook since symbolic link work,issue,negative,negative,negative,negative,negative,negative
416886337,@mknippen see courses/dl2/imdb.ipynb for a sentiment binary classification example,see sentiment binary classification example,issue,negative,neutral,neutral,neutral,neutral,neutral
416613937,"I have the same error, have one of you been able to solve it? @wenouyang  @AstaTus ",error one able solve,issue,negative,positive,positive,positive,positive,positive
416607341,"I have submitted a pull request now so hopefully we can close this one

https://github.com/fastai/fastai/pull/733",pull request hopefully close one,issue,negative,neutral,neutral,neutral,neutral,neutral
415309506,"Oh, it could be messy indeed. Please feel free to propose a PR about this.",oh could messy indeed please feel free propose,issue,negative,positive,neutral,neutral,positive,positive
415309253,"Please use the [forum](http://forums.fast.ai/) for questions about notebook. accuracy_np is for numpy arrays, not torch tensors, this is why you're getting an error.",please use forum notebook torch getting error,issue,negative,neutral,neutral,neutral,neutral,neutral
415309046,Please the [forum](http://forums.fast.ai/) for these questions. The error message indicates you didn't pass your model on the GPU.,please forum error message pas model,issue,negative,neutral,neutral,neutral,neutral,neutral
414804999,"yes, i'll send a revision shortly. ",yes send revision shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
414548922,"Thank you for clarification! Should be fixed how, hope I understood the purpose of `store` correctly",thank clarification fixed hope understood purpose store correctly,issue,positive,positive,neutral,neutral,positive,positive
414519027,"You need to use `self.store` to avoid race conditions. So better to change what's checked, rather than what's set.",need use avoid race better change checked rather set,issue,negative,positive,positive,positive,positive,positive
414395969,"Is it still the case that Macs aren't a supported platform for fastai (ULMFiT in particular)?
I'm running into a similar issue running `conda env update`, and 1 reported error upon running `pytest tests`:

`E   ModuleNotFoundError: No module named 'testfixtures'`",still case platform particular running similar issue running update error upon running module,issue,negative,positive,neutral,neutral,positive,positive
414116142,"Can you paste your ""pip list"" here please?

",paste pip list please,issue,negative,neutral,neutral,neutral,neutral,neutral
414113834,"One more bit that may or may not help you:

In jupyter the line ""from fastai.imports import *"" produces the following output which (after some internet research) I believe to be ignorable:

/home/reinz/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/reinz/anaconda3/envs/fastai/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/home/reinz/anaconda3/envs/fastai/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.
  from numpy.core.umath_tests import inner1d",one bit may may help line import following output research believe ignorable size may indicate binary incompatibility got return size may indicate binary incompatibility got return internal module removed future release import,issue,negative,neutral,neutral,neutral,neutral,neutral
414113141,To be clear: in the jupyter notebook both torch.cuda.is_available() and torch.backends.cudnn.enabled evaluate to True,clear notebook evaluate true,issue,positive,positive,positive,positive,positive,positive
414112947,"Just to make sure I rebooted my machine and re-ran all the tests. 

As you can see the output is unchanged: 
[testresuts_all.txt](https://github.com/fastai/fastai/files/2300174/testresuts_all.txt)

",make sure machine see output unchanged,issue,negative,positive,positive,positive,positive,positive
414112865,"Mmm, maybe we should put the tests requiring the GPU under a test torch.cuda.is_available? Even if it's not the first intent, we'd still like the library to be functional in a CPU-only environment.",maybe put test even first intent still like library functional environment,issue,negative,positive,positive,positive,positive,positive
414112243,"Yes, the other tests ran successfully. 

I also ran the dl course lesson 1 notebook since reporting this issue -- that worked.
",yes ran successfully also ran course lesson notebook since issue worked,issue,positive,positive,positive,positive,positive,positive
414111214,"Sure, I'll take a look asap (today or tomorrow)",sure take look today tomorrow,issue,negative,positive,positive,positive,positive,positive
414037428,Added it in the environment. Thanks for pointing this out!,added environment thanks pointing,issue,negative,positive,positive,positive,positive,positive
414037366,"@hermesdt Could you like at this? Not sure, but it looks like it's in the new tests you implemented.",could like sure like new,issue,positive,positive,positive,positive,positive,positive
414021117,There's a new transform pipeline now available in fastai_v1,new transform pipeline available,issue,negative,positive,positive,positive,positive,positive
414021015,"Yes certainly interested! I don't think _cuda makes sense as a suffix, since those funcs are not cuda-specific afaict. Also, you should probably use `to_gpu` as appropriate to respect the USE_GPU flag.",yes certainly interested think sense suffix since also probably use appropriate respect flag,issue,positive,positive,positive,positive,positive,positive
413643175,"As I have a hard dependency on Cuda 9.2 I even have the requirement for torch 0.4.1 to resolve the seemingly closed errors in rnn_reg.py:

```
~/anaconda3/lib/python3.6/site-packages/fastai/rnn_reg.py in forward(self, words, dropout, scale)
    174         if padding_idx is None: padding_idx = -1
    175 
--> 176         X = self.embed._backend.Embedding.apply(words,
    177              masked_embed_weight, padding_idx, self.embed.max_norm,
    178              self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)

~/anaconda3/lib/python3.6/site-packages/torch/nn/backends/backend.py in __getattr__(self, name)
      8         fn = self.function_classes.get(name)
      9         if fn is None:
---> 10             raise NotImplementedError
     11         return fn
     12 

NotImplementedError: 

```
Any hint on where to start is warmly appreciated. Maybe @yurket has some notes or snippets to go by? Thx for the support.",hard dependency even requirement torch resolve seemingly closed forward self dropout scale none self name name none raise return hint start warmly maybe go support,issue,positive,positive,neutral,neutral,positive,positive
413642191,"Doesn't seem to be fixed for Cuda 9.2 and torch 0.4.1 => any hint how you originally fixed it?
Would aim at front-running the same approach locally until 0.4.1 is officially supported.",seem fixed torch hint originally fixed would aim approach locally officially,issue,negative,positive,neutral,neutral,positive,positive
413448523,"@ssmostagh  You need to create a separate environment for cpu-only version of fastai.  
you can use : conda env create -f environment-cpu.yml to create the same. 
Once you have created the environment you might be able to do conda activate fastai-cpu. 

Regarding the tests that are failing, Those are valid cases of that should fail (i believe). If you observe the error stack, it is trying to create half precision tensors which were not available with older GPU's.

**P.S :** Please use forum for discussing issues like this. you will be able to get your responses faster.

~Gokkul",need create separate environment version use create create environment might able activate regarding failing valid fail believe observe error stack trying create half precision available older please use forum like able get faster,issue,negative,positive,positive,positive,positive,positive
413326294,Good catch. Would you mind suggesting a PR that makes this change in fastai?,good catch would mind suggesting change,issue,negative,positive,positive,positive,positive,positive
413110494,Please use the [forum](http://forums.fast.ai/) for this. You might also want to share more of your code so that people can help you more easily.,please use forum might also want share code people help easily,issue,positive,positive,positive,positive,positive,positive
412561610,"As it's minimally maintained, there won't be an effort to change the documentation of fastai now (although any PR in that sense will be accepted). fastai_v1 will be better documented.",minimally wo effort change documentation although sense accepted better,issue,positive,positive,positive,positive,positive,positive
412561050,"This had been endlessly debated on the [forum](http://forums.fast.ai/), lately [here](http://forums.fast.ai/t/recommendation-replace-import-with-import-as/19836) for the development of fastai_v1.
There won't be any change to the way things are imported in fastai as it's only maintained minimally while we develop the next version. ",endlessly forum lately development wo change way minimally develop next version,issue,negative,negative,negative,negative,negative,negative
412559955,"Hey all, could you please use the [forum](http://forums.fast.ai/) to discuss those issues? If there are typos to correct don't hesitate to submit a PR.
get_rnn_classifier and get_rnn_classifer should both work as there is a link from one to the other in the latest version.",hey could please use forum discus correct hesitate submit work link one latest version,issue,negative,positive,positive,positive,positive,positive
412468670,"@happypetewht  This error was due to a spelling mistake. Update the function call to 'get_rnn_classifer' instead of 'get_rnn_classifier'. I faced this error in line 76 of train_clas.py. 

",error due spelling mistake update function call instead faced error line,issue,negative,negative,negative,negative,negative,negative
412416926,"The CI checks fail with an unrelated setup error
```
istutils.errors.DistutilsError: Download error for https://files.pythonhosted.org/packages/69/1c/98cba002ed975a91a0294863d9c774cc0ebe38e05bbb65e83314550b1677/pbr-4.2.0-py2.py3-none-any.whl#sha256=b486975c0cafb6beeb50ca0e17ba047647f229087bd74e37f4a7e2cac17d2caa: [Errno 99] Cannot assign requested address

Command ""python setup.py egg_info"" failed with error code 1 in /tmp/pip-install-bihu24q8/cliff/
CondaValueError: pip returned an error
The command ""conda env update -f environment-cpu.yml"" failed and exited with 1 during .
```

Looks like a Travis CI issue when downloading dependencies",fail unrelated setup error error assign address command python error code pip returned error command update like travis issue,issue,negative,negative,negative,negative,negative,negative
412366607,you can install the latest version on goggle colab with `pip install git+https://github.com/fastai/fastai.git`,install latest version goggle pip install,issue,negative,positive,positive,positive,positive,positive
412364685,Thank for sharing that. I tried git pull. It does not work. I am using Google Colab now. Maybe that is the problem. Every time I have to pip install fastai. I think it would update it automatically,thank tried git pull work maybe problem every time pip install think would update automatically,issue,negative,neutral,neutral,neutral,neutral,neutral
412314631,"`fastai.lm_rnn.get_rnn_classifier` imports on my end. you can try updating your version of the library with `git pull`
<img width=""403"" alt=""screen shot 2018-08-11 at 10 46 59 pm"" src=""https://user-images.githubusercontent.com/24426271/43997956-7f834d9c-9db8-11e8-9205-7b05c75fcbad.png"">
",end try version library git pull screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
412001856,"You should go on the [forum](http://forums.fast.ai) for more help, but your error comes from get_model refusing n_hid as an argument. In older versions it used to be nhid that's why I told you to double check you have the latest library.",go forum help error come refusing argument older used told double check latest library,issue,negative,positive,positive,positive,positive,positive
411966310,"@sgugger Yes, i  used the last version, but i still have this bug.why?",yes used last version still,issue,negative,neutral,neutral,neutral,neutral,neutral
411908589,"Eh, this file has no reason to be here, it comes from the old course. Closing this but removing the file entirely, thanks for pointing this out!",eh file reason come old course removing file entirely thanks pointing,issue,negative,positive,positive,positive,positive,positive
411862296,Please use the [forum](http://forums.fast.ai/) for those questions. Be sure to share more details (for instance how you created your learner) as it'll help people give you an answer faster.,please use forum sure share instance learner help people give answer faster,issue,positive,positive,positive,positive,positive,positive
411680996,"You need to use the last version of the fastai library, just git pull in the fastai directory to update it.",need use last version library git pull directory update,issue,negative,neutral,neutral,neutral,neutral,neutral
411679237,"dir_path data/wiki/en/; cuda_id 0; cl 12; bs 64; backwards False; lr 0.001; sampled True; pretrain_id
Traceback (most recent call last):
  File ""pretrain_lm.py"", line 53, in <module>
    if __name__ == '__main__': fire.Fire(train_lm)
  File ""/home/cindy.ll/.conda/envs/ulm_env/lib/python3.6/site-packages/fire/core.py"", line 127, in Fire
    component_trace = _Fire(component, args, context, name)
  File ""/home/cindy.ll/.conda/envs/ulm_env/lib/python3.6/site-packages/fire/core.py"", line 366, in _Fire
    component, remaining_args)
  File ""/home/cindy.ll/.conda/envs/ulm_env/lib/python3.6/site-packages/fire/core.py"", line 542, in _CallCallable
    result = fn(*varargs, **kwargs)
  File ""pretrain_lm.py"", line 42, in train_lm
    learner,crit = get_learner(drops, 15000, sampled, md, em_sz, nh, nl, opt_fn, tprs)
  File ""/home/cindy.ll/codes/fastai/courses/dl2/imdb_scripts/sampled_sm.py"", line 86, in get_learner
    m = to_gpu(get_language_model(md.n_tok, em_sz, nh, nl, md.pad_idx, decode_train=False, dropouts=drops))
  File ""/home/cindy.ll/codes/fastai/courses/dl2/imdb_scripts/sampled_sm.py"", line 47, in get_language_model
    dropouti=dropouts[0], wdrop=dropouts[2], dropoute=dropouts[3], dropouth=dropouts[4])
TypeError: __init__() got an unexpected keyword argument 'n_hid'",backwards false true recent call last file line module file line fire component context name file line component file line result file line learner file line file line got unexpected argument,issue,negative,positive,neutral,neutral,positive,positive
411302309,Please use the [forum](http://forums.fast.ai/) for this. There is also detailed explanation on how to install without pip.,please use forum also detailed explanation install without pip,issue,negative,positive,positive,positive,positive,positive
410611939,@sebastianruder I'll let you check this one (Travis check failed for a reason unrelated to this script).,let check one travis check reason unrelated script,issue,negative,neutral,neutral,neutral,neutral,neutral
410441433,Issues are for the library only. This question would be better asked on the [forum](http://forums.fast.ai/). Tagging Sebastian Ruder might be useful.,library question would better forum might useful,issue,positive,positive,positive,positive,positive,positive
410431616,"Your change wasn't my original intention but I think it's a reasonable behavior -- My intention was to preserve the old behavior in `resume=False` which was to not do anything if `newpath/targs` existed (essentially, ""have we ever tried to resize to this size""). In hindsight, it's not super clear that that's a useful thing -- I think your change probably makes sense; resume=False -> redo everything. resume=True -> start from currently existing images",change original intention think reasonable behavior intention preserve old behavior anything essentially ever tried resize size hindsight super clear useful thing think change probably sense redo everything start currently,issue,positive,positive,positive,positive,positive,positive
410429943,"Thanks. I've added some clean-up (removed one last type and changed the doc strings so that they match the rest of the library).
Also, when resume=False you were putting the filenames list to [] so it wasn't doing anything (instead of starting back from 0). I'll let you check the modifications I made and tell me if it's okay to merge.",thanks added removed one last type doc match rest library also list anything instead starting back let check made tell merge,issue,negative,positive,neutral,neutral,positive,positive
410429293,Removed the type annotations and made it a bit more fault tolerant,removed type made bit fault tolerant,issue,negative,neutral,neutral,neutral,neutral,neutral
410381759,"Hi,
fastai won't support python 3.7 for this reason, since it won't officially support pytorch 0.4. You should install in an environment with python 3.6.
fastai_v1 will support pytorch 3.7 on the other hand, but that will be for October!",hi wo support python reason since wo officially support install environment python support hand,issue,positive,neutral,neutral,neutral,neutral,neutral
410380838,"Thanks a lot for all the work. As you suggested though, we'd rather not have the types inside the code since it's not done anywhere else. That way the code of the library will remain consistent. Could you just remove them?
We're adding types in fastai_v1 by using annotations, I hope that'll make life easier for pycharm user :)",thanks lot work though rather inside code since done anywhere else way code library remain consistent could remove hope make life easier user,issue,positive,positive,positive,positive,positive,positive
410164037,"Hi there,

This would be best asked on the [forum](http://forums.fast.ai/). The best way to answer your question is probably to load the model and validate it.",hi would best forum best way answer question probably load model validate,issue,positive,positive,positive,positive,positive,positive
409703546,"The current implementation needs to also check for old GPUs. Currently if a system has CUDA and cuDNN installed but has a GPU with compute capability <3, it results in failure, while all the checks are seemingly fine! Incorporating a simple check like the one below should fix this issue : 
```
def is_gpu_supported():
    for d in range(torch.cuda.device_count()):
        capability = torch.cuda.get_device_capability(d)[0]
        return False if capability < 3 else True

USE_GPU = torch.cuda.is_available()
def to_gpu(x, *args, **kwargs):
    '''puts pytorch variable to gpu, if cuda is available and USE_GPU is set to true. '''
    return x.cuda(*args, **kwargs) if (USE_GPU and is_gpu_supported()) else x
```",current implementation need also check old currently system compute capability failure seemingly fine simple check like one fix issue range capability return false capability else true variable available set return else,issue,negative,positive,neutral,neutral,positive,positive
409649399,"I run ~5-6 lessons notebooks with pytorch 4.0 on Linux and had to make just a couple small fixes. So the majority of the code should work fine with pytorch 4.0, I suppose. ",run make couple small majority code work fine suppose,issue,negative,positive,neutral,neutral,positive,positive
409579828,"Thanks for your reply ,now i am  a member  of this forum already.
i am searching useful information about this error ,but i still can't find.
I have only 8GB RAM ,and the system always said the memory error.
i don't know how to modify the  create_toks.py to adapt my RAM.
I would be most grateful if you could lend me a hand at your convenice.",thanks reply member forum already searching useful information error still ca find ram system always said memory error know modify adapt ram would grateful could lend hand,issue,positive,positive,positive,positive,positive,positive
409574486,Could you test it more then propose your script in a PR? It sounds like a nice feature.,could test propose script like nice feature,issue,positive,positive,positive,positive,positive,positive
409573791,Please use the [forum](http://forums.fast.ai/) for this kind of problems.,please use forum kind,issue,positive,positive,positive,positive,positive,positive
409472013,"Can we use CUDA9.2  and associates with fastai enviorment.
Also let me know difference between CUDA9.0 and CUDA90",use also let know difference,issue,negative,neutral,neutral,neutral,neutral,neutral
409218471,"I had this issue in Linux, however, my install was a little unusual (I have an old GPU with my own build from source).

@nikos-h 
I fixed it with 
```
    if dim == 2:
        return torch._C._nn.nll_loss(
            input, _Variable.long(target)_,
            weight, size_average,
            ignore_index, reduce
        )

```
in place of,
```
    if dim == 2:
        return torch._C._nn.nll_loss(input, _target_, weight, size_average, ignore_index, reduce)
```

but the error on python should be clear enough to tell you the exact place where this fails. you may not have `dim == 2`, for example.",issue however install little unusual old build source fixed dim return input target weight reduce place dim return input weight reduce error python clear enough tell exact place may dim example,issue,negative,positive,neutral,neutral,positive,positive
409102137,"Thank you, @sgugger. in the future I can close such open issued myself, it just might not happen immediately, I usually do that once I see the PR merged. But feel free to beat me to it any time.",thank future close open might happen immediately usually see feel free beat time,issue,positive,positive,neutral,neutral,positive,positive
409047819,"First thing I see: feedparser isn't in the dependencies of fastai, so you should add a mention that the user should install it.",first thing see add mention user install,issue,negative,positive,positive,positive,positive,positive
409016148,"I guess for now let's just add it into the notebook itself, since it's not being used a the moment anywhere else. Please see: https://github.com/fastai/fastai/pull/669",guess let add notebook since used moment anywhere else please see,issue,negative,neutral,neutral,neutral,neutral,neutral
408871646,"Mmm, when we start using the same code so many times, it means we need a helper function. I think the best solution is to write a function datafy that takes an object like preds/y and returns:
- preds.data if preds is not a list
- [o.data for o in preds] if preds is a list
Then all of this code will be simplified into 
res.append([f(datafy(preds), datafy(y)) for f in metrics)])
Can you modify your PR into something like that?",start code many time need helper function think best solution write function object like list list code simplified metric modify something like,issue,positive,positive,positive,positive,positive,positive
408870177,"@sgugger would you mind looking at this, it's a similar fix to #660 which you previously approved.",would mind looking similar fix previously,issue,negative,negative,neutral,neutral,negative,negative
408859755,Strange. Why should it first pass and then fail when all I did was add a space?,strange first pas fail add space,issue,negative,negative,neutral,neutral,negative,negative
408846260,"Hey, there has been some changes on this functions with another PR that I merged today (which is why I had to revert this one). Could you do another PR that changes the new ones (recall, recall_np, precision, precision_np)? Thanks a lot!",hey another today revert one could another new recall precision thanks lot,issue,negative,positive,positive,positive,positive,positive
408844493,Thanks for digging into this! Just changed your code to go with the usual fastai style and will merge when the automatic checks are passed.,thanks digging code go usual style merge automatic,issue,negative,negative,neutral,neutral,negative,negative
408717691,"Meanwhile, I checked the notebooks and submitted https://github.com/fastai/fastai/pull/661
I think more work will be needed to sort out the log- vs non-log- versions of `preds`.",meanwhile checked think work sort,issue,negative,neutral,neutral,neutral,neutral,neutral
408709613,"The current way the accuracy functions in the pascal notebook are setup, requires that the full y list be passed in, which is then handled within the function
i.e.
```
def detn_l1(input, target):
    bb_t,_ = target
    bb_i = input[:, :4]
    bb_i = F.sigmoid(bb_i)*224
    return F.l1_loss(V(bb_i),V(bb_t)).data

def detn_acc(input, target):
    _,c_t = target
    c_i = input[:, 4:]
    return accuracy(c_i, c_t)
```

I've sent in a PR which handles y if it's listy, by passing the complete y list/tuple to the function, and therefore the above works as expected",current way accuracy notebook setup full list handled within function input target target input return input target target input return accuracy sent passing complete function therefore work,issue,negative,positive,positive,positive,positive,positive
408584066,"That is doable, what about the log argument part? Do we make the `log_preds` the argument for those functions, instead of `preds`? I guess `precision` and `recall` can remain receiving `preds`, which would save doing `torch.exp()` twice - basically as I suggested in the code above. What I mean is that `_np` will vary not only in receiving non-torch, but also non-log `preds` (for `f1`/`fbeta` functions)

And while were are at it, would it make things more consistent to exp() `accuracy`'s `preds` argument?
It happens to achieve the same thing without `exp()` but is inconsistent with other metrics functions. I also found it strange to get all those negative prediction when debugging things.",doable log argument part make argument instead guess precision recall remain would save twice basically code mean vary also would make consistent accuracy argument achieve thing without inconsistent metric also found strange get negative prediction,issue,negative,negative,negative,negative,negative,negative
408535016,"I guess we should follow the same template as `accuracy` et al - the version without a suffix is torch, and the np version has `_np`; this does require modifying the notebooks though, which is a bit of extra trouble!",guess follow template accuracy al version without suffix torch version require though bit extra trouble,issue,negative,negative,neutral,neutral,negative,negative
408444163,Please use the [forum](http://forums.fast.ai/) for this kind of issues. My guess is that there is no simlink to the fastai library in the directory you are working in.,please use forum kind guess library directory working,issue,positive,positive,positive,positive,positive,positive
408248787,"@Varal7 this is true. 

There's a whole set of questions on the forum about ""what are these numbers which come back as classifier scores"" and ""why don't they add up to 1"" etc. The answer is always softmax, and my thought was to include it to avoid all that confusion. ",true whole set forum come back classifier add answer always thought include avoid confusion,issue,negative,positive,positive,positive,positive,positive
408239462,"Good idea!
I think, you can just use argmax instead of softmax for inference",good idea think use instead inference,issue,negative,positive,positive,positive,positive,positive
408093522,"Fine.. I have sorted out the issue.
Thanks closing it",fine sorted issue thanks,issue,positive,positive,positive,positive,positive,positive
408092978,"As @Gokkulnath said, please use the forum for this kind of questions. There is a detailed step by step process to install the library [here](http://forums.fast.ai/t/howto-installation-on-windows/10439), you apparently need to redo step 8.",said please use forum kind detailed step step process install library apparently need redo step,issue,positive,positive,positive,positive,positive,positive
408092516,"Hi, please use the [forum](http://forums.fast.ai/) for this.",hi please use forum,issue,negative,neutral,neutral,neutral,neutral,neutral
407996245,"hi @srinivasPrashanth027 
I guess symlink for fastai folder is missing. Can you check if it is there ?
P.S : Please refrain from raising a issue here instead please use [forums](http://forums.fast.ai/) for such queries. Most of the time you might find the solution already available there .

Regards,
Gokkul",hi guess folder missing check please refrain raising issue instead please use time might find solution already available,issue,positive,positive,neutral,neutral,positive,positive
407771203,"I am not sure, what to do with it. As you can see, this error is not related to fastai library, but something with external packages - pandas , feather-format, (numpy according to your gdb output). If it is not reproducible outside that specific instanse, it will be pretty hard to fix. I am not very confident with debugging low level code, so you should probably create an Issue in pandas repo and provide the core dump.",sure see error related library something external according output reproducible outside specific pretty hard fix confident low level code probably create issue provide core dump,issue,negative,positive,positive,positive,positive,positive
407756396,"Oh, disregard my comment. I had forgotten it was a model and not a learner wrapped around a model the user could define himself.",oh disregard comment forgotten model learner wrapped around model user could define,issue,negative,neutral,neutral,neutral,neutral,neutral
407624308,"No @sgugger means APIs for vision, NLP, etc. We have no immediate plans for additional backends, but maybe in the future that will change.",vision immediate additional maybe future change,issue,negative,neutral,neutral,neutral,neutral,neutral
407623188,"I'm not sure I follow you, this is exactly what I had the problem with - a binary classifier with 0/1 output. And after a lot of debug I finally figured it required out_sz=2, and then it all worked. Hence the suggestion. It doesn't work with out_sz=1 and bails with all kinds of mismatch issues on the CUDA side.

Are you talking about the same? ",sure follow exactly problem binary classifier output lot finally figured worked hence suggestion work mismatch side talking,issue,negative,positive,positive,positive,positive,positive
407622639,"Yup, though I'd prefer a warning because someone could design a classifier with just a 0/1 output (though they would have to be careful with the loss).",though prefer warning someone could design classifier output though would careful loss,issue,negative,negative,neutral,neutral,negative,negative
407621485,"OK, I now found the definition in conv_learner.py - thank you. I wrongly assumed it was multiclass.

In which case the assert would be simplified to something like this:

`if is_reg==False: assert out_sz >= 2,  ""is_reg==False (classification) requires out_sz>=2""`
",found definition thank wrongly assumed case assert would simplified something like assert classification,issue,positive,negative,negative,negative,negative,negative
407620548,"I think you confuse is_multi with something else: it's like in lesson 2, the difference between the planet and the dogs/cats dataset. is_multi means we can have multiple labels for the same entry. Even with 2 outputs, it could be possible to have is_multi=True if the two outputs can be 1 together, and we can also have a model with n outputs where is_multi=False, it just means that you can only have one label that is true at a time.
It terms of internals, this just decides what is the proper loss last activation (a log_softmax when is_multi=False and a sigmoid when is_multi=True).",think confuse something else like lesson difference planet multiple entry even could possible two together also model one label true time internals proper loss last activation sigmoid,issue,negative,positive,neutral,neutral,positive,positive
407607110,"> ""... that ties all the existing APIs together.""

Wait a minute... that's _very_ interesting! Can you clarify what all APIs we're talking about here?

Is the idea to have fastai be a higher level wrapper over both PyTorch and TensorFlow? That would be terrific!",together wait minute interesting clarify talking idea higher level wrapper would terrific,issue,positive,positive,positive,positive,positive,positive
407573233,"I found the culprit, the notebook code had this marvel:

```
df = train[columns]
df = test[columns]
```

so that the data was missed, and resulting in categories with just `NaN`s in them.

Deleting the 2nd line fixes things up, but I have a question here - what if some values of the categories appear only in the test set and not in the train set? I think it's much safer to combine the two and ensure we get them all. i.e.:

`df = train[columns].append(test[columns])`

I tested that the combination of the two works.

Proposed changes: https://github.com/fastai/fastai/pull/651

This is a very unusual domain - things can be missed so easily and there is no rigorous way to detect such problems.",found culprit notebook code marvel train test data resulting nan line question appear test set train set think much combine two ensure get train test tested combination two work unusual domain easily rigorous way detect,issue,positive,positive,positive,positive,positive,positive
407563804,"Ah! This is a skip for the n first epochs, not validate every n epochs. I got confused.
Yes your approach makes more sense then.",ah skip first validate every got confused yes approach sense,issue,negative,negative,neutral,neutral,negative,negative
407562657,"Sorry maybe I was too vague.

let's say you have 10 epochs and you skip validation for 5 epochs. Without your change to the LossRecorder, at the end self.losses will have 10 values, and self.val_losses as well, with the first 5 being 'nan', e.g.  losses=[9,8,7,6,5,4,3,2,1,0]  and val_losses=[nan, nan, nan, nan, nan, 14, 13, 12, 11, 10]

with that, you can directly plot both of these lists and they will properly align with the epoch x axis of the plot, without any post-processing:
plt.plot(list(range(10)), losses, val_losses)

In other words, plot already handles nan values just fine, which is quite convenient. There's no need to (and I'm arguing you shouldn't) filter them out during recording. No processing needed at all.

with your change you will get self.losses [0,1,2,3,4,5,6,7,8,9] and self.val_losses [5, 6, 7, 8, 9], and indeed you will need to post-process those lists if you want to plot them (or do some other analysis).",sorry maybe vague let say skip validation without change end well first nan nan nan nan nan directly plot properly align epoch axis plot without list range plot already nan fine quite convenient need filter recording change get indeed need want plot analysis,issue,negative,negative,neutral,neutral,negative,negative
407556281,"I don't get what you mean for the plot. If I put some float('nan') in a list, I get an empty plot at the end, which is why I was removing the values. I get it's not ideal because it won't have the same number of elements as the normal losses, but there is some processing to do at the end in any case.",get mean plot put float list get empty plot end removing get ideal wo number normal end case,issue,negative,positive,positive,positive,positive,positive
407551107,"That's probably it, yes. Would you mind proposing a PR to fix this?",probably yes would mind fix,issue,negative,neutral,neutral,neutral,neutral,neutral
407507784,"I did some more debug and found out that some of the embeddings were getting cardinality of 1, and it must be at least 2.

```
 [(1116, 50),
  (8, 4),
  (4, 2),
  (13, 7),
  (32, 16),
  (3, 2),
  (26, 13),
  (27, 14),
  (5, 3),
  (4, 2),
  (4, 2),
  (24, 12),
  (9, 5),
  (13, 7),
  (53, 27),
  (22, 11),
  (1, 1),
  (1, 1),
  (1, 1),
  (1, 1),
  (1, 1),
  (1, 1)]
```

I'm still investigating how that happened, but meanwhile I added some defensive validation of embeddings, if it's acceptable:

```
--- a/fastai/column_data.py
+++ b/fastai/column_data.py
@@ -89,6 +89,7 @@ class MixedInputModel(nn.Module):
     def __init__(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,
                  y_range=None, use_bn=False, is_reg=True, is_multi=False):
         super().__init__()
+        for i,(c,s) in enumerate(emb_szs): assert c > 1, f""cardinality must be >=2, got emb_szs[{i}]: ({c},{s})""
         self.embs = nn.ModuleList([nn.Embedding(c, s) for c,s in emb_szs])
         for emb in self.embs: emb_init(emb)
         n_emb = sum(e.embedding_dim for e in self.embs)
```

now the invalid embeddings above get rejected with:

`AssertionError: cardinality must be >=2, got emb_szs[16]: (1,1)`",found getting must least still investigating meanwhile added defensive validation acceptable class self super enumerate assert must got sum invalid get must got,issue,positive,positive,neutral,neutral,positive,positive
407452782,"The changes for the class SaveBestModel look fine and look indeed more elegant than mine.

But I'm not quite sure about the changes for the class LossRecorder. If you don't record the nan values for the validation losses, the losses and val_losses lists won't have the same length, which might later be an issue when you want to analyze/plot both recorded losses:
they won't align anymore (side node: plotting a list with some nan values actually works, which is nice because the plot has the proper x axis values, and you can plot both training and validation losses on the same plot even if you skipped some validation epochs).
",class look fine look indeed elegant mine quite sure class record nan validation wo length might later issue want wo align side node plotting list nan actually work nice plot proper axis plot training validation plot even validation,issue,positive,positive,positive,positive,positive,positive
407447185,"I see your points. I made a few changes, let me know if it seems okay to you.",see made let know,issue,negative,neutral,neutral,neutral,neutral,neutral
407414316,"I thought about it, but there are several drawbacks with this approach, and that's why I went with the approach in this pull request:

- in my local sandbox, I can also compute global metrics on some other dataset periodically. Not printing anything at all (i.e. not even ""nan"") would create issues for stats/column alignments during the progress reports

- as you said, that requires to go through all the on_epoch_end callbacks, and it's likely to break ppl's code/notebooks as well. My gut feeling was that ""nan"" float wouldn't break legacy/other ppl's code as much as not providing metrics at all.
As another example, the ""visualize"" option does not break with nan, it just doesn't print any graphical arrow (since boolean on 'nan' are False). If you really skip validation values (instead of putting 'nan'), the visualize feature in print_stats() is going to break unless it is changed as well.

- cosmetics: the conditional if in fit() around the validate() call didn't look as nice as an extra argument

I really think using 'nan' would be more elegant and more bug-proof for this feature.",thought several approach went approach pull request local sandbox also compute global metric periodically printing anything even nan would create progress said go likely break well gut feeling nan float would break code much providing metric another example visualize option break nan print graphical arrow since false really skip validation instead visualize feature going break unless well conditional fit around validate call look nice extra argument really think would elegant feature,issue,positive,positive,positive,positive,positive,positive
407409473,"That's a good idea: one thing though, I'd rather have the validate function not be called at all and nothing printed when we skip the validation. Then in all the on_epoch_end callbacks, we should add a test to detect if the metrics in the argument is None or not.",good idea one thing though rather validate function nothing printed skip validation add test detect metric argument none,issue,negative,positive,positive,positive,positive,positive
407404282,"This CUDA error message often comes from a bad index (though it might be something else). Basically to build the summary, we have to get an input through it and analyze the shapes of the different tensors that come through each steps. Here, the fake input built seems to have the wrong shape?
I'll try to go through it when I have time.",error message often come bad index though might something else basically build summary get input analyze different come fake input built wrong shape try go time,issue,negative,negative,negative,negative,negative,negative
407326201,"It looks like one check failed, but considering my change is unrelated, I'm guessing the upstream master is failing as well.
(and it's not failing in my current sandbox)",like one check considering change unrelated guessing upstream master failing well failing current sandbox,issue,negative,neutral,neutral,neutral,neutral,neutral
407324883,"The change worked in a custom notebook, but in dl1/lesson3-rossman.ipynb, it still fails, now with a different issue:

`/pytorch/torch/lib/THC/THCTensorIndex.cu:306: void indexSelectSmallIndex(TensorInfo<T, IndexType>, TensorInfo<T, IndexType>, TensorInfo<long, IndexType>, int, int, IndexType, long) [with T = float, IndexType = unsigned int, DstDim = 1, SrcDim = 1, IdxDim = -2]: block: [0,0,0], thread: [0,0,0] Assertion `srcIndex < srcSelectDimSize` failed.`

I pulled the relevant code out to have it in one place:
```
m = md.get_learner(emb_szs, n_cont=(len(df.columns)-len(cat_vars)),
                   emb_drop=0.04, out_sz=1, szs=[1000,500], drops=[0.001,0.01], y_range=y_range)
#m.summary() XXX: here

data=m.data
x = [torch.ones(3, data.trn_ds.cats.shape[1]).long(), torch.rand(3, data.trn_ds.conts.shape[1])]
model_summary(m.model, x)
```

failing with the full trace:

```
RuntimeError                              Traceback (most recent call last)
<ipython-input-87-3c91ba915470> in <module>()
     12 #x = [torch.from_numpy(a), torch.rand(3, data.trn_ds.conts.shape[1])]
     13 x
---> 14 model_summary(m.model, x)
     15 
     16 

/mnt/disc1/fast.ai/fastai/courses/dl1/fastai/model.py in model_summary(m, inputs)
    319     m.apply(register_hook)
    320     xs = [to_gpu(Variable(x)) for x in inputs]
--> 321     m(*xs)
    322 
    323     for h in hooks: h.remove()

~/build/myenv/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
    355             result = self._slow_forward(*input, **kwargs)
    356         else:
--> 357             result = self.forward(*input, **kwargs)
    358         for hook in self._forward_hooks.values():
    359             hook_result = hook(self, input, result)

/mnt/disc1/fast.ai/fastai/courses/dl1/fastai/column_data.py in forward(self, x_cat, x_cont)
    114         if self.n_emb != 0:
    115             x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]
--> 116             x = torch.cat(x, 1)
    117             x = self.emb_drop(x)
    118         if self.n_cont != 0:

RuntimeError: cuda runtime error (59) : device-side assert triggered at /pytorch/torch/lib/THC/generic/THCTensorMath.cu:243
```

and in the jupyter logs the pytorch error at the very top of this message.

Any ideas?",change worked custom notebook still different issue void long long float unsigned block thread assertion relevant code one place failing full trace recent call last module variable self input result input else result input hook hook self input result forward self enumerate error assert triggered error top message,issue,negative,positive,positive,positive,positive,positive
407056625,"Thanks for offering to help!
Normally when you get the x,y from your test augmentation dataloader, y has been transformed accordingly (as long as you have tfm_y put the good value, here it would be tfmType.CLASS I guess), like the train dataloader.
My guess is that inside the current TTA function predict_with_targs applied with dl2 probably already returns the targets appropriately transformed (but the TTA function doesn't look at them for now) though it would need to be tested.

The PR would need to be done to the fastai repo. fasatai_v1 is in the very early stages of development (there's no library for now, just dev notebooks).

",thanks offering help normally get test augmentation accordingly long put good value would guess like train guess inside current function applied probably already appropriately function look though would need tested would need done early development library dev,issue,positive,positive,positive,positive,positive,positive
407050751,"No problem.  I would be glad to help with this.
Do you know if fastai keeps track of what transformation was applied?  
How is the best way to contribute? PR to fastai repo or fastai_v1? Is fastai_v1 stable?",problem would glad help know track transformation applied best way contribute stable,issue,positive,positive,positive,positive,positive,positive
406954211,"Sounds good, @sgugger. I will then continue sending what I find can improve user's experience as I gradually find my way through fastai codebase.

Thank you for your support so far.",good continue sending find improve user experience gradually find way thank support far,issue,positive,positive,positive,positive,positive,positive
406919025,"Any PR fixing this would be welcome, yes. Thanks for volunteering!",fixing would welcome yes thanks,issue,positive,positive,positive,positive,positive,positive
406910604,"There is always a point in making small adjustments if it helps users in the meantime (and some may not want to go to v1). In any case it's useful for us to take note of all of these bugs/lack of features to make sure the next version is better.
We are in the early stages of development for now, but as soon as there is something to share and test, Jeremy will ask for help (there is a section dedicated to the development on the forum).",always point making small may want go case useful u take note make sure next version better early development soon something share test ask help section development forum,issue,positive,positive,positive,positive,positive,positive
406910300,"Good point.
We are in the process of rewriting the library entirely with Jeremy, so we will keep this in mind for fastai_v1. In the meantime though, the adjustments we make to this library are minimal (by lack of time). If you can see how to make a PR to correct this, we'll gladly accept it, otherwise it will have to wait for v1.",good point process library entirely keep mind though make library minimal lack time see make correct gladly accept otherwise wait,issue,positive,positive,positive,positive,positive,positive
406901404,"> Jeremy and I are in the process of rewriting the library completely for the v1, so this is going to be the version with a better API. For now we just maintain this one minimally, but a PR aimed at better user interface will always be appreciated.

Awesome! Then is there a point of working on this kind improvements in the current codebase? Is this useful and you backport these PRs to the new codebase? or perhaps if you release the beta soon I can just start using that and help with what I can from the user side, making the API more defensive. I'm also aware that this is taking your time, reviewing, validating and commenting, so perhaps these PRs for the current codebase are counterproductive?

I have just spent many hours hunting some strange failure in CUDA, until I finally removed a few parameters in the call in ColumnarModelData.from_data_frame and then it worked. So I am going to dig in and try to understand why fastai didn't handle it gracefully - since CUDA level errors are not helpful at all.",process library completely going version better maintain one minimally better user interface always awesome point working kind current useful new perhaps release beta soon start help user side making defensive also aware taking time perhaps current spent many hunting strange failure finally removed call worked going dig try understand handle gracefully since level helpful,issue,positive,positive,positive,positive,positive,positive
406901042,"I added asserts to cover #2 in my comment above - there are only 2 such tests, not 3.

#1 assert is completely unrelated, since it needs either of 3 to be deployed.",added cover comment assert completely unrelated since need either,issue,negative,positive,neutral,neutral,positive,positive
406899179,"Jeremy and I are in the process of rewriting the library completely for the v1, so this is going to be the version with a better API. For now we just maintain this one minimally, but a PR aimed at better user interface will always be appreciated.
I think an assert cycle_len in the three tests (cycle_save_name, use_clr, use_clr_beta) would be the best way.",process library completely going version better maintain one minimally better user interface always think assert three would best way,issue,positive,positive,positive,positive,positive,positive
406898829,"I don't see any such asserts, but you're correct that they should assert, as `cycle_len` is being used without validating whether it has been passed:

```
def fit_gen(...cycle_len=None...
... no cycle_len checking... and then using it:
self.sched = CircularLR(layer_opt, len(data.trn_dl)*cycle_len
```

that's not the greatest code. If it's required, shouldn't the API tell the user so?

So perhaps we need 2 unrelated asserts:

1. cycle_save_name requiring cycle_len or use_clr or use_clr_beta
2. use_clr, use_clr_beta both requiring cycle_len

I'm new to this project, so perhaps it's a standard here to rely on python failing as a way to indicate that something is wrong, rather than designing a more user-friendly API? ",see correct assert used without whether code tell user perhaps need unrelated new project perhaps standard rely python failing way indicate something wrong rather designing,issue,negative,negative,negative,negative,negative,negative
406898321,"Yeah, I see where it comes from: basically the y.data needs to be mapped on to all the elements of the list if y is a list (like [x.data for x in y]). I'll look at it this week, but feel free to propose a PR in the meantime!",yeah see come basically need list list like look week feel free propose,issue,positive,positive,positive,positive,positive,positive
406898199,"This is very messy indeed. If you want to offer a PR with aligned defaults, that would be most appreciated!",messy indeed want offer would,issue,negative,negative,negative,negative,negative,negative
406896502,I think it just requires cyc_len: use_clr and use_clr_beta will also trow back an error if they don't get a cyc_len.,think also trow back error get,issue,negative,neutral,neutral,neutral,neutral,neutral
406871122,"Ah well perhaps I'm mis-remembering, or students have gotten
better results than I did. I've removed the 2nd notebook now.
Thanks for checking.
",ah well perhaps gotten better removed notebook thanks,issue,positive,positive,positive,positive,positive,positive
406837106,"Hi Nick, thanks! This is great! I'm just on the way back from a conference. Will test the code once I'm back.",hi nick thanks great way back conference test code back,issue,positive,positive,positive,positive,positive,positive
406769293,"I made quite a few beginner attempts to beat 0.926 accuracy of the first notebook, borrowing from your version, but wasn't able to. Your version as is was incomplete (wds undefined) and blowing the gradients into the sky, but after tweaking things to keep it contained it was giving worse results. 

I also had to drastically reduce `bs` as I only have 8GB GPU RAM, and it wanted a lot more for retraining the full network. So it's possible that it's a hardware limitation on my side.

Your notebook used` arch=dn161`, the one I found uses `resnext101_64`. I looked at the forums at it appears that [93% accuracy](http://forums.fast.ai/t/dog-breed-identification-challenge/7464/316) is the max one could get from `resnext101_64` on this dataset. it was suggested `nasnet` could get it to 95%, but the poster didn't leave specific details on how he accomplished that, other than [this](http://forums.fast.ai/t/dog-breed-identification-challenge/7464/322):

> One of differences between nasnet and resnext is that for nasnet you need to define:

```
def nasnet(pre): return nasnetalarge(pretrained = 'imagenet' if pre else None)
model_features[nasnet]=4032*2
stats = ([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])
tfms = tfms_from_stats(stats, sz, aug_tfms=transforms_side_on, max_zoom=1.1)
```

So, I'm not sure how to proceed from here. Any guidance is welcome, @jph00 . I'm also fine leaving the found notebook as it is for now, and probably deleting yours as it's incomplete, unless you'd have a look.

Thanks.",made quite beginner beat accuracy first notebook borrowing version able version incomplete undefined blowing sky keep giving worse also drastically reduce ram lot full network possible hardware limitation side notebook used one found accuracy one could get could get poster leave specific accomplished one need define return else none sure proceed guidance welcome also fine leaving found notebook probably incomplete unless look thanks,issue,positive,positive,positive,positive,positive,positive
406642271,"@stas00 I just commited my version of the nb to the repo as lesson1-breeds2.ipynb. Perhaps you can take a look and combine the best bits of the two notebooks, and do a PR that removes the 2nd notebook and updates the first appropriately?",version perhaps take look combine best two notebook first appropriately,issue,positive,positive,positive,positive,positive,positive
406488553,"@jph00, do you have the original notebook that you used while teaching (it was called tmp_something...breed)? It'd be the easiest to use that instead (I can apply whatever API changes were made since then).

I tried following your suggestion, and unless I did something wrong, adding learner.bn_freeze(True) didn't seem to make much of a difference. I tried w/ and w/o unfreezing the whole model and using differential lrs, it gives better accuracy sooner, but converges to the same ceiling.",original notebook used teaching breed easiest use instead apply whatever made since tried following suggestion unless something wrong true seem make much difference tried unfreezing whole model differential better accuracy sooner ceiling,issue,positive,positive,positive,positive,positive,positive
406347841,I have to review the notebook but I guess it would be better to define a proper layer_groups at the model level than pass 12 learning rates. I'll get on it later today.,review notebook guess would better define proper model level pas learning get later today,issue,negative,positive,positive,positive,positive,positive
406347198,"@stas00 absolutely. Sorry about that - I haven't been coding for the last few months due to medical issues at home, so not surprised to hear that some notebooks have gotten out of sync with the PRs coming in. I'm back at work now so feel free to reach out directly if I miss anything. I'll ask @sgugger to look at this one.",absolutely sorry last due medical home hear gotten sync coming back work feel free reach directly miss anything ask look one,issue,negative,negative,neutral,neutral,negative,negative
406345427,"@jph00, could you also please address why the 3 -> 12 lrs ""broadcasting"" doesn't work here, perhaps in this thread:

http://forums.fast.ai/t/lesson7-cam-mismatch-between-of-lrs-and-of-layer-groups/19425",could also please address work perhaps thread,issue,negative,neutral,neutral,neutral,neutral,neutral
406344023,"I think this a is pretty great goal, although I think our current code-base doesn't really allow you to do this neatly - the approach you have here requires too much code, and doesn't generalize easily to other types of dataset (and observational weights are absolutely useful for images, nlp, etc too!)

So I think I'd rather try to tackle this in a more general way in our v1 rewrite - we've just started working on it at: https://github.com/fastai/fastai_v1 .

Many thanks for this contribution!",think pretty great goal although think current really allow neatly approach much code generalize easily observational absolutely useful think rather try tackle general way rewrite working many thanks contribution,issue,positive,positive,positive,positive,positive,positive
406342166,"Thanks Stas - that's a good idea. I kinda hope that people will try to create this themselves from scratch, but it's nice to have a complete example they can look at. The notebook you based this on seems to have been developed independently. I think you should be able to get much better performance by using `learner.bn_freeze()` - feel free to add more PRs to this if you improve it in the future.",thanks good idea hope people try create scratch nice complete example look notebook based independently think able get much better performance feel free add improve future,issue,positive,positive,positive,positive,positive,positive
406340086,"Thank you for your guidance, Sylvain. 

I have rewritten the patch to use f'' and also your suggested wording. ",thank guidance patch use also wording,issue,negative,neutral,neutral,neutral,neutral,neutral
406277013,"We're in the process of rewriting the version 1 of this library, so in the meantime we only maintain this one with minor fixes. Stay tuned for the new version in October!",process version library maintain one minor stay tuned new version,issue,negative,positive,neutral,neutral,positive,positive
406260505,Cheers ! Is there anything else you would like someone to take a look at? I'm going through the fast.ai codebase as it is. Would be happy to submit a PR for some fixes.,anything else would like someone take look going would happy submit,issue,positive,positive,positive,positive,positive,positive
406253024,"Good idea! Could you just modify your code to use python 3.6 string-formatting? Something like f'size mismatch, expected {len(self.layer_groups)} lrs but got {len(lrs)}'
Thanks.",good idea could modify code use python something like mismatch got thanks,issue,positive,positive,positive,positive,positive,positive
405939383,"I created a new env in python, cloned the fastai master branch, and tested. It works fine.
So the issue is my default environment. Should I abandon it or try to fix it?
I don't know where I would start with debugging so this point it would be easer to just save my files and start over.",new python master branch tested work fine issue default environment abandon try fix know would start point would easer save start,issue,negative,positive,positive,positive,positive,positive
405809248,"Yes, you are right, So sorry for this bug. I have corrected and pushed the code with the correct variable name.",yes right sorry bug corrected code correct variable name,issue,negative,negative,negative,negative,negative,negative
405712112,"Hi,
> Hi Nick, I'm getting this:
>NameError: name 'is_string_dtype' is not defined:
>So I had to modify your example.

Sorry, forgot about imports)

So, i tried both examples and i am not able to reproduce this issue. I even tried it on paperspace instance, since i see that you are using paperspace. It seems like there is something wrong with your particular instance, are you able to reproduce it on other vm instances?
![test](https://user-images.githubusercontent.com/7903523/42842347-a6926d48-8a15-11e8-9fd5-c773bb610d44.png)",hi hi nick getting name defined modify example sorry forgot tried able reproduce issue even tried instance since see like something wrong particular instance able reproduce test,issue,negative,positive,neutral,neutral,positive,positive
405580811,"If you look at the notebook imdb, you will see there is a whole section to convert the embeddings of the pretrained model to match the imdb vocab.
Any other question related to this should be asked on the [forum](http://forums.fast.ai/)",look notebook see whole section convert model match question related forum,issue,negative,positive,neutral,neutral,positive,positive
405579584,"Sorry, I thought I left a comment a few days ago, but I forgot to press the last button. There is a little bug I think.",sorry thought left comment day ago forgot press last button little bug think,issue,negative,negative,negative,negative,negative,negative
405490376,"@bny6613 
Hi Nick, I'm getting this:
> NameError: name 'is_string_dtype' is not defined:

So I had to modify your example.
```
import sys
import os.path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
import pandas as pd
from pandas.api.types import is_string_dtype



class provokeSIGSEGV(object):

    def main(self):

        df = pd.DataFrame({'account-start': ['2017-02-03', '2017-03-03', '2017-01-01'],
                           'client': ['Alice Anders', 'Bob Baker', 'Charlie Chaplin'],

                           })

        for n, c in df.items():
            if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()

        print(""Categorical data can be read before to_feather:"")
        print(df.client[0])

        df.to_feather(os.getcwd() + '/dfSIGSEGV')
        df = pd.read_feather(os.getcwd() + '/dfSIGSEGV')

        print(""-but not afterwards."")
        print(df.client[0])


if __name__ == ""__main__"":
    pssv = provokeSIGSEGV()
    pssv.main()
```

I'm still getting 

> Segmentation fault (core dumped)

Using gdb (GNU Debugger):

> Thread 1 ""python"" received signal SIGSEGV, Segmentation fault.
> 0x00007ffff5de9e55 in _basic_copy (elsize=1, src=src@entry=0x7ffff7fee040, dst=0x7fff9a4c40e8)
>    from /home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/numpy/core/multiarray.cpython-36m-x86_64-linux-gnu.so

",hi nick getting name defined modify example import import import import class object main self baker print categorical data read print print afterwards print still getting segmentation fault core gnu thread python received signal segmentation fault,issue,negative,positive,positive,positive,positive,positive
405381390,"All train_cats does is:
```
for n,c in df.items():
        if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()
```
So, if you remove library dependency and change train_cats call to this snippet, do you still get a segmentation fault?
```
import os.path
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
import sys

class provokeSIGSEGV(object):

	def main(self):

		df = pd.DataFrame({'account-start': ['2017-02-03', '2017-03-03', '2017-01-01'],
		                   'client': ['Alice Anders', 'Bob Baker', 'Charlie Chaplin'],

		                   })
        
		for n,c in df.items():
				if is_string_dtype(c): df[n] = c.astype('category').cat.as_ordered()
                    
		print(""Categorical data can be read before to_feather:"")
		print(df.client[0])
		
		df.to_feather(os.getcwd()+'/dfSIGSEGV')
		df = pd.read_feather(os.getcwd()+'/dfSIGSEGV')
		
		print(""-but not afterwards."")
		print(df.client[0])
				

if __name__ == ""__main__"":
    pssv = provokeSIGSEGV()       
    pssv.main()
```",remove library dependency change call snippet still get segmentation fault import import class object main self baker print categorical data read print print afterwards print,issue,negative,positive,positive,positive,positive,positive
405129546,Great. I have just submitted a PR on this. I tried to do it as efficiently as I knew how. ,great tried efficiently knew,issue,positive,positive,positive,positive,positive,positive
405127707,"Oh, I didn't catch those underscores, thanks for making a PR, it's clearer now!",oh catch thanks making clearer,issue,negative,positive,positive,positive,positive,positive
405095520,"FrankWork is suggesting to `s/nhid=/n_hid=/`
However, for me to get this to actually work, I also needed `s/nlayers=/n_layers=/`

See: https://github.com/fastai/fastai/commit/fb3e24cf98e39f7c8b7f3344d6411f1cbfbb804b

PR:  #627",suggesting however get actually work also see,issue,negative,neutral,neutral,neutral,neutral,neutral
404635907,"Good to hear, I'll watch fastai and  propose that again! ",good hear watch propose,issue,negative,positive,positive,positive,positive,positive
404589500,"We do plan to have a library used outside of the course, and it will be the next version of this one. With the changes in pytorch on one hand, and the new features added as time goes, Jeremy felt he had to start again from scratch to create something more intuitive that ties all the existing APIs together.

Please keep that idea in mind and if you want to adapt it to the fastai_v1, it will be more than welcome!",plan library used outside course next version one one hand new added time go felt start scratch create something intuitive together please keep idea mind want adapt welcome,issue,positive,positive,positive,positive,positive,positive
404562987,"pity, is it generally not planned to make a library, which is used outside the courses?
Should I adapt it to the new one or just delete it?  ",pity generally make library used outside adapt new one delete,issue,negative,positive,neutral,neutral,positive,positive
404512940,"This function is almost all the time used to reduce the size of images, which is why the default is cv2.INTER_AREA. A simple PR to define an interpolation depending on the target size wouldn't hurt though.",function almost time used reduce size default simple define interpolation depending target size would hurt though,issue,negative,neutral,neutral,neutral,neutral,neutral
404367184,"Thanks for the suggestion. Now that Jeremy has decided to create a new version of the library for the next course on October, this project will be maintained with the necessary fixes but we won't begin any major change.

I note the idea for fastai_v1 though, as a proper documentation is definitely on our list of things to do. Thanks for suggesting this! ",thanks suggestion decided create new version library next course project necessary wo begin major change note idea though proper documentation definitely list thanks suggesting,issue,positive,positive,neutral,neutral,positive,positive
404364143,"Sorry it took us so long to reply! Jeremy has been very busy with personal events and I've just joined the team.
I like the way you coded this... but using the test set too much is generally a bad practice so we'd like to avoid having inside the library. I'd definitely recommend posting a notebook on the [forum](http://forums.fast.ai/) with an example of use, since there are some situations where it can be useful. As long as you create your own fit function by copy-pasting the code you suggested, it will be the one used by any learner object.",sorry took u long reply busy personal team like way test set much generally bad practice like avoid inside library definitely recommend posting notebook forum example use since useful long create fit function code one used learner object,issue,positive,negative,neutral,neutral,negative,negative
404363407,"Thanks for your PR. It was also suggested in another one, so I'm closing this.",thanks also another one,issue,negative,positive,positive,positive,positive,positive
404363297,Not sure what you're referring to since what you propose is what is inside the sampled_sm.py. Can you suggest a PR?,sure since propose inside suggest,issue,negative,positive,positive,positive,positive,positive
404362241,Yes the first one can be removed. Don't hesitate to suggest a PR with this.,yes first one removed hesitate suggest,issue,negative,positive,positive,positive,positive,positive
404360199,"Please report on the [forum](http://forums.fast.ai/). As indicated in the error message, your GPU is too old to be supported by pytorch, so you'll need to rent some.",please report forum error message old need rent,issue,negative,positive,neutral,neutral,positive,positive
404355388,Please use the (forum)[http://forums.fast.ai/] for those issues. Be sure to describe your setup.,please use forum sure describe setup,issue,positive,positive,positive,positive,positive,positive
404349502,"Hi there, thanks for wanting to contribute to the library!

Every new development is welcome as long as it helps getting better result and doesn't interfere with pre-existing code. Ideally if you can keep the changes in the fit function to their minimum and use a separate custom Stepper class that is a child of the current Stepper class, that would be best.

A notebook that shows the benefits of this, with an example of use with the custom loss/evaluation metrics would be perfect and maximize your chances at getting your PR quickly approved.",hi thanks wanting contribute library every new development welcome long getting better result interfere code ideally keep fit function minimum use separate custom stepper class child current stepper class would best notebook example use custom metric would perfect maximize getting quickly,issue,positive,positive,positive,positive,positive,positive
404348647,This is a bug that's probably due to your model definition. Please use the (forum)[forums.fast.ai] to solve your issue.,bug probably due model definition please use forum solve issue,issue,negative,negative,negative,negative,negative,negative
404348401,"learner.fit is not supposed to take a reg_fn or clip arguments, it's passing the reg_fn and clip defined inside learner to the fit function of model.py. You should either:
- use the lines learner.reg_fn = reg_fn; learner.clip = clip before calling learner.fit,
or
- use the fit function directly.",supposed take clip passing clip defined inside learner fit function either use clip calling use fit function directly,issue,positive,positive,positive,positive,positive,positive
404346533,"Thanks for your suggestions. Don't hesitate to make a PR with them, any improvement to the notebooks is welcome.",thanks hesitate make improvement welcome,issue,positive,positive,positive,positive,positive,positive
403438718,"The Travis-CI failure is unrelated to my change, how can I re-trigger a run?",failure unrelated change run,issue,negative,negative,negative,negative,negative,negative
403239941,"All the tests specified in 'tests' directory fail when using 0.4.0. Maybe the lesson notebooks will work fine :)
`============================= test session starts =============================
platform win32 -- Python 3.6.5, pytest-3.6.2, py-1.5.4, pluggy-0.6.0
rootdir: F:\Vasu\Projects\pypy\fastAI\fastai, inifile: pytest.ini
collected 0 items / 7 errors

=================================== ERRORS ====================================
_____________________ ERROR collecting tests/test_core.py _____________________
ImportError while importing test module 'F:\Vasu\Projects\pypy\fastAI\fastai\tests\test_core.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
tests\__init__.py:3: in <module>
    import cv2,torch
C:\Installations\Anaconda3\envs\fastai\lib\site-packages\torch\__init__.py:78: in <module>
    from torch._C import *
E   ImportError: DLL load failed: The operating system cannot run %1.
___________________ ERROR collecting tests/test_dataset.py ____________________
ImportError while importing test module 'F:\Vasu\Projects\pypy\fastAI\fastai\tests\test_dataset.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
tests\__init__.py:3: in <module>
    import cv2,torch
C:\Installations\Anaconda3\envs\fastai\lib\site-packages\torch\__init__.py:78: in <module>
    from torch._C import *
E   ImportError: DLL load failed: The operating system cannot run %1.
_______________ ERROR collecting tests/test_layer_optimizer.py ________________
ImportError while importing test module 'F:\Vasu\Projects\pypy\fastAI\fastai\tests\test_layer_optimizer.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
tests\__init__.py:3: in <module>
    import cv2,torch
C:\Installations\Anaconda3\envs\fastai\lib\site-packages\torch\__init__.py:78: in <module>
    from torch._C import *
E   ImportError: DLL load failed: The operating system cannot run %1.
_______________ ERROR collecting tests/test_lsuv_initializer.py _______________
ImportError while importing test module 'F:\Vasu\Projects\pypy\fastAI\fastai\tests\test_lsuv_initializer.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
tests\__init__.py:3: in <module>
    import cv2,torch
C:\Installations\Anaconda3\envs\fastai\lib\site-packages\torch\__init__.py:78: in <module>
    from torch._C import *
E   ImportError: DLL load failed: The operating system cannot run %1.
___________________ ERROR collecting tests/test_samplers.py ___________________
ImportError while importing test module 'F:\Vasu\Projects\pypy\fastAI\fastai\tests\test_samplers.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
tests\__init__.py:3: in <module>
    import cv2,torch
C:\Installations\Anaconda3\envs\fastai\lib\site-packages\torch\__init__.py:78: in <module>
    from torch._C import *
E   ImportError: DLL load failed: The operating system cannot run %1.
__________________ ERROR collecting tests/test_structured.py __________________
ImportError while importing test module 'F:\Vasu\Projects\pypy\fastAI\fastai\tests\test_structured.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
tests\__init__.py:3: in <module>
    import cv2,torch
C:\Installations\Anaconda3\envs\fastai\lib\site-packages\torch\__init__.py:78: in <module>
    from torch._C import *
E   ImportError: DLL load failed: The operating system cannot run %1.
__________________ ERROR collecting tests/test_transform.py ___________________
ImportError while importing test module 'F:\Vasu\Projects\pypy\fastAI\fastai\tests\test_transform.py'.
Hint: make sure your test modules/packages have valid Python names.
Traceback:
tests\__init__.py:3: in <module>
    import cv2,torch
C:\Installations\Anaconda3\envs\fastai\lib\site-packages\torch\__init__.py:78: in <module>
    from torch._C import *
E   ImportError: DLL load failed: The operating system cannot run %1.
!!!!!!!!!!!!!!!!!!! Interrupted: 7 errors during collection !!!!!!!!!!!!!!!!!!!
=========================== 7 error in 4.43 seconds ===========================`",directory fail maybe lesson work fine test session platform win python collected error test module hint make sure test valid python module import torch module import load operating system run error test module hint make sure test valid python module import torch module import load operating system run error test module hint make sure test valid python module import torch module import load operating system run error test module hint make sure test valid python module import torch module import load operating system run error test module hint make sure test valid python module import torch module import load operating system run error test module hint make sure test valid python module import torch module import load operating system run error test module hint make sure test valid python module import torch module import load operating system run interrupted collection error,issue,negative,positive,positive,positive,positive,positive
403022382,"Hmm, is this an actively maintained project or more something only used for the fast.ai course?   ",actively project something used course,issue,negative,negative,negative,negative,negative,negative
401616118,"This otherwise wonderful project could really use some proper documentation.  I endorse this approach.
",otherwise wonderful project could really use proper documentation endorse approach,issue,positive,positive,positive,positive,positive,positive
401225444,"In `imdb_scripts/sampled_sm.py`, in function `get_language_model`, change the code as following

```
rnn_enc = RNN_Encoder(n_tok, em_sz, n_hid=nhid, n_layers=nlayers, pad_token=pad_token,
```

It will solve the 'nhid' problem.",function change code following solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
400613602,"It is awful to bother about such trifles when one has something really
serious (like brain surgery) to worry about.

Let me just say that reading a post forum of mine and then submit a PR with
exactly the same code is unkind, unpolite, and absolutely contrary to the
spirit of our community (or any other community whatsoever, I reckon).

Thanks for your kind reply.
Andrea

On Tue, Jun 26, 2018 at 11:53 PM, Jeremy Howard <notifications@github.com>
wrote:

> That does sound frustrating. I've been busy recently helping my wife
> through her brain surgery, so I haven't been keeping on top of the forums
> or PRs, but I'd guess that what happened is that someone else submitted a
> PR with the same thing.
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/575#issuecomment-400475025>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AhqNqlmgokqKKirpHbCAiD-0rLyiOm05ks5uAq08gaJpZM4Uv7V3>
> .
>
",awful bother one something really serious like brain surgery worry let say reading post forum mine submit exactly code unkind unpolite absolutely contrary spirit community community whatsoever reckon thanks kind reply tue wrote sound busy recently helping wife brain surgery keeping top guess someone else thing thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
400475025,"That does sound frustrating. I've been busy recently helping my wife through her brain surgery, so I haven't been keeping on top of the forums or PRs, but I'd guess that what happened is that someone else submitted a PR with the same thing.",sound busy recently helping wife brain surgery keeping top guess someone else thing,issue,negative,positive,positive,positive,positive,positive
400474286,We've got the start of a templating system available now in the /docs directory here. The `transforms.*` files show an example of use.,got start system available directory show example use,issue,negative,positive,positive,positive,positive,positive
400473847,I think that notebooks might be more descriptive and useful - or tests. I'm not sure that just scripts would be as helpful. Did you have some ideas for things where scripts would have a particular benefit?,think might descriptive useful sure would helpful would particular benefit,issue,positive,positive,positive,positive,positive,positive
400473469,Good point. Would you be interested in submitting a PR to fix this?,good point would interested fix,issue,positive,positive,positive,positive,positive,positive
400473292,Would you be interested in trying to fix this with a PR?,would interested trying fix,issue,negative,positive,positive,positive,positive,positive
400470725,We'll likely add these as part of the next course - but not yet.,likely add part next course yet,issue,negative,neutral,neutral,neutral,neutral,neutral
400411022,"I recall 48 was the minimum size in keras for their pretrained models. 900
retains the ratio of width/height.

On 26 June 2018 at 18:55, Yannet <notifications@github.com> wrote:

> On Tue, Jun 26, 2018 at 10:51 AM, simon <notifications@github.com> wrote:
>
> > Thanks. I got it working I think with a couple of hacks - in transforms I
> > only add the crop transform if crop_type is not none. In image_gen I only
> > do the scaling if sz is not none.
> >
> > This seems to work - at least it ran through training on a tiny sample
> > without errors. Am I going to come up against some other issues or will
> > that fix it for now? I am currently precomputing by dataset but it takes
> > 2.5 hours.
>
>
> Are your images large? If they are you should resize them.
>
>
> >
> >
> > On 26 June 2018 at 17:32, Yannet <notifications@github.com> wrote:
> >
> > > Rectangular images are not an option at the moment. You could try to
> work
> > > with your own dataset. Here is an example.
> > >
> > > https://github.com/yanneta/deep-learning-with-pytorch/
> > > blob/master/lesson9-muti-task.ipynb
> > >
> > > On Tue, Jun 26, 2018 at 9:10 AM, simon <notifications@github.com>
> wrote:
> > >
> > > > It would be better if cropping and scaling were treated just like any
> > > > other transformations rather than mandatory crop and resize as
> square.
> > > >
> > > > I have images that are all 48*900. I don't want to resize them nor
> do I
> > > > want to crop them. I thought maybe I could just set the resize and
> crop
> > > to
> > > > their existing size. However scale only outputs a square image; and
> the
> > > > intriguingly named ""nocrop"" class actually crops at random.
> > > >
> > > > —
> > > > You are receiving this because you are subscribed to this thread.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/fastai/fastai/issues/584>, or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/
> > > AC3CZQxvxRbi98jvbmKOWceWHb4fqjAYks5uAlzugaJpZM4U4QFw>
> > > > .
> > > >
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/fastai/fastai/issues/584#issuecomment-400379215>,
> > or mute
> > > the thread
> > > <https://github.com/notifications/unsubscribe-auth/ABJN6TWkHM3kd-
> > ZR6gXGPVVYadq0gJBrks5uAmI5gaJpZM4U4QFw>
> > > .
> > >
> >
> > —
> > You are receiving this because you commented.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/fastai/fastai/issues/584#issuecomment-400405264>,
> or mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/AC3CZaGY11-
> PxUq5u6xMp3t12T6RIhpWks5uAnSVgaJpZM4U4QFw>
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/584#issuecomment-400406735>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABJN6aBQN7Z6F4LK2LbJHrKM6ub46miFks5uAnWrgaJpZM4U4QFw>
> .
>
",recall minimum size ratio june wrote tue wrote thanks got working think couple add crop transform none scaling none work least ran training tiny sample without going come fix currently large resize june wrote rectangular option moment could try work example tue wrote would better scaling like rather mandatory crop resize square want resize want crop thought maybe could set resize crop size however scale square image intriguingly class actually random thread reply directly view mute thread thread reply directly view mute thread reply directly view mute thread thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
400410627,"48*900. They are images of rows of text where I am detecting markings which
are often on the left or right so important I don't crop it. I have 1.5m in
the training set so prefer to avoid any processing if possible. I have
already trained this successfully using keras but would like to replicate
the results using fastai/pytorch.

On 26 June 2018 at 18:55, Yannet <notifications@github.com> wrote:

> On Tue, Jun 26, 2018 at 10:51 AM, simon <notifications@github.com> wrote:
>
> > Thanks. I got it working I think with a couple of hacks - in transforms I
> > only add the crop transform if crop_type is not none. In image_gen I only
> > do the scaling if sz is not none.
> >
> > This seems to work - at least it ran through training on a tiny sample
> > without errors. Am I going to come up against some other issues or will
> > that fix it for now? I am currently precomputing by dataset but it takes
> > 2.5 hours.
>
>
> Are your images large? If they are you should resize them.
>
>
> >
> >
> > On 26 June 2018 at 17:32, Yannet <notifications@github.com> wrote:
> >
> > > Rectangular images are not an option at the moment. You could try to
> work
> > > with your own dataset. Here is an example.
> > >
> > > https://github.com/yanneta/deep-learning-with-pytorch/
> > > blob/master/lesson9-muti-task.ipynb
> > >
> > > On Tue, Jun 26, 2018 at 9:10 AM, simon <notifications@github.com>
> wrote:
> > >
> > > > It would be better if cropping and scaling were treated just like any
> > > > other transformations rather than mandatory crop and resize as
> square.
> > > >
> > > > I have images that are all 48*900. I don't want to resize them nor
> do I
> > > > want to crop them. I thought maybe I could just set the resize and
> crop
> > > to
> > > > their existing size. However scale only outputs a square image; and
> the
> > > > intriguingly named ""nocrop"" class actually crops at random.
> > > >
> > > > —
> > > > You are receiving this because you are subscribed to this thread.
> > > > Reply to this email directly, view it on GitHub
> > > > <https://github.com/fastai/fastai/issues/584>, or mute the thread
> > > > <https://github.com/notifications/unsubscribe-auth/
> > > AC3CZQxvxRbi98jvbmKOWceWHb4fqjAYks5uAlzugaJpZM4U4QFw>
> > > > .
> > > >
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/fastai/fastai/issues/584#issuecomment-400379215>,
> > or mute
> > > the thread
> > > <https://github.com/notifications/unsubscribe-auth/ABJN6TWkHM3kd-
> > ZR6gXGPVVYadq0gJBrks5uAmI5gaJpZM4U4QFw>
> > > .
> > >
> >
> > —
> > You are receiving this because you commented.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/fastai/fastai/issues/584#issuecomment-400405264>,
> or mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/AC3CZaGY11-
> PxUq5u6xMp3t12T6RIhpWks5uAnSVgaJpZM4U4QFw>
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/584#issuecomment-400406735>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABJN6aBQN7Z6F4LK2LbJHrKM6ub46miFks5uAnWrgaJpZM4U4QFw>
> .
>
",text often left right important crop training set prefer avoid possible already trained successfully would like replicate june wrote tue wrote thanks got working think couple add crop transform none scaling none work least ran training tiny sample without going come fix currently large resize june wrote rectangular option moment could try work example tue wrote would better scaling like rather mandatory crop resize square want resize want crop thought maybe could set resize crop size however scale square image intriguingly class actually random thread reply directly view mute thread thread reply directly view mute thread reply directly view mute thread thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
400406735,"On Tue, Jun 26, 2018 at 10:51 AM, simon <notifications@github.com> wrote:

> Thanks. I got it working I think with a couple of hacks - in transforms I
> only add the crop transform if crop_type is not none. In image_gen I only
> do the scaling if sz is not none.
>
> This seems to work - at least it ran through training on a tiny sample
> without errors. Am I going to come up against some other issues or will
> that fix it for now? I am currently precomputing by dataset but it takes
> 2.5 hours.


Are your images large? If they are you should resize them.


>
>
> On 26 June 2018 at 17:32, Yannet <notifications@github.com> wrote:
>
> > Rectangular images are not an option at the moment. You could try to work
> > with your own dataset. Here is an example.
> >
> > https://github.com/yanneta/deep-learning-with-pytorch/
> > blob/master/lesson9-muti-task.ipynb
> >
> > On Tue, Jun 26, 2018 at 9:10 AM, simon <notifications@github.com> wrote:
> >
> > > It would be better if cropping and scaling were treated just like any
> > > other transformations rather than mandatory crop and resize as square.
> > >
> > > I have images that are all 48*900. I don't want to resize them nor do I
> > > want to crop them. I thought maybe I could just set the resize and crop
> > to
> > > their existing size. However scale only outputs a square image; and the
> > > intriguingly named ""nocrop"" class actually crops at random.
> > >
> > > —
> > > You are receiving this because you are subscribed to this thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/fastai/fastai/issues/584>, or mute the thread
> > > <https://github.com/notifications/unsubscribe-auth/
> > AC3CZQxvxRbi98jvbmKOWceWHb4fqjAYks5uAlzugaJpZM4U4QFw>
> > > .
> > >
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/fastai/fastai/issues/584#issuecomment-400379215>,
> or mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/ABJN6TWkHM3kd-
> ZR6gXGPVVYadq0gJBrks5uAmI5gaJpZM4U4QFw>
> > .
> >
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/584#issuecomment-400405264>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZaGY11-PxUq5u6xMp3t12T6RIhpWks5uAnSVgaJpZM4U4QFw>
> .
>
",tue wrote thanks got working think couple add crop transform none scaling none work least ran training tiny sample without going come fix currently large resize june wrote rectangular option moment could try work example tue wrote would better scaling like rather mandatory crop resize square want resize want crop thought maybe could set resize crop size however scale square image intriguingly class actually random thread reply directly view mute thread thread reply directly view mute thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
400405264,"Thanks. I got it working I think with a couple of hacks - in transforms I
only add the crop transform if crop_type is not none. In image_gen I only
do the scaling if sz is not none.

This seems to work  - at least it ran through training on a tiny sample
without errors. Am I going to come up against some other issues or will
that fix it for now? I am currently precomputing by dataset but it takes
2.5 hours.

On 26 June 2018 at 17:32, Yannet <notifications@github.com> wrote:

> Rectangular images are not an option at the moment. You could try to work
> with your own dataset. Here is an example.
>
> https://github.com/yanneta/deep-learning-with-pytorch/
> blob/master/lesson9-muti-task.ipynb
>
> On Tue, Jun 26, 2018 at 9:10 AM, simon <notifications@github.com> wrote:
>
> > It would be better if cropping and scaling were treated just like any
> > other transformations rather than mandatory crop and resize as square.
> >
> > I have images that are all 48*900. I don't want to resize them nor do I
> > want to crop them. I thought maybe I could just set the resize and crop
> to
> > their existing size. However scale only outputs a square image; and the
> > intriguingly named ""nocrop"" class actually crops at random.
> >
> > —
> > You are receiving this because you are subscribed to this thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/fastai/fastai/issues/584>, or mute the thread
> > <https://github.com/notifications/unsubscribe-auth/
> AC3CZQxvxRbi98jvbmKOWceWHb4fqjAYks5uAlzugaJpZM4U4QFw>
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/584#issuecomment-400379215>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABJN6TWkHM3kd-ZR6gXGPVVYadq0gJBrks5uAmI5gaJpZM4U4QFw>
> .
>
",thanks got working think couple add crop transform none scaling none work least ran training tiny sample without going come fix currently june wrote rectangular option moment could try work example tue wrote would better scaling like rather mandatory crop resize square want resize want crop thought maybe could set resize crop size however scale square image intriguingly class actually random thread reply directly view mute thread thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
400379215,"Rectangular images are not an option at the moment. You could try to work
with your own dataset. Here is an example.

https://github.com/yanneta/deep-learning-with-pytorch/blob/master/lesson9-muti-task.ipynb

On Tue, Jun 26, 2018 at 9:10 AM, simon <notifications@github.com> wrote:

> It would be better if cropping and scaling were treated just like any
> other transformations rather than mandatory crop and resize as square.
>
> I have images that are all 48*900. I don't want to resize them nor do I
> want to crop them. I thought maybe I could just set the resize and crop to
> their existing size. However scale only outputs a square image; and the
> intriguingly named ""nocrop"" class actually crops at random.
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/584>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZQxvxRbi98jvbmKOWceWHb4fqjAYks5uAlzugaJpZM4U4QFw>
> .
>
",rectangular option moment could try work example tue wrote would better scaling like rather mandatory crop resize square want resize want crop thought maybe could set resize crop size however scale square image intriguingly class actually random thread reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
399717477,Yes you are right. I made an anaconda env 3.6 and everything worked!,yes right made anaconda everything worked,issue,negative,positive,positive,positive,positive,positive
398973769,"Here is a https://developer.nvidia.com/cuda-90-download-archive there is a downloadable for Mac...
Also according to this my Mac which has NVIDIA video card model GeForce GT 750M has 384 CUDA Cores...
https://www.anandtech.com/show/6873/nvidias-geforce-700m-family-full-details-and-specs/2

![screen shot 2018-06-21 at 3 14 40 pm](https://user-images.githubusercontent.com/145929/41746014-26e82506-7566-11e8-8e6b-13de0535e6a4.png)

",mac also according mac video card model screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
398461680,"Hey! I just thought about this yesterday too. I always really liked the keras documentation, both the website and the entirely markdown-based codebase. They're using mkdocs, which makes it really nice and easy to contribute. In the keras project they're also using a custom python script to incorporate the docstrings (mkdocs does not support that by default).

Or: Why not having an auto-generated docstring documentation + a rich mkdocs-style documentation with lots of examples, explanations and insights?",hey thought yesterday always really documentation entirely really nice easy contribute project also custom python script incorporate support default documentation rich documentation lot,issue,positive,positive,positive,positive,positive,positive
398425203,"The [environment.yml](https://github.com/fastai/fastai/blob/master/environment.yml) of fast.ai has a dependency to at least Python 3.6.
`- python>=3.6.0`
 An update may resolve your issue.",dependency least python python update may resolve issue,issue,negative,negative,negative,negative,negative,negative
397286411,"This is a python 3.6 (required for the fastai library) syntax for formatting string, I think you may be using an earlier version of python.",python library syntax string think may version python,issue,negative,neutral,neutral,neutral,neutral,neutral
397052481,"Thanks for adding this!

I tried using is_reg=False, out of the box, it told me my dependent variable was expected as CUDA.LONGTENSOR but it was CUDA.FLOAT32TENSOR. I tried by changing the type of my 'y' in ColumnarModelData and re-ran. It hit some cublas error at loss.backward()
![screenshot-2018-6-14 exp_model](https://user-images.githubusercontent.com/767894/41372663-93727146-6f6b-11e8-8e12-f6bbe50e1754.png)
",thanks tried box told dependent variable tried type hit error,issue,negative,positive,positive,positive,positive,positive
396176290,"This error is getting resolved after updating condo environment. So, closing this pull request!",error getting resolved environment pull request,issue,negative,neutral,neutral,neutral,neutral,neutral
395282548,"Yes -- I also see that you can use `learner.model.cuda(device)`, thanks Jeremy!",yes also see use device thanks,issue,positive,positive,positive,positive,positive,positive
395249897,"I’m sorry, I am not quite understanding the answer here. In one interface,
I see the images are normalized from 0 to 1, and that makes sense. I expect
to see normalized images as mentioned In Torchvision. On the iterator
interface, I see tensors that do not appear to be normalized. Also, when I
give a normalized image to my network, it gives significantly different
predictions than my non normalized input, making me think that nothing is
auto-normalizing the input, at least through predict_array.
On Wed, Jun 6, 2018 at 4:05 PM Yannet <notifications@github.com> wrote:

> Here is the answer to your question
>
>
> https://discuss.pytorch.org/t/whats-the-range-of-the-input-value-desired-to-use-pretrained-resnet152-and-vgg19/1683
>
> On Wed, Jun 6, 2018 at 1:53 PM, Nick Wertzberger <notifications@github.com
> >
> wrote:
>
> > Is it intentional that the resulting tensor is not normalized between 0
> and
> > 1?
> > On Wed, Jun 6, 2018 at 3:12 PM Jeremy Howard <notifications@github.com>
> > wrote:
> >
> > > You should never call get_x directly. Instead just use the standard
> > > dataset indexer: dataset.val_ds[i]
> > >
> > > —
> > > You are receiving this because you authored the thread.
> > > Reply to this email directly, view it on GitHub
> > > <https://github.com/fastai/fastai/issues/535#issuecomment-395198365>,
> > or mute
> > > the thread
> > > <https://github.com/notifications/unsubscribe-auth/AAV_
> > m2qo2WER1Y4UBKjpr7bTQRNr3hFwks5t6DfJgaJpZM4UX3Y0>
> > > .
> > >
> >
> > —
> > You are receiving this because you are subscribed to this thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/fastai/fastai/issues/535#issuecomment-395210062>,
> or mute
> > the thread
> > <
> https://github.com/notifications/unsubscribe-auth/AC3CZSrApH80DGGkqt8jiZHnl5GWEBf_ks5t6EFCgaJpZM4UX3Y0
> >
> > .
> >
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/535#issuecomment-395213494>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAV_mzDoF4iqg_xWDOY0f2i_0Y2zvry1ks5t6EQTgaJpZM4UX3Y0>
> .
>
",sorry quite understanding answer one interface see sense expect see interface see appear also give image network significantly different non input making think nothing input least wed wrote answer question wed nick wrote intentional resulting tensor wed wrote never call directly instead use standard indexer thread reply directly view mute thread thread reply directly view mute thread thread reply directly view mute thread,issue,negative,negative,neutral,neutral,negative,negative
395213494,"Here is the answer to your question

https://discuss.pytorch.org/t/whats-the-range-of-the-input-value-desired-to-use-pretrained-resnet152-and-vgg19/1683

On Wed, Jun 6, 2018 at 1:53 PM, Nick Wertzberger <notifications@github.com>
wrote:

> Is it intentional that the resulting tensor is not normalized between 0 and
> 1?
> On Wed, Jun 6, 2018 at 3:12 PM Jeremy Howard <notifications@github.com>
> wrote:
>
> > You should never call get_x directly. Instead just use the standard
> > dataset indexer: dataset.val_ds[i]
> >
> > —
> > You are receiving this because you authored the thread.
> > Reply to this email directly, view it on GitHub
> > <https://github.com/fastai/fastai/issues/535#issuecomment-395198365>,
> or mute
> > the thread
> > <https://github.com/notifications/unsubscribe-auth/AAV_
> m2qo2WER1Y4UBKjpr7bTQRNr3hFwks5t6DfJgaJpZM4UX3Y0>
> > .
> >
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/535#issuecomment-395210062>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZSrApH80DGGkqt8jiZHnl5GWEBf_ks5t6EFCgaJpZM4UX3Y0>
> .
>
",answer question wed nick wrote intentional resulting tensor wed wrote never call directly instead use standard indexer thread reply directly view mute thread thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
395210062,"Is it intentional that the resulting tensor is not normalized between 0 and
1?
On Wed, Jun 6, 2018 at 3:12 PM Jeremy Howard <notifications@github.com>
wrote:

> You should never call get_x directly. Instead just use the standard
> dataset indexer: dataset.val_ds[i]
>
> —
> You are receiving this because you authored the thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/535#issuecomment-395198365>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AAV_m2qo2WER1Y4UBKjpr7bTQRNr3hFwks5t6DfJgaJpZM4UX3Y0>
> .
>
",intentional resulting tensor wed wrote never call directly instead use standard indexer thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
395198532,"Seems reasonable - want to give it a go, and submit a PR if it works?",reasonable want give go submit work,issue,negative,positive,positive,positive,positive,positive
395198365,You should never call `get_x` directly. Instead just use the standard dataset indexer: `dataset.val_ds[i]`,never call directly instead use standard indexer,issue,negative,positive,neutral,neutral,positive,positive
395197312,Ah got it -- makes sense to me.  Thanks.,ah got sense thanks,issue,negative,positive,positive,positive,positive,positive
395196875,"I think it's right. To avoid pytorch mem problems, we want the first sequence to be the largest. Since we draw from N(bptt,5) below, then bptt+5*5 is 5 stdev from the mean, which should be safe. Feel free to reopen if this seems wrong to you.",think right avoid mem want first sequence since draw mean safe feel free reopen wrong,issue,negative,positive,positive,positive,positive,positive
395196182,Let's discuss in the forum thread,let discus forum thread,issue,negative,neutral,neutral,neutral,neutral,neutral
395032395,"The following codes cannot be run without modified the __init__.  I tested it on my language model.

learner = md.get_model(opt_fn, em_sz, nh, nl, dropouti=drops[0], dropout=drops[1], 
                      wdrop=drops[2], dropoute=drops[3], dropouth=drops[4], qrnn=True)",following run without tested language model learner,issue,negative,neutral,neutral,neutral,neutral,neutral
394632623,I just installed miniconda and fastai on Ubuntu 18.04 and ran the tests to check if everything is working as it should. I got that error on the first run. So this failing test does not indicate the environment is broken?,ran check everything working got error first run failing test indicate environment broken,issue,negative,negative,neutral,neutral,negative,negative
394122572,"Not sure why the tests failed?  Looks like it failed in an unrelated bit of code:
```
tests/test_core.py ....[36m                                                  [  9%][0m
tests/test_dataset.py .[36m                                                  [ 12%][0m
tests/test_layer_optimizer.py ..........[36m                                 [ 36%][0m
tests/test_lsuv_initializer.py F[36m                                         [ 39%][0m
tests/test_samplers.py ..[36m                                                [ 43%][0m
tests/test_structured.py .[36m                                               [ 46%][0m
tests/test_transform.py ....s.................[36m                           [100%][0m

=================================== FAILURES ===================================
[31m[1m_________________ test_fast_initialization_without_orthonormal _________________[0m

image_data = Variable containing:
( 0 , 0 ,.,.) = 
  255  252  254  ...   121  118  115
  246  251   55  ...   122  118  115
  234 ... 104
   52   53   55  ...    82   78   94
   53   52   54  ...    81   78   78
[torch.FloatTensor of size 1x3x224x224]


[1m    def test_fast_initialization_without_orthonormal(image_data):[0m
[1m        alexnet = models.alexnet(pretrained=False)[0m
[1m        pre_init_var = run_with_capture(alexnet, image_data)[0m
[1m        assert pre_init_var[0] >= 1000  # the first few pre-init variances are huge,[0m
[1m        assert pre_init_var[1] >= 100   # even larger than these conservative tests.[0m
[1m    [0m
[1m        tol = 0.1[0m
[1m        alexnet = apply_lsuv_init(alexnet, image_data, std_tol=tol, do_orthonorm=False, cuda=False)[0m
[1m        *post_init_var, final_var = run_with_capture(alexnet, image_data)[0m
[1m        for var in post_init_var:[0m
[1m>           assert 2 <= var <= 4[0m
[1m[31mE           assert 2 <= 1.9608554[0m

[1m[31mtests/test_lsuv_initializer.py[0m:52: AssertionError
[31m[1m================ 1 failed, 39 passed, 1 skipped in 7.70 seconds ================[0m
```",sure like unrelated bit code variable size assert first huge assert even conservative tol assert assert,issue,positive,positive,positive,positive,positive,positive
394090795,"I could be wrong, but seems like you can solve this particular issue by declaring __getitem__ method on F16 class, so it delegates the call to the module:  
```
def __getitem__(self, idx):
        return self.module[idx]
```",could wrong like solve particular issue method class call module self return,issue,negative,negative,negative,negative,negative,negative
394077894,I have created a PR https://github.com/fastai/fastai/pull/532. Please take a look when you have time.,please take look time,issue,negative,neutral,neutral,neutral,neutral,neutral
394030897,"Thanks for reply Jeremy. Sure, will try to do.",thanks reply sure try,issue,positive,positive,positive,positive,positive,positive
394026567,"Ok, I'll use the forums in future. 
The problem was the version of Pytorch. Updated environment.yml file to - pytorch=0.4.0. - pytorch<=0.4.0 installed version 0.1.12.",use future problem version file version,issue,negative,neutral,neutral,neutral,neutral,neutral
394024299,Thanks for letting us know. We'll post here if we come up with a solution (and let us know if you think of one!),thanks u know post come solution let u know think one,issue,positive,positive,positive,positive,positive,positive
394024077,Thanks for the idea. Any interest in trying to create a PR to fix this? Would be much appreciated! :),thanks idea interest trying create fix would much,issue,positive,positive,positive,positive,positive,positive
393737251,"@jph00 : I've just tested the change.

**tl;dr:** PR works well, both OK at runtime, PR more semantically correct.

---

**Details:**

Here are the original initialization lines:

```python
self.out = nn.Linear(em_sz_dec*2, len(itos_dec))
self.out.weight.data = self.emb_dec.weight.data
```

Because the weights are replaced right away, the init value actually doesn't matter.

In the end, `self.out.weight.data` will have the same shape as if it had been initialized with `em_sz_dec` directly.

Both versions (original and this PR) work the same at run time, but `em_sz_dec` is the one corresponding to the actual shape of the linear layer.

**More verbose output:**

Before PR:

Code:

```python
print(' em_sz_dec:', em_sz_dec)

self.out = nn.Linear(em_sz_dec*2, len(itos_dec))

print(' before: self.out.weight.data:', self.out.weight.data.size())
print(' before: self.emb_dec.weight.data:', self.emb_dec.weight.data.size())

self.out.weight.data = self.emb_dec.weight.data

print(' after: self.out.weight.data:', self.out.weight.data.size())
```

Output:

```
 em_sz_dec: 300
 before: self.out.weight.data: torch.Size([17573, 600])
 before: self.emb_dec.weight.data: torch.Size([17573, 300])
 after: self.out.weight.data: torch.Size([17573, 300])
```

---

After PR:

Output:

```
 em_sz_dec: 300
 before: self.out.weight.data: torch.Size([17573, 300])
 before: self.emb_dec.weight.data: torch.Size([17573, 300])
 after: self.out.weight.data: torch.Size([17573, 300])
```

Let me know if you need more info.",tested change work well semantically correct original python right away value actually matter end shape directly original work run time one corresponding actual shape linear layer verbose output code python print print print print output output let know need,issue,positive,positive,positive,positive,positive,positive
393720327,"I manually added `- defaults::intel-openmp` and changed `- pytorch<0.4` to `- pytorch=0.4` in environment-cpu.yml.  I used the new file to recreate a new env and it worked OK. See the new environment-cpu.yml attached.
@jph00 if you are OK with the change, I can close this PR and open a new PR to update the  environment-cpu.yml file
[environment-cpu.txt](https://github.com/fastai/fastai/files/2060523/environment-cpu.txt)

",manually added used new file recreate new worked see new attached change close open new update file,issue,negative,positive,positive,positive,positive,positive
393711042,"Should be solved in the latest PR, let me know if it's not the case @hnisonoff .",latest let know case,issue,negative,positive,positive,positive,positive,positive
393698104,"Oh yeah, it's the same problem with had in save_metrics at the point with the loss being sometimes a scalar and sometimes an array with only one element.
I'll get on it right away.",oh yeah problem point loss sometimes scalar sometimes array one element get right away,issue,negative,positive,positive,positive,positive,positive
393680034,Maybe easiest to just manually edit the yaml file that's already there?,maybe easiest manually edit file already,issue,negative,neutral,neutral,neutral,neutral,neutral
393679479,"The key thing about ModelData is that it encapsulates training, validation, and (optionally) test dataloaders, so that a Learner has all the data it needs. Might be worth mentioning that.",key thing training validation optionally test learner data need might worth,issue,negative,positive,positive,positive,positive,positive
393535840,"Hi Jeremy, two small changes that I think make the code easier to understand for newcomers.",hi two small think make code easier understand,issue,negative,negative,negative,negative,negative,negative
393427138,"@peterjc123 Your fix works 100%! @jph00 I'm trying to create a sharable env.yml file by `conda env export > environment-cpu.yml`. But it gives me this file:
`name: fastai-cpu
channels:
   defaults
prefix: C:\ProgramData\Anaconda3\envs\fastai-cpu\envs\fastai-cpu`

The file points to a specific location in my PC for env settings. How can I make it to export all installed package info instead of pointing to a folder in my pc?
",fix work trying create sharable file export file name prefix file specific location make export package instead pointing folder,issue,negative,neutral,neutral,neutral,neutral,neutral
393413713,"In case anyone wants a quicker, simpler solution for running a Python 3.6 environment, I took the additional jupyter environment installed via fastai
``python3.6 -m pip install fastai``

and I ran jupyter notebook directly, with
``python3.6 -m jupyter notebook``

Minimum hassles.",case anyone simpler solution running python environment took additional environment via python pip install ran notebook directly python notebook minimum,issue,negative,positive,neutral,neutral,positive,positive
393360827,I think the recent PR fixes this - feel free to reopen if that's not the case.,think recent feel free reopen case,issue,positive,positive,positive,positive,positive,positive
393312792,"I had the same question posted on fastai forum. I tried 2 ways:

1) use docker ufoym/deepo:all-py36-jupyter (or cpu variant if you don't have gpu)
2) run notebook on google colab with python3 (with comes with 3.6)

I think (1) should be good, although, my kernel died when running some specific cell in dl1 lesson 3. I don't know and havent debug why the kernel died. Running the same on google colab was fine. 

One person on that forum just told me to edit those f strings to use the old way. But it is sort of not maintainable and given that fastai seemed to be officially on py3.6, I don't want any nasty and worse, silent surprise later on. 

Let me know how this goes for you.",question posted forum tried way use docker variant run notebook python come think good although kernel running specific cell lesson know havent kernel running fine one person forum told edit use old way sort maintainable given officially want nasty worse silent surprise later let know go,issue,negative,negative,neutral,neutral,negative,negative
393269044,"Just to be sure, in your correction of the load_model method, you meant sd[n+'_raw'] = sd[n], not sd[n+'_raw'] = sd?",sure correction method meant,issue,negative,positive,positive,positive,positive,positive
393228003,OK so perhaps we need an update to environment-cpu and also to these docs? PRs welcome! :),perhaps need update also welcome,issue,negative,positive,positive,positive,positive,positive
393103276,"Yep, you're right. There are some errors in the documentation. We'll fix those over the next days. ",yep right documentation fix next day,issue,negative,positive,positive,positive,positive,positive
393058474,"@lchen23 Hi, I've figured out the solution. The problem is on `intel-openmp`. You have to install the one from defaults channel, so the command to fix is `conda install -c defaults intel-openmp -f`.",hi figured solution problem install one channel command fix install,issue,negative,neutral,neutral,neutral,neutral,neutral
393053977,"@peterjc123 Thanks for your help. To create my env, I basically just downloaded the fastai lib, `cd fastai` and ran `conda env update -f environment-cpu.yml`. My OS is windows 7 pro. Hope this info is helpful for you to reproduce the issue.",thanks help create basically ran update o pro hope helpful reproduce issue,issue,positive,positive,positive,positive,positive,positive
393051474,@lchen23 Thanks for your list. I'll try to build a new environment and try to reproduce your issue.,thanks list try build new environment try reproduce issue,issue,negative,positive,positive,positive,positive,positive
393040784,@peterjc123 Here's the list of packages I installed in conda https://github.com/lchen23/pytorch/blob/master/import_test.ipynb . I find I already have all the packages you mentioned and they are up to date. Just the pytorch-cpu doesn't work.,list find already date work,issue,negative,neutral,neutral,neutral,neutral,neutral
393025578,"@lchen23 Hi, would you please try `conda update conda`?",hi would please try update,issue,negative,neutral,neutral,neutral,neutral,neutral
392920387,"I will gladly do so.  Forgive me for an inappropriate use of `issues`.  I assumed that requesting code to `load` a model that was built from scripts present in the codebase was an appropriate use of this forum.
",gladly forgive inappropriate use assumed code load model built present appropriate use forum,issue,positive,positive,positive,positive,positive,positive
392871173,"Here's the results (see my notebook) after I tried `conda install mkl mkl-fft intel-openmp`. Basically, I already have mkl intel-openmp, but didn't have a channel to install mkl-fft.
https://github.com/lchen23/pytorch/blob/master/import_test.ipynb",see notebook tried install basically already channel install,issue,negative,neutral,neutral,neutral,neutral,neutral
392724327,"@lchen23 Thanks! Looks like `numpy` is correctly loaded but the others things are not.
Since I don't see intel-openmp there, I guess it may be the reason. Could you please try `conda install intel-openmp`?",thanks like correctly loaded since see guess may reason could please try install,issue,positive,positive,positive,positive,positive,positive
392675971,"@lchen23 Would you please provide us with some logs to help us, such as the logs with `python -v -c 'import torch'` and the result of the following code:
```python
# pip install psutil first
import psutil, os
p = psutil.Process( os.getpid() )
for dll in p.memory_maps():
  print(dll.path)
```
And you could try `conda install mkl mkl-fft intel-openmp numpy`.
I've tested 0.4.0 CPU on Windows Server 2008 R2, so it should work fine on Windows 7. I just don't know what's wrong there.",would please provide u help u python torch result following code python pip install first import o print could try install tested server work fine know wrong,issue,negative,positive,neutral,neutral,positive,positive
392669621,"@peterjc123 I just tried `conda install -c pytorch pytorch-cpu`, which installed pytorch-cpu 0.4.0.  And I got a new error: `ImportError: DLL load failed: The operating system cannot run %1`. My OS is Windows 7 pro. Maybe pytorch-cpu 0.4.0 could work for windows 10, I'm not sure. The pytorch-cpu 0.3.1 from `conda install -c peterjc123 pytorch-cpu` still works for me though.",tried install got new error load operating system run o pro maybe could work sure install still work though,issue,negative,positive,positive,positive,positive,positive
392530097,"@lchen23 Is there a reason that you could not use the official one, which is `conda install -c pytorch pytorch-cpu`?",reason could use official one install,issue,negative,neutral,neutral,neutral,neutral,neutral
392438452,"Based on the [forum feedback](http://forums.fast.ai/t/pytorch-internal-error-while-doing-the-imdb-notebook/16828), I think this might affect all users of Python 3.6, also for PyTorch 0.3.1 and 0.4.
This would also correspond to @sgugger 's observation that the error doesn't happen for him.",based forum feedback think might affect python also would also correspond observation error happen,issue,negative,neutral,neutral,neutral,neutral,neutral
392422642,"Yes, I believe so. I'm using Windows 7 and having the pytorch import problem. 
The original author also mentioned the purpose of his package is  ""It is a repo that contains scripts that makes using PyTorch on Windows easier.""  So, it's probably a windows specific problem.

There was a long chain of discussion of this issue in github, which include fast.ai users (https://github.com/pytorch/pytorch/issues/4518). That's why I think it's worth bringing this up and providing a simple, time-saving fix.",yes believe import problem original author also purpose package easier probably specific problem long chain discussion issue include think worth providing simple fix,issue,positive,positive,positive,positive,positive,positive
392380186,"Oh, & I just added stopwatch times because it seemed like a good idea",oh added time like good idea,issue,positive,positive,positive,positive,positive,positive
392336911,"Hmm... this lady says FP16 batch-norm only lead to a 0.5% decrease in accuracy, think I can stomach that for 10x faster training on tensor cores. I can always fine-tune with FP32 after initial training.

https://github.com/pytorch/pytorch/issues/520#issuecomment-277741834",lady lead decrease accuracy think stomach faster training tensor always initial training,issue,negative,neutral,neutral,neutral,neutral,neutral
392333418,Yes we don't currently support that combination.,yes currently support combination,issue,positive,neutral,neutral,neutral,neutral,neutral
392333352,Looks like that needs to be added to the setup.py file - PRs welcome! :),like need added file welcome,issue,positive,positive,positive,positive,positive,positive
392332537,I believe that's just for Windows - in which case perhaps mention that too?,believe case perhaps mention,issue,negative,neutral,neutral,neutral,neutral,neutral
392332475,"Can you please remove the 80 char formatting changes (see the style guide https://github.com/fastai/fastai/blob/master/docs/style.md ).

And then please split this in to multiple PRs - i.e. one for docs, one for formatting, etc. Thanks!",please remove char see style guide please split multiple one one thanks,issue,positive,positive,neutral,neutral,positive,positive
392332042,Thanks for the PR - not sure it's something I want to add however.,thanks sure something want add however,issue,positive,positive,positive,positive,positive,positive
392328275,Closed this issue and created a pull request.,closed issue pull request,issue,negative,negative,neutral,neutral,negative,negative
392269593,"Running on Ubuntu 16.04, with Nvidia GTX 1080 Ti. Cuda compilation tools, release 8.0, V8.0.61. FastAI latest build as of this date. ",running ti compilation release latest build date,issue,negative,positive,positive,positive,positive,positive
392157717,@jph00 My apologies for not following up on this. I have now updated this PR to remove sorting of the filenames in CSV altogether. Please let me know if any further changes are required.,following remove altogether please let know,issue,negative,neutral,neutral,neutral,neutral,neutral
390796911,"FYI who may struggle with the pascal-multi.ipynb

If you have a gpu, this is what you may want to do:

Get rid of all **.cpu** and in the class BCE_Loss, definition of forward

change the line from **t = V(t[:,:-1].contiguous())** to **t = V(t[:,:-1].contiguous().cuda())**",may struggle may want get rid class definition forward change line,issue,negative,neutral,neutral,neutral,neutral,neutral
390653604,Update: I created pull request that fixes this issue,update pull request issue,issue,negative,neutral,neutral,neutral,neutral,neutral
390645357,"I have the same issue. Mac OS is creating those .DS_Store files in every folder. You need to:

1. close all finder windows that have fast folders open
2. delete files from command line. In your fastai folder run: `find . -name "".DS_Store"" -delete`

I suppose it'd be nice if fastai ignored all hidden files while listing test, train and validation dirs
",issue mac o every folder need close finder fast open delete command line folder run find suppose nice hidden listing test train validation,issue,negative,positive,positive,positive,positive,positive
390512523,"@jph00 I'm still working on adding typing, but am slowed down much more than I expected because I'm not familiar with the code base. I'll push soon the framework/tool for getting it to work, so that others can contribute as well. 

Do you know of any contributors familiar with the codebase who would be interested in helping? ",still working much familiar code base push soon getting work contribute well know familiar would interested helping,issue,positive,positive,neutral,neutral,positive,positive
390456495,"newbie mistake.
code should be 
my_iter = iter(md.val_dl) #execute once
x,y = next(my_iter)[1] #execute multiple times",mistake code iter execute next execute multiple time,issue,negative,neutral,neutral,neutral,neutral,neutral
390435195,"@Eric-Arellano  After the instructions for testing, should there be a link to where/how ""report"" on test failures?",testing link report test,issue,negative,neutral,neutral,neutral,neutral,neutral
389371633,"No problem at all, I put the core tests back in one file and updated the if condition in `split_by_idxs`

I'm familiar with code folding but I don't use it enough - the keyboard shortcuts sound like a really good way to go 👍 ",problem put core back one file condition familiar code folding use enough keyboard sound like really good way go,issue,negative,positive,positive,positive,positive,positive
388914997,"@Eric-Arellano 
Thanks for the instructions. Now created pull request, number: #473 ",thanks pull request number,issue,negative,positive,positive,positive,positive,positive
388914490,Forgot to mention issue number: #461 ,forgot mention issue number,issue,negative,neutral,neutral,neutral,neutral,neutral
388868467,"@miwojc This is normal for open source projects - only a couple of people have push access to the repository to prevent someone accidentally pushing code that breaks the app.

Instead, you'll have to fork the repository and submit a pull request. Here's a guide on how to do this all! https://gist.github.com/Chaser324/ce0505fbed06b947d962

Thanks for taking the time to do this all!",normal open source couple people push access repository prevent someone accidentally pushing code instead fork repository submit pull request guide thanks taking time,issue,negative,positive,positive,positive,positive,positive
388859419,"i have locally created branch, corrected file, commit-ed,  but i am unable to access fastai.git when git push --set-upsteream origin 
![image](https://user-images.githubusercontent.com/32404415/40007042-d03e992a-5769-11e8-9acf-95b907541e6d.png)
",locally branch corrected file unable access git push origin image,issue,negative,negative,negative,negative,negative,negative
388663927,"Many thanks @Eric-Arellano - I think it should be working now. If you see anything that looks screwy, feel free to open an issue or send in a PR.",many thanks think working see anything screwy feel free open issue send,issue,positive,positive,positive,positive,positive,positive
388635177,"@jph00 Let me know if I can help at all with Travis! For example if you're comfortable giving me the login I'd be happy to set it up - no worries if you're not comfortable with that.

I don't know much DL to help with any of that, but would love to help with the software engineering side of things.",let know help travis example comfortable giving login happy set comfortable know much help would love help engineering side,issue,positive,positive,positive,positive,positive,positive
388630038,"Many thanks! I know a kind committer added stuff for Travis, but I suspect I need to do something at my end to actually enable it. I'll look at that now.",many thanks know kind committer added stuff travis suspect need something end actually enable look,issue,positive,positive,positive,positive,positive,positive
388473290,"@Eric-Arellano 

Looks like my PR was closed without merge. Might need to ask @jph00 to add that integration test.",like closed without merge might need ask add integration test,issue,negative,negative,neutral,neutral,negative,negative
388472385,"Hi, looks like someone already addressed this with PR #466. ",hi like someone already,issue,negative,neutral,neutral,neutral,neutral,neutral
388472054,"Thanks for writing this @anthonyjclark! I added a very simple unit test to make sure this never regresses.

Could you please add this to your PR? (I'm not sure how to edit your PR and don't want to create a new one). I created a new file called `tests/test_integration.py` with this code: https://pastebin.com/jZtWd1fb

You can run the tests as so:
1. Install virtual environment: `python3 -m venv .`
2. Activate virtual environment: `source bin/activate`
3. Install project requirements: `pip install -r requirements.txt`
4. Run new tests: `python pytest -m pytest tests/test_integration.py`",thanks writing added simple unit test make sure never could please add sure edit want create new one new file code run install virtual environment python activate virtual environment source install project pip install run new python,issue,positive,positive,positive,positive,positive,positive
388431452,"Sure @jph00 , let me take a look.",sure let take look,issue,negative,positive,positive,positive,positive,positive
388427753,Thanks! Would you like to submit a PR?,thanks would like submit,issue,positive,positive,positive,positive,positive,positive
388425444,Many thanks for the consideration - yes I think keeping in one file would be great. FYI if you're not familiar with code folding you should check it out and see if your editor can have it turned on by default (and also try to learn the keyboard shortcuts for increasing and decreasing folding level for a file) - hopefully things aren't too overwhelming when you can easily collapse the file into a handle of lines.,many thanks consideration yes think keeping one file would great familiar code folding check see editor turned default also try learn keyboard increasing decreasing folding level file hopefully overwhelming easily collapse file handle,issue,positive,positive,positive,positive,positive,positive
388424889,Many thanks @tensoralex ! It would be great to do a PR to the original cyclegan project that includes all the relative module path fixes that allow the module to be used from a notebook - that way we could remove the cgan folder entirely and use the source repo directly (e.g as a submodule). Any interest in giving that a go?,many thanks would great original project relative module path allow module used notebook way could remove folder entirely use source directly interest giving go,issue,positive,positive,positive,positive,positive,positive
388378060,"I am having this same NotImplementedError issue. Seems like mine could be also be related to the data path.. wondering why it needs the data path at all for just training the LM backbone? We already passed it a training and validation set that is in RAM, why does it need to look onto disk for data? @jackalhan did you find a solution?",issue like mine could also related data path wondering need data path training backbone already training validation set ram need look onto disk data find solution,issue,positive,neutral,neutral,neutral,neutral,neutral
388235489,"[`SaveBestModel`](https://github.com/fastai/fastai/blob/master/fastai/sgdr.py#L292) almost does what you want, so you'd need to extend it to save the `n` best models and then plot them.",almost want need extend save best plot,issue,positive,positive,positive,positive,positive,positive
388051293,"After reflection, modifying the library on an experiment-by-experiment basis seems like a better approach compared to adding functionality. Therefore closing this.",reflection library basis like better approach functionality therefore,issue,positive,positive,positive,positive,positive,positive
387599712,"That's funny cuz the reason why I broke them into separate files is because I thought it would be quicker to find the test(s) that you were looking for 😂 

I might be biased here because I think I personally find it less overwhelming when code is broken up into separate files. The compartmentalization is also helpful - e.g. I know that in `test_split_by_idxs.py` I'm only looking at code that pertains to tests for a function called `split_by_idxs`

It seems like it might be subjective, and given that I should probably stick with the existing patterns in the codebase? (i.e. keeping them in one file)",funny reason broke separate thought would find test looking might think personally find le overwhelming code broken separate compartmentalization also helpful know looking code function like might subjective given probably stick keeping one file,issue,negative,positive,neutral,neutral,positive,positive
387505043,"Possibly to be able to view the file names conveniently, but I am not so sure. I can easily undo my changes in the PR, and then remove the sorting.",possibly able view file conveniently sure easily undo remove,issue,positive,positive,positive,positive,positive,positive
387502179,Thanks this is very helpful! I must admit I'm not wondering why we're sorting the csv at all. It does seem like leaving it in the original order is most likely to be what's desired. Does anyone know of a reason that sorting is a good idea?,thanks helpful must admit wondering seem like leaving original order likely desired anyone know reason good idea,issue,positive,positive,positive,positive,positive,positive
387501331,"Are you sure we want to split the tests up into separate files? Seems to me like that's going to add complexity in finding tests and understanding modules - what's the downside of having large test files? Pretty much all modern editors support folding and/or visual file maps, so navigating large files is pretty convenient.",sure want split separate like going add complexity finding understanding downside large test pretty much modern support folding visual file large pretty convenient,issue,positive,positive,positive,positive,positive,positive
387181003,"It's not the CSV that is being changed. It's the list of filenames extracted from the CSV. That list is then used to segregate the files into training and validation data sets. The filenames might have been sorted in the first place just for viewing convenience, but I am not sure.",list extracted list used segregate training validation data might sorted first place convenience sure,issue,negative,positive,positive,positive,positive,positive
387117155,"I see.  what I dont understand is why are we sorting the CSV file in the first place as the CSV has order that does not change. Maybe this is something coming from code where files are being read from file system and the order can change from time to time, @jph00 ? 
",see dont understand file first place order change maybe something coming code read file system order change time time,issue,negative,positive,positive,positive,positive,positive
386932903,"Random note: for `test_cutout()`, I was getting intermittent failures that looked like this:

```
E       AssertionError: There is one cut out hole 10px x 10px in size (over 3 channels)
E       assert 270 == 300
```

I eventually found out that's because the randomized coordinates of holes created in `cutout()` can be near the edges of the image, which makes sense, but that will make the holes smaller than the specified `length` (e.g. if a hole with `length=10` is created at `[0, 0]` it will only be 5x5 instead of 10x10).

I wasn't sure if this is a bug, or if I should have just changed the test, so I'm open to any feedback!",random note getting intermittent like one cut hole size assert eventually found cutout near image sense make smaller length hole instead sure bug test open feedback,issue,negative,positive,neutral,neutral,positive,positive
386913195,"@PiotrCzapla The problem is this: If I pass [2, 3] as the val_idxs parameter in from_csv method, I want rows with index 2 and 3 from the passed CSV to be chosen as my validation data. But since the list of file names has already been sorted by the time validation data is picked, the rows chosen are different.

This does not create a problem in cases when we are randomly generating the validation indexes. But in some cases, the validation data is also provided along with the problem (example is the Kaggle competition https://www.kaggle.com/c/imaterialist-challenge-furniture-2018/data).",problem pas parameter method want index chosen validation data since list file already sorted time validation data picked chosen different create problem randomly generating validation validation data also provided along problem example competition,issue,negative,negative,negative,negative,negative,negative
386878465,"@sidchat04 I'm having a hard time understanding the issue. Do you mean that the order of the CSV file is not being kept? 
",hard time understanding issue mean order file kept,issue,negative,negative,negative,negative,negative,negative
386447003,"This happens in dataset.py here:

```
   115  def parse_csv_labels(fn, skip_header=True, cat_separator = ' '):
   116      """"""Parse filenames and label sets from a CSV file.
   117
   118      This method expects that the csv file at path :fn: has two columns. If it
   119      has a header, :skip_header: should be set to True. The labels in the
   120      label set are expected to be space separated.
   121
   122      Arguments:
   123          fn: Path to a CSV file.
   124          skip_header: A boolean flag indicating whether to skip the header.
   125
   126      Returns:
   127          a four-tuple of (
   128              sorted image filenames,
   129              a dictionary of filenames and corresponding labels,
   130              a sorted set of unique labels,
   131              a dictionary of labels to their corresponding index, which will
   132              be one-hot encoded.
   133          )
   134      .
   135      :param cat_separator: the separator for the categories column
   136      """"""
   137      df = pd.read_csv(fn, index_col=0, header=0 if skip_header else None, dtype=str)
   138      fnames = df.index.values
   139      df.iloc[:,0] = df.iloc[:,0].str.split(cat_separator)
   140      return sorted(fnames), list(df.to_dict().values())[0]
```

I removed the sorting on fnames and this seems to work. I am not sure though if we don't rely on the dataset being sorted by filenames in some other parts of the code.",parse label file method file path two header set true label set space path file flag whether skip header sorted image dictionary corresponding sorted set unique dictionary corresponding index param separator column else none return sorted list removed work sure though rely sorted code,issue,positive,positive,positive,positive,positive,positive
386443653,I think I ran into the same issue. By the time our filenames and targets arrive at `split_by_idx` they are sorted. They are split based on idxs that correspond to the original order in the csv and this produces incorrect results.,think ran issue time arrive sorted split based correspond original order incorrect,issue,negative,positive,positive,positive,positive,positive
386413402,"We only officially support GPU. For help with CPU, please use the forums.",officially support help please use,issue,positive,neutral,neutral,neutral,neutral,neutral
386413025,"(Actually I think you'll still get the warning - but it is using the new behavior too, so can be ignored.)",actually think still get warning new behavior,issue,negative,positive,neutral,neutral,positive,positive
386412874,If you `git pull` I think you'll find this resolved.,git pull think find resolved,issue,negative,neutral,neutral,neutral,neutral,neutral
386191761,"Thank you. As the forum said, installing from source works.",thank forum said source work,issue,negative,neutral,neutral,neutral,neutral,neutral
386165287,"Yes, you can. Please look at the following discussion: http://forums.fast.ai/t/pytorch-not-working-with-an-old-nvidia-card/14632 ",yes please look following discussion,issue,positive,neutral,neutral,neutral,neutral,neutral
386152507,This is fixed but another problem is getting occurred. Therefore this is closed,fixed another problem getting therefore closed,issue,negative,neutral,neutral,neutral,neutral,neutral
386138497,"0.4 broke lesson fastai.text package.

See the discussion here:  http://forums.fast.ai/t/notimplementederror-during-the-fitting-of-language-model-in-rnn-reg-py/15699

The environment.yml is fine:
-pytorch<0.4

It is the environment-cpu.yml file that needs to be fixed:
-pytorch>=0.2.0",broke lesson package see discussion fine file need fixed,issue,negative,positive,positive,positive,positive,positive
386131700,"I don't feel comfortable adding conda-forge - and certainly not at such high priority. It'll impact a lot of packages. Is there a way to fix this one package such that conda-forge is only used for this, and nothing else?",feel comfortable certainly high priority impact lot way fix one package used nothing else,issue,positive,positive,positive,positive,positive,positive
386131280,"I'm not sure this solution is quite right - seems that it will create a list of indep vars, even if there's just one. And if the indep vars is a tensor, it'll turn it into a list.

Might be a good idea to write a few tests of various edge cases as part of fixing this PR...",sure solution quite right create list even one tensor turn list might good idea write various edge part fixing,issue,positive,positive,positive,positive,positive,positive
386130736,Makes sense - might be nice in the future however to make abs paths work correctly.,sense might nice future however make work correctly,issue,negative,positive,positive,positive,positive,positive
385784328,"Jeremy -- 

Thanks for a great course, I had a great time. Per our convo last night, I've updated the formatting. ",thanks great course great time per last night,issue,positive,positive,positive,positive,positive,positive
385721610,"@jph00 I've extracted the test to a new PR #433, once it is merged this PR is going to be one commit.",extracted test new going one commit,issue,negative,positive,positive,positive,positive,positive
385709862,"I would be more than happy to contribute, but let me finish the course first :)",would happy contribute let finish course first,issue,positive,positive,positive,positive,positive,positive
385544102,"Sure, I would be happy to contribute to it. ",sure would happy contribute,issue,positive,positive,positive,positive,positive,positive
385529673,That is already being addressed. If you want to help let us know. @mcskinner  is adding some test as he goes through the library  (he is quite productive btw) and I'm working on tests for `transform.py`.  ,already want help let u know test go library quite productive working,issue,negative,neutral,neutral,neutral,neutral,neutral
385484114,"Duplicate of #425, merge that one instead",duplicate merge one instead,issue,negative,neutral,neutral,neutral,neutral,neutral
385483996,"Duplicate of #424, but I think@talhadar was the one identifying this fix on the forum?",duplicate think one fix forum,issue,negative,neutral,neutral,neutral,neutral,neutral
385460629,"I had the same bug and tested the proposed solution. 
This does the job!",bug tested solution job,issue,negative,neutral,neutral,neutral,neutral,neutral
385318537,@JannesKlaas I'm just paying back karma for the time I broke things myself :),paying back karma time broke,issue,negative,neutral,neutral,neutral,neutral,neutral
385318276,"Yes, looks like a stupid typo of mine, thanks for catching it! ",yes like stupid typo mine thanks catching,issue,positive,positive,neutral,neutral,positive,positive
385315172,"I change the self.data_path to be self.data.path, this time it is creating a problem in the following part:

```
 X = self.embed._backend.Embedding.apply(words,
                  masked_embed_weight, padding_idx, self.embed.max_norm,
                  self.embed.norm_type, self.embed.scale_grad_by_freq, self.embed.sparse)
```
`NotImplementedError: `",change time problem following part,issue,negative,neutral,neutral,neutral,neutral,neutral
385303433,"Hi @ashtonsix ,

I am working with the quora duplicates kaggle dataset which takes an input pair, just like SNLI.
Please see how I made a custom pair dataset & dataloader in https://github.com/arvind-cp/fastai/blob/arvind-cp-LM-eval/courses/dl2/FiTLAM%20-%20Quora%20Duplicate%20Pairs%20-%20STS%20task.ipynb

It still breaks the stepper methods. So, in model.py you can edit the step and evaluate methods like this:

from:
output = self.m(*xs)

to:

if len(xs) > 1: output = self.m([*xs])
else: output = self.m(*xs)

This way existing dataloaders/models + your new dataloader will work fine with minimal change to the library. Please let me know if this solution will work for you.",hi working input pair like please see made custom pair still stepper edit step evaluate like output output else output way new work fine minimal change library please let know solution work,issue,positive,positive,positive,positive,positive,positive
385286872,"Not sure how we ended up with so many commits in one PR! I'll close this, and each change can get added to a separate PR - hope that's OK.

(If it's not - please just let me know, and I can reopen this and we can discuss how to merge it in a way that preserves my sanity...)",sure ended many one close change get added separate hope please let know reopen discus merge way sanity,issue,positive,positive,positive,positive,positive,positive
385281913,"@NEIA20 @jph00 this PR and others to the same file have whitespace inconsistency.

Running the tests `python -m pytest -s tests` fails during startup.

Proposed fix in #410.

",file inconsistency running python fix,issue,negative,neutral,neutral,neutral,neutral,neutral
385276473,I think this is fixed now - feel free to open new issue or (better still) PR if anything else missing.,think fixed feel free open new issue better still anything else missing,issue,positive,positive,positive,positive,positive,positive
385276166,"Hmmm... I'm pretty sure I added this for some apparently good reason, but now not sure what that was! I'll merge this PR but let's keep an eye out for regressions, especially on pytorch 0.4.",pretty sure added apparently good reason sure merge let keep eye especially,issue,positive,positive,positive,positive,positive,positive
385276023,"I believe everything should work correctly on 0.4. I'll close this, and instead if there are breakages in 0.4 please opens issues/PRs for each one.",believe everything work correctly close instead please one,issue,negative,neutral,neutral,neutral,neutral,neutral
385275970,"I'd rather we moved towards using the loss functions with integrated softmax, rather than having them in the models.",rather towards loss rather,issue,negative,neutral,neutral,neutral,neutral,neutral
385275901,I'd rather not auto-add all the skeletons. Let's only add them once we have something we're happy with. I'll close this PR - instead could you please just add stuff that's not auto-generated?,rather let add something happy close instead could please add stuff,issue,positive,positive,positive,positive,positive,positive
385275512,Thanks! Some inline comments as to what that new code is doing would be helpful I think - it's not obvious to me at least.,thanks new code would helpful think obvious least,issue,positive,positive,neutral,neutral,positive,positive
385252888,"@oduvan, it looks you are quit passionate about good engineering practices and It seems that you want to help but you are put a back with the code smell. Maybe you even wonder why such awesome idea as fastai is being hampered by poor code readability?

On the other hand  Jeremy and some fastai students are focussing on completly different topics like making the library the fastest in the world. Have you seen this results:
- [CIFAR from 1h in Jan April 2018 to 2 min in April 2018](https://dawn.cs.stanford.edu/benchmark/CIFAR10/train.html) and 
- [ImageNet from 3h30m -> 2h57m and 128 less nodes](https://dawn.cs.stanford.edu/benchmark/CIFAR10/train.html) - anything above Fastai result is on google's private cloud.

I'm still amazed with them, and if you are too help us with getting this library up to open-source standards. To do so we need good _test coverage_ otherwise we are risking breaking things for Jeremy and others that are trying to promote this library.

If you want to help here is a pull request #286 where you will find how the test are being written.
I think you could start with the https://github.com/fastai/fastai/blob/master/fastai/core.py it has plenty of small functions that are used everywhere so good test there would be essential.

Re. cv2 - that opencv, simply click with pycharm on the object to jump to the right place. I know import * make things harder to follow but without test it is impossible to get rid of them, besides a lot of great minds that work with fast.ai use vim without plugins :( and they will get irritated when they would have to jump to the top to import every single thing they need. This can be cleaned up but first we need good tests.",quit passionate good engineering want help put back code smell maybe even wonder awesome idea poor code readability hand different like making library world seen min le anything result private cloud still amazed help u getting library need good otherwise breaking trying promote library want help pull request find test written think could start plenty small used everywhere good test would essential simply click object jump right place know import make harder follow without test impossible get rid besides lot great work use vim without get would jump top import every single thing need first need good,issue,positive,positive,positive,positive,positive,positive
385252267,"Here is an easy example. I'm trying to understand how open_image function works.

https://github.com/fastai/fastai/blob/master/fastai/dataset.py#L218

From source code, I see that it is using cv2 object. I want to understand what this object actually means (or can I learn something about the object), I scroll up to the top of the module and here is what I see

https://github.com/fastai/fastai/blob/master/fastai/dataset.py#L3

```
from .imports import *
from .torch_imports import *
from .core import *
from .transforms import *
```

""thank you for choosing our airlines"" (c) ",easy example trying understand function work source code see object want understand object actually learn something object scroll top module see import import import import thank choosing,issue,positive,positive,positive,positive,positive,positive
385250182,">  when you iterate a lot, the import * is a very useful approach at this stage.

how so?

I haven't seen this kind approach in any project. When Open Source project has a very bad coding style at the very beginning in order to clean everything up later. 

How long this project exists? 2 weeks?

I know, PEP8 is just a recommendations and some of them are not crucial (like line length), but I this using `import *` all over the place, just because it is easier to code like this - is bad idea. Because it become so much hard to read.

In order to save time on coding you can use PyCharm. It adds import lines automatically when you use functions",iterate lot import useful approach stage seen kind approach project open source project bad style beginning order clean everything later long project know pep crucial like line length import place easier code like bad idea become much hard read order save time use import automatically use,issue,positive,negative,neutral,neutral,negative,negative
385231054,Actually a second PR is silly. I've just done the fix as a second commit on this PR.,actually second silly done fix second commit,issue,negative,negative,negative,negative,negative,negative
385155488,"@oduvan  fastai is in early stages when you iterate a lot, the `import *` is a very useful approach at this stage. It can be later cleaned up quickly with pycharm or any other tool. I'm accustomed to pep8 and I find it easier to follow but read the style guide file: https://github.com/fastai/fastai/blob/master/docs/style.md

There is a lot of merit to the styles decisions and Jeremy explains it quite well. I think we will find a middle ground soon enough.",early iterate lot import useful approach stage later quickly tool accustomed pep find easier follow read style guide file lot merit quite well think find middle ground soon enough,issue,positive,positive,positive,positive,positive,positive
385154982,"@jph00  once the pull request above is merged you need to get a https://travis-ci.org account for fastai, it is free for opensource it uses your github credentials to pull the right repositories, then you just need to go to your profile and select  fastai for tests then you should be able to see the tests running at this url:
https://travis-ci.org/fastai/fastai

Here is how it should look like:
<img width=""1223"" alt=""screen shot 2018-04-28 at 10 56 33"" src=""https://user-images.githubusercontent.com/340180/39394548-737cd21c-4ad3-11e8-82dc-ca5d2206aca9.png"">

",pull request need get account free pull right need go profile select able see running look like screen shot,issue,positive,positive,positive,positive,positive,positive
385153079,"@devforfu I think Jeremy would prefer to talk about this on forum. Here is one article that maybe of interest to you, William implemented some tests for SWA:
https://medium.com/@hortonhearsafoo/adding-a-cutting-edge-deep-learning-training-technique-to-the-fast-ai-library-2cd1dba90a49

The  tests aren't yet  merged to Fast AI because they are bundled with other changes that @jph00  is reluctant to merge, so I will split the pull request to two and once it is merged maybe we start a thread on the forum to organise some ppl to write more tests  to the library. 

I wouldn't be too worried with testing the deep-learning parts yet as we are too early in the process. The Fast.ai does not have any test yet and bugs in regular code like transformations can easily break your code the same way as bugs in deep-learning parts. ",think would prefer talk forum one article maybe interest swa yet fast ai reluctant merge split pull request two maybe start thread forum write library would worried testing yet early process test yet regular code like easily break code way,issue,positive,positive,positive,positive,positive,positive
384922330,"> Since I deeply dislike PEP8 and the entire culture around bike-shedding and lack of open-mindedness in much of the python community, I think this tension might be hard to avoid ;)

if you are working on open-source project I would strongly recommend to learn PEP8 and what python community likes in general. 

My personal and the most unfavorite part is `import *`

**PEP8**

> Wildcard imports (from <module> import *) should be avoided, as they make it unclear which names are present in the namespace, confusing both readers and many automated tools. 

You say ""Practical Deep Learning For Coders"" - and at the same time writing you code in a way codes hate a lot :)",since deeply dislike pep entire culture around lack much python community think tension might hard avoid working project would strongly recommend learn pep python community general personal unfavorite part import pep module import make unclear present many say practical deep learning time writing code way hate lot,issue,negative,positive,neutral,neutral,positive,positive
384698731,"I re-tested my application (based on lesson1 notebook code) and it is actually works ok however I do get the following warning when initializing my model from a persisted local copy: 
```
/opt/program/fastai/initializers.py:6: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.
  if hasattr(m, 'weight'): init_fn(m.weight)
```",application based lesson notebook code actually work however get following warning model local copy favor,issue,negative,neutral,neutral,neutral,neutral,neutral
384644023,I can confirm it's not related to Pytorch 0.4 - I tested with both 0.3 and 0.4 and got the same error. ,confirm related tested got error,issue,negative,neutral,neutral,neutral,neutral,neutral
384514939,"I wonder how usually people test deep learning algorithms implementations? I mean, if we're talking about performance metrics and model accuracy verifications, not asserting correct properties values? Quite time consuming process to train model and assert its quality I guess. I mostly trying to do it analytically, but probably someone knows possible alternatives?",wonder usually people test deep learning mean talking performance metric model accuracy correct quite time consuming process train model assert quality guess mostly trying analytically probably someone possible,issue,negative,negative,neutral,neutral,negative,negative
384514481,"@Debugger28 Right, string interpolation was introduced in Python v3.6 only.",right string interpolation python,issue,negative,positive,positive,positive,positive,positive
384512574,"you need python 3.6

On Wed, Apr 25, 2018 at 5:32 PM, Debugger28 <notifications@github.com>
wrote:

> I am trying to run this:
>
> import fastai
>
> from fastai.imports import *
> from fastai.structured import *
>
> Error:
>
> File ""/Users/parihar/anaconda2/lib/python2.7/site-packages/
> fastai-0.6-py2.7.egg/fastai/structured.py"", line 33
> f'Tree {{ size={size}; ratio={ratio}', s)))
> ^
> SyntaxError: invalid syntax
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/397>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZUKpEWrWGeYxz6Oddc2kwl5ekQ93ks5tsRW6gaJpZM4TkWSY>
> .
>
",need python wed wrote trying run import import import error file line size ratio invalid syntax thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
384459154,"I had that error, and fixed it by replacing in model.py:212
res.append([f(preds.data,y.data) for f in metrics]) 
by 
res.append([f(preds.data,y) for f in metrics]) 

It may be related to the change to Pytorch 0.4....
",error fixed metric metric may related change,issue,negative,positive,neutral,neutral,positive,positive
384427847,"Some networks (like mine) need to accept multiple inputs in `.forward` & do something like this:

```py
class Model(nn.Module):
    def __init__(self):
        # ...
    def forward(self, batch):
        firstInput = batch.firstInput
        secondInput = batch.secondInput
        # ...
```

Right now `fastai` assumes every `DataLoader` will yield a 2-tuple of tensors `(x, y)` & crashes if `x` is an arbitrary object that contains tensors because some functions in `model.py` (`fit`, `validate`, `validate_next`) try to convert that arbitrary object into a `torch.Variable` (by calling `V`, leading to `NotImplementedError` from `T`).

My code stops `V` crashing on lists/tuples with a depth of 2, (depth-2 because functions like `fit` wrap `x` in a list).

| Code                | Works now | Works after my change |
|---------------------|-----------|-----------------------|
| V(torch.Tensor)     | :heavy_check_mark:         | :heavy_check_mark:                     |
| V([torch.Tensor])   | :heavy_check_mark:         | :heavy_check_mark:                     |
| V([(torch.Tensor)]) | ❌         | :heavy_check_mark:                     |

Supporting this requires either one modification in `core.py` or several in `model.py`.

Instead of making `V` find tensors in the input and convert them to variables, we could rename `create_variable` to `maybe_create_variable` & make it behave like the identity function when `T` throws errors.

If your worried about getting downstream errors that are tricky to debug we could control this with a flag in `Learner`.",like mine need accept multiple something like class model self forward self batch right every yield arbitrary object fit validate try convert arbitrary object calling leading code depth like fit wrap list code work work change supporting either one modification several instead making find input convert could rename make behave like identity function worried getting downstream tricky could control flag learner,issue,positive,positive,positive,positive,positive,positive
384413562,"I see the breaking changes now on the Pytorch site:

Major Changes and Potentially Breaking Changes:

Tensors and Variables have merged
Some operations now return 0-dimensional (scalar) Tensors
Deprecation of the volatile flag",see breaking site major potentially breaking return scalar deprecation volatile flag,issue,negative,positive,neutral,neutral,positive,positive
384006782,"Ah well in that case, putting a test in the PR would be perfect. We have
a 'tests' directory now, so you could put it there, if not inconvenient.
Otherwise a notebook as a gist with a link in the PR would be fine.
--
Jeremy Howard


On Tue, Apr 24, 2018, at 8:05 AM, Sidharth Chaturvedi wrote:
> Hi @jph00[1], I can provide a test case in a sample notebook, or even
> try to put in a pull request for a test case in code (though I don't
> have a lot of experience there). What would be the preferred way?>  I am actually also working on a simple fix for this issue, and will
>  try to put in a pull request for that soon.> — You are receiving this because you were mentioned. Reply to this
> email directly, view it on GitHub[2], or mute the thread[3].> 


Links:

  1. https://github.com/jph00
  2. https://github.com/fastai/fastai/issues/386#issuecomment-383967183
  3. https://github.com/notifications/unsubscribe-auth/AAVLd1V1pChOIq2DNz1hlVNShGrcdU62ks5trz9VgaJpZM4TgREX
",ah well case test would perfect directory could put inconvenient otherwise notebook gist link would fine tue wrote hi provide test case sample notebook even try put pull request test case code though lot experience would preferred way actually also working simple fix issue try put pull request reply directly view mute thread link,issue,positive,positive,positive,positive,positive,positive
383988857,"Done. I went with ""industrial_fishing"" for the name, but open to alternatives. This is extra nice because now that `image_data` fixture can be reused across any image processing tests! We can do something similar for each style of data loading.",done went name open extra nice fixture across image something similar style data loading,issue,negative,positive,positive,positive,positive,positive
383967183,"Hi @jph00, I can provide a test case in a sample notebook, or even try to put in a pull request for a test case in code (though I don't have a lot of experience there). What would be the preferred way?
I am actually also working on a simple fix for this issue, and will try to put in a pull request for that soon. ",hi provide test case sample notebook even try put pull request test case code though lot experience would preferred way actually also working simple fix issue try put pull request soon,issue,negative,neutral,neutral,neutral,neutral,neutral
383954567,"Just happened to try `'--gpu_ids', '0,0'` which seems to work. 

Closing this. Hopefully others will find this and save time.",try work hopefully find save time,issue,positive,neutral,neutral,neutral,neutral,neutral
383945402,"That would be cleaner indeed, sending a new PR",would cleaner indeed sending new,issue,negative,positive,positive,positive,positive,positive
383940516,There isn't always up to date conda packages available and it's not always easy to compile.,always date available always easy compile,issue,negative,positive,positive,positive,positive,positive
383939409,Could you provide a simple failing test case?,could provide simple failing test case,issue,negative,neutral,neutral,neutral,neutral,neutral
383939141,Sure! Best to discuss on the forum rather than here (also easier to share options there),sure best discus forum rather also easier share,issue,positive,positive,positive,positive,positive,positive
383938752,"Yup you should add them too.

Also note that you should write your docs in the form shown in `transform_tmpl.adoc`. The stuff in {{...}} will be expanded using suitable templates automatically.",add also note write form shown stuff expanded suitable automatically,issue,negative,positive,positive,positive,positive,positive
383938072,"I'd rather not added more params - instead, perhaps make it so if the tmp and models paths are absolute paths then it doesn't do `path.join`?",rather added instead perhaps make absolute,issue,negative,positive,positive,positive,positive,positive
383937436,Best to fix this in your environment instead.,best fix environment instead,issue,positive,positive,positive,positive,positive,positive
383936425,"Sorry I'm not following either the code added or your description. Could you try to show a really simple example of what is calling this new code, and why? Are there any approaches to solving this problem that wouldn't involve changing these functions? (I'd like to keep them as simple as possible since they're so widely used.)",sorry following either code added description could try show really simple example calling new code problem would involve like keep simple possible since widely used,issue,negative,negative,neutral,neutral,negative,negative
383925276,"Thanks! There's already an image in fastai/images - could you either use that image, or if you need some specific image put yours there? Give it a name that doesn't include 'lsuv' - so that other people can use it in their sample code too. (Also we should rename the image that's already in there to be more descriptive!)",thanks already image could either use image need specific image put give name include people use sample code also rename image already descriptive,issue,negative,positive,neutral,neutral,positive,positive
383422994,Hmm... I should probably get this working for inputs that are dicts too. What do you think?,probably get working think,issue,negative,neutral,neutral,neutral,neutral,neutral
383395697,"I've reverted back to the single transforms.py and rebased the branch on recent master so that the changes are clearly visible, the unet notebook is coming in a separate repository. ",back single branch recent master clearly visible notebook coming separate repository,issue,negative,positive,neutral,neutral,positive,positive
382884153,Figured that it is in the loss function (Cross Entropy),figured loss function cross entropy,issue,negative,neutral,neutral,neutral,neutral,neutral
382755109,"Just for the sake of experimenting, I tried to pass the momentum values and their squares when switching from SGD to Adam and it made everything worse (by a lot).
The spike in error when changing the optimizer with reinitializing the buffer isn't very important so it's probably best to leave it as it is now.",sake tried pas momentum switching made everything worse lot spike error buffer important probably best leave,issue,negative,positive,positive,positive,positive,positive
382709321,"Oh, there's definitely a possibility since all the buffed values are stored in a dictionary. Wonder if it could work somehow, to match it (aka momentum with beta1 for instance) and pass it along when we change optimizer.  ",oh definitely possibility since buffed dictionary wonder could work somehow match aka momentum beta instance pas along change,issue,negative,neutral,neutral,neutral,neutral,neutral
382613305,Absolutely. I've revised the docs to point to PyTorch. Should I add arguments and return values to the methods in the `Methods` section? The fastai.transforms template doesn't seem to have them — should the documentation not include that info? ,absolutely point add return section template seem documentation include,issue,negative,positive,positive,positive,positive,positive
382595954,"Many thanks! I'd suggest studying the pytorch DataLoader, that has almost identical API to this, and then in the docs only mention the differences (and point to the pytorch DataLoader docs for the details of the rest).",many thanks suggest almost identical mention point rest,issue,negative,positive,positive,positive,positive,positive
382283113,"@anshbansal for bounding boxes, the format that fastai uses is [ymin, xmin, ymax, xmax].

Pascal VOC uses xmin, ymin, width, height, not (coordinates top right, (height, width--)

... so the following should be updated from
Will use (coordinates top _right_, coordinates bottom right) instead of (coordinates top _right_, (_height_, _width_))
to
Fastai uses (coordinates top _left_, coordinates bottom right) instead of (coordinates top _left_, (_width_, _height_))
or simply:
Fastai uses bounding boxes defined as [ymin, xmin, ymax, xmax]

",bounding format width height top right height width following use top bottom right instead top top bottom right instead top simply bounding defined,issue,positive,positive,positive,positive,positive,positive
382274600,"Would you have to then convert the Half tensor to float tensor when bringing a model trained on GPU to CPU? If that is the case would this make sense:
```
def T(a, half=False, cuda=True):
    if not torch.is_tensor(a):
        a = np.array(np.ascontiguousarray(a))
        if a.dtype in (np.int8, np.int16, np.int32, np.int64):
            a = torch.LongTensor(a.astype(np.int64))
        elif a.dtype in (np.float32, np.float64):
            a = torch.HalfTensor(a) if half and cuda else torch.FloatTensor(a) # Change is here
        else: raise NotImplementedError(a.dtype)
    if cuda: a = to_gpu(a, async=True)
    return a
```",would convert half tensor float tensor model trained case would make sense half else change else raise return,issue,negative,negative,negative,negative,negative,negative
382245258,Cool! I added a warning in the docstring about using it outside of image classification for now. Also fixed up the conflicts.,cool added warning outside image classification also fixed,issue,negative,positive,positive,positive,positive,positive
382203888,Don't worry about Sphinx for now - I haven't done a good job of explaining things and probably won't until I've finished teaching part 2. ,worry sphinx done good job explaining probably wo finished teaching part,issue,negative,positive,positive,positive,positive,positive
382201561,"How about making it an fbeta score function, and then have f1 call that with param of 1? Also I think it's best to call it 'f1' not just 'f' to be clear.",making score function call param also think best call clear,issue,positive,positive,positive,positive,positive,positive
382197413,"@jph00 ok! no worries :) 

Did you see my comment on #326? I can make an issue for the sphinx implementation if that's easier to track",see comment make issue sphinx implementation easier track,issue,negative,neutral,neutral,neutral,neutral,neutral
382172540,"Made the changes you requested 👍 
Tell me if something is missing.

> but the reasoning is in the style guide

In that case, I don't really like this section of the style guide (sorry, didn't notice it until you mentioned), but let's save that discussion for another occasion :)",made tell something missing reasoning style guide case really like section style guide sorry notice let save discussion another occasion,issue,positive,negative,negative,negative,negative,negative
382159108,"I don't feel strongly about it, but the reasoning is in the style guide
if you're interested:
https://github.com/fastai/fastai/blob/master/docs/style.md
--
Jeremy Howard


On Tue, Apr 17, 2018, at 2:39 PM, Rony Lutsky wrote:
> *@ronlut* commented on this pull request.


> 
> In fastai/column_data.py[1]:


> >          if data.is_reg: -            self.crit = F.mse_loss +
> >          return F.mse_loss
>> I think readability here is more important than making it short...


>> Readability Counts


> (PEP20)


> Also, when and if someone will implement multi-output multi-class (or
> multi-output regression), things will get even more complicated.> If you're sure about this one liner, tell me. Honestly I don't really
> see the benefit in this case :)> — You are receiving this because you commented. Reply to this email
> directly, view it on GitHub[2], or mute the thread[3].> 


Links:

  1. https://github.com/fastai/fastai/pull/358#discussion_r182242052
  2. https://github.com/fastai/fastai/pull/358#discussion_r182242052
  3. https://github.com/notifications/unsubscribe-auth/AAVLd_G8i56M2mqol_Q_F-FHLfL5rKACks5tpmD3gaJpZM4TYmXq
",feel strongly reasoning style guide interested tue wrote pull request return think readability important making short readability pep also someone implement regression get even sure one liner tell honestly really see benefit case reply directly view mute thread link,issue,positive,positive,positive,positive,positive,positive
382107117,"Understood, will remove the math and add more code ;-). Of course you can include it in the next lesson if you think that could be useful.

I'll add some examples for the polynomial decay as well and post the notebook on the forum once I'm done.",understood remove math add code course include next lesson think could useful add polynomial decay well post notebook forum done,issue,negative,positive,positive,positive,positive,positive
382104588,"I already fixed it

--
Jeremy Howard


On Tue, Apr 17, 2018, at 11:47 AM, Phani Srikanth wrote:
> Oops. Fixed it in a hurry. Another PR on the way.


> — You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub[1], or mute the
> thread[2].> 


Links:

  1. https://github.com/fastai/fastai/pull/352#issuecomment-382101013
  2. https://github.com/notifications/unsubscribe-auth/AAVLd4JSnP7cpYp9dPcyyZgtZXKQbM8kks5tpjjWgaJpZM4TXI4P
",already fixed tue wrote fixed hurry another way state reply directly view mute thread link,issue,negative,positive,positive,positive,positive,positive
382101013,Oops. Fixed it in a hurry. Another PR on the way. https://github.com/fastai/fastai/pull/361,fixed hurry another way,issue,negative,positive,neutral,neutral,positive,positive
382095562,"I totally love it. I'd like to include this notebook in the next lesson, if I may (with credit of course). :) The math doesn't render correctly on github - beside which I think it's better to show python code rather than math, since anyone reading the docs understands python code, but may not understand math notation. (And python code can be run interactively!)

For the poly example, you should say what power you're using. And maybe show how changing the power changes the shape?

BTW, if you're interested, this paper shows how to smoothly transition between optimizers: https://www.preferred-networks.jp/docs/imagenet_in_15min.pdf . Might be an interesting extension for the future, if you feel the urge to check it out...",totally love like include notebook next lesson may credit course math render correctly beside think better show python code rather math since anyone reading python code may understand math notation python code run poly example say power maybe show power shape interested paper smoothly transition might interesting extension future feel urge check,issue,positive,positive,positive,positive,positive,positive
382040858,"It will work if you pass it as is to metrics. If you'd like to set a custom
threshold you would need to use a partial or a lambda (or define a new
function taking in predictions and targets and passing them along with
custom threshold to one of these).
",work pas metric like set custom threshold would need use partial lambda define new function taking passing along custom threshold one,issue,negative,positive,neutral,neutral,positive,positive
382036449,"Will it work with the threshold parameter?
Shouldn't it return a lambda/partial function for it to work?",work threshold parameter return function work,issue,negative,neutral,neutral,neutral,neutral,neutral
382026229,Yes that sounds great. Also got some conflicts now. If you're able to push a PR with those two little fixes we can try to use this for imagenet! :),yes great also got able push two little try use,issue,positive,positive,positive,positive,positive,positive
382025782,"Will put it in the next PR, I've also changed COSINE so that it goes from start to end when an end is specified, and to zero otherwise.
Writing the tutorial notebook, I'm hoping to have it ready today. ",put next also cosine go start end end zero otherwise writing tutorial notebook ready today,issue,negative,positive,neutral,neutral,positive,positive
382025432,"The intent is that `None` should result in using `num_cpus()`. If that's broken, a fix would be appreciated!",intent none result broken fix would,issue,negative,negative,negative,negative,negative,negative
382023692,"Cool! Might be nice to add *poly* decay too - seems popular for imagenet.

    lr = init_lr*(1 - iter/max_iter)**power
",cool might nice add poly decay popular power,issue,positive,positive,positive,positive,positive,positive
382020616,"It's a nice idea, but probably not widely useful enough for adding to the library - thanks for the PR anyway! :) ",nice idea probably widely useful enough library thanks anyway,issue,positive,positive,positive,positive,positive,positive
381999816,"@jph00 Finally had some time to do initial testing on the language model and NLP classifier stuff, got some out of memory issues that I'll have to dig into further (might just have to do with the size of that model and maintaining two copies of it). I think I should document that it's not quite working yet, and I can keep digging into it after this is merged—or maybe other students will be interested in investigating too once it's in the lib",finally time initial testing language model classifier stuff got memory dig might size model two think document quite working yet keep digging maybe interested investigating,issue,negative,positive,neutral,neutral,positive,positive
381361156,"the splits fix broke from_text_files


```
TypeError                                 Traceback (most recent call last)
<ipython-input-12-0e98c1d5fc20> in <module>()
      1 FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)
----> 2 md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=10)

~/fastai/courses/dl1/fastai/nlp.py in from_text_files(cls, path, field, train, validation, test, bs, bptt, **kwargs)
    305         """"""
    306         trn_ds, val_ds, test_ds = ConcatTextDataset.splits(
--> 307             path, text_field=field, train=train, validation=validation, test=test, keep_nones=True)
    308         return cls(path, field, trn_ds, val_ds, test_ds, bs, bptt, **kwargs)
    309 

~/anaconda3/envs/fastai/lib/python3.6/site-packages/torchtext/data/dataset.py in splits(cls, path, root, train, validation, test, **kwargs)
     70             path = cls.download(root)
     71         train_data = None if train is None else cls(
---> 72             os.path.join(path, train), **kwargs)
     73         val_data = None if validation is None else cls(
     74             os.path.join(path, validation), **kwargs)

~/fastai/courses/dl1/fastai/nlp.py in __init__(self, path, text_field, newline_eos, encoding, **kwargs)
    173 
    174         examples = [torchtext.data.Example.fromlist([text], fields)]
--> 175         super().__init__(examples, fields, **kwargs)
    176 
    177 

TypeError: __init__() got an unexpected keyword argument 'keep_nones'
```
",fix broke recent call last module path text path field train validation test path return path field path root train validation test path root none train none else path train none validation none else path validation self path text super got unexpected argument,issue,negative,positive,positive,positive,positive,positive
381298413,"@jph00 I have some comments/questions about the sphinx implementation: 

Sphinx takes text files written in [restructuredText (rst)](https://www.southampton.ac.uk/~fangohr/computing/rst/rst.txt) and transforms them into html (although it can generate other outputs as well, like pdfs). In `fastai/docs` there are files written in markdown and asiidoc. Sphinx can work with docs that are written in both markdown and rst, but because markdown and rst are so similar, and because sphinx was built to work with rst, I think that it would probably be simpler to just rewrite the existing docs in rst.

There are other documentation generators, and some that use markdown as their basis, but I think that sphinx seems pretty powerful and useful. I don't think it would be too much trouble to rewrite the existing docs - there aren't too many yet. Sphinx is also easy to integrate with [readTheDocs](https://docs.readthedocs.io/en/latest/) if that's something fastai is interested in as well

If we do want to use sphinx and re-write the docs into rst, that's probably the first thing I'd do

What do you think?",sphinx implementation sphinx text written although generate well like written markdown sphinx work written markdown markdown similar sphinx built work think would probably simpler rewrite documentation use markdown basis think sphinx pretty powerful useful think would much trouble rewrite many yet sphinx also easy integrate something interested well want use sphinx probably first thing think,issue,positive,positive,positive,positive,positive,positive
380866697,"Best place for that is the forums. Be sure to at-mention me (and feel
free to PM if I don't notice the thread).
--
Jeremy Howard


On Wed, Apr 11, 2018, at 6:58 PM, Michael Skinner wrote:
> I'm happy to do it. Let me know if anything comes to mind that you'd
> like to see improved, e.g. I should looking into undoing my fake'ish
> objects.> Semi-relatedly, is there a preferred channel for talking about the
> library development? Github is great once it comes to concrete
> changes, but sometimes there's a philosophical discussion to be had.> — You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub[1], or mute the
> thread[2].> 


Links:

  1. https://github.com/fastai/fastai/pull/330#issuecomment-380650300
  2. https://github.com/notifications/unsubscribe-auth/AAVLd8B8xJXs85dwVgbL7UVfOiEmvtbAks5tnrTjgaJpZM4TNOyC
",best place sure feel free notice thread wed skinner wrote happy let know anything come mind like see looking undoing preferred channel talking library development great come concrete sometimes philosophical discussion state reply directly view mute thread link,issue,positive,positive,positive,positive,positive,positive
380650300,"I'm happy to do it. Let me know if anything comes to mind that you'd like to see improved, e.g. I should looking into undoing my fake'ish objects.

Semi-relatedly, is there a preferred channel for talking about the library development? Github is great once it comes to concrete changes, but sometimes there's a philosophical discussion to be had.",happy let know anything come mind like see looking undoing preferred channel talking library development great come concrete sometimes philosophical discussion,issue,positive,positive,positive,positive,positive,positive
380631160,"I don't think this is worth an extra param, compared to just passing in val_idxs.",think worth extra param passing,issue,negative,positive,positive,positive,positive,positive
380630830,"Can you provide a gist or similar showing what problem this solves, and how the existing class is problematic?",provide gist similar showing problem class problematic,issue,negative,neutral,neutral,neutral,neutral,neutral
380328342,"And a shot of the error handler.
![image](https://user-images.githubusercontent.com/2524396/38597238-4c26c874-3d0b-11e8-9d25-35bdd9095813.png)
",shot error handler image,issue,negative,neutral,neutral,neutral,neutral,neutral
380284572,"[![Build Status](https://travis-ci.org/PiotrCzapla/fastai.svg?branch=master)](https://travis-ci.org/PiotrCzapla/fastai)

@jph00  the ci it is working fine, It is bundled with the changes to transform.py but it can be extracted to a new branch if you wish.",build status working fine extracted new branch wish,issue,positive,positive,positive,positive,positive,positive
380283994,"@jph00 I've extracted the relevant changes to transforms as mixins and placed them into transforms2.py. It works, tests are passing, but this is a bit too magical for my taste. 

I would rather speed up discussion regarding the new API and go for plan A ie add backwards compatible changes to transforms.py.
",extracted relevant work passing bit magical taste would rather speed discussion regarding new go plan ie add backwards compatible,issue,negative,positive,positive,positive,positive,positive
380258181,"The build is looking good after some spelling fixes (thx @Gokkulnath) we have first successful build on travis-ci. I've updated the transforms.py pull request #312 so that there are no conflicts, but I still want to get the minimal version of transforms2.py working so that the branch can be merged and the new API can be played within it separate space. ",build looking good spelling first successful build pull request still want get minimal version working branch new within separate space,issue,positive,positive,positive,positive,positive,positive
380237217,@jph00  I've seen you talking about this on pytroch issue tracker. I've fixed it by setting matplotlib to use Agg as backend and importing the torch and cv in a right order.,seen talking issue tracker fixed setting use torch right order,issue,negative,positive,positive,positive,positive,positive
380234384,"Importing torch first normally fixes that problem FYI.

We don't need qt - so agree that maybe a test-only env might help make
this faster and easier?
--
Jeremy Howard


On Tue, Apr 10, 2018, at 1:20 PM, Piotr Czapla wrote:
> update. I've managed to reproduce the crash in travis-ci locally in a
> docker instance I'm trying to see what I can do with that. Filtering
> tests only seems to solve the crash but introduce another one:


> from PyQt5 import QtCore, QtGui, QtWidgets E   ImportError: dlopen:
> cannot load any more object with static TLS
>> pytorch/pytorch#2575[1]


> — You are receiving this because you commented. Reply to this email
> directly, view it on GitHub[2], or mute the thread[3].> 


Links:

  1. https://github.com/pytorch/pytorch/issues/2575
  2. https://github.com/fastai/fastai/issues/286#issuecomment-380233710
  3. https://github.com/notifications/unsubscribe-auth/AAVLd0d1VmzAQB1wRd6jKyRZSSuBfSm_ks5tnRQjgaJpZM4THck4
",torch first normally problem need agree maybe might help make faster easier tue wrote update reproduce crash locally docker instance trying see filtering solve crash introduce another one import load object static reply directly view mute thread link,issue,negative,positive,positive,positive,positive,positive
380233710,"update. I've managed to reproduce the crash in travis-ci locally in a docker instance I'm trying to see what I can do with that. Filtering tests only seem to solve the crash but introduce another one: 
```
from PyQt5 import QtCore, QtGui, QtWidgets
E   ImportError: dlopen: cannot load any more object with static TLS
```

https://github.com/pytorch/pytorch/issues/2575
",update reproduce crash locally docker instance trying see filtering seem solve crash introduce another one import load object static,issue,negative,positive,positive,positive,positive,positive
380222351,"@Gokkulnath  the gist seems to be broken I see just the JS with plenty of document write :/ (after some fiddling I guess you meant this url: https://gist.github.com/Gokkulnath/31b91f1db29d171471269be07d9177ff)

The point of CI is to check that the dependencies don't collide so having them there may help us in the future, and should not hinder you when you write tests, as the test should be mostly executed locally on your pc /aws. 

to run the tests you simply install `pip install pytest` then run `python -m pytest tests`.  I'm playing with a docker instance to reporduce the crash we can observe at travis-ci and the test are failing so I can't show you how they look like but you will be able to see if they are working or not.


",gist broken see plenty document write fiddling guess meant point check collide may help u future hinder write test mostly executed locally run simply install pip install run python docker instance crash observe test failing ca show look like able see working,issue,negative,positive,neutral,neutral,positive,positive
380222266,"Update. Small change of plans as it seems that Datascience bowl deadline is in 2 days not in 7 as I initially though so I will first focus on finishing some ideas before I can jump on this again. So to avoid having this PR hanging around  much longer I'm going for the B option, and create transforms2.py. 

I will use a bit of python magic to enable the new API reusing the existing classes from transforms.py as much as it is possible, so that we can benefit from fixes changes to the transforms.py and keep the updated API.
",update small change bowl deadline day initially though first focus finishing jump avoid hanging around much longer going option create use bit python magic enable new class much possible benefit keep,issue,negative,positive,positive,positive,positive,positive
380217311,"@PiotrCzapla  I Would like to help in writing tests. Though i am not totally aware how it is done but interested in spending sometime learning it.
Misc : Can we have a separate Environment File for Test Env ? I believe we don't need some of   packages eg Jupyter, Ipython etc.. Guess this will reduce the time to run the test. 
Tried figuring out few of unnecessary stuffs : Check out the Gist  [here ](https://gist.github.com/Gokkulnath/31b91f1db29d171471269be07d9177ff)
",would like help writing though totally aware done interested spending sometime learning separate environment file test believe need guess reduce time run test tried unnecessary check gist,issue,positive,positive,neutral,neutral,positive,positive
380152859,Yeah it's for use in notebooks where `splits` is often called without a test set.,yeah use often without test set,issue,negative,neutral,neutral,neutral,neutral,neutral
380151827,I really appreciate you making the effort to make this initial test file clear - I expect future contributors will use this as a role model so this work will be particularly helpful.,really appreciate making effort make initial test file clear expect future use role model work particularly helpful,issue,positive,positive,neutral,neutral,positive,positive
379824371,"Hey @alew3 ,

Yeah, just need to send is_reg = False when creating ColumnarModelData. If you are using proc_df to prepare the data to use with ColumnarModelData then proc_df sets the Y in the required format. Else the Y needs to be an integer-valued array representing the class. The shape of Y should be (n,) ",hey yeah need send false prepare data use format else need array class shape,issue,negative,negative,negative,negative,negative,negative
379820084,"I'd rather use github PR comments for me  to do code reviews and for
authors to reply and ask questions etc - let's use the forums for
discussions please.
--
Jeremy Howard


On Mon, Apr 9, 2018, at 9:43 AM, apiltamang wrote:
> Took a quick swab at your notebook...
>  The accuracies and the log-loss seem very off (0.0025 now versus
>  >.99% from when I was taking the Part-1 course). Any explanation you
>  could provide for that? Thnx..> — You are receiving this because you were mentioned. Reply to this
> email directly, view it on GitHub[1], or mute the thread[2].> 


Links:

  1. https://github.com/fastai/fastai/pull/328#issuecomment-379817136
  2. https://github.com/notifications/unsubscribe-auth/AAVLdwyYd-UI3m1euS8CkJGkBpddTk4zks5tm4_DgaJpZM4TMZzj
",rather use code reply ask let use please mon wrote took quick swab notebook seem versus taking course explanation could provide reply directly view mute thread link,issue,negative,positive,positive,positive,positive,positive
379818250,"Oh, it's not a pretrained model. The steps you can see on the notebook are only the first ones toward real training on the whole ImageNet that Jeremy would like to try.",oh model see notebook first toward real training whole would like try,issue,negative,positive,positive,positive,positive,positive
379817136,"Took a quick swab at your notebook...
The accuracies and the log-loss seem very off (0.0025 now versus >.99% from when I was taking the Part-1 course). Any explanation you could provide for that? Thnx..",took quick swab notebook seem versus taking course explanation could provide,issue,negative,positive,positive,positive,positive,positive
379813426,"Hi @apiltamang 
Not sure of the way I'm doing my PR as well, it's very new to me. If you want some sample code, there is
[this notebook](https://github.com/sgugger/Deep-Learning/blob/master/Resnet%2050%20and%20Darknet%2053.ipynb).",hi sure way well new want sample code notebook,issue,positive,positive,positive,positive,positive,positive
379770871,"Nice ... despite being a dev. for several years now, I haven't yet had any familiarity with a CI system. Will be good to track this. Would you mind tagging me in future developments?

Thanks much!",nice despite dev several yet familiarity system good track would mind future thanks much,issue,positive,positive,positive,positive,positive,positive
379768474,"Hi,
Could you by any chance push a jupyter-notebook with sample code as well? I could checkout this branch, and as a sanity-check, run the notebook to see everything is solid!

You could later (maybe) delete the code and/or rename the notebook file to something like: ""lesson-7-CAM-using-darknet"", @jph00 willing.

Edit:
Very weird, I can't seem to find a way to checkout this branch. I think so because your PR is coming from an external repo. Nevermind what I asked.
Thanks..",hi could chance push sample code well could branch run notebook see everything solid could later maybe delete code rename notebook file something like lesson willing edit weird ca seem find way branch think coming external thanks,issue,positive,negative,neutral,neutral,negative,negative
379648357,"Thank you Jeremy :)

I have added Test_GoogleNetResize.ipynb on the fastai repo. I have sent another PR to remove it and bring the repo to ideal state. Sorry for the mistake.",thank added sent another remove bring ideal state sorry mistake,issue,negative,positive,positive,positive,positive,positive
379619080,"I've fixed the docs to reflect that it's not +/- 5 stdevs of bptt, but N(bptt,5). I noticed in the forum that you made the same mistake, so looks like you may have misunderstood the code her. Just an FYI",fixed reflect forum made mistake like may misunderstood code,issue,negative,positive,neutral,neutral,positive,positive
379618130,"Thanks for the additions. One thing that would be helpful is to create separate sections for abbrevs that only apply to certain areas (eg an NLP section would include 'bptt').

The docs are currently waiting on creation of a python script that converts the asciidoc template into the asciidoc output you can see in the docs directory. I believe someone is working on this, but don't know where he's up to.

We'll also need a sphinx (or similar) template to create the asciidoc templates from the existing docstrings.",thanks one thing would helpful create separate apply certain section would include currently waiting creation python script template output see directory believe someone working know also need sphinx similar template create,issue,positive,positive,positive,positive,positive,positive
379609952,"Thanks for single-handedly going this far for creating the docs, documenting etc...

For documentation, I think writing the general shape of the arrays/tensors that get passed in methods would be great. Really helps sort out what the method is about sometimes.

Also be generalizing, I mean, saying that an array is like:
(batch_size, n_channels, height, width). I realize that this is NOT always possible, so feel free to ignore otherwise.",thanks going far documentation think writing general shape get would great really sort method sometimes also mean saying array like height width realize always possible feel free ignore otherwise,issue,positive,positive,positive,positive,positive,positive
379566817,Can't verify as I'm on mobile but the job log seems to indicate we are trying to activate env `fastai` whereas the name of the CPU only env that we are installing is `fastai-cpu`,ca verify mobile job log indicate trying activate whereas name,issue,negative,neutral,neutral,neutral,neutral,neutral
379565924,"@jph00 any reason for this `None` filtering in `ConcatTextDatasetFromDataFrames` ([code here](https://github.com/fastai/fastai/blob/16313f83fef7f47b6008643e9eb8f5397fbabe54/fastai/nlp.py#L196)):
`return tuple(d for d in (train_data, val_data, test_data) if d is not None)`

It seems easy to remove, and my grepping says the only caller is the one in this stack trace.",reason none filtering code return none easy remove caller one stack trace,issue,negative,positive,positive,positive,positive,positive
379564926,I'm getting segmentation faults probably due to memory limits on travis-ci (4GB per docker container).,getting segmentation probably due memory per docker container,issue,negative,negative,negative,negative,negative,negative
379564725,"The from scratch stuff isn't too bad, it's legacy and external code where mocks can save you oodles of effort tracing through byzantine construction dependencies.

That said, fastai doesn't have that problem, and tests can provide a nice pressure to keep it that way.

Updated the point to just say no.",scratch stuff bad legacy external code save oodles effort tracing construction said problem provide nice pressure keep way point say,issue,negative,negative,neutral,neutral,negative,negative
379562409,"@jph00  fair enough, but it would be good to wait with the merge until someone makes pytest actually work with fastai as it doesn't right now, and pycharm isn't picking it up as well :/.

It seems that `pytest` command is not working with `conda` environments. I guess it is using wrong python, and wrong PYTHONPATH. But fortunately, there is a workaround suggested by @mcskinner works fine. Ie.
```
 python -m pytest tests
```

Having that said I will keep using unittest until this issue with pycharm and conda is fixed, and the tests are easy to convert later. 
",fair enough would good wait merge someone actually work right well command working guess wrong python wrong fortunately work fine ie python said keep issue fixed easy convert later,issue,positive,positive,positive,positive,positive,positive
379554578,"Here is the first version of travis-ci integration.
https://travis-ci.org/PiotrCzapla/fastai/builds/363774572

It was still building when I was leaving if this is red or yellow then it means the test are working (the current test fail so the button should be red)
[![Build Status](https://travis-ci.org/PiotrCzapla/fastai.svg?branch=master)](https://travis-ci.org/PiotrCzapla/fastai)",first version integration still building leaving red yellow test working current test fail button red build status,issue,negative,negative,neutral,neutral,negative,negative
379534506,"I've created the thread to discuss the new API as @jph00  requested.  If you have comments/suggestions please go there: http://forums.fast.ai/t/proposal-for-transforms-py-v2/14633

This PR will be either closed or a small backward compatible change would be merged to master, so it isn't best place to discuss the full proposal.",thread discus new please go either closed small backward compatible change would master best place discus full proposal,issue,positive,positive,positive,positive,positive,positive
379530282,"I see your point having a long live PR is awful from the maintainers perspective. It is as bad from the contributor perspective having to deal with the upcomming changes on an active repository. 
That is why I opted for full compatibility in the first rewrite and I wanted to have it out and merge ready in matters of days. But If you don't have the time to review it in the next couple of days I understand.

I will throw the gist to the forum to discuss the API v2 (the one showed in comment). Although I know that discussion can take ages, and I want to have something that works for the Data Science Bowl before it is finshed :).

I see 2 ways to achive that:
A. Have a quick discussion and merge a fully compatible, tested version providing it is ready in 3 days, the change won't be much longer than what is proposed above. If you won't have time, I understand.
B. Create transforms2.py and put there a proptotype version of the API that isn't 100% compatible (with redundancy removed). So that contributors can think about appling the changes to the second file as well.  I'm not sure If I manage to write the unit test in a way that they can be used for both transforms2.py and transforms.py but I will try.
C. I can keep everything in my fork for time being / or in a branch, but then we won't benefit from tests.

Given that you don't have time probably B. or C. would be a good way to go. Let me know and if you select B or C, close the PR.",see point long live awful perspective bad contributor perspective deal active repository full compatibility first rewrite merge ready day time review next couple day understand throw gist forum discus one comment although know discussion take want something work data science bowl see way quick discussion merge fully compatible tested version providing ready day change wo much longer wo time understand create put version compatible redundancy removed think second file well sure manage write unit test way used try keep everything fork time branch wo benefit given time probably would good way go let know select close,issue,positive,positive,neutral,neutral,positive,positive
379523635,"I don't have time to think about this deeply right now, but the direction sounds hopeful. Certainly I do want to have transforms_side_on et all work with tfm_y.

It's a bit inconvenient for me to have PRs sitting here that aren't actually ready to be merged. I also think it's nice to have some discussion more widely about significant user-visible changes. Therefore, would you be comfortable with me closing this and instead creating a gist showing the proposed new approach, and posting a thread on the forum that introduces it for discussion?

If that's not ideal for you, then feel free to say no!",time think deeply right direction hopeful certainly want work bit inconvenient sitting actually ready also think nice discussion widely significant therefore would comfortable instead gist showing new approach posting thread forum discussion ideal feel free say,issue,positive,positive,positive,positive,positive,positive
379523314,"My attitude to fastai contributors is to assume that they are smart, committed, and interested to learn. If there's a tool that we like and think people would appreciate learning about, then we should feel comfortable assuming that they'll happily take the time to study it. So far this assumption generally seems to hold - people crazy enough to study DL through fast.ai are generally pretty motivated to learn!",attitude assume smart interested learn tool like think people would appreciate learning feel comfortable assuming happily take time study far assumption generally hold people crazy enough study generally pretty learn,issue,positive,positive,positive,positive,positive,positive
379522594,"Frankly I'm not sure - I think the best thing to do would be to pop this all into a notebook along with examples showing how to use, and ask for feedback/help on the forum. I'll close it for now until we've had a chance to get more eyeballs on it. It's not a bad idea actually for more major changes to get shared as a gist on the forum first.",frankly sure think best thing would pop notebook along showing use ask forum close chance get bad idea actually major get gist forum first,issue,positive,positive,positive,positive,positive,positive
379514578,"I'm trying to fix this spacy problem to do lesson 4.  
I've looked through all these links and it's not clear what fixes it.  

What is this code in your 'fix spacy...' link above? I don't know what code that is? Is that run by me somehow?",trying fix spacy problem lesson link clear code spacy link know code run somehow,issue,negative,positive,positive,positive,positive,positive
379506007,"Ohh, one more thing, the idea of creating new ""transformation"" once `determ()` is called will let us implement TTA for mask & bounding box problems. Because the list of deterministic transformations  created in Transforms.determ can be saved and then reused to undo the transformation on a result from the model.
",one thing idea new transformation let u implement mask bounding box list deterministic saved undo transformation result model,issue,negative,positive,positive,positive,positive,positive
379504694,"@jph00 The PR is not intended to be merged yet. I would add more tests to make sure that the changes are indeed working as they should, but I'd like to hear your opinion before invest time in writing the tests.

To make the code readable I've added only the absolutely necessary changes and I left the now redundant code in place so that the commit is easier to read.

Writing the test for the transform_coord (awesome idea btw.) I've found an issue there, it seems that each time a transformation is applied a bounding box is shrunk by one pixel. So if you have 7 transformations your bounding box will be 7 pixels short. I will fix that once I have the green light to go with this design.

Below are few ideas that I haven't implemented for simplicity, and I would love to hear your opinion.

- Move `apply_transform` to the `Dataset` as it seems a more natural place for such function.
- Remove tfm_y in favor of tfmtype passed to each transformation
- Remove is_y completely and we can replace it with tfm.INPUT_PIXEL
- Remove set_state & store completely in favor of creating a copy of the transformation either with fixed random state. 
- Add ability to handle dictionaries (in np_collate)
- Add ability to handle namedtuples (in np_collate) so that batch of namedtuples would become a namedtuple (that is for future)


",intended yet would add make sure indeed working like hear opinion invest time writing make code readable added absolutely necessary left redundant code place commit easier read writing test awesome idea found issue time transformation applied bounding box shrunk one bounding box short fix green light go design simplicity would love hear opinion move natural place function remove favor transformation remove completely replace remove store completely favor copy transformation either fixed random state add ability handle add ability handle batch would become future,issue,positive,positive,positive,positive,positive,positive
379502720,"@mcskinner  I was thinking about py.test as well, but I would be careful here.  The fastai community is not that experienced with python and py.test magical behavior is quite complex to follow. If you mix that with programmers that haven't yet mastered  metaprogramming in python you may end up debugging test for ages.

See this discussion:
https://www.reddit.com/r/Python/comments/6j1gcq/if_you_are_not_using_pytest_why_not/djaxa3d/

But I'm torn here, I love how py.test works but I'm worried to use it here.",thinking well would careful community experienced python magical behavior quite complex follow mix yet python may end test see discussion torn love work worried use,issue,positive,positive,positive,positive,positive,positive
379501581,"This is great feedback Jeremy!

I was writing the whole thing for myself as I was running the notebook- I shouldn't have sent the notebook as-is.

I'll provide a concise version soon. Thanks again!",great feedback writing whole thing running sent notebook provide concise version soon thanks,issue,positive,positive,positive,positive,positive,positive
379494332,"Will think about it. 
Currently working on making `StructuredLearner.summary()` work :)",think currently working making work,issue,negative,neutral,neutral,neutral,neutral,neutral
379489779,"Roger that, sorry for the mess. I'll go ahead and add a script and maybe we can consider it an interim best practice in the testing doc? (PR out for that now).",roger sorry mess go ahead add script maybe consider interim best practice testing doc,issue,negative,positive,positive,positive,positive,positive
379488639,Great thanks! One thing to think about if you're interested - can we refactor this is_reg and is_multi stuff in all the places it's used so we don't have to have it as a param to so many functions and can simplify the code a bit?,great thanks one thing think interested stuff used param many simplify code bit,issue,positive,positive,positive,positive,positive,positive
379488480,"Thanks for this.

Just an FYI: your earlier `is_listy` change to torch_imports didn't work since fastai.core isn't imported there - since we don't as yet have the protection of unit tests or CI, please double-check that something like the lesson 1 notebook works before sending in a PR (or create a simple little integration test script to check).",thanks change work since since yet protection unit please something like lesson notebook work sending create simple little integration test script check,issue,positive,positive,neutral,neutral,positive,positive
379480587,"Great addition! And to clarify how to use it .. do I just have to pass is_reg=False to do data classification with my structured data? Also, what kind of datatype does my y have to be ? (categorical?)",great addition clarify use pas data classification structured data also kind categorical,issue,positive,positive,positive,positive,positive,positive
379480290,"Hmm.  I saw them in the notebooks and didn't comb through the libraries to see if they were also there.  Fundamentally, it comes down to the question of whether the notebooks are part of the source code or not.  I can see both sides of that question.

I would be in favour of taking an inclusivist viewpoint.  If the abbreviation appears in the notebook and is for a word which is likely to be used in the future (like `wgt`), then having it in the abbreviation list lets a future contributor know what term they should be using.  It would cause extra work or confusion if contributor A used 'w' and contributor B used 'wt' and contributor C used 'wgt'.",saw comb see also fundamentally come question whether part source code see side question would taking viewpoint abbreviation notebook word likely used future like abbreviation list future contributor know term would cause extra work confusion contributor used contributor used contributor used,issue,negative,neutral,neutral,neutral,neutral,neutral
379474536,Oh also it would be nice to start an asciidoc file in the docs/ dir where we can start describing fastai testing approaches/recommendations/etc.,oh also would nice start file start testing,issue,negative,positive,positive,positive,positive,positive
379474495,"Thanks! Fixing those 2 missing assertion issues would be great. BTW I found some of the tests a little unclear as to what you were testing and why. A comment or docstring on the test would be nice to explain tests where it's not pretty obvious from the code what's happening.

I think we should use pytest since it's more modern, concise, and [recommended by coders](https://www.slant.co/topics/2621/~python-unit-testing-frameworks).

We should also follow this suggestion from the [python testing guide](http://docs.python-guide.org/en/latest/writing/tests/):

> Use long and descriptive names for testing functions. The style guide here is slightly different than that of running code, where short names are often preferred. The reason is testing functions are never called explicitly. square() or even sqr() is ok in running code, but in testing code you would have names such as test_square_of_number_2(), test_square_negative_number(). These function names are displayed when a test fails, and should be as descriptive as possible.

I'll merge this PR now so that we have something to build on.",thanks fixing missing assertion would great found little unclear testing comment test would nice explain pretty obvious code happening think use since modern concise also follow suggestion python testing guide use long descriptive testing style guide slightly different running code short often preferred reason testing never explicitly square even running code testing code would function displayed test descriptive possible merge something build,issue,positive,positive,positive,positive,positive,positive
379473994,"I'll merge this now so folks can play with it - but I think you should revert the shape bug fix. It seems you added your transform right to the end of the list, after the channel axis rotation transform, but that's a really unusual place to put a transform. Normally we put them earlier in the pipeline.

And don't forget, if you have a question about what's happening in the code, just add a breakpoint and take a look in the debugger! :)",merge play think revert shape bug fix added transform right end list channel axis rotation transform really unusual place put transform normally put pipeline forget question happening code add take look,issue,negative,positive,positive,positive,positive,positive
379446998,There is not much value added in this PR after recent changes to master so withdraw it.,much value added recent master withdraw,issue,negative,positive,neutral,neutral,positive,positive
379433827,Merging this in so things don't break for now. Will add more changes to fix fp16 later,break add fix later,issue,negative,neutral,neutral,neutral,neutral,neutral
379364766,"I've merged these - but some of them only appear in the notebooks; I'm not sure either way if they should be in this doc, or maybe would be better to define them in the notebook where they appear?",appear sure either way doc maybe would better define notebook appear,issue,positive,positive,positive,positive,positive,positive
378995761,"I think we are in alignment here. Dummy integration tests are easier (just executing a notebook that is prepared), but I see your point with proper unit-tests, but let's give it a go.  I would pick the transformations as this will benefit the most from the tests and I know the code quite well. 

I will get first steps implemented in a separated branch.",think alignment dummy integration easier notebook prepared see point proper let give go would pick benefit know code quite well get first branch,issue,positive,positive,positive,positive,positive,positive
378985858,Add me to the list of folks who appreciate a nice testing safety blanket. Let me know what I can do to help!,add list appreciate nice testing safety blanket let know help,issue,positive,positive,positive,positive,positive,positive
378924092,"Yeah that would be good. I'd rather start with proper python tests rather than executing notebooks - I think starting the ""right way"" is important to provide a model for other contributors to follow. E.g this is what we're trying to do for docs right now - show a really good role model for the `fastai.transforms` module, and then let the community follow that for the other modules.

I think that means picking one piece of functionality, or the functionality displayed in one lesson, or picking one class, and trying to show how to test it in a reasonably light-weight but effective way. I do agree that integration tests should be the focus. A few thoughts:

- Tests should check correctness both with and without the GPU (assuming one is available); you can just toggle `fastai.core.USE_GPU` to check both backends
- CI integrations tests should run quickly. That probably means we can't *really* know if an algorithm is fully working (i.e that it actually makes the loss go down when run on real data) since that takes a while for any meaningful dataset. But we could at least do a single batch and check loss isn't NaN
- We could have a longer integration test for each major piece of functionality (e.g. 'fine tune an image classifier CNN') that runs for 30 seconds or so. With a carefully chosen dataset this should be enough to confirm the model is doing something reasonable
- We should include at least *some* unit tests, so folks know what our expectations for unit tests are.

If people submit a PR that changes core functionality like the DataLoader, I'd like to see unit tests with that, since there's a lot of edge cases that are easy to miss and the integration tests won't always identify those issues. E.g if padding isn't done correctly in DataLoader, integration tests might still run, but NLP models might become less accurate.",yeah would good rather start proper python rather think starting right way important provide model follow trying right show really good role model module let community follow think one piece functionality functionality displayed one lesson one class trying show test reasonably effective way agree integration focus check correctness without assuming one available toggle check run quickly probably ca really know algorithm fully working actually loss go run real data since meaningful could least single batch check loss nan could longer integration test major piece functionality tune image classifier carefully chosen enough confirm model something reasonable include least unit know unit people submit core functionality like like see unit since lot edge easy miss integration wo always identify padding done correctly integration might still run might become le accurate,issue,positive,positive,positive,positive,positive,positive
378920062,"Yup agree with the previous comments - especially since this is going to be seen by students, we should keep it simple. If possible, I'd like to make it even simpler - e.g. could we create an use an inherited class that does this automatically?
Also, you should check `fastai.core.USE_GPU` as well, since the user may have a GPU available but have chosen not to use it with this flag.",agree previous especially since going seen keep simple possible like make even simpler could create use class automatically also check well since user may available chosen use flag,issue,positive,positive,neutral,neutral,positive,positive
378919083,"Yes agree with all the comments - little readability improvements are appreciated, but without tests it is a bit concerning to merge them. These particular changes all look fine, but we should probably invest in tests before doing much more refactoring or readability improvements.",yes agree little readability without bit concerning merge particular look fine probably invest much readability,issue,positive,positive,positive,positive,positive,positive
378734503,"@mcskinner, I'm thinking about writing some test to flash out the API and how it is used so that I can propose such small changes to the code without the need to rerun everything manually. I've created an issue to discuss that:
https://github.com/fastai/fastai/issues/286
",thinking writing test flash used propose small code without need rerun everything manually issue discus,issue,negative,negative,negative,negative,negative,negative
378686207,"The goal, which is good to question, is to bring the style of the code more consistently in line with the conventions in this project's [style guide](https://github.com/fastai/fastai/blob/master/docs/style.md). It happens to jive with my personal philosophy that, because code is read far more often than written, any investment in readability improvements tends to have high ROI. This is related to Chris Olah and Shan Carter's discussion of [Research Debt](https://distill.pub/2017/research-debt/) and the related concept of Interpretive Labor.

In this case I'm trying to keep those changes very small and visually verifiable. That seemed to be the norm for this project rather than tests, so it's what I did. I'm sure there is a line at which the changes become large enough in scope to warrant an automated check, and that might have happened here.

As you said, we can let @jph00 decide where that line is :) I don't mind writing tests, and in fact find it quite therapeutic, but if that's asked I wouldn't mind it if someone else set up the scaffolding first ;)",goal good question bring style code consistently line project style guide jive personal philosophy code read far often written investment readability high roi related carter discussion research debt related concept interpretive labor case trying keep small visually verifiable norm project rather sure line become large enough scope warrant check might said let decide line mind writing fact find quite therapeutic would mind someone else set scaffolding first,issue,negative,positive,positive,positive,positive,positive
378643881,"Just curious, can you please document why these changes were necessary? If not in the .ipynb files, I see at least one .py file where the change was made.

A better method would be to create a simple utils method, and call that method from all those places. Then you could give that method a sensible name, and a good doc-string, so that everyone knows what your intentions are.

e.g.
```
def getDeviceStats():
''' this method is needed because of this and that, and so on .... '''
  return None if torch.cuda.is_available() else -1
```

More tip:
'None' and '-1' both appear to relate to the same thing, i.e. something been amiss. Would it make sense to return 0 and -1, or None and +1? This may not be possible, but just a thought.

Thanks ..",curious please document necessary see least one file change made better method would create simple method call method could give method sensible name good everyone method return none else tip appear relate thing something amiss would make sense return none may possible thought thanks,issue,positive,positive,positive,positive,positive,positive
378641335,"I obviously see that you're trying to do the right thing, but to what gains.. Injecting changes as such, and as trivial as they seem, might introduce subtle bugs which may cause a lot of confusion.

While in retrospect, I agree that such refactoring definitely can also lead to catching, otherwise hidden,  bugs.

For your intent, I strongly suggest including some unit tests. There oughta be no refactoring for the pure reason of only refactoring (or terraforming) without some unit and integration tests. While machine-learning is not exactly amenable to traditional testing techniques, code-modifications as above seem like they could use some unit tests. Also, it would set a very good template for including more unit tests.

I hope you take the suggestion for good! I've met only very few developers who don't balk when asked to write test. Ultimately, I don't have write access to this repo, so it's really @jph00's call .

",obviously see trying right thing gain trivial seem might introduce subtle may cause lot confusion retrospect agree definitely also lead catching otherwise hidden intent strongly suggest unit pure reason without unit integration exactly amenable traditional testing seem like could use unit also would set good template unit hope take suggestion good met balk write test ultimately write access really call,issue,positive,positive,positive,positive,positive,positive
378464801,"I'll run some tests on the language model and NLP classifier stuff. I think if it doesn't work, we can document it like you suggested, and I can try and dig into it when I have more time later.",run language model classifier stuff think work document like try dig time later,issue,negative,neutral,neutral,neutral,neutral,neutral
378372119,"Easy peasy, thanks for the insight on DataLoader. Is the py3.6 queue issue fix also local to fastai vs the torch version?",easy peasy thanks insight queue issue fix also local torch version,issue,positive,positive,positive,positive,positive,positive
378371072,Yes that's the reason - the forums is where we would like to have these discussions please.,yes reason would like please,issue,positive,neutral,neutral,neutral,neutral,neutral
378368735,"I think part of the reason why this was closed, was to move the discussion rather to the forums. Check the forums for this issue too. I barely remember reading somewhere that this might be a bug with PyTorch. Somebody might've resolved that though.",think part reason closed move discussion rather check issue barely remember reading somewhere might bug somebody might resolved though,issue,negative,negative,neutral,neutral,negative,negative
378366889,"It's a pity that Jeremy closed this. One has to be very attentive during his lectures....sometimes you blink and you miss it.
I also have this posed on forums. 

http://forums.fast.ai/t/lesson9-2018-pascal-multi-ipynb/14404

A quick update as well...

After defining the Focal_Loss class, running ssd_loss(batch, y, True) results in an error:

TypeError: Performing basic indexing on a tensor and encountered an error indexing dim 0 with an object of type torch.cuda.LongTensor. The only supported types are integers, slices, numpy scalars, or if indexing with a torch.LongTensor or torch.ByteTensor only a single Tensor may be passed.

I guess I will wait for some updates.",pity closed one attentive sometimes blink miss also quick update well class running batch true error basic indexing tensor error indexing dim object type indexing single tensor may guess wait,issue,negative,positive,positive,positive,positive,positive
378346261,"I've been trying to hand-write the code all the way from the top to the finish, and not quite done with it yet. Thus, don't have anything public to share.

I'm pretty sure people have done this though, so have faith. Somewhere in the fastai forum, you should find answers to any more issues, if still pending.",trying code way top finish quite done yet thus anything public share pretty sure people done though faith somewhere forum find still pending,issue,positive,positive,positive,positive,positive,positive
378343402,"@apiltamang,
I will try eliminating all .cpu() from all cells and update my results here.
If you do have a working notebook can you share with me?
Thanks",try update working notebook share thanks,issue,positive,positive,positive,positive,positive,positive
378342621,"This is because part of your data is in the GPU, hence the torch.**cuda**.FloatTensor, while part of the data is in CPU, hence the torch.FloatTensor without the **cuda** qualifier.

To resolve, do NOT execute any code calling .cpu() or to_cpu(). These were originally there only for some debugging purposes.

Let know if this helps ..",part data hence torch part data hence without qualifier resolve execute code calling originally let know,issue,negative,positive,positive,positive,positive,positive
378033837,"OK well I'll merge this, and we can chat about the other stuff when you're around in person if you like.",well merge chat stuff around person like,issue,positive,neutral,neutral,neutral,neutral,neutral
377730126,"@jph00 
Took another pass at things.  Reverted the parameter changes to use the defaults (momentum is supposed to be .1, for what it's worth).  Went a bunch deeper into how the current models are working.  My thoughts:

1) the only other model in this directory that actually has a weights file/related logic is inceptionresnet_2.  resnext50, resnext101, resnext101_64, and wrn use the load_pre helper but do not actually have actual logic in these classes to download anything.
2) inceptionresnet_2 is not actually currently working (models file is 404).  I attempted to match upstream changes here: https://github.com/Cadene/pretrained-models.pytorch/blob/master/pretrainedmodels/models/inceptionresnetv2.py  but I need some feedback/guidance on how the conv_layer implements cut (e.g. it is not slicing the right layers)
3) if we moved inception_4 and inceptionresnet_2 to the model_zoo approach (use the torchvision loader) then the load_pre logic can be removed altogether (since the other models do not actually use it)
4) i wrote basic loaders for NASnet and inception 3, but they are not converging/training improperly (e.g. 60% accuracy on my training/validation data), both need conv_layer cut and model_features tweaks, I would like feedback/guidance there.
5) the inception_4 model fails on the planet dataset when I just blindly change the model in the dl1/course-2 notebook, don't want to hunt further right now.



",took another pas parameter use momentum supposed worth went bunch current working model directory actually logic use helper actually actual logic class actually currently working file match upstream need cut slicing right approach use loader logic removed altogether since actually use wrote basic inception improperly accuracy data need cut would like model planet blindly change model notebook want hunt right,issue,negative,positive,neutral,neutral,positive,positive
377722145,"Disregard, the `ds` stuff comes in from the `@property`s on the ModelData parent. Derp.",disregard stuff come property parent,issue,negative,neutral,neutral,neutral,neutral,neutral
377698112,"@ForeverZyh,

I did not find nlp.py in the repository. If I were to guess, you are **not using Python 3.6**

Switch to Python 3.6, it will help",find repository guess python switch python help,issue,negative,neutral,neutral,neutral,neutral,neutral
377677851,"I'm gonna drop by again, hopefully on Monday. 
This is the spring break, so the little one is with me at home the whooole week... 
Starting next week I'll be a productive member of society again. 

Can't wait for some skeletons to build on! Kudos to @racheltho !",gon na drop hopefully spring break little one home week starting next week productive member society ca wait build kudos,issue,positive,negative,neutral,neutral,negative,negative
377506730,This issue has been fixed in the latest pull.,issue fixed latest pull,issue,negative,positive,positive,positive,positive,positive
377503437,"Sorry, the `^` is actually misplaced. 

```
File ""/home/zyh/DLTesting/repos/fastai/courses/ml1/fastai/nlp.py"", line 168
if os.path.isdir(path): paths=glob(f'{path}/.')
                                             ^
SyntaxError: invalid syntax
```",sorry actually file line path path invalid syntax,issue,negative,negative,negative,negative,negative,negative
377417482,"This is the code I'm running:

```
df, y, nas, mapper = proc_df(ori_df, dep, do_scale=True, ignore_flds=bincat_vars)
df_test, _, nas, mapper = proc_df(ori_df_test, do_scale=True, ignore_flds=bincat_vars,
                                 mapper=mapper, na_dict=nas)
train_ratio = 0.8
train_size = int(len(df) * train_ratio)
val_idx = list(range(train_size, len(df)))
md = ColumnarModelData.from_data_frame(PATH, val_idx, df, y, cat_flds=cat_vars, bs=128, test_df=df_test)
```

Stacktrace and error:
```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-5-1f311450d28f> in <module>()
      5 train_size = int(len(df) * train_ratio)
      6 val_idx = list(range(train_size, len(df)))
----> 7 md = ColumnarModelData.from_data_frame(PATH, val_idx, df, y, cat_flds=cat_vars, bs=128, test_df=df_test)

~/edu/kaggle/allstate/fastai/column_data.py in from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg, test_df)
     68     def from_data_frame(cls, path, val_idxs, df, y, cat_flds, bs, is_reg=True, test_df=None):
     69         ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)
---> 70         return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, test_df=test_df)
     71 
     72     def get_learner(self, emb_szs, n_cont, emb_drop, out_sz, szs, drops,

~/edu/kaggle/allstate/fastai/column_data.py in from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, test_df)
     61     @classmethod
     62     def from_data_frames(cls, path, trn_df, val_df, trn_y, val_y, cat_flds, bs, is_reg, test_df=None):
---> 63         test_ds = ColumnarDataset.from_data_frame(test_df, cat_flds, is_reg) if test_df is not None else None
     64         return cls(path, ColumnarDataset.from_data_frame(trn_df, cat_flds, trn_y, is_reg),
     65                     ColumnarDataset.from_data_frame(val_df, cat_flds, val_y, is_reg), bs, test_ds=test_ds)

~/edu/kaggle/allstate/fastai/column_data.py in from_data_frame(cls, df, cat_flds, y, is_reg)
     43     @classmethod
     44     def from_data_frame(cls, df, cat_flds, y=None, is_reg=True):
---> 45         return cls.from_data_frames(df[cat_flds], df.drop(cat_flds, axis=1), y, is_reg)
     46 
     47 

~/edu/kaggle/allstate/fastai/column_data.py in from_data_frames(cls, df_cat, df_cont, y, is_reg)
     39         cat_cols = [c.values for n,c in df_cat.items()]
     40         cont_cols = [c.values for n,c in df_cont.items()]
---> 41         return cls(cat_cols, cont_cols, y, is_reg)
     42 
     43     @classmethod

~/edu/kaggle/allstate/fastai/column_data.py in __init__(self, cats, conts, y, is_reg)
     27         self.y = np.zeros((n,1)) if y is None else y
     28         if is_reg:
---> 29             self.y =  self.y[:,None]
     30         self.is_reg = is_reg
     31 

TypeError: 'bool' object is not subscriptable
```
Thanks.",code running mapper mapper list range path error recent call last module list range path path path return path self path path none else none return path return return self none else object thanks,issue,negative,positive,neutral,neutral,positive,positive
377375734,"Can you please provide the code you ran, and the full stack trace and error?",please provide code ran full stack trace error,issue,negative,positive,positive,positive,positive,positive
377375465,Probably easiest to PR your wrapper so I can see what you did. Thanks for this!,probably easiest wrapper see thanks,issue,positive,positive,positive,positive,positive,positive
377374079,"Generally if normalizing needs to be done, what's important is that the final result is N(0,1). So I think the current behavior is generally what's preferred. I do agree however that it can be a little surprising in some situations!

Thanks a lot for the detailed analysis. I'm going to close this now since I think we've got this resolved.",generally need done important final result think current behavior generally preferred agree however little surprising thanks lot detailed analysis going close since think got resolved,issue,positive,positive,positive,positive,positive,positive
377343146,"Updated the gist with histograms, describes, and original/transformed values. So a summary of my findings keeping in mind that all data was drawn from standard normal.

Old proc_df: Scaler has low standard deviation compared to true distribution, X_train is standard normal, X_valid is normal but not standard, and values in X_train and X_valid are scaled to be quite different from the original values.

New proc_df: Scaler has correct standard deviation of true distribution, X_train is normal but not standard, X_valid is standard normal, and values in X_train and X_valid are scaled and still similar to original values.

Which of these behaviors is actually preferred? In both cases, future test sets would still be in the range of train's seen values but I'm not sure if there will be an effect on training or testing?",gist summary keeping mind data drawn standard normal old scaler low standard deviation true distribution standard normal normal standard scaled quite different original new scaler correct standard deviation true distribution normal standard standard normal scaled still similar original actually preferred future test would still range train seen sure effect training testing,issue,positive,positive,positive,positive,positive,positive
377337244,"FYI I just added some initial skeleton markdown docs for fastai.transforms, and a thought about how the template might be expanded into HTML as well. Both are in the docs dir. @racheltho is working on fleshing this out now. Hope to have a good role model to build on soon! :) ",added initial skeleton markdown thought template might expanded well working fleshing hope good role model build soon,issue,positive,positive,positive,positive,positive,positive
377336580,"ArraysDataset is an abstract class. You shouldn't be instantiating it directly. You can tell by the way it has methods marked with `@abstractmethod`.

Instead, you should be instantiating a child class. If the child class you need doesn't exist, feel free to submit a PR which implements it!",abstract class directly tell way marked instead child class child class need exist feel free submit,issue,positive,positive,positive,positive,positive,positive
377253955,"Thanks for the updates! Just to clarify, my previous comment re sphinx is that I'm fine with you using it or anything else to create the *initial skeleton* - but it's not something I want in the ongoing code base.

What I'm hoping we can create now is a single role model documentation page for a single module, where we test out ideas for documenting fastai, until we are happy that we have something that works well. I've been thinking more about this since we initially discussed it and have some ideas about something that *might* work. :) Are you planning to drop by again, or is it best to have that discussion here in the PR?",thanks clarify previous comment sphinx fine anything else create initial skeleton something want ongoing code base create single role model documentation page single module test happy something work well thinking since initially something might work drop best discussion,issue,positive,positive,positive,positive,positive,positive
377251160,"Thanks a lot for restructuring this - much more clear!

Sorry if this is a dumb question, but want to make sure I understand. The issue you're describing is that we're *first* replacing missing (with median), then *then* calculating the column stats. And your gist shows that the mapper contains the stdev and mean from after the replacement.

So.... isn't this what you actually want? I mean, the actual mean and stdev of the column really *are* now the mean and stdev with the missing vals replaced with median. It seems that your suggested way to scaling does not result in a column with a mean of zero and std of one, doesn't it? (AFAICT your gist never actually checks this, it only checks the mappers stored stats - although I may be missing something).",thanks lot much clear sorry dumb question want make sure understand issue first missing median calculating column gist mapper mean replacement actually want mean actual mean column really mean missing median way scaling result column mean zero one gist never actually although may missing something,issue,negative,negative,negative,negative,negative,negative
377244539,Thanks for this useful contribution. I'd prefer to keep this in a separate repo however. Perhaps you could just create a 'fastai-docker' repo or something like that?,thanks useful contribution prefer keep separate however perhaps could create something like,issue,positive,positive,positive,positive,positive,positive
377078470,This is great! Only thing you're missing is `abbr`->`abbreviation` ;),great thing missing abbreviation,issue,negative,positive,positive,positive,positive,positive
377037112,"I have updated documentation and made a folder sphinx_docs and complimentary readme files in docs folder. 
A shell script is included so you can just run it to generate all documentations. ",documentation made folder complimentary folder shell script included run generate,issue,negative,positive,positive,positive,positive,positive
376761607,Ah yes good point,ah yes good point,issue,positive,positive,positive,positive,positive,positive
376761524,Thanks - I particularly appreciate you explaining what testing you did.,thanks particularly appreciate explaining testing,issue,positive,positive,positive,positive,positive,positive
376761256,BTW (and not that it matters) but IIRC `T()` already does `to_gpu()` so you could probably just have removed the `.cuda()` entirely :) ,already could probably removed entirely,issue,negative,neutral,neutral,neutral,neutral,neutral
376760824,"Thanks! How about using `fastai.io.get_data` to grab the weight file? If it's already there, that function will skip it.",thanks grab weight file already function skip,issue,negative,positive,positive,positive,positive,positive
376699728,"Feel free to use whatever works best for you to create the skeleton! I
don't think we need to keep any of the output other than the basic
docstrings it copies over, right?
",feel free use whatever work best create skeleton think need keep output basic right,issue,positive,positive,positive,positive,positive,positive
376355754,Just change it to use `to_gpu()` instead. That only uses the GPU if available. PR welcome!,change use instead available welcome,issue,negative,positive,positive,positive,positive,positive
376017970,"Would an easy fix be to make the get_sz dependent on the shape? Something like 

sz = x.shape[2] if x.ndim == 4 else x.shape[1]",would easy fix make dependent shape something like else,issue,positive,positive,positive,positive,positive,positive
376013446,"Actually this isn't going to work. `from_arrays` is often used with fully connected layers that are only rank-2. We can't assume they're images. I'm going to close this for now since I'm not at all sure what the right solution is, or if there is one - I suspect there is a need to refactor the class hierarchy of ModelData somehow...",actually going work often used fully connected ca assume going close since sure right solution one suspect need class hierarchy somehow,issue,negative,positive,positive,positive,positive,positive
376013232,"BTW note you can't just say 'transforms_top_down'. You have to specify the transforms list in full, as shown in the notebook. Really we should change `transforms_top_down` to a function that takes a TfmType param...",note ca say specify list full shown notebook really change function param,issue,negative,positive,positive,positive,positive,positive
376009808,"This sounds interesting, but I'm unable to see what's going on in this PR. A PR should just contain a fix for a problem, ideally with docs and a brief test. To show the problem that's being solved, could you please create a gist with the notebook and a simple explanation?",interesting unable see going contain fix problem ideally brief test show problem could please create gist notebook simple explanation,issue,positive,neutral,neutral,neutral,neutral,neutral
375940831,"@davideboschetto Where did you change to y.long()?

    cat, cont, y = next(iter(md.trn_dl))
    cat, cont, y = Variable(cat), Variable(cont), Variable(y).long()
    pred = model(cat, cont)
    for p, true in zip(pred.data.numpy(), torch.max(y, 1)[0].data):
        print('pred log probs: {} -- True: {}'.format(p, true))

Then run lr_find() yields the error. y is set to a long so don't know where to change it.

Running on Bash Ubuntu on Win 10.
",change cat next iter cat variable cat variable variable model cat true zip print log true true run error set long know change running bash win,issue,positive,positive,positive,positive,positive,positive
375912899,"I think I see where the issue is. The `tfm_y` is not being set along when the  `tfms_from_stats` is called with `tfm_y=TfmType.MASK`. (see screenshot), which makes it impossible to use `aug_tfms=transforms_top_down` along with `tfm_y`. 

The issue isn't that easy to correct, as assign tfm_y to all aug_tfms will cause problems later as most of the time aug_tfms are global objects, that are reused between calls. But It could be a good temorary fix
<img width=""908"" alt=""screen shot 2018-03-24 at 18 58 02"" src=""https://user-images.githubusercontent.com/340180/37867294-4d946fae-2f96-11e8-9af5-8e3ded1771c0.png"">

",think see issue set along see impossible use along issue easy correct assign cause later time global could good fix screen shot,issue,positive,positive,neutral,neutral,positive,positive
375790199,"Absolutely. I didn't write any of the docstrings (they're all
contributed) - don't worry about stepping on any toes!
--
Jeremy Howard


On Fri, Mar 23, 2018, at 12:55 PM, cuddle-cuddle wrote:
> *@cuddle-cuddle* commented on this pull request.


> 
> In fastai/transforms.py[1]:


> > @@ -465,6 +478,21 @@ def __call__(self, im, y=None): return
> > compose(im, y, self.tfms)  def image_gen(normalizer, denorm, sz,
> > tfms=None, max_zoom=None, pad=0, crop_type=None, tfm_y=None,
> > sz_y=None, pad_mode=cv2.BORDER_REFLECT): +    """""" +    Returns
> > transformer for specified image operations.
>> Love this. Brings order to the universe.
>  Now I know I've been doing everything wrong, do I have your blessing
>  to change your previous doc strings too as well as mine?> Thanks!


> — You are receiving this because you commented. Reply to this email
> directly, view it on GitHub[2], or mute the thread[3].> 


Links:

  1. https://github.com/fastai/fastai/pull/238#discussion_r176848063
  2. https://github.com/fastai/fastai/pull/238#discussion_r176848063
  3. https://github.com/notifications/unsubscribe-auth/AAVLd-zgHLJdHaLXwI5dihCjRyurn0T9ks5thVMsgaJpZM4S33vM
",absolutely write worry stepping mar wrote pull request self return compose normalizer transformer image love order universe know everything wrong blessing change previous doc well mine thanks reply directly view mute thread link,issue,positive,positive,neutral,neutral,positive,positive
375673720,"I think this bug is fixed now - also all this code has been rewritten by another student to make it consistent with the more recent thread-safe approach. So I'll close this, but feel free to open a new PR or issue if anything comes up.",think bug fixed also code another student make consistent recent approach close feel free open new issue anything come,issue,positive,positive,positive,positive,positive,positive
375673110,"Many thanks for these helpful notes.

We recommend using conda, not pip, in the course. The pip installer was created to allow kaggle kernels to work, and for those who prefer not to use anaconda. We're not going to be changing the course to be recommending pip, so these suggestions aren't really ideal (unless I'm missing something).

I'm going to close this PR for now, since it's not clear to me that it's solving a problem we really have right now (e.g. folks that want to use `pip -e` can still do so). If anyone has a suggestion for a better way to handle our conda environment, it would be useful to discuss it on the forum first rather than here so that students can participate in the discussion and add their thoughts.",many thanks helpful recommend pip course pip installer allow work prefer use anaconda going course pip really ideal unless missing something going close since clear problem really right want use pip still anyone suggestion better way handle environment would useful discus forum first rather participate discussion add,issue,positive,positive,positive,positive,positive,positive
375666407,Very nice. Remind me to talk to you about the 'zoom' bit - we need to think about how that interacts with cropping.,nice remind talk bit need think,issue,negative,positive,positive,positive,positive,positive
375665273,Thanks! I'll close this issue whilst you're sleuthing - feel free to open a new one if required.,thanks close issue whilst feel free open new one,issue,positive,positive,positive,positive,positive,positive
375665006,Sounds reasonable to me. Thanks for the helpful gist.,reasonable thanks helpful gist,issue,positive,positive,positive,positive,positive,positive
375664147,"These kinds of problems are generally more rapidly dealt with on the forum FYI.

If you can bisect down to the commit that raised this problem, we should be able to fix it easy enough. Otherwise, unless we can replicate it ourselves, it'll be tricky for us to do anything about...",generally rapidly dealt forum bisect commit raised problem able fix easy enough otherwise unless replicate tricky u anything,issue,negative,positive,positive,positive,positive,positive
375619912,"Will check it out, got a bit sidetracked by this issue: [https://github.com/fastai/fastai/issues/241](https://github.com/fastai/fastai/issues/241). I think I will write a method to apply it to a pre-trained model and see if it improves things. Will post updates here",check got bit issue think write method apply model see post,issue,negative,neutral,neutral,neutral,neutral,neutral
375450388,"I use ""pip install -e ."" with fastai all the time. It's convenient to create separate projects and use fastai library there while still having ability to change fastai source code.",use pip install time convenient create separate use library still ability change source code,issue,positive,neutral,neutral,neutral,neutral,neutral
375245486,"You might also want to add the editable install of the library to the requirements.txt file and advise people to install the library that way:

```sh
python -m venv path/to/virtualenv
source path/to/virtualenv/bin/activate
pip install -r requirements.txt
```

or with pipenv (the new hot shit: <http://pipenv.org>)

```
cd path/to/repo
pipenv install -r requirements.txt
```",might also want add install library file advise people install library way sh python source pip install new hot install,issue,negative,positive,positive,positive,positive,positive
375226492,"@jph00 Since it reads like you may not be familiar with what `pip install -e path/to/fastai/repo` does, it basically adds a symlink to the package to the virtual environment / site-packages. This means the library is importable like any installed python library, but still any update to the source code / git pull will immediately be used.",since like may familiar pip install basically package virtual environment library importable like python library still update source code git pull immediately used,issue,positive,positive,positive,positive,positive,positive
375224778,"I'd like to support suggesting `pip install -e .` instead of the symlinks, as it is much better practice than using symlinks. Some arguments:
* Magic Symlink no longer necessary
* Notebooks / Code can be put anywhere and still import fastai without problems
* Not needing to clutter up the repo with my own experiments means it's easier to create actual pull requests for fastai.
* It works more similar like any other python library, i.e. what people with python knowledge expect.

I think it's fine to keep the symlink if you want that for the included notebooks so they still work even if people miss the `pip install -e .` step (also good for backwards compatibility). But for moving forward I think recommending `pip install -e .` is definitely the way forward.",like support suggesting pip install instead much better practice magic longer necessary code put anywhere still import without needing clutter easier create actual pull work similar like python library people python knowledge expect think fine keep want included still work even people miss pip install step also good backwards compatibility moving forward think pip install definitely way forward,issue,positive,positive,positive,positive,positive,positive
375118568,Thanks for the feedback. Addressed it in the latest commit.,thanks feedback latest commit,issue,positive,positive,positive,positive,positive,positive
375061213,"@jph00 sounds good. Yeah I hate having the code base littered with giant comments just for docs. We had that at my job, but it's pretty distracting for developers, so we moved away from it in favor of using [Swagger](https://swagger.io/docs/
), which is in a separate file, and then gets hosted externally. Swagger is designed for web API's though. I'll do a bit of sleuthing and see what's out there for a project like this.",good yeah hate code base giant job pretty away favor swagger separate file externally swagger designed web though bit see project like,issue,positive,negative,negative,negative,negative,negative
375019624,"We could have a better discussion on the forum, but the short answer is
yes, I'd love to have more docs. My preference (which we haven't
implemented anywhere yet) is to have a more fleshed-out doc in a
separate doc/ folder (which we'd then host somewhere) and a short
summary docstring with a link to the full docs for that symbol.

If you don't have time to help set something like that up, adding longer
docstrings would still be very helpful, since we can always paste them
into the full docs later if we set that up.
",could better discussion forum short answer yes love preference anywhere yet doc separate folder host somewhere short summary link full symbol time help set something like longer would still helpful since always paste full later set,issue,positive,positive,positive,positive,positive,positive
374996673,"If you ignore PEP8 warnings `7497-6838 =659` things to fix.

https://github.com/hhatto/autopep8 is nice and you can configure things to ignore https://github.com/pytorch/pytorch/blob/e7c1e6a8e39df0d206efe247f5eb0481eb8b8b6c/setup.cfg


maybe you can focus in what to ignore from the top of the warnings (because they show the way a programmer do things, or the more prevalent things on fast ai source code)


```
$ pep8 --statistics -qq . | sort -nr
3110    E231 missing whitespace after ','
1938    W191 indentation contains tabs
669     E501 line too long (83 > 79 characters)
619     E261 at least two spaces before inline comment
266     E302 expected 2 blank lines, found 1
188     E701 multiple statements on one line (colon)
164     E225 missing whitespace around operator
142     E128 continuation line under-indented for visual indent
130     E111 indentation is not a multiple of four
55      E301 expected 1 blank line, found 0
54      W293 blank line contains whitespace
```

I think `W191` should be fixed automatically because it contains tabs! :).

which is the largest line in the code?

So your configure could be some like

```
[pep8]
max-line-length = 512
ignore = E231

[flake8]
max-line-length = 512
```
with this you will skip 3110 `some,other` and 669 lines to loong. 3779 skips of 7497. Fixing  3718, maybe it will be nice to configure it and run it one time, so in the future the configuration could be checked.

Remember PEP8 is a guidance, but if your repo does have some specifics, they could be keep in place, you only need to configure things out, so that all people could follow and check if needed... that means that you can choose to ignore (maybe corrects the ones with less than 100 ocurrences in code, or maybe less than 50).

We should test if pycharm follows this warnings turn offs in automatic (no need to manually shut them down), if it does, it will be worth to do it.",ignore pep fix nice configure ignore maybe focus ignore top show way programmer prevalent fast ai source code pep statistic sort missing indentation line long least two comment blank found multiple one line colon missing around operator continuation line visual indent indentation multiple four blank line found blank line think fixed automatically line code configure could like pep ignore flake skip fixing maybe nice configure run one time future configuration could checked remember pep guidance could keep place need configure people could follow check choose ignore maybe le code maybe le test turn automatic need manually shut worth,issue,negative,positive,neutral,neutral,positive,positive
374946660,I don't think you need to add more detail to kwargs yet - once you've documented the relevant bit of `Learner` you can then include a brief summary here.,think need add detail yet relevant bit learner include brief summary,issue,negative,positive,positive,positive,positive,positive
374793101,"It is since version 4.4. (It's also recommended to move away from modifying $PATH in .bashrc).
Details here. https://www.anaconda.com/blog/developer-blog/how-to-get-ready-for-the-release-of-conda-4-4/",since version also move away path,issue,negative,neutral,neutral,neutral,neutral,neutral
374786227,"Hi Jeremy,
I intended to add more detail to kwargs** potentially later (based on research into Learn() class). Do you want that done before this is committed to the main repo? 
I think this is better than leaving it blank, but I can add more detail before a commit. I was thinking about doing it in small increments. 
",hi intended add detail potentially later based research learn class want done main think better leaving blank add detail commit thinking small,issue,positive,positive,neutral,neutral,positive,positive
374782189,Thanks for posting this - we noticed this too and are working on it now! I agree with both your suggested fixes. Look for a fix shortly...,thanks posting working agree look fix shortly,issue,positive,positive,neutral,neutral,positive,positive
374781387,"Many thanks for working on this! It's a good idea to discuss ideas like this on the forum beforehand so you can work with other projects that are in place as appropriate. We've had some discussions there and have felt that we'd rather avoid auto-generating docs from the docstrings.

Could you please split this into multiple smaller PRs which we can discuss separately? Please remove the sphinx stuff and all auto-generated files. Thanks again!",many thanks working good idea discus like forum beforehand work place appropriate felt rather avoid could please split multiple smaller discus separately please remove sphinx stuff thanks,issue,positive,positive,positive,positive,positive,positive
374780373,"I'd rather not make this a requirement, since we don't use it in the lessons.",rather make requirement since use,issue,negative,neutral,neutral,neutral,neutral,neutral
374779737,"I merged the earlier PR - thanks though!

BTW when sending a PR for notebooks, please ensure the diff only includes the actual code changes, not output or metadata changes.",thanks though sending please ensure actual code output,issue,positive,positive,neutral,neutral,positive,positive
374779229,Interesting! Have you tested this on a model and found it worked well?,interesting tested model found worked well,issue,positive,positive,positive,positive,positive,positive
374777961,FYI you should also call `reset` if it exists - see the other `predict*` functions for examples.,also call reset see predict,issue,negative,neutral,neutral,neutral,neutral,neutral
374777712,"I'll merge it, but FYI easier is to skip the conditional and use ` os.makedirs(dirname, exists_ok=True)`",merge easier skip conditional use,issue,negative,neutral,neutral,neutral,neutral,neutral
374777377,"I think you could provide more detail. Maybe easier to document Learner first. A learner is something that combines a ModelData object with a nn.Module object, such that you can train that module with that data. ",think could provide detail maybe easier document learner first learner something object object train module data,issue,negative,positive,positive,positive,positive,positive
374776580,I believe the new version of conda has changed this behaviour. Can you please check you're on the latest version? On my version it asks me to use `conda activate`.,believe new version behaviour please check latest version version use activate,issue,negative,positive,positive,positive,positive,positive
374537221,"Try replacing spacy_tok with string ""spacy"", when initializing TEXT variable. Instead of module reference it seems to use string variable instead.

TEXT = data.Field(lower=True, tokenize='spacy') #spacy_tok
http://torchtext.readthedocs.io/en/latest/data.html#field
",try string spacy text variable instead module reference use string variable instead text,issue,negative,neutral,neutral,neutral,neutral,neutral
373990053,"Looking at the commit history, it seems that the error is caused by this commit: 98fad0efb963baaae80d4c21eb6196c3456e4176

```
 def n_hot(ids, c):
-    res = np.zeros((c,), dtype=np.float32)
+    res = np.zeros((c,), dtype=np.int8)
     res[ids] = 1
     return res
```
The change to np.int8 appears to have caused the problem. I changed it back to float (while removing my workaround above) and it worked fine.
",looking commit history error commit return change problem back float removing worked fine,issue,negative,positive,positive,positive,positive,positive
373960072,"Yes, I noticed it has been refactored a bit. It's inside Tokenizer() class.
Try: `Tokenizer().spacy_tok`",yes bit inside class try,issue,negative,neutral,neutral,neutral,neutral,neutral
373945255,"The problem was introduced in commit 3e4b5a9, till the commit before (98fad0e) everything was working fine. The code below reproduces the error:

```
%reload_ext autoreload
%autoreload 2
%matplotlib inline

from fastai.learner import *

import torchtext
from torchtext import vocab, data
from torchtext.datasets import language_modeling

from fastai.rnn_reg import *
from fastai.rnn_train import *
from fastai.nlp import *
from fastai.lm_rnn import *

import dill as pickle
print(spacy_tok)
```

it fails since spacy_tok is not defined. ",problem commit till commit fade everything working fine code error import import import data import import import import import import dill pickle print since defined,issue,negative,positive,positive,positive,positive,positive
373748202,"Absolutely yes! :) Be sure to do plenty of testing to ensure it works as
well as it does in the paper on the same datasets, where possible.
",absolutely yes sure plenty testing ensure work well paper possible,issue,positive,positive,positive,positive,positive,positive
373497903,"This is trivial, seems like most of the datasets I find always have spaces in the labels, which means we have to first normalize them and then again denormalize before making a submission, so maybe it's just easier to be a parameter.",trivial like find always first normalize making submission maybe easier parameter,issue,positive,positive,positive,positive,positive,positive
373117277,"btw. pytorch managed to used auto pep8, some time in 2017, I will try to configure it according to your preferences and we see what results we get.
https://github.com/pytorch/pytorch/commit/e7c1e6a8e39df0d206efe247f5eb0481eb8b8b6c",used auto pep time try configure according see get,issue,negative,neutral,neutral,neutral,neutral,neutral
373103345,"Thanks - I think this issue will be a useful reference for the future,
in the absence (for now) of a fastai style-guide.
",thanks think issue useful reference future absence,issue,positive,positive,positive,positive,positive,positive
373037707,"Ok fair enough no more bike-sheeding :).

I've learned enough to be able to replicate your style where it matter so that I can try to contribute. I will set PEP8 to ignore what is intentional, and  correct all the rest and we see where it get us.

The following warnings are going to be disabled:

>3110 E231 missing whitespace after ','
>669 E501 line too long (83 > 79 characters)
>266 E302 expected 2 blank lines, found 1
>188 E701 multiple statements on one line (colon)
>142 E128 continuation line under-indented for visual indent

The rest of warnings stay, with intention to get rid of them or put them on the list above. 
That includes:

> 1938 W191 indentation contains tabs
> 164 E225 missing whitespaces around operator
> 130 E111 indentation is not a multiple of four

Let me think how I can best reflect this discussion in the linter configurations / tests etc. and I will propose something in a PR.
",fair enough learned enough able replicate style matter try contribute set pep ignore intentional correct rest see get u following going disabled missing line long blank found multiple one line colon continuation line visual indent rest stay intention get rid put list indentation missing around operator indentation multiple four let think best reflect discussion linter propose something,issue,negative,positive,positive,positive,positive,positive
373028209,"> But a regular python programmer is used to PEP8, and it is hard to shake off, especially when most of the python libraries (including TF & pytorch) follow this style to some extent. So there will be a constant tension, that I'd like to minimize.

Since I deeply dislike PEP8 and the entire culture around bike-shedding and lack of open-mindedness in much of the python community, I think this tension might be hard to avoid ;)

> I meant configuring linters to return warnings that you truly want to fix. 

Yup. Although I haven't found any linters that are thoughtful enough to actually work the way I want for nearly any language, unfortunately.

> To create a consistent style we can see what types of warnings we have in the code and decide what to correct and which checks to disable:

Thanks this is helpful

>   3110 E231 missing whitespace after ','

This is intentional. Nearly every class has something like:

    self.x,self.y = x,y

The spacing clearly separates LHS from RHS. Adding a space after commas here makes it less readable (to me).

>   1938 W191 indentation contains tabs

That is not intentional. Where do we have tabs? I thought my vimrc automatically fixes that.

>   669 E501 line too long (83 > 79 characters)

The 80 char line rule is a hangover from a long-gone era!

>   266 E302 expected 2 blank lines, found 1

Many classes are just a line or two, and often they're put right next to each other so you can clearly see how they are similar/different. Only classes longer than a about screen should have 2 blank lines.

>   188 E701 multiple statements on one line (colon)

I much prefer this:

```
if a: do_a()
else: do_b()
```

Generally, where the 2 parts of a conditional or try block fit on a line and don't have too much going on, I prefer to have them together.

>   164 E225 missing whitespaces around operator

For each operator it depends on the context. Generally if there aren't spaces around '=' it's probably a mistake. But for math equations I try to lay it out closest to how it looks in a paper. Often that means no spaces around some operators.

>   142 E128 continuation line under-indented for visual indent

Thanks for the example. Replacing 2 lines of code here with 3 means more vertical space is used for no (IMO) good reason, so I'd rather not do that.

>   130 E111 indentation is not a multiple of four

Generally I try to lay things out in a way that maximizes ability to understand the code block with jumping around. I'm sure there are examples where I've done a suboptimal job and am happy to fix them on a case by case basis.

> Here is a corrected version of PEP8 code. I hope it isn't that bad anymore.

It's better, although I still don't like the conditional.

> Let me know which PEP8 checks would you like to disable. Does the list I've suggested make sense?

I can't see any checks here which could be automated without breaking things, except perhaps for the tabs (I'd want to see what was triggering that first though).

Thanks again for your careful analysis!",regular python programmer used pep hard shake especially python follow style extent constant tension like minimize since deeply dislike pep entire culture around lack much python community think tension might hard avoid meant return truly want fix although found thoughtful enough actually work way want nearly language unfortunately create consistent style see code decide correct disable thanks helpful missing intentional nearly every class something like spacing clearly separate space le readable indentation intentional thought automatically line long char line rule era blank found many class line two often put right next clearly see class longer screen blank multiple one line colon much prefer else generally conditional try block fit line much going prefer together missing around operator operator context generally around probably mistake math try lay paper often around continuation line visual indent thanks example code vertical space used good reason rather indentation multiple four generally try lay way ability understand code block around sure done suboptimal job happy fix case case basis corrected version pep code hope bad better although still like conditional let know pep would like disable list make sense ca see could without breaking except perhaps want see first though thanks careful analysis,issue,positive,positive,neutral,neutral,positive,positive
372867328,"If anybody else comes across this, using the `environment-cpu.yaml` works on a Mac. There's instructions in the README.",anybody else come across work mac,issue,negative,neutral,neutral,neutral,neutral,neutral
372838883,"You've got me, the pycharm argument was a good reason, not the true one. Moreover my ""PEP8 example"" had more many blank lines than required by PEP8. (I've posted a corrected version at the end)

The point is that I could see your library being widely adopted I love the idea of an accessible deep learning library that can be used by *regular* programmers, with a sensible set of defaults. But a *regular* python programmer is used to PEP8, and it is hard to shake off, especially when most of the python libraries (including TF & pytorch) follow this style to some extent. So there will be a constant tension, that I'd like to minimize.

The argument about autoformatting was a bad turn, It was just to give you a good rationale to talk about the styles without going into the discussion around personal tastes and adoption. You are right formatting the code automatically won't work and I wasn't even thinking about it.

I meant configuring linters to return warnings that you truly want to fix. When It returns 8k warnings it isn't helpful. If we configure the pep8 linter then we can use it to create a consistent style for the project that can be learned by contributors, it autocorrect the code.

To create a consistent style we can see what types of warnings we have in the code and decide what to correct and which checks to disable:
```
$ pep8 --statistics -qq . | sort -nr
3110    E231 missing whitespace after ','
1938    W191 indentation contains tabs
669     E501 line too long (83 > 79 characters)
619     E261 at least two spaces before inline comment
266     E302 expected 2 blank lines, found 1
188     E701 multiple statements on one line (colon)
164     E225 missing whitespace around operator
142     E128 continuation line under-indented for visual indent
130     E111 indentation is not a multiple of four
55      E301 expected 1 blank line, found 0
54      W293 blank line contains whitespace
22      W391 blank line at end of file
20      E265 block comment should start with '# '
13      W291 trailing whitespace
10      E401 multiple imports on one line
9       E202 whitespace before ']'
8       E114 indentation is not a multiple of four (comment)
6       E266 too many leading '#' for block comment
6       E221 multiple spaces before operator
6       E127 continuation line over-indented for visual indent
5       E201 whitespace after '('
4       E702 multiple statements on one line (semicolon)
4       E402 module level import not at top of file
4       E116 unexpected indentation (comment)
4       E101 indentation contains mixed spaces and tabs
3       W503 line break before binary operator
3       W292 no newline at end of file
3       E303 too many blank lines (2)
3       E272 multiple spaces before keyword
3       E211 whitespace before '['
3       E203 whitespace before ':'
2       E251 unexpected spaces around keyword / parameter equals
2       E122 continuation line missing indentation or outdented
1       E712 comparison to True should be 'if cond is True:' or 'if cond:'
1       E711 comparison to None should be 'if cond is None:'
1       E703 statement ends with a semicolon
1       E502 the backslash is redundant between brackets
1       E271 multiple spaces after keyword
1       E228 missing whitespace around modulo operator
1       E222 multiple spaces after operator
1       E124 closing bracket does not match visual indentation
```

I guess you don't care about the infrequent issues and we can assume that all of the should be corrected. So let's talk  about the most frequrent issues:

> 3110    E231 missing whitespace after ','  

I guess you don't mind having that corrected. For me, it is a sign of clean code so I would love to see it fixed.

> 1938    W191 indentation contains tabs

I bet you had your reasoning for that, and I don't think ppl will care too much about this. Although the reason why PEP recommends spaces is to avoid having it mixed with spaces as this can introduce errors that are hard to notice, especially for newbies.  Correcting this would be a pain so I would keep it. I think there will be another warning if the tabs and spaces are mixed, so this warning can be safely disabled.

> 669     E501 line too long (83 > 79 characters)

I bet no-one cares 4 characters. The only reason to correct this is to be able to enforce the 80c rule in the future.

> 619    E261 at least two spaces before inline comment

That seems to be caused by commented code or the alignment you were talking about. I would turn that warning off.

> 266     E302 expected 2 blank lines, found 1

This is at the end of the classes, I would love that to be corrected. It helps me locate places where a class ends.

> 188     E701 multiple statements on one line (colon)

That is one major readability issue for me, I think it is the second reason after E231 why I started this issue.

> 164     E225 missing whitespaces around operator

I looked at few examples and I guess you are fine to get that corrected. Here they are:
- `*xs,y=args`  should become:
   `*xs, y = args`
- `self.n_emb, self.n_cont=n_emb, n_cont` should become
   `self.n_emb, self.n_cont = n_emb, n_cont`

> 142     E128 continuation line under-indented for visual indent

Here is an example:
```py
    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False, **kwargs):
        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,
            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head)
        return cls(data, models, precompute, **kwargs)
``` 
should become:
```py
    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False, **kwargs):
        models = ConvnetBuilder(
            f, data.c, data.is_multi, data.is_reg,
            ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut, custom_head=custom_head)
        return cls(data, models, precompute, **kwargs)
```
or
```py
    def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, custom_head=None, precompute=False, **kwargs):
        models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg,
                                ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut,
                                custom_head=custom_head)
        return cls(data, models, precompute, **kwargs)
```

> 130     E111 indentation is not a multiple of four

I guess we can have this corrected if it does not destroy vertical alignment.

Here is a corrected version of PEP8 code. I hope it isn't that bad anymore.
```py
def resize(self, targ, new_path):
        """"""Return a copy of ImageData with resized images cached in {self.path}/{new_path}/{targ}/.""""""
        new_ds = []
        dls = [self.trn_dl, self.val_dl, self.fix_dl, self.aug_dl]
        if self.test_dl:
            dls += [self.test_dl, self.test_aug_dl]
        else:
            dls += [None, None]
        t = tqdm_notebook(dls)
        for dl in t:  new_ds.append(self.resized(dl, targ, new_path))
        t.close()
        return self.__class__(new_ds[0].path, new_ds, self.bs, self.num_workers, self.classes)
```

Let me know which PEP8 checks would you like to disable. Does the list I've suggested make sense?",got argument good reason true one moreover pep example many blank pep posted corrected version end point could see library widely adopted love idea accessible deep learning library used regular sensible set regular python programmer used pep hard shake especially python follow style extent constant tension like minimize argument bad turn give good rationale talk without going discussion around personal adoption right code automatically wo work even thinking meant return truly want fix helpful configure pep linter use create consistent style project learned code create consistent style see code decide correct disable pep statistic sort missing indentation line long least two comment blank found multiple one line colon missing around operator continuation line visual indent indentation multiple four blank line found blank line blank line end file block comment start trailing multiple one line indentation multiple four comment many leading block comment multiple operator continuation line visual indent multiple one line semicolon module level import top file unexpected indentation comment indentation mixed line break binary operator end file many blank multiple unexpected around parameter continuation line missing indentation comparison true cond true cond comparison none cond none statement semicolon redundant multiple missing around modulo operator multiple operator bracket match visual indentation guess care infrequent assume corrected let talk missing guess mind corrected sign clean code would love see fixed indentation bet reasoning think care much although reason pep avoid mixed introduce hard notice especially correcting would pain would keep think another warning mixed warning safely disabled line long bet reason correct able enforce rule future least two comment code alignment talking would turn warning blank found end class would love corrected locate class multiple one line colon one major readability issue think second reason issue missing around operator guess fine get corrected become become continuation line visual indent example data return data become data return data data return data indentation multiple four guess corrected destroy vertical alignment corrected version pep code hope bad resize self return copy else none none return let know pep would like disable list make sense,issue,positive,positive,neutral,neutral,positive,positive
372737529,"> I was curious if it would be desirable to spell out docstrings of the sub-classes parameters even if its bears some repetition (**kwargs for example in ConvLearner)?

Yes I think so.

> Would you want each method also to have a doc string?

Yup.

> Is there any documentation you can point me to regarding the parameters these classes are using?

No, but feel free to ask on the forum if there's anything unclear.",curious would desirable spell even repetition example yes think would want method also doc string documentation point regarding class feel free ask forum anything unclear,issue,positive,positive,positive,positive,positive,positive
372736973,"Thanks for letting me know. Would you mind submitting a PR that undoes this change, or fixes it? Also could you provide a link to the forum discussion?",thanks know would mind change also could provide link forum discussion,issue,negative,positive,positive,positive,positive,positive
372736459,"Thanks for the thoughtful discussion! IIRC you can configure pycharm to disable this functionality - with most jetbrains stuff you can do so on a per-project basis, although I can't recall if pycharm allows that or not.

The main thing I note in the change you show is that it uses up a lot more vertical space, which I certainly don't like. Also, I often try to line things up vertically when 2 lines have similar params, which means inserting some extra spaces here and there. I wouldn't want to have a linter remove that manual formatting.

Since I generally prefer to format code based on the semantics and structure of the specific code I'm looking at, rather than based on automatic rules, I'm not sure how well auto-linting will work with this project - at least for formatting. Many of the other issues mentioned in your screenshot look like things I'd be happy to fix, although they'd need to be tested carefully of course.",thanks thoughtful discussion configure disable functionality stuff basis although ca recall main thing note change show lot vertical space certainly like also often try line vertically similar extra would want linter remove manual since generally prefer format code based semantics structure specific code looking rather based automatic sure well work project least many look like happy fix although need tested carefully course,issue,positive,positive,positive,positive,positive,positive
372522704,"@jph00, @gsgbills 

I don't think it is fixed. Let's review
In nlp.py **max_sl** still exists:
m = get_rnn_classifer(**max_sl**, bptt, self.bs, se

In lesson4-imdb.ipynb we are passing a value of 1500 in the 6th cell in section Sentiment which seems to be for max_sl.
What is max_sl??

it seems bptt is sequence length (as in torch)
max_sl would then mean maximum sequence length (i think)
why not set max_sl=bptt?",think fixed let review still se passing value th cell section sentiment sequence length torch would mean maximum sequence length think set,issue,negative,negative,negative,negative,negative,negative
371652885,"Hi Jeremy, I have really enjoyed the class so far. The notebooks are great examples, and having the data right there for testing has been phenomenal. 

I was curious if it would be desirable to spell out docstrings of the sub-classes parameters even if its bears some repetition (**kwargs for example in ConvLearner)? 
Would you want each method also to have a doc string? 
Is there any documentation you can point me to regarding the parameters these classes are using? I was just going to check the imported libraries for this one file as a starting point if not. 
",hi really class far great data right testing phenomenal curious would desirable spell even repetition example would want method also doc string documentation point regarding class going check one file starting point,issue,positive,positive,positive,positive,positive,positive
371279866,"Yeah, tested with a modified lesson2 notebook (obviously with `from_csv`) with google landmark dataset.",yeah tested lesson notebook obviously landmark,issue,negative,neutral,neutral,neutral,neutral,neutral
371276845,@WilliamNurmi - It makes sense.  I presume you tested Lesson Notebooks from Part I after this change and it worked?,sense presume tested lesson part change worked,issue,negative,neutral,neutral,neutral,neutral,neutral
371274505,"It looked to me like only 1's or 0's are ever stored, since these arrays represent the labels as n-hot bit arrays. Please correct me if I'm mistaken.",like ever since represent bit please correct mistaken,issue,negative,neutral,neutral,neutral,neutral,neutral
371273800,That will save space but doesn't that restricts the maximum number that can be stored?,save space maximum number,issue,positive,neutral,neutral,neutral,neutral,neutral
371245376,"Wow, thank you for pointing us to this chrome extension - this is seriously the most useful Chrome extension I've ever seen, and it works wonderfully!
https://chrome.google.com/webstore/detail/sourcegraph-for-github/dgjhfomjieaadpoljlnidmbgkdffpack",wow thank pointing u chrome extension seriously useful chrome extension ever seen work wonderfully,issue,positive,positive,positive,positive,positive,positive
371038419,@coreymason  Oops! i forgot the other environment files. Thanks for fixing them as well :)  ,forgot environment thanks fixing well,issue,positive,positive,positive,positive,positive,positive
371038037,"Whoops, looks like we had the same idea (my PR #198) but you missed a couple of the environment files.",whoop like idea couple environment,issue,negative,neutral,neutral,neutral,neutral,neutral
370982671,"@jph00
I looked over at coord2px. I think there was a problem either with the fish being off the screen or the crop taking place without two of the points. I'm actually surprised coord2px worked before because it just highlighted four points. I tried this strategy before on a different project and ran into problems when I had to do too much interpolation, causing the pixels to disapear. Instead of highlighting one point, I'm highlighting the whole rectangle. I verified it in the test_transforms notebook and it works fine on everything and now gets the crop above correct.

A problem I see with cropping though is this happens sometimes:

![image](https://user-images.githubusercontent.com/2773725/37067244-95b1450e-216e-11e8-93d5-1ad5140d611e.png)

It is a correct crop, but it leaves space on the bottom. If that is the case, then it might make sense to have logic that doesn't add a bounding box if too much (if any) of the bounding box has been removed.",think problem either fish screen crop taking place without two actually worked four tried strategy different project ran much interpolation causing instead one point whole rectangle notebook work fine everything crop correct problem see though sometimes image correct crop leaf space bottom case might make sense logic add bounding box much bounding box removed,issue,negative,positive,positive,positive,positive,positive
370981869,"Thank you for pointing that out.

I looked back and released that i did things like bs = 64/2 

Guess this was causing the issue.",thank pointing back like guess causing issue,issue,positive,neutral,neutral,neutral,neutral,neutral
370974950,"If you try RandomCrop with a target of 800 a few times, there will be times where the bounding box is gone, but it doesn't say the fish is lost. Here is one example:

![image](https://user-images.githubusercontent.com/2773725/37065996-f936962a-2168-11e8-80c8-e3c687e16ce3.png)

So I think there are some weird edge cases where the bounding box becomes incorrect. The same thing happens for CenterCrop at 900.  Everything works fine for dihedral, lighting, and flip I think because the box never gets cut off. But for any other more complicated transformations it will have trouble. 

So I'm think it is a problem wherever the conditional for ""loss my fish"" is.",try target time time bounding box gone say fish lost one example image think weird edge bounding box becomes incorrect thing everything work fine dihedral lighting flip think box never cut complicated trouble think problem wherever conditional loss fish,issue,negative,negative,negative,negative,negative,negative
370932946,"Configure your editor or IDE to display this info and/or jump to the token. That's a computer's job, not a human's :)

If you're just browsing the code online thru github, install the sourcetree chrome extension to get the same functionality (in-project only).",configure editor ide display jump token computer job human browsing code install chrome extension get functionality,issue,negative,neutral,neutral,neutral,neutral,neutral
370931729,"I can't help with MacOS sorry. If anyone knows how to get it working on MacOS, a PR would be welcomed.",ca help sorry anyone get working would,issue,negative,negative,negative,negative,negative,negative
370929736,We'd love PRs! :) Thanks for the offer. What do you need from us to help you get started?,love thanks offer need u help get,issue,positive,positive,positive,positive,positive,positive
370929471,Have you got the latest anaconda? If so: does conda activate not work for you?,got latest anaconda activate work,issue,negative,positive,positive,positive,positive,positive
370927747,I think you should just be able to use fix_dl in this case?,think able use case,issue,negative,positive,positive,positive,positive,positive
370907658,"Can you tell me what you found re bugs in cropping functions for
bounding box? I'm working on this at the moment so it's a high priority
for me! :)
",tell found bounding box working moment high priority,issue,negative,positive,positive,positive,positive,positive
370794711,"Linking a related [forum thread](http://forums.fast.ai/t/kernels-dies-when-using-fastai-library-due-to-cpu-memory-issue/12337). The pool executor change doesn't seem to solve issue for me. 30GB RAM is used up in no time by Kaggle's google landmark dataset.

EDIT: Maybe a slightly different issue since this one was reported to only occur after a few iterations..",linking related forum thread pool executor change seem solve issue ram used time landmark edit maybe slightly different issue since one occur,issue,negative,neutral,neutral,neutral,neutral,neutral
370768861,"Just to let you know, was playing with this on Win7 and ended up with the same problem! Going with y.long() fixes it for the moment.
I'm really hoping I'll be able to use Windows for Part2-2018!",let know win ended problem going moment really able use,issue,negative,positive,positive,positive,positive,positive
370502216,"Hey @iskode, thanks for the feedback!

I should have mentioned this in the PR, but I did a quick search to find any references to the `XY` names before posting. This was the only one I found 😄",hey thanks feedback quick search find posting one found,issue,negative,positive,positive,positive,positive,positive
370452970,"Hi Tommy,
I'm just a fastai student as you but I would suggest you to look across the whole project to update transformation functions as you've just done with [dl1/lesson7-cifar10 notebook ](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson7-cifar10.ipynb). So it'll be one PR to finish up this issue.",hi tommy student would suggest look across whole project update transformation done notebook one finish issue,issue,negative,positive,positive,positive,positive,positive
370244795,"After a little bit of analysis, the OOM error is caused because ThreadPoolExecutor creates all batches and stores them in memory and then returns a generator to fetch the batches from. This behavior has changed from Python 3.5 to 3.6
![executer_map_python3 5](https://user-images.githubusercontent.com/761785/36948098-845f2d6c-1ffb-11e8-918a-4f5bf0f2acb8.png)
![executer_map_python3 6](https://user-images.githubusercontent.com/761785/36948099-848bfbd0-1ffb-11e8-932f-67f930fb7c3a.png)

",little bit analysis error memory generator fetch behavior python,issue,negative,negative,negative,negative,negative,negative
370218859,"I faced the same OOM issue. It's caused by ThreadPoolExecutor in `DataLoader` class defined in fastai/dataloader.py. I am able to run the code after replacing the thread pool by a single execution thread. Here's the diff:
```     def __iter__(self):
-        with ThreadPoolExecutor(max_workers=self.num_workers) as e:
-            for batch in e.map(self.get_batch, iter(self.batch_sampler)):
-                yield get_tensor(batch, self.pin_memory)
+        for batch in map(self.get_batch, iter(self.batch_sampler)):
+            yield get_tensor(batch, self.pin_memory)
```
I tried to set max_workers to 1 too but that didn't work. Understanding where memory is being lost will require more ananlysis.
",faced issue class defined able run code thread pool single execution thread self batch iter yield batch batch map iter yield batch tried set work understanding memory lost require,issue,negative,positive,positive,positive,positive,positive
368355011,"@macsermkiat i'm sorry, but you can elaborate on why `import *` can improve the data science workflow? it severely hinders readability.

for example, suppose you have a file which has many import statements at the top. 

```
from module_a import *
from module_b import *
from module_c import *
from module_d import *
from module_e import *
```

later in the code, a function `some_random_function()` is used but is not defined anywhere in the file. to trace the origins of this function, you would need to go search through each module until you find it. 

compare that with readable import statements:

```
from module_a import some_function
from module_b import another_function
from module_c import some_random_function
...
```

you can quickly figure out where the function was defined. ",sorry elaborate import improve data science severely readability example suppose file many import top import import import import import later code function used defined anywhere file trace function would need go search module find compare readable import import import import quickly figure function defined,issue,negative,positive,positive,positive,positive,positive
368187240,"Ah, apologies, I wasn't thinking beyond using the environment.  Thinking about it a bit more, there's 3 cases I can imagine.

1) They want the most recent source and the whole fast.ai environment:
```
git clone ...
conda env update
```

2) They want the most recent source (updatable via git) in an environment of their choosing:
```
git clone ...
pip install -e .   # equivalent to python setup.py develop
```

3) They want the published package on PyPI:
```
pip install fastai
```

In all 3 cases, the package is installed into python like a normal pip package would.  You can then run python and `import fastai` will work from any folder.  This saves the need to symlink the package directory into each working directory.  The `git clone` approach no longer cares where the source directory is, and you can even `import fastai` in a separate repo.

In the case of approaches 1 & 2, the ""installed"" package is actually a symlink to the code in the cloned repo.  You can run `git pull` and the installed package is instantly updated.  Approach 1 just saves the extra step of typing `pip install -e .` into the CLI if you're creating the full environment.

If the basic approach (`pip install`) seems sound to you, I can update the README detailing the 3 approaches listed above and when they each make sense.",ah thinking beyond environment thinking bit want recent source whole environment git clone update want recent source via git environment choosing git clone pip install equivalent python develop want package pip install package python like normal pip package would run python import work folder need package directory working directory git clone approach longer source directory even import separate case package actually code run git pull package instantly approach extra step pip install full environment basic approach pip install sound update listed make sense,issue,positive,positive,positive,positive,positive,positive
368176794,"Have you update your local fastai with: `git pull`.
Because I ran the same command and it works perfectly.
BTW don't forget to close the issue and it's better to discuss issues in the forum than here.",update local git pull ran command work perfectly forget close issue better discus forum,issue,positive,positive,positive,positive,positive,positive
368175466,"Jeremy plans to make the lib more documented, but he showed some tip to know where a class or function comes from:
`?unknown_function + Enter`
Alternatively you can put the cursor in the first bracket of the function and type ` Alt + Tab` to see the docs.",make tip know class function come enter alternatively put cursor first bracket function type alt tab see,issue,negative,positive,positive,positive,positive,positive
368138940,"This sounds like an interesting idea - could you help me understand it a bit better? Also please check whether it continues to support the existing approaches.

There are two ways we currently support using fastai:

- git clone, then use the notebooks (which have symlinks to fastai)
- pip install fastai

It looks like you've removed the ability to pip install fastai? Or at least you've removed it from the readme for some reason? We need to allow pip installation of the library for a number of reasons, including allowing it to be used in kaggle kernels.

Also you've removed the symlinks, which I think might stop git clone approach from working unless you're using the conda env? We don't want to *require* people to use that env.",like interesting idea could help understand bit better also please check whether support two way currently support git clone use pip install like removed ability pip install least removed reason need allow pip installation library number used also removed think might stop git clone approach working unless want require people use,issue,positive,positive,positive,positive,positive,positive
368137194,Good idea. It actually used to be a param to fit() but seems I removed it some time!...,good idea actually used param fit removed time,issue,positive,positive,positive,positive,positive,positive
368136771,I think this would be best solved by adding a refresh interval option to tqdm.,think would best refresh interval option,issue,positive,positive,positive,positive,positive,positive
368136184,"I'm hoping to add the ability to read in a list-of-lists, so comma is the outermost delim, and space is the inner delim.",add ability read comma outermost space inner,issue,negative,neutral,neutral,neutral,neutral,neutral
368011349,"I was also a bit surprised to see that labels were expected to be space-separated. This broke in a non-obvious way when I was working with a labelled dataset that had spaces in their labels.

I understand that this will break compatibility with existing datasets, but would it make sense to use the column separator for multiple labels as opposed to space separating them? Or at least provide the ability to set a label delimiter?",also bit see broke way working understand break compatibility would make sense use column separator multiple opposed space separating least provide ability set label delimiter,issue,negative,negative,negative,negative,negative,negative
367719690,"I was not aware of the conversation - thank you for pointing me to it.

On one hand I fully understand the argument for making the transforms necessary and this might be the way to go on this. Should clear some of the confusion (leaning towards this solution).

Wanted to say that on the other hand I am tempted by giving users the extra flexibility of just running images straight from a directory, but the more I think about it the less convinced I am that this is the way to go - especially as it might make the code unnecessarily complex.",aware conversation thank pointing one hand fully understand argument making necessary might way go clear confusion leaning towards solution say hand giving extra flexibility running straight directory think le convinced way go especially might make code unnecessarily complex,issue,positive,positive,neutral,neutral,positive,positive
367592411,"I assume you've read the discussion about this at http://forums.fast.ai/t/fastai-dataset-imageclassifierdata-from-paths-without-transformations/9778 ?
This seems like a reasonable requirement to me, since the user will need to specify the size of the images they want.
What behavior would you expect from passing no transform?
This seems to cause quite a bit of confusion, so at the very least we should have parameter checking here to display a better error message",assume read discussion like reasonable requirement since user need specify size want behavior would expect passing transform cause quite bit confusion least parameter display better error message,issue,negative,positive,positive,positive,positive,positive
367521600,"I'm sure I'm not doing something correct.  The environment-cpu.yml does not work for me.  I still receive errors trying to find the NVIDIA driver.

> Traceback (most recent call last):
  File ""run.py"", line 60, in <module>
    checkImage(check_folder + fn)
  File ""run.py"", line 21, in checkImage
    preds = learn.predict_array(im[None])
  File ""/opt/conda/envs/fastai-cpu/lib/python3.6/site-packages/fastai-0.6-py3.6.egg/fastai/learner.py"", line 262, in predict_array
    def predict_array(self, arr): return to_np(self.model(V(T(arr).cuda())))
  File ""/opt/conda/envs/fastai-cpu/lib/python3.6/site-packages/torch/_utils.py"", line 69, in _cuda
    return new_type(self.size()).copy_(self, async)
  File ""/opt/conda/envs/fastai-cpu/lib/python3.6/site-packages/torch/cuda/__init__.py"", line 384, in _lazy_new
    _lazy_init()
  File ""/opt/conda/envs/fastai-cpu/lib/python3.6/site-packages/torch/cuda/__init__.py"", line 141, in _lazy_init
    _check_driver()
  File ""/opt/conda/envs/fastai-cpu/lib/python3.6/site-packages/torch/cuda/__init__.py"", line 62, in _check_driver
    http://www.nvidia.com/Download/index.aspx"""""")
AssertionError:
Found no NVIDIA driver on your system. Please check that you
have an NVIDIA GPU and installed a driver from
http://www.nvidia.com/Download/index.aspx",sure something correct work still receive trying find driver recent call last file line module file line none file line self return file line return self file line file line file line found driver system please check driver,issue,positive,positive,positive,positive,positive,positive
367405657,"Perfect! Thanks. I added code to download annotations to test_transforms. RandomRotateZoom works fine, but it doesn't fit newer tfm system. I can take a peak at it. Shouldn't be too hard to get that working.

And stretch_cv and padding_resize_cv seem to be working fine. I added them as misc tests at the bottom of the notebook.

I think I found some bugs in cropping functions for bounding box though. These don't appear unless the fish has been found under the test run. Might be worth having tests that run transforms many times to uncover errors that happen randomly. Same goes for RandomRotateZoom which has a uniformly selected 4 way conditional.",perfect thanks added code work fine fit system take peak hard get working seem working fine added bottom notebook think found bounding box though appear unless fish found test run might worth run many time uncover happen randomly go uniformly selected way conditional,issue,positive,positive,positive,positive,positive,positive
366787496,"Thanks so much for looking at this. The bounding boxes for fish are discussed in the part1 v1 lesson 7 notebook. Here's the code to download them copied from that notebook:

```
def get_annotations():
    annot_urls = {
        '5458/bet_labels.json': 'bd20591439b650f44b36b72a98d3ce27',
        '5459/shark_labels.json': '94b1b3110ca58ff4788fb659eda7da90',
        '5460/dol_labels.json': '91a25d29a29b7e8b8d7a8770355993de',
        '5461/yft_labels.json': '9ef63caad8f076457d48a21986d81ddc',
        '5462/alb_labels.json': '731c74d347748b5272042f0661dad37c',
        '5463/lag_labels.json': '92d75d9218c3333ac31d74125f2b380a'
    }
    cache_subdir = os.path.abspath(os.path.join(path, 'annos'))
    url_prefix = 'https://kaggle2.blob.core.windows.net/forum-message-attachments/147157/'
    
    if not os.path.exists(cache_subdir):
        os.makedirs(cache_subdir)
    
    for url_suffix, md5_hash in annot_urls.iteritems():
        fname = url_suffix.rsplit('/', 1)[-1]
        get_file(fname, url_prefix + url_suffix, cache_subdir=cache_subdir, md5_hash=md5_hash)
```
",thanks much looking bounding fish part lesson notebook code copied notebook path,issue,negative,positive,positive,positive,positive,positive
366785206,"This format takes up too much vertical space for my liking. For fastai, prefer formatting that allows more to be seen in one screen of text.",format much vertical space liking prefer seen one screen text,issue,negative,positive,positive,positive,positive,positive
366421520,"@jph00 
> I have a strong preference for more to fit in the about of screen space my eye can see at once.

Sure, but in case of notebooks:

- most of rows there contain a single instruction, with a lot of free horizontal space
- valuable vertical space mostly spend for output,  markdown description and comments (with clear variable names you can even omit some of last ones)

>  I've found that the approaches that work best for *me*

- look at programming languages for example, there are a lot of different style agreements. I think it safe to say that clear variable names are good for all, but abbreviations may be just matter of taste 
- you're writing notebooks for, presumably, newbies in ML and don't know a lot of domain language, so you're making their learning curve steeper
",strong preference fit screen space eye see sure case contain single instruction lot free horizontal space valuable vertical space mostly spend output markdown description clear variable even omit last found work best look example lot different style think safe say clear variable good may matter taste writing presumably know lot domain language making learning curve steeper,issue,positive,positive,positive,positive,positive,positive
366408022,"We actually had a discussion about this that was recently closed:
https://github.com/fastai/fastai/issues/86

A fellow student created kind of [a glossary of sorts](https://github.com/reshamas/fastai_deeplearn_part1/blob/master/fastai_dl_terms.md).

I hope this helps.",actually discussion recently closed fellow student kind glossary hope,issue,positive,positive,positive,positive,positive,positive
366296028,Created a PR - not sure if this is the solution we would like to go with but if that would be the case the PR is ready :slightly_smiling_face: ,sure solution would like go would case ready,issue,positive,positive,positive,positive,positive,positive
365885166,"https://github.com/fastai/fastai/issues/88
This issue is similar to this one.
@jph00 has already closed the previous issue.",issue similar one already closed previous issue,issue,negative,negative,neutral,neutral,negative,negative
365563388,"Not really, but maybe using get_ipython().__class__.__name__ == 'ZMQInteractiveShell' would be better, for the time being.
",really maybe would better time,issue,negative,positive,positive,positive,positive,positive
365555505,Thanks for pointing this out! Are you aware of something that works reliably? The SO thread also seems to be somewhat split on what's the best way to do this. ,thanks pointing aware something work reliably thread also somewhat split best way,issue,positive,positive,positive,positive,positive,positive
365438115,I checked the documentation [https://conda.io/docs/user-guide/getting-started.html#managing-environments](url) and it looks like it is split with `activate fastai` (Windows) and `source activate fastai` (Linux and macOS).  I will do a PR based on this for practice.,checked documentation like split activate source activate based practice,issue,negative,neutral,neutral,neutral,neutral,neutral
365434647,"Sorry, I didn't realize it was a python version problem (project uses python3.6).

Either way, after some research, I realized the conda environment pipeline, together with the `environment.yml` file is a better way (than virtualenv + requirements.txt) to define not only packages but python versions too.",sorry realize python version problem project either way research environment pipeline together file better way define python,issue,negative,neutral,neutral,neutral,neutral,neutral
365336296,I believe we are all now meant to use 'conda activate fastai'. Do you want to make that change? ,believe meant use activate want make change,issue,negative,neutral,neutral,neutral,neutral,neutral
365168940,"While it may be 'common' space indenting is more common, including for
`.py` files:
https://medium.com/@hoffa/400-000-github-repositories-1-billion-files-14-terabytes-of-code-spaces-or-tabs-7cfe0b5dd7fd

On Feb 13, 2018 07:21, ""Gokkul Nath TS"" <notifications@github.com> wrote:

> @antorsae <https://github.com/antorsae> Have a look here :
> https://www.quora.com/Why-would-a-coder-use-spaces-over-tabs . Hope the
> answers are convincing enough! :) . Tabs usage is a style convention used
> commonly by python programmers.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/140#issuecomment-365162885>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/ABckysrWK72ZNRk32VJAptPdyAdsnm3Wks5tUSoAgaJpZM4SA321>
> .
>
",may space common wrote look hope convincing enough usage style convention used commonly python reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
365162885,"@antorsae  Have a look here : https://www.quora.com/Why-would-a-coder-use-spaces-over-tabs . Hope the answers are convincing enough! :) .  Tabs usage is a  style convention used commonly by python programmers.
P.S : Please post such generic questions in Fast.ai Forums for faster response. 
~Gokkul",look hope convincing enough usage style convention used commonly python please post generic faster response,issue,positive,positive,neutral,neutral,positive,positive
365135216,"@jph00 Sure! Sorry for the delay. I have looked for usages, and it looks like stretch_cv is called only by RandomRotatateZoom which is only called in planet.py, but not used in any notebooks. I've tested the functions on the sample fish image and it seems to work fine. Next I was going to go into the lesson 2 notebook and see if replacing the get_data with planet.get_data_zoom works just as well.

Ideally, I'd like to include some tests in the test_transforms.ipynb file for consistency, but I haven't found where to download the fish bounding boxes that are used. It looks like the notebook only uses one picture to do transform testing, so I started to make my own test_transform notebook that just uses the image that comes with fastai with my own manual annotation. I could add this to the end of the current test_transforms, but manual bounds for the image collides a bit with the current code which uses I think a json file.

So I'm trying to decide what would be best to add. Maybe unit tests on accuracy on some standard model, maybe dogsvscats? Or add a new notebook that tries to standardize transform testing on the sample image provided? Or if I can find the bounding boxes, I can add add a test for RandomRotateZoom there. (Along with a new padding zoom test.) I like the idea of a new notebook using the sample image, since it makes it faster for anyone to test.

What do you think?",sure sorry delay like used tested sample fish image work fine next going go lesson notebook see work well ideally like include file consistency found fish bounding used like notebook one picture transform testing make notebook image come manual annotation could add end current manual image bit current code think file trying decide would best add maybe unit accuracy standard model maybe add new notebook standardize transform testing sample image provided find bounding add add test along new padding zoom test like idea new notebook sample image since faster anyone test think,issue,positive,positive,positive,positive,positive,positive
365126600,@erikgaas can you let me know whether you think you'll have a chance to check usages of these functions?,let know whether think chance check,issue,negative,neutral,neutral,neutral,neutral,neutral
365126115,"We're moving away from torchtext FYI (see fastai.text for early peek) so generally things will go thru `to_gpu` in the future, which checks that flag IIRC. Thanks for the PR!",moving away see early peek generally go future flag thanks,issue,negative,positive,positive,positive,positive,positive
364911278,Sounds like a good idea. Keeps in general spirit of the fastai approach.,like good idea general spirit approach,issue,positive,positive,positive,positive,positive,positive
363632074,Thanks! Can you check all usages of these functions to ensure they still work OK? ,thanks check ensure still work,issue,positive,positive,positive,positive,positive,positive
363431371,"Made a pull request: https://github.com/fastai/fastai/pull/132
Please, review.",made pull request please review,issue,negative,neutral,neutral,neutral,neutral,neutral
362798384,"I would expect a more normal kind of python at least in the `fastai` package. Being easy to read and understand is more import than making it some lines shorter, the mental model decides how *long* or *difficult* a script is. But it looks like a new language at first glance 😢. 

With `import *` I don't know something comes from which file, or from another package like torch. It's really more difficult to get a quick picture of a file even with IDE. and feels fragile.",would expect normal kind python least package easy read understand import making shorter mental model long difficult script like new language first glance import know something come file another package like torch really difficult get quick picture file even ide fragile,issue,positive,positive,neutral,neutral,positive,positive
362793852,"Jeremy had pointed that out somewhere in the VDO. Import *might be bad generally. But for datascience work, it helps in better workflow.",pointed somewhere import might bad generally work better,issue,negative,negative,neutral,neutral,negative,negative
362052668,"How do you manage to install packages in environment.yaml? I am currently using pipenv, a wrapper around virtualenv. It seems installing packages in `requirements.txt` was not enough. For example `graphviz` is missing in it. Would it be possible for you to update `requirements.txt` file?",manage install currently wrapper around enough example missing would possible update file,issue,negative,negative,neutral,neutral,negative,negative
361696366,"The reason for this is that the model fit function requires a callback class reference and for the attributes of that reference to have been initialized.  While this is normally done for the user in the calling subclass (learner) it is not done in lesson 5 because Jeremy has you building this yourself.  So you have two choices:
1. define you own callback class with the appropriate attributes.
2. Make the changes to the model fit routine to check to see if the callbacks class and attributes are appropriately defined before using them as suggested here [](http://forums.fast.ai/t/lesson-5-in-class-discussion/8408/205)",reason model fit function class reference reference normally done user calling subclass learner done lesson building two define class appropriate make model fit routine check see class appropriately defined,issue,positive,positive,positive,positive,positive,positive
361108459,Ah ok that's a different part of the NB to where I was looking. I'll check it out. BTW I check forums much more often than GH so that's the best place to report issues.,ah different part looking check check much often best place report,issue,positive,positive,positive,positive,positive,positive
361107775,"@jph00 I'm getting:

```
torch.max received an invalid combination of arguments - 
got (numpy.ndarray, dim=int), but expected one of:
 * (torch.FloatTensor source)
[...]
```

If you go to [lesson1.ipynb](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb) and CTRL+F ""accuracy("" you'll see that `probs`, an argument to accuracy, comes from `np.mean`, making it a numpy array.",getting received invalid combination got one source go accuracy see argument accuracy come making array,issue,negative,neutral,neutral,neutral,neutral,neutral
361107139,"@MattKleinsmith it works for me in in the lesson 1 notebook. Are you sure you have `git pull` up to date, and are using the latest version of the notebooks?",work lesson notebook sure git pull date latest version,issue,negative,positive,positive,positive,positive,positive
361107020,"Regression occurs in the lesson1 notebook accuracy calls, too. (On a deadline atm. Will fix if it exists when I'm free.)

https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1.ipynb",regression lesson notebook accuracy deadline fix free,issue,positive,positive,positive,positive,positive,positive
361105430,I recently changed metrics to use pytorch tensors rather than numpy arrays. So it looks like this is an example of a regression. I'll take a look shortly.,recently metric use rather like example regression take look shortly,issue,negative,neutral,neutral,neutral,neutral,neutral
361105369,"There isn't enough info here to replicate or fix the error. Best would be to ask on the forum including information about what you were doing when you got the error, and the details of your environment.",enough replicate fix error best would ask forum information got error environment,issue,negative,positive,positive,positive,positive,positive
361105300,"Let's move the discussion to #115 . We'll need more info about where you're calling the function from to fix this properly, BTW.",let move discussion need calling function fix properly,issue,negative,neutral,neutral,neutral,neutral,neutral
361105133,"That's an early research option which isn't well tested at all. I haven't had any luck getting better results from it. So I'd suggest avoiding it, unless you're interested in being involved in that research (and if the latter, have a search for the issue which added it, so the contributor can be included in the discussion).",early research option well tested luck getting better suggest unless interested involved research latter search issue added contributor included discussion,issue,positive,positive,positive,positive,positive,positive
361098365,It looks to be a problem with fit_gen in learner.py when `use_wd_sched` is set to true because `self.sched` never gets set.  This is my first time looking at this repo so I'm not sure if we should change (A) `self.wd_sched = ...` to `self.sched` or (B) `self.sched` should be set in addition to `self.wd_sched`.,problem set true never set first time looking sure change set addition,issue,negative,positive,positive,positive,positive,positive
361015920,"This is because you are comparing an autograd variable to a tensor.  Here's how I got around this:
```
def accuracy1(preds, targs):
    preds = torch.max(preds, dim=1)[1]
    #print ('preds: {}, {}'.format(preds.shape,type(preds)))
    #print ('targs: {}, {}'.format(targs.shape,type(targs)))
    return (preds==targs.data).float().mean()

```",variable tensor got around accuracy print type print type return,issue,negative,neutral,neutral,neutral,neutral,neutral
360995359,"@kevindewalt 
Might be a cause of a recent change (minor) I made to the 'fit' method. I will look onto it over the weekend. :)",might cause recent change minor made method look onto weekend,issue,negative,negative,neutral,neutral,negative,negative
360988473,"What if we take the wiki and turn it into aliases for the shorthand function calls?

So for example, we would have `batchnorm_freeze()`, which internally simply calls `bn_freeze()`.
The same with longhand versions of shorthand parameters in the method signatures.

That way, @jph00 can keep writing and using the shorthand versions, while there is also a more verbose interface available.",take turn shorthand function example would internally simply longhand shorthand method way keep writing shorthand also verbose interface available,issue,negative,positive,positive,positive,positive,positive
360951971,Yes much better - I was hoping someone might do that! :),yes much better someone might,issue,positive,positive,positive,positive,positive,positive
360951764,"Could you please raise this on the forum, since the crestle dev is there and he can fix it for us?",could please raise forum since dev fix u,issue,negative,neutral,neutral,neutral,neutral,neutral
360951681,"(BTW a pull request for this kind of thing is really helpful. If you haven't done a PR before, check the forum for tips and links to help get started).",pull request kind thing really helpful done check forum link help get,issue,positive,positive,positive,positive,positive,positive
360951517,Should be fixed now. Please re-open if you still see a problem,fixed please still see problem,issue,negative,positive,neutral,neutral,positive,positive
360927777,"**A use case:**

I had three versions of a dataset. The first contained large images, the second contained center crops of size 512, and the third contained center crops of size 256. I fit with the third dataset using standard fastai usage (lesson1), which saved activations to the tmp folder. I then wanted to fit with the second dataset using its precomputed activations. Getting and using these activations required me to enter the following after using set_data:

```python
learn.unfreeze()
learn.save_fc1()
learn.freeze()
learn.precompute = True
```

When I duplicated my dataset to include 128 and 64 versions, I had to use the above block two more times, and then decided to put it in the set_data method as an optional block.
",use case three first large second center size third center size fit third standard usage lesson saved folder fit second getting enter following python true include use block two time decided put method optional block,issue,positive,positive,positive,positive,positive,positive
360866264,"Thanks Jeremy for merging it.

On Jan 26, 2018 10:27 AM, ""Jeremy Howard"" <notifications@github.com> wrote:

Many thanks for the PR and the followup explanation.

—
You are receiving this because you authored the thread.
Reply to this email directly, view it on GitHub
<https://github.com/fastai/fastai/pull/98#issuecomment-360864989>, or mute
the thread
<https://github.com/notifications/unsubscribe-auth/AD6Mdf_k4EOoBJegoybn5iBD1c3nZWxsks5tOhkGgaJpZM4Rlt1d>
.
",thanks wrote many thanks explanation thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
360865870,"Looks like we've got a conflict here. Is the issue now resolved? If not, could you resolve the conflict?",like got conflict issue resolved could resolve conflict,issue,negative,neutral,neutral,neutral,neutral,neutral
360818196,"Can you please merge this @jph00 @racheltho so that anyone can reproduce the example in lesson4-imdb notebook? The existing code breaks with the following error: 

```python

TypeError                                 Traceback (most recent call last)
<ipython-input-20-b2f8cd3a0b3e> in <module>()
      1 learner = md.get_model(opt_fn, em_sz, nh, nl,
----> 2                dropouti=0.05, dropout=0.05, wdrop=0.1, dropoute=0.02, dropouth=0.05)
      3 learner.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)
      4 learner.clip=0.3

~/gandalf/fastai/courses/dl1/fastai/nlp.py in get_model(self, opt_fn, emb_sz, n_hid, n_layers, **kwargs)
    268 
    269         """"""
--> 270         m = get_language_model(self.nt, emb_sz, nhid=n_hid, nlayers=n_layers, pad_idx=self.pad_idx, **kwargs)
    271         model = SingleModel(to_gpu(m))
    272         return RNN_Learner(self, model, opt_fn=opt_fn)

TypeError: get_language_model() got an unexpected keyword argument 'pad_idx'
```

This merge request fixes the exact error that is mentioned above. ",please merge anyone reproduce example notebook code following error python recent call last module learner partial self model return self model got unexpected argument merge request exact error,issue,negative,positive,neutral,neutral,positive,positive
360282184,"Thanks for the advice! I've added a `num_cpus()` function now, which uses `os.cpu_count()` if `os.sched_getaffinity` is unavailable.

Thanks! Glad you like the blog. :)",thanks advice added function unavailable thanks glad like,issue,positive,positive,positive,positive,positive,positive
360175312,"i think it might be better to define a method such as:
```
def get_num_cpus():
   try:
        // use os.sched_getaffinity method to try get cpu count
   except:
       // fall back to 2
  return num_cpu
```

and use this method wherever we desire to get optimal number of cpus. This would help prevent using try/catch at multiple places, as well as make the intention for using '2'  more evident.

Shouldn't take you long at all !! Also big fan of your blogs :)",think might better define method try use method try get count except fall back return use method wherever desire get optimal number would help prevent multiple well make intention evident take long also big fan,issue,positive,positive,positive,positive,positive,positive
359805624,"It should be solved now.

On Mon, Jan 22, 2018 at 3:55 PM, Jeremy Howard <notifications@github.com>
wrote:

> @yanneta <https://github.com/yanneta> is this solved?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/87#issuecomment-359615188>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZfmzdDvTT0n3Hbh7lXufZ9chuw_Gks5tNR_igaJpZM4RZ8Ad>
> .
>
",mon wrote reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
359656789,"Ran into this issue while trying out the kaggle's House Regression Price Prediction Competition
",ran issue trying house regression price prediction competition,issue,negative,neutral,neutral,neutral,neutral,neutral
359629765,"Yeah I think it's the first/last rows that are causing this. It doesn't seem to impact the results, but a PR to fix would certainly be appreciated! :)",yeah think causing seem impact fix would certainly,issue,positive,positive,positive,positive,positive,positive
359629289,I'll close this in the absence of a failing test case - feel free to reopen if you manage to create one.,close absence failing test case feel free reopen manage create one,issue,negative,positive,positive,positive,positive,positive
359612961,"This is discussed at various points in the course. I have a strong preference for more to fit in the about of screen space my eye can see at once. I've found that the approaches that work best for me for data science are not the same as those that work best for general software engineering. Unfortunately, few people have written about effective patterns for data science code - although there's a lot of examples in the APL/J/K world of a more extreme version of what I do.

Anyhoo - the naming is very much intentional and based on a couple of decades of both software engineering and data science experience, so I'll be sticking with it. Every variable name is either a mnemonic (lr->learning rate), or is based on standards from the ML and stats literature (x->independent variables; y->dependent variables). They, hopefully, are consistent throughout the code base. I'm happy to take PRs for any examples of inconsistent naming! :)

Many thanks for the discussion.",various course strong preference fit screen space eye see found work best data science work best general engineering unfortunately people written effective data science code although lot world extreme version naming much intentional based couple engineering data science experience sticking every variable name either mnemonic learning rate based literature independent dependent hopefully consistent throughout code base happy take inconsistent naming many thanks discussion,issue,positive,positive,positive,positive,positive,positive
359611710,Yes it runs but isn't officially supported yet. Will be after pytorch 0.4. There are workarounds on the forums if you want help.,yes officially yet want help,issue,positive,neutral,neutral,neutral,neutral,neutral
359611543,Funnily enough I just noticed that and fixed it. Will push shortly.,funnily enough fixed push shortly,issue,negative,positive,neutral,neutral,positive,positive
358282040,"After more tinkering around, turned out it was more of a PyCharm issue than the library itself, seems to run absolutely fine on Jupyter Notebooks. Closing.",around turned issue library run absolutely fine,issue,negative,positive,positive,positive,positive,positive
357757600,"An easy way to get around this is to add a fake numerical column with
constant value.

On Fri, Jan 12, 2018 at 3:32 PM, Deb <notifications@github.com> wrote:

> Error stack when calling with only categorical features.
>
> ~/favorita/fastai/model.py in fit(model, data, epochs, opt, crit, metrics, callbacks, **kwargs)
>      87             batch_num += 1
>      88             for cb in callbacks: cb.on_batch_begin()
> ---> 89             loss = stepper.step(V(x),V(y))
>      90             avg_loss = avg_loss * avg_mom + loss * (1-avg_mom)
>      91             debias_loss = avg_loss / (1 - avg_mom**batch_num)
>
> ~/favorita/fastai/model.py in step(self, xs, y)
>      38     def step(self, xs, y):
>      39         xtra = []
> ---> 40         output = self.m(*xs)
>      41         if isinstance(output,(tuple,list)): output,*xtra = output
>      42         self.opt.zero_grad()
>
> ~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
>     222         for hook in self._forward_pre_hooks.values():
>     223             hook(self, input)
> --> 224         result = self.forward(*input, **kwargs)
>     225         for hook in self._forward_hooks.values():
>     226             hook_result = hook(self, input, result)
>
> ~/favorita/fastai/column_data.py in forward(self, x_cat, x_cont)
>     104         x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]
>     105         x = torch.cat(x, 1)
> --> 106         x2 = self.bn(x_cont)
>     107         x = self.emb_drop(x)
>     108         x = torch.cat([x, x2], 1)
>
> ~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/module.py in __call__(self, *input, **kwargs)
>     222         for hook in self._forward_pre_hooks.values():
>     223             hook(self, input)
> --> 224         result = self.forward(*input, **kwargs)
>     225         for hook in self._forward_hooks.values():
>     226             hook_result = hook(self, input, result)
>
> ~/anaconda3/lib/python3.6/site-packages/torch/nn/modules/batchnorm.py in forward(self, input)
>      35         return F.batch_norm(
>      36             input, self.running_mean, self.running_var, self.weight, self.bias,
> ---> 37             self.training, self.momentum, self.eps)
>      38
>      39     def __repr__(self):
>
> ~/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py in batch_norm(input, running_mean, running_var, weight, bias, training, momentum, eps)
>     637                training=False, momentum=0.1, eps=1e-5):
>     638     f = torch._C._functions.BatchNorm(running_mean, running_var, training, momentum, eps, torch.backends.cudnn.enabled)
> --> 639     return f(input, weight, bias)
>     640
>     641
>
> RuntimeError: running_mean should contain 1 elements not 0
>
> Error stack when calling with only continuous features.
>
>
> ~/favorita/fastai/column_data.py in forward(self, x_cat, x_cont)
>     103     def forward(self, x_cat, x_cont):
>     104         x = [e(x_cat[:,i]) for i,e in enumerate(self.embs)]
> --> 105         x = torch.cat(x, 1)
>     106         x2 = self.bn(x_cont)
>     107         x = self.emb_drop(x)
>
> RuntimeError: seq can't be empty
>
> ------------------------------
> You can view, comment on, or merge this pull request online at:
>
>   https://github.com/fastai/fastai/pull/90
> Commit Summary
>
>    - to allow categorical only or continuous only dependent features
>
> File Changes
>
>    - *M* fastai/column_data.py
>    <https://github.com/fastai/fastai/pull/90/files#diff-0> (15)
>
> Patch Links:
>
>    - https://github.com/fastai/fastai/pull/90.patch
>    - https://github.com/fastai/fastai/pull/90.diff
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/90>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZWZeEpnoj8Mefdq-r8p4nrpAR5E6ks5tJ-uOgaJpZM4Rc_EM>
> .
>
",easy way get around add fake numerical column constant value deb wrote error stack calling categorical fit model data opt metric loss loss step self step self output output list output output self input hook hook self input result input hook hook self input result forward self enumerate self input hook hook self input result input hook hook self input result forward self input return input self input weight bias training momentum training momentum return input weight bias contain error stack calling continuous forward self forward self enumerate ca empty view comment merge pull request commit summary allow categorical continuous dependent file patch link thread reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
356997528,"Can you check if using

RandomDihedralXY instead of RandomDihedral solves your problem? We have to
fix RandomDihedral.



On Wed, Jan 10, 2018 at 1:00 PM, Irshad Muhammad <notifications@github.com>
wrote:

> transforms_pt = [RandomRotateZoom(9, 0.18, 0.1), RandomLighting(0.05, 0.1), RandomDihedral()]
> tfms=tfms_from_model(f_model, sz, aug_tfms=transforms_pt, pad=sz//12)
>
> val_idx = get_cv_idxs(train_len)
> data = ImageClassifierData.from_csv(path, 'train-jpg', f'{path}train_v2.csv', bs, tfms, suffix='.jpg', val_idxs=val_idx, test_name='test-jpg')
> lr=0.2
> lrs=[lr/9, lr/3, lr]
> learn = ConvLearner.pretrained(f_model, data, metrics=metrics)
>
> learn.fit(lr, 3, cycle_len=1, cycle_mult=2)
>
> Error:
>   0%|          | 0/506 [00:00<?, ?it/s]
> ---------------------------------------------------------------------------
> NameError                                 Traceback (most recent call last)
> <ipython-input-28-a0d195fa61d1> in <module>()
>      11 learn = ConvLearner.pretrained(f_model, data, metrics=metrics)
>      12
> ---> 13 learn.fit(lr, 3, cycle_len=1, cycle_mult=2)
>
> ~/fastai/courses/dl1/fastai/learner.py in fit(self, lrs, n_cycle, wds, **kwargs)
>     211         self.sched = None
>     212         layer_opt = self.get_layer_opt(lrs, wds)
> --> 213         self.fit_gen(self.model, self.data, layer_opt, n_cycle, **kwargs)
>     214
>     215     def warm_up(self, start_lr=1e-5, end_lr=10, wds=None):
>
> ~/fastai/courses/dl1/fastai/learner.py in fit_gen(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, **kwargs)
>     158         n_epoch = sum_geom(cycle_len if cycle_len else 1, cycle_mult, n_cycle)
>     159         fit(model, data, n_epoch, layer_opt.opt, self.crit,
> --> 160             metrics=metrics, callbacks=callbacks, reg_fn=self.reg_fn, clip=self.clip, **kwargs)
>     161
>     162     def get_layer_groups(self): return self.models.get_layer_groups()
>
> ~/fastai/courses/dl1/fastai/model.py in fit(model, data, epochs, opt, crit, metrics, callbacks, **kwargs)
>      84         stepper.reset(True)
>      85         t = tqdm(iter(data.trn_dl), leave=False, total=len(data.trn_dl))
> ---> 86         for (*x,y) in t:
>      87             batch_num += 1
>      88             for cb in callbacks: cb.on_batch_begin()
>
> ~/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py in __iter__(self)
>     951 """""", fp_write=getattr(self.fp, 'write', sys.stderr.write))
>     952
> --> 953             for obj in iterable:
>     954                 yield obj
>     955                 # Update and possibly print the progressbar.
>
> ~/fastai/courses/dl1/fastai/dataset.py in __next__(self)
>     241         if self.i>=len(self.dl): raise StopIteration
>     242         self.i+=1
> --> 243         return next(self.it)
>     244
>     245     @property
>
> ~/fastai/courses/dl1/fastai/dataloader.py in __iter__(self)
>      73     def __iter__(self):
>      74         with ThreadPoolExecutor(max_workers=self.num_workers) as e:
> ---> 75             for batch in e.map(self.get_batch, iter(self.batch_sampler)):
>      76                 yield get_tensor(batch, self.pin_memory)
>      77
>
> ~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/_base.py in result_iterator()
>     584                     # Careful not to keep a reference to the popped future
>     585                     if timeout is None:
> --> 586                         yield fs.pop().result()
>     587                     else:
>     588                         yield fs.pop().result(end_time - time.time())
>
> ~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/_base.py in result(self, timeout)
>     423                 raise CancelledError()
>     424             elif self._state == FINISHED:
> --> 425                 return self.__get_result()
>     426
>     427             self._condition.wait(timeout)
>
> ~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/_base.py in __get_result(self)
>     382     def __get_result(self):
>     383         if self._exception:
> --> 384             raise self._exception
>     385         else:
>     386             return self._result
>
> ~/anaconda3/envs/fastai/lib/python3.6/concurrent/futures/thread.py in run(self)
>      54
>      55         try:
> ---> 56             result = self.fn(*self.args, **self.kwargs)
>      57         except BaseException as exc:
>      58             self.future.set_exception(exc)
>
> ~/fastai/courses/dl1/fastai/dataloader.py in get_batch(self, indices)
>      66
>      67     def get_batch(self, indices):
> ---> 68         res = self.collate_fn([self.dataset[i] for i in indices], self.pad_idx)
>      69         if not self.transpose: return res
>      70         res[0] = res[0].T
>
> ~/fastai/courses/dl1/fastai/dataloader.py in <listcomp>(.0)
>      66
>      67     def get_batch(self, indices):
> ---> 68         res = self.collate_fn([self.dataset[i] for i in indices], self.pad_idx)
>      69         if not self.transpose: return res
>      70         res[0] = res[0].T
>
> ~/fastai/courses/dl1/fastai/dataset.py in __getitem__(self, idx)
>      95     def __getitem__(self, idx):
>      96         x,y = self.get_x(idx),self.get_y(idx)
> ---> 97         return self.get(self.transform, x, y)
>      98
>      99     def __len__(self): return self.n
>
> ~/fastai/courses/dl1/fastai/dataset.py in get(self, tfm, x, y)
>     100
>     101     def get(self, tfm, x, y):
> --> 102         return (x,y) if tfm is None else tfm(x,y)
>     103
>     104     @abstractmethod
>
> ~/fastai/courses/dl1/fastai/transforms.py in __call__(self, im, y)
>     463         if crop_type == CropType.NO: crop_tfm = NoCropXY(sz, tfm_y)
>     464         self.tfms = tfms + [crop_tfm, normalizer, channel_dim]
> --> 465     def __call__(self, im, y=None): return compose(im, y, self.tfms)
>     466
>     467
>
> ~/fastai/courses/dl1/fastai/transforms.py in compose(im, y, fns)
>     444 def compose(im, y, fns):
>     445     for fn in fns:
> --> 446         im, y =fn(im, y)
>     447     return im if y is None else (im, y)
>     448
>
> ~/fastai/courses/dl1/fastai/transforms.py in __call__(self, x, y)
>     134         if choice==0: pass
>     135         elif choice==1: x = rotate_cv(x, rand0(self.deg), self.mode)
> --> 136         elif choice==2: x = zoom_cv(x, random.random()*self.zoom)
>     137         elif choice==3:
>     138             str_choice = random.randint(0,1)
>
> ~/fastai/courses/dl1/fastai/transforms.py in zoom_cv(x, z)
>      17 def zoom_cv(x,z):
>      18     if z==0: return x
> ---> 19     r,c,*_ = im.shape
>      20     M = cv2.getRotationMatrix2D((c/2,r/2),0,z+1.)
>      21     return cv2.warpAffine(x,M,(c,r))
>
> NameError: name 'im' is not defined
>
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/87>, or mute the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZbeGESdpvGH2wvp9lDJZdGnPjDZFks5tJST7gaJpZM4RZ8Ad>
> .
>
",check instead problem fix wed wrote data path path learn data error recent call last module learn data fit self none self self model data metric else fit model data self return fit model data opt metric true iter self iterable yield update possibly print self raise return next property self self batch iter yield batch careful keep reference future none yield else yield result self raise finished return self self raise else return run self try result except self index self index index return self index index return self self return self return get self get self return none else self normalizer self return compose compose compose return none else self pas rand return return name defined thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
356955217,"I can't agree more with @FabianHertwig 

To add to his comment, the best API is the one that is well adapted. The best way to do that is to make it simple for new adapters to get them up and running. The steeper the learning curve is, the worse adaption rate you are going to have. One of the best ways to lower the learning curve is to make the API self-explaining. 

The only benefit of abbreviating having to type fewer characters when writing code. I do not know a programmer that will sacrifice ease of learning a new API for having to type less.

My understanding is that this API is for developers. If that is still true, please make it, so it's easy for developers to learn it.

All API requires some learning, but the best ones are those that take the least time to learn.",ca agree add comment best one well best way make simple new get running steeper learning curve worse adaption rate going one best way lower learning curve make benefit type writing code know programmer sacrifice ease learning new type le understanding still true please make easy learn learning best take least time learn,issue,positive,positive,positive,positive,positive,positive
356915968,"Yeah, that is the point I was trying to make with the observation that ""Jeremy's bs is good bs"". These abbreviations are used so often, and often in concise code of multiple components, it seems to me to be a no-brainer to see how useful it is to use an abbreviation. To look at, to type, and to get familiar with.

Besides, Jeremy clearly warned us at the beginning that his approach might look quite different than accepted practise!",yeah point trying make observation good used often often concise code multiple see useful use abbreviation look type get familiar besides clearly u beginning approach might look quite different accepted,issue,positive,positive,positive,positive,positive,positive
356913735,"I think the short names are better. This is designed for an interactive environment not for an application package. As such the best practices are different.

Interactively you might use learning rate or batch size 100 times in a project as you try multiple alternatives. It is not comparable to an application where you have hundreds of variables used infrequently so longer names make more sense. And these are so core that you cannot seriously forget what lr or bs means unless you are a complete beginner - and you won't be that for long. Personally I am relieved not to have to write ImageDataGenerator().flow_from_directory() multiple times in a notebook.",think short better designed interactive environment application package best different might use learning rate batch size time project try multiple comparable application used infrequently longer make sense core seriously forget unless complete beginner wo long personally relieved write multiple time notebook,issue,positive,positive,positive,positive,positive,positive
356913412,"The goal should be to make the API pythonic and pandorable, not blindly follow any book. [PEP8](https://www.python.org/dev/peps/pep-0008/) starts out by saying ""A Foolish Consistency is the Hobgoblin of Little Minds."" There are abbreviations used in Python and Pandas - so we don't need to be rigid and say ""No abbreviations. Period."" Such refactorings needs to be decided on a case by case basis by the repo owner - naming of things is not something a committee could ever agree upon. 

Coming to the more practical aspect, of refactoring the library vs breaking it, the good thing is that the library is still pre-alpha. It's a good time to make such changes. 

In cases where backward compatibility needs to be maintained, a catch all kwargs parameter can be added to methods where parameters are renamed so it continues working with the older names.


",goal make pythonic blindly follow book pep saying foolish consistency hobgoblin little used python need rigid say period need decided case case basis owner naming something committee could ever agree upon coming practical aspect library breaking good thing library still good time make backward compatibility need catch parameter added working older,issue,positive,positive,positive,positive,positive,positive
356884041,"There is a whole chapter about naming things in the Clean Code book by Robert Martin. In my experience most programmers follow the ideas in that book. So I think we should get rid of all abbreviations. Even `lr` should be named `learning_rate`. If it is important that the most incorrect are selected by recall then `plot_most_confident_incorrect_by_recall` could be the perfect name. It tells you everything you need to know. Otherwise one could name it `plot_incorrect` and hide the details of how the functions works. 

And even you do not have any autocompletion it is important to use good names. Code is read 100 to 1000 times more then it is written. Even by the programmer who wrote the code. This library is starred over 2000 times. So I guess some lines of code are read way over 2000 times. So if you invest a little time in writing good names, you can save a lot of time that is spent reading the code.

The question is, how can we refactor the library to use better names? Should we break the API and just use other names at one point in time?",whole chapter naming clean code book martin experience follow book think get rid even important incorrect selected recall could perfect name everything need know otherwise one could name hide work even important use good code read time written even programmer wrote code library starred time guess code read way time invest little time writing good save lot time spent reading code question library use better break use one point time,issue,positive,positive,positive,positive,positive,positive
356872210,"@rohitgeo Agreed on balance. For example, I use `lr` to mean the learning rate since that is a common abbreviation used in many machine learning APIs. So I wouldn't advocate for writing `learning_rate` there, that would be taking it too far.",agreed balance example use mean learning rate since common abbreviation used many machine learning would advocate writing would taking far,issue,negative,negative,neutral,neutral,negative,negative
356824667,"I think there's a balance between short and long names. `sz` and `lrs` are at one end and `plot_most_confident_incorrect_by_recall` is at the other end - both can be avoided. Thanks to intellisense and auto-completion in the notebook, we don't have to type out everything, so there's not so much motivation to abreviate everything.",think balance short long one end end thanks notebook type everything much motivation everything,issue,positive,positive,neutral,neutral,positive,positive
356788933,"I second the above comment. Each and every-time I've encountered the acronym 'bs', I read it as so many people are used to saying it in their daily lives (cue: and that's not batch_size). Can't stop that wisp of weird feeling that follows shortly!

One way that helps is to immediately write documentation for the method. I sought to write a few as I took the class, but there are certainly places where it could improve.

",second comment acronym read many people used saying daily cue ca stop wisp weird feeling shortly one way immediately write documentation method sought write took class certainly could improve,issue,negative,positive,neutral,neutral,positive,positive
356721854,"Yes!  There's no reason to abbreviate things!

[Shameless self-blog-promotion](https://beehollander.wordpress.com/2016/07/08/the-6-month-bug-and-why-i-will-never-abbreviate-variable-names/).",yes reason abbreviate shameless,issue,negative,neutral,neutral,neutral,neutral,neutral
356712700,"Hmmm, that was interesting to think about - its true that I also wondered about some of the abbreviations, but only once or twice, and then I forgot about it. It does help however, having short names when you are putting statements together on one line... as Jeremy does.

After thinking about them now, I believe that I at least can live with them :) Jeremy's bs is good bs!  ",interesting think true also twice forgot help however short together one line thinking believe least live good,issue,positive,positive,positive,positive,positive,positive
356137997,"I commented out `cuda90` (=> `#cuda90`) in `environment.yml` file and `conda env update` works successfully.
  ",file update work successfully,issue,negative,positive,positive,positive,positive,positive
356057243,I'm going to close this for now (it's been hanging out for a month) and touch on it in a couple of weeks when I get a chance to look into the tensor dimensionality issue with pytorch. ,going close hanging month touch couple get chance look tensor dimensionality issue,issue,negative,neutral,neutral,neutral,neutral,neutral
355692781,"thanks @sogaiu. You are right. This is a bug. I fixed it.

On Fri, Jan 5, 2018 at 8:30 AM, Yannet Interian <yannet@gmail.com> wrote:

> I will.
>
> On Thu, Jan 4, 2018 at 9:31 PM, Jeremy Howard <notifications@github.com>
> wrote:
>
>> @yanneta <https://github.com/yanneta> do you want to look at this?
>>
>> —
>> You are receiving this because you were mentioned.
>> Reply to this email directly, view it on GitHub
>> <https://github.com/fastai/fastai/issues/72#issuecomment-355476450>, or mute
>> the thread
>> <https://github.com/notifications/unsubscribe-auth/AC3CZfNqyW9KZu--pUmUyqPRIM1QCYBWks5tHbO_gaJpZM4RN8GC>
>> .
>>
>
>
",thanks right bug fixed wrote wrote want look reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
355599303,"I will.

On Thu, Jan 4, 2018 at 9:31 PM, Jeremy Howard <notifications@github.com>
wrote:

> @yanneta <https://github.com/yanneta> do you want to look at this?
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/72#issuecomment-355476450>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZfNqyW9KZu--pUmUyqPRIM1QCYBWks5tHbO_gaJpZM4RN8GC>
> .
>
",wrote want look reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
355476384,I'd be happy to accept a PR that replaced shell commands with python x-platform equivalents :),happy accept shell python,issue,positive,positive,positive,positive,positive,positive
355476317,"Yes it could do, I think. I guess give it a go and see if you can come up with a situation where it fails - if you can, a PR to fix would be appreciated! :)",yes could think guess give go see come situation fix would,issue,negative,neutral,neutral,neutral,neutral,neutral
354661005,"Actually I was always under the impression that the test set will atleast won't contain that or will have a method to auto resolve that issues(using imputer like thing) or remove that particular entry..
Thanks.",actually always impression test set wo contain method auto resolve imputer like thing remove particular entry thanks,issue,positive,positive,positive,positive,positive,positive
354648157,"> We might need to look for nan's in test set also?

Yes, NaN could exists in the test set and not in the train set and given the actual code that would cause some issues regarding the resulting dimensions of the 2 sets.
  ",might need look nan test set also yes nan could test set train set given actual code would cause regarding resulting,issue,negative,neutral,neutral,neutral,neutral,neutral
354646653,"We might need to look for nan's in test set also?
",might need look nan test set also,issue,negative,neutral,neutral,neutral,neutral,neutral
354620825,"Yup. That fix wasn't right 

--
Jeremy Howard


On Sun, Dec 31, 2017, at 11:34 AM, Zohaggie wrote:
> Does this undo the change recently put in to fix the way the library
> has worked under Windows?> — You are receiving this because you modified the open/close state.
> Reply to this email directly, view it on GitHub[1], or mute the
> thread[2].> 

Links:

  1. https://github.com/fastai/fastai/pull/75#issuecomment-354620442
  2. https://github.com/notifications/unsubscribe-auth/AAVLd0FHY8xkjtg5cNk53zQiDiCIvaBoks5tF-HEgaJpZM4RP6lP
",fix right sun wrote undo change recently put fix way library worked state reply directly view mute thread link,issue,negative,positive,positive,positive,positive,positive
354620442,Does this undo the change recently put in to fix the way the library has worked under Windows?,undo change recently put fix way library worked,issue,negative,neutral,neutral,neutral,neutral,neutral
354573835,Thanks. Your fixes have resolved the issues. lesson1 runs to expected completion (Windows + CUDA 9.0).,thanks resolved lesson completion,issue,positive,positive,positive,positive,positive,positive
354568268,"I think the .long() solution is a good one - I can't see any reason that this should cause problems on Linux or CPU. I'll try it out.

BTW, I'm well aware of the status of pytorch on Windows - the issue is whether I'm ready to support fastai on Windows :) . I suspect I'll endeavor to support it officially after 0.4 is out and Windows CI is done for pytorch, but where we have simple clear solutions to problems in the meantime I'll include them.",think solution good one ca see reason cause try well aware status issue whether ready support suspect endeavor support officially done simple clear include,issue,positive,positive,positive,positive,positive,positive
354538602,"The maintainer of pytorch for Windows, peterjc123, says ""The Windows PRs are actively merged. The official Windows CI is near to be setup, and the official package is planned for 0.4.0."" at https://github.com/pytorch/pytorch/issues/494#issuecomment-350527200

pytorch 1.3 + CUDA 9.0 for Windows is available and works for me. tensorflow-gpu 1.4 for Windows also works but requires CUDA 8.0, 9.0 is not yet supported. I'm running CUDA 8.0 and CUDA 9.0 side-by-side without issue.",maintainer actively official near setup official package available work also work yet running without issue,issue,negative,positive,positive,positive,positive,positive
354510622,"I've done some research. In python 3, `int` is unlimited [sic] in magnitude on all platforms. numpy has a different set of numeric types which correspond to C sizes. Most are fixed in size but a few differ in size by implementation (e.g. np.intc). The size of a Tensor type is the same on all platforms.

As you've stated, the issue is that the dataset returns a numpy data type (np.intc?) which has implementation dependent sizes. The size can differ according to machine architecture, OS, C compiler, and other factors. You can't make any assumptions about the size of an np.intc. The size could even differ on the same system and same C compiler. Using np.int32 would make for consistent processing across all platforms -- all platforms would raise an error because a LongTensor is expected. LongTensor's are always 64-bits.

There's at least four possible solutions:
1. Have the dataset return np.int64.
2. For places where LongTensor is expected, such as in model.py, force the type to 64-bit. Note that `variable.int64()` isn't an implemented attribute. `variable.long()` is implemented (works for both cpu and gpu) but I'm unsure if it guarantees 64-bit. I'll post this question on stackoverflow.
3. Change the type earlier in the call sequence. This would help a static type checker. It would be more efficient if the variable undergoes multiple type changes.
4. Change the type later in the call sequence, at the point where C is called. Change calls to `torch._C.*` (e.g. `torch._C._nn.nll_loss`) to coerce to the required C data type.

I'll continue working on this issue over the next few days.

http://pytorch-zh.readthedocs.io/en/latest/tensors.html
https://docs.scipy.org/doc/numpy-1.12.0/user/basics.types.html",done research python unlimited sic magnitude different set correspond size fixed size differ size implementation size tensor type stated issue data type implementation dependent size size differ according machine architecture o compiler ca make size size could even differ system compiler would make consistent across would raise error always least four possible return force type note attribute work unsure post question change type call sequence would help static type checker would efficient variable multiple type change type later call sequence point change coerce data type continue working issue next day,issue,negative,positive,neutral,neutral,positive,positive
354460602,Right. So far I'm able to code one-to-one replacements of non-portable shell commands with os functions. The example you gave requires some python code to replace the non-portable shell command. The downside of using shell commands is lack of portability which is problematic for a MOOC audience.,right far able code shell o example gave python code replace shell command downside shell lack portability problematic audience,issue,negative,positive,positive,positive,positive,positive
354394813,I don't know how - which is why I asked the original question :) - I guess I would have to write some Python code to do it...,know original question guess would write python code,issue,negative,positive,positive,positive,positive,positive
354359812,May I answer a question with a question??? How would you perform this operation if shell commands weren't implemented in jupyter?,may answer question question would perform operation shell,issue,negative,neutral,neutral,neutral,neutral,neutral
354342696,"I agree with this comment, but what is the cross-platform version of this? (from the lesson4-IMDB notebook)
!find {TRN} -name '*.txt' | xargs cat | wc -w",agree comment version notebook find cat,issue,negative,neutral,neutral,neutral,neutral,neutral
354306362,I'm wondering why the issue is showing up at all? Seems like it should show up everywhere or nowhere. I'm guessing the difference is in some recent change to pytorch which has not caught up to the Windows version.,wondering issue showing like show everywhere nowhere guessing difference recent change caught version,issue,negative,neutral,neutral,neutral,neutral,neutral
354207672,I think the right fix is to have the dataset return the correct type (np.int32) in the first place. Closing this issue since Windows isn't something I'm ready to officially support just yet. But if you create a fix that works on Linux and Windows with and without CUDA then I'll certainly consider merging it.,think right fix return correct type first place issue since something ready officially support yet create fix work without certainly consider,issue,positive,positive,positive,positive,positive,positive
354207265,"As I mentioned on the forum, it's because of the change to `TTA`. I'm checking in a fix to the notebook now - but it's worth making sure you understand how TTA now works so you know how to fix this kind of issue yourself in the future. Let me know on the forums if you have any questions.",forum change fix notebook worth making sure understand work know fix kind issue future let know,issue,positive,positive,positive,positive,positive,positive
354204935,"The solution you proposed assumes we're on CUDA, which may not be the case. I'll see if I can think of something...",solution may case see think something,issue,negative,neutral,neutral,neutral,neutral,neutral
353806831,@bsalita I went through Forum notes and added (is_test=True) and that did not solve the error.   Not sure what to do next.,went forum added solve error sure next,issue,negative,positive,positive,positive,positive,positive
353718140,Sure thing @jph00! Currently a bit behind on this initiative for other work (NIPS paper challenge being one). But will be taking this up soon... ,sure thing currently bit behind initiative work paper challenge one taking soon,issue,negative,positive,neutral,neutral,positive,positive
353176686,"@jph00 terribly sorry, I didn't see your earlier comment. I must have done something wrong. Sorry for the trouble. Just checked it now again and not sure how I encountered this error.",terribly sorry see comment must done something wrong sorry trouble checked sure error,issue,negative,negative,negative,negative,negative,negative
353164594,I think the issue is your locale - I don't think we should be forcing a decoder here.,think issue locale think forcing,issue,negative,neutral,neutral,neutral,neutral,neutral
350939130,"Sorry, I should have responded earlier... I thought I'd have time to work on this last weekend but didn't. Basically I can simplify the `is_reg` parameter passing by modifying PassThruDataset have the `is_reg` property, eg, inherit `BaseDataset`. I'm not quite as sure how to address the tensor dimension issue with `F.cross_entropy` (which calls logsoftmax, then nllloss -- this appears to be the same as what ConvnetBuilder does when `is_multi` is false) - Intuitively it seems that the forward method in EmbeddingDotBias class needs to return a higher dimensional tensor than what it's currently returning... I'll look at the lesson6-rnn notebook and lesson7-cifar notebooks and see if I can apply a comparable method as the forward methods in those models defined there.",sorry thought time work last weekend basically simplify parameter passing property inherit quite sure address tensor dimension issue false intuitively forward method class need return higher dimensional tensor currently look notebook see apply comparable method forward defined,issue,negative,negative,neutral,neutral,negative,negative
350866061,I'm guessing your PR fixed this? Closing this. Feel free to reopen if needed.,guessing fixed feel free reopen,issue,positive,positive,positive,positive,positive,positive
350865663,"I'm confused - the current counts for both dn161 and dn121 work for me. If you're getting an error, can you show me the details?",confused current work getting error show,issue,negative,negative,negative,negative,negative,negative
350864270,"You can create a folder called 'tmp', or use 'tmp' as the first 3 chars of your filenames.",create folder use first,issue,negative,positive,positive,positive,positive,positive
350796890,"Now, it throws the following error:
<img width=""910"" alt=""screen shot 2017-12-11 at 10 44 04 pm"" src=""https://user-images.githubusercontent.com/5631503/33844737-3b826458-dec7-11e7-9963-5d3dc158363e.png"">
",following error screen shot,issue,negative,neutral,neutral,neutral,neutral,neutral
350616254,"ahh I see! I've worked with sym-links a little, and I'm always a little _effy_ with them.

I figured I don't really need to push a 'experiments' folder, but just add it in .gitignore. From now on, I (or anyone) can always continue to create things in this folder without affecting version control.

So let me know if this sounds better (and less invasive :) ). If not, I'll try to work with sym-links, but do know they always manage to break down somewhere, somehow. I tried a bunch to create sym-links referencing the data via the default path in the fastai notebooks (since my data is always stored at a different root folder), but I gave up cause some line in some library always kept going belly-up!
",see worked little always little figured really need push folder add anyone always continue create folder without affecting version control let know better le invasive try work know always manage break somewhere somehow tried bunch create data via default path since data always different root folder gave cause line library always kept going,issue,positive,positive,neutral,neutral,positive,positive
350613979,"What I mean is that you don't need to have it inside of the library. You
can make a directory outside and make a simlink inside that directory
pointing to the library.

If you are local l am happy to show you how to do it tomorrow.

On Dec 10, 2017 5:30 PM, ""apiltamang"" <notifications@github.com> wrote:

> you got it! Moved it to the root.. and outside of the library :)
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/64#issuecomment-350600852>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZbrgPRdB_X0MeNeamC1Y5IArBp8vks5s_IWYgaJpZM4Q8sta>
> .
>
",mean need inside library make directory outside make inside directory pointing library local happy show tomorrow wrote got root outside library reply directly view mute thread,issue,positive,positive,neutral,neutral,positive,positive
350600852,you got it! Moved it to the root.. and outside of the library :),got root outside library,issue,negative,neutral,neutral,neutral,neutral,neutral
350592231,"What about making a folder outside of the library.

On Dec 10, 2017 3:11 PM, ""apiltamang"" <notifications@github.com> wrote:

Creating an experiments folder which should allow students to create
notebooks and scripts in their local machine, without those content being
version-controlled and pushed to remote.

Reason I think this would be a good idea is because I tend to create a new
notebook and do a bunch of experiments all the time. However, whenever I
want to update my code, I have to throw away those notebooks. Also, when I
create a new branch and want to make code/docs contributions, I have to
again find a way to hide those experimental notebooks from git. I reckon I
wouldn't want to loose my experimental content, and would also rather have
them stay in a centralized folder.

Anyways, let me know if this is okay.. thnx!
------------------------------
You can view, comment on, or merge this pull request online at:

  https://github.com/fastai/fastai/pull/64
Commit Summary

   - add an experimental folder to include your experimental notebooks and
   scripts

File Changes

   - *M* .gitignore <https://github.com/fastai/fastai/pull/64/files#diff-0>
   (2)
   - *A* courses/dl1/experiments/README.md
   <https://github.com/fastai/fastai/pull/64/files#diff-1> (2)

Patch Links:

   - https://github.com/fastai/fastai/pull/64.patch
   - https://github.com/fastai/fastai/pull/64.diff

—
You are receiving this because you are subscribed to this thread.
Reply to this email directly, view it on GitHub
<https://github.com/fastai/fastai/pull/64>, or mute the thread
<https://github.com/notifications/unsubscribe-auth/AC3CZVH5SBpMrAklrb4Fn6gxXHDWLK2Qks5s_GUqgaJpZM4Q8sta>
.
",making folder outside library wrote folder allow create local machine without content remote reason think would good idea tend create new notebook bunch time however whenever want update code throw away also create new branch want make find way hide experimental git reckon would want loose experimental content would also rather stay folder anyways let know view comment merge pull request commit summary add experimental folder include experimental file patch link thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
350036881,"I agree - that's a lot of places! Any thoughts on how to simplify?

And yes, we shouldn't use binary x-entropy here. We need to use softmax not sigmoid, and then categorical cross-entropy. We do use that in ConvLearner for single label multiclass classification, so you should be able to use a similar approach here. That will be a good exercise :) Feel free to ask on the forum if you get stuck.",agree lot simplify yes use binary need use sigmoid categorical use single label classification able use similar approach good exercise feel free ask forum get stuck,issue,positive,positive,positive,positive,positive,positive
349878890,"I had a chance to update the PR. The amount of places where `is_reg` has to be passed around is too high in my opinion, which can be resolved by modifying `PassThruDataset`. A more long winded way to explain it is that in ConvLearner is_reg is determined via `data.test_ds.is_reg`; however, with `CollabFilterDataset` the test_ds is a `PassThruDataset` and thus does not have the `is_reg` property on it, so I've had to pass it around. Modifying the `PassThruDataset` to try to make it inherit `BaseDataset` will resolve this issue, which I don't think will be too crazy.

More pertinently, I was seeing issues with `F.cross_entropy`... it expects a rank 2 or rank 4 tensor - the rank 2 seems obvious to me (it's a probability for each class, across each item in the test dataset), rank 4, not so much. The model in this case spits out a rank 1 tensor. It appears that ConvLearner uses `F.binary_cross_entropy` which works with arbitrary sized input and I was able to have the code run here using that. HOWEVER, in ConvLearner, the model is generating a prediction for each class, whereas the model in this case is only generating a single prediction... In order to appropriately build a classifier here, I believe the model would need to be changed to generate a vector of predictions for each class, is this correct? It's not immediately clear to me how to change the model for this. Any guidance on this would be appreciated and I'm interested to tackle the problem.

Test notebook is here: https://github.com/lrajlich/fastai/blob/CollabFilterLearner-is_reg-notebook/courses/dl1/lesson5-movielens_copy.ipynb",chance update amount around high opinion resolved long winded way explain determined via however thus property pas around try make inherit resolve issue think crazy pertinently seeing rank rank tensor rank obvious probability class across item test rank much model case rank tensor work arbitrary sized input able code run however model generating prediction class whereas model case generating single prediction order appropriately build classifier believe model would need generate vector class correct immediately clear change model guidance would interested tackle problem test notebook,issue,positive,negative,negative,negative,negative,negative
349709568,"Much improved!

BTW one thing that I think is missing still is an understanding of *why* we do these things - currently your docs are focused on ""what"" and not ""why"". It might be nice to mention in the docs a link to the relevant part of the AWD LSTM paper (or whichever paper is appropriate) to show which bit it's implementing. Feel free to ask if you're interested in doing this but aren't sure about something.",much one thing think missing still understanding currently might nice mention link relevant part awd paper whichever paper appropriate show bit feel free ask interested sure something,issue,positive,positive,positive,positive,positive,positive
349708524,Please test this change carefully and show whether it improves the accuracy on each of the lessons that uses it in class.,please test change carefully show whether accuracy class,issue,negative,negative,neutral,neutral,negative,negative
349158571,closing this branch. Opened a new branch with consolidated docs and conflicts resolved.,branch new branch consolidated resolved,issue,negative,positive,positive,positive,positive,positive
349158428,closing this branch. I've opened a new branch where I've consolidated all the docs.,branch new branch consolidated,issue,negative,positive,positive,positive,positive,positive
348848760,"yes, I haven't had a chance to work on it until today, I'm running into some issues which I'm still resolving but I should have something in a day or two. ",yes chance work today running still something day two,issue,positive,neutral,neutral,neutral,neutral,neutral
348813085,"Can you update this according to the feedback on the earlier PR, ensure they are valid docstrings, and fix the conflicts? Thanks a lot! :)",update according feedback ensure valid fix thanks lot,issue,positive,positive,positive,positive,positive,positive
348812945,"Thanks! A few comments:

- Rather than 'Method processes the weights in the wrapped module by essentially deleting them', you can always remove the word 'method' from the start, so it's just 'process the weights in the wrapped module by essentially deleting them'
- LockedDropout is doing variational dropout, so you should document that
- For methods where you're not sure what it's doing, don't add docs to them, but instead ask for help understanding them on the forum. I don't want us to have docs saying ""I don't know what this is""!
- Ditto for even if you're not quite *sure* what's happening in a method - rather than adding a docstring, ask on the forum about it, and then document it after you're confident you understand it clearly",thanks rather wrapped module essentially always remove word start wrapped module essentially variational dropout document sure add instead ask help understanding forum want u saying know ditto even quite sure happening method rather ask forum document confident understand clearly,issue,positive,positive,positive,positive,positive,positive
348691735,"```
def from_data_frame(cls, path, val_idxs, df, **y**, cat_flds, bs, test_df=None):
        ((val_df, trn_df), (val_y, trn_y)) = split_by_idx(val_idxs, df, y)
        return cls.from_data_frames(path, trn_df, val_df, trn_y, val_y, cat_flds, bs, test_df=test_df)
```
Shouldn't we turn that y's value also as float
```
x = ratings.drop(['rating', 'timestamp'],axis=1)
y = ratings['rating']
In [14]:
data = ColumnarModelData.from_data_frame(path, val_idxs, x, y, ['userId', 'movieId'], 64)
```
As we have this line in lesson5 nbs.",path return path turn value also float data path line lesson,issue,negative,neutral,neutral,neutral,neutral,neutral
348283504,"Hi @jph00 here is an update on the weight decaying and regularization.

With a resnet50, I switched off dropout, `unfreeze`ed all layers and added two FC layers to help overfit. First I overfitted with 8/12 epochs, then introduced weight decay for 8/12 epochs. Results are below. 

I could overfit better with Cifat10, somehow.

I also wanted to find out how does Adam and AdamW compare when doing the regularization. I did it on Cifar10 below. AdamW could recover better.

For the loss part during weight decay, I did not see training loss getting any worst than validation loss - but both were going down (almost) uniformly and the accuracy improving.

I have updated the `adamw-sgdw-demo.ipynb` notebook where these were run. 

In the meantime, I am running the other notebooks without enabling weight decay to check for regression. Should be done by tomorrow.

### Cats And Dogs (AdamW)
[![adamw_overfitting_dogscats.png](https://s33.postimg.org/icsuo1m9b/adamw_overfitting_dogscats.png)](https://postimg.org/image/l6w01hoff/)

### Cifar 10 (AdamW)
[![image.png](https://s33.postimg.org/wytimyju7/image.png)](https://postimg.org/image/ran7w2fhn/)

### Cifar 10 (Adam)
[![image.png](https://s33.postimg.org/xbkwt779r/image.png)](https://postimg.org/image/6qidxn4wb/)

",hi update weight regularization switched dropout unfreeze added two help overfit first weight decay could overfit better somehow also find compare regularization could recover better loss part weight decay see training loss getting worst validation loss going almost uniformly accuracy improving notebook run running without weight decay check regression done tomorrow dog,issue,negative,positive,neutral,neutral,positive,positive
347973218,"Yes!

On Wed, Nov 29, 2017 at 9:48 AM, Luke Rajlich <notifications@github.com>
wrote:

> @yanneta <https://github.com/yanneta> sounds good, I assume you mean to
> accept an is_reg parameter similar to https://github.com/fastai/
> fastai/blob/master/fastai/conv_learner.py#L23., which I'll have default
> as true to preserve existing usage. Let me know otherwise. I'll also
> modify the model activation function so that the model will work with
> classes other than just 0 and 1, similarly to ConvLearner.
>
> —
> You are receiving this because you were mentioned.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/49#issuecomment-347940316>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZcUxe7LN48gDuvep5AEz9O2PSw0Vks5s7ZjUgaJpZM4QvQMd>
> .
>
",yes wed luke wrote good assume mean accept parameter similar default true preserve usage let know otherwise also modify model activation function model work class similarly reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
347951034,"I guess start with a model that over-fits, then add more and more weight decay, and you should see the training loss after a few epochs gets worse, and validation gets better. e.g. use a resnet 50 with no dropout on dogs v cats and unfreeze all layers.",guess start model add weight decay see training loss worse validation better use dropout dog unfreeze,issue,negative,positive,neutral,neutral,positive,positive
347940316,"@yanneta sounds good, I assume you mean to accept an `is_reg` parameter similar to https://github.com/fastai/fastai/blob/master/fastai/conv_learner.py#L23., which I'll have default as `true` to preserve existing usage. Let me know otherwise. I'll also modify the model activation function so that the model will work with classes other than just `0` and `1`, similarly to ConvLearner.",good assume mean accept parameter similar default true preserve usage let know otherwise also modify model activation function model work class similarly,issue,positive,positive,positive,positive,positive,positive
347933333,"Sure, @jph00, I will run all the notebooks and report back.

For checking overfitting, I believe the criteria to check would be if validation loss is decreasing hand-in-hand with training loss, right? I will create 4 FC layers of 1024 dim to over-fit the model. Would you suggest something else?",sure run report back believe criterion check would validation loss decreasing training loss right create dim model would suggest something else,issue,negative,positive,positive,positive,positive,positive
347928374,You can look at how this is handled in convolutional networks. We just pass an argument instead of writing a new class.,look handled convolutional pas argument instead writing new class,issue,negative,positive,positive,positive,positive,positive
347896758,"Wow this is genius :) Can you confirm:

- Without this enabled, the existing lessons work as before
- Weight decay with this method is effectively regularizing an over-fitting model
",wow genius confirm without work weight decay method effectively model,issue,positive,positive,positive,positive,positive,positive
347882797,"A note on performance: I tried to compare performance with and without the weight decay. I considered two factors:

a) In `on_batch_begin()`, I needed to make a copy of `param_groups`. This is because we need this in 'on_batch_end()' when the optimizer would have changed the weights already. If we have 5 million parameters, then the size of `param_groups` would be approximately 40MB.

b) In `on_batch_end()`, I am applying the decay, where-in we have a loop. This will loop as many times as the number of layers. This does not add to the complexity of the algorithm (Big O).

Both the operations being vectorized and happening in GPU, I did not find any slowdown in performance. I tested with 4 cycles with multiplier of 2 on resnet152.",note performance tried compare performance without weight decay considered two make copy need would already million size would approximately decay loop loop many time number add complexity algorithm big happening find slowdown performance tested multiplier,issue,positive,positive,neutral,neutral,positive,positive
347829762,"Thanks for your reply!
I will update it with the right docstrings.
+ the updates to plot the most uncertain examples by class. Because now it is displaying the most uncertain examples from all classes.",thanks reply update right plot uncertain class uncertain class,issue,negative,positive,positive,positive,positive,positive
346540352,"This is going to break some things, but I think the LanguageModelData will be better for it.

Updated so that it can be created from text files or dataframes.",going break think better text,issue,negative,positive,positive,positive,positive,positive
346513320,"Just tested my notebook again, works without complaint.",tested notebook work without complaint,issue,negative,negative,negative,negative,negative,negative
346441404,"Your docs aren't quite right. Try running the code and make sure you understand how it works. You'll be able to see the exact return type too.

Basically the idea is: when training, you don't pass in a mapper, but one gets calculated, containing the means and standard deviations of the continuous variables in the training set. Then, for the test set, you pass in that mapper, so that you scale the test set in the same way.",quite right try running code make sure understand work able see exact return type basically idea training pas mapper one calculated standard continuous training set test set pas mapper scale test set way,issue,negative,positive,positive,positive,positive,positive
346405976,I changed the dataloader recently to use ThreadPool instead of ProcessPool. Has that resolved this problem?,recently use instead resolved problem,issue,negative,neutral,neutral,neutral,neutral,neutral
346178199,"@yanneta - Yes, that totally works.  I also updated the pull request.  It's just a change to the Default value for the function.

Testing:
<img width=""699"" alt=""screen shot 2017-11-21 at 2 09 12 pm"" src=""https://user-images.githubusercontent.com/1437573/33099500-e8a5bb60-cec5-11e7-96f5-54e7a76038f3.png"">
",yes totally work also pull request change default value function testing screen shot,issue,positive,neutral,neutral,neutral,neutral,neutral
346171239,What about a default of cv_idx=0 instead. Would that solve the problem?,default instead would solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
345567077,"Thanks for the fix! BTW AddPadding does reflection padding by default, which could change your existing models. You can add a flag to get constant padding again.",thanks fix reflection padding default could change add flag get constant padding,issue,negative,positive,neutral,neutral,positive,positive
345566974,Best to discuss this on the forum. Be sure to share the code you're using to create the model.,best discus forum sure share code create model,issue,positive,positive,positive,positive,positive,positive
345540003,Closing this for now since it's not getting any action. Feel free to create a new PR fixing issues mentioned.,since getting action feel free create new fixing,issue,positive,positive,positive,positive,positive,positive
345483726,"Just git pulled fastai, uninstalled pytorch & reinstalled from source. Still getting `RuntimeError: received 0 items of ancdata`

Will use the workaround in the mean time.

Also this deprecation warning: (running `.TTA(.)`)
```
.../miniconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/container.py:72: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
```",git uninstalled source still getting received use mean time also deprecation warning running implicit dimension choice change call include argument input module input,issue,negative,negative,negative,negative,negative,negative
345467830,"Might be worth trying compiling pytorch from source. I did it yesterday and it was surprisingly easy. Just conda uninstall pytorch before installing your compiled version. That way, we'll know if they've already fixed it.",might worth trying source yesterday surprisingly easy version way know already fixed,issue,positive,positive,positive,positive,positive,positive
345440641,"@apiltamang you don't need to know what metrics might come (and indeed you can't, since the user can write their own!) That's why I suggested ""just write 'val_metrics:' at the end, and then show all metrics in the array there"" - that is, simply join the metrics up into a single string, just like I do now, and don't try to name each one individually. Does that make sense?",need know metric might come indeed ca since user write write end show metric array simply join metric single string like try name one individually make sense,issue,positive,negative,neutral,neutral,negative,negative
345423931,"**Update**: I editted line 67 of conv_learner.py to remove the argument to `nn.LogSoftmax()`

`        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax(1)`

To:

`        final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax()`

And I'm no longer getting the TypeError when initializing the learner. Haven't tested this in actual predictions yet though.

I'm guessing `nn.LogSoftmax()` only takes self as its argument? I'm not familiar enough w/ PyTorch or fastai to know if the `1` had a purpose.

**Edit**: yeah I'm seeing the change from: 
`        final_actn = nn.Sigmoid if self.is_multi else nn.LogSoftmax`
to:
`         final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax(1)`

In the last commit. Hmm. Again, don't know if my change breaks the intended loop yet.

**Final Edit**: yup, back to the `RuntimeError: received 0 items of ancdata`",update line remove argument else else longer getting learner tested actual yet though guessing self argument familiar enough know purpose edit yeah seeing change else else last commit know change intended loop yet final edit back received,issue,negative,positive,neutral,neutral,positive,positive
345422774,"I'm getting a TypeError when trying to initialize a learner on the lesson1-rxt50 notebook now (just git pulled fastai).

Specific error: `TypeError: __init__() takes 1 positional argument but 2 were given`

 Steps to reproduce it:

(NOTE: this assumes data directory is setup as is class default: Notebook_Folder/data/dogscats/...)


```
%reload_ext autoreload
%autoreload 2
%matplotlib inline

from fastai.imports import *

from fastai.transforms import *
from fastai.conv_learner import *
from fastai.model import *
from fastai.dataset import *
from fastai.sgdr import *
from fastai.plots import *

PATH = ""data/dogscats/""
sz = 299
ARCH = resnext50
bs = 8

tfms = tfms_from_model(ARCH, sz, aug_tfms=transforms_side_on, max_zoom=1.1)
data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=6, num_workers=4, test_name='test1')
learn = ConvLearner.pretrained(ARCH, data, ps=0.5, precompute=False)
```

Learner initialization in the last line is what's triggering it. Clearing the tmp/ folder had no effect. If at all useful, below is the error:

```
---------------------------------------------------------------------------
TypeError                                 Traceback (most recent call last)
<ipython-input-1-8882f3608021> in <module>()
     19 tfms = tfms_from_model(ARCH, sz, aug_tfms=transforms_side_on, max_zoom=1.1)
     20 data = ImageClassifierData.from_paths(PATH, tfms=tfms, bs=6, num_workers=4, test_name='test1')
---> 21 learn = ConvLearner.pretrained(ARCH, data, ps=0.5, precompute=False)

~/Kaukasos/FADL1/fastai/conv_learner.py in pretrained(cls, f, data, ps, xtra_fc, xtra_cut, **kwargs)
     91     @classmethod
     92     def pretrained(cls, f, data, ps=None, xtra_fc=None, xtra_cut=0, **kwargs):
---> 93         models = ConvnetBuilder(f, data.c, data.is_multi, data.is_reg, ps=ps, xtra_fc=xtra_fc, xtra_cut=xtra_cut)
     94         return cls(data, models, **kwargs)
     95 

~/Kaukasos/FADL1/fastai/conv_learner.py in __init__(self, f, c, is_multi, is_reg, ps, xtra_fc, xtra_cut)
     43         if not isinstance(self.ps, list): self.ps = [self.ps]*n_fc
     44 
---> 45         fc_layers = self.get_fc_layers()
     46         self.n_fc = len(fc_layers)
     47         self.fc_model = to_gpu(nn.Sequential(*fc_layers))

~/Kaukasos/FADL1/fastai/conv_learner.py in get_fc_layers(self)
     65             res += self.create_fc_layer(ni, nf, p=self.ps[i], actn=nn.ReLU())
     66             ni=nf
---> 67         final_actn = nn.Sigmoid() if self.is_multi else nn.LogSoftmax(1)
     68         if self.is_reg: final_actn = None
     69         res += self.create_fc_layer(ni, self.c, p=self.ps[-1], actn=final_actn)

TypeError: __init__() takes 1 positional argument but 2 were given
```
",getting trying initialize learner notebook git specific error positional argument given reproduce note data directory setup class default import import import import import import import path arch arch data path learn arch data learner last line clearing folder effect useful error recent call last module arch data path learn arch data data data return data self list self ni else none ni positional argument given,issue,negative,positive,neutral,neutral,positive,positive
345418211,"I pulled the change and still fails for 61,191 images, but runs fine for 40,669. 

The one difference I noticed was that once the error occurs, it does not release the open file descriptors - requiring kernel restart to do anything on that notebook.

Current: https://github.com/hiromis/fastai-workspace/blob/master/Lesson2-Broken-Part2.ipynb
Before: https://github.com/hiromis/fastai-workspace/blob/master/Lesson2-Broken.ipynb
",change still fine one difference error release open file kernel restart anything notebook current,issue,negative,positive,positive,positive,positive,positive
345412558,I just changed the predictions so they're calculated with a loop rather than a list comprehension. Can you let me know if that fixes the problem?,calculated loop rather list comprehension let know problem,issue,negative,neutral,neutral,neutral,neutral,neutral
345402288,@sampathweb Makes sense to test it by chunk and a warning to increase limit. ,sense test chunk warning increase limit,issue,negative,neutral,neutral,neutral,neutral,neutral
345318365,"> Is it only in learn.predict() that this is happening?

I just triggered this bug by calling `.TTA()` on a test set:
`log_preds = learn.TTA(is_test=True)`

update: @hiromis workaround worked -- had to up ulimit to 4096 (2048 still caused Runtime Error).

This was running the [lesson1-rxt-50.ipynb](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson1-rxt50.ipynb) notebook -- running `learn.TTA(is_test = True)` after loading weights saved in the line `learn.save('224_all_50')`",happening triggered bug calling test set update worked still error running notebook running true loading saved line,issue,negative,positive,positive,positive,positive,positive
345305018,"I think I found an even nicer way to do this - in Learner we access `self.model.models` instead of `self.model`:
```
def summary(self): return model_summary(self.models.model, [3,self.data.sz,self.data.sz])
```
",think found even way learner access instead summary self return,issue,negative,neutral,neutral,neutral,neutral,neutral
345298799,"@pani6me - I would then Test in Chunks.  Pass through 10K Files or smaller number of files through test.  You will hit memory limitations before `ulimit` alone becomes a problem.  So I would not worry about it.  In most applications, you can chunk (pass in smaller batches) the data that goes through to resolve this.",would test pas smaller number test hit memory alone becomes problem would worry chunk pas smaller data go resolve,issue,negative,neutral,neutral,neutral,neutral,neutral
345291356,Filer resource limits will be there. If we had 1 million files to process and the prediction goes fast then increasing the ulimit probably won't help. How about we check number of open files of PID against the ulimit and wait if the open_fds < X%ulimit ? ,filer resource million process prediction go fast increasing probably wo help check number open wait,issue,negative,positive,neutral,neutral,positive,positive
345203722,"Yes, this is much nicer :smile: I'll take a look at this later in the day when I get a chance and will push a new version.",yes much smile take look later day get chance push new version,issue,positive,positive,positive,positive,positive,positive
345163032,"Thank you guys for finding a work-around to the issue.  Very much appreciated.  I ran into the issue again tonight and the three lines from @hiromis fixed the error for me.  It definitely seems like it's a pytorch issue underlying, so I don't know if they know of that work-around or not, but It seems like a leak of some sort and I'm glad you were all able to recreate it.  

```
#Code from Hiromis above
import resource
rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)
resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))
```",thank finding issue much ran issue tonight three fixed error definitely like issue underlying know know like leak sort glad able recreate code import resource,issue,positive,positive,positive,positive,positive,positive
345142297,"It was actually 60k images that caused the issue - 40k ran fine.

I stared at [`DataLoaderIter.__next__`](https://github.com/pytorch/pytorch/blob/master/torch/utils/data/dataloader.py#L185) function for a little while. It has a statement `if self.num_workers == 0: ` that will result in a different path, and considering some people changing `num_workers` to zero to avoid the issue makes me think the issue is in the `else` portion of that code.

Do you guys think`validate` (fastai model.py line 98ish) could run into the same issue since it uses `iter(dl)` if we ever had ....however unlikely... 60k images for validation? Or would the list comprehension in `predict_with_targs` make some differences? 

validate:
```
    for (*x,y) in iter(dl):
        preds,l = stepper.evaluate(VV(x), VV(y))
        loss.append(to_np(l))
        res.append([f(to_np(preds),to_np(y)) for f in metrics])
```

predict_with_targs:

`preda,targa = zip(*[(get_prediction(m(*VV(x))),y) for *x,y in iter(dl)])`

",actually issue ran fine function little statement result different path considering people zero avoid issue think issue else portion code think validate line could run issue since iter ever however unlikely validation would list comprehension make validate iter metric zip iter,issue,positive,negative,neutral,neutral,negative,negative
345128794,"Yeah..it's coming from pytorch's forked multiprocessing code.  I have no idea.  I am hoping the core-devs in Pytorch can figure it out.  I posted our workaround in the pytorch's github issue linked to this.

The issue is not `learn.predict`, but more so Reading ALL the Data in parallel.  When doing Training, we are only reading one mini-batch at a Time.  So we don't read ALL the data.  But when doing `TTA`, we are reading ALL the data (from disk - which's slow) in very quick intervals, since the GPUs don't take that much time doing just the forward pass.  So, there's increased demand on input Data Loaders to give more data quickly, causing the explosion of file descriptors.  This is not an issue in Training since the training process gives Data Loader breather time while it does its back prop.  Also, explains that when @hiromis had 4K images TTA was fine, but broke when she had 6K images in the test folder.

Just my understanding of why this problem occurs only during the prediction step and not in training.",yeah coming forked code idea figure posted issue linked issue reading data parallel training reading one time read data reading data disk slow quick since take much time forward pas demand input data give data quickly causing explosion file issue training since training process data loader breather time back prop also fine broke test folder understanding problem prediction step training,issue,negative,positive,positive,positive,positive,positive
345128105,"> figure out why so many FDs are being used

That would definitely be better. My tracing skill with python is limited but I shall give it a try. ",figure many used would definitely better tracing skill python limited shall give try,issue,positive,positive,positive,positive,positive,positive
345121079,"How about simply:

```
precompute = self.precompute
precompute = False
res = model_summary(......)
self.precompute = precompute
```

...since it seems unlikely you really want to view just the FC layers summary anyway.",simply false since unlikely really want view summary anyway,issue,negative,negative,negative,negative,negative,negative
345120618,"Better still would be to figure out *why* so many FDs are being used. It sounds like some code isn't closing file handles when it should be. 

Is it only in learn.predict() that this is happening?",better still would figure many used like code file happening,issue,positive,positive,positive,positive,positive,positive
345113606,"Cool.  Glad that it helped.  I like the idea of **warning if ulimit is low**.  I would not recommend adding the `ulimit` setting into fast.ai code.  `ulimit` affects all applications on the system, so we should avoid changing it automatically inside the library code.

Two suggestions that come to mind  -
1. Add to Readme of fast.ai on Installation / known issues and reference this github issue
2. Add `try` and `catch` exception in `TTA` and print the `ulimit` increase suggestion.

",cool glad like idea warning low would recommend setting code system avoid automatically inside library code two come mind add installation known reference issue add try catch exception print increase suggestion,issue,positive,positive,positive,positive,positive,positive
345091054,"@sampathweb It works from Terminal 👍 

I also got it to work from jupyter notebook using python:

<img width=""810"" alt=""screen shot 2017-11-17 at 7 50 59 am"" src=""https://user-images.githubusercontent.com/5401333/32920302-1ce5956a-cb6c-11e7-9943-cd2b4e2b7dc0.png"">

So maybe we can check the `ulimit -n` value somewhere in the fastai library and up it a bit if it's considered not enough. Or if that's too invasive, we can display a warning. What does everybody think?


Putting the actual code for copying and pasting:
```
import resource
rlimit = resource.getrlimit(resource.RLIMIT_NOFILE)
resource.setrlimit(resource.RLIMIT_NOFILE, (2048, rlimit[1]))
```",work terminal also got work notebook python screen shot maybe check value somewhere library bit considered enough invasive display warning everybody think actual code pasting import resource,issue,negative,neutral,neutral,neutral,neutral,neutral
345083704,Thank you @sampathweb . Ran into the same issue in paperspace. Increased the limit (to 4096) from command-line worked (from within Jupyter Notebook didn't work.)  ,thank ran issue limit worked within notebook work,issue,negative,neutral,neutral,neutral,neutral,neutral
345082159,@hiromis Try it from your Terminal before launching Jupyter notebook.  Let us know if that works.  Looks like it worked for one person who had similar error - http://forums.fast.ai/t/runtime-error-while-running-prediction-on-planet-dataset/7944/3,try terminal notebook let u know work like worked one person similar error,issue,negative,neutral,neutral,neutral,neutral,neutral
345072315,"@sampathweb, thank you so much for solving the mystery for me!! 

This is what it looks like if I run the shell command from jupyter notebok:
<img width=""347"" alt=""screen shot 2017-11-17 at 6 34 13 am"" src=""https://user-images.githubusercontent.com/5401333/32917084-60b36f0c-cb61-11e7-88cd-f14a41fb8d44.png"">

And I think I know what's going wrong because in the past, I tried setting an environment variable from jupyter notebook using `!` and the change did not take. It seems as though each command you execute via `!` is backed by different session. I was able to set an environment in a ""Pythony"" way instead, so maybe we can do something similar here .

I will look into how we can do this in python.

Thanks once again!!

 ",thank much mystery like run shell command screen shot think know going wrong past tried setting environment variable notebook change take though command execute via backed different session able set environment way instead maybe something similar look python thanks,issue,positive,positive,neutral,neutral,positive,positive
345008380,"@jph00 - Once it's confirmed that it works, I would suggest you just give us a script or command to increase `ulimit`.  Lots of them out there online, so I am hesitant to suggest.  Giving a new AMI doesn't help most of us that are actively using the machines and have local notebooks.  Might be useful to create one towards the end of the course for the future MOOC participants..",confirmed work would suggest give u script command increase lot hesitant suggest giving new ami help u actively local might useful create one towards end course future,issue,positive,positive,positive,positive,positive,positive
345000819,Good sleuthing team! Sounds like I may have to rebuild the AMIs. What a pain :(,good team like may rebuild pain,issue,negative,positive,positive,positive,positive,positive
344992474,"For reference, in my Docker container that was based on `nvidia/cuda:8.0-cudnn6-devel-ubuntu16.04`, the `ulimit -n` is 1048576.  That may be why I don't see this problem.  Hopefully increasing the ulimit resolves it for you.  

Lots of posts online on how to change ulimit on your system.  If this works, someone can check with a devops person post what's the best way to set it on startup.",reference docker container based may see problem hopefully increasing lot change system work someone check person post best way set,issue,positive,positive,positive,positive,positive,positive
344954983,"I was able to reproduce the problem in a New AWS EC2 instance I spun up and reproduced the steps from @hiromis.  

The problem is it's hitting the number of open file descriptors (fds).  It's set to a limit of 1024 by default.  I increased it to 2048 and it resolved the issue.  Can you try and let me know?

<img width=""329"" alt=""screen shot 2017-11-16 at 7 17 55 am"" src=""https://user-images.githubusercontent.com/1437573/32898963-7ecd2d5c-ca9e-11e7-9202-57450ca6268c.png"">

You can do in Jupyter Notebook or do it in the Terminal (Before launching Jupyter).  Please note that setting is only for that terminal session (which is good for now - you are not changing any global setting for the system)

We can change the default, and usually done when we want more fds (in Socket programming).  Let me know if this works and we can change the default.",able reproduce problem new instance spun problem number open file set limit default resolved issue try let know screen shot notebook terminal please note setting terminal session good global setting system change default usually done want socket let know work change default,issue,negative,positive,positive,positive,positive,positive
344815025,"Thanks, @apiltamang! 

I probably should have tried removing the data first before resorting to a new AWS instance 😅 But I guess hindsight is 50/50.

I tried running TTA on images in test-jpg-additional.tar.7z without changing num_workers, and that also ran fine. So we could just combine the predictions after running them separately. ",thanks probably tried removing data first new instance guess hindsight tried running without also ran fine could combine running separately,issue,negative,positive,positive,positive,positive,positive
344804488,"@hiromis Glad you could reproduce it!

I suppose one could train all they want, then save it to a file, and later reinstantiate a model/data with 0 num_workers, then apply it for the training. I see that as the only side-step for the moment. Good luck!",glad could reproduce suppose one could train want save file later apply training see moment good luck,issue,positive,positive,positive,positive,positive,positive
344803665,"@apiltamang I don't think the proposition is crazy at all.

https://github.com/hiromis/fastai-workspace/blob/master/Lesson2-Broken.ipynb

So, it's the data. That, we know.
",think proposition crazy data know,issue,negative,negative,negative,negative,negative,negative
344802362,"another update:

if you use num_workers=0 while instantiating the 'ImageClassifierData.from_csv(...)' method, then the exception won't be thrown.

It'll take about 15 min. though to finish getting predictions. So likely not a good soln.",another update use method exception wo thrown take min though finish getting likely good,issue,negative,positive,positive,positive,positive,positive
344799391,"I have a crazy proposition...
Started seeing this once I moved the pictures from test-jpg-additional into the test-jpg folder. Initially there'd be 40,669 images, for which learn.TTA(is_test=True) works fine. As soon as i copied the extra ~20,000 images into the test.jpg folder, the system goes kaboom!

Can you try removing all those additional images? Simply cd into test-jpg, and run ""rm file_*.jpg"". This ought to remove the additional images. Doing that helped me avoid the above exception.

Of course that doesn't mean I can make any submissions :( !",crazy proposition seeing folder initially work fine soon copied extra folder system go try removing additional simply run ought remove additional avoid exception course mean make,issue,negative,negative,neutral,neutral,negative,negative
344795382,"On a brand new AWS instance with fastai-part1v2-p2 (ami-8c4288f4), the Lesson2-Copy1.ipynb still gives the same error. I downloaded the planet directly from Kaggle rather than copying from the old instance.

The next step seems to be deleting the additional test data since that was the beginning of this all.",brand new instance still error planet directly rather old instance next step additional test data since beginning,issue,negative,positive,neutral,neutral,positive,positive
344778891,Creating a new AWS instance sounds like the best next step - let us know if that resolves it.,new instance like best next step let u know,issue,positive,positive,positive,positive,positive,positive
344767959,"I am encountering the same issue here. Here is the sequence of the event that led to the issue:
1. I made a submission file for the Planet competition. At this point, there was no error when running `learn.TTA(is_test=True)`
2. Noticed that I did not add images from test-jpg-additional.tar.7z
3. Added additional test images to test-jpg folder. 
4. Recreated the model with a new ImageClassifierData and loaded the saved weights
5. `learn.TTA(is_test=True)` failed so deleted /tmp. 

Here are things I have tried:
- Deleted /tmp folder
- Verified that `precompute` is not set to True
- Restarted kernel, jupyter notebook, AWS (also removed /tmp folder before running)
- Created a simpler version of the notebook I am having an issue with and still get the same error https://github.com/hiromis/fastai-workspace/blob/master/Lesson2-Copy1.ipynb

None of the above made any difference. `learn.TTA()` (the validation TTA) runs with no issues in the original notebook.

I am starting to consider http://wiki.fast.ai/index.php/Starting_Over_with_AWS and try out the new AMI for this class as I have a feeling that it is a issue in the environment rather than data or code... 
",issue sequence event led issue made submission file planet competition point error running add added additional test folder model new loaded saved tried folder set true kernel notebook also removed folder running simpler version notebook issue still get error none made difference validation original notebook starting consider try new ami class feeling issue environment rather data code,issue,negative,positive,positive,positive,positive,positive
344449191,Can we display it as a header instead on every line? that way it does not waste space on the row and it pulls the headers from the metrics array?,display header instead every line way waste space row metric array,issue,negative,negative,negative,negative,negative,negative
344109511,"@jph00 
I can do a basic rewrite.. no problem.
As for the metrics, unfortunately, I'm not aware of all the metrics that can come by. So, definitely blindsided a bit. If it can be merged for now, I'll continue to test as I learn more of the possible metrics.

Anyways let me know.. it's not a big deal. If you'd rather close it, I'm fine.",basic rewrite problem metric unfortunately aware metric come definitely bit continue test learn possible metric anyways let know big deal rather close fine,issue,negative,positive,positive,positive,positive,positive
344098534,It might also be a problem with your `tmp` folder.,might also problem folder,issue,negative,neutral,neutral,neutral,neutral,neutral
344017202,I'll let you know when I get off work. I set precompute to false and that seems to have fixed the issue for me. I'll see if I can still recreate the issue after a reboot tonight. ,let know get work set false fixed issue see still recreate issue tonight,issue,negative,negative,negative,negative,negative,negative
343763640,"You are right.  Different architectures don't make new folder but they make
new files.

On Sun, Nov 12, 2017 at 10:43 AM, Kevin Bird <notifications@github.com>
wrote:

> Can you elaborate on that? Doesn't each model generate its own folder in
> the tmp directory and it really shouldn't matter when you change between
> two separate architectures? Is that what you mean by different networks?
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/23#issuecomment-343757822>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZfQV5mkkLllTPr4Pt1fcLVlu7MHpks5s1zxcgaJpZM4Qax2T>
> .
>
",right different make new folder make new sun bird wrote elaborate model generate folder directory really matter change two separate mean different reply directly view mute thread,issue,negative,positive,positive,positive,positive,positive
343757822,Can you elaborate on that?  Doesn't each model generate its own folder in the tmp directory and it really shouldn't matter when you change between two separate architectures?  Is that what you mean by different networks?,elaborate model generate folder directory really matter change two separate mean different,issue,negative,positive,neutral,neutral,positive,positive
343755228,Thanks especially for the pics to show us it working and its performance!,thanks especially show u working performance,issue,negative,positive,neutral,neutral,positive,positive
343753683,"One thing is that if you are using different networks you have to delete
the tmp file in between runs.

On Sun, Nov 12, 2017 at 9:04 AM, Kevin Bird <notifications@github.com>
wrote:

> Are you wanting me to post them independently or are you asking?
>
> I tried doing dn121 by itself and got the same error.
>
> I am trying to do it with precompute=False now which I think will be a
> work-around just slower.
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/23#issuecomment-343751427>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZVoR_Mp5siMeQFnfX_XWi5ZmiNvhks5s1yUugaJpZM4Qax2T>
> .
>
",one thing different delete file sun bird wrote wanting post independently tried got error trying think reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
343751427,"Are you wanting me to post them independently or are you asking?

I tried doing dn121 by itself and got the same error.  

I am trying to do it with `precompute=False` now which I think will be a work-around just slower.  ",wanting post independently tried got error trying think,issue,negative,neutral,neutral,neutral,neutral,neutral
343751296,"Can you ran each of them independently?

On Sun, Nov 12, 2017 at 8:23 AM, Kevin Bird <notifications@github.com>
wrote:

> arch=[dn161,dn169,dn201]
> tfms = []
> data = []
> learn = []
>
> for i in range(len(arch)):
>     tfms.append(tfms_from_model(arch[i], sz, aug_tfms=transforms_side_on, max_zoom=1.15))
>     data.append(ImageClassifierData.from_paths(path, tfms=tfms[i], test_name=""test"", bs=bs))
>     learn.append(ConvLearner.pretrained(arch[i],data[i], precompute=True))
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/issues/23#issuecomment-343748592>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZb-tVNDqXOfNxnweLNZGs0LscdFyks5s1xtygaJpZM4Qax2T>
> .
>
",ran independently sun bird wrote data learn range arch arch path test arch data reply directly view mute thread,issue,negative,positive,neutral,neutral,positive,positive
343748592,"```
arch=[dn161,dn169,dn201]
tfms = []
data = []
learn = []

for i in range(len(arch)):
    tfms.append(tfms_from_model(arch[i], sz, aug_tfms=transforms_side_on, max_zoom=1.15))
    data.append(ImageClassifierData.from_paths(path, tfms=tfms[i], test_name=""test"", bs=bs))
    learn.append(ConvLearner.pretrained(arch[i],data[i], precompute=True))
```",data learn range arch arch path test arch data,issue,negative,neutral,neutral,neutral,neutral,neutral
343746754,"Can you please also share how you define the data and learner.
Thanks!",please also share define data learner thanks,issue,positive,positive,positive,positive,positive,positive
343698241,Thanks - that's helpful! Feel to to fix any other places you see this,thanks helpful feel fix see,issue,positive,positive,positive,positive,positive,positive
343330527,"Yes.

On Thu, Nov 9, 2017 at 3:15 PM, ohmeow <notifications@github.com> wrote:

> Sure. Just to make sure I'm clear on this ...
>
> If a list is passed in, it will apply the learning rates to learner's
> respective groups? learn.sched.plot() will display the results for the LAST
> learning rate in the list?
>
> —
> You are receiving this because you commented.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/16#issuecomment-343323329>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZUyrMdyVxgD57TPQHCQvRlUG6P_Nks5s04eSgaJpZM4QWzGB>
> .
>
",yes wrote sure make sure clear list apply learning respective display last learning rate list reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
343323329,"Sure.  Just to make sure I'm clear on this ... 

If a list is passed in, it will apply the learning rates to learner's respective groups?  learn.sched.plot() will display the results for the LAST learning rate in the list?

",sure make sure clear list apply learning learner respective display last learning rate list,issue,positive,positive,positive,positive,positive,positive
343277202,"ohmeow,
Thanks for helping with this. Note that lr_find can also take a list of learning rates. Could you please document that as well.
Thanks,
Yannet",thanks helping note also take list learning could please document well thanks,issue,positive,positive,positive,positive,positive,positive
343277132,"Had some rebase conflicts here. Hastily closed the PR, and couldn't reopen it. So, a new one at #19 ",rebase hastily closed could reopen new one,issue,negative,positive,neutral,neutral,positive,positive
342835770,summary() currently assumes precompute=False (not intentionally - you just found a bug!),summary currently intentionally found bug,issue,negative,neutral,neutral,neutral,neutral,neutral
342833787,"There's an error in `model_summary` code, even with current codebase, so have not been able to test it.  @jph00 @yanneta.  As you can see this code doesn't have the pull request and uses `.cuda` method.  The notebook is the `lesson1.ipynb` 

<img width=""895"" alt=""screen shot 2017-11-08 at 6 24 11 am"" src=""https://user-images.githubusercontent.com/1437573/32554228-f02f1340-c44d-11e7-8e1e-3183d76dbd1a.png"">
<img width=""905"" alt=""screen shot 2017-11-08 at 6 25 27 am"" src=""https://user-images.githubusercontent.com/1437573/32554234-f3fa05c0-c44d-11e7-916e-cf3e459fbbba.png"">
",error code even current able test see code pull request method notebook screen shot screen shot,issue,negative,positive,positive,positive,positive,positive
342708544,"I think this is fine as is, except that you should just write 'val_metrics:' at the end, and then show all metrics in the array there. You should test it to ensure it works correctly with multiple metrics.",think fine except write end show metric array test ensure work correctly multiple metric,issue,positive,positive,positive,positive,positive,positive
342708231,"This is really cool that you got this working - I've just committed a different approach instead however which requires less code, which hopefully you'll find find useful to take a look at :)",really cool got working different approach instead however le code hopefully find find useful take look,issue,positive,positive,positive,positive,positive,positive
342606688,At the moment I don't have a good suggestion. Let's keep thinking about it. I think that after one day of training you get used to the numbers.,moment good suggestion let keep thinking think one day training get used,issue,negative,positive,positive,positive,positive,positive
341986539,"That is true. I think though that ""train_loss"", and ""val_loss"" would be fairly certain to be always applicable, no?

Anyways, I think there could be a design improvement here. Just printing out an array of numbers definitely seems a little crude. Let me know what a best possible alternate may be.

",true think though would fairly certain always applicable anyways think could design improvement printing array definitely little crude let know best possible alternate may,issue,positive,positive,neutral,neutral,positive,positive
341980014,"Hi,
There are a couple of problems here. We often don't use accuracy as the metric so ""val_acc"" would be misleading. If you read the code carefully, ""metrics"" is a list of arbitrary length. ""metrics"" can be defined by the user.  I am not sure the best way to solve it. 

Thank you,
Yannet ",hi couple often use accuracy metric would misleading read code carefully metric list arbitrary length metric defined user sure best way solve thank,issue,positive,positive,positive,positive,positive,positive
341802680,looks like we were looping over same list multiple times.,like looping list multiple time,issue,negative,neutral,neutral,neutral,neutral,neutral
341800990,I merged the code. Do you know what was the slow part? ,code know slow part,issue,negative,negative,negative,negative,negative,negative
341764756,"Thanks, I think I have made change which also condense the function. @jph00 please comment if the latest change is ok.

I agree list comprehension are good, in this case, i had a huge training set and difference between old and new code was 32 secs vs 4 mins on my machine.",thanks think made change also condense function please comment latest change agree list comprehension good case huge training set difference old new code machine,issue,positive,positive,positive,positive,positive,positive
341758836,"@trusty - I think Yannet may be referring to couple of things -
1. Jeremy likes the use of list comprehension to keep the code concise with fewer lines of code.
2. How often `read_dirs` is the bottleneck in the overall model training process.

Coming from a Software Eng. background, I agree with your spacing and style of code, but that may not consistent with the way library is written.",trusty think may couple use list comprehension keep code concise code often bottleneck overall model training process coming background agree spacing style code may consistent way library written,issue,positive,positive,positive,positive,positive,positive
341722561,"Ramesh,
I am experiencing a slower notebook than before. I am not sure this is due to your changes but I want to investigate before merging. I will be working on this later today. Thanks! ",notebook sure due want investigate working later today thanks,issue,positive,positive,positive,positive,positive,positive
341712176,I commited another change in my master and it is part of the pull request now. that new changes are also tested. that version is atleast 3x faster than the version it replaces atleast on my machine.,another change master part pull request new also tested version faster version machine,issue,negative,positive,positive,positive,positive,positive
341601995,@yanneta - I tested it on an P2 GPU instance using the AMI that Jeremy created for the course.  I ran the lesson1.ipynb for the dogs/cats notebook.,tested instance ami course ran notebook,issue,negative,neutral,neutral,neutral,neutral,neutral
341597843,"@trusty - Your change looks right, but looks like recent change to the library has created conflicts. 
 Can you resolve the and push again for the maintainers to see.  I am just commenting here on your change.  I am not the maintainer of the project.",trusty change right like recent change library resolve push see change maintainer project,issue,positive,positive,positive,positive,positive,positive
341591096,@yanneta - Thanks for reviewing my pull request.  I am working on it now to test with the New AMI that Jeremy has created.  I will confirm here once I run through couple of lesson notebooks in courses/dl1,thanks pull request working test new ami confirm run couple lesson,issue,negative,positive,positive,positive,positive,positive
341590761,@apiltamang - I would prefer to leave out the multi-gpu support out of this Pull request.  This pull request is intended to make fastai work both in CPU and GPU.  Adding multi-gpu might be better served in a separate pull request.,would prefer leave support pull request pull request intended make work might better separate pull request,issue,positive,positive,positive,positive,positive,positive
341577254,"Ramesh,
Have you test the code with and without GPU to make sure it works?

Best,
Yannet

On Thu, Nov 2, 2017 at 2:04 PM, apiltamang <notifications@github.com> wrote:

> i think it's a decent start. I've always wondered why PyTorch makes it
> hard to separate the logic between GPU and CPU in this manner.
>
> I will test your commit out, and if you're cool, I might add in a support
> for multi-gpu resource utilization. PyTorch makes using multi-gpu
> super-easy, so maybe worth giving it a shot. But, instead of utilizing all
> GPUs by default, wonder how hard it might be to specify how many GPU's to
> use!
>
> —
> You are receiving this because you are subscribed to this thread.
> Reply to this email directly, view it on GitHub
> <https://github.com/fastai/fastai/pull/12#issuecomment-341557609>, or mute
> the thread
> <https://github.com/notifications/unsubscribe-auth/AC3CZcNGZygYU37goqKQ6Q5x0EN7jTgtks5syi5jgaJpZM4QQVWm>
> .
>
",test code without make sure work best wrote think decent start always hard separate logic manner test commit cool might add support resource utilization maybe worth giving shot instead default wonder hard might specify many use thread reply directly view mute thread,issue,positive,positive,positive,positive,positive,positive
341557609,"i think it's a decent start. I've always wondered why PyTorch makes it hard to separate the logic between GPU and CPU in this manner.

I will test your commit out, and if you're cool, I might add in a support for multi-gpu resource utilization. PyTorch makes using multi-gpu super-easy, so maybe worth giving it a shot. But, instead of utilizing all GPUs by default, wonder how hard it might be to specify how many GPU's to use!",think decent start always hard separate logic manner test commit cool might add support resource utilization maybe worth giving shot instead default wonder hard might specify many use,issue,positive,positive,positive,positive,positive,positive
341343228,"is this project still alive? I see your pr, hopefully it will be merged. :)",project still alive see hopefully,issue,positive,positive,neutral,neutral,positive,positive
341340482,"Fork this repo and make the changes in your repo. once you are ready, ask for a pull request.",fork make ready ask pull request,issue,negative,positive,positive,positive,positive,positive
334811993,Not quite right - you need to pass is_test too. I'll fix and commit separately now.,quite right need pas fix commit separately,issue,negative,positive,positive,positive,positive,positive
334683502,"hey @jph00 @yanneta, this is a n obvious bug fix. Can you have a look?",hey obvious bug fix look,issue,negative,neutral,neutral,neutral,neutral,neutral
334562440,"This looks pretty good to me. re: your question... I'm not really sure of the answer - I'd suggest try replacing the current methods and then refactoring it until you've got it simplified as much as you can in the Planet and Dogs v Cats notebooks, then let's discuss to see if we can make it even simpler! ",pretty good question really sure answer suggest try current got simplified much planet dog let discus see make even simpler,issue,positive,positive,positive,positive,positive,positive
333996259,"I think I got your point. Made a couple of changes. 
if max_zoom is not None and crop_type is None:
        crop_type = CropType.RANDOM
....
and 
class Transforms():
    def __init__(self, sz, tfms, denorm, crop_type=CropType.CENTER):
        self.sz,self.denorm = sz,denorm
        crop_fn = CenterCrop
",think got point made couple none none class self,issue,negative,neutral,neutral,neutral,neutral,neutral
333988987,"I don't think so - if the user specifies a particular type, we should
use that type. We should only use a default if None is passed. Does that
make sense?
",think user particular type use type use default none make sense,issue,negative,positive,positive,positive,positive,positive
333344775,"I have removed the versions from environment.yml file and moved several packages from the pip section to the conda section.  It seems that the bcoltz that comes with conda doesn't work very well (It is an older version) -- so I have added it to pip. 
BTW, I personally prefer the setup where all the version numbers are explicitly specified -- so that a student can start with a new environment for the course and we know that the particular environment will definitely work. ",removed file several pip section section come work well older version added pip personally prefer setup version explicitly student start new environment course know particular environment definitely work,issue,positive,positive,neutral,neutral,positive,positive
331112095,"Thanks for the update. I'm not an expert in conda config by any means, but I think that you can:

- Remove the version numbers from all the conda packages, except for pytorch, which we should keep to 0.2 (since we're using some stuff there that's likely to change)
- Move everything from the 'pip:' section to the main dependencies section, except for opencv-python (which isn't in conda) and anything else that's not in conda
- Replace all the '==' with '>=' except for pytorch, for requirements.txt
- For conda's python, 3.7 works fine too, so perhaps anything >=3.6 should be acceptable",thanks update expert think remove version except keep since stuff likely change move everything section main section except anything else replace except python work fine perhaps anything acceptable,issue,positive,positive,positive,positive,positive,positive
330905457,"Thanks for checking in. I would prefer the conda approach for the class since that's what we'll be teaching the students. We can still have a requirements.txt for those that are familiar and comfortable with that, of course.",thanks would prefer approach class since teaching still familiar comfortable course,issue,positive,positive,positive,positive,positive,positive
330732759,I just realized that the project only works with Python 3.6 and also pytorch requires installation from a specific channel. We can specify in the README about those two requirements (and use a requirements.txt file for all other dependencies) or I can export a conda yml file that takes care of all these things automatically. I am not sure which approach would you like to use in the class. Probably the conda approach is newbie friendly but requirements.txt is more flexible..,project work python also installation specific channel specify two use file export file care automatically sure approach would like use class probably approach friendly flexible,issue,positive,positive,positive,positive,positive,positive
330687439,We may well do that once we release the course officially!,may well release course officially,issue,negative,neutral,neutral,neutral,neutral,neutral
330687250,"Whilst I know it's not officially recommended, I'm not a fan of using lots of vertical space, and like to be able to see everything in one screen where possible. Thanks anyways for the PR! :)",whilst know officially fan lot vertical space like able see everything one screen possible thanks anyways,issue,positive,positive,positive,positive,positive,positive
330687013,Could you please remove the specific version numbers unless there are cases where they're needed? Or perhaps replace with '>='? ,could please remove specific version unless perhaps replace,issue,negative,neutral,neutral,neutral,neutral,neutral
329973707,"Well, if you just want to view the notebook, you could try:

http://nbviewer.jupyter.org/github/fastai/fastai/blob/master/tutorials/linalg_pytorch.ipynb
",well want view notebook could try,issue,negative,neutral,neutral,neutral,neutral,neutral
