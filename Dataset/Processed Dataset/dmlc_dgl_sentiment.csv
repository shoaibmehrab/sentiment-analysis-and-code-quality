id,original_comment,processed_comment,source,sentiment_VADER,sentiment_textblob,sentiment_pattern,sentiment_bert,sentiment_spacy,max_voted_sentiment
2040965157,"@nv-dlasalle GraphBolt will have full support for Cooperative Minibatching, it is going to be even more optimized than in our paper, it will provide speedups even for cheap GNN models such as GraphSAGE forward/backward passes.",full support going even paper provide even cheap,issue,negative,positive,positive,positive,positive,positive
2040964230,"@frozenbugs is there anyone else who can take over this issue? If we can support the IGB datasets, both homogenous and heterogenous, it would be a good benchmark for us going forward to improve our scalability and test every aspect of GraphBolt.",anyone else take issue support homogenous heterogenous would good u going forward improve test every aspect,issue,positive,positive,positive,positive,positive,positive
2040963529,"I believe the regression tests and optimized version of the kernel has been implemented.

Feel free to open the issue if you think there is a way to improve it so that it won't cause a regression.",believe regression version kernel feel free open issue think way improve wo cause regression,issue,positive,positive,positive,positive,positive,positive
2040962367,@frozenbugs is there more to be done for this issue? We already support feature copy overlap when features are pinned.,done issue already support feature copy overlap pinned,issue,negative,neutral,neutral,neutral,neutral,neutral
2040962087,What new functionality will this class support taking into account it stores small graphs? We could in theory make each graph of a different node type to support small graphs.,new functionality class support taking account small could theory make graph different node type support small,issue,positive,negative,neutral,neutral,negative,negative
2038582247,This issue has been automatically marked as stale due to lack of activity. It will be closed if no further activity occurs. Thank you,issue automatically marked stale due lack activity closed activity thank,issue,negative,negative,negative,negative,negative,negative
2035831964,"Commit ID: ee02a139ecaa17668227bc1e86c2676d01b52964

Build ID: 1

Status: âœ… CI test succeeded.

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7269/1/1/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7269/1/1/logs/cireport.log)",commit id build id status test report path link full path link,issue,negative,positive,positive,positive,positive,positive
2035794164,"To trigger regression tests: 
 - `@dgl-bot run [instance-type] [which tests] [compare-with-branch]`; 
 For example: `@dgl-bot run g4dn.4xlarge all dmlc/master` or `@dgl-bot run c5.9xlarge kernel,api dmlc/master`",trigger regression run example run run kernel,issue,negative,neutral,neutral,neutral,neutral,neutral
2034202060,"Commit ID: e5c8c7058c24de898b493bae133216ac20ee4f64

Build ID: 1

Status: âŒ CI test failed in Stage [Torch CPU Example test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7268/1/1/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7268/1/1/logs/cireport.log)",commit id build id status test stage torch example test report path link full path link,issue,negative,positive,positive,positive,positive,positive
2033979381,"Commit ID: 904a12f32780ca28e7dfc4a9ff1e42e85453548e

Build ID: 2

Status: âŒ CI test failed in Stage [Authentication].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7267/2/2/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7267/2/2/logs/cireport.log)",commit id build id status test stage authentication report path link full path link,issue,negative,positive,positive,positive,positive,positive
2033978999,"Not authorized to trigger CI. Please ask core developer to help trigger via issuing comment: 
 - `@dgl-bot`",authorized trigger please ask core developer help trigger via issuing comment,issue,positive,neutral,neutral,neutral,neutral,neutral
2033893666,This PR can be merged rather quickly as the optimization can be pretty significant. Homo sampling has 1 synchronization instead of 2 now.,rather quickly optimization pretty significant homo sampling synchronization instead,issue,positive,positive,positive,positive,positive,positive
2033798124,"Commit ID: fddc3e62c8912c1f66483ae6f0fecf8896eec956

Build ID: 1

Status: âšªï¸ CI test cancelled due to overrun.

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7263/1/1/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7263/1/1/logs/cireport.log)",commit id build id status test due overrun report path link full path link,issue,negative,positive,positive,positive,positive,positive
2033745817,"I have unresolved the conversations related to future PRs and will be addressing them shortly. As I address them, I will resolve these conversations.",unresolved related future shortly address resolve,issue,negative,neutral,neutral,neutral,neutral,neutral
2033739768,I will be opening followup PRs to resolve the review comments planned for later.,opening resolve review later,issue,negative,neutral,neutral,neutral,neutral,neutral
2033191779,"@frozenbugs @Rhett-Ying if I was able to adequately address your reviews, feel free to merge. After this is merged, I will have follow-up PRs to further polish, improve and refactor certain parts of the code, including the things we discussed here.",able adequately address feel free merge polish improve certain code,issue,positive,positive,positive,positive,positive,positive
2033183189,"@Rhett-Ying CI failure:

```
ests/distributed/test_partition.py::test_partition_graph_graphbolt_homo[True-False-True-False-4-random] Converting to homogeneous graph takes 0.001s, peak mem: 3.929 GB
Reshuffle nodes and edges: 0.001 seconds
Split the graph: 0.003 seconds
Fatal Python error: Segmentation fault

Thread 0x00007f2c0475e700 (most recent call first):
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/threading.py"", line 324 in wait
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/threading.py"", line 607 in wait
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/tqdm/_monitor.py"", line 60 in run
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/threading.py"", line 1016 in _bootstrap_inner
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/threading.py"", line 973 in _bootstrap

Current thread 0x00007f2c33492800 (most recent call first):
  File ""/home/ubuntu/jenkins/workspace/dgl_PR-7239@2/python/dgl/backend/pytorch/tensor.py"", line 126 in astype
  File ""/home/ubuntu/jenkins/workspace/dgl_PR-7239@2/python/dgl/partition.py"", line 223 in create_subgraph
  File ""/home/ubuntu/jenkins/workspace/dgl_PR-7239@2/python/dgl/partition.py"", line 239 in partition_graph_with_halo
  File ""/home/ubuntu/jenkins/workspace/dgl_PR-7239@2/python/dgl/distributed/partition.py"", line 1016 in partition_graph
  File ""/home/ubuntu/jenkins/workspace/dgl_PR-7239@2/tests/distributed/test_partition.py"", line 1051 in test_partition_graph_graphbolt_homo
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/python.py"", line 194 in pytest_pyfunc_call
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_callers.py"", line 102 in _multicall
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_manager.py"", line 119 in _hookexec
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_hooks.py"", line 501 in __call__
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/python.py"", line 1831 in runtest
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/runner.py"", line 170 in pytest_runtest_call
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_callers.py"", line 102 in _multicall
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_manager.py"", line 119 in _hookexec
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_hooks.py"", line 501 in __call__
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/runner.py"", line 263 in &lt;lambda&gt;
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/runner.py"", line 342 in from_call
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/runner.py"", line 262 in call_runtest_hook
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/runner.py"", line 223 in call_and_report
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/runner.py"", line 134 in runtestprotocol
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/runner.py"", line 115 in pytest_runtest_protocol
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_callers.py"", line 102 in _multicall
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_manager.py"", line 119 in _hookexec
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_hooks.py"", line 501 in __call__
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/main.py"", line 352 in pytest_runtestloop
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_callers.py"", line 102 in _multicall
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_manager.py"", line 119 in _hookexec
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_hooks.py"", line 501 in __call__
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/main.py"", line 327 in _main
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/main.py"", line 273 in wrap_session
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/main.py"", line 320 in pytest_cmdline_main
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_callers.py"", line 102 in _multicall
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_manager.py"", line 119 in _hookexec
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pluggy/_hooks.py"", line 501 in __call__
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 175 in main
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/_pytest/config/__init__.py"", line 198 in console_main
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/site-packages/pytest/__main__.py"", line 7 in &lt;module&gt;
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/runpy.py"", line 86 in _run_code
  File ""/opt/conda/envs/pytorch-ci/lib/python3.10/runpy.py"", line 196 in _run_module_as_main

Extension modules: numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, torch._C, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, dgl._ffi._cy3.core, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._flinalg, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, psutil._psutil_linux, psutil._psutil_posix, pyarrow.lib, pyarrow._hdfsio, pyarrow._parquet, pyarrow._fs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, scipy.io.matlab._mio_utils, scipy.io.matlab._streams, scipy.io.matlab._mio5_utils, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.special._ufuncs_cxx, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial.transform._rotation, yaml._yaml (total: 111)
tests/scripts/task_distributed_test.sh: line 37:   649 Segmentation fault      (core dumped) python3 -m pytest -v --capture=tee-sys --junitxml=pytest_distributed.xml --durations=100 tests/distributed/*.py
```",failure random converting homogeneous graph peak mem reshuffle split graph fatal python error segmentation fault thread recent call first file line wait file line wait file line run file line file line current thread recent call first file line file line file line file line file line file line file line file line file line file line file line file line file line file line file line lambda file line file line file line file line file line file line file line file line file line file line file line file line file line file line file line file line file line file line file line main file line file line module file line file line extension total line segmentation fault core python,issue,negative,negative,neutral,neutral,negative,negative
2033179720,"Commit ID: fa2b5e2c0563f904698b5c45f4d51a30080026f2

Build ID: 35

Status: âŒ CI test failed in Stage [Distributed Torch CPU Unit test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7239/35/35/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7239/35/35/logs/cireport.log)",commit id build id status test stage distributed torch unit test report path link full path link,issue,negative,positive,positive,positive,positive,positive
2031915243,We never merge PR into release branch such as `2.1.x` directly. please open a new PR that targets on `master` branch instead.,never merge release branch directly please open new master branch instead,issue,negative,positive,neutral,neutral,positive,positive
2031469730," Hello @Rhett-Ying ,

I've submitted a Pull Request addressing some documentation issues. Whenever you have a moment, could you please review it? Your feedback would be greatly appreciated.

Best regards,
MikuSugar
",hello pull request documentation whenever moment could please review feedback would greatly best,issue,positive,positive,positive,positive,positive,positive
2031140208,"Commit ID: 4cce10f813b6fbd3ae493c410bd83432489995bb

Build ID: 27

Status: âŒ CI test failed in Stage [GPU Build].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7239/27/27/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7239/27/27/logs/cireport.log)",commit id build id status test stage build report path link full path link,issue,negative,positive,positive,positive,positive,positive
2030980004,@frozenbugs I can't reproduce the failure in the CI in my local system. How can I proceed?,ca reproduce failure local system proceed,issue,negative,negative,negative,negative,negative,negative
2030939046,"Commit ID: be2394c94c1a5bd89549d4e20bc38ebc820358d8

Build ID: 4

Status: âŒ CI test failed in Stage [Lint Check].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7253/4/4/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7253/4/4/logs/cireport.log)",commit id build id status test stage lint check report path link full path link,issue,negative,positive,positive,positive,positive,positive
2030429331,"Commit ID: 36e570dd68216a4c5273b20c1913cf20857b8155

Build ID: 20

Status: âŒ CI test failed in Stage [PyTorch Cugraph GPU Unit test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7239/20/20/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7239/20/20/logs/cireport.log)",commit id build id status test stage unit test report path link full path link,issue,negative,positive,positive,positive,positive,positive
2030293806,Related issue about old architecture support: https://github.com/NVIDIA/cccl/issues/1083,related issue old architecture support,issue,negative,positive,neutral,neutral,positive,positive
2029552543,"Commit ID: e971968efb2ab84deacb2f55d07cb25ea02e04bf

Build ID: 2

Status: âŒ CI test failed in Stage [Torch CPU (Win64) Unit test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7253/2/2/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7253/2/2/logs/cireport.log)",commit id build id status test stage torch win unit test report path link full path link,issue,positive,positive,positive,positive,positive,positive
2029030738,"The latest DGL 2.1.0 supports up to torch 2.2.1 for now. torch 2.2.2 is not supported yet. According to above discussions, we have 2 work items:

- [ ] improve the error message when loading graphbolt library upon unsupported torch versions.
- [ ] figure out a better way to support new torch versions.",latest torch torch yet according work improve error message loading library upon unsupported torch figure better way support new torch,issue,negative,positive,positive,positive,positive,positive
2028880027,I might have found a solution without limiting to newer architectures only. Will try the potential solution first.,might found solution without limiting try potential solution first,issue,positive,positive,positive,positive,positive,positive
2026450818,@Andrew-S-Rosen Then the error message could be improved as it is currently not very enlightening.,error message could currently enlightening,issue,negative,positive,positive,positive,positive,positive
2026430224,"> We unfortunately can not do that. Then you wouldn't be able to build from source with torch 2.2.2. I for example work with torch==2.3.0a0+ebedce2. If we added that line, you wouldn't be able to build from source with latest torch versions as it would attempt to install torch==2.2.1.

Ah, this certainly makes sense.

> What we could do however is to load graphbolt and the components relying on us to compile for specific torch versions to do a version check and not load them if the version is not suitable instead of giving an error, it can give a warning instead.

Actually, I feel the error may be more helpful than a warning. It is easier to catch the error in CI for a downstream code relying on `dgl` as a dependency ðŸ‘ ",unfortunately would able build source torch example work added line would able build source latest torch would attempt install ah certainly sense could however load u compile specific torch version check load version suitable instead giving error give warning instead actually feel error may helpful warning easier catch error downstream code dependency,issue,negative,positive,positive,positive,positive,positive
2026426963,"> > Hi @Andrew-S-Rosen, it looks like we currently support torch up to 2.2.1. DGL's next release should include out of the box support for later torch versions.
> 
> Good to know, thanks! In that case, should doing `pip install dgl==2.1.0` also ensure that `torch<=2.1.1` is returned so such issues don't happen to unexpecting end users?

We unfortunately can not do that. Then you wouldn't be able to build from source with torch 2.2.2. I for example work with `torch==2.3.0a0+ebedce2`. If we added that line, you wouldn't be able to build from source with latest torch versions as it would attempt to install `torch==2.2.1`.

What we could do however is to load graphbolt and the components relying on us to compile for specific torch versions to do a version check and not load them if the version is not suitable instead of giving an error, it can give a warning instead.",hi like currently support torch next release include box support later torch good know thanks case pip install also ensure torch returned happen unexpecting end unfortunately would able build source torch example work added line would able build source latest torch would attempt install could however load u compile specific torch version check load version suitable instead giving error give warning instead,issue,positive,positive,positive,positive,positive,positive
2026419079,"> Hi @Andrew-S-Rosen, it looks like we currently support torch up to 2.2.1. DGL's next release should include out of the box support for later torch versions.

Good to know, thanks! In that case, should doing `pip install dgl==2.1.0` also ensure that `torch<=2.1.1` is returned so such issues don't happen to end users?",hi like currently support torch next release include box support later torch good know thanks case pip install also ensure torch returned happen end,issue,positive,positive,positive,positive,positive,positive
2026415965,You can build DGL from source if you want earlier support for the latest torch versions. We definitely need to fix the additional dependency issues though. @Rhett-Ying @frozenbugs ,build source want support latest torch definitely need fix additional dependency though,issue,positive,positive,positive,positive,positive,positive
2026414981,"> ## Additional context
> Even installing those dependencies, there is still an error:
> 
> ```python
> Traceback (most recent call last):
>   File ""<stdin>"", line 1, in <module>
>   File ""/home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/__init__.py"", line 16, in <module>
>     from . import (
>   File ""/home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/dataloading/__init__.py"", line 13, in <module>
>     from .dataloader import *
>   File ""/home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/dataloading/dataloader.py"", line 27, in <module>
>     from ..distributed import DistGraph
>   File ""/home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/distributed/__init__.py"", line 5, in <module>
>     from .dist_graph import DistGraph, DistGraphServer, edge_split, node_split
>   File ""/home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/distributed/dist_graph.py"", line 11, in <module>
>     from .. import backend as F, graphbolt as gb, heterograph_index
>   File ""/home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/graphbolt/__init__.py"", line 55, in <module>
>     load_graphbolt()
>   File ""/home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/graphbolt/__init__.py"", line 45, in load_graphbolt
>     raise FileNotFoundError(
> FileNotFoundError: Cannot find DGL C++ graphbolt library at /home/rosen/software/miniconda/envs/test2/lib/python3.10/site-packages/dgl/graphbolt/libgraphbolt_pytorch_2.2.2.so
> ```
> 
> I'm leaning towards this being some incompatibility with the newly released `torch==2.2.2`. Doing the full install process with `torch==2.2.1` seems to be okay.

Hi @Andrew-S-Rosen, it looks like we currently support torch up to 2.2.1. DGL's next release should include out of the box support for later torch versions.

The list of currently supported torch versions:
```
2.0.0
2.0.1
2.1.0
2.1.1
2.1.2
2.2.0
2.2.1
```",additional context even still error python recent call last file line module file line module import file line module import file line module distributed import file line module import file line module import file line module file line raise find library leaning towards incompatibility newly full install process hi like currently support torch next release include box support later torch list currently torch,issue,positive,positive,neutral,neutral,positive,positive
2025915190,@TristonC is my dispatch mechanism correct so that I can run one code for Compute Capability >= 70 and another otherwise.,dispatch mechanism correct run one code compute capability another otherwise,issue,negative,neutral,neutral,neutral,neutral,neutral
2022088423,copy_to can be between sample neighbors and fetch feature as well.,sample fetch feature well,issue,negative,neutral,neutral,neutral,neutral,neutral
2021872622,"@frozenbugs Do you think we can perform the separation of different etypes into different sampled csc inside the dgl blocks conversion function, so that our sampling code does not need any loops over etypes when sampling?

We can use a batched representation overall throughout sampling code and only convert into dictionaries when absolutely needed.",think perform separation different different inside conversion function sampling code need sampling use representation overall throughout sampling code convert absolutely,issue,negative,positive,neutral,neutral,positive,positive
2019872473,Seems like some code made `all_nodes_set`'s dtype incompatible with `graph.indices`'s.,like code made incompatible,issue,negative,neutral,neutral,neutral,neutral,neutral
2019555312,"Commit ID: 7e480ef1a59d12c0197107b1e7284ea13671c4ee

Build ID: 1

Status: âŒ CI test failed in Stage [Torch GPU Unit test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7242/1/1/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7242/1/1/logs/cireport.log)",commit id build id status test stage torch unit test report path link full path link,issue,negative,positive,positive,positive,positive,positive
2019541557,What's the overall epoch time improvement?,overall epoch time improvement,issue,negative,neutral,neutral,neutral,neutral,neutral
2017454661,Let's merge this first and optimize in the future.,let merge first optimize future,issue,negative,positive,positive,positive,positive,positive
2017426251,@caojy1998  any detailed performance number for the current improvement?,detailed performance number current improvement,issue,positive,positive,positive,positive,positive,positive
2017001370,@peizhou001 please help look into this Windows package issue.,please help look package issue,issue,positive,neutral,neutral,neutral,neutral,neutral
2016990607,"> > > I'm facing the same problem. I am using the oficial Docker image provided by DGL and, even when running the SAGE example twice, I get different acc values.
> > > (edit) it seems to be a confirmed bug. Checkout the [Issue](https://github.com/dmlc/dgl/issues/4155)
> > 
> > 
> > No, it is a different case for me. In the [issue](https://github.com/dmlc/dgl/issues/4155), when they also use the CPU, it gives indeterminate results, which in my case is different, as using the CPU results in deterministic outcomes
> 
> Save the initial weights of the model and reuse them in each run, as suggested by [jermainewang](https://github.com/jermainewang), did not solve your problem?

Yes I tried it but the same results.
Also, I tried to save the data while it's still on the CUDA device, but still no changes. Is there any other solution? I've been trying all possible approaches with no correct answer, even after following the PyTorch deterministic documentation
",facing problem docker image provided even running sage example twice get different edit confirmed bug issue different case issue also use indeterminate case different deterministic save initial model reuse run solve problem yes tried also tried save data still device still solution trying possible correct answer even following deterministic documentation,issue,positive,positive,neutral,neutral,positive,positive
2016634491,"> > I'm facing the same problem. I am using the oficial Docker image provided by DGL and, even when running the SAGE example twice, I get different acc values.
> > (edit) it seems to be a confirmed bug. Checkout the [Issue](https://github.com/dmlc/dgl/issues/4155)
> 
> No, it is a different case for me. In the [issue](https://github.com/dmlc/dgl/issues/4155), when they also use the CPU, it gives indeterminate results, which in my case is different, as using the CPU results in deterministic outcomes

Save the initial weights of the model and reuse them in each run, as suggested by [jermainewang](https://github.com/jermainewang), did not solve your problem?",facing problem docker image provided even running sage example twice get different edit confirmed bug issue different case issue also use indeterminate case different deterministic save initial model reuse run solve problem,issue,negative,positive,neutral,neutral,positive,positive
2016632950,"> I checked the code in the repo and found the setup is not correct. As @Rhett-Ying mentioned, the model weight will be re-initialized each time you created a `model` object. If you want to have a deterministic behavior. You could either reset all the seeds right before the model is created each time, or initialize the model once, checkpoint the weights and reload them for each repeated runs.

I stored the weights before training my model as you told and it worked! Now the model is deterministic. Bellow is my code snippet:

```py
   #checkpoint the model weights
   torch.save(base_model.state_dict(), 'base_model.pth')
   
   #load the model weights
   base_model.load_state_dict(torch.load('base_model.pth'))
```",checked code found setup correct model weight time model object want deterministic behavior could either reset right model time initialize model reload repeated training model told worked model deterministic bellow code snippet model load model,issue,negative,positive,positive,positive,positive,positive
2016503359,"> I'm facing the same problem. I am using the oficial Docker image provided by DGL and, even when running the SAGE example twice, I get different acc values.
> 
> (edit) it seems to be a confirmed bug. Checkout the [Issue](https://github.com/dmlc/dgl/issues/4155)

No, it is a different case for me. In the [issue](https://github.com/dmlc/dgl/issues/4155), when they also use the CPU, it gives indeterminate results, which in my case is different, as using the CPU results in deterministic outcomes",facing problem docker image provided even running sage example twice get different edit confirmed bug issue different case issue also use indeterminate case different deterministic,issue,negative,positive,neutral,neutral,positive,positive
2016496008,"I'm facing the same problem. I am using the oficial Docker image provided by DGL and, even when running the SAGE example twice, I get different acc values.

(edit) it seems to be a confirmed bug. Checkout the [Issue](https://github.com/dmlc/dgl/issues/4155)",facing problem docker image provided even running sage example twice get different edit confirmed bug issue,issue,negative,positive,positive,positive,positive,positive
2014271448,"> > > > > > I did another test and the results are (features are sliced with `[:, :32]`):
> > > > > > 
> > > > > > * Old version: 5.817s
> > > > > > * Current PR (with the `if` inside the loop): 5.802s
> > > > > > * Current PR (without the `if` inside the loop): 5.783s
> > > > > > 
> > > > > > So it seems that deleting the `if` might be faster!
> > > > > 
> > > > > 
> > > > > The fact that all the numbers are so close is suspicious to me. Could we test with no feature fetch and no forward pass?
> > > > 
> > > > 
> > > > Without feature fetching and forward pass: 4.319s (before) and 4.707s (after). About 9% slower
> > > 
> > > 
> > > Do you want to look into implementing atomic load and see if it helps before the cas loop? Or do you want to merge this first, then continue to optimize?
> > 
> > 
> > @mfbalin I tried to implement it but I think the atomic load can just be a `CompareAndSwap`. Like `old_val = CompareAndSwap(&(hash_map_data[val_pos]), empty_key, value);` is a way to load it atomically. But in the end it's the same with the current code since we are doing the same thing in the loop.
> 
> https://gcc.gnu.org/onlinedocs/gcc-4.1.0/gcc/Atomic-Builtins.html You can use __sync_fetch_and_or with 2nd argument as 0 to perform an atomic load operation.

I see. I tried `__sync_fetch_and_or` and tested. The performance is about the same (4.717s)",another test sliced old version current inside loop current without inside loop might faster fact close suspicious could test feature fetch forward pas without feature fetching forward pas want look atomic load see loop want merge first continue optimize tried implement think atomic load like value way load atomically end current code since thing loop use argument perform atomic load operation see tried tested performance,issue,positive,positive,neutral,neutral,positive,positive
2014217539,"> > > > > I did another test and the results are (features are sliced with `[:, :32]`):
> > > > > 
> > > > > * Old version: 5.817s
> > > > > * Current PR (with the `if` inside the loop): 5.802s
> > > > > * Current PR (without the `if` inside the loop): 5.783s
> > > > > 
> > > > > So it seems that deleting the `if` might be faster!
> > > > 
> > > > 
> > > > The fact that all the numbers are so close is suspicious to me. Could we test with no feature fetch and no forward pass?
> > > 
> > > 
> > > Without feature fetching and forward pass: 4.319s (before) and 4.707s (after). About 9% slower
> > 
> > 
> > Do you want to look into implementing atomic load and see if it helps before the cas loop? Or do you want to merge this first, then continue to optimize?
> 
> @mfbalin I tried to implement it but I think the atomic load can just be a `CompareAndSwap`. Like `old_val = CompareAndSwap(&(hash_map_data[val_pos]), empty_key, value);` is a way to load it atomically. But in the end it's the same with the current code since we are doing the same thing in the loop.

https://gcc.gnu.org/onlinedocs/gcc-4.1.0/gcc/Atomic-Builtins.html
You can use __sync_fetch_and_or with 2nd argument as 0 to perform an atomic load operation. CompareAndSwap is one of the most expensive atomic operations.",another test sliced old version current inside loop current without inside loop might faster fact close suspicious could test feature fetch forward pas without feature fetching forward pas want look atomic load see loop want merge first continue optimize tried implement think atomic load like value way load atomically end current code since thing loop use argument perform atomic load operation one expensive atomic,issue,positive,negative,neutral,neutral,negative,negative
2014216007,"> > > > I did another test and the results are (features are sliced with `[:, :32]`):
> > > > 
> > > > * Old version: 5.817s
> > > > * Current PR (with the `if` inside the loop): 5.802s
> > > > * Current PR (without the `if` inside the loop): 5.783s
> > > > 
> > > > So it seems that deleting the `if` might be faster!
> > > 
> > > 
> > > The fact that all the numbers are so close is suspicious to me. Could we test with no feature fetch and no forward pass?
> > 
> > 
> > Without feature fetching and forward pass: 4.319s (before) and 4.707s (after). About 9% slower
> 
> Do you want to look into implementing atomic load and see if it helps before the cas loop? Or do you want to merge this first, then continue to optimize?

@mfbalin I tried to implement it but I think the atomic load can just be a `CompareAndSwap`. Like `old_val = CompareAndSwap(&(hash_map_data[val_pos]), empty_key, value);` is a way to load it atomically. But in the end it's the same with the current code since we are doing the same thing in the loop.",another test sliced old version current inside loop current without inside loop might faster fact close suspicious could test feature fetch forward pas without feature fetching forward pas want look atomic load see loop want merge first continue optimize tried implement think atomic load like value way load atomically end current code since thing loop,issue,positive,positive,neutral,neutral,positive,positive
2011065797,"The code there is just for demonstration, which is not expected to be runnable seamlessly, can you try https://github.com/dmlc/dgl/tree/master/examples/distributed/graphsage.",code demonstration runnable seamlessly try,issue,negative,positive,neutral,neutral,positive,positive
2011064627,What's your DGL version? Can you follow our DGL template for bug report?,version follow template bug report,issue,negative,neutral,neutral,neutral,neutral,neutral
2011063233,"Can you double check the original code by the TGN author, if you believe it should be averaged, feel free to file an PR and link your justification.",double check original code author believe feel free file link justification,issue,positive,positive,positive,positive,positive,positive
2008690658,"> > > I did another test and the results are (features are sliced with `[:, :32]`):
> > > 
> > > * Old version: 5.817s
> > > * Current PR (with the `if` inside the loop): 5.802s
> > > * Current PR (without the `if` inside the loop): 5.783s
> > > 
> > > So it seems that deleting the `if` might be faster!
> > 
> > 
> > The fact that all the numbers are so close is suspicious to me. Could we test with no feature fetch and no forward pass?
> 
> Without feature fetching and forward pass: 4.319s (before) and 4.707s (after). About 9% slower

Do you want to look into implementing atomic load and see if it helps before the cas loop? Or do you want to merge this first, then continue to optimize?",another test sliced old version current inside loop current without inside loop might faster fact close suspicious could test feature fetch forward pas without feature fetching forward pas want look atomic load see loop want merge first continue optimize,issue,negative,positive,neutral,neutral,positive,positive
2008683228,"> > I did another test and the results are (features are sliced with `[:, :32]`):
> > 
> > * Old version: 5.817s
> > * Current PR (with the `if` inside the loop): 5.802s
> > * Current PR (without the `if` inside the loop): 5.783s
> > 
> > So it seems that deleting the `if` might be faster!
> 
> The fact that all the numbers are so close is suspicious to me. Could we test with no feature fetch and no forward pass?

Without feature fetching and forward pass: 4.319s (before) and 4.707s (after). About 9% slower",another test sliced old version current inside loop current without inside loop might faster fact close suspicious could test feature fetch forward pas without feature fetching forward pas,issue,negative,positive,neutral,neutral,positive,positive
2008649063,"> I did another test and the results are (features are sliced with `[:, :32]`):
> 
> * Old version: 5.817s
> * Current PR (with the `if` inside the loop): 5.802s
> * Current PR (without the `if` inside the loop): 5.783s
> 
> So it seems that deleting the `if` might be faster!

The fact that all the numbers are so close is suspicious to me. Could we test with no feature fetch and no forward pass?",another test sliced old version current inside loop current without inside loop might faster fact close suspicious could test feature fetch forward pas,issue,negative,positive,neutral,neutral,positive,positive
2008647878,"I did another test and the results are (features are sliced with `[:, :32]`):
- Old version: 5.817s
- Current PR (with the `if` inside the loop): 5.802s
- Current PR (without the `if` inside the loop): 5.783s

So it seems that deleting the `if` might be faster!",another test sliced old version current inside loop current without inside loop might faster,issue,negative,positive,neutral,neutral,positive,positive
2008595067,"@peizhou001

Sorry for reopening this old thread, but I am not a programmer and can't figure out how to use this API call. For compatibility reasons I've install dgl 1.0.2.

Where, and how, do I use dgl.use_libxsmm(flag)?

Thanks.",sorry old thread programmer ca figure use call compatibility install use flag thanks,issue,negative,negative,neutral,neutral,negative,negative
2006701795,"Commit ID: 582908c6dde52ab7e08bceff826376aa9188752e

Build ID: 2

Status: âŒ CI test failed in Stage [Torch CPU (Win64) Example test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7231/2/2/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7231/2/2/logs/cireport.log)",commit id build id status test stage torch win example test report path link full path link,issue,positive,positive,positive,positive,positive,positive
2006212523,Or no change is required at all. Just use `neg_sampler = dgl.dataloading.negative_sampler.Uniform(5)` directly. This should work if only `DistGraph.find_edges()` is available.,change use directly work available,issue,negative,positive,positive,positive,positive,positive
2005846715,@mfbalin I tested again with the latest master branch merged. It's 7.911s (before) vs. 7.919s (after),tested latest master branch,issue,negative,positive,positive,positive,positive,positive
2005676257,"The regression seems to be fixed, @frozenbugs could you verify from the graphs?",regression fixed could verify,issue,negative,positive,neutral,neutral,positive,positive
2005646863,"@RamonZhou it might be best to measure the performance by making the feature dimension smaller in case the feature fetch is the bottleneck on your system. Like `features = features[:, :32]`.",might best measure performance making feature dimension smaller case feature fetch bottleneck system like,issue,positive,positive,positive,positive,positive,positive
2004586603,"> > > > > > How much slower is this new implementation compared to the old one?
> > > > > 
> > > > > 
> > > > > @mfbalin The time complexity should be the same. I also tested on my local machine, there's no significant slow down in any of `pinned-cuda`, `cpu-cuda` and `cuda-cuda` modes.
> > > > 
> > > > 
> > > > @RamonZhou Could you also test the advanced pyg example with `cpu-pinned-cuda`? That one stresses the CPU sampling and unique_and_compact the most.
> > > 
> > > 
> > > @mfbalin I tested it and the average epoch time is 7.94s before and 7.99s after
> > 
> > 
> > we may also add an option to decide which path to go depends on whether user need deterministic or not.
> 
> Maybe not? because it keeps the same speed while making the result sable, there is no reason why user want the result non-deterministic w/o performance benefits.

I see around 5% performance loss with this PR on my machine with the advanced PyG example `--mode=cpu-pinned-cuda`.",much new implementation old one time complexity also tested local machine significant slow could also test advanced example one sampling tested average epoch time may also add option decide path go whether user need deterministic maybe speed making result sable reason user want result performance see around performance loss machine advanced example,issue,negative,positive,positive,positive,positive,positive
2003306316,Could you please paste the error message here?,could please paste error message,issue,negative,neutral,neutral,neutral,neutral,neutral
2003256453,"> > > > > How much slower is this new implementation compared to the old one?
> > > > 
> > > > 
> > > > @mfbalin The time complexity should be the same. I also tested on my local machine, there's no significant slow down in any of `pinned-cuda`, `cpu-cuda` and `cuda-cuda` modes.
> > > 
> > > 
> > > @RamonZhou Could you also test the advanced pyg example with `cpu-pinned-cuda`? That one stresses the CPU sampling and unique_and_compact the most.
> > 
> > 
> > @mfbalin I tested it and the average epoch time is 7.94s before and 7.99s after
> 
> we may also add an option to decide which path to go depends on whether user need deterministic or not.

Maybe not? because it keeps the same speed while making the result sable, there is no reason why user want the result non-deterministic w/o performance benefits.",much new implementation old one time complexity also tested local machine significant slow could also test advanced example one sampling tested average epoch time may also add option decide path go whether user need deterministic maybe speed making result sable reason user want result performance,issue,negative,positive,neutral,neutral,positive,positive
2003007272,"> > > > How much slower is this new implementation compared to the old one?
> > > 
> > > 
> > > @mfbalin The time complexity should be the same. I also tested on my local machine, there's no significant slow down in any of `pinned-cuda`, `cpu-cuda` and `cuda-cuda` modes.
> > 
> > 
> > @RamonZhou Could you also test the advanced pyg example with `cpu-pinned-cuda`? That one stresses the CPU sampling and unique_and_compact the most.
> 
> @mfbalin I tested it and the average epoch time is 7.94s before and 7.99s after

we may also add an option to decide which path to go depends on whether user need deterministic or not.",much new implementation old one time complexity also tested local machine significant slow could also test advanced example one sampling tested average epoch time may also add option decide path go whether user need deterministic,issue,negative,positive,neutral,neutral,positive,positive
2002986989,"> > > > How much slower is this new implementation compared to the old one?
> > > 
> > > 
> > > @mfbalin The time complexity should be the same. I also tested on my local machine, there's no significant slow down in any of `pinned-cuda`, `cpu-cuda` and `cuda-cuda` modes.
> > 
> > 
> > @RamonZhou Could you also test the advanced pyg example with `cpu-pinned-cuda`? That one stresses the CPU sampling and unique_and_compact the most.
> 
> @mfbalin I tested it and the average epoch time is 7.94s before and 7.99s after

Thank you. Let's test it again before we merge it. The changes during the review process may impact performance.",much new implementation old one time complexity also tested local machine significant slow could also test advanced example one sampling tested average epoch time thank let test merge review process may impact performance,issue,positive,positive,neutral,neutral,positive,positive
2002960892,"> > > How much slower is this new implementation compared to the old one?
> > 
> > 
> > @mfbalin The time complexity should be the same. I also tested on my local machine, there's no significant slow down in any of `pinned-cuda`, `cpu-cuda` and `cuda-cuda` modes.
> 
> @RamonZhou Could you also test the advanced pyg example with `cpu-pinned-cuda`? That one stresses the CPU sampling and unique_and_compact the most.

@mfbalin  I tested it and the average epoch time is 7.94s before and 7.99s after",much new implementation old one time complexity also tested local machine significant slow could also test advanced example one sampling tested average epoch time,issue,negative,positive,neutral,neutral,positive,positive
1999952367,"> > How much slower is this new implementation compared to the old one?
> 
> @mfbalin The time complexity should be the same. I also tested on my local machine, there's no significant slow down in any of `pinned-cuda`, `cpu-cuda` and `cuda-cuda` modes.

@RamonZhou Could you also test the advanced pyg example with `cpu-pinned-cuda`? That one stresses the CPU sampling and unique_and_compact the most.",much new implementation old one time complexity also tested local machine significant slow could also test advanced example one sampling,issue,negative,positive,positive,positive,positive,positive
1999150793,"> How much slower is this new implementation compared to the old one?

@mfbalin The time complexity should be the same. I also tested on my local machine, there's no significant slow down in any of `pinned-cuda`, `cpu-cuda` and `cuda-cuda` modes.",much new implementation old one time complexity also tested local machine significant slow,issue,negative,positive,neutral,neutral,positive,positive
1999091249,"> @xiangyuzhi Do you think it is a better idea to make DiakBasedFeature a subclass of TorchBasedFeature if we want to treat the two the same?

It looks wired. I think we can use the current solution for now. Since we need a series of adjustments to use this class later, including making it optional, or automatically selecting the feature class based on data and memory size. We can modify and use it in the future PRs.",think better idea make subclass want treat two wired think use current solution since need series use class later making optional automatically feature class based data memory size modify use future,issue,positive,positive,positive,positive,positive,positive
1999068651,How much slower is this new implementation compared to the old one?,much new implementation old one,issue,negative,positive,positive,positive,positive,positive
1999052785,@xiangyuzhi Do you think it is a better idea to make DiakBasedFeature a subclass of TorchBasedFeature if we want to treat the two the same?,think better idea make subclass want treat two,issue,positive,positive,positive,positive,positive,positive
1997414378,"@TristonC The CI has the following error message:
```
/home/ubuntu/jenkins/workspace/dgl_PR-7215/third_party/cccl/libcudacxx/include/cuda/std/detail/libcxx/include/support/atomic/atomic_cuda.h:12:4: error: #error ""CUDA atomics are only supported for sm_60 and up on *nix and sm_70 and up on Windows.""
   12 | #  error ""CUDA atomics are only supported for sm_60 and up on *nix and sm_70 and up on Windows.""
```

I am going to work around it.",following error message error error atomics nix error atomics nix going work around,issue,negative,neutral,neutral,neutral,neutral,neutral
1996614061,"This works for me. Thanks!
Anyone who meets the errors on GPU 4090 could try this solution.

> I also tried to get this example code working, this is what worked for me.
> 
> After a lot of back and forth trying to match `python`,`pytorch` and `cuda` versions [1], the following steps worked for me. (It's easier to start with a new environment because there might be lots of conflicts going on with packages)
> 
> [1] - https://www.dgl.ai/pages/start.html
> 
> ```shell
> ## Create new environment, use arbitrary name ""myenv"" that you prefer
> conda create -n myenv python=3.11
> 
> ## Activate environment
> source activate myenv
> 
> ## Install pytorch 2.2 
> conda install pytorch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 pytorch-cuda=12.1 -c pytorch -c nvidia
> 
> ## Install dgl which matches pytorch 2.2 and cuda 12.1 
> conda install -c dglteam/label/cu121 dgl
> 
> ## Add environment to jupyter kernel
> conda install -c anaconda ipykernel -y
> python -m ipykernel install --user --name=myenv
> 
> # install remaining things that dgl needs
> pip install torchdata
> pip install pandas
> pip install pyyaml
> pip install pydantic
> ```
> 
> > I tried another example, and the same error occurred.
> > ```python
> > import torch.nn.functional as F
> > import dgl
> > from dgl.nn import GraphConv
> > import torch.nn as nn
> > import torch
> > class Classifier(nn.Module):
> >     def __init__(self, in_dim, out_dim):
> >         super(Classifier, self).__init__()
> >         self.conv1 = GraphConv(in_dim, out_dim,)
> >     def forward(self, g, h):
> >         # Apply graph convolution and activation.
> >         h = F.relu(self.conv1(g, h))
> >         return h
> > src_ids = torch.tensor([2, 3, 4])
> > dst_ids = torch.tensor([1, 2, 3])
> > device = torch.device('cuda:0')
> > g = dgl.graph((src_ids, dst_ids)).to(device)
> > g = dgl.add_self_loop(g)
> > x = torch.randn((5, 100)).to(device)
> > model = Classifier(100, 20).to(device)
> > model(g, x)
> > ```

",work thanks anyone could try solution also tried get example code working worked lot back forth trying match python following worked easier start new environment might lot going shell create new environment use arbitrary name prefer create activate environment source activate install install install install add environment kernel install anaconda python install user install need pip install pip install pip install pip install tried another example error python import import import import import torch class classifier self super classifier self forward self apply graph convolution activation return device device device model classifier device model,issue,positive,positive,positive,positive,positive,positive
1996219210,"@wangguan1995 In the code snippet you shared, `type` is wrongly used. It should be node/edge type name instead of data type you used: `type=""float32""`. Here's the correct way to instantiate `OnDiskFeatureData`

```
        a = torch.tensor([[1, 2, 4], [2, 5, 3]])
        b = torch.tensor([[[1, 2], [3, 4]], [[2, 5], [3, 4]]])
        write_tensor_to_disk(test_dir, ""a"", a, fmt=""torch"")
        write_tensor_to_disk(test_dir, ""b"", b, fmt=""numpy"")
        feature_data = [
            gb.OnDiskFeatureData(
                domain=""node"",
                type=""paper"",
                name=""a"",
                format=""torch"",
                path=os.path.join(test_dir, ""a.pt""),
            ),
            gb.OnDiskFeatureData(
                domain=""edge"",
                type=""paper:cites:paper"",
                name=""b"",
                format=""numpy"",
                path=os.path.join(test_dir, ""b.npy""),
            ),
        ]
        feature_store = gb.TorchBasedFeatureStore(feature_data)
```",code snippet type wrongly used type name instead data type used float correct way torch node paper torch edge paper paper,issue,negative,negative,negative,negative,negative,negative
1996206976,"> @mfbalin Could you help to comment here?

I haven't used a custom dataset before, including `gb.OnDiskFeatureData`. So I don't know what could be going wrong.",could help comment used custom know could going wrong,issue,negative,negative,negative,negative,negative,negative
1996123241,"@caojy1998 Could we also add IGB-full or IGB260M? To test, we can start with the tiny variant, e.g. IGB-tiny.",could also add test start tiny variant,issue,negative,neutral,neutral,neutral,neutral,neutral
1993701420,"Let's leave this as draft, and merge it once the end to end code is ready to clean up.",let leave draft merge end end code ready clean,issue,positive,positive,positive,positive,positive,positive
1991071800,"Commit ID: 700ec8da4624b8338ee5e0bbabe87c61957d0b2d

Build ID: 27

Status: âŒ CI test failed in Stage [CPU Build (Win64)].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7128/27/27/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7128/27/27/logs/cireport.log)",commit id build id status test stage build win report path link full path link,issue,positive,positive,positive,positive,positive,positive
1988018186,"> @frozenbugs How do I run the regression tests to ensure this PR is not slowing down the CPU layer_neighbor implementation?

Just merge the code, and the result will be send out tomorrow to you. If any unexpected happens, we can revert this PR.",run regression ensure implementation merge code result send tomorrow unexpected revert,issue,negative,positive,neutral,neutral,positive,positive
1987676639,"**inner_edge**

```
>>> import dgl
>>> g=dgl.load_graphs('/home/ubuntu/workspace/distgb_datasets/ogbn_products_noBalance/part0/graph.dgl')[0][0]
>>> g.edata['inner_edge'].sum()
tensor(60667142)
>>> import torch
>>> eids = torch.arange(60667142)
>>> u,v = g.find_edges(eids)
>>> g.ndata['inner_node'][v].sum()
tensor(60667142)
>>> g.ndata['inner_node'][u].sum()
tensor(58922912)

```",import tensor import torch tensor tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
1986885621,@frozenbugs How do I run the regression tests to ensure this PR is not slowing down the CPU layer_neighbor implementation?,run regression ensure implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
1986885120,"Commit ID: 869a9809c98b5595bb3127b417d5b994103960b3

Build ID: 2

Status: âŒ CI test failed in Stage [Regression Test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7205/2/2/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7205/2/2/logs/cireport.log)",commit id build id status test stage regression test report path link full path link,issue,negative,positive,positive,positive,positive,positive
1986846681,"Do you happen to have any updates on this?
I could not build it with 16GB of RAM (out of memory). I had to modify `make -j` (in `dgl_sparse/build.sh`, `graphbolt/build.sh` and `script/build_dgl.sh`) to `make -j n` where n is the number of jobs following cmake docs in [here](https://cmake.org/cmake/help/latest/manual/cmake.1.html#cmdoption-cmake-build-j), to reduce the memory consumptions coming from the high number of jobs.
I tried n=2 and the total memory usage on my device while building was 9GB.",happen could build ram memory modify make make number following reduce memory coming high number tried total memory usage device building,issue,negative,positive,neutral,neutral,positive,positive
1985304567,"Another issue is `prob` data are expected to be stored in `edge_attributes` of `FusedCSCSamplingGraph` while `prob` data is stored as feature data in `DistTensor` in `DistDGL`. One WAR is assign such data to `edge_attributes` before calling `g._sample_neighbors()`ï¼ˆ**both in client and server**). Though such assignment does not really involves tensor data movement, it's still hacky and assignment incurs overhead(at least call from python to c++). But such overhead could be mitigated if we assign at the beginning of sampler or dataloader instantiation. As each sampler process will do like this, this will result in race condition if multiple threads are sampling though it's not the case for now.

Another approach is to assign it to `FuseCSCSamplingGraph` during partition.

**WAR_0**
```
 # Assign prob to edge attributes if it is not None.
    if prob is not None:
        edge_attributes = g.edge_attributes
        if edge_attributes is None:
            edge_attributes = {}
        edge_attributes[""DIST_DGL_PROB""] = prob[0].to(torch.bool)
        g.edge_attributes = edge_attributes
        probs_name = ""DIST_DGL_PROB""
    else:
        probs_name = None

    subgraph = g._sample_neighbors(
        nodes, fanout, replace=replace, probs_name=probs_name, return_eids=return_eids
    )
```",another issue prob data prob data feature data one war assign data calling client server though assignment really tensor data movement still hacky assignment overhead least call python overhead could assign beginning sampler sampler process like result race condition multiple sampling though case another approach assign partition assign prob edge none prob none none prob else none,issue,negative,negative,neutral,neutral,negative,negative
1985280734,"In existing DistDGL, `sample_neighbors` in `graph_services.py` just fetch local partition(**includes inner edges only**) to `dgl.sampling.sample_neighbors()`. But one issue is `inner_edge` and `non-inner_edge`. Seems DGL sampling supports `len(prob) < g.num_edges()`.

**To be confirmed**

```
import dgl
import torch

g = dgl.rand_graph(100, 1000)
num_nodes = g.num_nodes()
num_edges = g.num_edges()

# length of prob should be the same as the number of edges ???
prob = torch.arange(num_edges - 10).to(torch.float32)

nodes = torch.arange(0, num_nodes)

sg = dgl.sampling.sample_neighbors(g, nodes, 2, prob=[prob])
print(sg)

'''
Graph(num_nodes=100, num_edges=200,
      ndata_schemes={}
      edata_schemes={'_ID': Scheme(shape=(), dtype=torch.int64)})
'''

```",fetch local partition inner one issue sampling prob confirmed import import torch length prob number prob prob print graph scheme,issue,negative,positive,positive,positive,positive,positive
1984110084,"Commit ID: None

Build ID: 10

Status: âŒ CI test failed in Stage [Declarative: Checkout SCM].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7193/10/10/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7193/10/10/logs/cireport.log)",commit id none build id status test stage declarative report path link full path link,issue,negative,positive,positive,positive,positive,positive
1982239937,This benchmark has already been incorporated into the regression test.,already incorporated regression test,issue,negative,neutral,neutral,neutral,neutral,neutral
1982217097,"Generally, deepwalk should be performed on a bidirected graph of ogbn-arxiv. To solve this problem, you can convert it to a bidirected graph by adding reverse edges.",generally graph solve problem convert graph reverse,issue,negative,positive,neutral,neutral,positive,positive
1981448103,"```
tensor([[     0,  52893,  14528,  ...,     -1,     -1,     -1],
        [     1, 141692, 100594,  ...,     -1,     -1,     -1],
        [     2, 119218,  16921,  ...,     -1,     -1,     -1],
        ...,
        [   125,  42653,    125,  ...,     -1,     -1,     -1],
        [   126, 116629,    126,  ..., 116629,    126, 116629],
        [   127,  45306,     -1,  ...,     -1,     -1,     -1]])
```
I ran your code and found the error occured for the sampled batch above. As shown in the matrix, too many random walk traces early stop due to no out edges (indicated by the -1s). -1 is not a valid index to get the node embedding, which results in the error.",tensor ran code found error batch shown matrix many random walk early stop due valid index get node error,issue,negative,negative,neutral,neutral,negative,negative
1981392178,"I also tried to get this example code working, this is what worked for me. 

After a lot of back and forth trying to match `python`,`pytorch` and `cuda` versions [1], the following steps worked for me. (It's easier to start with a new environment because there might be lots of conflicts going on with packages)
 
[1] - https://www.dgl.ai/pages/start.html

```bash
## Create new environment, use arbitrary name ""myenv"" that you prefer
conda create -n myenv python=3.11

## Activate environment
source activate myenv

## Install pytorch 2.2 
conda install pytorch==2.2.0 torchvision==0.17.0 torchaudio==2.2.0 pytorch-cuda=12.1 -c pytorch -c nvidia

## Install dgl which matches pytorch 2.2 and cuda 12.1 
conda install -c dglteam/label/cu121 dgl

## Add environment to jupyter kernel
conda install -c anaconda ipykernel -y
python -m ipykernel install --user --name=myenv

# install remaining things that dgl needs
pip install torchdata
pip install pandas
pip install pyyaml
pip install pydantic

```

> I tried another example, and the same error occurred.
> 
> ```python
> import torch.nn.functional as F
> import dgl
> from dgl.nn import GraphConv
> import torch.nn as nn
> import torch
> class Classifier(nn.Module):
>     def __init__(self, in_dim, out_dim):
>         super(Classifier, self).__init__()
>         self.conv1 = GraphConv(in_dim, out_dim,)
>     def forward(self, g, h):
>         # Apply graph convolution and activation.
>         h = F.relu(self.conv1(g, h))
>         return h
> src_ids = torch.tensor([2, 3, 4])
> dst_ids = torch.tensor([1, 2, 3])
> device = torch.device('cuda:0')
> g = dgl.graph((src_ids, dst_ids)).to(device)
> g = dgl.add_self_loop(g)
> x = torch.randn((5, 100)).to(device)
> model = Classifier(100, 20).to(device)
> model(g, x)
> ```

",also tried get example code working worked lot back forth trying match python following worked easier start new environment might lot going bash create new environment use arbitrary name prefer create activate environment source activate install install install install add environment kernel install anaconda python install user install need pip install pip install pip install pip install tried another example error python import import import import import torch class classifier self super classifier self forward self apply graph convolution activation return device device device model classifier device model,issue,positive,positive,neutral,neutral,positive,positive
1981371441,"As the provided google drive link doesn't contain a file named ""x_in.npy"", I assume it is replaced with the file ""node_feat.npy"". I found that the matrix is in shape (2, 3), which is inconsistent with the graph size.
```
x_in = np.load(""node_feat.npy"")
print(x_in.shape). # (2, 3)
```
Could you check your data uploaded and also the shape of your local x_in matrix?

I didn't quite get the second question. What's the purpose of such periodic saving?",provided drive link contain file assume file found matrix shape inconsistent graph size print could check data also shape local matrix quite get second question purpose periodic saving,issue,negative,neutral,neutral,neutral,neutral,neutral
1978013656,"I was able to move the coo conversion into the model definition, making it a bit simpler to use. Since #7188 was merged, it is okay to do that now because torch compile still works even when `gb.expand_indptr` is being used in model forward. @frozenbugs ",able move coo conversion model definition making bit simpler use since torch compile still work even used model forward,issue,negative,positive,positive,positive,positive,positive
1976410225,"Another severe issue(at least bothers me a lot):
The graph has to be saved and loaded, even if it already exists in my PC memory:

```
dgl.save_graphs(""./graph.bin"", graph)
np.save(""./x_in.npy"", x_in.cpu().numpy())
np.save(""./area.npy"", area.cpu().numpy().reshape(-1, 1))
graph = dgl.load_graphs(""./graph.bin"")[0][0]
```

Each epoch of my training(500 graphs) will cost a huge IO time and enhance so little over my model. ",another severe issue least lot graph saved loaded even already memory graph graph epoch training cost huge io time enhance little model,issue,negative,negative,neutral,neutral,negative,negative
1976393350,"assign type to be None will jump over this bug
```python
type=""float32"" # not work
type= None # it works
```
",assign type none jump bug python float work none work,issue,negative,neutral,neutral,neutral,neutral,neutral
1975792014,"@Rhett-Ying Can we add torch 2.2 to the CI also so that the code that is enabled only for 2.2 can be tested? For now, I tested locally with a docker container that has `2.2.0a0+81ea7a4`.",add torch also code tested tested locally docker container,issue,negative,neutral,neutral,neutral,neutral,neutral
1975786807,@frozenbugs got the CI to pass. I think it is ready to review.,got pas think ready review,issue,negative,positive,positive,positive,positive,positive
1975669207,"> > > @mfbalin can you fix the build?
> > 
> > 
> > I can not, we need to start depending on Torch 2.2 instead of 2.0. The CI needs to be updated.
> 
> We are deprecating Torch 1.3 (oldest Torch version: 2.0) in DGL 2.1, likely we will not move to 2.2 in near future. If it requires 2.2, let's table the change until then?

Also, it may be possible to still get this PR through by adding version checks on certain parts of the code. I will see if it is easily doable. Then, maybe we won't have to wait that long.",fix build need start depending torch instead need torch torch version likely move near future let table change also may possible still get version certain code see easily doable maybe wo wait long,issue,positive,positive,neutral,neutral,positive,positive
1975668188,"> > > @mfbalin can you fix the build?
> > 
> > 
> > I can not, we need to start depending on Torch 2.2 instead of 2.0. The CI needs to be updated.
> 
> We are deprecating Torch 1.3 (oldest Torch version: 2.0) in DGL 2.1, likely we will not move to 2.2 in near future. If it requires 2.2, let's table the change until then?

Sure. Which release of DGL do you think will move to 2.2 do you think?",fix build need start depending torch instead need torch torch version likely move near future let table change sure release think move think,issue,negative,positive,positive,positive,positive,positive
1975665977,"> > @mfbalin can you fix the build?
> 
> I can not, we need to start depending on Torch 2.2 instead of 2.0. The CI needs to be updated.

We are deprecating Torch 1.3 (oldest Torch version: 2.0) in DGL 2.1, likely we will not move to 2.2 in near future. If it requires 2.2, let's table the change until then?",fix build need start depending torch instead need torch torch version likely move near future let table change,issue,negative,positive,neutral,neutral,positive,positive
1975659560,"> @mfbalin can you fix the build?

I can not, we need to start depending on Torch 2.2 instead of 2.0. The CI needs to be updated.",fix build need start depending torch instead need,issue,negative,neutral,neutral,neutral,neutral,neutral
1975265558,I think we should also update the information on the documentation and getting started webpages about the new requirements.,think also update information documentation getting new,issue,negative,positive,positive,positive,positive,positive
1974874946,"There is an issue, I hope pytorch developers can help fix it: https://github.com/pytorch/pytorch/issues/121080",issue hope help fix,issue,positive,neutral,neutral,neutral,neutral,neutral
1973524663,"I see what you mean, having taken a second look at the PyTorch instructions. However running `pip install torch` still works, albeit I think the wheels being put on PyPI default to being CUDA 12.1. For packaging I would've thought a CPU target as the default would make more sense, but I can understand their reason for doing so. ðŸ¤·ðŸ¼â€â™‚ï¸ 

For DGL, however, is installation from PyPI just being dropped completely? Like I said, I found it a good user experience to be able to `pip install dgl` and just have a working version to start development out of the box not needing to worry about accelerators or where to source the wheels from. I'd ask the DGL team to consider maintaining the PyPI distribution, even if it's just CPU only.

A potential workaround for `pyproject.toml` is to point to the exact wheel, but it means that I have to pin the package to a specifiy Python version and distribution - that's also not ideal IMHO.

e.g. 

```toml
dependencies = [
   ""torch"",  # installs from PyPI, but just adds CUDA bloat if you're not using CUDA which I can live with because it works
   ""dgl==2.0.0"",  # doesn't work because there are no >1.1.3 wheels on PyPI
   ""dgl @ https://data.dgl.ai/wheels/dgl-2.0.0-cp310-cp310-manylinux1_x86_64.whl"",   # works, but forces Python 3.10
]
```

At the end of the day I'm aiming to have a complete out of the box experience, and making the most performant configuration optional for the end-user - they can choose to rebuild DGL from source with whatever libraries they want, but as a package maintainer I'm more interested in providing an environment that at least works.",see mean taken second look however running pip install torch still work albeit think put default would thought target default would make sense understand reason however installation completely like said found good user experience able pip install working version start development box needing worry source ask team consider distribution even potential point exact wheel pin package python version distribution also ideal torch bloat live work work work python end day aiming complete box experience making performant configuration optional choose rebuild source whatever want package maintainer interested providing environment least work,issue,positive,positive,positive,positive,positive,positive
1970930393,"Sweet, thanks for the response! FYI, the way I incorporated edge features into the model is just by using `u_dot_e` in the `DotProductPredictor` and it worked just fine! ðŸ‘ðŸ» ",sweet thanks response way incorporated edge model worked fine,issue,positive,positive,positive,positive,positive,positive
1970278738,DGL keeps consistent with PyTorch and cuda 12.1 is the latest version that torch supports.,consistent latest version torch,issue,negative,positive,positive,positive,positive,positive
1970275854,please fix the lint error,please fix lint error,issue,negative,neutral,neutral,neutral,neutral,neutral
1970261282,"> but on the other hand it makes entire model unnecessarily slower as much more calculations have to be done

I'm curious how to avoid this if graph level features are introduced to the message passing abstraction? My understanding is that it may require dedicated GPU kernels. Remember each graph in a batch may have different numbers of nodes and edges, so it is not like a normal dense broadcasting.
",hand entire model unnecessarily much done curious avoid graph level message passing abstraction understanding may require remember graph batch may different like normal dense,issue,positive,positive,neutral,neutral,positive,positive
1970255301,"I replace my pytorch version with 2.1and it worked. Thank you



å‘è‡ªæˆ‘çš„iPhone


------------------ Original ------------------
From: Minjie Wang ***@***.***&gt;
Date: Thu,Feb 29,2024 9:52 AM
To: dmlc/dgl ***@***.***&gt;
Cc: twdream ***@***.***&gt;, Author ***@***.***&gt;
Subject: Re: [dmlc/dgl] GraphBolt (Issue #7157)





 
Hi, could you please follow the bug report template to provide more information? Such as your DGL version, install methods, OS, etc?
 
â€”
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you authored the thread.Message ID: ***@***.***&gt;",replace version worked thank original wang date author subject issue hi could please follow bug report template provide information version install o reply directly view id,issue,positive,positive,positive,positive,positive,positive
1970254202,"Hi @laserkelvin , we followed the practice of PyTorch to host different packages for different CUDA versions. I wonder how did you resolve the problem for PyTorch?",hi practice host different different wonder resolve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1970250129,"Hi, could you please follow the bug report template to provide more information? Such as your DGL version, install methods, OS, etc?",hi could please follow bug report template provide information version install o,issue,negative,neutral,neutral,neutral,neutral,neutral
1970248122,"You are right. The synthetic edge features are not used in the later modeling. The complexity here is that there are multiple ways to incorporate edge features. For example, one option is to change the `MLPPredictor` as followings:

```python
class MLPPredictor(nn.Module):
    def __init__(self, in_features, out_classes):
        super().__init__()
        self.W = nn.Linear(in_features * 2, out_classes)

    def apply_edges(self, edges):
        h_u = edges.src['h']
        h_v = edges.dst['h']
        h_e = edges.data['h']
        score = self.W(torch.cat([h_u, h_v, h_e], 1))  # Concatenate edge and node embeddings
        return {'score': score}

    def forward(self, graph, h_node, h_edge):
        with graph.local_scope():
            graph.ndata['h'] = h_node
            graph.edata['h'] = h_edge   # Attach edge embeddings to graph.
            graph.apply_edges(self.apply_edges)
            return graph.edata['score']
```

One could also make similar modification to DotPredictor or message passing. I agree that we should demonstrate at least one option. Putting this as an item to fix.",right synthetic edge used later modeling complexity multiple way incorporate edge example one option change python class self super self score concatenate edge node return score forward self graph attach edge graph return one could also make similar modification message passing agree demonstrate least one option item fix,issue,positive,positive,neutral,neutral,positive,positive
1970039719,"Also, for the mag240M dataset, if we also provide the preprocessed version, can we perform the following type casts?
1. `indices`, `node_type_offset`, `train_set`, `validation_set`, `test_set` into `int32`.
2. `type_per_edge` into `uint8`.

We don't need to do anything for `all_nodes_set` because it automatically gets its dtype from `graph.indices`.",also also provide version perform following type index need anything automatically,issue,negative,neutral,neutral,neutral,neutral,neutral
1970021194,"For papers100M, it says that the data is already preprocessed. That is why it does not perform the required type casts, causing an error.

```
The dataset is already preprocessed.
```

For products dataset, however, it performs the preprocessing step when we first download it.
```
Extracting file to datasets
Start to preprocess the on-disk dataset.
Finish preprocessing the on-disk dataset.
```

Why is there such a discrepancy between these two datasets? I am guessing that we want to take the burden of preprocessing from the user by providing the preprocessed versions of these larger datasets to the users.

Also, after downloading papers, we get the following graph returned:

```
FusedCSCSamplingGraph(csc_indptr=tensor([         0,          1,          9,  ..., 3228124709, 3228124710,
                              3228124712]),
                      indices=tensor([102309412,   5808518,   6609397,  ...,  92367769,  59629722,
                               95195371]),
                      total_num_nodes=111059956, num_edges=3228124712,
                      node_attributes={},
                      edge_attributes={},)
```

We get an error because the indices array is not using `int32` but train_set is is using `int32`.

So we need to modify `papers100M` dataset and cast its `indices` array of the graph into `int32`.

@caojy1998 ",data already perform type causing error already however step first file start finish discrepancy two guessing want take burden user providing also get following graph returned get error index array need modify cast index array graph,issue,negative,positive,positive,positive,positive,positive
1969559578,"@Skeleton003 @frozenbugs added some tests, could you check if things are in-order?

@Rhett-Ying If you could provide a look as well, that would be great. I really want to land this PR for DGL 2.1.",skeleton added could check could provide look well would great really want land,issue,positive,positive,positive,positive,positive,positive
1969315999,"> > If we are moving features to the GPU, then why not do the same for the graph as well; as usually, the graph takes even less space than the features? @frozenbugs @Rhett-Ying
> 
> Leaving graph on CPU is consistent with PyG canonical example?

Then we could still leave it on CPU and pin its memory? I also tested and saw no performance difference between pinning features vs moving them to the GPU. @RamonZhou what performance difference do you see between pinning features vs moving them to the GPU? I believe we can simply pin both the graph and the features and the performance should already be better than PyG original example. Compared to PyG, we can advertise that we are using much less GPU memory because we use pinned system memory while being faster.",moving graph well usually graph even le space leaving graph consistent canonical example could still leave pin memory also tested saw performance difference pinning moving performance difference see pinning moving believe simply pin graph performance already better original example advertise much le memory use pinned system memory faster,issue,positive,positive,positive,positive,positive,positive
1968564096,"> If we are moving features to the GPU, then why not do the same for the graph as well; as usually, the graph takes even less space than the features? @frozenbugs @Rhett-Ying

Leaving graph on CPU is consistent with PyG canonical example?",moving graph well usually graph even le space leaving graph consistent canonical example,issue,negative,neutral,neutral,neutral,neutral,neutral
1968344952,"> > I have changed the indice dtype to int32.
> 
> Now, we are getting an error because train_set etc. is not in int32. Will need #7127 to be merged to resolve the error.

OK, we can wait for that PR to see if there are further questions.",getting error need resolve error wait see,issue,negative,neutral,neutral,neutral,neutral,neutral
1968318921,"@Skeleton003 I am done making changes. Thank you for letting me collaborate with you on this PR. Feel free to take over and make any changes you deem necessary.

@frozenbugs This PR could be reviewed and landed as it is or the `type_per_edge` changes could be changed to another PR if you so desire.",skeleton done making thank collaborate feel free take make deem necessary could landed could another desire,issue,positive,positive,positive,positive,positive,positive
1968315465,The R-GCN example works with the current state of the PR.,example work current state,issue,negative,neutral,neutral,neutral,neutral,neutral
1968296789,"> > > > However, if we move the changes to a standalone function, preprocess memory requirements will increase. @frozenbugs
> > > 
> > > 
> > > You're right, I didnt consider memory requirement. But it seems only `type_per_edge` will be affected?
> > 
> > 
> > Oh, the memory usage of not only `type_per_edge`, but the whole graph will increase. So a standalone function may not be the best solution. Let's modify `_graph_data_to_fused_csc_sampling_graph` directly.
> 
> I am pushing my changes shortly before ending the day.

Thank you for your effort!",however move function memory increase right didnt consider memory requirement affected oh memory usage whole graph increase function may best solution let modify directly pushing shortly ending day thank effort,issue,positive,positive,positive,positive,positive,positive
1968293318,"> I have changed the indice dtype to int32.

Now, we are getting an error because train_set etc. is not in int32. Will need #7127 to be merged to resolve the error.",getting error need resolve error,issue,negative,neutral,neutral,neutral,neutral,neutral
1968291794,"> > > However, if we move the changes to a standalone function, preprocess memory requirements will increase. @frozenbugs
> > 
> > 
> > You're right, I didnt consider memory requirement. But it seems only `type_per_edge` will be affected?
> 
> Oh, the memory usage of not only `type_per_edge`, but the whole graph will increase. So a standalone function may not be the best solution. Let's modify `_graph_data_to_fused_csc_sampling_graph` directly.

I am pushing my changes shortly before ending the day.",however move function memory increase right didnt consider memory requirement affected oh memory usage whole graph increase function may best solution let modify directly pushing shortly ending day,issue,positive,positive,positive,positive,positive,positive
1968290841,"> > However, if we move the changes to a standalone function, preprocess memory requirements will increase. @frozenbugs
> 
> You're right, I didnt consider memory requirement. But it seems only `type_per_edge` will be affected?

Oh, the memory usage of not only `type_per_edge`, but the whole graph will increase. So a standalone function may not be the best solution. Let's modify `_graph_data_to_fused_csc_sampling_graph` directly.",however move function memory increase right didnt consider memory requirement affected oh memory usage whole graph increase function may best solution let modify directly,issue,positive,positive,positive,positive,positive,positive
1968279391,"> However, if we move the changes to a standalone function, preprocess memory requirements will increase. @frozenbugs

@Skeleton003 what do you think about potential increase in preprocess memory requirements?",however move function memory increase skeleton think potential increase memory,issue,positive,neutral,neutral,neutral,neutral,neutral
1968279338,"> However, if we move the changes to a standalone function, preprocess memory requirements will increase. @frozenbugs

You're right, I didnt consider memory requirement. But it seems only `type_per_edge` will be affected?",however move function memory increase right didnt consider memory requirement affected,issue,negative,positive,positive,positive,positive,positive
1968277923,@mfbalin  Please feel free to push your changes to this branch. And I think a standalone function is good.,please feel free push branch think function good,issue,positive,positive,positive,positive,positive,positive
1968277725,"However, if we move the changes to a standalone function, preprocess memory requirements will increase. @frozenbugs ",however move function memory increase,issue,negative,neutral,neutral,neutral,neutral,neutral
1968275449,"Or is it fine to protect the changes in `_graph_data_to_fused_csc_sampling_graph` with a flag called `cast_into_smallest_dtype`, and keep the current code instead of having a new `cast_sampling_graph_to_smallest_dtypes` as above?",fine protect flag keep current code instead new,issue,positive,positive,positive,positive,positive,positive
1968274562,"Should we make a standalone function to do the casting after returning from `_graph_data_to_fused_csc_sampling_graph`?
```python
def cast_sampling_graph_to_smallest_dtypes(g):
    """"""Modifies g in place and casts its tensors to smallest possible dtypes.""""""
    if g.total_num_nodes <= torch.iinfo(torch.int32).max:
        g.indices = g.indices.int()
    if g.total_num_edges <= torch.iinfo(torch.int32).max:
        g.csc_indptr = g.csc_indptr.int()
        g.edge_attributes[ORIGINAL_EDGE_ID] = g.edge_attributes[ORIGINAL_EDGE_ID].int()
    
    dtypes = [torch.uint8, torch.int16, torch.int32, torch.int64]
    dtype_maxes = [torch.iinfo(dtype).max for dtype in dtypes]
    dtype_id = bisect.bisect_left(dtype_maxes, len(g.edge_type_to_id) - 1)
    etype_dtype = dtypes[dtype_id]
    g.type_per_edge = g.type_per_edge.to(etype_dtype)
```",make function casting python place possible,issue,negative,neutral,neutral,neutral,neutral,neutral
1968264360,"> > @Skeleton003 When do you think we can do the requested changes by @frozenbugs? I checked and saw that `_graph_data_to_fused_csc_sampling_graph` is used only by `preprocess_ondisk_dataset` if I am not mistaken. So, why do we need to move the changes from one function to another?
> 
> Yes, `_graph_data_to_fused_csc_sampling_graph` is used by `preprocess_ondisk_dataset` only. I agree to add a parameter(flag) to control whether to convert the data type, and I will do it if so does @frozenbugs .

I am quickly working on what I thought Steve wanted. Can push my changes in half an hour if that is okay with you. Then, you can take over and make any necessary modifications. Does that work? @Skeleton003",skeleton think checked saw used mistaken need move one function another yes used agree add parameter flag control whether convert data type quickly working thought push half hour take make necessary work skeleton,issue,negative,positive,neutral,neutral,positive,positive
1968260339,"> @Skeleton003 When do you think we can do the requested changes by @frozenbugs? I checked and saw that `_graph_data_to_fused_csc_sampling_graph` is used only by `preprocess_ondisk_dataset` if I am not mistaken. So, why do we need to move the changes from one function to another?

Yes, `_graph_data_to_fused_csc_sampling_graph` is used by `preprocess_ondisk_dataset` only. I agree to add a parameter(flag) to control whether to convert the data type, and I will do it if so does @frozenbugs .",skeleton think checked saw used mistaken need move one function another yes used agree add parameter flag control whether convert data type,issue,negative,neutral,neutral,neutral,neutral,neutral
1968233718,"@Skeleton003 When do you think we can do the requested changes by @frozenbugs? I checked and saw that `_graph_data_to_fused_csc_sampling_graph` is used only by `preprocess_ondisk_dataset` if I am not mistaken. So, why do we need to move the changes from one function to another?",skeleton think checked saw used mistaken need move one function another,issue,negative,neutral,neutral,neutral,neutral,neutral
1968220009,"If we are moving features to the GPU, then why not do the same for the graph as well; as usually, the graph takes even less space than the features? @frozenbugs @Rhett-Ying ",moving graph well usually graph even le space,issue,negative,negative,negative,negative,negative,negative
1968186444,"PyG original example uses different fanouts compared to this example:
https://github.com/pyg-team/pytorch_geometric/blob/25b2f208e671eeec285bfafa2e246ea0a234b312/examples/ogbn_products_sage.py#L20-L28

Using `15, 10, 5` will be much faster than `10, 10, 10`.",original example different example much faster,issue,negative,positive,positive,positive,positive,positive
1968164453,"> @RamonZhou It might help improve end-to-end performance if we move the `copy_to` operation so that it is before `fetch_feature` but after `sample_neighbor` as discussed in #7005. We will need to pin the features in this case. I see close to 2x speedup just by doing this.
> 
> Another thing is to imitate the inference function in our official node_classification example so that we use the dataloader's functionality to load the features. Below, we update the featurestore to be the next layer's features, and no manual feature fetch indexing operation needed.
> 
> https://github.com/dmlc/dgl/blob/dbafbe41599b48a66e14dba4589ad257d32155ac/examples/sampling/graphbolt/node_classification.py#L199-L227

This suggestion can probably improve the inference performance but here we hope not to modify the PyG model too much because if PyG users want to use our GB dataloader, they won't want to do much modification to their original model.",might help improve performance move operation need pin case see close another thing imitate inference function official example use functionality load update next layer manual feature fetch indexing operation suggestion probably improve inference performance hope modify model much want use wo want much modification original model,issue,positive,positive,positive,positive,positive,positive
1968159678,"Proposed modification to to_pyg_data. Note that it only works when fanout values are identical across layers.
```python
    def to_pyg_data(self):
        """"""Construct a PyG Data from `MiniBatch`. This function only supports
        node classification task on a homogeneous graph and the number of
        features cannot be more than one.
        """"""
        from torch_geometric.data import Data

        if self.sampled_subgraphs is None:
            edge_index = None
        else:
            col_nodes = []
            row_nodes = []
            prev_num_edges = 0
            for subgraph in reversed(self.sampled_subgraphs):
                if subgraph is None:
                    continue
                sampled_csc = subgraph.sampled_csc
                indptr = sampled_csc.indptr
                indices = sampled_csc.indices
                expanded_indptr = expand_indptr(
                    indptr, dtype=indices.dtype, output_size=len(indices)
                )
                # Drop the edges sampled for dst nodes in later layers like PyG.
                my_slice = slice(prev_num_edges, expanded_indptr.size(0))
                prev_num_edges = indices.size(0)
                col_nodes.append(expanded_indptr[my_slice])
                row_nodes.append(indices[my_slice])
            col_nodes = torch.cat(col_nodes)
            row_nodes = torch.cat(row_nodes)
            edge_index = torch.stack((row_nodes, col_nodes))
```",modification note work identical across python self construct data function node classification task homogeneous graph number import data none none else reversed none continue index index drop later like slice index,issue,negative,neutral,neutral,neutral,neutral,neutral
1968058536,"> @Skeleton003 is the work on this PR finished? If so, we can get a review and merge this PR. We will need the changes in this PR so that we can update the runtime numbers in the release blog.
> 
> @frozenbugs @Rhett-Ying @TristonC

@mfbalin We are going to discuss about this in the meeting in 1 hour.",skeleton work finished get review merge need update release going discus meeting hour,issue,negative,neutral,neutral,neutral,neutral,neutral
1967377796,"@Skeleton003 is the work on this PR finished? If so, we can get a review and merge this PR. We will need the changes in this PR so that we can update the runtime numbers in the release blog.

@frozenbugs @Rhett-Ying @TristonC ",skeleton work finished get review merge need update release,issue,negative,neutral,neutral,neutral,neutral,neutral
1966157443,"It would be more impactful if you can add an example with graphbolt, our new dataloading package. graphbolt example: https://github.com/dmlc/dgl/blob/master/examples/sampling/graphbolt/node_classification.py",would add example new package example,issue,negative,positive,positive,positive,positive,positive
1966027369,"I am not sure, if this is not urgent, let's table it.",sure urgent let table,issue,negative,positive,positive,positive,positive,positive
1965764831,"@RamonZhou It might help improve end-to-end performance if we move the `copy_to` operation so that it is before `fetch_feature` but after `sample_neighbor` as discussed in #7005. We will need to pin the features in this case. I see close to 2x speedup just by doing this.

Another thing is to imitate the inference function in our official node_classification example so that we use the dataloader's functionality to load the features. Below, we update the featurestore to be the next layer's features, and no manual feature fetch indexing operation needed.
https://github.com/dmlc/dgl/blob/dbafbe41599b48a66e14dba4589ad257d32155ac/examples/sampling/graphbolt/node_classification.py#L199-L227",might help improve performance move operation need pin case see close another thing imitate inference function official example use functionality load update next layer manual feature fetch indexing operation,issue,positive,neutral,neutral,neutral,neutral,neutral
1965739487,"> > > > @mfbalin please take a look at https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/impl/ondisk_dataset.py#L824. OnDiskDataset's `_init_all_nodes_set` makes use of `num_nodes` API of `FusedCSCSamplingGraph` to generate `all_nodes_set`. Could you please also modify the return type of `FusedCSCSamplingGraph.num_nodes` from `Union[int, Dict[str, int]]` to `Union[torch.Tensor, Dict[str, torch.Tensor]]` and test if your changes work correctly? Many thanks.
> > > 
> > > 
> > > @Skeleton003 I think this modification needs to be done in #7127. Otherwise, I will have to re-do all the changes in your PR here. Can you incorporate the `_init_all_nodes_set` modification in #7127? Or if you wouldn't mind, I can push to your branch there.
> > 
> > 
> > Sorry for my late reply due to jet lag. Of course I can modify the `_init_all_nodes_set` in #7127 . thank u
> 
> @Skeleton003 Please pardon me, I couldn't wait and pushed my changes to your PR. Hope it is okay.

It's OK! Thank you for fixxing the bugs!",please take look use generate could please also modify return type union union test work correctly many thanks skeleton think modification need done otherwise incorporate modification would mind push branch sorry late reply due jet lag course modify thank skeleton please pardon could wait hope thank,issue,positive,negative,neutral,neutral,negative,negative
1965736269,"> > > @mfbalin please take a look at https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/impl/ondisk_dataset.py#L824. OnDiskDataset's `_init_all_nodes_set` makes use of `num_nodes` API of `FusedCSCSamplingGraph` to generate `all_nodes_set`. Could you please also modify the return type of `FusedCSCSamplingGraph.num_nodes` from `Union[int, Dict[str, int]]` to `Union[torch.Tensor, Dict[str, torch.Tensor]]` and test if your changes work correctly? Many thanks.
> > 
> > 
> > @Skeleton003 I think this modification needs to be done in #7127. Otherwise, I will have to re-do all the changes in your PR here. Can you incorporate the `_init_all_nodes_set` modification in #7127? Or if you wouldn't mind, I can push to your branch there.
> 
> Sorry for my late reply due to jet lag. Of course I can modify the `_init_all_nodes_set` in #7127 . thank u

@Skeleton003 Please pardon me, I couldn't wait and pushed my changes to your PR. Hope it is okay.",please take look use generate could please also modify return type union union test work correctly many thanks skeleton think modification need done otherwise incorporate modification would mind push branch sorry late reply due jet lag course modify thank skeleton please pardon could wait hope,issue,positive,negative,neutral,neutral,negative,negative
1965734804,"> > @mfbalin please take a look at https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/impl/ondisk_dataset.py#L824. OnDiskDataset's `_init_all_nodes_set` makes use of `num_nodes` API of `FusedCSCSamplingGraph` to generate `all_nodes_set`. Could you please also modify the return type of `FusedCSCSamplingGraph.num_nodes` from `Union[int, Dict[str, int]]` to `Union[torch.Tensor, Dict[str, torch.Tensor]]` and test if your changes work correctly? Many thanks.
> 
> @Skeleton003 I think this modification needs to be done in #7127. Otherwise, I will have to re-do all the changes in your PR here. Can you incorporate the `_init_all_nodes_set` modification in #7127? Or if you wouldn't mind, I can push to your branch there.

Sorry for my late reply due to jet lag. Of course I can modify the `_init_all_nodes_set` in #7127 . thank u",please take look use generate could please also modify return type union union test work correctly many thanks skeleton think modification need done otherwise incorporate modification would mind push branch sorry late reply due jet lag course modify thank,issue,positive,negative,neutral,neutral,negative,negative
1965709246,"There were some changes in master, we should update the branch and resolve any potential issue w.r.t. dtype use of int32.

Note: There will be after #7127 is merged.",master update branch resolve potential issue use note,issue,negative,neutral,neutral,neutral,neutral,neutral
1965558794,"There seems to be a bug in the link_prediction dataloading codepath when we switch the dtype to int. I am debugging it. I tested the current code with a patch in the link prediction example where I cast the indices and the TVT sets back to int64 and the accuracy issue is resolved. This indicates that GraphBolt link prediction code path most likely has a bug.

@Skeleton003 we can work on it together. Could you review the latest state of the PR and see if there is anything out of place? Otherwise, we will need to debug `quickstart/link_prediction.py` example.

@Rhett-Ying do you have any insight what the problem might be?",bug switch tested current code patch link prediction example cast index back accuracy issue resolved link prediction code path likely bug skeleton work together could review latest state see anything place otherwise need example insight problem might,issue,negative,positive,positive,positive,positive,positive
1965537093,"@frozenbugs : Sorry, I have no idea what is causing this problem. This is what I see in the debugger:
```
(Pdb) l
 31                 # Detach the output, which then allows discarding the intermediary results
 32                 outputs = ctx.fn(*x).detach_()
 33  
 34             # clear memory of input node features
 35             import pdb; pdb.set_trace()
 36  ->         inputs[1].untyped_storage().resize_(0)
 37  
 38             # store for backward pass
 39             ctx.inputs = [inputs]
 40             ctx.outputs = [outputs]
 41  
(Pdb) type(inputs[1])
<class 'torch.Tensor'>
(Pdb) hasattr(inputs[1], ""untyped_storage"")
True
(Pdb) 
```
The only reason I can think of is different versions of Python. You are using Python3.7:
```
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py:1194: in _call_impl
    return forward_call(*input, **kwargs)
``` 
and in our container, we are using Python3.10
```
(Pdb) u
> /usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py(1511)_wrapped_call_impl()
-> return self._call_impl(*args, **kwargs)
```
BTW, perhaps the versions of the â€œtorchâ€ are also different. It's what we are using:
```
root@ea1fb332897e:/opt/dgl/qa/L0_python_unittests# pip list | grep torch
pytorch-quantization      2.1.2
torch                     2.3.0a0+ebedce2
torch-tensorrt            2.3.0a0
torchdata                 0.7.1a0
torchmetrics              1.3.1
torchtext                 0.17.0a0
torchvision               0.18.0a0
```
",sorry idea causing problem see detach output intermediary clear memory input node import store backward pas type class true reason think different python python return input container python return perhaps torch also different root pip list torch torch,issue,negative,negative,neutral,neutral,negative,negative
1965504938,"I can't find out why the test is still failing. The quickstart link_prediction example test is failing due to low accuracy, %98 normally vs %60 with this PR.",ca find test still failing example test failing due low accuracy normally,issue,negative,positive,neutral,neutral,positive,positive
1965446055,"> Can you separate out the tutorial part to another PR? For the example, we can merge directly as long as it is runnable with concrete readme.

No problem. I have removed the tutorial from this pull request, and created another one here: https://github.com/dmlc/dgl/pull/7155",separate tutorial part another example merge directly long runnable concrete problem removed tutorial pull request another one,issue,negative,positive,neutral,neutral,positive,positive
1964819950,@Skeleton003 incorporated your suggestion from #7147 here. The tests should hopefully pass now. Could you check if things look good?,skeleton incorporated suggestion hopefully pas could check look good,issue,positive,positive,positive,positive,positive,positive
1964480158,"> @mfbalin please take a look at https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/impl/ondisk_dataset.py#L824. OnDiskDataset's `_init_all_nodes_set` makes use of `num_nodes` API of `FusedCSCSamplingGraph` to generate `all_nodes_set`. Could you please also modify the return type of `FusedCSCSamplingGraph.num_nodes` from `Union[int, Dict[str, int]]` to `Union[torch.Tensor, Dict[str, torch.Tensor]]` and test if your changes work correctly? Many thanks.

@Skeleton003 I think this modification needs to be done in #7127. Otherwise, I will have to re-do all the changes in your PR here. Can you incorporate the `_init_all_nodes_set` modification in #7127? Or if you wouldn't mind, I can push to your branch there.",please take look use generate could please also modify return type union union test work correctly many thanks skeleton think modification need done otherwise incorporate modification would mind push branch,issue,positive,positive,positive,positive,positive,positive
1964345902,"> ```
> The main culprit is the use of torch.nonzero causing a CPU GPU synchronization to read the size of the nonzero ids each time it is called.
> ```
> 
> @mfbalin The direct cause of sync is the tensor data that `torch.nonzero` operates on is not on GPU side while the `sampled_csc` is targeted on GPU?

No, the operation happens on GPU. The reason is that nonzero checks if tensor elements are nonzero, however it is unknown how many will be nonzero. This information is needed on CPU side to allocate output tensor so there is a GPU CPU synchronization.

Calling nonzero for each etype in the graph makes this issue much worse, each time adding a fixed but really high overhead.",main culprit use causing synchronization read size nonzero time direct cause sync tensor data side targeted operation reason nonzero tensor nonzero however unknown many nonzero information side allocate output tensor synchronization calling nonzero graph issue much worse time fixed really high overhead,issue,negative,positive,neutral,neutral,positive,positive
1963665503,"> > > > _init_all_nodes_set
> > > 
> > > 
> > > Why do we need to change _init_all_nodes_set?
> > 
> > 
> > Please take a kind look at the [Description](https://github.com/dmlc/dgl/pull/7147#issue-2151742994). The purpose of this PR is to generate `all_nodes_set` with a specific dtype, and this purpose cannot be achieved if neither `FusedCSCSamplingGraph.num_nodes` nor `OnDiskDataset._init_all_nodes_set` is changed, because currently `FusedCSCSamplingGraph.num_nodes` always returns `Union[int, Dict[str, int]]` and `ItemSet` cannot judge the dtype of an `int`.
> 
> How the dtype should be decided? By external users or depend on any attribute of graph in _init_all_nodes_set?

Depends on `graph.indices.dtype`.",need change please take kind look description purpose generate specific purpose neither currently always union judge decided external depend attribute graph,issue,positive,positive,positive,positive,positive,positive
1963631875,"> > _init_all_nodes_set
> 
> Why do we need to change _init_all_nodes_set?

Please take a kind look at the [Description](https://github.com/dmlc/dgl/pull/7147#issue-2151742994). The purpose of this PR is to generate `all_nodes_set` with a specific dtype, and this purpose cannot be achieved if neither `FusedCSCSamplingGraph.num_nodes` nor `OnDiskDataset._init_all_nodes_set` is changed, because currently `FusedCSCSamplingGraph.num_nodes` always returns `Union[int, Dict[str, int]]` and `ItemSet` cannot judge the dtype of an `int`.",need change please take kind look description purpose generate specific purpose neither currently always union judge,issue,positive,positive,positive,positive,positive,positive
1963624669,"Can you separate out the tutorial part to another PR? For the example, we can merge directly as long as it is runnable with concrete readme.",separate tutorial part another example merge directly long runnable concrete,issue,negative,positive,neutral,neutral,positive,positive
1963615825,"@frozenbugs The io_uring library needs support of linux kernel, which I think maybe the reason why it cannot pass the build test in windows? ",library need support kernel think maybe reason pas build test,issue,negative,neutral,neutral,neutral,neutral,neutral
1963591644,"> > @mfbalin please take a look at https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/impl/ondisk_dataset.py#L824. OnDiskDataset's `_init_all_nodes_set` makes use of `num_nodes` API of `FusedCSCSamplingGraph` to generate `all_nodes_set`. Could you please also modify the return type of `FusedCSCSamplingGraph.num_nodes` from `Union[int, Dict[str, int]]` to `Union[torch.Tensor, Dict[str, torch.Tensor]]` and test if your changes work correctly? Many thanks.
> 
> I don't think we need to change `num_nodes` return type to Tensor, int should be fine.

You're right. So what is supposed to be modified is `OnDiskDataset._init_all_nodes_set`.",please take look use generate could please also modify return type union union test work correctly many thanks think need change return type tensor fine right supposed,issue,positive,positive,positive,positive,positive,positive
1963578434,"> @mfbalin please take a look at https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/impl/ondisk_dataset.py#L824. OnDiskDataset's `_init_all_nodes_set` makes use of `num_nodes` API of `FusedCSCSamplingGraph` to generate `all_nodes_set`. Could you please also modify the return type of `FusedCSCSamplingGraph.num_nodes` from `Union[int, Dict[str, int]]` to `Union[torch.Tensor, Dict[str, torch.Tensor]]` and test if your changes work correctly? Many thanks.

I don't think we need to change `num_nodes` return type to Tensor, int should be fine.",please take look use generate could please also modify return type union union test work correctly many thanks think need change return type tensor fine,issue,positive,positive,positive,positive,positive,positive
1963551843,"```
The main culprit is the use of torch.nonzero causing a CPU GPU synchronization to read the size of the nonzero ids each time it is called.
```
@mfbalin 
The direct cause of sync is the tensor data that `torch.nonzero` operates on is not on GPU side while the `sampled_csc` is targeted on GPU?",main culprit use causing synchronization read size nonzero time direct cause sync tensor data side targeted,issue,negative,positive,positive,positive,positive,positive
1963537275,"@mfbalin please take a look at https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/impl/ondisk_dataset.py#L824.
OnDiskDataset's `_init_all_nodes_set` makes use of `num_nodes` API of `FusedCSCSamplingGraph` to generate `all_nodes_set`. Could you please also modify the return type of `FusedCSCSamplingGraph.num_nodes` from `Union[int, Dict[str, int]]` to `Union[torch.Tensor, Dict[str, torch.Tensor]]` and test if your changes work correctly? Many thanks.",please take look use generate could please also modify return type union union test work correctly many thanks,issue,positive,positive,positive,positive,positive,positive
1963184318,cuda 12.2 is not supported yet. You may try to build from source on your own by referring to https://docs.dgl.ai/install/index.html#install-from-source,yet may try build source,issue,negative,neutral,neutral,neutral,neutral,neutral
1961951660,"I have run ogb_example.py (base) and ogb_example_ARGO.py and observe following performance improvements:

![image](https://github.com/dmlc/dgl/assets/58251767/fafe130c-bc0b-4a32-b2d5-5ce89b006130)


Well done!
(measured on Ubuntu 22.04.4, DGL 2.0.0, pytorch  2.2.1)",run base observe following performance image well done measured,issue,negative,negative,negative,negative,negative,negative
1961947560,"@Skeleton003 With PR #7147, a `torch.tensor(6, dtype=torch.int32)` can be passed into `gb.ItemSet` so we can specify the dtype of `all_nodes_set` now. However, due to the length needing to fit into the dtype, we will need to remove the `-1` we added to the code.",skeleton specify however due length needing fit need remove added code,issue,negative,positive,positive,positive,positive,positive
1961045430,"Looks like I'm running CUDA 12.2.r12.2, which doesn't appear to be on the list:
<img width=""942"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/7418031/a40d7d2f-d04d-4ebb-8893-f41a5780fd47"">

```
nvcc --version

nvcc: NVIDIA (R) Cuda compiler driver
Copyright (c) 2005-2023 NVIDIA Corporation
Built on Tue_Aug_15_22:02:13_PDT_2023
Cuda compilation tools, release 12.2, V12.2.140
Build cuda_12.2.r12.2/compiler.33191640_0`
```",like running appear list image version compiler driver copyright corporation built compilation release build,issue,negative,neutral,neutral,neutral,neutral,neutral
1960724875,"The CI failure is probably due to `all_nodes_set` being an integer as it fails during the testing phase. We need to find a way to fix it, see the discussion in #7130.
@Rhett-Ying @Skeleton003 ",failure probably due integer testing phase need find way fix see discussion skeleton,issue,negative,negative,negative,negative,negative,negative
1960698017,"#7131 was just merged, let's hope that it will help the CI pass.",let hope help pas,issue,positive,neutral,neutral,neutral,neutral,neutral
1960587747,please refer to https://www.dgl.ai/pages/start.html for the install command.,please refer install command,issue,negative,neutral,neutral,neutral,neutral,neutral
1960586481,@parva93 `2.17` is too old. what's your OS and version? could you try build from source on your own? please refer to https://docs.dgl.ai/install/index.html#install-from-source.,old o version could try build source please refer,issue,negative,positive,neutral,neutral,positive,positive
1960512614,I am having similar issues. I want to use the newer version of dgl but am unable to use the newer version 2.0 as on our university cluster the version of GLibc is 2.17. Any workaround for this issue?,similar want use version unable use version university cluster version issue,issue,negative,negative,negative,negative,negative,negative
1960382389,I guess I need to wait for #7123 to get merged first.,guess need wait get first,issue,negative,positive,positive,positive,positive,positive
1959747234,"> I would strongly prefer not to judge number of nodes and number of edges as a whole. For example, ogbn-papers100M has 111M vertices but 3.2B edges. It is best to use int32 for node_dtype for it but int64 for the edge_dtype.

Got it.",would strongly prefer judge number number whole example vertex best use got,issue,positive,positive,positive,positive,positive,positive
1959645875,"I would strongly prefer not to judge number of nodes and number of edges as a whole. For example, ogbn-papers100M has 111M vertices but 3.2B edges. It is best to use int32 for node_dtype for it but int64 for the edge_dtype.",would strongly prefer judge number number whole example vertex best use,issue,positive,positive,positive,positive,positive,positive
1958811253,"@ayushnoori if you don't plan to write a unit test, we can also merge this, can you add a comment in capped_neighbor_sampler.py, says ""This code was contributed by a community member (ayushnoori). There aren't currently any unit tests in place to verify its functionality, so please be cautious if you need to make any changes to the code's logic.""",plan write unit test also merge add comment code community member currently unit place verify functionality please cautious need make code logic,issue,negative,neutral,neutral,neutral,neutral,neutral
1958807632,"```
************* Module dgl.dataloading.capped_neighbor_sampler
python/dgl/dataloading/capped_neighbor_sampler.py:60:4: W0221: Parameters differ from overridden 'sample' method (arguments-differ)
python/dgl/dataloading/capped_neighbor_sampler.py:151:27: C0103: Variable name ""node_IDs"" doesn't conform to snake_case naming style (invalid-name)
python/dgl/dataloading/capped_neighbor_sampler.py:102:27: W0612: Unused variable 'rel_type' (unused-variable)
python/dgl/dataloading/capped_neighbor_sampler.py:102:37: W0612: Unused variable 'dst_type' (unused-variable)
```",module differ method variable name conform naming style unused variable unused variable,issue,negative,neutral,neutral,neutral,neutral,neutral
1958800696,"> Did you test the performance compare to original pyg example?

I have updated in the description",test performance compare original example description,issue,negative,positive,positive,positive,positive,positive
1958678476,LGTM @RamonZhou please take a second look and approve.,please take second look approve,issue,negative,neutral,neutral,neutral,neutral,neutral
1958573499,"Actually, you could directly instantiate with https://github.com/dmlc/dgl/blob/b0080d5bacf78d1b6f7e20652540d0e6da7c0e9c/python/dgl/graphbolt/impl/basic_feature_store.py#L12. Here's an example: https://github.com/dmlc/dgl/blob/00f33224038924c40229bb9c6f8dbe6d0b083960/tests/python/pytorch/graphbolt/test_dataloader.py#L18-L36",actually could directly example,issue,negative,positive,neutral,neutral,positive,positive
1958572214,"Since DGL2.0, `GraphBolt` is the recommend framework for data loading and sampling. Could you try with below example and see if it works for you.
https://github.com/dmlc/dgl/tree/master/examples/sampling/graphbolt/lightning",since recommend framework data loading sampling could try example see work,issue,negative,neutral,neutral,neutral,neutral,neutral
1958565242,"This sounds like an incremental learning problem.  Your idea of updating with new random walks might work.  However, you might also want to keep track of the old random walks in case of your model forgetting about the older context.

Another direction is to make your model a dynamic graph model, in which case you could try dynamic graph random walks such as [this](https://arxiv.org/pdf/1901.01346.pdf) ([github repo](https://github.com/shps/incremental-representation-learning)).",like incremental learning problem idea new random might work however might also want keep track old random case model forgetting older context another direction make model dynamic graph model case could try dynamic graph random,issue,positive,negative,negative,negative,negative,negative
1958553647,"> LGTM. These changes may be helpful in addressing the CI failure I met in #7127 .

I think it definitely will.",may helpful failure met think definitely,issue,negative,negative,negative,negative,negative,negative
1958548233,LGTM. These changes may be helpful in addressing the CI failure I met in #7127 .,may helpful failure met,issue,negative,negative,negative,negative,negative,negative
1958489387,you could try build from source on your own by referring to https://docs.dgl.ai/install/index.html#install-from-source,could try build source,issue,negative,neutral,neutral,neutral,neutral,neutral
1956113604,Or we just re-write `IdMap` with `numpy` and `torch` as original one is too complicated(probably caused by multiple backend support).,torch original one complicated probably multiple support,issue,positive,negative,neutral,neutral,negative,negative
1956112048,"One fix is to specify dtype for `utils.toindex()`.
```
--- a/python/dgl/distributed/id_map.py
+++ b/python/dgl/distributed/id_map.py
@@ -101,8 +101,9 @@ class IdMap:
 
     def __init__(self, id_ranges):
         self.num_parts = list(id_ranges.values())[0].shape[0]
+        dtype = list(id_ranges.values())[0].dtype
         self.num_types = len(id_ranges)
-        ranges = np.zeros((self.num_parts * self.num_types, 2), dtype=np.int64)
+        ranges = np.zeros((self.num_parts * self.num_types, 2), dtype=dtype)
         typed_map = []
         id_ranges = list(id_ranges.values())
         id_ranges.sort(key=lambda a: a[0, 0])
@@ -113,9 +114,10 @@ class IdMap:
 
         assert np.all(np.diff(ranges[:, 0]) >= 0)
         assert np.all(np.diff(ranges[:, 1]) >= 0)
-        self.range_start = utils.toindex(np.ascontiguousarray(ranges[:, 0]))
-        self.range_end = utils.toindex(np.ascontiguousarray(ranges[:, 1]) - 1)
-        self.typed_map = utils.toindex(np.concatenate(typed_map))
+        dtype_str = ""int32"" if dtype != np.int64 else ""int64""
+        self.range_start = utils.toindex(np.ascontiguousarray(ranges[:, 0]), dtype=dtype_str)
+        self.range_end = utils.toindex(np.ascontiguousarray(ranges[:, 1]) - 1, dtype=dtype_str)
+        self.typed_map = utils.toindex(np.concatenate(typed_map), dtype=dtype_str)
 
     def __call__(self, ids):
         """"""Convert the homogeneous IDs to (type_id, type_wise_id).
@@ -137,7 +139,7 @@ class IdMap:
         if len(ids) == 0:
             return ids, ids
 
-        ids = utils.toindex(ids)
+        ids = utils.toindex(ids, ""int32"")
         ret = _CAPI_DGLHeteroMapIds(
             ids.todgltensor(),
             self.range_start.todgltensor(),
@@ -146,7 +148,7 @@ class IdMap:
             self.num_parts,
             self.num_types,
         )
-        ret = utils.toindex(ret).tousertensor()
+        ret = utils.toindex(ret, ""int32"").tousertensor()
         return ret[: len(ids)], ret[len(ids) :]
```",one fix specify class self list list list class assert assert else self convert homogeneous class return ret class ret ret ret ret return ret ret,issue,negative,neutral,neutral,neutral,neutral,neutral
1956067832,Did you test the performance compare to original pyg example?,test performance compare original example,issue,negative,positive,positive,positive,positive,positive
1955740335,"As for item set that's generated in runtime such as `all_nodes_set`, we need to figure out a way to format dtype according to `graph.indices`",item set need figure way format according,issue,negative,neutral,neutral,neutral,neutral,neutral
1955738343,"Because sample_neighbors does type checking for the nodes and indices tensors, if the things coming from the itemset don't match the graph indices dtype, it gives an error due to these lines:
https://github.com/dmlc/dgl/blob/3ced3411e55bca803ed5ec5e1de6f62e1f21478f/python/dgl/graphbolt/impl/fused_csc_sampling_graph.py#L644-L647",type index coming match graph index error due,issue,negative,negative,negative,negative,negative,negative
1955093185,@Rhett-Ying Are we going to release GPU accelerated R-GCN example? It already works and I think the release blog should mention it.,going release accelerated example already work think release mention,issue,negative,neutral,neutral,neutral,neutral,neutral
1954938815,"@frozenbugs : Unfortunately, I am unable to reproduce the problem you mentioned in my Linux environment. This appears to be some kind of multi-threading bug that only appears on Windows. Similar problems were reported for  [PR#6187](https://github.com/dmlc/dgl/pull/6187) and [PR#6194](https://github.com/dmlc/dgl/pull/6194) where I suggested similar fixes. I'll convert this to ""Draft"".",unfortunately unable reproduce problem environment kind bug similar similar convert draft,issue,negative,positive,neutral,neutral,positive,positive
1954670530,"@Rhett-Ying However, all_nodes_set can be an integer so it looks like currently, there is no way to specify its dtype. Casting to int is pretty crucial for performance though, I am hoping that we can find an easy solution.",however integer like currently way specify casting pretty crucial performance though find easy solution,issue,positive,positive,positive,positive,positive,positive
1953833076,"> @caojy1998 which example is used? we'd better add `ogbn-papers100M` into the available datasets for the example.

Graphbolt node_classification is used here. I will use another PR to put the dataset into available dataset.",example used better add available example used use another put available,issue,negative,positive,positive,positive,positive,positive
1953526435,@caojy1998  which example is used? we'd better add `ogbn-papers100M` into the available datasets for the example.,example used better add available example,issue,negative,positive,positive,positive,positive,positive
1953366521,"Next work item: avoid `make -j`and be consistent when building DGL/sparse/graphbolt.

Reference: CMake 3.28 has added JOB_SERVER_AWARE option that could be applicable to our case: https://cmake.org/cmake/help/latest/command/add_custom_command.html",next work item avoid make consistent building reference added option could applicable case,issue,negative,positive,positive,positive,positive,positive
1953361976,"> @mfbalin Though limiting the parallelism of `make` mitigate this issue, is it possible to reduce the memory consumption of GPU sampling code even building with `make -j` or can we say we build necessary code only, no redundancy is introduced?

@Rhett-Ying I have been careful about writing the code, already had compilation time and speed in mind since the beginning. There are some optimizations I did that trade-off compilation time for runtime speed, though they are pretty crucial for neighbor sampling performance. Thus, if we can fix our compilation infrastructure first, then we can see if we can do more things to reduce compilation time. There may be some things we can do to compile different template parameters in different files, though they will reduce maintainability quite a bit. Also, I think when we have all CUDA architectures enabled, that may be increasing the RAM requirements too, I think it is worth a look to see if there is a way to reduce that or compile for different CUDA architectures separately.",though limiting parallelism make mitigate issue possible reduce memory consumption sampling code even building make say build necessary code redundancy careful writing code already compilation time speed mind since beginning compilation time speed though pretty crucial neighbor sampling performance thus fix compilation infrastructure first see reduce compilation time may compile different template different though reduce quite bit also think may increasing ram think worth look see way reduce compile different separately,issue,positive,positive,neutral,neutral,positive,positive
1952699560,"> I've updated the program with the suggested changes (AAA series); please let me know if there are any pending issues, thanks!

All previous issues have been resolved - please close them. Thank you.
I will add 2 more small issues (bad link address and  taking into account time of all epochs in the original example).",program series please let know pending thanks previous resolved please close thank add small bad link address taking account time original example,issue,positive,negative,negative,negative,negative,negative
1951640266,"We can modify the https://github.com/dmlc/dgl/blob/master/examples/sampling/graphbolt/node_classification.py to add a sampler option to switch between sample_neighbors and sample_layer_neighbors.

Also, a boolean argument called `--overlap_graph_fetch` to be passed into the `gb.Dataloader`, https://docs.dgl.ai/en/latest/generated/dgl.graphbolt.DataLoader.html#dgl.graphbolt.DataLoader.

The regression tests will then need to be updated to cover the combination of the relevant variables, note that `overlap_graph_fetch` is applicable only for the GPU.",modify add sampler option switch also argument regression need cover combination relevant note applicable,issue,negative,positive,positive,positive,positive,positive
1951635477,@mfbalin please add more context to help @caojy1998 on this work item.,please add context help work item,issue,positive,neutral,neutral,neutral,neutral,neutral
1951619063,"Commit ID: 1fb44b6bab8bbc5e8b3d8d2a5b8ec64b2eaa5843

Build ID: 5

Status: âŒ CI test failed in Stage [C++ CPU (Win64)].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7117/5/5/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7117/5/5/logs/cireport.log)",commit id build id status test stage win report path link full path link,issue,positive,positive,positive,positive,positive,positive
1951595961,"@mfbalin Though limiting the parallelism of `make` mitigate this issue, is it possible to reduce the memory consumption of GPU sampling code even building with `make -j` or can we say we build necessary code only, no redundancy is introduced?",though limiting parallelism make mitigate issue possible reduce memory consumption sampling code even building make say build necessary code redundancy,issue,negative,neutral,neutral,neutral,neutral,neutral
1951591186,"```
================================== FAILURES ===================================
_________________________ test_group_rev_res[idtype0] _________________________

idtype = torch.int32

    @parametrize_idtype
    def test_group_rev_res(idtype):
        dev = F.ctx()
    
        num_nodes = 5
        num_edges = 20
        feats = 32
        groups = 2
        g = dgl.rand_graph(num_nodes, num_edges).to(dev)
        h = th.randn(num_nodes, feats).to(dev)
        conv = nn.GraphConv(feats // groups, feats // groups)
        model = nn.GroupRevRes(conv, groups).to(dev)
&gt;       result = model(g, h)

tests\python\pytorch\nn\test_nn.py:2287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py:1194: in _call_impl
    return forward_call(*input, **kwargs)
python\dgl\nn\pytorch\conv\grouprevres.py:254: in forward
    *(args + tuple([p for p in self.parameters() if p.requires_grad]))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

ctx = &lt;torch.autograd.function.InvertibleCheckpointBackward object at 0x00000052832EAE58&gt;
fn = &lt;bound method GroupRevRes._forward of GroupRevRes(
  (gnn_modules): ModuleList(
    (0): GraphConv(in=16, out=16, normalization=both, activation=None)
    (1): GraphConv(in=16, out=16, normalization=both, activation=None)
  )
)&gt;
fn_inverse = &lt;bound method GroupRevRes._inverse of GroupRevRes(
  (gnn_modules): ModuleList(
    (0): GraphConv(in=16, out=16, normalization=both, activation=None)
    (1): GraphConv(in=16, out=16, normalization=both, activation=None)
  )
)&gt;
num_inputs = 2
inputs_and_weights = (Graph(num_nodes=5, num_edges=20,
      ndata_schemes={}
      edata_schemes={}), tensor([[ 0.5982, -1.6816, -0.5572, ...ameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       requires_grad=True))
inputs = (Graph(num_nodes=5, num_edges=20,
      ndata_schemes={}
      edata_schemes={}), tensor([[ 0.5982, -1.6816, -0.5572, ... 1.5027,  2.4316, -1.7318,  1.3843,
         -1.2294,  0.1610,  0.0136,  1.2388, -2.0080, -0.7917,  1.5043, -0.5614]]))
x = [Graph(num_nodes=5, num_edges=20,
      ndata_schemes={}
      edata_schemes={}), tensor([[ 0.5982, -1.6816, -0.5572, ... 1.5027,  2.4316, -1.7318,  1.3843,
         -1.2294,  0.1610,  0.0136,  1.2388, -2.0080, -0.7917,  1.5043, -0.5614]])]
element = tensor([[ 0.5982, -1.6816, -0.5572, -1.2908, -1.7179, -1.3323,  0.8583, -0.6617,
          1.5634, -2.0408,  0.0528, -...  1.5027,  2.4316, -1.7318,  1.3843,
         -1.2294,  0.1610,  0.0136,  1.2388, -2.0080, -0.7917,  1.5043, -0.5614]])

    @staticmethod
    def forward(ctx, fn, fn_inverse, num_inputs, *inputs_and_weights):
        ctx.fn = fn
        ctx.fn_inverse = fn_inverse
        ctx.weights = inputs_and_weights[num_inputs:]
        inputs = inputs_and_weights[:num_inputs]
        ctx.input_requires_grad = []
    
        with torch.no_grad():
            # Make a detached copy, which shares the storage
            x = []
            for element in inputs:
                if isinstance(element, torch.Tensor):
                    x.append(element.detach())
                    ctx.input_requires_grad.append(element.requires_grad)
                else:
                    x.append(element)
                    ctx.input_requires_grad.append(None)
            # Detach the output, which then allows discarding the intermediary results
            outputs = ctx.fn(*x).detach_()
    
        # clear memory of input node features
&gt;       inputs[1].untyped_storage().resize_(0)
E       AttributeError: 'Tensor' object has no attribute 'untyped_storage'

python\dgl\nn\pytorch\conv\grouprevres.py:35: AttributeError
_________________________ test_group_rev_res[idtype1] _________________________

idtype = torch.int64

    @parametrize_idtype
    def test_group_rev_res(idtype):
        dev = F.ctx()
    
        num_nodes = 5
        num_edges = 20
        feats = 32
        groups = 2
        g = dgl.rand_graph(num_nodes, num_edges).to(dev)
        h = th.randn(num_nodes, feats).to(dev)
        conv = nn.GraphConv(feats // groups, feats // groups)
        model = nn.GroupRevRes(conv, groups).to(dev)
&gt;       result = model(g, h)

tests\python\pytorch\nn\test_nn.py:2287: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\nn\modules\module.py:1194: in _call_impl
    return forward_call(*input, **kwargs)
python\dgl\nn\pytorch\conv\grouprevres.py:254: in forward
    *(args + tuple([p for p in self.parameters() if p.requires_grad]))
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

ctx = &lt;torch.autograd.function.InvertibleCheckpointBackward object at 0x000000528B7445E8&gt;
fn = &lt;bound method GroupRevRes._forward of GroupRevRes(
  (gnn_modules): ModuleList(
    (0): GraphConv(in=16, out=16, normalization=both, activation=None)
    (1): GraphConv(in=16, out=16, normalization=both, activation=None)
  )
)&gt;
fn_inverse = &lt;bound method GroupRevRes._inverse of GroupRevRes(
  (gnn_modules): ModuleList(
    (0): GraphConv(in=16, out=16, normalization=both, activation=None)
    (1): GraphConv(in=16, out=16, normalization=both, activation=None)
  )
)&gt;
num_inputs = 2
inputs_and_weights = (Graph(num_nodes=5, num_edges=20,
      ndata_schemes={}
      edata_schemes={}), tensor([[-2.0861e-01,  1.5159e+00, -...ameter containing:
tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],
       requires_grad=True))
inputs = (Graph(num_nodes=5, num_edges=20,
      ndata_schemes={}
      edata_schemes={}), tensor([[-2.0861e-01,  1.5159e+00, -...75e-01,
         -1.4968e-02,  1.2952e+00, -1.2937e+00,  9.9673e-01, -1.9580e-01,
          1.3495e+00,  1.5232e+00]]))
x = [Graph(num_nodes=5, num_edges=20,
      ndata_schemes={}
      edata_schemes={}), tensor([[-2.0861e-01,  1.5159e+00, -...75e-01,
         -1.4968e-02,  1.2952e+00, -1.2937e+00,  9.9673e-01, -1.9580e-01,
          1.3495e+00,  1.5232e+00]])]
element = tensor([[-2.0861e-01,  1.5159e+00, -1.7376e+00, -7.2614e-01,  9.7599e-01,
          3.5593e-01,  4.2687e-01, -1.5182e-...275e-01,
         -1.4968e-02,  1.2952e+00, -1.2937e+00,  9.9673e-01, -1.9580e-01,
          1.3495e+00,  1.5232e+00]])

    @staticmethod
    def forward(ctx, fn, fn_inverse, num_inputs, *inputs_and_weights):
        ctx.fn = fn
        ctx.fn_inverse = fn_inverse
        ctx.weights = inputs_and_weights[num_inputs:]
        inputs = inputs_and_weights[:num_inputs]
        ctx.input_requires_grad = []
    
        with torch.no_grad():
            # Make a detached copy, which shares the storage
            x = []
            for element in inputs:
                if isinstance(element, torch.Tensor):
                    x.append(element.detach())
                    ctx.input_requires_grad.append(element.requires_grad)
                else:
                    x.append(element)
                    ctx.input_requires_grad.append(None)
            # Detach the output, which then allows discarding the intermediary results
            outputs = ctx.fn(*x).detach_()
    
        # clear memory of input node features
&gt;       inputs[1].untyped_storage().resize_(0)
E       AttributeError: 'Tensor' object has no attribute 'untyped_storage'
```
@drivanov ",dev dev dev model dev result model return input forward object bound method bound method graph tensor tensor graph tensor graph tensor element tensor forward make detached copy storage element element else element none detach output intermediary clear memory input node object attribute dev dev dev model dev result model return input forward object bound method bound method graph tensor tensor graph tensor graph tensor element tensor forward make detached copy storage element element else element none detach output intermediary clear memory input node object attribute,issue,negative,positive,positive,positive,positive,positive
1951576360,"@drivanov 
```
================================== FAILURES ===================================
______________________ test_spot_target_excludes[1-1-1] _______________________

degree_threshold = 1, batch_size = 1, num_workers = 1

    @pytest.mark.parametrize(""degree_threshold"", [1, 2, 3, 4, 5])
    @pytest.mark.parametrize(""batch_size"", [1, 10, 50])
    @pytest.mark.parametrize(""num_workers"", [1, 4])
    def test_spot_target_excludes(degree_threshold, batch_size, num_workers):
        g, reverse_eids, seed_edges = _create_homogeneous()
        sampler = dgl.dataloading.MultiLayerFullNeighborSampler(1)
        low_degree_excluder = dgl.dataloading.SpotTarget(
            g,
            exclude=""reverse_id"",
            degree_threshold=degree_threshold,
            reverse_eids=reverse_eids,
        )
        sampler = dgl.dataloading.as_edge_prediction_sampler(
            sampler,
            exclude=low_degree_excluder,
            negative_sampler=dgl.dataloading.negative_sampler.Uniform(1),
        )
        dataloader = dgl.dataloading.DataLoader(
            g,
            seed_edges,
            sampler,
            batch_size=batch_size,
            num_workers=num_workers,
        )
    
        with dataloader.enable_cpu_affinity():
            for i, (input_nodes, pair_graph, neg_pair_graph, blocks) in enumerate(
&gt;               dataloader
            ):

tests\python\pytorch\dataloading\test_spot_target.py:58: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _
python\dgl\dataloading\dataloader.py:1160: in __iter__
    self, super().__iter__(), num_threads=num_threads
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py:435: in __iter__
    return self._get_iterator()
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py:381: in _get_iterator
    return _MultiProcessingDataLoaderIter(self)
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\site-packages\torch\utils\data\dataloader.py:1034: in __init__
    w.start()
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\multiprocessing\process.py:112: in start
    self._popen = self._Popen(self)
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py:223: in _Popen
    return _default_context.get_context().Process._Popen(process_obj)
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\multiprocessing\context.py:322: in _Popen
    return Popen(process_obj)
C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\multiprocessing\popen_spawn_win32.py:89: in __init__
    reduction.dump(process_obj, to_child)
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

obj = &lt;Process(Process-117, initial daemon)&gt;
file = &lt;_io.BufferedWriter name=11&gt;, protocol = None

    def dump(obj, file, protocol=None):
        '''Replacement for pickle.dump() using ForkingPickler.'''
&gt;       ForkingPickler(file, protocol).dump(obj)
E       AttributeError: Can't pickle local object 'DataLoader.enable_cpu_affinity.&lt;locals&gt;.init_fn'

C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\multiprocessing\reduction.py:60: AttributeError
---------------------------- Captured stdout call -----------------------------
1 DL workers are assigned to cpus [0], main process will use cpus [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15]
-------------------------- Captured stderr teardown ---------------------------
Traceback (most recent call last):

  File ""&lt;string&gt;"", line 1, in &lt;module&gt;

  File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py"", line 105, in spawn_main

    exitcode = _main(fd)

  File ""C:\Users\Administrator\AppData\Local\Programs\Python\Python37\lib\multiprocessing\spawn.py"", line 115, in _main

    self = reduction.pickle.load(from_parent)

EOFError: Ran out of input

```",sampler sampler sampler sampler enumerate self super return return self start self return return process initial daemon file protocol none dump file file protocol ca pickle local object call assigned main process use teardown recent call last file string line module file line file line self ran input,issue,positive,positive,neutral,neutral,positive,positive
1950281887,"I've updated the program with the suggested changes (AAA series); please let me know if there are any pending issues, thanks!",program series please let know pending thanks,issue,positive,positive,positive,positive,positive,positive
1950257427,"- [x]  profile memory footprint of feature data.
- [x]  re-preprocess datasets and run end2end example to check if accuracy is expected.(just make sure the new processing works well)",profile memory footprint feature data run example check accuracy make sure new work well,issue,positive,positive,positive,positive,positive,positive
1950255980,"Benchmark on self-made dataset with graph-features, containing a heterograph with 3 million nodes and 30 million edges.

```sh
Version: old | Dataset: selfmade | include_EID: True
Memory Usage: 12.004 GB | Execution Time: 26.74319 seconds
Version: new | Dataset: selfmade | include_EID: True
Memory Usage: 10.524 GB | Execution Time: 26.45344 seconds
 
Version: old | Dataset: selfmade | include_EID: False
Memory Usage: 12.004 GB | Execution Time: 25.80169 seconds
Version: new | Dataset: selfmade | include_EID: False
Memory Usage: 10.524 GB | Execution Time: 25.55227 seconds
```",million million sh version old true memory usage execution time version new true memory usage execution time version old false memory usage execution time version new false memory usage execution time,issue,positive,positive,neutral,neutral,positive,positive
1943705192,CMake 3.28 has added `JOB_SERVER_AWARE` option that could be applicable to our case: https://cmake.org/cmake/help/latest/command/add_custom_command.html,added option could applicable case,issue,negative,neutral,neutral,neutral,neutral,neutral
1942235137,"@nv-dlasalle 
After checking `cuda_bf16.h` (12.3) and the [doc](https://docs.nvidia.com/cuda/cuda-math-api/group__CUDA__MATH____BFLOAT16__ARITHMETIC.html#group__CUDA__MATH____BFLOAT16__ARITHMETIC_1g9ce572e47cde154b9404bf86a0438e91), it seems starting from cuda12.2, an 'emulated' support of many bf16 operations have been added to older devices (sm70), which includes atomicAdd operation. I think, technically, all sm70-sm80 devices should support bf16 operations via 'emulation path' from driver side (with cuda 12.2+). 

Then, do we need to update https://github.com/dmlc/dgl/blob/master/src/array/cuda/atomic.cuh to update the assertions?  
cc. @yaox12 ",doc starting support many added older operation think technically support via path driver side need update update,issue,positive,positive,positive,positive,positive,positive
1941867666,"@chang-l to clarify the issue, because DGL has some operations only implemented via atomics, we cannot support these GPUs, but pytorch has non-atomic versions of its operators and thus can implement operations for BF16 on these GPUs?",clarify issue via atomics support thus implement,issue,negative,neutral,neutral,neutral,neutral,neutral
1940485757,"Btw, let me provide a bit more background here: 

Recently, PyTorch introduces this commit: https://github.com/pytorch/pytorch/commit/fc5fda14bcc41008e5610bf39c53eb066933ea4e, which changes the behavior of `torch.cuda.is_bf16_supported()`. Previously, `torch.cuda.is_bf16_supported()` will be `False` for any GPUs older than A100 (<sm80). But after this commit, it could return `True` even with V100 GPUs (sm70).  As a result, it can bypass the check here (and many other places in the tests) even with a V100 (sm70) GPU that does NOT support bf16 operations: https://github.com/dmlc/dgl/blob/8e6cbd621f34c0892ab5adac5259cd61401a6d2b/tests/python/common/ops/test_ops.py#L410-L415
Sadly, even if we know that A100 is the first gen GPU that supports bf16 operations [[1]](https://en.wikipedia.org/wiki/Ampere_(microarchitecture)) [[2]](https://images.nvidia.com/aem-dam/en-zz/Solutions/data-center/nvidia-ampere-architecture-whitepaper.pdf), we could not use this API(`torch.cuda.is_bf16_supported()`) to query for the bf16 operation support any more.  cc. @TristonC @nv-dlasalle @frozenbugs 

As of now, this commit has not been populated to any pytorch release branch yet. So, it can only be reproduced from a nightly PyTorch build.",let provide bit background recently commit behavior previously false older commit could return true even result bypass check many even support sadly even know first gen could use query operation support commit release branch yet nightly build,issue,positive,positive,neutral,neutral,positive,positive
1935728117,"@Rhett-Ying I think the compilation of GraphBolt and DGL sparse should respect the parallelism command of the parent build process. I don't know how to achieve that. Could you look into it?

The problem is partially related to the GPU code so I am removing my assignment. It is related to the build commands. After the build commands are fixed, we can look into reducing the memory consumption of the GraphBolt GPU code compilation.",think compilation sparse respect parallelism command parent build process know achieve could look problem partially related code removing assignment related build build fixed look reducing memory consumption code compilation,issue,negative,positive,neutral,neutral,positive,positive
1935727073,"The main issue is that we are using `make -j` to compile GraphBolt and DGL sparse here:
https://github.com/dmlc/dgl/blob/8e6cbd621f34c0892ab5adac5259cd61401a6d2b/dgl_sparse/build.sh#L22-L30

and here:
https://github.com/dmlc/dgl/blob/8e6cbd621f34c0892ab5adac5259cd61401a6d2b/graphbolt/build.sh#L20-L28",main issue make compile sparse,issue,negative,positive,positive,positive,positive,positive
1935721641,"> The launching of parallel CMake builds inside CMake here: https://github.com/dmlc/dgl/blob/master/CMakeLists.txt#L427 may also be an issue

I noticed this also, this is the main issue we need to fix. The sublibraries dglsparse and graphbolt should respect the parallelism make options of the main DGL compilation process.",parallel inside may also issue also main issue need fix respect parallelism make main compilation process,issue,negative,positive,positive,positive,positive,positive
1935716731,The launching of parallel CMake builds inside CMake here: https://github.com/dmlc/dgl/blob/master/CMakeLists.txt#L427 may also be an issue,parallel inside may also issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1935406486,"may be
1. dependencies on third-party that requires high memory during compilation?
2. include large hpp? CCCL, HugeCTR?
3. any other template that bloats?",may high memory compilation include large template,issue,negative,positive,positive,positive,positive,positive
1935371607,What else do you think could be the culprit other than the use of nested AT_DISPATCH mscros?,else think could culprit use,issue,negative,neutral,neutral,neutral,neutral,neutral
1935192167,"It runs OK in the DGL NGC container 24.01. Will try to repo without container.
```
root@ecfeb6f27748:/opt/dgl/dgl-source/examples/multigpu# python node_classification_sage.py --gpu 0,1,2,3
Training in mixed mode using 4 GPU(s)
Loading data
This will download 1.38GB. Will you proceed? (y/N)
y
Downloading http://snap.stanford.edu/ogb/data/nodeproppred/products.zip
Downloaded 1.38 GB: 100%|| 1414/1414 [00:20<00:00, 67.44it/s]
Extracting dataset/products.zip
Loading necessary files...
This might take a while.
Processing graphs...
100%|1/1 [00:01<00:00,  1.66s/it]
Converting graphs into DGL objects...
100%|1/1 [00:00<00:00,  4.29it/s]
Saving...
Training...
Epoch 00000 | Loss 2.4287 | Accuracy 0.7714 | Time 5.3175
Epoch 00001 | Loss 0.9772 | Accuracy 0.8369 | Time 4.5307
Epoch 00002 | Loss 0.7459 | Accuracy 0.8538 | Time 4.5606
Epoch 00003 | Loss 0.6612 | Accuracy 0.8641 | Time 4.5573
Epoch 00004 | Loss 0.5897 | Accuracy 0.8713 | Time 4.5261
Epoch 00005 | Loss 0.5837 | Accuracy 0.8748 | Time 4.5167
Epoch 00006 | Loss 0.5278 | Accuracy 0.8786 | Time 4.5288
Epoch 00007 | Loss 0.4970 | Accuracy 0.8826 | Time 4.5237
Epoch 00008 | Loss 0.5000 | Accuracy 0.8828 | Time 4.5237
Epoch 00009 | Loss 0.4745 | Accuracy 0.8863 | Time 4.5328
Testing...
Test accuracy 0.7296",container try without container root python training mixed mode loading data proceed loading necessary might take converting saving training epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time epoch loss accuracy time testing test accuracy,issue,negative,neutral,neutral,neutral,neutral,neutral
1932095767,"> I just tried loading this dataset in a GraphBolt example but it didn't work. Could you ping me when it starts working @caojy1998?

OK, currently it is still under construction.",tried loading example work could ping working currently still construction,issue,negative,neutral,neutral,neutral,neutral,neutral
1931339461,I just tried loading this dataset in a GraphBolt example but it didn't work. Could you ping me when it starts working @caojy1998?,tried loading example work could ping working,issue,negative,neutral,neutral,neutral,neutral,neutral
1931073665,"So the remaining work items are

- [ ] > profile memory footprint of feature data.
- [ ] > re-preprocess datasets and run end2end example to check if accuracy is expected.(just make sure the new processing works well)",work profile memory footprint feature data run example check accuracy make sure new work well,issue,positive,positive,positive,positive,positive,positive
1930637640,"@Rhett-Ying: I tried to follow your direction and use `include_original_eids=True`. For most tests, it worked. Unfortunately, with these changes I 

- four tests started to fail:
 ```
test_OnDiskDataset_preprocess_homogeneous
test_OnDiskDataset_preprocess_auto_force_preprocess
test_OnDiskDataset_load_graph 
test_OnDiskDataset_auto_force_preprocess
```
- this warning still appears for the following four tests:
 ```
 test_OnDiskDataset_load_feature
 test_OnDiskDataset_load_graph
 test_OnDiskDataset_load_tasks
 test_OnDiskDataset_load_tasks_selectively
 ```

NOTE: `test_OnDiskDataset_load_graph` is presented in both lists. It's not an error, it's because in this test we do have multiple calls generating this warning.

For these cases, I reverted to  `include_original_eids=False`.
",tried follow direction use worked unfortunately four fail warning still following four note error test multiple generating warning,issue,negative,negative,negative,negative,negative,negative
1930135836,"Latest benchmark:
```sh
Version: old | Dataset: ogbn-mag | include_EID: True
Memory Usage: 7.983 GB | Execution Time: 14.86984 seconds
Version: new | Dataset: ogbn-mag | include_EID: True
Memory Usage: 6.674 GB | Execution Time: 14.08306 seconds
 
Version: old | Dataset: ogbn-mag | include_EID: False
Memory Usage: 7.969 GB | Execution Time: 13.24852 seconds
Version: new | Dataset: ogbn-mag | include_EID: False
Memory Usage: 6.674 GB | Execution Time: 12.80191 seconds
 
Version: old | Dataset: ogbn-products | include_EID: True
Memory Usage: 14.054 GB | Execution Time: 41.93387 seconds
Version: new | Dataset: ogbn-products | include_EID: True
Memory Usage: 10.922 GB | Execution Time: 38.63654 seconds
 
Version: old | Dataset: ogbn-products | include_EID: False
Memory Usage: 14.054 GB | Execution Time: 36.94148 seconds
Version: new | Dataset: ogbn-products | include_EID: False
Memory Usage: 10.922 GB | Execution Time: 35.49174 seconds
```
@Rhett-Ying @czkkkkkk ",latest sh version old true memory usage execution time version new true memory usage execution time version old false memory usage execution time version new false memory usage execution time version old true memory usage execution time version new true memory usage execution time version old false memory usage execution time version new false memory usage execution time,issue,positive,positive,neutral,neutral,positive,positive
1928935073,"> By the way, the pip installs dgl -f https://data.dgl.ai/wheels/cu121/repo.html installation also fails on the collab. After installation, when I write import dgl.sparse, it returns ImportError: Cannot load DGL C++ sparse library

I tried with collab(T4 GPU) and it works well. `!pip install dgl -f https://data.dgl.ai/wheels/cu121/repo.html`",way pip installation also installation write import load sparse library tried work well pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1928743462,"> @Skeleton003 the default or previous dtype of `type_per_edge` is `torch.int64`? could you paste the results for `ogbn-products` as well? And how do you measure the memory usage?

Yes, default or previous dtype of `type_per_edge` is `torch.int64`. The code and results are pasted in the description.",skeleton default previous could paste well measure memory usage yes default previous code pasted description,issue,positive,negative,negative,negative,negative,negative
1928600702,"According to the `ogbn-mag` results, storing edge attributes has impact on memory usage.",according edge impact memory usage,issue,negative,neutral,neutral,neutral,neutral,neutral
1928597404,@Skeleton003 the default or previous dtype of `type_per_edge` is `torch.int64`? could you paste the results for `ogbn-products` as well? And how do you measure the memory usage?,skeleton default previous could paste well measure memory usage,issue,negative,negative,negative,negative,negative,negative
1927576059,"Tried to change the dtype of `type_per_edge` for hetero graph:

After change `type_per_edge` to `torch.int32`:
```sh
Version: old | Dataset: ogbn-mag | include_EID: True
Memory Usage: 8.008 GB | Execution Time: 14.99524 seconds
Version: new | Dataset: ogbn-mag | include_EID: True
Memory Usage: 8.682 GB | Execution Time: 13.81134 seconds
 
Version: old | Dataset: ogbn-mag | include_EID: False
Memory Usage: 7.976 GB | Execution Time: 13.61416 seconds
Version: new | Dataset: ogbn-mag | include_EID: False
Memory Usage: 8.053 GB | Execution Time: 12.39217 seconds
```

After change `type_per_edge` to `torch.int16`:
```
Version: old | Dataset: ogbn-mag | include_EID: True
Memory Usage: 8.008 GB | Execution Time: 15.08433 seconds
Version: new | Dataset: ogbn-mag | include_EID: True
Memory Usage: 8.448 GB | Execution Time: 13.50126 seconds
 
Version: old | Dataset: ogbn-mag | include_EID: False
Memory Usage: 7.976 GB | Execution Time: 13.57649 seconds
Version: new | Dataset: ogbn-mag | include_EID: False
Memory Usage: 7.819 GB | Execution Time: 12.00695 seconds
```",tried change hetero graph change sh version old true memory usage execution time version new true memory usage execution time version old false memory usage execution time version new false memory usage execution time change version old true memory usage execution time version new true memory usage execution time version old false memory usage execution time version new false memory usage execution time,issue,positive,positive,neutral,neutral,positive,positive
1927494355,@yxy235  Is there anything we are missing here when it comes to GPU support for GraphBolt?,anything missing come support,issue,negative,negative,negative,negative,negative,negative
1927369111,"Benchmarking results are pasted in the description. @Rhett-Ying  @czkkkkkk 

Good news is that the new implementation is generally faster than the old one, and is more memory-saving for homo datasets (ogbn-products).

But it is worth noting that the new implementation uses more memory to deal with datasets with a heterograph (ogbn-mag). I am going through the code to figure out why, but I don't have a clue right now. Your inspiration on this issue will be appreciated.",pasted description good news new implementation generally faster old one homo worth new implementation memory deal going code figure clue right inspiration issue,issue,positive,positive,positive,positive,positive,positive
1926569085,"1. After ls -lh /lib/x86_64-linux-gnu/libm.so.6 the ldd version is 2.31
2. 2.1.0+cu121

â€«×‘×ª××¨×™×š ×™×•× ×‘×³, 5 ×‘×¤×‘×¨×³ 2024 ×‘-11:07 ×ž××ª â€ªRhett Yingâ€¬â€ <â€ª
***@***.***â€¬â€>:â€¬

>
>    1. first locate your libm.so and check if it links to 2.27 instead of
>    2.31: ls -lh /lib/x86_64-linux-gnu/libm.so.6
>    2. As for the collab issue, could you confirm which torch version
>    you're using for now?
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/dmlc/dgl/issues/7046#issuecomment-1926516687>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AVTIJUG2G6ODH2HTE2UZPCDYSCONPAVCNFSM6AAAAABCRPQQAGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSMRWGUYTMNRYG4>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",version first locate check link instead issue could confirm torch version reply directly view id,issue,negative,positive,positive,positive,positive,positive
1926526205,please check if such peak memory issue happens in current implementation. https://github.com/dmlc/dgl/issues/7086,please check peak memory issue current implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
1926521753,@Skeleton003 could you look into it and try with the new implementation: https://github.com/dmlc/dgl/pull/6986,skeleton could look try new implementation,issue,negative,positive,positive,positive,positive,positive
1926516687,"1. first locate your `libm.so` and check if it links to 2.27 instead of 2.31: `ls -lh /lib/x86_64-linux-gnu/libm.so.6`
2. As for the collab issue, could you confirm which torch version you're using for now?",first locate check link instead issue could confirm torch version,issue,negative,positive,positive,positive,positive,positive
1926390040,"By the way, the pip installs dgl -f https://data.dgl.ai/wheels/cu121/repo.html installation also fails on the collab.
After installation, when I write import dgl.sparse, it returns ImportError: Cannot load DGL C++ sparse library",way pip installation also installation write import load sparse library,issue,negative,neutral,neutral,neutral,neutral,neutral
1925860528,"Commit ID: 0a211868741068502c10aed120c0218c76bfbc0b

Build ID: 39

Status: âŒ CI test failed in Stage [Torch CPU].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7039/39/39/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-7039/39/39/logs/cireport.log)",commit id build id status test stage torch report path link full path link,issue,negative,positive,positive,positive,positive,positive
1925823659,"Just tested the link_prediction example with the fix in #7083, all the 4 different modes work as expected.",tested example fix different work,issue,negative,neutral,neutral,neutral,neutral,neutral
1925809846,"Just tested all 4 different modes for the node_prediction example, all work as expected.",tested different example work,issue,negative,neutral,neutral,neutral,neutral,neutral
1925742758,"Not sure, could you please detail what to check/try in more detailed manner?

×‘×ª××¨×™×š ×™×•× ××³, 4 ×‘×¤×‘×¨×³ 2024 ×‘-4:31 ×ž××ª Rhett Ying ***@***.***
>:

> On my ubuntu 20.04, libm is found below which links with GLIBC 2.31, not
> 2.27. could you confirm your lib? and have you ever built math lib on your
> own?
>
> ls -lh /lib/x86_64-linux-gnu/libm.so.6
>
> lrwxrwxrwx 1 root root 12 Nov 22 13:32 /lib/x86_64-linux-gnu/libm.so.6 -> libm-2.31.so
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/dmlc/dgl/issues/7046#issuecomment-1925556055>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AVTIJUDLKGFGYLNOMIVZHR3YR3XGXAVCNFSM6AAAAABCRPQQAGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSMRVGU2TMMBVGU>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",sure could please detail detailed manner found link could confirm ever built math root root reply directly view id,issue,positive,positive,positive,positive,positive,positive
1925718162,Let's wait for #7083 to be merged first so that I can test the link prediction example in this PR properly.,let wait first test link prediction example properly,issue,negative,positive,positive,positive,positive,positive
1925607039,"@drivanov Sorry for the vagueness. What I mean is if we mean to verify such warning is thrown or inevitable, then directly wrap with `with pytest.warns()` instead of a wrapper like `_ondist_xx()` you did. For other testcases that throw warning, we just remove the edge feature or specify `include_original_eids=True` to eliminate the warnings.",sorry vagueness mean mean verify warning thrown inevitable directly wrap instead wrapper like throw warning remove edge feature specify eliminate,issue,negative,negative,negative,negative,negative,negative
1925556055,"On my ubuntu 20.04, `libm` is found below which links with GLIBC 2.31, not 2.27. could you confirm your lib? and have you ever built math lib on your own?
```
ls -lh /lib/x86_64-linux-gnu/libm.so.6
```
```
lrwxrwxrwx 1 root root 12 Nov 22 13:32 /lib/x86_64-linux-gnu/libm.so.6 -> libm-2.31.so
```",found link could confirm ever built math root root,issue,negative,neutral,neutral,neutral,neutral,neutral
1925186420,I didn't know `TORCH_CHECK` supports such mixed parameters for the error message. Really convenient.,know mixed error message really convenient,issue,negative,positive,neutral,neutral,positive,positive
1924737358,"ldd (Ubuntu GLIBC 2.31-0ubuntu9.14) 2.31
Copyright (C) 2020 Free Software Foundation, Inc.
This is free software; see the source for copying conditions.  There is NO
warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.
Written by Roland McGrath and Ulrich Drepper.

/usr/bin/ldd

Linux newton 5.4.0-169-generic #187-Ubuntu SMP Thu Nov 23 14:52:28 UTC 2023
x86_64 x86_64 x86_64 GNU/Linux

After installing using pip I still have: OSError: /lib64/libm.so.6: version
`GLIBC_2.27' not found


â€«×‘×ª××¨×™×š ×™×•× ×•×³, 2 ×‘×¤×‘×¨×³ 2024 ×‘-3:05 ×ž××ª â€ªRhett Yingâ€¬â€ <â€ª
***@***.***â€¬â€>:â€¬

> could you run below commands on your system and share the outputs?
>
>    1. ldd --version
>    2. which ldd
>    3. uname -a
>
> And could you try to install via pip: pip install dgl -f
> https://data.dgl.ai/wheels/cu121/repo.html?
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/dmlc/dgl/issues/7046#issuecomment-1922599814>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AVTIJUEMYLJOXPYXLGNFUGTYRQ3TXAVCNFSM6AAAAABCRPQQAGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSMRSGU4TSOBRGQ>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",copyright free foundation free see source warranty even fitness particular purpose written newton generic pip still version found could run system share version could try install via pip pip install reply directly view id,issue,positive,positive,positive,positive,positive,positive
1924572939,"@Rhett-Ying :  Sorry, I'm not sure I understand what you're talking about. We already have similar captures of that warning [here](https://github.com/dmlc/dgl/blob/master/tests/python/pytorch/graphbolt/impl/test_ondisk_dataset.py#L2097-L2103) and [here](https://github.com/dmlc/dgl/blob/master/tests/python/pytorch/graphbolt/impl/test_ondisk_dataset.py#L2986C1-L2990C71). They are generated only for `include_original_edge_id=False`. I created a generic function for these two and 24 other cases.

Note that I'm not simply suppressing this warning even though it won't be generated. With the following lines:
```
    with pytest.warns(
        DGLWarning,
        match=""Edge feature is stored, but edge IDs are not saved."",
    ):
```
the program **expects** that this warning will be generated, therefore  it should be considered as  **inevitable**

Moreover, if the program **expects** to see, but won't see, this warning for some test, that test will fail with the following error message:
```
================================================================================= short test summary info =================================================================================
FAILED tests/python/pytorch/graphbolt/impl/test_ondisk_dataset.py::test_OnDiskDataset_preprocess_auto_force_preprocess - Failed: DID NOT WARN. No warnings of type (<class 'dgl.base.DGLWarning'>,) were emitted.
```

I just got it with the following changes:
```
        # 4. Change nothing.
        with pytest.warns(
            DGLWarning,
            match=""Edge feature is stored, but edge IDs are not saved."",
        ):
            preprocessed_metadata_path = (
                gb.ondisk_dataset.preprocess_ondisk_dataset(
                    test_dir, include_original_edge_id=True
                )
            )
```
I made to  `test_OnDiskDataset_preprocess_auto_force_preprocess`. As you could see, here `include_original_edge_id=True`, therefore, this warning should not have been generated, and when it was not captured, this test failed.",sorry sure understand talking already similar warning generic function two note simply warning even though wo following edge feature edge saved program warning therefore considered inevitable moreover program see wo see warning test test fail following error message short test summary warn type class got following change nothing edge feature edge saved made could see therefore warning test,issue,negative,negative,neutral,neutral,negative,negative
1924471535,"> please verify if `is_inplace_pinned` and revert the change here. others look good to me. please ping me once addressed the comments.

@Rhett-Ying :  just checked out [fix#7044](https://github.com/dmlc/dgl/pull/7044) for `is_inplace_pinned` and reverted my change for this issue.",please verify revert change look good please ping checked fix change issue,issue,positive,positive,positive,positive,positive,positive
1923921763,"> > What happens when `dgl` is imported directly? I just wanted to know as the PR description is not very clear about the reason.
> 
> These changes are suggested by @Rhett-Ying . The PR [#6986], which makes use of `dgl.sparse`, failed CI in stage **PyTorch Cugraph GPU Unit test**, reporting ""_FileNotFoundError: Cannot find DGL C++ sparse library at /home/ubuntu/jenkins/workspace/dgl_PR-6986/build/dgl_sparse/libdgl_sparse_pytorch_2.0.0.so_"". We guess this is because `dgl.sparse` is not built in **PyTorch Cugraph GPU Unit test** of CI.
> 
> However, I am still not sure whether these changes will help PR [#6986] pass **PyTorch Cugraph GPU Unit test**. I will be more than excited to learn other solutions if you @mfbalin have more insights into this problem.

Thank you for the reply. I asked because I wanted to learn from you, not the other way around :).

If this PR doesn't solve the CI issue, I will also think about it.",directly know description clear reason use stage unit test find sparse library guess built unit test however still sure whether help pas unit test excited learn problem thank reply learn way around solve issue also think,issue,positive,positive,positive,positive,positive,positive
1923895503,"> What happens when `dgl` is imported directly? I just wanted to know as the PR description is not very clear about the reason.

These changes are suggested by @Rhett-Ying . The PR [#6986], which makes use of `dgl.sparse`, failed CI in stage **PyTorch Cugraph GPU Unit test**, reporting ""_FileNotFoundError: Cannot find DGL C++ sparse library at /home/ubuntu/jenkins/workspace/dgl_PR-6986/build/dgl_sparse/libdgl_sparse_pytorch_2.0.0.so_"". We guess this is because `dgl.sparse` is not built in **PyTorch Cugraph GPU Unit test** of CI.

However, I am still not sure whether these changes will help PR [#6986] pass **PyTorch Cugraph GPU Unit test**. I will be more than excited to learn other solutions if you @mfbalin  have more insights into this problem.",directly know description clear reason use stage unit test find sparse library guess built unit test however still sure whether help pas unit test excited learn problem,issue,positive,positive,positive,positive,positive,positive
1923830368,"Could you see if switching to g++-10 fixes the issue? You can see the following issues similar to yours:

https://github.com/NVIDIA/nccl/issues/650
https://github.com/NVlabs/instant-ngp/issues/119",could see switching issue see following similar,issue,negative,neutral,neutral,neutral,neutral,neutral
1923825118,What happens when `dgl` is imported directly? I just wanted to know as the PR description is not very clear about the reason.,directly know description clear reason,issue,negative,positive,neutral,neutral,positive,positive
1923759285,"The build configuration changed recently, do you still have the compilation issue @jinfeng-data?",build configuration recently still compilation issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1923756460,"The requirements of GPU cache are here: https://github.com/dmlc/dgl/tree/master/third_party/HugeCTR/gpu_cache#requirements, any CUDA version >= 11.0 should work in theory. I am looking into it.",cache version work theory looking,issue,negative,neutral,neutral,neutral,neutral,neutral
1923753323,"Hi @jinfeng-data, can you try and see if you can compile with a newer CUDA version?",hi try see compile version,issue,negative,neutral,neutral,neutral,neutral,neutral
1923536136,"> My experiment and suggestion above is a nit, I just wanted to see what is the best way to do it.

I see. I will change it later for better performance.",experiment suggestion nit see best way see change later better performance,issue,positive,positive,positive,positive,positive,positive
1923515771,"My experiment and suggestion above is a nit, I just wanted to see what is the best way to do it.",experiment suggestion nit see best way,issue,positive,positive,positive,positive,positive,positive
1923512204,"I was experimenting to see what is the best way to create such tensors, below, you can see what I did:

The output of the code below on colab is as follows:

```
(<torch.utils.benchmark.utils.common.Measurement object at 0x7d385ed635b0>
 f(10000000, 20000000)
 setup: import torch
   604.70 us
   1 measurement, 1000 runs , 1 thread,
 <torch.utils.benchmark.utils.common.Measurement object at 0x7d377182ef80>
 f(10000000, 20000000)
 setup: import torch
   133.53 us
   1 measurement, 1000 runs , 1 thread)
```

```python
import torch
import torch.utils.benchmark as benchmark
 
def f(pos_num, neg_num, dtype=torch.bool, device=""cuda:0""):
    return torch.cat(
        (
            torch.ones(
                pos_num,
                dtype=dtype,
                device=device,
            ),
            torch.zeros(
                neg_num,
                dtype=dtype,
                device=device,
            ),
        ),
    )

def g(pos_num, neg_num, dtype=torch.bool, device=""cuda:0""):
    labels = torch.empty(pos_num + neg_num, dtype=dtype, device=device)
    labels[:pos_num] = 1
    labels[pos_num:] = 0
    return labels

assert torch.equal(f(10, 20), g(10, 20))

N = 10000000
neg_factor = 2

stmt = f'f({N}, {N * neg_factor})'

f_timer = benchmark.Timer(stmt=stmt, setup='import torch', globals={'f': f})
g_timer = benchmark.Timer(stmt=stmt, setup='import torch', globals={'f': g})

f_timer.timeit(1000), g_timer.timeit(1000)
```",see best way create see output code object setup import torch u measurement thread object setup import torch u measurement thread python import torch import return return assert torch torch,issue,positive,positive,positive,positive,positive,positive
1923389857,"@frozenbugs I am hoping that with my most recent commits, the main concerns related to your previous reviews should be addressed now.",recent main related previous,issue,negative,neutral,neutral,neutral,neutral,neutral
1923339524,"1. could you try to install with pip instead of conda?
2. what is the GLIBC version on your machine? `ldd --vesiion`",could try install pip instead version machine,issue,negative,neutral,neutral,neutral,neutral,neutral
1923331916,"@yxy235 If you ask for my review as well, it will be easier for me to keep track of what is changing when it comes to GPU GraphBolt support.",ask review well easier keep track come support,issue,positive,neutral,neutral,neutral,neutral,neutral
1922884483,"Typo, to support random walk sampling.",typo support random walk sampling,issue,negative,negative,negative,negative,negative,negative
1922599814,"could you run below commands on your system and share the outputs?
1. `ldd --version`
2. `which ldd`
3. `uname -a`

And could you try to install via pip: `pip install  dgl -f https://data.dgl.ai/wheels/cu121/repo.html`?",could run system share version could try install via pip pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1922009413,"The main problem seems to be the fact that the cuda wheels were uploaded to https://data.dgl.ai/wheels/repo.html, they probably should have been uploaded only to https://data.dgl.ai/wheels/cu121/repo.html instead.",main problem fact probably instead,issue,negative,positive,positive,positive,positive,positive
1921970272,"The issue seems to be related to the following:
Wheel with no CUDA: [dgl-2.0.0-cp310-cp310-win_amd64.whl](https://data.dgl.ai/wheels/dgl-2.0.0-cp310-cp310-win_amd64.whl)
Wheel with CUDA: [dgl-2.0.0+cu121-cp310-cp310-win_amd64.whl](https://data.dgl.ai/wheels/dgl-2.0.0%2Bcu121-cp310-cp310-win_amd64.whl)
One can see that the CUDA wheel name is lexicographically smaller than the no CUDA one due to `+ < -`.
However, I am not sure if that is exactly how it works. I am currently looking into it.",issue related following wheel wheel one see wheel name lexicographically smaller one due however sure exactly work currently looking,issue,negative,positive,neutral,neutral,positive,positive
1921934786,"One of the warnings was fixed in #7044. If you merge into the latest master, I believe it should go away.",one fixed merge latest master believe go away,issue,negative,positive,positive,positive,positive,positive
1921007111,"Ubuntu 20.04

â€«×‘×ª××¨×™×š ×™×•× ×”×³, 1 ×‘×¤×‘×¨×³ 2024 ×‘-5:00 ×ž××ª â€ªRhett Yingâ€¬â€ <â€ª
***@***.***â€¬â€>:â€¬

> @yonatansverdlov <https://github.com/yonatansverdlov> pls note that
> ubuntu20.04/CentOS8/RHEL8 or above are required since DGL 2.0
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/dmlc/dgl/issues/7046#issuecomment-1920409062>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AVTIJUATJS5K4UYJHQY6HRLYRMAMNAVCNFSM6AAAAABCRPQQAGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSMRQGQYDSMBWGI>
> .
> You are receiving this because you were mentioned.Message ID:
> ***@***.***>
>
",note since reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1920670520,"See the end of the page: https://docs.python.org/3/library/queue.html

![image](https://github.com/dmlc/dgl/assets/16190101/f1aaa864-a0ba-4b27-95af-8c1cf69c15a5)
",see end page image,issue,negative,neutral,neutral,neutral,neutral,neutral
1920663342,any detailed reason for such difference? is `queue` implemented based on `deque`?,detailed reason difference queue based,issue,negative,positive,positive,positive,positive,positive
1920642457,"> do you profile with python 37+ as the link you pasted is almost 10 years ago and it's python 2.7?

https://colab.research.google.com/drive/1-__8Ud09DiXcnjBstBZGuLR-OOMIBBun?usp=sharing

Runtimes below:
```
deque 0.04945635795593262
Queue 0.6552836894989014
```",profile python link pasted almost ago python queue,issue,negative,neutral,neutral,neutral,neutral,neutral
1920630671,do you profile with python 37+ as the link you pasted is almost 10 years ago and it's python 2.7?,profile python link pasted almost ago python,issue,negative,neutral,neutral,neutral,neutral,neutral
1920513263,"> @Gibyeng One more question, are you trying to install on linux machine directly or working within a docker container? We just found `torch-scatter` installation failure happens in docker container only.

Directly on the machine. I tried again just now,  tihs time I can create the env with no problem.",one question trying install machine directly working within docker container found installation failure docker container directly machine tried time create problem,issue,negative,negative,neutral,neutral,negative,negative
1920510130,"> Could you try it again? `torch-scatter` was introduced during our test and it has been removed. You were just unlucky I guess...

It works fine to me now.",could try test removed unlucky guess work fine,issue,negative,positive,positive,positive,positive,positive
1920457276,"LGTM to me, @peizhou001 please take anther look and approve.",please take anther look approve,issue,negative,neutral,neutral,neutral,neutral,neutral
1920452473,"Yes, I also try to re-execute this command. I think it would not cause an error now.",yes also try command think would cause error,issue,negative,neutral,neutral,neutral,neutral,neutral
1920411668,"@Gibyeng One more question, are you trying to install on linux machine directly or working within a docker container? We just found `torch-scatter` installation failure happens in docker container only.",one question trying install machine directly working within docker container found installation failure docker container,issue,negative,negative,negative,negative,negative,negative
1920358092,Could you try it again?  `torch-scatter` was introduced during our test and it has been removed.  You were just unlucky I guess...,could try test removed unlucky guess,issue,negative,neutral,neutral,neutral,neutral,neutral
1920349521,"Sorry, I meant what is your Linux distro and version number?  (Ubuntu 20.04, CentOS 7, etc.)

It seems that your math library `libm` is linked to a GLIBC library of 2.27 or newer, but your system GLIBC library has an older version.  This usually should not happen as they are both fundamental system libraries if you normally use package managers for dependency management.  Did you build the math library or GLIBC by yourself?",sorry meant version number math library linked library system library older version usually happen fundamental system normally use package dependency management build math library,issue,negative,negative,negative,negative,negative,negative
1919833528,"Also, for each different mode of graph and feature storages, we need copy_to inserted. This makes the examples quite bulky. We could probably insert it only at the end and let the dataloader move it further up. This would also fix #6981.",also different mode graph feature need inserted quite bulky could probably insert end let move would also fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1919826353,"The main examples take two parameters, storage device and device. To take advantage of this optimization, we need to move the features to the pinned memory even if the storage device is cpu.

Should we add one more parameter to the `args.mode` that denotes the `feature_storage`? Then, we would have the following modes:

`graph-features-device`: `cpu-cpu-cpu`, `cpu-cpu-cuda`, `cpu-pinned-cuda`, `pinned-pinned-cuda`, `cuda-pinned-cuda`, `cuda-cuda-cuda`.

@frozenbugs @Rhett-Ying ",main take two storage device device take advantage optimization need move pinned memory even storage device add one parameter would following,issue,positive,positive,neutral,neutral,positive,positive
1919125100,I am quite happy with the final refactored version. Quite elegant in my opinion thanks to the reviewers' help.,quite happy final version quite elegant opinion thanks help,issue,positive,positive,positive,positive,positive,positive
1918979906,I will open a PR showing how to use dgl.sparse to implement a custom sampler soon.,open showing use implement custom sampler soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1918979052,@frozenbugs I think we can ship not only the feature fetch overlap but also the graph fetch overlap optimizations. Do you think we can make another release blog mentioning these techniques? We can also mention using dgl.sparse for the sampling operation by implementing LADIES sampler with all these optimizations enabled through GraphBolt.,think ship feature fetch overlap also graph fetch overlap think make another release also mention sampling operation lady sampler,issue,negative,neutral,neutral,neutral,neutral,neutral
1918785243,"linux

â€«×‘×ª××¨×™×š ×™×•× ×“×³, 31 ×‘×™× ×•×³ 2024 ×‘-10:07 ×ž××ª â€ªQuan (Andy) Ganâ€¬â€ <â€ª
***@***.***â€¬â€>:â€¬

> What is your OS?
>
> â€”
> Reply to this email directly, view it on GitHub
> <https://github.com/dmlc/dgl/issues/7046#issuecomment-1918588088>, or
> unsubscribe
> <https://github.com/notifications/unsubscribe-auth/AVTIJUBN5HDLZYKPMA7MFO3YRH3V7AVCNFSM6AAAAABCRPQQAGVHI2DSMVQWIX3LMV43OSLTON2WKQ3PNVWWK3TUHMYTSMJYGU4DQMBYHA>
> .
> You are receiving this because you authored the thread.Message ID:
> ***@***.***>
>
",o reply directly view id,issue,negative,positive,neutral,neutral,positive,positive
1916126388,"For the discussion about whether we need overlap_feature_fetch, let's keep for a while after release, and clean it up if it is proven to be a stable solution for different hardware config.",discussion whether need let keep release clean proven stable solution different hardware,issue,positive,positive,positive,positive,positive,positive
1916006969,@Rhett-Ying I think I finally did it the right way. Should be ready to merge if it looks good to you.,think finally right way ready merge good,issue,positive,positive,positive,positive,positive,positive
1915940526,"> @caojy1998 do you have any timeline on when we can have `ogbn-papers100M` as a built-in dataset? I would like to update the multiGPU example to have the papers100M as an option.

Maybe we can expect we have a version before Feb 9th.",would like update example option maybe expect version th,issue,negative,neutral,neutral,neutral,neutral,neutral
1914857162,@caojy1998 do you have any timeline on when we can have `ogbn-papers100M` as a built-in dataset? I would like to update the multiGPU example to have the papers100M as an option.,would like update example option,issue,negative,neutral,neutral,neutral,neutral,neutral
1914366587,"the code LGTM now, can you run `lintrunner -a` to fix the lint error? and can you add a unit test for your code.

The test case can be put here: [tests/python/pytorch/dataloading](https://github.com/dmlc/dgl/tree/master/tests/python/pytorch/dataloading), and you can use this test case as example: https://github.com/dmlc/dgl/blob/master/tests/python/pytorch/graphbolt/impl/test_in_subgraph_sampler.py",code run fix lint error add unit test code test case put use test case example,issue,negative,neutral,neutral,neutral,neutral,neutral
1914212272,"@Rhett-Ying I just fixed the root cause, it was the buggy use of `_find_and_wrap_parent`. Because it modifies the datapipe_graph parameter it receives, it needs to return the modified version back to the user.",fixed root cause buggy use parameter need return version back user,issue,negative,positive,neutral,neutral,positive,positive
1914072012,@Skeleton003 please work on the design doc first.,skeleton please work design doc first,issue,negative,positive,positive,positive,positive,positive
1913388407,"Thanks for the edits, @frozenbugs. Happy to address all the formatting errors. Do you see any issues with the function implementation itself?",thanks happy address see function implementation,issue,positive,positive,positive,positive,positive,positive
1912787567,"LGTM. And confirmed the accuracy is back to 0.7141 with an 8GPU test. And with the overlap feature, the performance improved about 17% for per epoch training time.",confirmed accuracy back test overlap feature performance per epoch training time,issue,negative,positive,positive,positive,positive,positive
1912089881,I know how to make the current implementation deterministic. We can discuss if you would like to hear it.,know make current implementation deterministic discus would like hear,issue,negative,neutral,neutral,neutral,neutral,neutral
1911797094,"To double check, I printed before reduce and after reduce:
```
Training...
48it [00:03, 12.19it/s]
Validating...
10it [00:00, 15.82it/s]
0 tensor(0.7791, device='cuda:0')
1 tensor(0.7715, device='cuda:1')
3 tensor(0.7722, device='cuda:3')
2 tensor(0.7752, device='cuda:2')
Epoch 00000 | Average Loss 2.4012 | Accuracy 0.7745 | Time 4.7326
```
The average is correctly being computed without any barrier or synchronization calls.",double check printed reduce reduce training tensor tensor tensor tensor epoch average loss accuracy time average correctly without barrier synchronization,issue,negative,negative,neutral,neutral,negative,negative
1911713197,"<details><summary>Output of the code without `dist.barrier()`</summary>
<p>

Training with 4 gpus.
The dataset is already preprocessed.
Training...
48it [00:04, 10.66it/s]
Validating...
10it [00:00, 10.12it/s]
Epoch 00000 | Average Loss 2.3168 | Accuracy 0.7865 | Time 5.5491
48it [00:01, 28.29it/s]
Validating...
10it [00:00, 36.07it/s]
Epoch 00001 | Average Loss 0.9710 | Accuracy 0.8419 | Time 2.2026
48it [00:01, 24.33it/s]
Validating...
10it [00:00, 32.25it/s]
Epoch 00002 | Average Loss 0.7345 | Accuracy 0.8605 | Time 2.3079
48it [00:01, 28.20it/s]
Validating...
10it [00:00, 37.16it/s]
Epoch 00003 | Average Loss 0.6306 | Accuracy 0.8700 | Time 1.9945
48it [00:02, 21.81it/s]
Validating...
10it [00:00, 36.24it/s]
Epoch 00004 | Average Loss 0.5645 | Accuracy 0.8772 | Time 2.5011
48it [00:01, 28.22it/s]
Validating...
10it [00:00, 24.57it/s]
Epoch 00005 | Average Loss 0.5239 | Accuracy 0.8832 | Time 2.1315
48it [00:01, 28.49it/s]
Validating...
10it [00:00, 38.09it/s]
Epoch 00006 | Average Loss 0.4918 | Accuracy 0.8830 | Time 2.5510
48it [00:01, 27.96it/s]
Validating...
10it [00:00, 36.42it/s]
Epoch 00007 | Average Loss 0.4692 | Accuracy 0.8884 | Time 2.0129
48it [00:01, 28.27it/s]
Validating...
10it [00:00, 35.34it/s]
Epoch 00008 | Average Loss 0.4505 | Accuracy 0.8897 | Time 2.0001
48it [00:01, 28.69it/s]
Validating...
10it [00:00, 19.44it/s]
Epoch 00009 | Average Loss 0.4357 | Accuracy 0.8913 | Time 2.2071
Testing...
541it [00:18, 29.33it/s]
Test Accuracy 0.7410

</p>
</details>



<details><summary>Output of the code with `dist.barrier()`</summary>
<p>

Training with 4 gpus.
The dataset is already preprocessed.
Training...
48it [00:03, 12.29it/s]
Validating...
10it [00:00, 10.37it/s]
Epoch 00000 | Average Loss 2.2419 | Accuracy 0.7864 | Time 4.9177
48it [00:02, 23.59it/s]
Validating...
10it [00:00, 17.37it/s]
Epoch 00001 | Average Loss 0.9524 | Accuracy 0.8430 | Time 2.6339
48it [00:02, 22.12it/s]
Validating...
10it [00:00, 39.49it/s]
Epoch 00002 | Average Loss 0.7151 | Accuracy 0.8613 | Time 2.4796
48it [00:02, 23.06it/s]
Validating...
10it [00:00, 38.47it/s]
Epoch 00003 | Average Loss 0.6128 | Accuracy 0.8712 | Time 2.3739
48it [00:01, 28.55it/s]
Validating...
10it [00:00, 32.66it/s]
Epoch 00004 | Average Loss 0.5513 | Accuracy 0.8772 | Time 2.0109
48it [00:01, 28.54it/s]
Validating...
10it [00:00, 13.37it/s]
Epoch 00005 | Average Loss 0.5116 | Accuracy 0.8821 | Time 2.4538
48it [00:02, 23.71it/s]
Validating...
10it [00:00, 32.75it/s]
Epoch 00006 | Average Loss 0.4851 | Accuracy 0.8860 | Time 2.6003
48it [00:01, 28.59it/s]
Validating...
10it [00:00, 11.73it/s]
Epoch 00007 | Average Loss 0.4598 | Accuracy 0.8879 | Time 2.5554
48it [00:01, 28.68it/s]
Validating...
10it [00:00, 33.32it/s]
Epoch 00008 | Average Loss 0.4466 | Accuracy 0.8911 | Time 1.9959
48it [00:01, 28.53it/s]
Validating...
10it [00:00, 33.29it/s]
Epoch 00009 | Average Loss 0.4297 | Accuracy 0.8917 | Time 2.0093
Testing...
541it [00:18, 28.80it/s]
Test Accuracy 0.7421

</p>
</details> ",summary output code without training already training epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time testing test accuracy summary output code training already training epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time epoch average loss accuracy time testing test accuracy,issue,negative,negative,negative,negative,negative,negative
1911179462,"Our team has done some triage into this issue. Looks like that the with CUDA the float32 datatype was used, so the precision can go to about 7 digits. We recommend doing either 6- or 7-digits precision comparison.  ",team done triage issue like float used precision go recommend either precision comparison,issue,positive,neutral,neutral,neutral,neutral,neutral
1910807800,Currently disabling the overlap feature bring the accuracy back. Thx @mfbalin ,currently overlap feature bring accuracy back,issue,negative,neutral,neutral,neutral,neutral,neutral
1909721646,"Hi @yxgu2353 , I am closing this issue assuming you are happy about our response. Feel free to follow up and reopen the issue if you have more questions with regard to our response.",hi issue assuming happy response feel free follow reopen issue regard response,issue,positive,positive,positive,positive,positive,positive
1909606953,@Skeleton003  pls rebase on latest master and resolve the conflicts,skeleton rebase latest master resolve,issue,negative,positive,positive,positive,positive,positive
1909526553,"only the sampled node pairs are required, no need to recover hetero info. so it's different from existing `FusedCSCSamplingGraph.sample_neighbors()`.",node need recover hetero different,issue,negative,neutral,neutral,neutral,neutral,neutral
1909444004,"> However, how do you think we can check the graph in a general manner? The user might pass sample_neighbors, sample_layer_neighbors or any other custom datapipes. The features could be custom too.

I am not sure whether I understand this comment, but for the discussion before this one, I think the error msg reported by Rui is not very bad, if we want to clarify more, adding a python try-catch to wrap the call of copy_to and clarify the error msg should be enough.",however think check graph general manner user might pas custom could custom sure whether understand comment discussion one think error bad want clarify python wrap call clarify error enough,issue,negative,negative,neutral,neutral,negative,negative
1909390221,"The issue is that the installation instructions are faulty and even when one selects NONE for CUDA, the command it gives installs a CUDA version. What is the pip install command to install a non-cuda version? Thank you.",issue installation faulty even one none command version pip install command install version thank,issue,negative,neutral,neutral,neutral,neutral,neutral
1909264006,"Seems you install dgl CUDA version in a machine without CUDA, please install the CPU version.
",install version machine without please install version,issue,negative,neutral,neutral,neutral,neutral,neutral
1907324077,"@frozenbugs 

This is the removing duplicate from PyGï¼š https://github.com/pyg-team/pytorch_geometric/blob/master/torch_geometric/utils/_coalesce.py

 But I didn't see how it is being imported and used in its example: https://github.com/pyg-team/pytorch_geometric/blob/master/examples/ogbn_products_sage.py ",removing duplicate see used example,issue,negative,neutral,neutral,neutral,neutral,neutral
1906745399,"sample_neighbor:
```
mfbalin@BALIN-PC:~/dgl-1/examples/sampling/graphbolt/lightning$ time python ../node_classification.py --mode=cuda-cuda
Training in cuda-cuda mode.
Loading data...
The dataset is already preprocessed.
Training...
Training: 193it [00:03, 56.63it/s]
Evaluating: 39it [00:00, 82.79it/s]
Epoch 00000 | Loss 1.3463 | Accuracy 0.8546 | Time 3.4102
Training: 193it [00:03, 58.04it/s]
Evaluating: 39it [00:00, 93.24it/s]
Epoch 00001 | Loss 0.6015 | Accuracy 0.8772 | Time 3.3272
Training: 193it [00:03, 62.76it/s]
Evaluating: 39it [00:00, 89.93it/s]
Epoch 00002 | Loss 0.4923 | Accuracy 0.8855 | Time 3.0765
Training: 193it [00:03, 56.94it/s]
Evaluating: 39it [00:00, 86.70it/s]
Epoch 00003 | Loss 0.4435 | Accuracy 0.8899 | Time 3.3910
Training: 193it [00:03, 60.06it/s]
Evaluating: 39it [00:00, 93.32it/s]
Epoch 00004 | Loss 0.4156 | Accuracy 0.8923 | Time 3.2145
Training: 193it [00:03, 59.32it/s]
Evaluating: 39it [00:00, 84.14it/s]
Epoch 00005 | Loss 0.3964 | Accuracy 0.8964 | Time 3.2547
Training: 193it [00:03, 59.73it/s]
Evaluating: 39it [00:00, 83.30it/s]
Epoch 00006 | Loss 0.3812 | Accuracy 0.8964 | Time 3.2326
Training: 193it [00:03, 58.72it/s]
Evaluating: 39it [00:00, 83.97it/s]
Epoch 00007 | Loss 0.3815 | Accuracy 0.8977 | Time 3.2878
Training: 193it [00:03, 63.09it/s]
Evaluating: 39it [00:00, 93.26it/s]
Epoch 00008 | Loss 0.3708 | Accuracy 0.9005 | Time 3.0602
Training: 193it [00:03, 62.66it/s]
Evaluating: 39it [00:00, 85.37it/s]
Epoch 00009 | Loss 0.3534 | Accuracy 0.9019 | Time 3.0814
Testing...
598it [00:02, 232.05it/s]
598it [00:02, 224.06it/s]
598it [00:02, 289.34it/s]
Test accuracy 0.7621

real    0m51.041s
user    2m32.037s
sys     0m13.134s
```
sample_neighbor2:
```
mfbalin@BALIN-PC:~/dgl-1/examples/sampling/graphbolt/lightning$ time python ../node_classification.py --mode=cuda-cuda
Training in cuda-cuda mode.
Loading data...
The dataset is already preprocessed.
Training...
/home/mfbalin/.local/lib/python3.10/site-packages/torch/utils/data/datapipes/utils/common.py:141: UserWarning: Local function is not supported by pickle, please use regular python function or functools.partial instead.
  warnings.warn(
Training: 193it [00:03, 54.45it/s]
Evaluating: 39it [00:00, 75.89it/s]
Epoch 00000 | Loss 1.2735 | Accuracy 0.8571 | Time 3.5468
Training: 193it [00:03, 61.34it/s]
Evaluating: 39it [00:00, 81.49it/s]
Epoch 00001 | Loss 0.5809 | Accuracy 0.8773 | Time 3.1485
Training: 193it [00:03, 59.74it/s]
Evaluating: 39it [00:00, 71.88it/s]
Epoch 00002 | Loss 0.4913 | Accuracy 0.8861 | Time 3.2323
Training: 193it [00:03, 63.60it/s]
Evaluating: 39it [00:00, 86.88it/s]
Epoch 00003 | Loss 0.4441 | Accuracy 0.8912 | Time 3.0362
Training: 193it [00:03, 62.74it/s]
Evaluating: 39it [00:00, 79.67it/s]
Epoch 00004 | Loss 0.4180 | Accuracy 0.8940 | Time 3.0776
Training: 193it [00:03, 61.73it/s]
Evaluating: 39it [00:00, 84.68it/s]
Epoch 00005 | Loss 0.4019 | Accuracy 0.8961 | Time 3.1277
Training: 193it [00:03, 61.69it/s]
Evaluating: 39it [00:00, 77.86it/s]
Epoch 00006 | Loss 0.3848 | Accuracy 0.8976 | Time 3.1301
Training: 193it [00:02, 65.94it/s]
Evaluating: 39it [00:00, 67.68it/s]
Epoch 00007 | Loss 0.3744 | Accuracy 0.8991 | Time 2.9285
Training: 193it [00:02, 65.85it/s]
Evaluating: 39it [00:00, 79.20it/s]
Epoch 00008 | Loss 0.3684 | Accuracy 0.9015 | Time 2.9325
Training: 193it [00:02, 65.26it/s]
Evaluating: 39it [00:00, 84.56it/s]
Epoch 00009 | Loss 0.3579 | Accuracy 0.9016 | Time 2.9591
Testing...
598it [00:02, 224.16it/s]
598it [00:02, 212.81it/s]
598it [00:02, 266.85it/s]
Test accuracy 0.7675

real    0m50.712s
user    2m34.052s
sys     0m13.463s",time python training mode loading data already training training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time testing test accuracy real user time python training mode loading data already training local function pickle please use regular python function instead training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time testing test accuracy real user,issue,negative,positive,neutral,neutral,positive,positive
1906670057,"My latest commit, after PR and with unlimited CUDA threads, 559ms -> 575ms, reduced the regression from 5.5% to 2.8% while still providing more than 30% gains in the limited case:

<details><summary>New results with latest commit to reduce regression without limiting CUDA threads</summary>
<p>

```
* params:  n_rows=128000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 22560, Throughput in MiB/s: 2029


* params:  n_rows=128000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1966, Throughput in MiB/s: 2328


* params:  n_rows=128000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 233, Throughput in MiB/s: 196


* params:  n_rows=128000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 21998, Throughput in MiB/s: 2080


* params:  n_rows=128000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1957, Throughput in MiB/s: 2338


* params:  n_rows=128000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 218, Throughput in MiB/s: 209


* params:  n_rows=16000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 18377, Throughput in MiB/s: 14113


* params:  n_rows=16000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1991, Throughput in MiB/s: 13024


* params:  n_rows=16000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 263, Throughput in MiB/s: 983


* params:  n_rows=16000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 16608, Throughput in MiB/s: 15618


* params:  n_rows=16000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1876, Throughput in MiB/s: 13824


* params:  n_rows=16000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 302, Throughput in MiB/s: 856


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 10267, Throughput in MiB/s: 4458


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1165, Throughput in MiB/s: 3928


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 302, Throughput in MiB/s: 150


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 9714, Throughput in MiB/s: 4712


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1089, Throughput in MiB/s: 4201


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 220, Throughput in MiB/s: 207


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 11002, Throughput in MiB/s: 6934


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1284, Throughput in MiB/s: 5940


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 181, Throughput in MiB/s: 420


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 9622, Throughput in MiB/s: 7928


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1053, Throughput in MiB/s: 7239


* params:  n_rows=16000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 196, Throughput in MiB/s: 388


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 49405, Throughput in MiB/s: 20078


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 5133, Throughput in MiB/s: 19328


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 226, Throughput in MiB/s: 4367


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 47704, Throughput in MiB/s: 20790


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 4955, Throughput in MiB/s: 20013


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 275, Throughput in MiB/s: 3596


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 90000, Throughput in MiB/s: 21868


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 9214, Throughput in MiB/s: 21360


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 264, Throughput in MiB/s: 7458


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 89198, Throughput in MiB/s: 22067


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 9053, Throughput in MiB/s: 21741


* params:  n_rows=2000000, avg_degree=256, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 245, Throughput in MiB/s: 8015


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 17230, Throughput in MiB/s: 15054


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1941, Throughput in MiB/s: 13364


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 261, Throughput in MiB/s: 994


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 15575, Throughput in MiB/s: 16654


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1751, Throughput in MiB/s: 14811


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 243, Throughput in MiB/s: 1066


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 26330, Throughput in MiB/s: 19117


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 2937, Throughput in MiB/s: 17136


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 245, Throughput in MiB/s: 2042


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 24612, Throughput in MiB/s: 20458


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 2784, Throughput in MiB/s: 18086


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 196, Throughput in MiB/s: 2560


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 8786, Throughput in MiB/s: 5210


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1139, Throughput in MiB/s: 4018


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 230, Throughput in MiB/s: 197


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 8727, Throughput in MiB/s: 5244


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1046, Throughput in MiB/s: 4373


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 239, Throughput in MiB/s: 190


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 9421, Throughput in MiB/s: 8099


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1218, Throughput in MiB/s: 6262


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 246, Throughput in MiB/s: 310


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 8707, Throughput in MiB/s: 8762


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1055, Throughput in MiB/s: 7225


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 228, Throughput in MiB/s: 334


Total runtimes in us:  {<Device.Pinned: 1>: 575263}
```

</p>
</details> ",latest commit unlimited reduced regression still providing gain limited case summary new latest commit reduce regression without limiting u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput total u,issue,positive,positive,positive,positive,positive,positive
1906623145,"The general case is bound to regress a little bit because instead of having these kernels fused as before and having the UVA copy start immediately, now we launch one more kernel before performing the actual copy operation, so the PCI-e copies start later, which means they can utilize the PCI-e slightly less with unlimited number of threads.",general case bound regress little bit instead fused uva copy start immediately launch one kernel actual copy operation start later utilize slightly le unlimited number,issue,negative,negative,neutral,neutral,negative,negative
1906525358,"> Can you quantify the optimization?

@frozenbugs I updated the description. Ran the benchmark test with and without limiting the number of cuda threads used for the UVA copy. It looks like there is around %5.5 regression when we don't limit the number of CUDA threads used, 559ms -> 590ms but when we limit the CUDA threads to 6144, 1028ms -> 702ms, 32% speedup as expected. So my optimization is doing what it promises, I will try to reduce the amount of regression for the unlimited CUDA thread case.",quantify optimization description ran test without limiting number used uva copy like around regression limit number used limit optimization try reduce amount regression unlimited thread case,issue,positive,neutral,neutral,neutral,neutral,neutral
1906044524,"@jermainewang Broadcasting graph level features into node features solves problems that I mentioned, but on the other hand it makes entire model unnecessarily slower as much more calculations have to be done. By supporting graph-level features in dataloading pipeline do you mean that they will be available by calling DGLGraph? Because that would mean they will be callable during message passing if I understand correctly.",graph level node hand entire model unnecessarily much done supporting pipeline mean available calling would mean callable message passing understand correctly,issue,positive,positive,neutral,neutral,positive,positive
1905678696,"For `ItemSampler` , it's fixed in https://github.com/dmlc/dgl/pull/6982. One side effect of this fix is all workers are using same seed generator for `DistributedItemSampler`'s shuffle.",fixed one side effect fix seed generator shuffle,issue,negative,positive,neutral,neutral,positive,positive
1905591249,"According to recent use experience about `ItemSet`, `ItemSetDict` and `ItemSampler`, we'd better refactor these components to be clear and easy to use. For `ItemSet`, we could differentiate tensor-like data from stream data. For tensor-like data, we could iterate with better performance(the indexing way we're using for now). For stream data, we have to iterate over one by one. Namely, we have `IterableItemSet` and `MapItemSet`. As for `ItemSetDict`, it's like `Named` ones.",according recent use experience better clear easy use could differentiate data stream data data could iterate better performance indexing way stream data iterate one one namely like,issue,positive,positive,positive,positive,positive,positive
1905462723,"@Rhett-Ying the modified example is runnable. I will run the two versions and report if there is any regression. In my experience so far, the runtime didn't get affected at all, will provide actual data on it though.",example runnable run two report regression experience far get affected provide actual data though,issue,negative,positive,neutral,neutral,positive,positive
1905417415,"Splitting large datapipe(stage) into smaller ones(sub-stage) gives the chance for better pipelining, scheduling, then better performance in further. And this could further benefit from optimization in specific calls(OPs) such as sampling, compact. But the tradeoff between scheduling benefits and overhead incurred should be well measured and profiled. And I think the schedule logic(or top DataLoader) is the major part that needs sophisticated design to accommodate various cases.",splitting large stage smaller chance better better performance could benefit optimization specific sampling compact overhead well measured think schedule logic top major part need sophisticated design accommodate various,issue,positive,positive,positive,positive,positive,positive
1905373909,"> > Incorporating the concept of `pre-process` aligns with our plan. However, I am hesitant about transforming `sample_per_layer` and `compact_per_layer` into datapipes; this seems overly intricate and somewhat excessively optimized. In my view, a more straightforward and adaptable approach involves offering fundamental ops such as `sample` and compact, allowing users to assemble these ops as needed.
> > Additionally, there is a dependency between `sample` and `compact`, as well as between two layers of `sample`, preventing us from capitalizing on scheduling benefits by splitting them.
> 
> I am not sure I fully understand your point of view. I guess discussing this in a meeting is the best way forward as communication over text can be slow and prone to misunderstanding. Thank you very much for the early feedback!

Just ping me when needed, we can have a short meeting or discuss it in the weekly meeting",concept plan however hesitant transforming overly intricate somewhat excessively view straightforward adaptable approach offering fundamental sample compact assemble additionally dependency sample compact well two sample u splitting sure fully understand point view guess meeting best way forward communication text slow prone misunderstanding thank much early feedback ping short meeting discus weekly meeting,issue,positive,positive,positive,positive,positive,positive
1905372620,"I wanted to separate sampling and the compact operation because implementing the Cooperative Minibatching idea will require us to customize the compact operation later to avoid unnecessary work.

Cooperative Minibatching: https://arxiv.org/pdf/2310.12403.pdf",separate sampling compact operation idea require u compact operation later avoid unnecessary work,issue,negative,negative,negative,negative,negative,negative
1905371388,"> Incorporating the concept of `pre-process` aligns with our plan. However, I am hesitant about transforming `sample_per_layer` and `compact_per_layer` into datapipes; this seems overly intricate and somewhat excessively optimized. In my view, a more straightforward and adaptable approach involves offering fundamental ops such as `sample` and compact, allowing users to assemble these ops as needed.
> 
> Additionally, there is a dependency between `sample` and `compact`, as well as between two layers of `sample`, preventing us from capitalizing on scheduling benefits by splitting them.

I am not sure I fully understand your point of view. I guess discussing this in a meeting is the best way forward as communication over text can be slow and prone to misunderstanding. Thank you very much for the early feedback!",concept plan however hesitant transforming overly intricate somewhat excessively view straightforward adaptable approach offering fundamental sample compact assemble additionally dependency sample compact well two sample u splitting sure fully understand point view guess meeting best way forward communication text slow prone misunderstanding thank much early feedback,issue,positive,positive,positive,positive,positive,positive
1905368447,"Incorporating the concept of `pre-process` aligns with our plan. However, I am hesitant about transforming `sample_per_layer` and `compact_per_layer` into datapipes; this seems overly intricate and somewhat excessively optimized. In my view, a more straightforward and adaptable approach involves offering fundamental ops such as `sample` and compact, allowing users to assemble these ops as needed.

Additionally, there is a dependency between `sample` and `compact`, as well as between two layers of `sample`, preventing us from capitalizing on scheduling benefits by splitting them.",concept plan however hesitant transforming overly intricate somewhat excessively view straightforward adaptable approach offering fundamental sample compact assemble additionally dependency sample compact well two sample u splitting,issue,negative,positive,neutral,neutral,positive,positive
1905240023,"> @mfbalin if new mode is added, you'd better update the `README` accordingly.

I don't currently have the computational resources to run the mag240M example and update the numbers there. Could I ask you or anyone on the team to do that? That would be a big help.",new mode added better update accordingly currently computational run example update could ask anyone team would big help,issue,positive,positive,positive,positive,positive,positive
1905238606,"@mfbalin if new mode is added, you'd better update the `README` accordingly.",new mode added better update accordingly,issue,negative,positive,positive,positive,positive,positive
1905228724,"If we enable GPU sampling for this example as in #6958, the GPU runtimes should go down a lot more. Let's consider doing that or at least adding the option before the release?",enable sampling example go lot let consider least option release,issue,negative,negative,negative,negative,negative,negative
1901781621,"The reason why we might want to move the shuffling operation to the GPU is as you can see, it starts taking very long as the itemset size grows. That is why, it might be a good idea to have GPU option. Otherwise, GPUs will idle between epochs while shuffling.",reason might want move shuffling operation see taking long size might good idea option otherwise idle shuffling,issue,negative,positive,positive,positive,positive,positive
1901777296,"Actually, on my machine with AMD Ryzen 5950X CPU, torch seems to be the much more performant one:
```
len: 32768, device: cpu, numpy: 0.0017, torch: 0.0010
len: 32768, device: cuda, numpy: 0.0028, torch: 0.0050
len: 65536, device: cpu, numpy: 0.0053, torch: 0.0038
len: 65536, device: cuda, numpy: 0.0055, torch: 0.0039
len: 131072, device: cpu, numpy: 0.0119, torch: 0.0052
len: 131072, device: cuda, numpy: 0.0101, torch: 0.0060
len: 262144, device: cpu, numpy: 0.0174, torch: 0.0108
len: 262144, device: cuda, numpy: 0.0208, torch: 0.0050
len: 524288, device: cpu, numpy: 0.0380, torch: 0.0230
len: 524288, device: cuda, numpy: 0.0437, torch: 0.0086
len: 1048576, device: cpu, numpy: 0.0776, torch: 0.0530
len: 1048576, device: cuda, numpy: 0.0868, torch: 0.0156
len: 2097152, device: cpu, numpy: 0.1667, torch: 0.1479
len: 2097152, device: cuda, numpy: 0.2033, torch: 0.0585
len: 4194304, device: cpu, numpy: 0.4680, torch: 0.3354
len: 4194304, device: cuda, numpy: 0.5764, torch: 0.2689
len: 8388608, device: cpu, numpy: 1.2623, torch: 0.9207
len: 8388608, device: cuda, numpy: 1.4132, torch: 0.2697
len: 16777216, device: cpu, numpy: 3.0960, torch: 2.1247
len: 16777216, device: cuda, numpy: 3.4015, torch: 0.2903
len: 33554432, device: cpu, numpy: 6.9723, torch: 4.6462
len: 33554432, device: cuda, numpy: 7.4700, torch: 0.2341
len: 67108864, device: cpu, numpy: 14.5287, torch: 9.9723
len: 67108864, device: cuda, numpy: 15.6430, torch: 0.3678
len: 134217728, device: cpu, numpy: 30.6493, torch: 20.7330
len: 134217728, device: cuda, numpy: 32.3042, torch: 0.4654
```",actually machine torch much performant one device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch,issue,negative,positive,neutral,neutral,positive,positive
1901776128,"I benchmarked the two approaches and seems like numpy is faster on the CPU, at least in the Google Colab environment: https://colab.research.google.com/drive/1_5M2aLPrjLcHSrnTyT6GpB0FMyRhuCbO?usp=sharing

```python
import torch
import numpy
import time

def numpy_way(len, shuffle, device, rng):
    indices = torch.arange(len)
    if shuffle:
        rng.shuffle(indices.numpy())
    return indices.to(device)

def torch_way(len, shuffle, device, rng):
    if shuffle:
        seed = rng.integers(2 ** 62).item()
        torch_rng = torch.Generator(device).manual_seed(seed)
        return torch.randperm(len, generator=torch_rng, device=device)
    else:
        return torch.arange(len, device=device)

rng = numpy.random.default_rng()

for log_len in range(15, 25):
    len = 2 ** log_len
    for device in [""cpu"", ""cuda""]:
        runtimes = []
        for shuffler in [numpy_way, torch_way]:
            for i in range(10):
                if i == 3: # Warmup for 3 iterations.
                    start = time.time()
                indices = shuffler(len, True, device, rng)
            if device == ""cuda"":
                torch.cuda.synchronize()
            runtimes.append(time.time() - start)
        print(f""len: {len}, device: {device}, numpy: {runtimes[0]:.4f}, torch: {runtimes[1]:.4f}"")
```

```
len: 32768, device: cpu, numpy: 0.0046, torch: 0.0037
len: 32768, device: cuda, numpy: 0.0037, torch: 0.0017
len: 65536, device: cpu, numpy: 0.0059, torch: 0.0069
len: 65536, device: cuda, numpy: 0.0072, torch: 0.0020
len: 131072, device: cpu, numpy: 0.0128, torch: 0.0146
len: 131072, device: cuda, numpy: 0.0143, torch: 0.0036
len: 262144, device: cpu, numpy: 0.0285, torch: 0.0339
len: 262144, device: cuda, numpy: 0.0312, torch: 0.0056
len: 524288, device: cpu, numpy: 0.0593, torch: 0.0757
len: 524288, device: cuda, numpy: 0.0618, torch: 0.0111
len: 1048576, device: cpu, numpy: 0.1561, torch: 0.1794
len: 1048576, device: cuda, numpy: 0.1328, torch: 0.0212
len: 2097152, device: cpu, numpy: 0.3178, torch: 0.4349
len: 2097152, device: cuda, numpy: 0.3435, torch: 0.0391
len: 4194304, device: cpu, numpy: 0.8298, torch: 1.1266
len: 4194304, device: cuda, numpy: 0.9278, torch: 0.0763
len: 8388608, device: cpu, numpy: 2.9981, torch: 2.5587
len: 8388608, device: cuda, numpy: 1.8150, torch: 0.1607
len: 16777216, device: cpu, numpy: 5.9163, torch: 7.2578
len: 16777216, device: cuda, numpy: 5.5185, torch: 0.3070
```

@Rhett-Ying So we might wanna keep your existing solution because it is more performant, in the google colab environment. However, if we want to have the advantages I listed above, we could go with the torch solution.",two like faster least environment python import torch import import time shuffle device index shuffle return device shuffle device shuffle seed device seed return else return range device shuffler range start index shuffler true device device start print device device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch device torch might wan na keep solution performant environment however want listed could go torch solution,issue,positive,negative,neutral,neutral,negative,negative
1901756495,"> I don't know whether moving `ItemSampler` to GPU is a good idea or best practice. Does `torch.DataLoader` ever think about it? Putting all workloads onto GPU may lose overlapping. The best practice may be combining CPU and GPU together instead of relying on single one of them.

There is one more reason the solution I propose could be better than the numpy one. If we use numpy, it will keep its own thread pool separate from torch thread pool. It is best if we use torch for all operations if we can, even if it runs on the CPU and we don't do any refactoring to enable GPU execution.",know whether moving good idea best practice ever think onto may lose best practice may combining together instead single one one reason solution propose could better one use keep thread pool separate torch thread pool best use torch even enable execution,issue,positive,positive,positive,positive,positive,positive
1901749208,I don't know whether moving `ItemSampler` to GPU is a good idea or best practice. Does `torch.DataLoader` ever think about it? Putting all workloads onto GPU may lose overlapping. The best practice may be combining CPU and GPU together instead of relying on single one of them.,know whether moving good idea best practice ever think onto may lose best practice may combining together instead single one,issue,positive,positive,positive,positive,positive,positive
1901741152,"> > Is there a particular reason we use `np.rng` and `np.shuffle`? If we used torch, the code could be enabled to work on the GPU later.
> 
> `torch.Generator()` cannot be pickled. and is this targeted on GPU? why do we need that?

I see. @frozenbugs was also asking about whether we should consider enabling GPU for the ItemSampler. Now I know what are the limitations. Thanks!

There is still a way to utilize torch shuffle while utilizing np.rng. We store an np.rng object and whenever we need to shuffle, we get a random number from np.rng, and seed a new torch rng. Then we shuffle with torch shuffle with torch rng.",particular reason use used torch code could work later targeted need see also whether consider know thanks still way utilize torch shuffle store object whenever need shuffle get random number seed new torch shuffle torch shuffle torch,issue,negative,positive,neutral,neutral,positive,positive
1901725493,"> Is there a particular reason we use `np.rng` and `np.shuffle`? If we used torch, the code could be enabled to work on the GPU later.

`torch.Generator()` cannot be pickled. and is this targeted on GPU? why do we need that?",particular reason use used torch code could work later targeted need,issue,negative,positive,neutral,neutral,positive,positive
1900633986,"Is there a particular reason we use `np.rng` and `np.shuffle`? If we used torch, the code could be enabled to work on the GPU later.",particular reason use used torch code could work later,issue,negative,positive,neutral,neutral,positive,positive
1899477070,"However, how do you think we can check the graph in a general manner? The user might pass sample_neighbors, sample_layer_neighbors or any other custom datapipes. The features could be custom too.",however think check graph general manner user might pas custom could custom,issue,negative,positive,neutral,neutral,positive,positive
1899472071,"Hmm, I think we need to work on the dataloader argument checking overall. We could check where the CopyTo is, whether the feature store is pinned or is on the device, whether the graph is pinned or is on the device etc.",think need work argument overall could check whether feature store pinned device whether graph pinned device,issue,negative,neutral,neutral,neutral,neutral,neutral
1899470377,then please throw an exception if contradiction happens.,please throw exception contradiction,issue,negative,neutral,neutral,neutral,neutral,neutral
1899465977,"Yes, for GPU sampling, num_workers has to be 0. I believe. Is there any use case where passing a value greater than 0 would be useful when using the GPU for sampling?",yes sampling believe use case passing value greater would useful sampling,issue,positive,positive,positive,positive,positive,positive
1899464730,Do you think we should automatically set `args.mode = cpu-cuda` if the user passes `num-workers>0`?,think automatically set user,issue,negative,neutral,neutral,neutral,neutral,neutral
1899314780,"LGTM, Good catch to cover this corner case @mfbalin ",good catch cover corner case,issue,negative,positive,positive,positive,positive,positive
1899188159,It appears that the multi-GPU example is buggy even with overlap_fetch_feature disabled.,example buggy even disabled,issue,negative,negative,negative,negative,negative,negative
1898147292,@yxy235 can you merge this PR as soon as the CI turns green? It is a hotfix after #6962. I don't want to leave the master branch in a partly buggy state.,merge soon turn green want leave master branch partly buggy state,issue,negative,negative,negative,negative,negative,negative
1898078668,"nit: Please add `[GraphBolt][PyG]` in front of the title of the PR for future retrieval. Also, the abstract of the PR should be below `# Description`.",nit please add front title future retrieval also abstract description,issue,negative,neutral,neutral,neutral,neutral,neutral
1898058837,"@frozenbugs what changes would be required if we wanted to enable GPU sampling in the rest of the examples here? I want to minimize the change to the examples to do this.

I feel that only the lightning example looks a bit too complicated. The line counts of the two other examples don't increase at all.",would enable sampling rest want minimize change feel lightning example bit complicated line two increase,issue,negative,negative,negative,negative,negative,negative
1897761101,"Is there any more concern before approval is given @frozenbugs? I am looking forward to merging these PRs, and to the end-to-end benchmark analysis @TristonC is going to do with #6961.",concern approval given looking forward analysis going,issue,negative,neutral,neutral,neutral,neutral,neutral
1897675727,"Hi, just as you've pointed out, this is indeed an often-discussed topic. My view of this is to break it into two aspects:
* How to support graph-level features in the dataloading pipeline. This is related to the future plan of GraphBolt @frozenbugs 
* How to utilize graph-level features in message passing.

As your request is more about the second point, my suggestion is to utilize DGL's readout/broadcast operations to convert between graph-level features and node-/edge- level features so that you can directly use them in your UDFs. See the following APIs:
* https://docs.dgl.ai/api/python/dgl.html#batching-and-reading-out-ops
* https://docs.dgl.ai/generated/dgl.broadcast_nodes.html#dgl.broadcast_nodes
* https://docs.dgl.ai/generated/dgl.broadcast_edges.html#dgl.broadcast_edges",hi pointed indeed topic view break two support pipeline related future plan utilize message passing request second point suggestion utilize convert level directly use see following,issue,negative,positive,neutral,neutral,positive,positive
1897671134, I am closing this issue assuming you are happy about our response. Feel free to follow up and reopen the issue if you have more questions with regard to our response.,issue assuming happy response feel free follow reopen issue regard response,issue,positive,positive,positive,positive,positive,positive
1897670660,"We just release DGL 2.0 on Linux last friday, can you double check. @LiutongZhou ",release last double check,issue,negative,neutral,neutral,neutral,neutral,neutral
1897661868,"You can understand mini-batch training by reading this doc: https://docs.dgl.ai/en/1.1.x/tutorials/large/index.html
And the code for mini-batch creation is here: https://github.com/dmlc/dgl/tree/master/python/dgl/graphbolt",understand training reading doc code creation,issue,negative,neutral,neutral,neutral,neutral,neutral
1897567438,"> > We saw better scale up performance one a single DGX node from 1GU to 8GPUs with this PR.
> 
> Why does this PR lead to better performance? I thought it would only help lower the memory usage.

Will find out if is just his PR or other PR combined effect. ",saw better scale performance one single node lead better performance thought would help lower memory usage find combined effect,issue,positive,positive,positive,positive,positive,positive
1897393245,"> We saw better scale up performance one a single DGX node from 1GU to 8GPUs with this PR.

Why does this PR lead to better performance? I thought it would only help lower the memory usage.",saw better scale performance one single node lead better performance thought would help lower memory usage,issue,positive,positive,positive,positive,positive,positive
1897388394,We saw better scale up performance one a single DGX node from 1GU to 8GPUs with this PR.,saw better scale performance one single node,issue,negative,positive,positive,positive,positive,positive
1895175901,"@frozenbugs, I measured the memory consumption of the multi-GPU example in #6961. Without this PR, the consumption grows as more GPUs are used. With this PR, adding more GPUs does not significantly change the memory consumption. The tests pass as well. The multi-GPU example also seems to terminate cleanly.",measured memory consumption example without consumption used significantly change memory consumption pas well example also terminate cleanly,issue,negative,positive,positive,positive,positive,positive
1894344517,"@frozenbugs Do you think anybody would like to work on adding such an example? We could showcase it after a larger dataset is added to GraphBolt in as part of #6909. We can then showcase the speedups hopefully, however, to show speedups, the feature copy needs to dominate the overall training runtime. But with #6954, the feature copy can be fully overlapped so it is going to be a bit harder to show speedups after it is merged.

When we have a large dataset such as `ogbn-papers100M` or maybe the mag240M `hetero-rgcn.py` example, we need to wrap its main TorchBasedFeature with a GPUCachedFeature in #6939.",think anybody would like work example could showcase added part showcase hopefully however show feature copy need dominate overall training feature copy fully going bit harder show large maybe example need wrap main,issue,positive,positive,neutral,neutral,positive,positive
1894336846,"@hutiechuan can you start from the upto-date master branch? There seem to be leftover commits from the previous PR.
Basically, sync your master branch to the DGL master, then create your new branch and add your changes.",start master branch seem leftover previous basically sync master branch master create new branch add,issue,negative,negative,neutral,neutral,negative,negative
1891830439,Please paste the result of the code in description.,please paste result code description,issue,negative,neutral,neutral,neutral,neutral,neutral
1891102873,Awesome! Done in: https://github.com/conda-forge/dgl-feedstock/pull/30. You now have full power in the feedstock. ,awesome done full power,issue,positive,positive,positive,positive,positive,positive
1890997146,feel free to put me on the maintainer list and loop me in when you need help.,feel free put maintainer list loop need help,issue,positive,positive,positive,positive,positive,positive
1890143050,"GPU sampling run examples with #6861, note that my current directory is `dgl/sampling/graphbolt/lightning`. @Rhett-Ying 
```
mfbalin@BALIN-PC:~/dgl-1/examples/sampling/graphbolt/lightning$ python ../rgcn/hetero_rgcn.py --dataset=ogbn-mag
Downloading datasets/ogbn-mag.zip from https://data.dgl.ai/dataset/graphbolt/ogbn-mag.zip...
datasets/ogbn-mag.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 519M/519M [00:04<00:00, 114MB/s]
Extracting file to datasets
Start to preprocess the on-disk dataset.
Finish preprocessing the on-disk dataset.
Loaded dataset: node_classification
node_num for rel_graph_embed: {'author': tensor(1134649), 'field_of_study': tensor(59965), 'institution': tensor(8740)}
Number of embedding parameters: 154029312
Number of model parameters: 337460
Start to train...
Training~Epoch 01: 615it [00:34, 17.71it/s]
Evaluating the model on the validation set.
Inference: 16it [00:00, 23.79it/s]
Finish evaluating on validation set.
Epoch: 01, Loss: 2.6385, Valid accuracy: 39.45%, Time 34.7261
Training~Epoch 02: 615it [00:34, 17.65it/s]
Evaluating the model on the validation set.
Inference: 16it [00:00, 23.86it/s]
Finish evaluating on validation set.
Epoch: 02, Loss: 2.0427, Valid accuracy: 42.69%, Time 34.8499
Training~Epoch 03: 615it [00:33, 18.52it/s]
Evaluating the model on the validation set.
Inference: 16it [00:00, 28.95it/s]
Finish evaluating on validation set.
Epoch: 03, Loss: 1.7699, Valid accuracy: 41.81%, Time 33.2093
Testing...
Inference: 11it [00:00, 28.80it/s]
Test accuracy 40.7664
```

```
mfbalin@BALIN-PC:~/dgl-1/examples/sampling/graphbolt/lightning$ python ../node_classification.py 
Training in pinned-cuda mode.
Loading data...
Downloading datasets/ogbn-products.zip from https://data.dgl.ai/dataset/graphbolt/ogbn-products.zip...
datasets/ogbn-products.zip: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.52G/1.52G [00:14<00:00, 108MB/s]
Extracting file to datasets
Start to preprocess the on-disk dataset.
Finish preprocessing the on-disk dataset.
Training...
Training: 193it [00:06, 31.57it/s]
Evaluating: 39it [00:00, 40.34it/s]
Epoch 00000 | Loss 1.8010 | Accuracy 0.8300 | Time 7.1117
Training: 193it [00:05, 34.02it/s]
Evaluating: 39it [00:00, 40.95it/s]
Epoch 00001 | Loss 0.7753 | Accuracy 0.8601 | Time 6.6312
Training: 193it [00:05, 34.56it/s]
Evaluating: 39it [00:00, 41.44it/s]
Epoch 00002 | Loss 0.6226 | Accuracy 0.8722 | Time 6.5305
Training: 193it [00:05, 36.79it/s]
Evaluating: 39it [00:00, 44.94it/s]
Epoch 00003 | Loss 0.5483 | Accuracy 0.8795 | Time 6.1186
Training: 193it [00:05, 37.67it/s]
Evaluating: 39it [00:00, 44.68it/s]
Epoch 00004 | Loss 0.5007 | Accuracy 0.8833 | Time 6.0020
Training: 193it [00:05, 35.73it/s]
Evaluating: 39it [00:00, 39.28it/s]
Epoch 00005 | Loss 0.4729 | Accuracy 0.8884 | Time 6.3999
Training: 193it [00:05, 34.40it/s]
Evaluating: 39it [00:00, 40.66it/s]
Epoch 00006 | Loss 0.4486 | Accuracy 0.8903 | Time 6.5741
Training: 193it [00:05, 35.86it/s]
Evaluating: 39it [00:00, 44.92it/s]
Epoch 00007 | Loss 0.4274 | Accuracy 0.8938 | Time 6.2544
Training: 193it [00:05, 35.95it/s]
Evaluating: 39it [00:00, 44.25it/s]
Epoch 00008 | Loss 0.4148 | Accuracy 0.8942 | Time 6.2540
Training: 193it [00:05, 36.11it/s]
Evaluating: 39it [00:00, 45.44it/s]
Epoch 00009 | Loss 0.4030 | Accuracy 0.8975 | Time 6.2067
Testing...
598it [00:02, 219.17it/s]
598it [00:02, 211.76it/s]
598it [00:02, 265.77it/s]
Test accuracy 0.7580
```

```
mfbalin@BALIN-PC:~/dgl-1/examples/sampling/graphbolt/lightning$ python node_classification.py 
The dataset is already preprocessed.
GPU available: True (cuda), used: True
TPU available: False, using: 0 TPU cores
IPU available: False, using: 0 IPUs
HPU available: False, using: 0 HPUs
You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]

  | Name      | Type               | Params
-------------------------------------------------
0 | layers    | ModuleList         | 206 K 
1 | dropout   | Dropout            | 0     
2 | train_acc | MulticlassAccuracy | 0     
3 | val_acc   | MulticlassAccuracy | 0     
-------------------------------------------------
206 K     Trainable params
0         Non-trainable params
206 K     Total params
0.828     Total estimated model params size (MB)
Sanity Checking: 0it [00:00, ?it/s]/home/mfbalin/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
/home/mfbalin/.local/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:432: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 32 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.
  rank_zero_warn(
Epoch 23: : 192it [00:07, 26.87it/s, v_num=167, train_acc=0.900, num_nodes/0=2.56e+5, num_edges/0=3.94e+5, num_nodes/1=39882.0, num_edges/1=43571.0, num_nodes/2=4404.0, num_edges/2=4020.0, num_nodes/3=411.0, val_acc=0.911]
```",sampling run note current directory python file start finish loaded tensor tensor tensor number number model start train model validation set inference finish validation set epoch loss valid accuracy time model validation set inference finish validation set epoch loss valid accuracy time model validation set inference finish validation set epoch loss valid accuracy time testing inference test accuracy python training mode loading data file start finish training training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time training epoch loss accuracy time testing test accuracy python already available true used true available false available false available false device tensor properly utilize set precision performance read name type dropout dropout trainable total total model size sanity many may bottleneck consider increasing value argument try number machine improve performance many may bottleneck consider increasing value argument try number machine improve performance epoch,issue,negative,positive,positive,positive,positive,positive
1890140114,"@mfbalin could you run below examples(run all the examples that are changed in this PR is preferable) with GPU sampling and share the accuracy results to see if it's comparable to the counterparts in DGL. We're looking into the accuracy issue in https://github.com/dmlc/dgl/issues/6941.

`python3 https://github.com/dmlc/dgl/tree/master/examples/sampling/graphbolt/rgcn/hetero_rgcn.py --dataset ogbn-mag --num_gpus 1`
`python3 https://github.com/dmlc/dgl/blob/master/examples/sampling/graphbolt/node_classification.py`",could run run preferable sampling share accuracy see comparable looking accuracy issue python python,issue,negative,neutral,neutral,neutral,neutral,neutral
1888283759,"master branch always points to next release(it's a convention), so I change it to `2.1`. For now, we're release 2.0.",master branch always next release convention change release,issue,negative,neutral,neutral,neutral,neutral,neutral
1888224974,@Rhett-Ying What is the target release date of 2.1? I assume we can release and showcase the GPU support for GraphBolt in 2.1.,target release date assume release showcase support,issue,negative,neutral,neutral,neutral,neutral,neutral
1886429238,"I get it. Thank you for your reply.



---Original---
From: ***@***.***&gt;
Date: Thu, Jan 11, 2024 10:14 AM
To: ***@***.***&gt;;
Cc: ***@***.******@***.***&gt;;
Subject: Re: [dmlc/dgl] the correctness of dgl.shortest_dist (especially theoutput path) (Issue #6762)




 
Hi, @study1157, this is not a bug. As described in the documentation: https://docs.dgl.ai/generated/dgl.shortest_dist.html?highlight=edge%20IDs, returned path contains edge IDs instead of node IDs. You can try the following code to get node IDs.
 g = dgl.graph(([1, 1, 2, 3, 4, 2, 4, 3], [0, 2, 0, 4, 2, 3, 1, 2])) dist, path = shortest_dist(g, 2, True) print(dist, path) # tensor([1, 3, 0, 1, 2]) tensor([[ 2, -1, -1], #         [ 5,  3,  6], #         [-1, -1, -1], #         [ 5, -1, -1], #         [ 5,  3, -1]]) for target in range(5):     edges = []     path_eids = [int(eid) for eid in path[target] if eid != -1]     u, v = g.find_edges(path_eids)     print(f""path from 2 to {target}:"", list(zip(u.numpy().tolist(), v.numpy().tolist()))) # path from 2 to 0: [(2, 0)] # path from 2 to 1: [(2, 3), (3, 4), (4, 1)] # path from 2 to 2: [] # path from 2 to 3: [(2, 3)] # path from 2 to 4: [(2, 3), (3, 4)]
 
â€”
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you were mentioned.Message ID: ***@***.***&gt;",get thank reply date subject correctness especially path issue hi study bug documentation returned path edge instead node try following code get node path true print path tensor tensor target range path target print path target list zip path path path path path reply directly view id,issue,positive,positive,neutral,neutral,positive,positive
1886120816,"`torch 2.1.2` is not supported in latest DGL stable release while `2.1.0/1` is supported. If you want to use DGL with `torch 2.1.2`, you could try with our nightly build. But note that only Linux wheel package is available for now.

BTW, DGL 2.0.0 will be released this month and it supports `torch 2.1.2`.",torch latest stable release want use torch could try nightly build note wheel package available month torch,issue,negative,positive,positive,positive,positive,positive
1886120009,@ali6947 Thanks for the contribution. We will discuss how to proceed for this PR.,thanks contribution discus proceed,issue,negative,positive,positive,positive,positive,positive
1886087728,"Hi, @study1157, this is not a bug. As described in the documentation: https://docs.dgl.ai/generated/dgl.shortest_dist.html?highlight=edge%20IDs, returned path contains edge IDs instead of node IDs. You can try the following code to get node IDs.

```python
g = dgl.graph(([1, 1, 2, 3, 4, 2, 4, 3], [0, 2, 0, 4, 2, 3, 1, 2]))
dist, path = shortest_dist(g, 2, True)
print(dist, path)
# tensor([1, 3, 0, 1, 2]) tensor([[ 2, -1, -1],
#         [ 5,  3,  6],
#         [-1, -1, -1],
#         [ 5, -1, -1],
#         [ 5,  3, -1]])

for target in range(5):
    edges = []
    path_eids = [int(eid) for eid in path[target] if eid != -1]
    u, v = g.find_edges(path_eids)
    print(f""path from 2 to {target}:"", list(zip(u.numpy().tolist(), v.numpy().tolist())))
# path from 2 to 0: [(2, 0)]
# path from 2 to 1: [(2, 3), (3, 4), (4, 1)]
# path from 2 to 2: []
# path from 2 to 3: [(2, 3)]
# path from 2 to 4: [(2, 3), (3, 4)]
```",hi study bug documentation returned path edge instead node try following code get node python path true print path tensor tensor target range path target print path target list zip path path path path path,issue,negative,positive,positive,positive,positive,positive
1884178052,"@ayushnoori Check out this implementation. It may not handle all the corner cases but the general idea should apply. cc @czkkkkkk 

```python
def block_to_homogeneous(block, source_ndata, source_ndata_name):
    """"""Convert a DGLBlock to a homogeneous graph.

    This function performs a two-step process to convert a given block into a
    homogeneous graph. It first transforms the block into a heterogeneous graph,
    treating its source nodes as heterogeneous nodes. Then, this heterogeneous
    graph is further converted to a homogeneous graph. The function outputs
    includes the homogeneous graph, the mapping from node type to node type ID,
    node type count offsets, and the number of destination nodes for each node
    type. Notably, the `source_ndata` of the original block is retained and
    stored in the `source_ndata_name` attribute of the homogeneous graph.

    Parameters
    ----------
    block : dgl.Block
        The block to convert.
    source_ndata : dict[str, Tensor]
        The source node features of the block.
    source_ndata_name : str
        The name of the source node features in the homogeneous graph.
    
    Returns
    -------
    DGL.Graph
        The converted homogeneous graph.
    dict[str, int]
        The mapping from node type to node type ID.
    list[int]
        The node type count offsets.
    dict[str, int]
        The number of destination nodes for each node type.
    """"""
    num_dst_nodes_dict = {}
    num_src_nodes_dict = {}
    for ntype in block.dsttypes:
        num_dst_nodes_dict[ntype] = block.number_of_dst_nodes(ntype)
    for ntype in block.srctypes:
        num_src_nodes_dict[ntype] = block.number_of_src_nodes(ntype)

    hetero_edges = {}
    for srctpye, etype, dsttype in block.canonical_etypes:
        src, dst = block.all_edges(etype=etype, order=""eid"")
        hetero_edges[(srctpye, etype, dsttype)] = (src, dst)
    hetero_g = dgl.heterograph(
        hetero_edges,
        num_nodes_dict=num_src_nodes_dict,
        idtype=block.idtype,
        device=block.device,
    )
    ntype_to_id = {ntype: hetero_g.get_ntype_id(ntype) for ntype in hetero_g.ntypes}
    hetero_g.ndata[source_ndata_name] = source_ndata
    homo_g, ntype_counts, _ = dgl.to_homogeneous(
        hetero_g, ndata=[source_ndata_name], return_count=True
    )
    ntype_offset = np.insert(np.cumsum(ntype_counts), 0, 0)
    return homo_g, ntype_to_id, ntype_offset, num_dst_nodes_dict

class HGTGNN(nn.Module):
    def __init__(
        self,
        in_size: int,
        hid_size: int,
        num_heads: int,
        num_ntypes: int,
        num_etypes: int,
        num_layers: int,
    ):
        super().__init__()
        self.in_size = in_size
        self.out_size = hid_size
        self.conv_layers = nn.ModuleList()
        self.conv_layers.append(
            HGTConv(
                in_size,
                hid_size // num_heads,
                num_heads,
                num_ntypes,
                num_etypes,
            )
        )
        for _ in range(num_layers - 1):
            self.conv_layers.append(
                HGTConv(
                    hid_size,
                    hid_size // num_heads,
                    num_heads,
                    num_ntypes,
                    num_etypes,
                )
            )

    def forward(
        self,
        mfgs,
        X_node_dict: Dict[str, torch.Tensor]
    ) -> Dict[str, torch.Tensor]:
        assert len(mfgs) == len(self.conv_layers)
        for ntype, X in X_node_dict.items():
            assert X.shape[1] == self.in_size
        H_node_dict = X_node_dict
        for i, conv in enumerate(self.conv_layers):
            # There are several steps to conduct HGT on a DGLBlock.
            # 1. Convert the DGLBlock to a homogeneous graph. The
            # homogeneous graph is based on the source nodes of the DGLBlock.
            # 2. Run HGTConv on the homogeneous graph to compute homogeneous
            # features.
            # 3. Extract the heterogeneous features of the destination nodes
            # from the homogeneous features.
            homo_ndata_name = ""x""
            (
                homo_g,
                ntype_to_id,
                ntype_offset,
                num_dst_nodes_dict,
            ) = block_to_homogeneous(mfgs[i], H_node_dict, homo_ndata_name)
            # Run hgtconv on the homogeneous graph.
            homo_features = conv(
                homo_g,
                homo_g.ndata[homo_ndata_name],
                homo_g.ndata[dgl.NTYPE],
                homo_g.edata[dgl.ETYPE],
            )
            # Convert the output features back to a dict.
            dst_features = {}
            for ntype in mfgs[i].dsttypes:
                ntype_id = ntype_to_id[ntype]
                feature = homo_features[
                    ntype_offset[ntype_id] : ntype_offset[ntype_id + 1]
                ]
                dst_features[ntype] = feature[: num_dst_nodes_dict[ntype]]
            H_node_dict = dst_features
        return H_node_dict
```

",check implementation may handle corner general idea apply python block convert homogeneous graph function process convert given block homogeneous graph first block heterogeneous graph treating source heterogeneous heterogeneous graph converted homogeneous graph function homogeneous graph node type node type id node type count number destination node type notably original block attribute homogeneous graph block block convert tensor source node block name source node homogeneous graph converted homogeneous graph node type node type id list node type count number destination node return class self super range forward self assert assert enumerate several conduct convert homogeneous graph homogeneous graph based source run homogeneous graph compute homogeneous extract heterogeneous destination homogeneous run homogeneous graph convert output back feature feature return,issue,negative,positive,positive,positive,positive,positive
1884101850,@rudongyu please check if it is displayed as expected on our doc page after merge.,please check displayed doc page merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1884089039,"> @mfbalin could you manually run `python3 examples/sampling/graphbolt/node_classification.py --num-workers 5 --device cpu` to confirm this PR resolves the issue we hit?

I already did. That is why I marked the issue is going to be fixed with this PR.",could manually run python device confirm issue hit already marked issue going fixed,issue,negative,positive,neutral,neutral,positive,positive
1884088308,@mfbalin could you manually run `python3 examples/sampling/graphbolt/node_classification.py --num-workers 5 --device cpu` to confirm this PR resolves the issue we hit?,could manually run python device confirm issue hit,issue,negative,neutral,neutral,neutral,neutral,neutral
1883609664,"Found a better solution, opening a PR.",found better solution opening,issue,positive,positive,positive,positive,positive,positive
1883592039,"That is if we don't want to add `mp.set_start_method(""spawn"")` to main for all examples or into the dataloader for when cuda is available in the system.",want add spawn main available system,issue,negative,positive,positive,positive,positive,positive
1883586909,"If `is_dataloader_worker` indicates whether the process is a dataloader process, then the is_pinned check can be avoided as follows:
```python
 inline bool is_accessible_from_gpu(torch::Tensor tensor) { 
   return (!is_dataloader_worker && tensor.is_pinned()) || tensor.device().type() == c10::DeviceType::CUDA; 
 } 
 ```",whether process process check python bool torch tensor return,issue,negative,neutral,neutral,neutral,neutral,neutral
1883584989,"However, we need to figure out how to do the dispatch when it is one of the dataloader workers. Maybe we can mark each of the launched processes by a global variable which can be checked inside this function so that we don't check if tensors are pinned if they are dataloader workers.",however need figure dispatch one maybe mark global variable checked inside function check pinned,issue,negative,neutral,neutral,neutral,neutral,neutral
1883582973,"I identified the issue. When we are dispatching to the GPU, we check two things, whether the tensors are pinned or whether they are on CUDA. I verified that changing this function:
https://github.com/dmlc/dgl/blob/4323986b25ce5c6d0ced0a6db5550402740aeb99/graphbolt/src/utils.h#L18-L20
To
```python
return tensor.device().type() == c10::DeviceType::CUDA;
```
resolves the issue.",issue check two whether pinned whether function python return issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1883525916,"Probably related: https://pytorch.org/docs/master/notes/multiprocessing.html#cuda-in-multiprocessing
I don't know if there is a way to stop CUDA from being initialized when not using it. I will do some research on it.",probably related know way stop research,issue,negative,neutral,neutral,neutral,neutral,neutral
1882662774,"adding `mp.set_start_method(""spawn"")` at the top of `main()` resolves this crash",spawn top main crash,issue,negative,positive,positive,positive,positive,positive
1882550941,@hutiechuan you might want to use your username and e-mail when making a commit if you want the git history to show your name for this code. https://linuxize.com/post/how-to-configure-git-username-and-email/#setting-global-git-username-and-email,might want use making commit want git history show name code,issue,negative,neutral,neutral,neutral,neutral,neutral
1882313276,"Commit ID: 6e182e92f8e0d98da5afeec8d3281981fe7a2800

Build ID: 8

Status: âŒ CI test failed in Stage [Tensorflow CPU].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6916/8/8/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6916/8/8/logs/cireport.log)",commit id build id status test stage report path link full path link,issue,negative,positive,positive,positive,positive,positive
1880449789,"@aishwaryyasarkar 
After system maintenance you did, have you changed the `ip_config.txt`? or number of machines used for distributed training? please make sure number of partitions equals with number of machines used for training.",system maintenance number used distributed training please make sure number number used training,issue,positive,positive,positive,positive,positive,positive
1880418865,"if loaded in numpy, we could access via `src, dst = edges`.",loaded could access via,issue,negative,neutral,neutral,neutral,neutral,neutral
1880417827,"we've just found reading edges from **CSV** is quite slow(takes about 30min for 300M edges), while **Numpy**(in shape of `(2, N)` is quite fast(less than 1 second). we need to support numpy and benchmark it.",found reading quite slow min shape quite fast le second need support,issue,negative,negative,neutral,neutral,negative,negative
1880378050,"@Rhett-Ying Yes, the slicing ensures that h matches with the input nodes in the next layer. By taking the first block.number_of_dst_nodes() entries in h, we ensure that we're only working with the nodes that were meant to be the destination nodes in the current layer, which become the source nodes for the next layer. 

Some output results are like below:
Layer 0: Feature tensor shape before convolution: torch.Size([26014, 128])
Layer 0: Feature tensor shape after convolution: torch.Size([26014, 128])
Layer 0: Number of destination nodes: 12810
Layer 0: Feature tensor shape after slicing: torch.Size([12810, 128])
Layer 1: Feature tensor shape before convolution: torch.Size([12810, 128])
Layer 1: Feature tensor shape after convolution: torch.Size([12810, 128])
Layer 1: Number of destination nodes: 4501
Layer 1: Feature tensor shape after slicing: torch.Size([4501, 128])
Layer 2: Feature tensor shape before convolution: torch.Size([4501, 128])
Layer 2: Feature tensor shape after convolution: torch.Size([4501, 40])
Layer 2: Number of destination nodes: 1024
Layer 2: Feature tensor shape after slicing: torch.Size([1024, 40])

",yes slicing input next layer taking first ensure working meant destination current layer become source next layer output like layer feature tensor shape convolution layer feature tensor shape convolution layer number destination layer feature tensor shape slicing layer feature tensor shape convolution layer feature tensor shape convolution layer number destination layer feature tensor shape slicing layer feature tensor shape convolution layer feature tensor shape convolution layer number destination layer feature tensor shape slicing,issue,positive,positive,neutral,neutral,positive,positive
1880351670,@Rhett-Ying Could you take a look at this issue?,could take look issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1880322265,@czkkkkkk Could you provide a review if you have the time?,could provide review time,issue,negative,neutral,neutral,neutral,neutral,neutral
1879969938,We will probably handle this automatically when we finalize the design of the pipelining and executor logic for the sampling stage.,probably handle automatically finalize design executor logic sampling stage,issue,negative,neutral,neutral,neutral,neutral,neutral
1878765267,"No, I update the cuda to 11.6 and install other version
________________________________
å‘ä»¶äºº: æ¯›æ—¥å¼º ***@***.***>
å‘é€æ—¶é—´: 2023å¹´12æœˆ8æ—¥ 10:49
æ”¶ä»¶äºº: dmlc/dgl ***@***.***>
æŠ„é€: Leon stark ***@***.***>; Comment ***@***.***>
ä¸»é¢˜: Re: [dmlc/dgl] dgl._ffi.base.DGLError: [13:15:35] /opt/dgl/src/array/cuda/spmm.cu:213: Check failed: e == CUSPARSE_STATUS_SUCCESS: CUSPARSE ERROR: 1 (#2762)


Actually I uninstalled using pip uninstall dgl-cu110, and the output of dgl.__path__ is ['/data/zhuangxiang/anaconda3/lib/python3.8/site-packages/dgl']
Hello, I have encountered the same problem. Have you resolved it yet

â€•
Reply to this email directly, view it on GitHub<https://github.com/dmlc/dgl/issues/2762#issuecomment-1846472032>, or unsubscribe<https://github.com/notifications/unsubscribe-auth/AKRWZ62FKIKMIQCN34VYA4DYIJ55DAVCNFSM4ZMUCIL2U5DIOJSWCZC7NNSXTN2JONZXKZKDN5WW2ZLOOQ5TCOBUGY2DOMRQGMZA>.
You are receiving this because you commented.Message ID: ***@***.***>
",update install version stark comment check error actually uninstalled pip output hello problem resolved yet reply directly view id,issue,negative,negative,neutral,neutral,negative,negative
1878268427,"> for example, we defined 2 tasks: node classification, link prediction in https://docs.dgl.ai/en/latest/stochastic_training/ondisk_dataset_homograph.html#Generate-tasks. And we want to load one of them only. As for the train/val/test set, we usually need to load all of them for the target task.

OK. I will rewrite the code.",example defined node classification link prediction want load one set usually need load target task rewrite code,issue,negative,negative,negative,negative,negative,negative
1878266402,"for example, we defined 2 tasks: node classification, link prediction in https://docs.dgl.ai/en/latest/stochastic_training/ondisk_dataset_homograph.html#Generate-tasks. And we want to load one of them only. As for the train/val/test set, we usually need to load all of them for the target task.",example defined node classification link prediction want load one set usually need load target task,issue,negative,negative,negative,negative,negative,negative
1878264668,@yxy235 I'm afraid you misunderstood. what user want is to optionally load task instead of train/val/test set in task. just select on **task-level** as we could define any number of tasks in single `metadata.yaml` of dataset.,afraid misunderstood user want optionally load task instead set task select could define number single,issue,negative,negative,negative,negative,negative,negative
1878261832,this work item is related to #6681  can we determine whether to reload/preprocess dataset automatically?,work item related determine whether automatically,issue,negative,neutral,neutral,neutral,neutral,neutral
1878203934,@yxy235 Want to handle this? I need this functionality in some of the examples in #6861. You can see my temporary changes to torch based feature store in that PR.,want handle need functionality see temporary torch based feature store,issue,negative,neutral,neutral,neutral,neutral,neutral
1878135357,"> @hutiechuan for lint issue, you could run `lintrunner -a` on your local branch to resolve it.



> pls refactor this example in the layout of the counterpart in GraphBolt

Which example are you referring to? Is it for lint issue?",lint issue could run local branch resolve example layout counterpart example lint issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1878079294,"@hutiechuan for lint issue, you could run `lintrunner -a` on your local branch to resolve it.",lint issue could run local branch resolve,issue,negative,neutral,neutral,neutral,neutral,neutral
1878008959,"> Yes. I totally aware of and agree with what you said. #6900 looks good to me.
> 
> The reason why we didn't apply mutex on `manual_seed` is the assumption we call `gb.seed()` at the very beginning and it's on main thread of current process. No multi-threading is involved at that time. As for the root cause of you what you hit now is probably caused by `gb.seed()` is called in current test and when we run multiple tests, we're running on same process. that makes `ThreadLocal->Get()` returns previously set seed. I am wondering if this is the case. And if you run the test in your PR alone instead of all graphbolt tests, will you hit the issue? could you confirm this?
> 
> Anyway I want to figure why this issue is hit in this PR, not found before.

Before I resorted to sorting the sampled edges in the tests, I was trying to see if I can set the seed and have GPU specialized expected test result arrays. But I noticed that the GPU results kept changing. A small investigation showed that the problem was with `gb.seed()` not setting the current thread random engine seed.

But now that I am sorting the sampled edges, we don't need to set the seed in the test file anymore. Let me delete it.",yes totally aware agree said good reason apply assumption call beginning main thread current process involved time root cause hit probably current test run multiple running process get previously set seed wondering case run test alone instead hit issue could confirm anyway want figure issue hit found trying see set seed specialized test result kept small investigation problem setting current thread random engine seed need set seed test file let delete,issue,positive,positive,neutral,neutral,positive,positive
1878002198,"Yes. I totally aware of and agree with what you said. #6900 looks good to me. 

The reason why we didn't apply mutex on `manual_seed` is the assumption we call `gb.seed()` at the very beginning and it's on main thread of current process. No multi-threading is involved at that time. As for the root cause of you what you hit now is probably caused by `gb.seed()` is called in current test and when we run multiple tests, we're running on same process. that makes `ThreadLocal->Get()` returns previously set seed. I am wondering if this is the case. And if you run the test in your PR alone instead of all graphbolt tests, will you hit the issue? could you confirm this?

Anyway I want to figure why this issue is hit in this PR, not found before.",yes totally aware agree said good reason apply assumption call beginning main thread current process involved time root cause hit probably current test run multiple running process get previously set seed wondering case run test alone instead hit issue could confirm anyway want figure issue hit found,issue,positive,positive,positive,positive,positive,positive
1877973976,"> > @Rhett-Ying I found a bug in the `gb.seed()` functionality, can you take a quick look? I realized it after setting the graphbolt seed but seeing that I keep getting different results. Opened a separate PR for it in #6900.
> 
> could you elaborate more about the root cause? It's about racing if multiple threads are setting seed simultaneously? and when such scenario happens? Calling `gb.seed()` at the begin of python causes racing? Does it work well in CPU sampling? Why such issue is exposed in GPU sampling?

The GPU random seed is derived from the CPU random engine. In the tests, I was setting the seed but kept getting different results. The issue mainly results from the fact that setting the manual seed doesn't set the existing RandomEngine seed in the current main thread. I further ensured that the shared manual seed variable is protected by a mutex so that any potential race conditions are eliminated. Any variable potentially accessed by multiple threads needs to be either atomic or protected by mutexes.",found bug functionality take quick look setting seed seeing keep getting different separate could elaborate root cause racing multiple setting seed simultaneously scenario calling begin python racing work well sampling issue exposed sampling random seed derived random engine setting seed kept getting different issue mainly fact setting manual seed set seed current main thread manual seed variable potential race variable potentially multiple need either atomic,issue,negative,positive,neutral,neutral,positive,positive
1877972944,"> @Rhett-Ying I found a bug in the `gb.seed()` functionality, can you take a quick look? I realized it after setting the graphbolt seed but seeing that I keep getting different results. Opened a separate PR for it in #6900.

could you elaborate more about the root cause? It's about racing if multiple threads are setting seed simultaneously? and when such scenario happens? Calling `gb.seed()` at the begin of python causes racing? Does it work well in CPU sampling? Why such issue is exposed in GPU sampling?",found bug functionality take quick look setting seed seeing keep getting different separate could elaborate root cause racing multiple setting seed simultaneously scenario calling begin python racing work well sampling issue exposed sampling,issue,negative,positive,positive,positive,positive,positive
1877832793,"@Rhett-Ying I found a bug in the `gb.seed()` functionality, can you take a quick look? I realized it after setting the graphbolt seed but seeing that I keep getting different results. Opened a separate PR for it in #6900.",found bug functionality take quick look setting seed seeing keep getting different separate,issue,negative,positive,positive,positive,positive,positive
1876301034,"> Can you try again with the fix in #6898?

Yes, the error is fixed.",try fix yes error fixed,issue,negative,positive,neutral,neutral,positive,positive
1876299086,"Whenever a tensor might be pinned and get accessed from the GPU, we gotta use `torch.ops.graphbolt.index_select`. It can basically replace `torch.index_select` anywhere it is used. We might want to add a python wrapper so that we can simply write `gb.index_select`.",whenever tensor might pinned get got ta use basically replace anywhere used might want add python wrapper simply write,issue,negative,neutral,neutral,neutral,neutral,neutral
1876294029,"I was trying to see where the logic for edge-ids was located. Now, I know where. Will fix it in a quick PR.",trying see logic know fix quick,issue,negative,positive,positive,positive,positive,positive
1875999975,@Rhett-Ying Do you think we can move forward with this PR? I need parts of it for the hetero neighbor sampler PR in #6895.,think move forward need hetero neighbor sampler,issue,negative,neutral,neutral,neutral,neutral,neutral
1875871733,@Rhett-Ying do you think we can merge this soon so that I can utilize the functionality here in my future and existing PRs?,think merge soon utilize functionality future,issue,negative,neutral,neutral,neutral,neutral,neutral
1875620752,"@yxy235 resolved the merge conflicts, after checking if I resolved them properly, feel free to merge if @Rhett-Ying is good with it.",resolved merge resolved properly feel free merge good,issue,positive,positive,positive,positive,positive,positive
1875593901,"Let's handle the merge conflicts and merge. @yxy235
I was waiting to see if @Rhett-Ying would want to take a look before we merged. @Rhett-Ying, is it fine if I review a PR and merge it if it looks good?",let handle merge merge waiting see would want take look fine review merge good,issue,positive,positive,positive,positive,positive,positive
1874795769,"> please add testcases for this change

The changes are workable in TGIF. So do you think it is fine to add unittests in a later PR?",please add change workable think fine add later,issue,negative,positive,positive,positive,positive,positive
1874241178,"I recommend using `100000` and larger sizes in addition to the benchmarked sizes when the GPU is involved. Otherwise, there is insufficient work for the GPU and we measure the kernel launch latency. That is why there might be such a large difference when it comes to using a small size like `100` for CUDA, and also no difference in runtime at all when it comes to different sizes.

Also, I recommend a benchmark script similar to how I did in #6871 instead of using manual iterations and the use of `time.time()`. It should be more reliable.",recommend size addition size involved otherwise insufficient work measure kernel launch latency might large difference come small size like also difference come different size also recommend script similar instead manual use reliable,issue,positive,negative,neutral,neutral,negative,negative
1874074000,"> I understand that the outputs are being checked in assertions. What I am asking is whether the outputs look right to you? Are they consistent?

Yes, the outputs look right to me. The only difference between GPU and CPU sampling is the order of `original_row_node_ids`, but the value of them are consistent.",understand checked whether look right consistent yes look right difference sampling order value consistent,issue,positive,positive,positive,positive,positive,positive
1874048358,"> > LGTM. Have you verified whether the different outputs from the GPU look right?
> 
> Do you mean the result of GPU sampling? The result of sampling has been verified through assertion in the test.

I understand that the outputs are being checked in assertions. What I am asking is whether the outputs look right to you? Are they consistent?",whether different look right mean result sampling result sampling assertion test understand checked whether look right consistent,issue,negative,positive,positive,positive,positive,positive
1874024598,"> Also, are you aware of this issue? #6874

Yes. I will add it tomorrow.",also aware issue yes add tomorrow,issue,negative,positive,positive,positive,positive,positive
1874024146,"> LGTM. Have you verified whether the different outputs from the GPU look right?

Do you mean the result of GPU sampling? The result of sampling has been verified through assertion in the test.",whether different look right mean result sampling result sampling assertion test,issue,negative,negative,neutral,neutral,negative,negative
1873593041,@Skeleton003 please rebase on latest master and resolve the conflicts,skeleton please rebase latest master resolve,issue,positive,positive,positive,positive,positive,positive
1873555198,@Skeleton003 is this PR ready? integrate the change made in https://github.com/dmlc/dgl/pull/6875 for benchmark?,skeleton ready integrate change made,issue,negative,positive,positive,positive,positive,positive
1873539072,It's another known issue. let me fix it,another known issue let fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1873293460,@Skeleton003 Not tested with `fanout` as current implementation is same as DGL,skeleton tested current implementation,issue,negative,neutral,neutral,neutral,neutral,neutral
1872967379,"Haven't tested it but it looks great to me, I am excited that GraphBolt can be used with PyG easily as well.",tested great excited used easily well,issue,positive,positive,positive,positive,positive,positive
1872681537,"> BTW it is better to checkout a new branch in your fork repo instead of using your master branch.

will do",better new branch fork instead master branch,issue,negative,positive,positive,positive,positive,positive
1872552986,"> LGTM, GPU sampling should work for all cases now, whether the graph is pinned or is already on the GPU. @yxy235 could you add a test for it in a separate PR?

OK, I will add it next week.",sampling work whether graph pinned already could add test separate add next week,issue,negative,neutral,neutral,neutral,neutral,neutral
1872510695,"Here are some simple steps to polish your code format using `lintrunner`.

0. `conda activate dgl` (or your env name), and `cd ~/dgl` (or where your dgl directory locates).
1. `pip install lintrunner`
2. `lintrunner` or `lintrunner <file_name>`. The latter one shows all suggested code changes for a specific file while the former one are for all modified files (according to the output of `git status`).
3. `lintrunner -a`. This command will automatically apply the suggested changes to all modified files. Also, you can run `lintrunner -a <file_name>` whose effect is easy to guess.",simple polish code format activate name directory pip install latter one code specific file former one according output git status command automatically apply also run whose effect easy guess,issue,negative,positive,neutral,neutral,positive,positive
1872508280,"> ## Description
> In principle, we should shuffle upon the whole item set to achieve good randomness.
> 
> For now, accuracy aligns with https://github.com/dmlc/dgl/blob/master/examples/sampling/graphbolt/rgcn/README.md#accuracies
> 
> **use_indexing=True, buffer_size=-1** Training~Epoch 02: 615it [01:01, 9.92it/s] Evaluating the model on the training set. Inference: 154it [00:17, 8.61it/s] Finish evaluating on training set. Evaluating the model on the validation set. Inference: 16it [00:01, 9.47it/s] Finish evaluating on validation set. Evaluating the model on the test set. Inference: 11it [00:01, 8.93it/s] Finish evaluating on test set. Run: 01, Epoch: 03, Loss: 1.8374, Train: 65.51%, Valid: 41.73%, Test: 41.36% Finish evaluating on test set. Run 01: Highest Train: 65.51 Highest Valid: 42.13 Final Train: 59.28 Final Test: 41.40
> 
> **use_indexing=False, BF=-1** Run: 01, Epoch: 02, Loss: 2.0556, Train: 60.57%, Valid: 42.76%, Test: 42.09% Finish evaluating on test set. Training~Epoch 02: 615it [01:51, 5.51it/s] Evaluating the model on the training set. Inference: 154it [00:29, 5.19it/s] Finish evaluating on training set. Evaluating the model on the validation set. Inference: 16it [00:03, 5.33it/s] Finish evaluating on validation set. Evaluating the model on the test set. Inference: 11it [00:02, 5.12it/s] Finish evaluating on test set. Run: 01, Epoch: 03, Loss: 1.7843, Train: 66.54%, Valid: 42.68%, Test: 41.60% Finish evaluating on test set. Run 01: Highest Train: 66.54 Highest Valid: 42.76 Final Train: 60.57 Final Test: 42.09
> 
> ## Checklist
> Please feel free to remove inapplicable items for your PR.
> 
> * [ ]  The PR title starts with [$CATEGORY] (such as [NN], [Model], [Doc], [Feature]])
> * [ ]  I've leverage the [tools](https://docs.google.com/document/d/1iHyj7zlmygKSk5gBPsqIqL5ASPzJSPREaNT_QdsiYA4/edit) to beautify the python and c++ code.
> * [ ]  The PR is complete and small, read the [Google eng practice (CL equals to PR)](https://google.github.io/eng-practices/review/developer/small-cls.html) to understand more about small PR. In DGL, we consider PRs with less than 200 lines of core code change are small (example, test and documentation could be exempted).
> * [ ]  All changes have test coverage
> * [ ]  Code is well-documented
> * [ ]  To the best of my knowledge, examples are either not affected by this change, or have been fixed to be compatible with this change
> * [ ]  Related issue is referred in this PR
> * [ ]  If the PR is for a new model/paper, I've updated the example index [here](../examples/README.md).
> 
> ## Changes

Did you test in fanout order [25, 10] or [10, 25]?",description principle shuffle upon whole item set achieve good randomness accuracy model training set inference finish training set model validation set inference finish validation set model test set inference finish test set run epoch loss train valid test finish test set run highest train highest valid final train final test run epoch loss train valid test finish test set model training set inference finish training set model validation set inference finish validation set model test set inference finish test set run epoch loss train valid test finish test set run highest train highest valid final train final test please feel free remove inapplicable title category model doc feature leverage beautify python code complete small read practice understand small consider le core code change small example test documentation could test coverage code best knowledge either affected change fixed compatible change related issue new example index test order,issue,positive,positive,positive,positive,positive,positive
1872494386,"> It looks like this PR shows how to convert a GraphBolt dataset into a PyG dataset. Is there going to be more PRs in the future that convert GraphBolt sampled minibatches into PyG minibatches so that we can use the GraphBolt dataloader?

For sure",like convert going future convert use sure,issue,positive,positive,positive,positive,positive,positive
1872416940,It looks like this PR shows how to convert a GraphBolt dataset into a PyG dataset. Is there going to be more PRs in the future that convert GraphBolt sampled minibatches into PyG minibatches so that we can use the GraphBolt dataloader?,like convert going future convert use,issue,negative,neutral,neutral,neutral,neutral,neutral
1872112851,"Looks good to me, thank you for the quick fix!",good thank quick fix,issue,positive,positive,positive,positive,positive,positive
1871945620,"Don't see any regression in our large scale test as well, so this should be good to merge. Thanks @Rhett-Ying !",see regression large scale test well good merge thanks,issue,positive,positive,positive,positive,positive,positive
1871743874,Feel free to push to my branch as you like. `node_classification.py` and `link_prediction.py` have the 4 different mixed modes enabled.,feel free push branch like different mixed,issue,positive,positive,positive,positive,positive,positive
1871734857,"@frozenbugs can you check `graphbolt/node_classification.py` and `graphbolt/link_prediction.py` files to see if the mixed mode option looks good?

Also if others can also test the examples with all the different available modes, that would be great. One thing is that FeatureStore does not have a `.to()` method, only has a `pin_memory_()` method. So I am adding a `to_()` method for it. Let me know if `to_()` is appropriate or we need to change it to `to()`.",check see mixed mode option good also also test different available would great one thing method method method let know appropriate need change,issue,positive,positive,positive,positive,positive,positive
1871269644,"> s PR comes from the fact that : `cub` doesn't have implicit synchron

Yes, but not all `thrust` API are synchronizing. Only the ones such as `thrust::reduce` that return the reduction result as the function return value are synchronizing. So I am eliminating those ones only so that I can manage the copies myself and optimize them.",come fact cub implicit yes thrust thrust return reduction result function return value manage optimize,issue,positive,neutral,neutral,neutral,neutral,neutral
1870954256,Is the benefits of this PR comes from the fact that : `cub` doesn't have implicit synchronization while `thrust` have? ,come fact cub implicit synchronization thrust,issue,negative,neutral,neutral,neutral,neutral,neutral
1870772068,"> This could be intentionally set to save bandwidth, @RamonZhou for confirm.

Right below, `seed_nodes` is being copied for `node_inference`. What is the difference between the two? Without this fix, I can not run an example with GPU sampling.",could intentionally set save confirm right copied difference two without fix run example sampling,issue,negative,positive,positive,positive,positive,positive
1870769201,"This could be intentionally set to save bandwidth, @RamonZhou for confirm.",could intentionally set save confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
1870722848,"Hi @lh123cha , this is expected behaviour if `relabel_nodes=False`. It will result in a subgraph containing all original nodes but only edges induced by the `node_ids`. Is there a specific reason why you don't want relabel node ids? You can get the original ids even if you use ""relabel_nodes=True"". (in the `""_ID""` field of ndata and edata)",hi behaviour result original induced specific reason want relabel node get original even use field,issue,positive,positive,positive,positive,positive,positive
1870707827,"Could you please add the following environment information?
 - DGL Version (e.g., 1.0):
 - Backend Library & Version (e.g., PyTorch 0.4.1, MXNet/Gluon 1.3):
 - OS (e.g., Linux):
 - How you installed DGL (`conda`, `pip`, source):
 - Build command you used (if compiling from source):
 - Python version:
 - CUDA/cuDNN version (if applicable):
 - GPU models and configuration (e.g. V100):
 - Any other relevant information:

We recommend to install dgl as introduced in this page: https://www.dgl.ai/pages/start.html",could please add following environment information version library version o pip source build command used source python version version applicable configuration relevant information recommend install page,issue,positive,positive,positive,positive,positive,positive
1870459145,"Yeah seems to solve the particular error we were seeing. I'd like to test with some large dataset with distributed execution as well, I'll have the time to do that tomorrow. ",yeah solve particular error seeing like test large distributed execution well time tomorrow,issue,positive,positive,positive,positive,positive,positive
1870231322,@thvasilo could you try with this patch(you could just directly change the code in your installed path)? it passes the verify script I previously created.,could try patch could directly change code path verify script previously,issue,negative,negative,neutral,neutral,negative,negative
1869996444,`exclude_edges()` is not called upon the sampled subgraph. What we need to assure is sampling works well with this case. that's it.,upon need assure sampling work well case,issue,positive,neutral,neutral,neutral,neutral,neutral
1869890723,"> @songqing Have you run this example and does it work as expected?

Yes, this is my test.
<img width=""714"" alt=""f1"" src=""https://github.com/dmlc/dgl/assets/9260628/22499358-5061-4800-8dfa-92079f3b063e"">
",run example work yes test,issue,negative,neutral,neutral,neutral,neutral,neutral
1869567330,"> A concern is is this implementation outperform torch version? CPU version benefits from the multi thread, but GPU seems doesn't have this advantage.

I will increase the performance of this operation in a future PR. The current implementation may not be faster but it will be.

Possible optimizations are:

1. Add a sort that does not return the second output, which is currently ignored anyway.
2. Before sort, compute num_bits.",concern implementation outperform torch version version thread advantage increase performance operation future current implementation may faster possible add sort return second output currently anyway sort compute,issue,positive,neutral,neutral,neutral,neutral,neutral
1869421372," A concern is is this implementation outperform torch version?
CPU version benefits from the multi thread, but GPU seems doesn't have this advantage.",concern implementation outperform torch version version thread advantage,issue,negative,neutral,neutral,neutral,neutral,neutral
1869356130,"> @yxy235 we'd better make change in forked repo instead of official repo. Please remember to remove the created branch on official repo for clean-up.

OK.",better make change forked instead official please remember remove branch official,issue,positive,positive,positive,positive,positive,positive
1869207480,@frozenbugs is there a way to ignore the example CI failure and merge it anyway?,way ignore example failure merge anyway,issue,negative,negative,negative,negative,negative,negative
1869207128,"@Rhett-Ying the example test fails very often. I think the threshold should be lowered.
```
=========================== short test summary info ============================
FAILED tests/examples/test_sparse_examples.py::test_hgnn - AssertionError: assert 0.65 &gt; 0.66
 +  where 0.65 = float('.650\n')
=================== 1 failed, 11 passed in 124.52s (0:02:04) ===================
```",example test often think threshold short test summary assert float,issue,negative,neutral,neutral,neutral,neutral,neutral
1869084951,"```
=========================== short test summary info ============================
FAILED tests/examples/test_sparse_examples.py::test_hgnn - AssertionError: assert 0.652 &gt; 0.66
 +  where 0.652 = float('.652\n')
=================== 1 failed, 11 passed in 124.78s (0:02:04) ===================
```
Looks like this test is not very reliable. May want to lower the accuracy check to `0.65`. @Rhett-Ying ",short test summary assert float like test reliable may want lower accuracy check,issue,negative,neutral,neutral,neutral,neutral,neutral
1868510506,"@valleu326 `compensate()` works as expected if and only if `origin_ids` is a `torch.arange(num_nodes/edges)`. And the methods that call `compensate()` in `heterograph.py` meets the requirement. So it works well.

Anyway, the example in `compensate()` is confusing and should be fixed.",compensate work call compensate requirement work well anyway example compensate fixed,issue,negative,positive,neutral,neutral,positive,positive
1868224013,"> 1. model.inference()?
> 2. remove eval on train_set?
> 3. args such as `--epochs`?

https://github.com/dmlc/dgl/blob/master/examples/sampling/graphbolt/rgcn/hetero_rgcn.py#L549-L550
Do we allow number of epochs to be more than 3 in this example?",remove allow number example,issue,negative,neutral,neutral,neutral,neutral,neutral
1867218439,"> LGTM overall, please also add the test for new added function.

Unittests are in another PR.",overall please also add test new added function another,issue,negative,positive,neutral,neutral,positive,positive
1867148446,"LGTM overall, please also add the test for new added function.",overall please also add test new added function,issue,negative,positive,neutral,neutral,positive,positive
1865249309,NVIDIA DGL team will check this issue. Thanks @WenxiongLiao  for reporting. We can repro your issue. ,team check issue thanks issue,issue,negative,positive,positive,positive,positive,positive
1865247977,"My latest commit seems to have resolved the multiple architecture case. I will use `cuobjdump` to ensure that the generated binary contents match the passed architecture list. Below is the `-DCUDA_ARCH_NAME=All` information from the binary with a 4090 GPU:

```
mfbalin@BALIN-PC:~/dgl-1$ cuobjdump /home/mfbalin/dgl-1/build/graphbolt/libgraphbolt_pytorch_2.0.1.so -sass -ptx | grep ""code for sm_""
        code for sm_89
        code for sm_50
        code for sm_60
        code for sm_70
        code for sm_75
        code for sm_80
        code for sm_86
        code for sm_90
        code for sm_89
        code for sm_50
        code for sm_60
        code for sm_70
        code for sm_75
        code for sm_80
        code for sm_86
        code for sm_90
        code for sm_89
        code for sm_50
        code for sm_60
        code for sm_70
        code for sm_75
        code for sm_80
        code for sm_86
        code for sm_90
```

And the output when `-DCUDA_ARCH_NAME=Auto` with a 4090 GPU:

```
mfbalin@BALIN-PC:~/dgl-1$ cuobjdump /home/mfbalin/dgl-1/build/graphbolt/libgraphbolt_pytorch_2.0.1.so -sass -ptx | grep ""code for sm_""
        code for sm_89
        code for sm_89
        code for sm_89
```",latest commit resolved multiple architecture case use ensure binary content match architecture list information binary code code code code code code code code code code code code code code code code code code code code code code code code code output code code code code,issue,positive,positive,positive,positive,positive,positive
1864515178,"anyway, I was reading the source code and found the bug, it's just used by heterograph.py, hopefully someone can fix it, that's it.",anyway reading source code found bug used hopefully someone fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1864490290,"> @caojy1998 benchmark result image links are broken.

Oh I see. You do not have the access to the link. I will re-paste it here.",result image link broken oh see access link,issue,negative,negative,negative,negative,negative,negative
1864482564,@caojy1998 benchmark result image links are broken.,result image link broken,issue,negative,negative,negative,negative,negative,negative
1864152698,"This benchmark has been finished. Here is a result for reference.

Time: 
![1](https://github.com/dmlc/dgl/assets/84027205/245a0ebe-c35e-4225-8ab1-da006434127d)
![2](https://github.com/dmlc/dgl/assets/84027205/16c64a1a-b1fb-47cc-9c74-6c49a4242adc)
![3](https://github.com/dmlc/dgl/assets/84027205/652c7f0f-d452-49ec-85a6-2511b4da7e13)
![4](https://github.com/dmlc/dgl/assets/84027205/1772ec0c-b509-405c-bc8f-acbf825c9a07)
![5](https://github.com/dmlc/dgl/assets/84027205/648884e8-c3e3-40da-a2ba-43b95e2927ff)
![6](https://github.com/dmlc/dgl/assets/84027205/cc5d4200-c57f-4793-aa79-8635ab7222da)

Throughput:
![11](https://github.com/dmlc/dgl/assets/84027205/58de7ec2-080f-4710-86f9-2899e75a7b71)
![12](https://github.com/dmlc/dgl/assets/84027205/ef7e80d1-24f7-4dd4-a119-51fe5f3413fb)
![13](https://github.com/dmlc/dgl/assets/84027205/0c30592b-9fee-4ec4-828d-acd78560e059)
![14](https://github.com/dmlc/dgl/assets/84027205/f3277549-9f5d-415f-9d04-c5422f218390)
![15](https://github.com/dmlc/dgl/assets/84027205/1283cf89-d92d-4add-99dd-67a8242e0a57)





",finished result reference time throughput,issue,negative,neutral,neutral,neutral,neutral,neutral
1863762196,"I was able to run the training example with the GPU sampling successfully, everything seems to be working. In order for me to enable the tests, I need #6738 to move forward.",able run training example sampling successfully everything working order enable need move forward,issue,negative,positive,positive,positive,positive,positive
1863673642,"The tests should be passing now, @Rhett-Ying can you check if my workaround for the dataloader test failure is correct?",passing check test failure correct,issue,negative,negative,negative,negative,negative,negative
1861377692,"@Kevis9 Could you update PyTorch to the latest stable or nightly release or is there a reason you are sticking to 2.0?
In the latter case you might need to work around the issue by moving the data to the CPU. In newer releases if should work according to the [docs](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html):
> The following normally-nondeterministic operations will act deterministically when mode=True:
> [torch.Tensor.scatter_reduce()](https://pytorch.org/docs/stable/generated/torch.Tensor.scatter_reduce.html#torch.Tensor.scatter_reduce) when reduce='sum' or reduce='mean' and called on CUDA tensor
",could update latest stable nightly release reason sticking latter case might need work around issue moving data work according following act tensor,issue,negative,positive,positive,positive,positive,positive
1859597927,"@peizhou001 When I set `num_workers=0` in this test, the test passes. What do you think could be the issue?
https://github.com/dmlc/dgl/blob/65d83ad70c664359139870068aa8357a6553c0e6/tests/python/pytorch/graphbolt/test_dataloader.py#L36",set test test think could issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1859541277,Why is the test failing? Does not seem to be related to my changes.,test failing seem related,issue,negative,neutral,neutral,neutral,neutral,neutral
1859501207,"> Hi @czkkkkkk, is there any paper/document/resource that describes temporal neighbor sampling in more detail? I would like to read up on it so that we can later extend LayerNeighborSampler for the temporal use case as well.

Actually I am not familiar with this area. This feature is requested by another project. The setting is that the nodes and edges in a graph have timestamps, and each seed node also has an independent timestamp. In temporal sampling, we need to filter out neighbors with timestamps later than the seed nodes before sampling.",hi temporal neighbor sampling detail would like read later extend temporal use case well actually familiar area feature another project setting graph seed node also independent temporal sampling need filter later seed sampling,issue,positive,positive,neutral,neutral,positive,positive
1858213458,"Hi @czkkkkkk, is there any paper/document/resource that describes temporal neighbor sampling in more detail? I would like to read up on it so that we can later extend LayerNeighborSampler for the temporal use case as well.",hi temporal neighbor sampling detail would like read later extend temporal use case well,issue,positive,neutral,neutral,neutral,neutral,neutral
1857331858,@frozenbugs @Rhett-Ying please kindly take a look at this PR.,please kindly take look,issue,positive,positive,positive,positive,positive,positive
1857168299,"Yes, it is fixed, thanks for your help.",yes fixed thanks help,issue,positive,positive,positive,positive,positive,positive
1855242051,"@peizhou001 Could you review the tests? @frozenbugs This approach may or may not be better than `dgl.to_block` when it comes to efficiency. I will be providing benchmarks soon. So, can we review everything but the implementation itself? Depending on the results of the benchmark, I might change the implementation.",could review approach may may better come efficiency providing soon review everything implementation depending might change implementation,issue,positive,positive,positive,positive,positive,positive
1855101401,Related issue: https://github.com/dmlc/dgl/issues/5425 . It is not easy to have deterministic results for arbitrary models since some GPU kernels are inherently non-deterministic. Just like what @anko-intel suggested. One workaround is to switch some of the computation to CPU and then copy the results back to GPU to by-pass those kernels.,related issue easy deterministic arbitrary since inherently like one switch computation copy back,issue,positive,positive,neutral,neutral,positive,positive
1855099025,"As the error message suggested, the sparse softmax internally calls PyTorch's `scatter_reduce` which does not have deterministic CUDA implementation. Could you try on CPU?",error message sparse internally deterministic implementation could try,issue,negative,neutral,neutral,neutral,neutral,neutral
1855098224,Related to #5275 . It needs additional support from TorchScript or TorchDynamo for custom data structure which DGL relies on.,related need additional support custom data structure,issue,negative,neutral,neutral,neutral,neutral,neutral
1854838171,"Development will continue in this repository. Hopefully, I will better adapt to the code review process and adjust the workflow accordingly.",development continue repository hopefully better adapt code review process adjust accordingly,issue,positive,positive,positive,positive,positive,positive
1854536883,"Hi. I am not sure to understand. In my example batching is done as a last step, could you explain to me what means ""mutating graphs before batching"" ? Thanks a lot ",hi sure understand example done last step could explain thanks lot,issue,positive,positive,positive,positive,positive,positive
1854490667,"Hi, please note that this is an internal utility so the code may not be well tested (or properly documented). Did you encounter any unexpected results when using related official APIs?",hi please note internal utility code may well tested properly encounter unexpected related official,issue,positive,positive,neutral,neutral,positive,positive
1854485365,"Yes, it's a current limitation that mutating a batched graph structure will corrupt its batching information. Could you try mutating graphs *before* batching?",yes current limitation graph structure corrupt information could try,issue,negative,negative,negative,negative,negative,negative
1854477202,CUDA 12 support has been added in the new 1.1.3 release https://github.com/dmlc/dgl/releases/tag/v1.1.3,support added new release,issue,negative,positive,positive,positive,positive,positive
1854475544,The CI status is currently only visible for internal team. Sorry for the inconvenience!,status currently visible internal team sorry inconvenience,issue,negative,negative,negative,negative,negative,negative
1854474056,No. Extending them to large graphs is non-trivial and will probably require new distributed system design.,extending large probably require new distributed system design,issue,negative,positive,positive,positive,positive,positive
1854472488,"For general questions, we suggest moving them to our discuss forum: discuss.dgl.ai

> 1.Is the graph data completely distributed on each machine or does each machine only have a part of the complete graph data?The paper mentions that the sampling work of graphs is done on subgraphs, so is the graph data in each machine complete or incomplete?

Graph is partitioned and distributed across machines so each machine only hosts a partition. The distributed sampler ensures information are correctly collected from them.

> 2.Is the DistDGL model on a separate machine? What does it mean here that it distributes a small batch training process to a cluster? Is the cluster here a training cluster?

> 3.Is there a sampling server, running trainer, and KVstore server on each machine? I donâ€™t quite understand here?

There are two concepts here. One is logically the system contains trainer, sampling servers, KVstore servers etc. The other is physically how are they deployed. For later, we choose a particular homogeneous deployment where each machine acts as both a trainer and a server.",general suggest moving discus forum graph data completely distributed machine machine part complete graph data paper sampling work done graph data machine complete incomplete graph partitioned distributed across machine partition distributed sampler information correctly collected model separate machine mean small batch training process cluster cluster training cluster sampling server running trainer server machine quite understand two one logically system trainer sampling physically later choose particular homogeneous deployment machine trainer server,issue,negative,positive,neutral,neutral,positive,positive
1853485956,"> You can see https://pytorch.org/docs/stable/notes/randomness.html#reproducibility. On CPU inserting into seed_everything():
> 
> ```
> dgl.seed(seed)
> torch.manual_seed(seed)
> ```
> 
> is enough.

**How to reproduce the results in gpu mode?**",see seed seed enough reproduce mode,issue,negative,neutral,neutral,neutral,neutral,neutral
1852850326,"@frozenbugs I misunderstood your comment in the PR, opened this issue so that we can track it.",misunderstood comment issue track,issue,negative,neutral,neutral,neutral,neutral,neutral
1852228243,"You can see https://pytorch.org/docs/stable/notes/randomness.html#reproducibility.
On CPU inserting into seed_everything():
```
dgl.seed(seed)
torch.manual_seed(seed)
```
is enough.",see seed seed enough,issue,negative,neutral,neutral,neutral,neutral,neutral
1851504952,"> Can you paste the output to PR description?

added",paste output description added,issue,negative,neutral,neutral,neutral,neutral,neutral
1851437751,@frozenbugs Thank you for the quick back-and-forth on the code styling portion of the review. Feel free to merge when the CI passes.,thank quick code styling portion review feel free merge,issue,positive,positive,positive,positive,positive,positive
1851416608,"Aside of _CSRRowWiseOneHopExtractorAlignedKernel, everything else looks good to me. Happy to approve once it is addressed.",aside everything else good happy approve,issue,positive,positive,positive,positive,positive,positive
1849712784,"Note to @frozenbugs : Finished review non-UVA code, will review UVA code later.",note finished review code review uva code later,issue,negative,neutral,neutral,neutral,neutral,neutral
1849155277,user guide and stochastic training are already updated. As for remaining work items such as adding notebook for preparing dataset is tracked in separate work items.,user guide stochastic training already work notebook tracked separate work,issue,negative,neutral,neutral,neutral,neutral,neutral
1847898885,"Hi @mikemhenry and @CarlinLiao, DGL sparse isn't compatible with Pytorch 2.1.1 for now. Could you try 2.0.x? In fact, for every version update of Pytorch, DGL needs to trigger a corresponding update.",hi sparse compatible could try fact every version update need trigger corresponding update,issue,negative,neutral,neutral,neutral,neutral,neutral
1847714960,"This is from another machine that I've been using with SPT with a slightly different environment (Linux native instead of WSL, Python 3.11.0 instead of 3.11.5), but I was able to replicate the issue. It looks like I have libdgl_spare for torch 2.0.0 and 2.0.1 but not 2.1.1.

```sh
$ python
Python 3.11.0 | packaged by conda-forge | (main, Jan 14 2023, 12:27:40) [GCC 11.3.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from dgl import graph
>>> g = graph(([0, 1, 2], [1, 2, 3]))
>>> g.adj()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/liaoc2/miniconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/heterograph.py"", line 3821, in adj
    from .sparse import spmatrix
  File ""/home/liaoc2/miniconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/sparse/__init__.py"", line 43, in <module>
    load_dgl_sparse()
  File ""/home/liaoc2/miniconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/sparse/__init__.py"", line 35, in load_dgl_sparse
    raise FileNotFoundError(f""Cannot find DGL C++ sparse library at {path}"")
FileNotFoundError: Cannot find DGL C++ sparse library at /home/liaoc2/miniconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/dgl_sparse/libdgl_sparse_pytorch_2.1.1.so
>>> exit()
$ conda list | grep -e 'dgl' -e 'torch'
dgl                       1.1.2.cu118             py311_0    dglteam/label/cu118
pytorch                   2.1.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch
pytorch-cuda              11.8                 h7e8668a_5    pytorch
pytorch-mutex             1.0                        cuda    pytorch
torchtriton               2.1.0                     py311    pytorch
$ ls -l /home/liaoc2/miniconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/dgl_sparse/
total 1752
-rwxrwxr-x 2 liaoc2 liaoc2 894033 Aug 14 04:36 libdgl_sparse_pytorch_2.0.0.so
-rwxrwxr-x 2 liaoc2 liaoc2 894033 Aug 14 04:36 libdgl_sparse_pytorch_2.0.1.so
``` ",another machine slightly different environment native instead python instead able replicate issue like torch sh python python main type help copyright license information import graph graph recent call last file line module file line import file line module file line raise find sparse library path find sparse library exit list total,issue,positive,positive,positive,positive,positive,positive
1847588405,"> So for this PR, I think we can check it in.

The code has still not been approved so I am closing this PR in favor of #6710.",think check code still favor,issue,negative,neutral,neutral,neutral,neutral,neutral
1846934626,"OK,I will use other function in my work,thanks again",use function work thanks,issue,negative,positive,positive,positive,positive,positive
1846472032,"> Actually I uninstalled using `pip uninstall dgl-cu110`, and the output of `dgl.__path__` is `['/data/zhuangxiang/anaconda3/lib/python3.8/site-packages/dgl']`
Hello, I have encountered the same problem. Have you resolved it yet
",actually uninstalled pip output hello problem resolved yet,issue,negative,neutral,neutral,neutral,neutral,neutral
1846420814,"> I am wondering how about converting various datasets to `DGLGraph`(as an intermediate representation or bridge) first, then compose `gb.Dataset` from the `DGLGraph`?

The challenge is not on converting DGLGraph to gb graph, but create tasks, in which different dataset are very different.",wondering converting various intermediate representation bridge first compose challenge converting graph create different different,issue,negative,positive,neutral,neutral,positive,positive
1846253257,"I'm still getting this issue with DGL 1.1.2 and torch 2.1.1

```sh
$ python
Python 3.11.5 (main, Sep 11 2023, 13:23:44) [GCC 11.2.0] on linux
Type ""help"", ""copyright"", ""credits"" or ""license"" for more information.
>>> from dgl import graph
>>> g = graph(([0, 1, 2], [1, 2, 3]))
>>> g.adj()
Traceback (most recent call last):
  File ""<stdin>"", line 1, in <module>
  File ""/home/carlin/anaconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/heterograph.py"", line 3821, in adj
    from .sparse import spmatrix
  File ""/home/carlin/anaconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/sparse/__init__.py"", line 43, in <module>
    load_dgl_sparse()
  File ""/home/carlin/anaconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/sparse/__init__.py"", line 35, in load_dgl_sparse
    raise FileNotFoundError(f""Cannot find DGL C++ sparse library at {path}"")
FileNotFoundError: Cannot find DGL C++ sparse library at /home/carlin/anaconda3/envs/spt_cggnn/lib/python3.11/site-packages/dgl/dgl_sparse/libdgl_sparse_pytorch_2.1.1.so
$ conda list | grep -e 'dgl' -e 'torch'
dgl                       1.1.2.cu118             py311_0    dglteam/label/cu118
ffmpeg                    4.3                  hf484d3e_0    pytorch
libjpeg-turbo             2.0.0                h9bf148f_0    pytorch
pyg                       2.4.0           py311_torch_2.1.0_cu118    pyg
pytorch                   2.1.1           py3.11_cuda11.8_cudnn8.7.0_0    pytorch
pytorch-cuda              11.8                 h8dd9ede_2    pytorch
pytorch-mutex             1.0                        cuda    pytorch
torchtriton               2.1.0                     py311    pytorch
torchvision               0.15.2          cuda118py311h4cc2eb7_0  
```

* DGL 1.1.2.cu118
* torch 2.1.1
* Python 3.11.5
* conda
* WSL2",still getting issue torch sh python python main type help copyright license information import graph graph recent call last file line module file line import file line module file line raise find sparse library path find sparse library list torch python,issue,negative,positive,neutral,neutral,positive,positive
1845590259,"Hi! I see that continuous-integration/jenkins/pr-merge check was not successful, however, for some reason the details page does not load for me, so I cannot see what causes the problem. Please tell me if I need to change something.",hi see check successful however reason page load see problem please tell need change something,issue,positive,positive,positive,positive,positive,positive
1844524386,"+1
Hope to support cuda 12.x as soon as possible.",hope support soon possible,issue,positive,neutral,neutral,neutral,neutral,neutral
1844375675,"> throughput <img alt=""Screenshot 2023-12-06 at 21 31 40"" width=""825"" src=""https://github.com/dglai/DGL_scripts/assets/84027205/1c1d47a2-5be8-4f76-bbf0-57df9dc0260f""> <img alt=""Screenshot 2023-12-06 at 21 32 05"" width=""784"" src=""https://github.com/dglai/DGL_scripts/assets/84027205/46f81b08-dcb2-434b-8546-c1b64f0358d0""> <img alt=""Screenshot 2023-12-06 at 21 32 40"" width=""815"" src=""https://github.com/dglai/DGL_scripts/assets/84027205/1ab20d3f-db6c-4ab2-8965-c5817054073b""> 

@caojy1998 The throughput result picture links seem to be broken, I can not view it anymore. ",throughput throughput result picture link seem broken view,issue,negative,negative,negative,negative,negative,negative
1842468788,"throughput
<img width=""825"" alt=""Screenshot 2023-12-06 at 21 31 40"" src=""https://github.com/dglai/DGL_scripts/assets/84027205/1c1d47a2-5be8-4f76-bbf0-57df9dc0260f"">
<img width=""784"" alt=""Screenshot 2023-12-06 at 21 32 05"" src=""https://github.com/dglai/DGL_scripts/assets/84027205/46f81b08-dcb2-434b-8546-c1b64f0358d0"">
<img width=""815"" alt=""Screenshot 2023-12-06 at 21 32 40"" src=""https://github.com/dglai/DGL_scripts/assets/84027205/1ab20d3f-db6c-4ab2-8965-c5817054073b"">
time
![time result](https://github.com/dmlc/dgl/assets/84027205/7d60445f-2609-4b71-bf14-682c21d67d74)
",throughput time time result,issue,negative,neutral,neutral,neutral,neutral,neutral
1842134942,"> My concerns are still on the coding style. To make the review processes of later PRs go smoothly, we should build consensus for the code styling. Since I am busy with a paper ddl this week, I will have a discussion with @frozenbugs in the next week. Maybe we can have a document and you can comment on it. So for this PR, I think we can check it in. After we build the consensus, we can refactor its code. @frozenbugs, what do you think?

Sounds good to me. So long as we can build consensus, I can promise to adhere to it to the best of my ability. I can contribute to the document and ensure that it advises the use of the most performant and efficient practices.

@czkkkkkk Thank you so much for reviewing my code when you have a deadline, I really appreciate it. Thanks to you, I can make faster progress.",still style make review later go smoothly build consensus code styling since busy paper week discussion next week maybe document comment think check build consensus code think good long build consensus promise adhere best ability contribute document ensure use performant efficient thank much code deadline really appreciate thanks make faster progress,issue,positive,positive,positive,positive,positive,positive
1842125943,"My concerns are still on the coding style. To make the review processes of later PRs go smoothly, we should build consensus for the code styling. Since I am busy with a paper ddl this week, I will have a discussion with @frozenbugs in the next week. Maybe we can have a document and you can comment on it. So for this PR, I think we can check it in. After we build the consensus, we can refactor its code. @frozenbugs, what do you think?",still style make review later go smoothly build consensus code styling since busy paper week discussion next week maybe document comment think check build consensus code think,issue,negative,positive,positive,positive,positive,positive
1842087394,"@frozenbugs @czkkkkkk We can open issues for things that are important to fix or keep track of. Some implementation details are never going to be used or changed in the future. I write code with maximum performance and efficiency in mind, thus most of the choices I make when writing code have that philosophy. I think the current state of the PR is fairly good, if we can merge this, I can start work on `unique_and_compact` without having to rebase on this PR.

However, I appreciate the assistance as after the code review process, the code seems much more pleasing to the eye.",open important fix keep track implementation never going used future write code maximum performance efficiency mind thus make writing code philosophy think current state fairly good merge start work without rebase however appreciate assistance code review process code much pleasing eye,issue,positive,positive,positive,positive,positive,positive
1842048456,"@czkkkkkk Is there anything major that blocks the merge of this PR? Thanks to your suggestions, the code is in much better shape.",anything major merge thanks code much better shape,issue,positive,positive,positive,positive,positive,positive
1842023809,"> For now, I think the compilation time or generated code size of several lines of code is not a big issue for us. However, defining variables at the beginning harms the readability because the definitions are too far from their usages. For example,
> 
> ```c++
> Foo foo = 1;
> ...
> ...
> ...
> func(foo);
> ```
> 
> It makes code review a struggle. Basically, our principle is to define variables shortly before their usages. What's worse, we cannot know what variables are used if you capture all of them in a lambda.

I see. I simplified the code much more according to your direction. Now, only trivial variables like `stream` or `num_nodes` are defined outside the dispatch. Since the whole function is contained in the indptr dispatch, all the variables are captured. So, there is no ambiguity there.

Please let me know what you think about the final code. Both the UVA and nonUVA versions of the code have simpler pre-dispatch sections now compared to the Sort implementation at the top of the code.

```cpp
std::tuple<torch::Tensor, torch::Tensor> UVAIndexSelectCSCImpl(
    torch::Tensor indptr, torch::Tensor indices, torch::Tensor nodes) {
  // Sorting nodes so that accesses over PCI-e are more regular.
  const auto perm_tensor =
      Sort(nodes, cuda::NumberOfBits(indptr.size(0) - 1)).second;
  auto stream = c10::cuda::getDefaultCUDAStream();
  const int64_t num_nodes = nodes.size(0);

  return AT_DISPATCH_INTEGRAL_TYPES(
```

```cpp
std::tuple<torch::Tensor, torch::Tensor> IndexSelectCSCImpl(
    torch::Tensor indptr, torch::Tensor indices, torch::Tensor nodes) {
  auto stream = c10::cuda::getDefaultCUDAStream();
  const int64_t num_nodes = nodes.size(0);
  return AT_DISPATCH_INTEGRAL_TYPES(
```",think compilation time code size several code big issue u however beginning readability far example foo foo foo code review struggle basically principle define shortly worse know used capture lambda see simplified code much according direction trivial like stream defined outside dispatch since whole function dispatch ambiguity please let know think final code uva code simpler sort implementation top code torch torch torch torch index torch regular auto sort auto stream return torch torch torch torch index torch auto stream return,issue,negative,positive,neutral,neutral,positive,positive
1841999768,"For now, I think the compilation time or generated code size of several lines of code is not a big issue for us. However, defining variables at the beginning harms the readability because the definitions are too far from their usages. For example,
```cpp
Foo foo = 1;
...
...
...
func(foo);
```
It makes code review a struggle. Basically, our principle is to define variables shortly before their usages. What's worse, we cannot know what variables are used if you capture all of them in a lambda.",think compilation time code size several code big issue u however beginning readability far example foo foo foo code review struggle basically principle define shortly worse know used capture lambda,issue,negative,negative,neutral,neutral,negative,negative
1841505154,"@rudongyu Thank you for your review and suggestions! I've rewritten the code to avoid loops, it's much faster now. Please take a look when you have time.",thank review code avoid much faster please take look time,issue,negative,positive,positive,positive,positive,positive
1841431818,"I refactored the `indices` and `nodes` dispatches into separate templated functions according to your review, @czkkkkkk. The code should be a lot more readable as a result. Thanks!",index separate according review code lot readable result thanks,issue,negative,positive,positive,positive,positive,positive
1841227214,"> > @czkkkkkk Thanks for the review. I tried to improve the code overall according to your suggestions. Can you resolve the comments that you think are in good shape, and comment on the ones that you still think need further improvement?
> 
> Also thanks very much for the contribution. My current concern is mostly on the code structure. I agree that we need to use lambda for dispatch pytorch data types. However, organizing too many lines of code within a lambda function is totally unreadable. So I think we need to use more sub functions or utility functions to breakdown a large function. For example,
> 
> ```c++
> template<indptr_t>
> std::tuple<torch::Tensor, torch::Tensor> UVAIndexSelectCSCImpl_(...) {
> }
> 
> std::tuple<torch::Tensor, torch::Tensor> UVAIndexSelectCSCImpl (torch::Tensor indptr, torch::Tensor indices, torch::Tensor nodes) {
>   return AT_DISPATCH_INTEGRAL_TYPES(
>       indptr.scalar_type(), ""UVAIndexSelectCSCIndptr"", ([&] {
>       return UVAIndexSelectCSCImpl_<scalar_t>(indptr, indices, nodes);
>   }
> }
> ```

I can do it but it will be worse in terms of compile time and generated code size. The reasons are as follows:
The function defines at the beginning a handful of variables to be used for the main implementation such as
```cpp
  const auto [sorted, perm_tensor] =
      Sort(nodes, cuda::NumberOfBits(indptr.size(0) - 1));
  const auto perm = perm_tensor.data_ptr<int64_t>();

  auto allocator = cuda::BuildAllocator();
  auto stream = c10::cuda::getDefaultCUDAStream();
  const auto exec_policy = thrust::cuda::par_nosync(allocator).on(stream);

  const int64_t num_nodes = nodes.size(0);

  // Output indptr for the slice indexed by nodes.
  auto sub_indptr =
      torch::empty(num_nodes + 1, nodes.options().dtype(indptr.scalar_type()));
  torch::Tensor sub_indices;
  thrust::counting_iterator<int64_t> iota(0);
```

If we put this piece of code inside a function templated on `indptr_t`, then the same code will be compiled multiple times for each different `indptr_t` unnecessarily, increasing compile times and generated code size. If we define them before the dispatch and attempt to pass them into the other function, then we have to pass them all, and their definitions will be further away from where they are used. I fail to see how that will increase readability. If you have a better suggestion to refactor the code and increase the readability without harming the considerations above, I can attempt it.

However, refactoring common parts of the code into a function called `ComputeDegree` makes a lot of sense. Thank you for the suggestion.

I will try to refactor the dispatch part for the indices tensor type into another function according to your other suggestion above, hopefully it will be more readable as a result. ",thanks review tried improve code overall according resolve think good shape comment still think need improvement also thanks much contribution current concern mostly code structure agree need use lambda dispatch data however many code within lambda function totally unreadable think need use sub utility breakdown large function example template torch torch torch torch torch torch index torch return return index worse compile time code size function beginning handful used main implementation auto sorted sort auto perm auto allocator auto stream auto thrust allocator stream output slice indexed auto torch torch thrust iota put piece code inside function code multiple time different unnecessarily increasing compile time code size define dispatch attempt pas function pas away used fail see increase readability better suggestion code increase readability without attempt however common code function lot sense thank suggestion try dispatch part index tensor type another function according suggestion hopefully readable result,issue,positive,positive,neutral,neutral,positive,positive
1840360946,"> @czkkkkkk Thanks for the review. I tried to improve the code overall according to your suggestions. Can you resolve the comments that you think are in good shape, and comment on the ones that you still think need further improvement?

Also thanks very much for the contribution. My current concern is mostly on the code structure. I agree that we need to use lambda for dispatch pytorch data types. However, organizing too many lines of code within a lambda function is totally unreadable. So I think we need to use more sub functions or utility functions to breakdown a large function. For example,

```cpp
template<indptr_t>
std::tuple<torch::Tensor, torch::Tensor> UVAIndexSelectCSCImpl_(...) {
}

std::tuple<torch::Tensor, torch::Tensor> UVAIndexSelectCSCImpl (torch::Tensor indptr, torch::Tensor indices, torch::Tensor nodes) {
  return AT_DISPATCH_INTEGRAL_TYPES(
      indptr.scalar_type(), ""UVAIndexSelectCSCIndptr"", ([&] {
      return UVAIndexSelectCSCImpl_<scalar_t>(indptr, indices, nodes);
  }
}
```

And also for some common utilities, you can also wrap them in a global function to reduce code redundancy. Moreover, it is more clear what variables are used in a function instead of capturing them into a lambda. For example,
```cpp
std::tuple<torch::Tensor, torch::Tensor> ComputeDegree(torch::Tensor indptr, torch::Tensor indices, torch::Tensor nodes) {
        auto in_deg = allocator.Allocate(...);
        auto sliced_indptr = allocator.Allocate(...);
        return AT_DISPATCH_INDEX_TYPES(
            nodes.scalar_type(), ""ComputeDegree"", ([&] {
              using nodes_t = index_t;
              thrust::for_each(
                  exec_policy, iota, iota + num_rows,
                  DegreeFunc<indptr_t, nodes_t>{
                      nodes.data_ptr<nodes_t>(), indptr.data_ptr<indptr_t>(),
                      in_deg.get(), sliced_indptr.get()});
             return {in_deg, sliced_indptr};
            }));
```
",thanks review tried improve code overall according resolve think good shape comment still think need improvement also thanks much contribution current concern mostly code structure agree need use lambda dispatch data however many code within lambda function totally unreadable think need use sub utility breakdown large function example template torch torch torch torch torch torch index torch return return index also common also wrap global function reduce code redundancy moreover clear used function instead lambda example torch torch torch torch index torch auto auto return thrust iota iota return,issue,positive,positive,positive,positive,positive,positive
1840107290,This task is currently almost finished. We have a usable script for compare benchmark and daily regression test.,task currently almost finished usable script compare daily regression test,issue,negative,neutral,neutral,neutral,neutral,neutral
1840094085,"@czkkkkkk Thanks for the review. I tried to improve the code overall according to your suggestions. Can you resolve the comments that you think are in good shape, and comment on the ones that you still think need further improvement?",thanks review tried improve code overall according resolve think good shape comment still think need improvement,issue,positive,positive,positive,positive,positive,positive
1839798302,"@frozenbugs this PR is pretty much ready, the benchmarks look great, the output of the benchmark is below:

In summary, when we have an irregular (degree) graph, which is pretty much all real-life graphs, then pinned memory bandwidth for a graph with average degree 64 is 18193MiB/s. When the graph is regular, then the bandwidth is 19235MiB/s. These numbers are comparable to the UVA_index_select benchmark. One can also add the DGL baseline and use NeighborSampler with -1 fanout if one is curious about performance comparison with DGL.

When the graph is on the GPU, then bandwidth for irregular and regular are: 426864MiB/s and 575657MiB/s.

These results were obtained on an NVIDIA A100 80GB.

```
* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 84, Throughput in MB/s: 538


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 124, Throughput in MB/s: 36627


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 299, Throughput in MB/s: 152758


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 83, Throughput in MB/s: 546


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 118, Throughput in MB/s: 38504


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 275, Throughput in MB/s: 166332


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 110, Throughput in MB/s: 687


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 172, Throughput in MB/s: 44182


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 432, Throughput in MB/s: 176240


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 108, Throughput in MB/s: 700


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 155, Throughput in MB/s: 49146


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 381, Throughput in MB/s: 199854


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 110, Throughput in MB/s: 412


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1068, Throughput in MB/s: 4287


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 8991, Throughput in MB/s: 5092


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 111, Throughput in MB/s: 408


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1019, Throughput in MB/s: 4489


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 8775, Throughput in MB/s: 5216


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 109, Throughput in MB/s: 695


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1181, Throughput in MB/s: 6458


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 9899, Throughput in MB/s: 7705


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 112, Throughput in MB/s: 681


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1061, Throughput in MB/s: 7185


* params:  n_rows=2000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 8933, Throughput in MB/s: 8540


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 194, Throughput in MB/s: 1335


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 293, Throughput in MB/s: 88447


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 817, Throughput in MB/s: 317470


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 133, Throughput in MB/s: 1942


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 214, Throughput in MB/s: 121159


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 580, Throughput in MB/s: 447150


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 267, Throughput in MB/s: 1885


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 367, Throughput in MB/s: 136980


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1127, Throughput in MB/s: 446473


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 162, Throughput in MB/s: 3097


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 225, Throughput in MB/s: 223192


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 823, Throughput in MB/s: 611675


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 109, Throughput in MB/s: 2365


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 2042, Throughput in MB/s: 12700


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 17634, Throughput in MB/s: 14708


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 109, Throughput in MB/s: 2361


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1809, Throughput in MB/s: 14336


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 15976, Throughput in MB/s: 16236


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 108, Throughput in MB/s: 4639


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 2812, Throughput in MB/s: 17904


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 25153, Throughput in MB/s: 20021


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 108, Throughput in MB/s: 4619


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 2767, Throughput in MB/s: 18197


* params:  n_rows=2000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 23882, Throughput in MB/s: 21084


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 85, Throughput in MB/s: 537


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 130, Throughput in MB/s: 34957


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 357, Throughput in MB/s: 128012


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 84, Throughput in MB/s: 538


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 123, Throughput in MB/s: 36945


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 328, Throughput in MB/s: 139445


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 114, Throughput in MB/s: 669


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 177, Throughput in MB/s: 42856


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 489, Throughput in MB/s: 155692


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 108, Throughput in MB/s: 702


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 162, Throughput in MB/s: 47078


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 434, Throughput in MB/s: 175439


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 113, Throughput in MB/s: 404


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1255, Throughput in MB/s: 3646


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 10312, Throughput in MB/s: 4438


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 116, Throughput in MB/s: 391


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1227, Throughput in MB/s: 3728


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 9597, Throughput in MB/s: 4769


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 113, Throughput in MB/s: 674


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1325, Throughput in MB/s: 5755


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 11285, Throughput in MB/s: 6760


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 116, Throughput in MB/s: 652


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 1247, Throughput in MB/s: 6114


* params:  n_rows=20000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 10097, Throughput in MB/s: 7555


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 200, Throughput in MB/s: 1300


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 296, Throughput in MB/s: 87421


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 868, Throughput in MB/s: 298852


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 135, Throughput in MB/s: 1915


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 219, Throughput in MB/s: 118009


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 630, Throughput in MB/s: 411353


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 270, Throughput in MB/s: 1865


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 369, Throughput in MB/s: 136419


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 1179, Throughput in MB/s: 426864


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 166, Throughput in MB/s: 3029


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 228, Throughput in MB/s: 220194


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 874, Throughput in MB/s: 575657


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 110, Throughput in MB/s: 2346


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 2434, Throughput in MB/s: 10655


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 18492, Throughput in MB/s: 14029


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 111, Throughput in MB/s: 2323


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 2416, Throughput in MB/s: 10736


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 16653, Throughput in MB/s: 15576


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 109, Throughput in MB/s: 4580


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 2982, Throughput in MB/s: 16889


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 27678, Throughput in MB/s: 18193


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 110, Throughput in MB/s: 4568


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 2967, Throughput in MB/s: 16969


* params:  n_rows=20000000, avg_degree=64, indptr_dtype=torch.int64, tensor_dtype=torch.int64, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 26177, Throughput in MB/s: 19235


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 85, Throughput in MB/s: 535


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 130, Throughput in MB/s: 35014


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 366, Throughput in MB/s: 125025


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 84, Throughput in MB/s: 543


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 125, Throughput in MB/s: 36427


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.GPU, tensor_device=Device.GPU, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 337, Throughput in MB/s: 135571


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 128, Throughput in MB/s: 356


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 3331, Throughput in MB/s: 1373


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.IRREGULAR

Runtime in us: 32755, Throughput in MB/s: 1397


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 128, Throughput in MB/s: 356


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=100000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 3292, Throughput in MB/s: 1390


* params:  n_rows=200000000, avg_degree=8, indptr_dtype=torch.int64, tensor_dtype=torch.int32, num_indices=1000000, indptr_device=Device.Pinned, tensor_device=Device.Pinned, indices_device=Device.GPU, regular=Regularity.REGULAR

Runtime in us: 31269, Throughput in MB/s: 1463


Total runtimes in us:  {<Device.GPU: 0>: 16695, <Device.Pinned: 1>: 351823}
```",pretty much ready look great output summary irregular degree graph pretty much pinned memory graph average degree graph regular comparable one also add use one curious performance comparison graph irregular regular u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput u throughput total u,issue,positive,positive,positive,positive,positive,positive
1839106029,"@frozenbugs @czkkkkkk  For CUDA dispatch of FusedCSCSamplingGraph class operations, what kind of code path should be followed?
EDIT: Asking for follow-up PRs.",dispatch class kind code path edit,issue,positive,positive,positive,positive,positive,positive
1838996871,"> I can quickly handle the coding part, but I might need assistance from @caojy1998 as I lack certain permissions. Previously, a lot of misaligned (benchmark) settings resulted in this being blocked.

OK, I will help to run benchmark test.",quickly handle part might need assistance lack certain previously lot blocked help run test,issue,negative,positive,positive,positive,positive,positive
1837954977,"I can quickly handle the coding part, but I might need assistance from @caojy1998 as I lack certain permissions. Previously, a lot of misaligned (benchmark) settings resulted in this being blocked.",quickly handle part might need assistance lack certain previously lot blocked,issue,negative,positive,positive,positive,positive,positive
1837951457,"Node classification and multi-GPU done, missing link prediction.",node classification done missing link prediction,issue,negative,negative,negative,negative,negative,negative
1837725142,@Rhett-Ying Would you mind get someone review this?,would mind get someone review,issue,negative,neutral,neutral,neutral,neutral,neutral
1837597465,"Will this enable storing arbitrary metadata on the graph itself, such as any tensor that doesn't have to have the first dimension equal to the number of nodes or number of edges? Can one store a scalar as part of the metadata?",enable arbitrary graph tensor first dimension equal number number one store scalar part,issue,negative,positive,neutral,neutral,positive,positive
1837293667,"cuda12.1 and Pytorch 2.1 is ready in nightly build of DGL(Linux only). As for stable releases, we're working on and should be ready in a week.",ready nightly build stable working ready week,issue,positive,positive,positive,positive,positive,positive
1837293468,I was using `node_attributes` to store `dgl.NID` (original NID) when integrating DistDGL with GraphBolt. But such change is not merged into master yet.,store original nid change master yet,issue,negative,positive,positive,positive,positive,positive
1837050413,@BarclayII thank you for your reply. may i ask you how to trace the computational graph of  gnn model? i want to know the input type and output type for some operations of gnn when i use mixed-precison.,thank reply may ask trace computational graph model want know input type output type use,issue,negative,neutral,neutral,neutral,neutral,neutral
1835339608,"> Yes, only GPU. Can I get access to the benchmark repo?

You can have access but you can't kick off any run so it might not easy for you to test it. We will find a way to allow outside contributor to contribute to benchmark, at this stage we will help on the migration.",yes get access access ca kick run might easy test find way allow outside contributor contribute stage help migration,issue,positive,positive,positive,positive,positive,positive
1833238506,"> @frozenbugs where should the benchmark scripts be stored for Graphbolt?

Currently, we decide to put this test in the private repo of regression test.",currently decide put test private regression test,issue,negative,neutral,neutral,neutral,neutral,neutral
1833170807,@czkkkkkk could you help look into this issue?,could help look issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1833109126,@Rhett-Ying This issue has been resolved in PR #6304. I think it can be closed as completed.,issue resolved think closed,issue,negative,negative,neutral,neutral,negative,negative
1833108053,@caojy1998 from our team will help you take care of merging this benchmark.,team help take care,issue,positive,neutral,neutral,neutral,neutral,neutral
1833080117,@Rhett-Ying @yaox12 could you help? I am not good at writing CMakefiles.,could help good writing,issue,positive,positive,positive,positive,positive,positive
1832998849,It seems that tensorboard requires PyTorch JIT compatibility to trace PyTorch code for computation graph visualization.  Currently DGL does not support PyTorch JIT.,compatibility trace code computation graph visualization currently support,issue,negative,neutral,neutral,neutral,neutral,neutral
1832680577,We can use the final printed sum of runtimes printed by #6644 as the regression test.,use final printed sum printed regression test,issue,negative,neutral,neutral,neutral,neutral,neutral
1832476701,"> If this is a performance critical PR, we should make sure that it is fully tested. Can you paste the result in the description of the PR? I would expect, we test the overall index select speed given different reasonable sizes of features and reasonable numbers of ids. If we can cover multiple commonly used GPU, that would be a great plus.

@frozenbugs Updated the description. This PR is a strict improvement on the existing code because it swaps the slower torch::sort with faster cub sort. Let's merge it, and use the #6644 regression test to properly benchmark UVAIndexSelect so that future potential changes such as making sort optional as suggested by @czkkkkkk are going to be guaranteed to be improvements as well. So long as any future changes can lower the final reported runtime number in #6644, I am going to be fine with any suggested changes in future PRs. Runtime is improved by 2.5% on average with this PR. And the added latency by cub sorting is `< 70us`, and can improve runtime up to 4x compared to no sorting (current code uses torch::sort so we get only 2.5% speedup).",performance critical make sure fully tested paste result description would expect test overall index select speed given different reasonable size reasonable cover multiple commonly used would great plus description strict improvement code torch faster cub sort let merge use regression test properly future potential making sort optional going well long future lower final number going fine future average added latency cub u improve current code torch get,issue,positive,positive,neutral,neutral,positive,positive
1831592389,"If this is a performance critical PR, we should make sure that it is fully tested.
Can you paste the result in the description of the PR?
I would expect, we test the overall index select speed given different reasonable sizes of features and reasonable numbers of ids. If we can cover multiple commonly used GPU, that would be a great plus.",performance critical make sure fully tested paste result description would expect test overall index select speed given different reasonable size reasonable cover multiple commonly used would great plus,issue,positive,positive,positive,positive,positive,positive
1831471589,"Generally, there is no need to install a specific old version of torch, the older the version the more installation problems, just use the new version.
I recommend you first remove you torch 1.9.0, then follow the command here to install 
> pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu116",generally need install specific old version torch older version installation use new version recommend first remove torch follow command install pip install torch,issue,negative,positive,positive,positive,positive,positive
1831446087,"run this code:
import dgl
import torch
import torch.nn as nn
import torch.nn.functional as F
from dgl.nn.pytorch import GATConv
from dgl import AddSelfLoop
from dgl.data import  CoraGraphDataset
RuntimeError: DGL requires PyTorch >= 1.12.0

what I should do? update my torch1.9.0 to 1.12.0?
I think it is very difficult thing.
because I met many things when I install torch ",run code import import torch import import import import import update torch think difficult thing met many install torch,issue,negative,neutral,neutral,neutral,neutral,neutral
1831431593,"you can see the error message: **""Please install the cuda version of dgl""**
please remove the installed dgl lib, then install dgl by this command
> pip install  dgl -f https://data.dgl.ai/wheels/cu116/repo.html",see error message please install version please remove install command pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1831418820,"> Could you provide more detail about the error?

å“ˆå“ˆå“ˆä½ æ˜¯ä¸­å›½äººå§ï¼Œæˆ‘å°±ä¸è¯´è‹±è¯­äº†ï¼›å°±æ˜¯æˆ‘åœ¨å®‰è£…pip install dglä¹‹åŽè¿è¡Œä¸‹ä¸‹è¾¹ä»£ç å‡ºé”™äº†ï¼Œæ¯”ä¹‹å‰æ”¹äº†æ”¹ï¼š
import dgl
import torch
import torch.nn as nn
import torch.nn.functional as F
from dgl.nn.pytorch import GATConv
from dgl import AddSelfLoop
from dgl.data import  CoraGraphDataset

transform = (
    AddSelfLoop()
) 
data = CoraGraphDataset(transform=transform)
g = data[0]
device = torch.device(""cuda"" if torch.cuda.is_available() else ""cpu"")
g = g.int().to(device)
features = g.ndata[""feat""]
labels = g.ndata[""label""]
masks = g.ndata[""train_mask""], g.ndata[""val_mask""], g.ndata[""test_mask""] 
in_size = features.shape[1]
out_size = data.num_classes

DGLError: [15:58:04] C:\Users\Administrator\DGL_scripts\release\win-64\dgl\src\runtime\c_runtime_api.cc:82: Check failed: allow_missing: Device API cuda is not enabled. Please install the cuda version of dgl.

æˆ‘ç”µè„‘æ˜¯æœ‰cudaçš„ï¼Œ11.6ï¼›torchç‰ˆæœ¬æ˜¯GPUçš„1.9.0",could provide detail error install import import torch import import import import import transform data data device else device feat label check device please install version,issue,negative,neutral,neutral,neutral,neutral,neutral
1831248817,The CI fail seems to be related to an example unrelated to this PR.,fail related example unrelated,issue,negative,negative,negative,negative,negative,negative
1831140072,"> @mfbalin As for thrust, we're very likely to merge #6166 in a few days. If CCCL is ready, you need to include CCCL into GraphBolt?

The current thrust, cub and libcudacxx in `third_party` would work as well. I just don't know how to modify https://github.com/dmlc/dgl/blob/master/graphbolt/CMakeLists.txt.",thrust likely merge day ready need include current thrust cub would work well know modify,issue,positive,positive,neutral,neutral,positive,positive
1831138674,"@mfbalin As for thrust, we're very likely to merge https://github.com/dmlc/dgl/pull/6166 in a few days. If CCCL is ready, you need to include CCCL into GraphBolt?",thrust likely merge day ready need include,issue,negative,positive,neutral,neutral,positive,positive
1831123749,I think this PR can be reviewed and merged. third_party thrust and cub as Graphbolt CUDA dependencies can be added as part of another PR. I will need the `third_party` thrust and cub in my follow-up PRs soon.,think thrust cub added part another need thrust cub soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1829954051,Could you provide more detail about the error?,could provide detail error,issue,negative,neutral,neutral,neutral,neutral,neutral
1829286498,"> Why not use the cub library of CUDA?

Because we support older cuda versions but want to make use of a single latest version (better performance and more capabilities) of cub and thrust for a more consistent experience, now called cccl.",use cub library support older want make use single latest version better performance cub thrust consistent experience,issue,positive,positive,positive,positive,positive,positive
1829197931,@yaox12 how should Graphbolt depend on the thrust and cub in terms of the cmake setup?,depend thrust cub setup,issue,negative,neutral,neutral,neutral,neutral,neutral
1828911776,@frozenbugs  can you please help double-check if the commit https://github.com/dmlc/dgl/commit/1b3f14b0b41262f44b81ff9fa23bddd99ac09c7f can fix this issue?,please help commit fix issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1828910304,"I think this is could be due to the issue: https://github.com/dmlc/dgl/issues/6561, i.e., the sampling (child) processes invoked new CUDA instances (which is not allowed when processes are created via `fork` method). Even though such CUDA error msg is cleaned afterwards in the code (see the description https://github.com/dmlc/dgl/issues/6561), it is not enough and this cuda error is somehow revealed at device after the sampling done...

The issue https://github.com/dmlc/dgl/issues/6561 has been fixed by https://github.com/dmlc/dgl/pull/6568 and merged into master. I tested using the src build and confirm that the crash can be resolved after applying the commit https://github.com/dmlc/dgl/commit/1b3f14b0b41262f44b81ff9fa23bddd99ac09c7f.",think could due issue sampling child new via fork method even though error afterwards code see description enough error somehow revealed device sampling done issue fixed master tested build confirm crash resolved commit,issue,negative,positive,neutral,neutral,positive,positive
1828370606,"I got the following on an A100 GPU using cuda events with @czkkkkkk 's script, the num_indices=1 and 1000 don't have enough work so they basically measure the latency of the kernel calls so the throughput numbers there are not really meaningful (It is around 13-50 microseconds). I also added n_rows=100000000 and num_indices=1000000 so that the sort can start showing its benefits and the GPU has enough work so that we can make a meaningful measurement.

* params:  n_rows=100000, feat_size=1, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |       0.071|       0.071|
|USE_PERM=0  |       0.192|       0.191|
* params:  n_rows=100000, feat_size=1, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |      72.196|      65.748|
|USE_PERM=0  |     189.293|     194.837|
* params:  n_rows=100000, feat_size=1, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    4082.063|    4174.462|
|USE_PERM=0  |    1378.614|    1377.696|
* params:  n_rows=100000, feat_size=1, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   20581.713|   20647.879|
|USE_PERM=0  |    1569.614|    1569.905|
* params:  n_rows=100000, feat_size=4, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |       0.162|       0.279|
|USE_PERM=0  |       0.750|       0.770|
* params:  n_rows=100000, feat_size=4, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |     272.118|     280.097|
|USE_PERM=0  |     734.771|     772.882|
* params:  n_rows=100000, feat_size=4, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    7647.111|   10998.791|
|USE_PERM=0  |    4108.625|    4170.957|
* params:  n_rows=100000, feat_size=4, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   52919.814|   61917.899|
|USE_PERM=0  |    4246.507|    4281.451|
* params:  n_rows=100000, feat_size=47, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |       3.083|       3.362|
|USE_PERM=0  |       8.852|       8.951|
* params:  n_rows=100000, feat_size=47, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    3293.616|    3368.385|
|USE_PERM=0  |    9025.188|    9071.950|
* params:  n_rows=100000, feat_size=47, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   27769.808|   28303.101|
|USE_PERM=0  |   17579.887|   17599.679|
* params:  n_rows=100000, feat_size=47, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   95671.628|   95308.123|
|USE_PERM=0  |   18276.858|   17876.550|
* params:  n_rows=100000, feat_size=256, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |      16.826|      16.678|
|USE_PERM=0  |      42.086|      43.388|
* params:  n_rows=100000, feat_size=256, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   16831.527|   16885.168|
|USE_PERM=0  |   21211.618|   21230.505|
* params:  n_rows=100000, feat_size=256, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   27548.352|   28295.247|
|USE_PERM=0  |   24924.061|   24962.289|
* params:  n_rows=100000, feat_size=256, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   72202.218|   91757.683|
|USE_PERM=0  |   24811.207|   24946.592|
* params:  n_rows=100000, feat_size=353, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |      23.258|      23.111|
|USE_PERM=0  |      58.290|      58.290|
* params:  n_rows=100000, feat_size=353, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   17984.512|   17353.226|
|USE_PERM=0  |   21522.545|   20464.169|
* params:  n_rows=100000, feat_size=353, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   21743.683|   21377.347|
|USE_PERM=0  |   22647.429|   22613.858|
* params:  n_rows=100000, feat_size=353, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   57166.706|   46488.262|
|USE_PERM=0  |   21394.869|   20985.085|
* params:  n_rows=100000000, feat_size=1, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |       0.071|       0.071|
|USE_PERM=0  |       0.182|       0.183|
* params:  n_rows=100000000, feat_size=1, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |      70.051|      71.558|
|USE_PERM=0  |     186.451|     186.078|
* params:  n_rows=100000000, feat_size=1, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |     661.498|     662.250|
|USE_PERM=0  |     744.165|     743.898|
* params:  n_rows=100000000, feat_size=1, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    1044.306|    1043.902|
|USE_PERM=0  |     753.305|     753.308|
* params:  n_rows=100000000, feat_size=4, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |       0.147|       0.145|
|USE_PERM=0  |       0.377|       0.367|
* params:  n_rows=100000000, feat_size=4, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |     176.262|     123.682|
|USE_PERM=0  |     309.538|     639.535|
* params:  n_rows=100000000, feat_size=4, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    2413.065|    2606.739|
|USE_PERM=0  |     721.271|     722.824|
* params:  n_rows=100000000, feat_size=4, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    3011.711|    3406.509|
|USE_PERM=0  |     724.937|     725.004|
* params:  n_rows=100000000, feat_size=47, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |       1.662|       1.770|
|USE_PERM=0  |       4.149|       4.179|
* params:  n_rows=100000000, feat_size=47, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    1526.226|    3355.474|
|USE_PERM=0  |    4216.971|    8458.389|
* params:  n_rows=100000000, feat_size=47, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    7194.576|    7191.266|
|USE_PERM=0  |    4430.515|    4430.762|
* params:  n_rows=100000000, feat_size=47, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   18966.435|   19071.299|
|USE_PERM=0  |    4389.194|    4390.788|
* params:  n_rows=100000000, feat_size=256, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |       7.243|       8.724|
|USE_PERM=0  |      48.558|      20.086|
* params:  n_rows=100000000, feat_size=256, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |    8831.953|   15847.030|
|USE_PERM=0  |   18283.633|   20535.623|
* params:  n_rows=100000000, feat_size=256, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   24532.952|   24528.535|
|USE_PERM=0  |   21454.990|   21454.894|
* params:  n_rows=100000000, feat_size=256, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   25055.641|   25050.638|
|USE_PERM=0  |   21493.712|   21493.181|
* params:  n_rows=100000000, feat_size=353, num_indices=1, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |      11.259|      11.920|
|USE_PERM=0  |      28.219|      27.685|
* params:  n_rows=100000000, feat_size=353, num_indices=1000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   13181.912|   12062.259|
|USE_PERM=0  |   21285.650|   20243.649|
* params:  n_rows=100000000, feat_size=353, num_indices=100000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   23969.470|   23661.786|
|USE_PERM=0  |   24337.217|   24112.928|
* params:  n_rows=100000000, feat_size=353, num_indices=1000000, feature_device=Device.Pinned, indices_device=Device.GPU

|            |USE_ALIGN=1 |USE_ALIGN=0 |
|------------|------------|------------|
|USE_PERM=1  |   24317.730|   24071.315|
|USE_PERM=0  |   24373.349|   24156.353|",got following script enough work basically measure latency kernel throughput really meaningful around also added sort start showing enough work make meaningful measurement,issue,positive,positive,positive,positive,positive,positive
1827083570,"hello, how can i visualize the computation graphs of GNN in DGL?
 i had tried using tensorboard.SummaryWriter.add_graph(), but this api just accept input as tensor data-type. it refuses to accept DGL graphs as inputs. Is there any way I can visualize the model?",hello visualize computation tried accept input tensor accept way visualize model,issue,positive,neutral,neutral,neutral,neutral,neutral
1825963740,"Commit ID: d6771cf79ac307988cf77ea43fdf9cce2314ff69

Build ID: 1

Status: âŒ CI test failed in Stage [Torch CPU Tutorial test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6617/1/1/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6617/1/1/logs/cireport.log)",commit id build id status test stage torch tutorial test report path link full path link,issue,negative,positive,positive,positive,positive,positive
1825370309,"> I think i found the answer.. the reason is when you are inside the virtual environment, you can not open shared directory of cudatoolkit which is standing outside the virtual environment.
> 
> you can use sudo like
> 
> --> sudo python main.py
> 
> or just install cudatoolkit inside the virtual environment like
> 
> --> conda activate [your env] --> conda install -c anaconda cudatoolkit=10.1 --> python main.py
> 
> I used second way (installing cudatoolkit inside the environment) because ""sudo python"" uses ""python"" outside the virtual environment. So it's not using the right version I want to use inside the virtual environment.

Thanks a lot! That was exactly a solution of this problem for me!!!",think found answer reason inside virtual environment open directory standing outside virtual environment use like python install inside virtual environment like activate install anaconda python used second way inside environment python python outside virtual environment right version want use inside virtual environment thanks lot exactly solution problem,issue,positive,positive,positive,positive,positive,positive
1825096317,https://github.com/dmlc/dgl/blob/e242de9cb57eded6ee745ba85ee8f3faa63e4567/tests/examples/test_sampling_examples.py#L25C48-L25C52 Remove the skip it in this PR to make sure it actually fix the issue.,remove skip make sure actually fix issue,issue,negative,positive,positive,positive,positive,positive
1823748678,"As we announced in our slack channel: After DGL 2.0 (ETA: 2023Q4), we'll be prioritizing PyTorch backend due to resource constraints, saying goodbye to MXNet and TensorFlow support. If you're interested in investigating this further and fixing it, feel free to reopen the issue and modify the related DGL-TF code. We're happy to help you get your code merged.",slack channel eta due resource saying support interested investigating fixing feel free reopen issue modify related code happy help get code,issue,positive,positive,positive,positive,positive,positive
1823725987,"I think the Nans come from padding. As an example, for a batch of a 2-node graph and a 4-node graph, the mask should be
```
tensor([[[0., 0., -inf, -inf],
         [0., 0., -inf, -inf],
         [0., 0., -inf, -inf],
         [0., 0., -inf, -inf]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
```
instead of
```
tensor([[[0., 0., -inf, -inf],
         [0., 0., -inf, -inf],
         [-inf, -inf, -inf, -inf],
         [-inf, -inf, -inf, -inf]],

        [[0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.],
         [0., 0., 0., 0.]]])
```
Rows full of -inf in the second example will lead to Nans because of a softmax operation with all input values as -inf.",think come padding example batch graph graph mask tensor instead tensor full second example lead operation input,issue,negative,positive,positive,positive,positive,positive
1823723120,"> The change makes sense, but one thing needs discussion is do we need to carefully deal with the type nodes? or just do a explicit conversion in python side at tensor level, or implicit conversion in C side at variable level?

The main purpose I added an extra dispatch macro is to avoid conversion. If conversion is applied always that makes sure `nodes.dtype` equals `indices.dtype`, that is the safest. Or user is responsible for indexing on graph with `nodes` IDs is dtype-safe.
",change sense one thing need discussion need carefully deal type explicit conversion python side tensor level implicit conversion side variable level main purpose added extra dispatch macro avoid conversion conversion applied always sure user responsible indexing graph,issue,negative,positive,positive,positive,positive,positive
1823718811,"The change makes sense, but one thing needs discussion is do we need to carefully deal with the type nodes? or just do a explicit conversion in python side at tensor level, or implicit conversion in C side at variable level?",change sense one thing need discussion need carefully deal type explicit conversion python side tensor level implicit conversion side variable level,issue,negative,negative,neutral,neutral,negative,negative
1822477048,"@mfbalin could you help resolve below warning which is the side effect of this PR?
```
utils.h:49:73: warning: comparison of integer expressions of different signedness: â€˜long long unsigned intâ€™ and â€˜const long intâ€™ [-Wsign-compare]
   49 |   while (bits < static_cast<int>(sizeof(T) * 8) && (1ull << bits) < range) {
```",could help resolve warning side effect warning comparison integer different long long unsigned long ull range,issue,negative,negative,neutral,neutral,negative,negative
1822386543,"hi,@wondey-sh
May I ask if there is any other solution for deploying DGL online in your project now?

",hi may ask solution project,issue,negative,neutral,neutral,neutral,neutral,neutral
1821540398,"> > could you add a testcase for this issue?
> 
> It's probably not easy to add testcase for this issue in python code path as it needs to create a large graph.

I agree. It may take too much memory and runtime.",could add issue probably easy add issue python code path need create large graph agree may take much memory,issue,positive,positive,positive,positive,positive,positive
1821293257,"@czkkkkkk My expected conclusions with the above considerations would be as follows: (Below, by threadblock, I actually mean the total number of CUDA threads. The more CUDA threads a kernel uses, the more SMs it occupies.)

* Specialized kernel for feat_size=1 has a similar performance to unspecialized kernels. However, it can reduce the number of threadblocks used significantly (as much as 1 or 2 orders of magnitude).
* Sorting the indices can slow down the performance due to sorting overhead. But for large-scale scenarios (such as papers100M or mag240M), it will make a big performance difference and it will be worth sorting.
* Aligned memory access is slightly faster than unaligned kernels. This performance difference is expected to be noticable especially if feat_size is not a good number. To test this, we can try a few prime numbers for feat_size such as 353 and 47.
* For 1 < feature size < 32, unaligned kernel will use 2x fewer threadblocks compared to aligned kernel with same performance, if the implementation allows it. If not, it can be changed to have this outcome by assigning each warp to a row instead of block.",would actually mean total number kernel specialized kernel similar performance unspecialized however reduce number used significantly much magnitude index slow performance due overhead make big performance difference worth memory access slightly faster unaligned performance difference especially good number test try prime feature size unaligned kernel use kernel performance implementation outcome warp row instead block,issue,negative,positive,neutral,neutral,positive,positive
1821043865,"Resource usage can be measured by looking at the profile and recording how many total CUDA threads were used. (or also reporting the number of total CUDA threads in the C++ code.) The smaller the number of threads used, the more threads left to perform other tasks when PCI-e copies are overlapped with other computations.",resource usage measured looking profile recording many total used also number total code smaller number used left perform,issue,negative,positive,neutral,neutral,positive,positive
1821034731,"@czkkkkkk thank you for the investigation. The sorting optimization PR was motivated by the lack of performance on large datasets such as the mag240M dataset. Can you test with the mag240M-like scenarios below:
1. n_rows = 3B, feat_size=1, num_indices=1M for random edge type accesses with int8 datatype.
2. n_rows = 240M, feat_size=768, num_indices=1M for random vertex feature accesses with float16 dtype.

Performance matters a lot more for the large-scale training scenario because if the dataset is already small, no need to use UVA, everything can be moved to the GPU. Even the ogbn-products scenario is not large enough for the UVA bottlenecks to start showing up.

In my experience, the throughput of the 1. scenario can improve up to 4x by using PERM instead of not using it. More details can be found in the #5882 discussion.",thank investigation optimization lack performance large test random edge type random vertex feature float performance lot training scenario already small need use uva everything even scenario large enough uva start showing experience throughput scenario improve perm instead found discussion,issue,positive,negative,negative,negative,negative,negative
1820095849,So what's the DGL version you're using to load graph? I think `0.4` is too old and not compatible in recent DGL versions.,version load graph think old compatible recent,issue,negative,positive,neutral,neutral,positive,positive
1820089425,"> could you add a testcase for this issue?

It's probably not easy to add testcase for this issue in python code path as it needs to create a large graph.",could add issue probably easy add issue python code path need create large graph,issue,positive,positive,positive,positive,positive,positive
1820053947,@Rhett-Ying could you review this quick fix?,could review quick fix,issue,negative,positive,positive,positive,positive,positive
1819627780,"Yes, there seems to be a bug in the code. Let me quickly fix it.",yes bug code let quickly fix,issue,negative,positive,positive,positive,positive,positive
1818738955,"@chang-l I am closing this as we can reproduce it, feel free to reopen it if any followup is required.",reproduce feel free reopen,issue,positive,positive,positive,positive,positive,positive
1818299779,"> As discussed offline, we'd better handle dtype issue in `preprocess` stage and throw exception/warning if mismatched instead of hacking and formatting silently.

For now, no explicit formatting is applied. So we don't need to handle dtype in `preprocess` stage as we previously discussed.",better handle issue stage throw instead hacking silently explicit applied need handle stage previously,issue,negative,positive,positive,positive,positive,positive
1815624660,Thanks for reporting this. We do need to avoid passing unexpected data.,thanks need avoid passing unexpected data,issue,negative,positive,positive,positive,positive,positive
1813682167,"When we load dgl, we will read file from .dgl to get the configuration if the directory does not exist, we will create one. So please make sure the python runner has access to the directory. Or you can create .dgl by yourself first and open the access to the python runner.",load read file get configuration directory exist create one please make sure python runner access directory create first open access python runner,issue,positive,positive,positive,positive,positive,positive
1812088546,@xiangyuzhi Please also include a figure of the pseudocode for LADIES in the description.,please also include figure lady description,issue,negative,neutral,neutral,neutral,neutral,neutral
1809888512,Failed on some test cases. The lazy copy mechanism appears to be a feature.,test lazy copy mechanism feature,issue,negative,negative,negative,negative,negative,negative
1809358302,"This has caused a lot of trouble in the past, so really glad you've caught this and will fix it, @chang-l. It will also save a lot of developer time as the resulting bugs from this issue take a while to track down.",lot trouble past really glad caught fix also save lot developer time resulting issue take track,issue,positive,positive,neutral,neutral,positive,positive
1807911423,"it's just one line, it doesn't affect the code........  :(",one line affect code,issue,negative,neutral,neutral,neutral,neutral,neutral
1806961581,"@rudongyu I'd like to reopen the issue because the current behavior of `list(g.nodes)` is extremely not friendly, but it seems that I do not have the privilege to reopen it. Thanks.",like reopen issue current behavior list extremely friendly privilege reopen thanks,issue,positive,positive,positive,positive,positive,positive
1806960655,"> Thanks for reporting the issue. We expect users to use `g.nodes()` and `g.edges()` as introduced in our documentation. Feel free to reopen it if you have further questions.

@rudongyu Thanks for your reply and clarification. I agree with you, but `g.nodes` is an iterable object and it is an intuitive way to use `list` to wrap it if someone does not read the doc at first. However, I think the behavior when I use `list` to wrap it should be more friendly. There should be raised with an Error if you expect user not to use it in this way instead of falling into an endless loop and capturing infinite memory.",thanks issue expect use documentation feel free reopen thanks reply clarification agree iterable object intuitive way use list wrap someone read doc first however think behavior use list wrap friendly raised error expect user use way instead falling endless loop infinite memory,issue,positive,positive,positive,positive,positive,positive
1805260915,"@frozenbugs, @Rhett-Ying, @peizhou001, I refactored the necessary interfaces of `MinibatchBase` to functions instead of properties. This is because defining them as properties needs to rename all the attributes of `MiniBatch` and `DGLMinibatch` to avoid naming conflict. For example, `input_nodes` will become `_input_nodes`. Then all the usages of these attributes, including constructors, will need to include the underscores. Take converting `MiniBatch` to `DGLMiniBatch` as an example.
```
minibatch = DGLMiniBatch(
    _blocks=self._to_dgl_blocks(),
    _node_features=self._node_features,
    _edge_features=self._edge_features,
    _labels=self._labels,
)
```
Please leave your comments if you have a better solution. If we think this solution is fine, I will go ahead to improve the docstring and add unittests.",necessary instead need rename avoid naming conflict example become need include take converting example please leave better solution think solution fine go ahead improve add,issue,positive,positive,positive,positive,positive,positive
1804747943,"Hi @yxy235 , for GRACE example, here is the stack trace:
```=== Final ===
Traceback (most recent call last):
  File ""/workspace/examples/grace/main.py"", line 134, in <module>
    label_classification(
  File ""/opt/dgl/dgl-source/examples/pytorch/grace/eval.py"", line 20, in wrapper
    results = [f(*args, **kwargs) for _ in range(n_times)]
  File ""/opt/dgl/dgl-source/examples/pytorch/grace/eval.py"", line 20, in <listcomp>
    results = [f(*args, **kwargs) for _ in range(n_times)]
  File ""/opt/dgl/dgl-source/examples/pytorch/grace/eval.py"", line 64, in label_classification
    Y = onehot_encoder.transform(Y).toarray().astype(np.bool)
  File ""/usr/local/lib/python3.10/dist-packages/numpy/__init__.py"", line 324, in __getattr__
    raise AttributeError(__former_attrs__[attr])
AttributeError: module 'numpy' has no attribute 'bool'.
`np.bool` was a deprecated alias for the builtin `bool`. To avoid this error in existing code, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.
The aliases was originally deprecated in NumPy 1.20; for more details and guidance see the original release note at:
    https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations. Did you mean: 'bool_'?

```",hi grace example stack trace final recent call last file line module file line wrapper range file line range file line file line raise module attribute alias bool avoid error code use bool modify behavior safe specifically scalar type use originally guidance see original release note mean,issue,negative,positive,positive,positive,positive,positive
1803126447,"Split `SuperPixelDataset` into `MNISTSuperPixelDataset` and `CIFAR10SuperPixelDataset`, please help me to check it again @rudongyu @frozenbugs ",split please help check,issue,positive,neutral,neutral,neutral,neutral,neutral
1803072052,"> There appears to be a bug in the `multi-bleu.perl` script loaded by the [get_dataset(...) method](https://github.com/dmlc/dgl/blob/master/examples/pytorch/transformer/dataset/__init__.py#L205) called from [translation_train.py](https://github.com/dmlc/dgl/blob/master/examples/pytorch/transformer/translation_train.py#L74)
> 
> This script is called from [here](https://github.com/dmlc/dgl/blob/master/examples/pytorch/transformer/translation_test.py#L65) and quite often it gives the following error:
> 
> ```
> READING file: checkpoints/2-sort-False-2.pkl
> Illegal division by zero at scripts/multi-bleu.perl line 154, <STDIN> line 1000.
> ```
> 
> This happens in the following snippet:
> 
> ```
> if ($length_reference==0){
>   printf ""BLEU = 0, 0/0/0/0 (BP=0, ratio=0, hyp_len=0, ref_len=0)\n"";
>   exit(1);
> }
> 
> if ($length_translation<$length_reference) {
>   $brevity_penalty = exp(1-$length_reference/$length_translation);           <<========= It happens here
> ```
> 
> It looks like we should use `$length_translation` instead of `$length_reference` in this snippet:
> 
> ```
> if ($length_translation==0){
>   printf ""BLEU = 0, 0/0/0/0 (BP=0, ratio=0, hyp_len=0, ref_len=0)\n"";
>   exit(1);
> }
> ```

Hi, @drivanov. The script is from [moses](https://github.com/moses-smt/mosesdecoder/blob/master/scripts/generic/multi-bleu.perl) and widely used. The zero-division error in your case indicates that the model doesn't output anything. The check `$length_reference==0` is to avoid zero-division when computing ratio of lengths later. It maybe unnecessary to run the script if no model predictions are given, but for sure you can add the following block to avoid such error:
```perl
if ($length_translation==0){
  printf ""NIL Hypothesis."";
  exit(1);
}
```",bug script loaded method script quite often following error reading file illegal division zero line line following snippet exit like use instead snippet exit hi script widely used error case model output anything check avoid ratio later maybe unnecessary run script model given sure add following block avoid error nil hypothesis exit,issue,negative,negative,neutral,neutral,negative,negative
1803040509,"> How did you test the fix?

The examples can run successfully after the fix.",test fix run successfully fix,issue,negative,positive,positive,positive,positive,positive
1803021194,I see. I reproduced the issue. We will dive deep into it.,see issue dive deep,issue,negative,neutral,neutral,neutral,neutral,neutral
1801396937,@chang-l May I ask you about what is the problem with running this [grace example](https://github.com/dmlc/dgl/tree/master/examples/pytorch/grace)? I didn't catch error when running it.,may ask problem running grace example catch error running,issue,negative,neutral,neutral,neutral,neutral,neutral
1800948700,"> Hi @wondey-sh, have you estimated the expected memory usage?

Hi @czkkkkkk , the example code is used in part of my model inference code, and I expect that it can be run in a g4dn.xlarge machine. However, OOM happens even when `batch_size` is 1. The graphs in my dataset is much larger than the example code, but are perfectly fine for training with `batch_size=16`. Thanks.",hi memory usage hi example code used part model inference code expect run machine however even much example code perfectly fine training thanks,issue,positive,positive,positive,positive,positive,positive
1800576939,@rudongyu could you please look into the issue @drivanov pointed out?,could please look issue pointed,issue,negative,neutral,neutral,neutral,neutral,neutral
1796400605,It seems we have not pulled the latest master branch due to the large file limit. Close this issue.,latest master branch due large file limit close issue,issue,negative,positive,positive,positive,positive,positive
1796378398,@Rhett-Ying @frozenbugs Do we have script to generate these binary files? These npy file are bigger than 5MB threshold for our system. And it may not make sense to git track them (rather than tracking the script of generating them).,script generate binary file bigger threshold system may make sense git track rather script generating,issue,negative,neutral,neutral,neutral,neutral,neutral
1796136048,"There appears to be a bug in the `multi-bleu.perl` script loaded by the  [get_dataset(...) method](https://github.com/dmlc/dgl/blob/master/examples/pytorch/transformer/dataset/__init__.py#L205) called from  [translation_train.py](https://github.com/dmlc/dgl/blob/master/examples/pytorch/transformer/translation_train.py#L74) 

This script is called from [here](https://github.com/dmlc/dgl/blob/master/examples/pytorch/transformer/translation_test.py#L65) and quite often it gives the following error:
```
READING file: checkpoints/2-sort-False-2.pkl
Illegal division by zero at scripts/multi-bleu.perl line 154, <STDIN> line 1000.
```
This happens in the following snippet: 
```
if ($length_reference==0){
  printf ""BLEU = 0, 0/0/0/0 (BP=0, ratio=0, hyp_len=0, ref_len=0)\n"";
  exit(1);
}

if ($length_translation<$length_reference) {
  $brevity_penalty = exp(1-$length_reference/$length_translation);           <<========= It happens here
```

It looks like we should use `$length_translation` instead of `$length_reference` in this snippet:
```
if ($length_translation==0){
  printf ""BLEU = 0, 0/0/0/0 (BP=0, ratio=0, hyp_len=0, ref_len=0)\n"";
  exit(1);
}
```
",bug script loaded method script quite often following error reading file illegal division zero line line following snippet exit like use instead snippet exit,issue,negative,negative,negative,negative,negative,negative
1794255019,"> Please don't rename the variable in MiniBatch to align with DGLMiniBatch, we intentionally kept them different, since the downstream of MiniBatch could be PyG or other library as well

I see. Do you think it is better to keep `MiniBatchBase` as an interface class without any data such as `input_nodes`, `node_features`, etc?",please rename variable align intentionally kept different since downstream could library well see think better keep interface class without data,issue,positive,positive,positive,positive,positive,positive
1794126621,"> @frozenbugs , @peizhou001 , I added a abstract class for `MiniBatch` and `DGLMiniBatch`. But I still need your help for several issues when fetching features.
> 
> 1. Seems that `DGLBlock` does not have `original_edge_ids`. How can I retrieve the edge ids when fetching edge features for `DGLBlock`?
> 2. I moved as many attributes of `MiniBatch` and `DGLMiniBatch` to `MiniBatchBase` as I can. Please check whether there are missing attributes that are shared by the two classes.
> 3. To align with `DGLMiniBatch`, I renamed the `seed_nodes` in `MiniBatch` to `output_nodes`. I may need to refactor all the usages of `seed_nodes` in`MiniBatch` later. Please check whether this is reasonable.

- The edge should be in dglblock.edata[dgl.EID], here is the [code](https://github.com/dmlc/dgl/blob/master/python/dgl/graphbolt/minibatch.py#L297C40-L297C40) that assigning the value. 
- Please don't rename the variable in MiniBatch to align with DGLMiniBatch, we intentionally kept them different, since the downstream of MiniBatch could be PyG or other library as well",added abstract class still need help several fetching retrieve edge fetching edge many please check whether missing two class align may need later please check whether reasonable edge code value please rename variable align intentionally kept different since downstream could library well,issue,positive,positive,neutral,neutral,positive,positive
1794080150,"BTW, the accuracy is not stable.
```
    def test_node_classification():

        script = os.path.join(EXAMPLE_ROOT, ""node_classification.py"")

        out = subprocess.run([""python"", str(script)], capture_output=True)

        assert out.returncode == 0

        stdout = out.stdout.decode(""utf-8"")

>       assert float(stdout[-5:]) > 0.70

E       AssertionError: assert 0.623 > 0.7

E        +  where 0.623 = float('.623\n')

```",accuracy stable script python script assert assert float assert float,issue,negative,neutral,neutral,neutral,neutral,neutral
1794079024,"It failed yet on windows. try to capture stderr as well?
```
    def test_link_prediction():

        script = os.path.join(EXAMPLE_ROOT, ""link_prediction.py"")

        out = subprocess.run([""python"", str(script)], capture_output=True)

>       assert out.returncode == 0

E       assert 3221226356 == 0

E         +3221226356

E         -0


```",yet try capture well script python script assert assert,issue,negative,neutral,neutral,neutral,neutral,neutral
1794030641,"I have just installed `torcheval` on all windows CI machines, let's see if the latest run succeed.",let see latest run succeed,issue,negative,positive,positive,positive,positive,positive
1793321317,"@frozenbugs , @peizhou001 , I added a abstract class for `MiniBatch` and `DGLMiniBatch`. But I still need your help for several issues when fetching features.
1. Seems that `DGLBlock` does not have `original_edge_ids`. How can I retrieve the edge ids when fetching edge features for `DGLBlock`?
2. I moved as many attributes of `MiniBatch` and `DGLMiniBatch` to `MiniBatchBase` as I can. Please check whether there are missing attributes that are shared by the two classes.
3. To align with `DGLMiniBatch`, I renamed the `seed_nodes` in `MiniBatch` to `output_nodes`. I may need to refactor all the usages of `seed_nodes` in`MiniBatch` later. Please check whether this is reasonable.",added abstract class still need help several fetching retrieve edge fetching edge many please check whether missing two class align may need later please check whether reasonable,issue,positive,positive,neutral,neutral,positive,positive
1792913913,"To ensure the CI test is successful, I have updated the `BuiltinDataset`: `test-only.zip` by regenerating it with the latest code. This may resolve the encountered `OnDiskGraphTopologyType` mismatch in the original dataset.",ensure test successful latest code may resolve mismatch original,issue,positive,positive,positive,positive,positive,positive
1792599525,Consider to merge first and optimize on top of it.,consider merge first optimize top,issue,positive,positive,positive,positive,positive,positive
1792489964,"



> @futurelyï¼Œdglåœ¨cudaå†…æ ¸ä¸­ä½¿ç”¨åŽŸå­æ“ä½œï¼Œå³ä½¿æˆ‘ä»¬ä¿®å¤äº†æ‰€æœ‰éšæœºç§å­ï¼Œæˆ‘ä»¬ä¹Ÿä¸èƒ½ä¿è¯ç¡®å®šæ€§ã€‚ï¼ˆPyTorch å¯¹äºŽå‡ ä¸ªè¿ç®—ç¬¦ä¹Ÿæœ‰ç±»ä¼¼çš„é—®é¢˜ï¼šhttps://pytorch.org/docs/stable/notes/randomness.htmlï¼‰ã€‚
> 
> è™½ç„¶æˆ‘è®¤ä¸ºæœºå™¨å­¦ä¹ ç ”ç©¶äººå‘˜ä½¿ç”¨å›ºå®šéšæœºç§å­æŠ¥å‘Šæœ€ä½³æŒ‡æ ‡è€Œä¸æ˜¯æŠ¥å‘Šä½¿ç”¨ä¸åŒéšæœºç§å­å¤šæ¬¡è¿è¡Œçš„å¹³å‡æŒ‡æ ‡å¹¶ä¸æ˜¯ä¸€ä¸ªå¥½ä¹ æƒ¯ï¼Œä½†å¦‚æžœä»–ä»¬è¿™æ ·åšï¼Œæˆ‘ç†è§£ä»–ä»¬ã€‚æ˜¯çš„ï¼Œæˆ‘ä»¬ä¼šå°è¯•åˆ é™¤ dgl 0.5 ä¸­çš„åŽŸå­æ“ä½œå¹¶ä¿è¯ç¡®å®šæ€§ã€‚
> 
> æ ¹æ®æˆ‘çš„ç»éªŒï¼Œå¦‚æžœæ•°æ®é›†ç›¸å¯¹è¾ƒå¤§ï¼Œéžç¡®å®šæ€§é—®é¢˜å¯¹ç»“æžœçš„å½±å“éžå¸¸å°ã€‚å¦‚æžœ GNN æ¨¡åž‹åœ¨å°æ•°æ®é›†ä¸Šçš„æ€§èƒ½ï¼ˆæˆ‘ä¸æ˜¯å»ºè®® cora/citeseer/pubmed.. ä½†å®ƒä»¬å®žé™…ä¸Šæ˜¯ï¼‰ä¼šå› ä¸ºåŽŸå­æ“ä½œçš„éšæœºæ€§è€Œæœ‰å¾ˆå¤§å·®å¼‚ï¼ˆ0.001 + 0.1 + 0.01 æˆ– 0.01 + 0.001 + 0.1ï¼Ÿï¼‰ï¼Œæˆ‘è®¤ä¸ºç ”ç©¶äººå‘˜åº”è¯¥æ›´å¥½åœ°è½¬å‘æ›´å¤§çš„æ•°æ®é›†ï¼ˆä¸æ˜¯é‚£ä¹ˆè„†å¼±ï¼‰æˆ–æŠ¥å‘Šå¤šæ¬¡è¿è¡Œçš„å¹³å‡ç»“æžœï¼Œä»¥ä¾¿ç»“æžœæ›´æœ‰è¯´æœåŠ›ã€‚å¦‚æžœä¸€ç¯‡è®ºæ–‡å£°ç§°å…¶æ¨¡åž‹åœ¨å›ºå®šéšæœºç§å­çš„æƒ…å†µä¸‹ä¼˜äºŽåŸºçº¿ 0.*ï¼Œè°çŸ¥é“è¿™æ˜¯éšæœºå™ªå£°è¿˜æ˜¯æ¨¡åž‹æœ¬èº«èŽ·å¾—çš„å®žè´¨æ€§è¿›å±•ã€‚

It is now November 2023. Do you have a solution to the problem of the inability to reproduce DGL's results",solution problem inability reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
1791850619,"As discussed offline, we'd better handle dtype issue in `preprocess` stage and throw exception/warning if mismatched instead of hacking and formatting silently.",better handle issue stage throw instead hacking silently,issue,negative,positive,positive,positive,positive,positive
1789967936,"DistDGL supports and well tested on Linux only. For your issue, I think it's not built at all: https://github.com/dmlc/dgl/blob/14b4a90b4eface27b20a89817f1c0c4210d602da/src/rpc/rpc.cc#L6.",well tested issue think built,issue,negative,neutral,neutral,neutral,neutral,neutral
1789940836,Thanks for reporting the issue. We expect users to use `g.nodes()` and `g.edges()` as introduced in our documentation. Feel free to reopen it if you have further questions.,thanks issue expect use documentation feel free reopen,issue,positive,positive,positive,positive,positive,positive
1788410870,"> I don't think adding raw data into repo is a good practice. why not store data in S3 and download if needed. just for illustration and tutorial of creating `OnDiskDataset` from raw data?

The cora data set is pretty small, and this example is intuitive for show case the canonical dataformat.",think raw data good practice store data illustration tutorial raw data cora data set pretty small example intuitive show case canonical,issue,positive,positive,neutral,neutral,positive,positive
1786318379,"> Did you test the throughput of the new work compare to existing code?

Not yet.",test throughput new work compare code yet,issue,negative,positive,positive,positive,positive,positive
1784586138,Did you test the throughput of the new work compare to existing code?,test throughput new work compare code,issue,negative,positive,positive,positive,positive,positive
1782164514,"Yes, we are looking into options that can improve on-disk feature index-select. If you have more recommendation in mind, please let us know, we will investigate.",yes looking improve feature recommendation mind please let u know investigate,issue,positive,neutral,neutral,neutral,neutral,neutral
1782160227,"Yes, let's change it to 17. @Rhett-Ying to take care just in case there are any unexpected issue.",yes let change take care case unexpected issue,issue,positive,positive,neutral,neutral,positive,positive
1780671483,"Hi @hv0905 , we don't have big-endian expert in the team and don't have a handy machine to reproduce the error. If you can help us identify the issue, that will be very helpful.",hi expert team handy machine reproduce error help u identify issue helpful,issue,negative,positive,positive,positive,positive,positive
1780309544,The code repository is too huge to follow. Could you give a minimum script to reproduce the issue?,code repository huge follow could give minimum script reproduce issue,issue,negative,positive,positive,positive,positive,positive
1780280370,"@YijianLiu Is this issue a duplicate of https://discuss.dgl.ai/t/about-node-allocation-of-metis/4058?

If so, I will close this one.",issue duplicate close one,issue,negative,neutral,neutral,neutral,neutral,neutral
1780279529,"Hi, the number of source nodes and the number of target nodes should always keep the same. You can repeat the node IDs to represent multiple edges from or to them, e.g.,

```
src_nodes = [0, 1]
tgt_nodes = [1, 1]
```

It means both node 0 and node 1 are connected to node 1.",hi number source number target always keep repeat node represent multiple node node connected node,issue,negative,neutral,neutral,neutral,neutral,neutral
1778724994,"I reproduced the same errors. Could someone help to have a look at it ? Thanks very much. 

> dgl/third_party/dmlc-core/include/dmlc/./serializer.h:63:16: error: 'Write' is not a member of 'dmlc::serializer::UndefinedSerializerFor<dgl::serialize::GraphType>'
> dgl/third_party/dmlc-core/include/dmlc/./serializer.h:66:22: error: 'Read' is not a member of 'dmlc::serializer::UndefinedSerializerFor<dgl::SparseFormat>'",could someone help look thanks much error member error member,issue,negative,positive,positive,positive,positive,positive
1778437335,We decide to not include it at this stage because we have not seen enough potential usage.,decide include stage seen enough potential usage,issue,negative,neutral,neutral,neutral,neutral,neutral
1778415828,"Do you mean io_uring? I believe it is currently the best Linux async IO interface available, other than Intel's userspace NVMe driver https://spdk.io/.",mean believe currently best io interface available driver,issue,positive,positive,positive,positive,positive,positive
1776715009,"Please include the command in discription, such as
```$ python examples/sampling/graphbolt/node_classification.py --device=cuda```",please include command python,issue,negative,neutral,neutral,neutral,neutral,neutral
1775086765,"This should serve as a sampling-based training example, illustrating how sparse APIs support sampling. Let's have a chat tomorrow to discuss how to implement these changes.",serve training example sparse support sampling let chat tomorrow discus implement,issue,negative,neutral,neutral,neutral,neutral,neutral
1774916684,"Verified that this is not reproducible in graphbolt, closing this issue since dataloader function will be taken over by graphbolt soon.",reproducible issue since function taken soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1774828837,"This work has been taken up by Graphbolt, a new dataloading framework by DGL.",work taken new framework,issue,negative,positive,positive,positive,positive,positive
1774825002,[Action Item]: verify this is fixed in graphbolt.,action item verify fixed,issue,negative,positive,neutral,neutral,positive,positive
1774750829,"The primary optimization has done. For most cases, which has less than int32 number of nodes, we have the optimization in place. The future work is to support cases that have more than int32 but less than int64 number of nodes.",primary optimization done le number optimization place future work support le number,issue,positive,positive,positive,positive,positive,positive
1774614624,This has been handled by other issues specific to different hardware setup. We don't need a separated issue to track the work.,handled specific different hardware setup need issue track work,issue,negative,neutral,neutral,neutral,neutral,neutral
1774603831,"Currently we don't have a common open dataset with edge feature, postpone to future.",currently common open edge feature postpone future,issue,negative,negative,neutral,neutral,negative,negative
1774328129,"@UtkrishtP Can you double check whether the problem is resolved or not? If not, feel free to reopen, we can investigate more.",double check whether problem resolved feel free reopen investigate,issue,negative,positive,positive,positive,positive,positive
1774082345,"Hi @khaled-rahman , I've just tried to build DGL v1.1.2 using gcc version `11.4.0` on a `s390x` (IBM Z) architecture machine, and the same error encountered:  
![image](https://github.com/dmlc/dgl/assets/29349119/16a194da-dc60-4099-ad82-dcd4948e6be7)  

Are there any other options you adjusted to solve the problem instead of upgrading the compiler? Any help would be thanked!

My compiler version:
![image](https://github.com/dmlc/dgl/assets/29349119/7e2cba8b-de37-4653-a004-7ba37aecd568)
",hi tried build version architecture machine error image solve problem instead compiler help would compiler version image,issue,negative,neutral,neutral,neutral,neutral,neutral
1773652744,"> can you give the sample code which can reproduce this issue

My main questions are about METIS. I am trying to use metis on reddit datatset, and I get reddit.json
Reddist dataset has about 240,000, when I use METIS to get 3 parts of graph.dgl, I find that the nodes on one server have up to 150,000, it is greatly more than 80,000 for average node nums, why?",give sample code reproduce issue main metis trying use metis get use metis get find one server greatly average node,issue,negative,positive,neutral,neutral,positive,positive
1772969578,I now close this issue. A workaround is to use dgl-1.0.2+cu118 as pointed out in https://github.com/dmlc/dgl/issues/6375 .,close issue use pointed,issue,negative,neutral,neutral,neutral,neutral,neutral
1772965584,"> BTW, this error will not occur if I use the previous version of dgl. I tried to install **dgl-1.0.2+cu118** on the server which is the installed version on my cooperator's PC, run the code and nothing happened.


Thanks! You saved my life. I can now run my code.",error occur use previous version tried install server version run code nothing thanks saved life run code,issue,negative,positive,neutral,neutral,positive,positive
1772381922,"> How soon can this bug be fixed? Because I'm really stuck on it.

I am writing the testcase that Rui suggested, and I come up with a strange error when running test. I will fix it as soon as possible.",soon bug fixed really stuck writing come strange error running test fix soon possible,issue,negative,positive,neutral,neutral,positive,positive
1772371640,How soon can this bug be fixed? Because I'm really stuck on it.,soon bug fixed really stuck,issue,negative,positive,positive,positive,positive,positive
1772244051,can you give the sample code which can reproduce this issue,give sample code reproduce issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1771658294,"Sorry, this is the same bug as here https://github.com/dmlc/dgl/issues/6375. Sadly it looks that it won't be solved in a short time.",sorry bug sadly wo short time,issue,negative,negative,negative,negative,negative,negative
1771638798,"The problem exists as long as a graph is created in a dataset class. Even the graph is not returned, and even for a torch dataset and torch dataloader. That is rediculous. Is there a way to load dgl graphs at all?

```
import dgl
from torch import nn
import torch
from torch.utils.data import DataLoader

class Trivial(nn.Module):
	def __init__(self):
		super().__init__()
		self.my_param = nn.Parameter(torch.randn((3, 3)))

	def forward(self, feature_dict, g=None):
		pass


class GraphDataset(torch.utils.data.Dataset):
	def __init__(self):
		super().__init__()

	def __getitem__(self, i):
		g = dgl.graph((torch.tensor([2, 3, 4]), torch.tensor([1, 2, 3])))
		return torch.randn((3, 3)), torch.randn((3, 3))

	def __len__(self):
		return 20

def main():
	train_dataset = GraphDataset()
	train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=1, drop_last=True)

	model_all = Trivial()
	model_all.to('cuda')  # if you remove this line, then everything is OK, otherwise not.

	for i, (g1, t) in enumerate(train_loader):
		gt = t.to('cuda')


if __name__ == '__main__':
	main()
```

```
Traceback (most recent call last):
  File ""/home/wzm/MyCode/BiEq/dgl_debug.py"", line 40, in <module>
    main()
  File ""/home/wzm/MyCode/BiEq/dgl_debug.py"", line 36, in main
    gt = t.to('cuda')
RuntimeError: CUDA error: unspecified launch failure
CUDA kernel errors might be asynchronously reported at some other API call,so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
```",problem long graph class even graph returned even torch torch way load import torch import import torch import class trivial self super forward self pas class self super self return self return main trivial remove line everything otherwise enumerate main recent call last file line module main file line main error unspecified launch failure kernel might call might incorrect consider passing,issue,negative,positive,neutral,neutral,positive,positive
1771232855,"The error two looks like because input is tf.Tensor type,but if I want to use tensorflow.keras.models.Model to create a neural network,I must be use keras.layers.Input as model's input.So how can I add DGL's GraphConv layer to tensorflow model?",error two like input type want use create neural network must use model add layer model,issue,negative,neutral,neutral,neutral,neutral,neutral
1771165312,"This PR make sense to merge such that we can do GPU sampling in the future, but I think more importantly is adding to function for https://github.com/dmlc/dgl/blob/557c0a86aada41d540de3c30de16e7049047c229/python/dgl/graphbolt/minibatch.py#L181, such that we can to cuda first and then to dgl, such that the generated dgl_blocks are on CUDA as well.",make sense merge sampling future think importantly function first well,issue,positive,positive,positive,positive,positive,positive
1770369848,@yaox12 can you help us take a look at this PR?,help u take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1770311534,"> I come to the same problem with you , I want to know if you solve it?

Hello, did you figure it out? I want to know how to slove it.
",come problem want know solve hello figure want know,issue,negative,neutral,neutral,neutral,neutral,neutral
1770218594,"@frozenbugs please have a look on the updated title, and check whether there are any other problems.",please look title check whether,issue,negative,neutral,neutral,neutral,neutral,neutral
1769838581,Thanks @frozenbugs. Let's investigate it more and get back later. ,thanks let investigate get back later,issue,negative,positive,neutral,neutral,positive,positive
1769797503,Thanks @Rhett-Ying. You mean this example will not be maintained? Can we somehow port the better implementation to here to replace the outdated one?,thanks mean example somehow port better implementation replace outdated one,issue,positive,negative,neutral,neutral,negative,negative
1768496426,@rudongyu could you help take a look?,could help take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1767561352,"@frozenbugs  Thanks for running it. 
It always failed at this case: `test_EGTLayer [True | False]`, but sometimes whole tests would pass, sometimes would segfault. 
 
Can you also try `bash script/run_pytest.sh -c tests/python/pytorch`? (I know it could take longer, sorry...)   Weirdly, when I just run `test_nn.py` or `pytorch/nn`, it works fine as you observed.",thanks running always case true false sometimes whole would pas sometimes would also try bash know could take longer sorry weirdly run work fine,issue,positive,negative,neutral,neutral,negative,negative
1767535692,"I am not able reproduce (tried 7 times) with manually built dgl with `bash script/run_pytest.sh -c tests/python/pytorch/nn/test_nn.py` with torch 1.13.0+cu117, CUDA Version: 11.6, Tesla T4

Are you fail randomly or alway a specific test case `tests/python/pytorch/nn/test_nn.py::test_EGTLayer[False]`?",able reproduce tried time manually built bash torch version fail randomly alway specific test case false,issue,negative,negative,negative,negative,negative,negative
1766539856,"The primary goal of this PR is `Add names to ItemSets in _init_all_nodes_set.`, we should reflect this in the title.
If we have to mention the add warning, or add warning is as important as add names, make it 2 PRs.",primary goal add reflect title mention add warning add warning important add make,issue,negative,positive,positive,positive,positive,positive
1765542191,"Sorry for this, I found problems that dgl has missing file `tensoradapter_pytorch_2.1.0.dll` and `dgl_sparse_pytorch_2.1.0.dll` that maybe not support for torch 2.1.0.",sorry found missing file maybe support torch,issue,negative,negative,negative,negative,negative,negative
1765400971,"Hello,
It has the same functionality in the newer versions. Can you please help me to retain the first batching information in the second batching?",hello functionality please help retain first information second,issue,positive,positive,positive,positive,positive,positive
1765159626,"I think this could be related to the asynchronous in kernel launching during dataloading. Maybe it is related to this old issue(?) https://github.com/dmlc/dgl/issues/5526 (also a cpu sampling issue)

Hi @Rhett-Ying , in this comment https://github.com/dmlc/dgl/pull/6148#issuecomment-1692713327, you added two envs `CUDA_LAUNCH_BLOCKING=1` and `PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync`. Are they both required to make it work? If so (i.e., crashed with `CUDA_LAUNCH_BLOCKING=1`), then we should focus on the stack traces reported from the runs with `CUDA_LAUNCH_BLOCKING=1`.
",think could related asynchronous kernel maybe related old issue also sampling issue hi comment added two make work focus stack,issue,negative,positive,neutral,neutral,positive,positive
1765120021,"Now, this issue has been resolved in the latest PyTorch 2.1.0 release. https://github.com/pytorch/pytorch/commit/6ea790c5b600338f848ec240dbb7cfe248e6f2de


Closing",issue resolved latest release,issue,negative,positive,positive,positive,positive,positive
1761296027,"It is concerning that with #GPU increase, the performance drops while we don't see it in previous situation in dgl. Can you double check existing dgl's performance with 5 6 7 8 GPUs to see the situation?",concerning increase performance see previous situation double check performance see situation,issue,negative,negative,neutral,neutral,negative,negative
1760850843,This is supposed to update to CCCL release with windows build error patch here: https://github.com/NVIDIA/cccl/tree/branch/2.2.x,supposed update release build error patch,issue,negative,neutral,neutral,neutral,neutral,neutral
1760842889,"You need to use this branch, their official release doesn't contain the fix for the build error we encountered.
It is here: https://github.com/NVIDIA/cccl/tree/branch/2.2.x",need use branch official release contain fix build error,issue,negative,neutral,neutral,neutral,neutral,neutral
1760831907,"As mentioned in https://github.com/NVIDIA/cccl/issues/327#issuecomment-1760045739, CCCL 2.2 is ready. I will continue on this work item.",ready continue work item,issue,negative,positive,positive,positive,positive,positive
1759111146,"I figured you are right, maybe I should put it as a stand alone code. I now close this feature request.",figured right maybe put stand alone code close feature request,issue,negative,positive,positive,positive,positive,positive
1758998556,"Thanks for the clarification, I will close this issue for now.
If you're interested in investigating this further and fixing it, feel free to reopen the issue and modify the related DGL-TF code. We're happy to help you get your code merged.",thanks clarification close issue interested investigating fixing feel free reopen issue modify related code happy help get code,issue,positive,positive,positive,positive,positive,positive
1758989521,"> Even if duplication is enabled for LayerNeighbor, it will sample the exact same neighborhood for all duplicated seed vertices. Thus, it doesn't make sense to expose this functionality to users with the current implementation, unless this behavior is okay.

I have known this situation. Although they will sample the exact same neighborhood, this behavior still has value. In machine learning, some model may attach different contexts to the same subgraphs, which may leads to different results.",even duplication sample exact neighborhood seed vertex thus make sense expose functionality current implementation unless behavior known situation although sample exact neighborhood behavior still value machine learning model may attach different may different,issue,negative,positive,neutral,neutral,positive,positive
1758857278,"Even if duplication is enabled for LayerNeighbor, it will sample the exact same neighborhood for all duplicated seed vertices. Thus, it doesn't make sense to expose this functionality to users with the current implementation, unless this behavior is okay.",even duplication sample exact neighborhood seed vertex thus make sense expose functionality current implementation unless behavior,issue,negative,positive,positive,positive,positive,positive
1758832916,"The operator `segment_mm` is primarily used for projecting heterogeneous node/edge features with type-specific weight matrices.  What is the use case of your generalized operator and how common is it?  I don't see an immediate application.

If this is only tailored for a specific application, I would suggest you to write your own PyTorch operator outside DGL.",operator primarily used projecting heterogeneous weight matrix use case generalized operator common see immediate application specific application would suggest write operator outside,issue,negative,positive,neutral,neutral,positive,positive
1757850856,"@frozenbugs @czkkkkkk Is it possible for me to join the effort to support GPUs? I have plans for making Graphbolt lightning-fast on GPUs, however, I will need help and closer collaboration to do so.",possible join effort support making however need help closer collaboration,issue,positive,neutral,neutral,neutral,neutral,neutral
1757241460,"For model part, we directly use the model in the DGL `example` directory, instead of migrating them into regression system.",model part directly use model example directory instead regression system,issue,negative,positive,neutral,neutral,positive,positive
1757232284,"The function ""add a submitter for the regression test"" is enabled! Currently, we can use `--submitter` to add the information of the sender, so that the send can receive a mail informing the result of the test.",function add submitter regression test currently use submitter add information sender send receive mail result test,issue,negative,neutral,neutral,neutral,neutral,neutral
1756616181,"> I think it would be best to open an issue related to optimizing UVA so that it is not forgotten. I would have the time to open a PR only if I switched to using Graphbolt for my own research in my PhD studies. I am unfortunately not funded to keep contributing to DGL or Graphbolt so I don't know when that may happen.

It is totally fine. I will enable those optimizations later.",think would best open issue related uva forgotten would time open switched research unfortunately funded keep know may happen totally fine enable later,issue,negative,positive,positive,positive,positive,positive
1755954535,I think it would be best to open an issue related to optimizing UVA so that it is not forgotten. I would have the time to open a PR only if I switched to using Graphbolt for my own research in my PhD studies. I am unfortunately not funded to keep contributing to DGL or Graphbolt so I don't know when that may happen.,think would best open issue related uva forgotten would time open switched research unfortunately funded keep know may happen,issue,negative,positive,neutral,neutral,positive,positive
1754540130,"> @czkkkkkk can you base your implementation on this [file](https://github.com/dmlc/dgl/blob/master/src/array/cuda/uvm/array_index_select_uvm.cu) and this [file](https://github.com/dmlc/dgl/blob/master/src/array/cuda/uvm/array_index_select_uvm.cuh) for the UVA index select implementation? It includes the sort and permutation optimization I contributed in #5882.

I see. In this PR, we will focus on supporting CUDA kernels for graphbolt. So we will enable your optimizations in later PRs. And also it would be great if you have time to work on it since you are the authors of these optimizations.",base implementation file file uva index select implementation sort permutation optimization see focus supporting enable later also would great time work since,issue,positive,positive,neutral,neutral,positive,positive
1754358007,@czkkkkkk can you base your implementation on this [file](https://github.com/dmlc/dgl/blob/master/src/array/cuda/uvm/array_index_select_uvm.cu) and this [file](https://github.com/dmlc/dgl/blob/master/src/array/cuda/uvm/array_index_select_uvm.cuh) for the UVA index select implementation? It includes the sort and permutation optimization I contributed in #5882.,base implementation file file uva index select implementation sort permutation optimization,issue,negative,negative,negative,negative,negative,negative
1753636356,"Another related function (may be incoporated into this function) is 
``
dgl.ops.segment_mm(a, b, seglen_ab)
``

####Parameters
- a (Tensor) â€“ The left operand, 2-D tensor of shape (D1, N)
- b (Tensor) â€“ The right operand, 3-D tensor of shape (N, D2)
- seglen_ab (Tensor) â€“ An integer tensor of shape (R,). Each element is the length of segments of input a in the 1-st dim and b in the 0-th dim. The summation of all elements must be equal to N.

#### Output
The output matrix of shape (R, D1, D2). 


#### Example
Let seglen_ab == [2, 4], 2 matrix multiplications will be computed:
a[:, 0:2] @ b[0:2, :]  and a[:, 4:6] @ b[4:6, :]
The result of each of this mutiplication has shape (D1, D2), and they will be stacked in dim 0 to produce output of shape (2, D1, D2)
",another related function may function tensor left operand tensor shape tensor right operand tensor shape tensor integer tensor shape element length input dim dim summation must equal output output matrix shape example let matrix result shape dim produce output shape,issue,negative,positive,neutral,neutral,positive,positive
1752867473,"> Hi @StortInter
>
> In **getitem**, when I change return 0 to return gh it will not fail, may I ask why do you need to return a integer? It is a very weird bug might due to some incompatibility between dgl and pytorch, if you can post a meaningful code which reproduces this issue, we might be able to provide more help.
>
> ```python
> import os
> 
> import dgl
> import torch
> 
> os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
> device = torch.device('cuda:0')
> 
> 
> class MyDataset(dgl.data.DGLDataset):
>  def process(self):
>      pass
> 
>  def __init__(self):
>      super().__init__('MyDataset')
> 
>  def __getitem__(self, idx):
>      gh = dgl.graph(([1, 2], [1, 2]))    # comment to resolve error
>      return gh
> 
>  def __len__(self):
>      return 1000
> 
> 
> if __name__ == '__main__':
>  iter_0 = dgl.dataloading.GraphDataLoader(
>      dataset=MyDataset(),
>      num_workers=1   # set 0 to resolve error
>  )
> 
>  for i in iter_0.__iter__():
>      i.to(device=device)
> 
>  for i in iter_0.__iter__():
>      i.to(device=device)
> ```

Hi @frozenbugs,

Here is the original code of the dataloader:

```python
# -*- coding: utf-8 -*-


import dgl
import numpy as np
from dgl.data import DGLDataset


class GraphDataset_k_nearest(DGLDataset):
    def __init__(self, x, y, k, num_nodes, win_length):
        self.x = x
        self.labels = y
        self.k = k
        self.num_nodes = num_nodes
        self.win_length = win_length

    def __getitem__(self, idx):
        node_features = self.x[idx]

        cor_matrix = np.corrcoef(node_features.T)
        src_node = []
        dst_node = []
        for j in range(cor_matrix.shape[0]):
            dst = cor_matrix[j].argsort()[-self.k:][::-1]
            src_node.extend([j] * len(dst))
            dst_node.extend(dst)

        G = dgl.graph((src_node, dst_node))
        G = dgl.to_bidirected(G)

        features = node_features.reshape(1, node_features.shape[0], node_features.shape[1])
        self.feature = features

        G.ndata['x'] = node_features.reshape(self.num_nodes, self.win_length)
        self.G = G
        return self.G, self.feature, self.labels[idx]

    def __len__(self):
        return len(self.x)

```

Just use `random` to generate `x={Tensor(10000, 420, 128)}`, `y={Tensor(10000,)}` and set `k=128`, `num_nodes=128` and `win_length=420`, for the data is too large.",hi change return return fail may ask need return integer weird bug might due incompatibility post meaningful code issue might able provide help python import o import import torch device class process self pas self super self comment resolve error return self return set resolve error hi original code python import import import class self self range return self return use random generate tensor tensor set data large,issue,positive,positive,neutral,neutral,positive,positive
1752445939,"Hi @wzm2256 , we haven't touched graph classification related support in Graphbolt, but indeed this should be part of fundamental functions in dgl library.

Can you put your workaround solution in https://github.com/dmlc/dgl/blob/b79dae36adfcde6e599ac05d21358353ce675996/python/dgl/batch.py#L446 for now and we can look into the optimization later when we invest in graph classification related support in Graphbolt",hi touched graph classification related support indeed part fundamental library put solution look optimization later invest graph classification related support,issue,positive,neutral,neutral,neutral,neutral,neutral
1752399718,"minimum demo for reference:
```
import dgl
import dgl.graphbolt as gb
import torch

g = dgl.graph(([5, 0, 1, 5, 6, 7, 2, 2, 4], [0, 1, 2, 2, 2, 2, 3, 4, 4]))
graph = gb.from_dglgraph(g, True)

seed_nodes = torch.LongTensor([0, 3, 4])
seed_nodes = torch.LongTensor([5, 2, 2, 4])

itemset = gb.ItemSet(seed_nodes, names=""seed_nodes"")
item_sampler = gb.ItemSampler(itemset, batch_size=len(seed_nodes))
num_layer = 2
fanouts = [torch.LongTensor([2]) for _ in range(num_layer)]

datapipe = item_sampler.sample_neighbor(graph, fanouts)

for data in datapipe:
    print(data)
```",minimum reference import import import torch graph true range graph data print data,issue,negative,positive,positive,positive,positive,positive
1752299799,"> if you change the default behavior of this script, update `README.md` accordingly.

OK, I have changed the `README.md`.",change default behavior script update accordingly,issue,negative,neutral,neutral,neutral,neutral,neutral
1752111820,"I will try to work on this feature, but I have never written any cuda code before, so please do not count on me...",try work feature never written code please count,issue,negative,neutral,neutral,neutral,neutral,neutral
1751965737,"Ok, I got it. Thank you for your help.



---Original---
From: ""Minjie ***@***.***&gt;
Date: Sun, Oct 8, 2023 07:23 AM
To: ***@***.***&gt;;
Cc: ***@***.******@***.***&gt;;
Subject: Re: [dmlc/dgl] If I want to use dgl with hdfs, does the server withdgl installed must be used as the DataNode of the hadoop cluster? (Issue#6377)




 
Hi @youngeryoungeryang , we inherit this USE_HDFS flag from dmlc-core https://github.com/dmlc/dmlc-core/blob/main/cmake/Modules/FindHDFS.cmake but have not formally tested it. In another word, this is not an official feature of DGL. My suggestion is to load data from HDFS using other packages before calling DGL.
 
â€”
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you were mentioned.Message ID: ***@***.***&gt;",got thank help date sun subject want use server must used cluster issue hi inherit flag formally tested another word official feature suggestion load data calling reply directly view id,issue,positive,negative,neutral,neutral,negative,negative
1751941358,"@frozenbugs Is the below pseudo code what we want to achieve in this work item?

```
src = [5, 0, 1, 5, 6, 7, 2, 2, 4]
dst = [0, 1, 2, 2, 2, 2, 3, 4, 4]
g = Graph(src, dst)

seed_nodes = [0, 3, 4]
fanouts = [2, 2]

# 1st hop
input_nodes, node_pairs = sample(g, seed_nodes)
input_nodes #  5, 2, 2, 4] ## original seed nodes not included.
node_pairs # ([5, 2, 2, 4], [0, 3, 4, 4]) ##not compact

# 2nd hop with de-duplication(Existing behavior)
seed_nodes = unique(input_nodes) # [5, 2, 4]
input_nodes, node_pairs = sample(g, seed_nodes)
input_nodes # [1, 5, 2, 4]
node_pairs # ([1, 5, 2, 4], [2, 2, 4, 4])

# 2nd hop without de-duplication(TODO)
seed_nodes = input_nodes # [5, 2, 2, 4]
input_nodes, node_pairs = sample(g, seed_nodes)
input_nodes # [1, 5, 6, 7, 2, 4]
node_pairs # ([1, 5, 6, 7, 2, 4], [2, 2, 2, 2, 4, 4])
```",pseudo code want achieve work item graph st hop sample original seed included compact hop behavior unique sample hop without sample,issue,negative,positive,positive,positive,positive,positive
1751881671,"The number of graph nodes I use is different, so I'll add nodes to each graph up to the maximum number of nodes. At the same time, the corresponding position of the mask variable is -inf",number graph use different add graph maximum number time corresponding position mask variable,issue,negative,neutral,neutral,neutral,neutral,neutral
1751852106,"Hi @youngeryoungeryang , we inherit this USE_HDFS flag from dmlc-core https://github.com/dmlc/dmlc-core/blob/main/cmake/Modules/FindHDFS.cmake but have not formally tested it. In another word, this is not an official feature of DGL. My suggestion is to load data from HDFS using other packages before calling DGL.",hi inherit flag formally tested another word official feature suggestion load data calling,issue,negative,neutral,neutral,neutral,neutral,neutral
1751849474,"For bug report, could you follow the bug report template so we can know more about your hardware/software configs? Also, to better assist you, could you also provide a minimal reproducible example? Thanks.",bug report could follow bug report template know also better assist could also provide minimal reproducible example thanks,issue,positive,positive,positive,positive,positive,positive
1751848370,"Hi @wzm2256 , thank you for the suggestion. I think this would be related to GraphBolt, our ongoing project for redesigning data loading. In general, what you described should be supported by the graph mini-batch produced by the pipeline. cc @frozenbugs .",hi thank suggestion think would related ongoing project data loading general graph produced pipeline,issue,negative,positive,neutral,neutral,positive,positive
1751847580,Duplicate of https://discuss.dgl.ai/t/import-dgl-json-decoder-jsondecodeerror-extra-data-line-2-column-1-char-23/4017/2 . Likely not a bug of DGL but corruption of the config file.,duplicate likely bug corruption file,issue,negative,neutral,neutral,neutral,neutral,neutral
1751706066,"My Pytorch version is 1.13.0 and Cuda version is 11.7. During the coding process, I found that the model training results were inconsistent and could not reproduce the results. Therefore, I wanted to set dgl. seed, but an error occurred and I would like to inquire about a solution
Traceback (most recent call last):
  File ""/home/gnn/zjz/test/å­¦é•¿çš„ä»£ç æµ‹è¯•/run.py"", line 200, in <module>
    main(**d)
  File ""/home/gnn/zjz/test/å­¦é•¿çš„ä»£ç æµ‹è¯•/run.py"", line 81, in main
    dgl.seed(seed)
  File ""/home/gnn/miniconda3/envs/zjz_graph_dgl/lib/python3.10/site-packages/dgl/random.py"", line 19, in seed
    _CAPI_SetSeed(val)
  File ""dgl/_ffi/_cython/./function.pxi"", line 295, in dgl._ffi._cy3.core.FunctionBase.__call__
  File ""dgl/_ffi/_cython/./function.pxi"", line 227, in dgl._ffi._cy3.core.FuncCall
  File ""dgl/_ffi/_cython/./function.pxi"", line 217, in dgl._ffi._cy3.core.FuncCall3
dgl._ffi.base.DGLError: [20:55:36] /opt/dgl/src/random/random.cc:36: Check failed: e == CURAND_STATUS_SUCCESS: CURAND Error: CURAND_STATUS_INITIALIZATION_FAILED at /opt/dgl/src/random/random.cc:36
Stack trace:
  [bt] (0) /home/gnn/miniconda3/envs/zjz_graph_dgl/lib/python3.10/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f1cb6da71ef]
  [bt] (1) /home/gnn/miniconda3/envs/zjz_graph_dgl/lib/python3.10/site-packages/dgl/libdgl.so(+0x6ad666) [0x7f1cb70ad666]
  [bt] (2) /home/gnn/miniconda3/envs/zjz_graph_dgl/lib/python3.10/site-packages/dgl/libdgl.so(DGLFuncCall+0x48) [0x7f1cb70bad38]
  [bt] (3) /home/gnn/miniconda3/envs/zjz_graph_dgl/lib/python3.10/site-packages/dgl/_ffi/_cy3/core.cpython-310-x86_64-linux-gnu.so(+0x160eb) [0x7f1cf1b550eb]
  [bt] (4) /home/gnn/miniconda3/envs/zjz_graph_dgl/lib/python3.10/site-packages/dgl/_ffi/_cy3/core.cpython-310-x86_64-linux-gnu.so(+0x165cb) [0x7f1cf1b555cb]
  [bt] (5) python(_PyObject_MakeTpCall+0x25b) [0x4f9d9b]
  [bt] (6) python(_PyEval_EvalFrameDefault+0x4deb) [0x4f583b]
  [bt] (7) python(_PyFunction_Vectorcall+0x6f) [0x500b2f]
  [bt] (8) python(_PyEval_EvalFrameDefault+0x4b2b) [0x4f557b]",version version process found model training inconsistent could reproduce therefore set seed error would like inquire solution recent call last file line module main file line main seed file line seed file line file line file line check error stack trace python python python python,issue,negative,positive,neutral,neutral,positive,positive
1751579947,"A late response but here is what I got from `conda env export`:
```yaml
name: base
channels:
  - dglteam/label/cu118   # change to whatever CUDA version you need
  - defaults
dependencies:
  - dgl
```",late response got export name base change whatever version need,issue,negative,negative,negative,negative,negative,negative
1751374698,"Using kafka stream with mac m2 pro I am getting this error:

2023-10-06 16:09:36.541  INFO 69179 --- [-StreamThread-1] c.o.l.k.s.ProductCategoryCodeOutput11    : product category info key: 11: value: BpaUlfProductCodes(id=11, product_cd=CAC, product_category_cd=CC)
2023-10-06 16:09:36.708 ERROR 69179 --- [-StreamThread-1] org.apache.kafka.streams.KafkaStreams    : stream-client [6830606d-cea5-4833-9018-e1d7522f4fd4-728c09bb-339a-4a06-8c74-b883960ac800] Encountered the following exception during processing and Kafka Streams opted to SHUTDOWN_CLIENT. The streams client is going to shut down now. 

java.lang.UnsatisfiedLinkError: /private/var/folders/hj/rlzyd74168qf7184qly8zjjw0000gn/T/librocksdbjni12962212990828040106.jnilib: dlopen(/private/var/folders/hj/rlzyd74168qf7184qly8zjjw0000gn/T/librocksdbjni12962212990828040106.jnilib, 0x0001): tried: '/private/var/folders/hj/rlzyd74168qf7184qly8zjjw0000gn/T/librocksdbjni12962212990828040106.jnilib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64')), '/System/Volumes/Preboot/Cryptexes/OS/private/var/folders/hj/rlzyd74168qf7184qly8zjjw0000gn/T/librocksdbjni12962212990828040106.jnilib' (no such file), '/private/var/folders/hj/rlzyd74168qf7184qly8zjjw0000gn/T/librocksdbjni12962212990828040106.jnilib' (mach-o file, but is an incompatible architecture (have 'x86_64', need 'arm64'))
	at java.base/jdk.internal.loader.NativeLibraries.load(Native Method) ~[na:na]
	at java.base/jdk.internal.loader.NativeLibraries$NativeLibraryImpl.open(NativeLibraries.java:388) ~[na:na]
	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(NativeLibraries.java:232) ~[na:na]
	at java.base/jdk.internal.loader.NativeLibraries.loadLibrary(NativeLibraries.java:174) ~[na:na]
	at java.base/java.lang.ClassLoader.loadLibrary(ClassLoader.java:2394) ~[na:na]
	at java.base/java.lang.Runtime.load0(Runtime.java:755) ~[na:na]
	at java.base/java.lang.System.load(System.java:1953) ~[na:na]
	at org.rocksdb.NativeLibraryLoader.loadLibraryFromJar(NativeLibraryLoader.java:79) ~[rocksdbjni-6.22.1.1.jar:na]
	at org.rocksdb.NativeLibraryLoader.loadLibrary(NativeLibraryLoader.java:57) ~[rocksdbjni-6.22.1.1.jar:na]
	at org.rocksdb.RocksDB.loadLibrary(RocksDB.java:69) ~[rocksdbjni-6.22.1.1.jar:na]
	at org.rocksdb.RocksDB.<clinit>(RocksDB.java:38) ~[rocksdbjni-6.22.1.1.jar:na]
	at org.rocksdb.DBOptions.<clinit>(DBOptions.java:22) ~[rocksdbjni-6.22.1.1.jar:na]
	at org.apache.kafka.streams.state.internals.RocksDBStore.openDB(RocksDBStore.java:126) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.KeyValueSegment.openDB(KeyValueSegment.java:56) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.KeyValueSegments.getOrCreateSegment(KeyValueSegments.java:51) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.KeyValueSegments.getOrCreateSegment(KeyValueSegments.java:26) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.AbstractSegments.getOrCreateSegmentIfLive(AbstractSegments.java:85) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.AbstractRocksDBSegmentedBytesStore.put(AbstractRocksDBSegmentedBytesStore.java:214) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.RocksDBWindowStore.put(RocksDBWindowStore.java:47) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.RocksDBWindowStore.put(RocksDBWindowStore.java:25) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.ChangeLoggingWindowBytesStore.put(ChangeLoggingWindowBytesStore.java:135) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.ChangeLoggingWindowBytesStore.put(ChangeLoggingWindowBytesStore.java:36) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.MeteredWindowStore.lambda$put$2(MeteredWindowStore.java:187) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:809) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.state.internals.MeteredWindowStore.put(MeteredWindowStore.java:186) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.AbstractReadWriteDecorator$WindowStoreReadWriteDecorator.put(AbstractReadWriteDecorator.java:168) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.kstream.internals.KStreamJoinWindow$KStreamJoinWindowProcessor.process(KStreamJoinWindow.java:57) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.ProcessorNode.process(ProcessorNode.java:146) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forwardInternal(ProcessorContextImpl.java:253) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:232) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.ProcessorContextImpl.forward(ProcessorContextImpl.java:191) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.SourceNode.process(SourceNode.java:84) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamTask.lambda$process$1(StreamTask.java:731) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.metrics.StreamsMetricsImpl.maybeMeasureLatency(StreamsMetricsImpl.java:809) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamTask.process(StreamTask.java:731) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.TaskManager.process(TaskManager.java:1296) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.runOnce(StreamThread.java:784) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.runLoop(StreamThread.java:604) ~[kafka-streams-3.1.2.jar:na]
	at org.apache.kafka.streams.processor.internals.StreamThread.run(StreamThread.java:576) ~[kafka-streams-3.1.2.jar:na]
",stream mac pro getting error product category key value error following exception client going shut tried file incompatible architecture need file file incompatible architecture need native method na na na na na na na na na na na na na na jar na jar na jar na jar na jar na jar na jar na jar na jar na jar na jar na jar na jar na jar na jar na put jar na jar na jar na jar na jar na jar na jar na jar na jar na jar na process jar na jar na jar na jar na jar na jar na jar na,issue,negative,neutral,neutral,neutral,neutral,neutral
1750754795,"> Hi @jzhang-github , thanks for digging into the details. Is this TF only issue or also reproducible on Pytorch.
> 
> As we announced in our slack channel: After DGL 2.0 (ETA: 2023Q4), we'll be prioritizing PyTorch backend due to resource constraints, saying goodbye to MXNet and TensorFlow support.

Hi, this issue is not detected on the PyTorch backend.",hi thanks digging issue also reproducible slack channel eta due resource saying support hi issue,issue,positive,positive,neutral,neutral,positive,positive
1739574868,"I'm facing this issue as well
@ShivaniNR have you solved it?

EDIT: I solved uninstalling Microsoft Visual C++ 2015-2022 Redistributable (x64) - 14.34.31931 then installing the one recommended in DGL docs. I stopped having issues since then. ",facing issue well edit visual one stopped since,issue,negative,neutral,neutral,neutral,neutral,neutral
1738365217,"Hi @jzhang-github , thanks for digging into the details. Is this TF only issue or also reproducible on Pytorch.

As we announced in our slack channel: After DGL 2.0 (ETA: 2023Q4), we'll be prioritizing PyTorch backend due to resource constraints, saying goodbye to MXNet and TensorFlow support.",hi thanks digging issue also reproducible slack channel eta due resource saying support,issue,positive,positive,neutral,neutral,positive,positive
1738350491,"Hi @wondey-sh , it looks like TorchScript will be superseded by TorchDynamo in the future, so we put this feature request on hold.  For TorchDynamo compatibility, we are blocked by the lack of support for custom class (which we rely on for defining the SparseMatrix class). We would love to hear if the community has any solution or workaround for that.",hi like future put feature request hold compatibility blocked lack support custom class rely class would love hear community solution,issue,positive,positive,positive,positive,positive,positive
1738346623,"Hi @StortInter

In __getitem__, when I change return 0 to return gh it will not fail, may I ask why do you need to return a integer?
It is a very weird bug might due to some incompatibility between dgl and pytorch, if you can post a meaningful code which reproduces this issue, we might be able to provide more help.

```python
import os

import dgl
import torch

os.environ['CUDA_LAUNCH_BLOCKING'] = '1'
device = torch.device('cuda:0')


class MyDataset(dgl.data.DGLDataset):
    def process(self):
        pass

    def __init__(self):
        super().__init__('MyDataset')

    def __getitem__(self, idx):
        gh = dgl.graph(([1, 2], [1, 2]))    # comment to resolve error
        return gh

    def __len__(self):
        return 1000


if __name__ == '__main__':
    iter_0 = dgl.dataloading.GraphDataLoader(
        dataset=MyDataset(),
        num_workers=1   # set 0 to resolve error
    )

    for i in iter_0.__iter__():
        i.to(device=device)

    for i in iter_0.__iter__():
        i.to(device=device)
```",hi change return return fail may ask need return integer weird bug might due incompatibility post meaningful code issue might able provide help python import o import import torch device class process self pas self super self comment resolve error return self return set resolve error,issue,positive,positive,neutral,neutral,positive,positive
1738340462,"The said image seems to have a wrong URL.  In the source notebook (https://github.com/dmlc/dgl/blob/master/notebooks/sparse/hgnn.ipynb) the image looks like this:
![](https://data.dgl.ai/tutorial/img/hgnn/hypergraph4.PNG)
and the URL is https://data.dgl.ai/tutorial/img/hgnn/hypergraph4.PNG.  However, in the rendered HTML page the URL seems to be https://data.dgl.ai/tutorial/img/hgnn/equiv.PNG, which is the same ""Citation-cocitation"" figure appearing below.

@frozenbugs Do you know how our notebooks are converted to docs?  This seems really weird.",said image wrong source notebook image like however page figure know converted really weird,issue,negative,negative,negative,negative,negative,negative
1737500436,"I recently did more tests on this issue.

The issue may be caused by running parallel processes on the same card. If you use the GPU memory close to 100% , this issue persists.

I really hope the developers could indicate the source of this issue: wrongdoing of user, cuda, tensorflow memory growth, or dgl?

### To reproduce
The code:
```python
import dgl
import dgl.function as fn
import tensorflow as tf

# Source nodes for edges (2, 1), (3, 2), (4, 3)
src_ids = tf.constant([2, 3, 4])
# Destination nodes for edges (2, 1), (3, 2), (4, 3)
dst_ids = tf.constant([1, 2, 3])
g = dgl.graph((src_ids, dst_ids))
# g_test = ... # create a DGLGraph
g.ndata['h'] = tf.random.uniform((g.num_nodes(), 10)) # each node has feature size 10
g.edata['w'] = tf.random.uniform((g.num_edges(), 1))  # each edge has feature size 1
# collect features from source nodes and aggregate them in destination nodes
g.update_all(fn.copy_u('h', 'm'), fn.sum('m', 'h_sum'))
# multiply source node features with edge weights and aggregate them in destination nodes
g.update_all(fn.u_mul_e('h', 'w', 'm'), fn.max('m', 'h_max'))
# compute edge embedding by multiplying source and destination node embeddings


for i in range(20):
    g.apply_edges(fn.u_mul_v('h', 'h', 'w_new'))
    print('========================')
    print(g.edata['w_new'])
```

My output:
```python
2023-09-27 22:00:14.250049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.
To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.
2023-09-27 22:00:14.897858: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT
2023-09-27 22:00:16.726146: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:47] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.
2023-09-27 22:00:16.726217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1639] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6146 MB memory:  -> device: 0, name: NVIDIA RTX A6000, pci bus id: 0000:41:00.0, compute capability: 8.6
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[1.0253576e-02 1.3075180e-01 5.7482266e-01 6.7359045e-02 1.5899391e-01
  2.2390601e-01 9.7890697e-02 6.2681255e-03 1.2859498e-01 3.4314601e-04]
 [2.8556930e-03 6.2411278e-01 6.4070112e-01 3.4034211e-02 2.6684648e-01
  4.8859417e-02 2.2112578e-03 2.0315725e-01 1.0968258e-01 2.8247829e-04]
 [4.0815558e-02 7.5615031e-01 3.8724628e-01 6.1505869e-02 6.2921041e-01
  1.5420045e-01 2.1904839e-04 2.9457828e-02 4.9425358e-01 1.8605481e-01]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[1.0253576e-02 1.3075180e-01 5.7482266e-01 6.7359045e-02 1.5899391e-01
  2.2390601e-01 9.7890697e-02 6.2681255e-03 1.2859498e-01 3.4314601e-04]
 [2.8556930e-03 6.2411278e-01 6.4070112e-01 3.4034211e-02 2.6684648e-01
  4.8859417e-02 2.2112578e-03 2.0315725e-01 1.0968258e-01 2.8247829e-04]
 [4.0815558e-02 7.5615031e-01 3.8724628e-01 6.1505869e-02 6.2921041e-01
  1.5420045e-01 2.1904839e-04 2.9457828e-02 4.9425358e-01 1.8605481e-01]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[1.0253576e-02 1.3075180e-01 5.7482266e-01 6.7359045e-02 1.5899391e-01
  2.2390601e-01 9.7890697e-02 6.2681255e-03 1.2859498e-01 3.4314601e-04]
 [2.8556930e-03 6.2411278e-01 6.4070112e-01 3.4034211e-02 2.6684648e-01
  4.8859417e-02 2.2112578e-03 2.0315725e-01 1.0968258e-01 2.8247829e-04]
 [4.0815558e-02 7.5615031e-01 3.8724628e-01 6.1505869e-02 6.2921041e-01
  1.5420045e-01 2.1904839e-04 2.9457828e-02 4.9425358e-01 1.8605481e-01]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
 [0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]], shape=(3, 10), dtype=float32)
========================
tf.Tensor(
[[1.0253576e-02 1.3075180e-01 5.7482266e-01 6.7359045e-02 1.5899391e-01
  2.2390601e-01 9.7890697e-02 6.2681255e-03 1.2859498e-01 3.4314601e-04]
 [2.8556930e-03 6.2411278e-01 6.4070112e-01 3.4034211e-02 2.6684648e-01
  4.8859417e-02 2.2112578e-03 2.0315725e-01 1.0968258e-01 2.8247829e-04]
 [4.0815558e-02 7.5615031e-01 3.8724628e-01 6.1505869e-02 6.2921041e-01
  1.5420045e-01 2.1904839e-04 2.9457828e-02 4.9425358e-01 1.8605481e-01]], shape=(3, 10), dtype=float32)
```


",recently issue issue may running parallel card use memory close issue really hope could indicate source issue wrongdoing user memory growth reproduce code python import import import source destination create node feature size edge feature size collect source aggregate destination multiply source node edge aggregate destination compute edge multiplying source destination node range print print output python binary use available enable following rebuild appropriate compiler warning could find setting environment variable set original value device memory device name bus id compute capability,issue,positive,positive,positive,positive,positive,positive
1736662841,"Hi @frozenbugs , just curious to know whether the team has any concrete plan to support TorchScript with Sparse API? Sparse API works well in my projects, but the lack of TorchScript support is definitely an obstacle to the deployment. Thanks a lot.",hi curious know whether team concrete plan support sparse sparse work well lack support definitely obstacle deployment thanks lot,issue,positive,positive,neutral,neutral,positive,positive
1736450079,"Let's wait for a new release for now. If when we decide to cut a new release of DGL which incorporate this issue, let's depend on the head on the main branch to fix this issue.",let wait new release decide cut new release incorporate issue let depend head main branch fix issue,issue,negative,positive,positive,positive,positive,positive
1736365962,"@Rhett-Ying CCCL finally has a Windows CI, we can either wait for a new release, I don't know when that is though, or we can depend on the current head on the main branch that has Windows CI to fix the windows cuda compilation problems.",finally either wait new release know though depend current head main branch fix compilation,issue,negative,positive,neutral,neutral,positive,positive
1735301279,"Hi @kiymetkaya , we plan to release dgl 2.0 in late this year ~Dec. We don't have plan for minor version yet, but we may do it in Nov if we need major update from dgl's dependency.

Meanwhile, from your log, I think you've successfully build dgl, there are no error but a warning related to our ongoing feature, which can be ignored.",hi plan release late year plan minor version yet may need major update dependency meanwhile log think successfully build error warning related ongoing feature,issue,negative,positive,neutral,neutral,positive,positive
1734722746,"Hi @frozenbugs , I plan to sample neighbors and  construct subgraphs on the CPU servers that make up the Hadoop cluster, and send the subgraphs to the GPU server through network, then train them on the GPU server.

I have read FindHDFS.cmake and I know this error is caused by no finding hdfs.h and libhdfs.so. But currently I just use the GPU server with installed dgl as a client for the hadoop cluster, it accesses hdfs files through a python package (as shown below), and does not install hdfs through source code. 
![image](https://github.com/dmlc/dgl/assets/45582966/214c27b8-903d-4745-aa93-3faa798016e9)

So if I want to use dgl with hdfs, do I have to install hadoop from source on the GPU server and add it as a Datanode to the existing hadoop cluster?",hi plan sample construct make cluster send server network train server read know error finding currently use server client cluster python package shown install source code image want use install source server add cluster,issue,negative,neutral,neutral,neutral,neutral,neutral
1733022297,"Hi @yaox12, @chang-l, can you help on this issue.

It is pretty strange error, effectively the code only moves tensor([0]) to cuda:0.
with `num_worker = 1` in dataloader and `gh = dgl.graph(([1, 2], [1, 2]))`, then something goes run that breaks to cuda:0 operator.

It crashes even I change the code to dgl-unrelated code:
```
t = torch.tensor([[0, 0, 0], [0, 1, 2]])
t.to(device=device)
```",hi help issue pretty strange error effectively code tensor something go run operator even change code code,issue,positive,positive,positive,positive,positive,positive
1732951496,"> Hi @jzhang-github , I was not able to reproduce the issue, can you double check? https://colab.research.google.com/drive/13HhUKqZvdUwOwqjQ0dX_x5RddDWK-PGV#scrollTo=HszKugZRKoUI

Hi @frozenbugs , thank you for your reply. I included `cuda-11.8` libraries into `PATH` and `LD_LIBRARY_PATH` , then the strange disappeared. I guess this issue may be caused by my pure `cuda-12.2 `.",hi able reproduce issue double check hi thank reply included path strange guess issue may pure,issue,negative,positive,positive,positive,positive,positive
1732823606,"Hi @youngeryoungeryang , Can you tell us more about what do you want to achieve so that we can give you better advice?
- Are you plan to run dataloader on your CPU servers and run the training on GPU server?
- Are you plan to run both dataloader and training on one node and fetch feature data from hdfs?
- Are you plan to run dataloader to sample graph topology stored on hdfs and then training on GPU server?
- Or more.",hi tell u want achieve give better advice plan run run training server plan run training one node fetch feature data plan run sample graph topology training server,issue,negative,positive,positive,positive,positive,positive
1732813720,"Hi @jzhang-github , I was not able to reproduce the issue, can you double check?
https://colab.research.google.com/drive/13HhUKqZvdUwOwqjQ0dX_x5RddDWK-PGV#scrollTo=HszKugZRKoUI",hi able reproduce issue double check,issue,negative,positive,positive,positive,positive,positive
1732188303,"BTW, this error will not occur if I use the previous version of dgl. I tried to install **dgl-1.0.2+cu118** on the server which is the installed version on my cooperator's PC, run the code and nothing happened.",error occur use previous version tried install server version run code nothing,issue,negative,negative,negative,negative,negative,negative
1731765217,"I tried to reproduce this regression using initially CPU only configuration on AWS machine (ami: ami-0ff11ac96c22c53a5, type: r6i.32xlarge - 8375C) turning off prefetcher options and then on AWS machine with GPU (ami: ami-0705983c654abda59, type: g4dn.16xlarge - 8259CL) and both attempts failed to show regression. 
![image](https://github.com/dmlc/dgl/assets/59651240/7e2da052-b80b-48b8-b5b3-26539ff094e6)
![image](https://github.com/dmlc/dgl/assets/59651240/bc8f9528-f910-4958-9d4b-4e25a685b2a0)
Are there more configurations that show this performance regression of unfused Neighbor Sampler between version 1.1.1 and 1.1.2?
",tried reproduce regression initially configuration machine ami type turning machine ami type show regression image image show performance regression unfused neighbor sampler version,issue,negative,neutral,neutral,neutral,neutral,neutral
1730535238,"@mfbalin Yes, reverse edges are added for both `ogbnm-mag` and `ogb-lsc-mag240m` in default.",yes reverse added default,issue,negative,neutral,neutral,neutral,neutral,neutral
1729841317,"@Rhett-Ying How many edges does mag240M have? In my experience, making mag240M undirected (1.7B edges -> 3,4B edges) boosts accuracy by more than 10%. I would recommend adding an undirected option to the dataset loader or also saving an undirected version of it.",many experience making undirected accuracy would recommend undirected option loader also saving undirected version,issue,negative,positive,positive,positive,positive,positive
1729277409,"@czkkkkkk , Thanks for reverting back and looking into this issue.

> DGL multi-process fused neighbor sampling is slower than single-process. We found this is because Pytorch limits the threads used by workers if multi-processing is enabled.

- Is there any workaround for this to increase performance? Also if we compare to it's non-fused neighbor sampling(DGL 1.1.1) the performance increase as we scale # workers. 

- Is there any reason why this has changed? It would be great if you can provide me a more detailed explanation, or part of the code in the pytorch dataloader that has changed.

- Until DGL 1.1.1 scaling # workers for CPU based sampling was yielding great performance, I am curious to know why this has been changed by Pytorch's dataloader recently?

> The non-fused neighbor sampling of DGL 1.1.2 is slower than DGL 1.1.1. This could really be a problem. To understand more about this issue, could you help us to profile some data points on direct comparison among these two versions? For example, direct comparison on the same number of workers and batch size.

- I have added a graph in the DGL 1.1.1 section which consists of runtimes for various batch sizes and worker combinations. and in the experiment section I have compared the best case for DGL 1.1.1 with DGL 1.1.2. Attaching the side-side comparison below:

<img width=""400"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/140893310/f4348b00-4eb7-4b6a-a2a6-92c68efa6819"">
<img width=""400"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/140893310/5f37fc7f-87db-4cd3-b59d-5f34d72caf6c"">
<img width=""400"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/140893310/f1dd02c5-3faf-4551-b745-5b820c3f1aee"">
<img width=""400"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/140893310/aea5737b-e9f8-4319-a320-5880ab372b7c"">
<p align=""center"">
<img width=""400"" alt=""image"" align=""center"" src=""https://github.com/dmlc/dgl/assets/140893310/7ddc15d4-7b82-4705-994a-e71547300823"">
</p>

> Fused neighbor sampler is slower than non-fused neighbor sampler in some cases. From your results, we cannot safely draw this conclusion because your are comparing fused sampling of DGL 1.1.2 and non-fused sampling of DGL 1.1.1. Considering the possible performance regression of DGL 1.1.2 in the last point, it is fair if you compare both fused and non-fused sampling on DGL 1.1.2.

- The reason why I showed this comparison is, because as per fused sampling implementation (#5328) since they have merged two operations together. They have claimed and shown experimentally the performances to improve significantly over the non-fused neighbor sampling counterpart. 

- Hence it should have been better than or atleast equal to DGL's 1.1.1 non-fused neighbor sampling, but it seems it has regressed.

Let me know if you have any further questions or need any data.",thanks back looking issue fused neighbor sampling found used increase performance also compare neighbor sampling performance increase scale reason would great provide detailed explanation part code scaling based sampling yielding great performance curious know recently neighbor sampling could really problem understand issue could help u profile data direct comparison among two example direct comparison number batch size added graph section various batch size worker experiment section best case comparison image image image image center image center fused neighbor sampler neighbor sampler safely draw conclusion fused sampling sampling considering possible performance regression last point fair compare fused sampling reason comparison per fused sampling implementation since two together shown experimentally improve significantly neighbor sampling counterpart hence better equal neighbor sampling let know need data,issue,positive,positive,positive,positive,positive,positive
1728892738,@rudongyu please take another round of review.,please take another round review,issue,negative,negative,negative,negative,negative,negative
1728693744,"@UtkrishtP, thanks for your comprehensive study on DGL. Let's discuss the issues one-by-one.
* **DGL multi-process fused neighbor sampling is slower than single-process.** We found this is because Pytorch limits the threads used by workers if multi-processing is enabled.
* **The non-fused neighbor sampling of DGL 1.1.2 is slower than DGL 1.1.1.** This could really be a problem. To understand more about this issue, could you help us to profile some data points on direct comparison among these two versions? For example, direct comparison on the same number of workers and batch size.
* **Fused neighbor sampler is slower than non-fused neighbor sampler in some cases.** From your results, we cannot safely draw this conclusion because your are comparing fused sampling of DGL 1.1.2 and non-fused sampling of DGL 1.1.1. Considering the possible performance regression of DGL 1.1.2 in the last point, it is fair if you compare both fused and non-fused sampling on DGL 1.1.2.",thanks comprehensive study let discus fused neighbor sampling found used neighbor sampling could really problem understand issue could help u profile data direct comparison among two example direct comparison number batch size fused neighbor sampler neighbor sampler safely draw conclusion fused sampling sampling considering possible performance regression last point fair compare fused sampling,issue,positive,positive,positive,positive,positive,positive
1728645466,"> @rudongyu Fixed the problem in the code you mentioned, please help me to review it

I'm good with the other parts except that a dataset index item is required in docs/source/api/python/dgl.data.rst. You can proceed to merge this pr after adding that. Thanks for your work!",fixed problem code please help review good except index item proceed merge thanks work,issue,positive,positive,positive,positive,positive,positive
1728635721,We cannot see the code. Looks like it is not an official DGL code. Could you provide a minimal script that can reproduce this problem?,see code like official code could provide minimal script reproduce problem,issue,negative,negative,neutral,neutral,negative,negative
1727778614,"I just reinstalled everything and it's now working. Trust me, I tried this several times before. Thanks for your help.",everything working trust tried several time thanks help,issue,positive,positive,neutral,neutral,positive,positive
1726790063,"@peizhou001 when working with callbacks and validation accuracies, we gotta pass `mode=""max""`, otherwise it looks at the worst validation accuracy. Made the last-minute commits to fix that. I had made the same mistake before when working on the labor lightning example. I guess the remaining thing to do is to implement the inference and saved model loading for this example.",working validation got ta pas otherwise worst validation accuracy made fix made mistake working labor lightning example guess thing implement inference saved model loading example,issue,negative,negative,negative,negative,negative,negative
1726789665,"@rudongyu Fixed the problem in the code you mentioned, please help me to review it",fixed problem code please help review,issue,negative,positive,neutral,neutral,positive,positive
1726754022,"@frozenbugs @peizhou001 I prefer to make this example runnable first even with limited options. we could add more options step by step such as `drop_last`, `gpu` and so on.",prefer make example runnable first even limited could add step step,issue,negative,positive,neutral,neutral,positive,positive
1724821887,"Codes: https://github.com/QueuQ

 python train.py --dataset Reddit-CL \
       --backbone GAT \
       --gpu 0 \
       --epochs 200 \
       --sample_nbs False \
       --minibatch True \
       --batch_size 2000 \
       --repeats 5 \
       --ratio_valid_test 0.1 0.3 \
       --overwrite_result False \
       --perform_testing True",python backbone gat false true false true,issue,positive,negative,neutral,neutral,negative,negative
1724810138,"Hi @jayurbain, I follow your steps but can't reproduce in my PC
<img width=""467"" alt=""138d81ba68ef72824782d3060615394"" src=""https://github.com/dmlc/dgl/assets/110809584/07f5ab61-c039-452d-b239-9da5864ac77a"">
Looks your dgl version is without cuda support,  one possible reason is you have both conda and pip envrionment,  so the version maybe confused. Could you try to check your package path? If not solved, please consider uninstall dgl and then reinstall.",hi follow ca reproduce version without support one possible reason pip version maybe confused could try check package path please consider reinstall,issue,negative,negative,negative,negative,negative,negative
1724768860,It might be hard for us to look into this code. Could you provide a minimal script that can reproduce this problem?,might hard u look code could provide minimal script reproduce problem,issue,negative,negative,negative,negative,negative,negative
1724759162,"@ZionDoki, thanks for reporting this issue! We will fix it soon.",thanks issue fix soon,issue,negative,positive,positive,positive,positive,positive
1724259622,This bug does not happen when running on CPU but only for GPUs. It is very weird. @czkkkkkk ,bug happen running weird,issue,negative,negative,negative,negative,negative,negative
1722794802,"Hi @WMX567, seems the size of your node features of the last GAT layer does not match the number of nodes. You can try to print out their shapes during training to figure out which of them is unexpected.",hi size node last gat layer match number try print training figure unexpected,issue,negative,positive,neutral,neutral,positive,positive
1722552872,"@Rsalganik1123 if you want a layer sampling method, feel free to check out the already available Layer-Neighbor Sampler: https://docs.dgl.ai/en/latest/generated/dgl.dataloading.LaborSampler.html.",want layer sampling method feel free check already available sampler,issue,positive,positive,positive,positive,positive,positive
1720437671,"There are many places are using this extract_archive, for those didn't specify the overwrite, please double check whether it is safe to the change.
```
python/dgl/data/knowledge_graph.py:    extract_archive,
python/dgl/data/knowledge_graph.py:        extract_archive(tgz_path, self.raw_path)
python/dgl/data/movielens.py:    extract_archive,
python/dgl/data/movielens.py:        extract_archive(zip_file_path, self.raw_dir, overwrite=True)
python/dgl/data/qm9_edge.py:from .utils import _get_dgl_url, download, extract_archive
python/dgl/data/gindt.py:    extract_archive,
python/dgl/data/gindt.py:        extract_archive(zip_file_path, self.raw_path)
python/dgl/data/utils.py:    ""extract_archive"",
python/dgl/data/utils.py:def extract_archive(file, target_dir, overwrite=False):
python/dgl/data/dgl_dataset.py:from .utils import download, extract_archive, get_download_dir, makedirs
python/dgl/data/dgl_dataset.py:            extract_archive(zip_file_path, self.raw_path)
(dgl-dev-gpu-117) ubuntu@ip-172-31-28-63:~/github/dgl$ grep extract_archive -r examples/
examples/pytorch/gcmc/data.py:from dgl.data.utils import download, extract_archive, get_download_dir
examples/pytorch/gcmc/data.py:        extract_archive(zip_file_path, ""{}/{}"".format(download_dir, name))
examples/pytorch/ggnn/data_utils.py:    extract_archive,
examples/pytorch/ggnn/data_utils.py:        extract_archive(zip_file_path, extract_dir)
examples/pytorch/transformer/dataset/utils.py:        extract_archive(""scripts.zip"", ""scripts"")
examples/pytorch/jtnn/jtnn/datautils.py:    extract_archive,
examples/pytorch/jtnn/jtnn/datautils.py:        extract_archive(self.zip_file_path, ""{}/jtnn"".format(self.dir))
examples/pytorch/ogb/line/reading_data.py:    extract_archive,
examples/pytorch/ogb/line/reading_data.py:        extract_archive(zip_file_path, ""{}/{}"".format(dir, name))
Binary file examples/pytorch/ogb/deepwalk/__pycache__/reading_data.cpython-37.pyc matches
examples/pytorch/ogb/deepwalk/reading_data.py:    extract_archive,
examples/pytorch/ogb/deepwalk/reading_data.py:        extract_archive(zip_file_path, ""{}/{}"".format(dir, name))
(dgl-dev-gpu-117) ubuntu@ip-172-31-28-63:~/github/dgl$ grep extract_archive -r tests/
tests/python/common/data/test_utils.py:def test_extract_archive():
tests/python/common/data/test_utils.py:            data.utils.extract_archive(gz_path, dst_dir, overwrite=True)
tests/python/common/data/test_utils.py:            data.utils.extract_archive(tar_path, dst_dir, overwrite=True)
tests/python/common/data/test_utils.py:    test_extract_archive()
Binary file tests/python/common/data/__pycache__/test_data.cpython-37-pytest-7.2.1.pyc matches
Binary file tests/python/common/data/__pycache__/test_utils.cpython-37-pytest-7.2.1.pyc matches
tests/python/common/data/test_data.py:def test_extract_archive():
tests/python/common/data/test_data.py:            data.utils.extract_archive(gz_path, dst_dir, overwrite=True)
tests/python/common/data/test_data.py:            data.utils.extract_archive(tar_path, dst_dir, overwrite=True)
```",many specify overwrite please double check whether safe change import file import import name name binary file name binary file binary file,issue,positive,positive,positive,positive,positive,positive
1719089315,"Enable the function: Add an option compare, which can compare the performance of a certain branch with the performance of master branch.",enable function add option compare compare performance certain branch performance master branch,issue,negative,positive,positive,positive,positive,positive
1719064802,"@anko-intel Sure here is the output:

```
Architecture:                    x86_64
CPU op-mode(s):                  32-bit, 64-bit
Byte Order:                      Little Endian
Address sizes:                   46 bits physical, 48 bits virtual
CPU(s):                          128
On-line CPU(s) list:             0-127
Thread(s) per core:              2
Core(s) per socket:              16
Socket(s):                       4
NUMA node(s):                    4
Vendor ID:                       GenuineIntel
CPU family:                      6
Model:                           85
Model name:                      Intel(R) Xeon(R) Gold 6242 CPU @ 2.80GHz
Stepping:                        7
CPU MHz:                         1201.461
CPU max MHz:                     3900.0000
CPU min MHz:                     1200.0000
BogoMIPS:                        5600.00
Virtualization:                  VT-x
L1d cache:                       2 MiB
L1i cache:                       2 MiB
L2 cache:                        64 MiB
L3 cache:                        88 MiB
NUMA node0 CPU(s):               0-15,64-79
NUMA node1 CPU(s):               16-31,80-95
NUMA node2 CPU(s):               32-47,96-111
NUMA node3 CPU(s):               48-63,112-127
```",sure output architecture order little address size physical virtual list thread per core core per socket socket node vendor id family model model name gold stepping min cache mib li cache mib cache mib cache mib node node node node,issue,negative,positive,positive,positive,positive,positive
1719029956,"@UtkrishtP could you also provide ""model name"" from  lscpu?",could also provide model name,issue,negative,neutral,neutral,neutral,neutral,neutral
1718632656,"@ndbaker1 thanks for letting us know, yes, something wrong with the CI, we will take a look at it, and I will handle the merge of the PR.",thanks u know yes something wrong take look handle merge,issue,negative,negative,negative,negative,negative,negative
1715182879,@ndbaker1 it seems I can not edit your PR directly so you have to handle the nit comment by yourself.,edit directly handle nit comment,issue,negative,positive,neutral,neutral,positive,positive
1712987193,@jermainewang would you see if this branch can be merged? Dont want this branch to go too out of sync from the master,would see branch dont want branch go sync master,issue,negative,neutral,neutral,neutral,neutral,neutral
1712702481,"@Rhett-Ying Thanks for your kind reply.
The test cases are updated. Test result is as follows:
```sh
......
----------------------------------------------------------------------
Ran 6 tests in 0.000s

OK
```
In addition to the above unit test, I have confirmed that the changes work well with the [official distributed GraphSAGE training example](https://github.com/dmlc/dgl/blob/master/examples/distributed/graphsage/node_classification.py).",thanks kind reply test test result sh ran addition unit test confirmed work well official distributed training example,issue,positive,positive,positive,positive,positive,positive
1712689096,please update test cases like https://github.com/dmlc/dgl/blob/ce8a7dd314df9dd89964604571e5eeebc7009726/tests/tools/test_launch.py#L24,please update test like,issue,positive,neutral,neutral,neutral,neutral,neutral
1712688877,@9rum Thanks for filing this PR. have your verified in your local?,rum thanks filing local,issue,negative,positive,neutral,neutral,positive,positive
1712583390,@Rhett-Ying I kindly ask to review this pull request.,kindly ask review pull request,issue,negative,positive,positive,positive,positive,positive
1711209616,"> Regarding this change, I wonder if it's a chance to switch to CMake 3.8+, list CUDA among the languages supported, and then add CUDA (.cu) sources directly to targets similar to other languages, since the current way to enable CUDA, i.e., `FindCUDA`, is deprecated. Reference: https://cmake.org/cmake/help/latest/module/FindCUDA.html

Right. We should deprecate FindCUDA since it is deprecated from CMAKE 3.10. But I am not familiar with the new cmake syntax. @yaox12 Could you help to make such a change after this PR?",regarding change wonder chance switch list among add directly similar since current way enable reference right deprecate since familiar new syntax could help make change,issue,positive,positive,positive,positive,positive,positive
1711143917,"Regarding this change, I wonder if it's a chance to switch to CMake 3.8+, list CUDA among the languages supported, and then add CUDA (.cu) sources directly to targets similar to other languages, since the current way to enable CUDA, i.e., `FindCUDA`, is deprecated.  
Reference: https://cmake.org/cmake/help/latest/module/FindCUDA.html",regarding change wonder chance switch list among add directly similar since current way enable reference,issue,negative,neutral,neutral,neutral,neutral,neutral
1711117006,"Currently, I have enable the function: For the one-of job, the email should send to the runner. For daily run, it can be send to all of the dgl group members.",currently enable function job send runner daily run send group,issue,negative,neutral,neutral,neutral,neutral,neutral
1709786941,"@chwan1016 thanks for catching it, cora is a pretty small graph so it is very sensitive to small changes, this example is an example that demonstrate the usability of DGL so we did not keep an eye on the acc of the model.

Do you happen to know why the accuracy is dropped?
If not, let's change the README to Cora: ~0.75 to avoid confusion in the future.",thanks catching cora pretty small graph sensitive small example example demonstrate usability keep eye model happen know accuracy let change cora avoid confusion future,issue,negative,positive,neutral,neutral,positive,positive
1709779807,"@drivanov I appreciate your work on this. However, we do not yet have plans to support csc_sampling_graph on GPU, so we would prefer not to enable the test at this time, as it would complicate the CI process.",appreciate work however yet support would prefer enable test time would complicate process,issue,positive,neutral,neutral,neutral,neutral,neutral
1709599827,"LGTM, please address the conflict, and I will double check for you.",please address conflict double check,issue,negative,neutral,neutral,neutral,neutral,neutral
1709401181,"Hi, @yurivict. Sorry, we are unable to replicate the issue you've reported and consequently cannot proceed with a resolution. Any assistance or insights from the community would be highly appreciated. Furthermore, potential confirmation of whether this issue pertains to FreeBSD would be immensely helpful. Thanks for your understanding.",hi sorry unable replicate issue consequently proceed resolution assistance community would highly furthermore potential confirmation whether issue would immensely helpful thanks understanding,issue,positive,negative,negative,negative,negative,negative
1709393057,"Hi, currently there are no examples in exactly the same scenario in DGL. You may iterate over graphs like in graph classification, but change the training objective to that in link prediction. Hope this helps.",hi currently exactly scenario may iterate like graph classification change training objective link prediction hope,issue,positive,positive,positive,positive,positive,positive
1709032279,"Hi, there is a step-to-step guide on this page for installing from source: https://docs.dgl.ai/en/0.9.x/install/index.html.
Could you elaborate on more specific difficulties you have encountered? (e.g., error messages)",hi guide page source could elaborate specific error,issue,negative,positive,positive,positive,positive,positive
1708835729,"@Abigale001 Sorry, it was a long time ago and I couldn't remember whether I solved this problem.",sorry long time ago could remember whether problem,issue,negative,negative,negative,negative,negative,negative
1707136770,"It looks like the real reason for the failed tests that I couldn't reproduce in my Linux environment was some kind of multithreading bug that shows up only on Windows. I did make some changes and we will see if them will fix that problem. 
",like real reason could reproduce environment kind bug make see fix problem,issue,negative,positive,positive,positive,positive,positive
1706237907,Yeah. Specifically ask it to polish your documentation.,yeah specifically ask polish documentation,issue,negative,neutral,neutral,neutral,neutral,neutral
1706230639,"> Did you try chatgpt to polish the documentation?

Well, I pick answers from it. Maybe my prompts are not specific.",try polish documentation well pick maybe specific,issue,negative,neutral,neutral,neutral,neutral,neutral
1705993875,"> The GraphGPS model code is here: https://github.com/paoxiaode/GraphGPS_DGL

Thank you very much for your sharing",model code thank much,issue,negative,positive,positive,positive,positive,positive
1705898724,"We have implemented GraphGPS model under DGL based on the official GraphGPS code, but the code is not yet publicly available and needs a few days to be organized, I'll let you know when the code becomes public.",model based official code code yet publicly available need day organized let know code becomes public,issue,negative,positive,positive,positive,positive,positive
1705799060,"> > Overall the example is in a good shape now. Let's wait for the final clean up of the graphbolt UX, and have this example merged.
> 
> Perhaps it would be better for me to put the contents of the README in the **description** of this PR? Because we will provide official channels in the future? Then this README is no longer needed.

We still need README, and it is better to describe the data structure of the example. Let's discuss offline to clarify what needs to be included in README.",overall example good shape let wait final clean example perhaps would better put content description provide official future longer still need better describe data structure example let discus clarify need included,issue,positive,positive,positive,positive,positive,positive
1705372556,"> Overall the example is in a good shape now. Let's wait for the final clean up of the graphbolt UX, and have this example merged.

Perhaps it would be better for me to put the contents of the README in the **description** of this PR? Because we will provide official channels in the future? Then this README is no longer needed.",overall example good shape let wait final clean example perhaps would better put content description provide official future longer,issue,positive,positive,positive,positive,positive,positive
1705172890,"@frozenbugs, absolutely. Will make another PR to improve the documentation/code of the link prediction tutorials if need be.",absolutely make another improve link prediction need,issue,negative,positive,positive,positive,positive,positive
1704895680,"Overall the example is in a good shape now. Let's wait for the final clean up of the graphbolt UX, and have this example merged.",overall example good shape let wait final clean example,issue,positive,positive,positive,positive,positive,positive
1704571157,@frozenbugs @peizhou001 pls help review the naming proposal: https://quip-amazon.com/g3XcAzBaXBN1/Unify-MiniBatch-keywords-in-GraphBolt.,help review naming proposal,issue,negative,neutral,neutral,neutral,neutral,neutral
1703277241,:tada: Awesome! I am really excited for the next dgl release ,awesome really excited next release,issue,positive,positive,positive,positive,positive,positive
1702363725,"hi I have the same problem, how do you solve it finally?

Downloading /home8t/zzy_8t/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...
download failed, retrying, 4 attempts left
Downloading /home8t/zzy_8t/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...
download failed, retrying, 3 attempts left
Downloading /home8t/zzy_8t/.dgl/cora_v2.zip from https://data.dgl.ai/dataset/cora_v2.zip...",hi problem solve finally left left,issue,negative,neutral,neutral,neutral,neutral,neutral
1702261111,"> If we want to perform such a check, it can happen inside of the num_pick_fn function. We already go over the weights to check how many are positive there.

@mfbalin We decided to put it in the offline script.

",want perform check happen inside function already go check many positive decided put script,issue,positive,positive,positive,positive,positive,positive
1702254226,"Also, not only the Labor branch, but also the neighbor branch is affected by this change.",also labor branch also neighbor branch affected change,issue,negative,neutral,neutral,neutral,neutral,neutral
1701908514,"Thanks so much for the fix @anko-intel, much appreciated. :) ",thanks much fix much,issue,negative,positive,positive,positive,positive,positive
1701754165,@hmacdope can you make that change when you get a chance? I don't have write permission on your fork,make change get chance write permission fork,issue,negative,neutral,neutral,neutral,neutral,neutral
1701751819,"I would create a new conda environment (with pip and python), activate it, then run `pip install dgl -f https://data.dgl.ai/wheels/repo.html` which should pull in a new wheel that the dgl team built. `conda install -c conda-forge dgl` will not work on a osx-arm64 mac without using emulation (at least for now). ",would create new environment pip python activate run pip install pull new wheel team built install work mac without emulation least,issue,negative,negative,neutral,neutral,negative,negative
1701549854,"Oh, sweet! Thanks!
So, if I understand correctly, I should `pip uninstall dgl` and then `conda install -c conda-forge dgl`?
Please, confirm.",oh sweet thanks understand correctly pip install please confirm,issue,positive,positive,positive,positive,positive,positive
1701477542,"Regression testing for all branches of code is needed. Layer=True,False Replace=True,False NonUniform=True,False.",regression testing code false false false,issue,negative,negative,negative,negative,negative,negative
1700988444,"> Possibly related to using / not using `-D_BLAS=0` https://libxsmm.readthedocs.io/en/latest/#link-instructions

You are right, according to https://github.com/libxsmm/libxsmm#header-only you have to define __BLAS=0
so, adding it to lines [217-221](https://github.com/dmlc/dgl/pull/6189/files#diff-1e7de1ae2d059d21e1dd75d5812d5a34b0222cef273b7c3a2af62eb747f9d20aR217):
```
if(USE_LIBXSMM)
  set(CMAKE_C_FLAGS ""${CMAKE_C_FLAGS} -DUSE_LIBXSMM -DDGL_CPU_LLC_SIZE=40000000 -D__BLAS=0"")
  set(CMAKE_CXX_FLAGS ""${CMAKE_CXX_FLAGS} -DUSE_LIBXSMM -DDGL_CPU_LLC_SIZE=40000000 -D__BLAS=0"")
  message(STATUS ""Build with LIBXSMM optimization."")
endif(USE_LIBXSMM)
```
seems to be enough ",possibly related right according define set set message status build optimization enough,issue,negative,positive,neutral,neutral,positive,positive
1700745881,"Tried to debug with `compute-sanitizer`. It seems to be caused by `cusparseSpMM`. But I'm not sure of the root cause yet. cc @chang-l @nv-dlasalle in case you have any clues.

Log file: [log_neighbor.txt](https://github.com/dmlc/dgl/files/12485003/log_neighbor.txt)
",tried sure root cause yet case log file,issue,negative,positive,positive,positive,positive,positive
1700712245," @frozenbugs Yes please, I can't figure out exactly why some builds are missing the symbols. Any ideas?",yes please ca figure exactly missing,issue,negative,negative,negative,negative,negative,negative
1700510418,"> Passing `--sampler=neighbor` makes it crash even earlier to the end of the command above.

Yes, I tried and crashed too.",passing crash even end command yes tried,issue,negative,neutral,neutral,neutral,neutral,neutral
1700481539,"Hi @hmacdope, are you still working on resolving this issue? Let us know if you need any help from us. Thanks!",hi still working issue let u know need help u thanks,issue,positive,positive,positive,positive,positive,positive
1700474926,"> Cannot reproduce the issue. In terms of PDF documentation, I agree there are merits in releasing a downloadable version. However, there are a couple of technical difficulties in this:
> 
> 1. The current API doc uses various plugins to properly render math, codes and links. Many of them will be broken when converted to PDF.
> 2. We are still actively updating our document to fix inaccurate or mistaken information. I think keeping our document up-to-date is still more important at the current stage of the project.
> 
> That is said, if we received more and more report of connection issue, we will try our best to resolve that directly. So, if you could share more details such as your IP location, the period of time that you encounter connection issues, etc., these will be really helpful.

I am now able to access the document page normally after clearing the DNS cache of my local host. Thank you.",reproduce issue documentation agree version however couple technical current doc various properly render math link many broken converted still actively document fix inaccurate mistaken information think keeping document still important current stage project said received report connection issue try best resolve directly could share location period time encounter connection really helpful able access document page normally clearing cache local host thank,issue,positive,positive,positive,positive,positive,positive
1700434732,"@yaox12 @TristonC this might related Pytorch / CUDA memory management, can you help us take a look?",might related memory management help u take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1700429371,Passing `--sampler=neighbor` makes it crash even earlier to the end of the command above.,passing crash even end command,issue,negative,neutral,neutral,neutral,neutral,neutral
1700425068,@mfbalin is this reproducible with neighbor sampling? or just labor samping?,reproducible neighbor sampling labor,issue,negative,neutral,neutral,neutral,neutral,neutral
1700270805,We have stopped supporting 0.4.3.  Could you check out [this function](https://docs.dgl.ai/generated/dgl.sampling.random_walk.html#dgl.sampling.random_walk) that also has restart probability support?,stopped supporting could check function also restart probability support,issue,positive,positive,positive,positive,positive,positive
1700259475,Currently has a workaround using environment variable. See https://github.com/dmlc/dgl/pull/6148#issuecomment-1692713327 for details.,currently environment variable see,issue,negative,neutral,neutral,neutral,neutral,neutral
1700247293,We have released a patch version 1.1.2post1 for Mac M1 to support PyTorch 2.0.1.  @Atcold ,patch version post mac support,issue,negative,neutral,neutral,neutral,neutral,neutral
1699576594,"Unfortunately, I can't reproduce these issues in the latest version of the NVidia container. Looks like `torch\utils\data\dataloader.py` has been updated and we are still using the old version. Let's wait until we start using the new version of this file. I changed the status of the current PR to ""Draft"".",unfortunately ca reproduce latest version container like still old version let wait start new version file status current draft,issue,negative,positive,neutral,neutral,positive,positive
1699490690,The `HeteroNodeDataView` is a dictionary-like class so it supports all the methods a python dictionary has. I do agree that the type name itself is not straightforward. The ideal case is just return a python dict so such confusion naturally goes away. This will require some deep refactor of `DGLGraph`. I've marked this as a feature request.,class python dictionary agree type name straightforward ideal case return python confusion naturally go away require deep marked feature request,issue,positive,positive,positive,positive,positive,positive
1699478124,"For general questions, I suggest posting them to our discuss forum (discuss.dgl.ai) to keep the issue tracker cleaner. Thanks!

Have you checked our tutorial/doc on neighbor sampling on heterogeneous graph? Also, the official example [here](https://github.com/dmlc/dgl/blob/master/examples/core/rgcn/hetero_rgcn.py) is also using neighbor sampling on heterogeneous graph.",general suggest posting discus forum keep issue tracker cleaner thanks checked neighbor sampling heterogeneous graph also official example also neighbor sampling heterogeneous graph,issue,positive,positive,positive,positive,positive,positive
1699462314,"Cannot reproduce the issue. In terms of PDF documentation, I agree there are merits in releasing a downloadable version. However, there are a couple of technical difficulties in this:

1. The current API doc uses various plugins to properly render math, codes and links. Many of them will be broken when converted to PDF.
2. We are still actively updating our document to fix inaccurate or mistaken information. I think keeping our document up-to-date is still more important at the current stage of the project.

That is said, if we received more and more report of connection issue, we will try our best to resolve that directly. So, if you could share more details such as your IP location, the period of time that you encounter connection issues, etc., these will be really helpful.",reproduce issue documentation agree version however couple technical current doc various properly render math link many broken converted still actively document fix inaccurate mistaken information think keeping document still important current stage project said received report connection issue try best resolve directly could share location period time encounter connection really helpful,issue,positive,positive,positive,positive,positive,positive
1698717114,"@peizhou001 I did a simple test. I combined different fanouts and replace settings together and measured the total time.
```cpp
n = 1000000;
probs = torch::rand({n}, torch::kDouble);
for (int i = 1; i <= 1000; ++ i) {
    fanout = i * 1000;
    replace = (i & 1) > 0;
    Sample(0, n, fanout, replace, probs, ...); // Replace Sample function with different implementations.
}
```

Results are:
- `torch::multinomial`: 96573.2ms
- `std::memcpy(torch::multinomial)`: 98845.2ms
- My code: 74089.2ms

So I think the gain not only comes from the elimination of `std::memcpy`. ",simple test combined different replace together measured total time torch torch replace sample replace replace sample function different torch torch code think gain come elimination,issue,positive,neutral,neutral,neutral,neutral,neutral
1698574290,"> Why is the dependency on PyTorch's version so strict?
> I'm considering using this library in my book, but I'm afraid the readers may not be able to hack stuff to make it work.
> Is there a safe way to handle this?

Hi @Atcold , one reason is because the DGL sparse library is a PyTorch extension library which depends on its ABI. In the past, we found that newer PyTorch may break backward compatibility (also see the open issue here https://github.com/pytorch/pytorch/issues/28754). Therefore, as a workaround, DGL will build one extension library for each supported PyTorch version, and the matching is strict.",dependency version strict considering library book afraid may able hack stuff make work safe way handle hi one reason sparse library extension library past found may break backward compatibility also see open issue therefore build one extension library version matching strict,issue,negative,positive,neutral,neutral,positive,positive
1698427516,"> @peizhou001 I've run some tests locally and the it seems to be correct (the output distributions of these two are the same). Plus, this is not actually a rewriting of algorithm. All the checks, if-conditions, algorithms and the binary search are the same as the internal implementation of `ATen`. I only did some simplification and removed some useless instructions.

Got it, but also we first need to know if the slowdown comes from `memcpy`.",run locally correct output two plus actually algorithm binary search internal implementation simplification removed useless got also first need know slowdown come,issue,negative,negative,neutral,neutral,negative,negative
1698338349,"> Commit ID: [2b5dbcb](https://github.com/dmlc/dgl/commit/2b5dbcb55d40f57a3dc7e46d3d54f7ebbcbdbdbd)
> 
> Build ID: 10
> 
> Status: âŒ CI test failed in Stage [Torch CPU (Win64) Unit test].
> 
> Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6194/10/10/logs/report.html)
> 
> Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6194/10/10/logs/cireport.log)

pls address this.
",commit id build id status test stage torch win unit test report path link full path link address,issue,positive,positive,positive,positive,positive,positive
1696905339,"@frozenbugs CI told me ""Unused argument 'dim' (unused-argument)"", I wonder how to pass it without changing API. ",told unused argument wonder pas without,issue,negative,neutral,neutral,neutral,neutral,neutral
1696814067,Please add unit test in this PR or a follow PR if we need to get it merged for example first.,please add unit test follow need get example first,issue,negative,positive,positive,positive,positive,positive
1696790005,"> @frozenbugs @Rhett-Ying @peizhou001 Can a significant portion of edge weights be zero? Should I optimize considering this case as well in the future? Will users use edge weights to separate train, validation or test edges etc. by setting a lot of edge weights to 0?

It is hard to predict how users will use the edge weight in a very specific way, but we usually only optimize for common usage, if a user pattern become a common pattern, we can always optimize it later.",significant portion edge zero optimize considering case well future use edge separate train validation test setting lot edge hard predict use edge weight specific way usually optimize common usage user pattern become common pattern always optimize later,issue,positive,negative,neutral,neutral,negative,negative
1696747438,"@peizhou001 I've run some tests locally and the it seems to be correct (the output distributions of these two are the same).
Plus, this is not actually a rewriting of algorithm. All the checks, if-conditions, algorithms and the binary search are the same as the internal implementation of `ATen`. I only did some simplification and removed some useless instructions.",run locally correct output two plus actually algorithm binary search internal implementation simplification removed useless,issue,negative,negative,negative,negative,negative,negative
1696685233,"Is there a separate single test against` torch::multinomial` and the new algorithm?

I doubt if the gains comes from the saving of `memcpy`, if that is the case, we need to avoid the copy instead of rewrite the algorithm.",separate single test torch new algorithm doubt gain come saving case need avoid copy instead rewrite algorithm,issue,negative,positive,neutral,neutral,positive,positive
1696337275,"So with the conda-forge build things are setup in a way to keep that in sync. The `dgl` team is doing an awesome thing where they build a large matrix of different CPU architectures, cuda  architectures/versions, and pytorch versions. One portion of that which is a little brittle is the way that `libdgl_sparse_pytorch_*` is shipped. From 

```
-rwxr-xr-x 1 atcold admin 888543 Aug 28 15:17 libdgl_sparse_pytorch_1.13.0.dylib
-rwxr-xr-x 1 atcold admin 888543 Aug 28 15:17 libdgl_sparse_pytorch_1.13.1.dylib
-rwxr-xr-x 1 atcold admin 890814 Aug 28 15:17 libdgl_sparse_pytorch_2.0.0.dylib
```

We can see that they build `libdgl_sparse` against 3 different pytorch versions. 

When packaging up software, it is a very hard problem :tm: to try and anticipate how dependencies can change. I am guessing that 2.0.1 of torch didn't exist when the wheel was built, so they couldn't link/build against it.

> Why is the dependency on PyTorch's version so strict?

`dgl` and `dgl_sparce` link against it, so as long as the ABI doesn't change then things _should_ be okay, but that is tricky when you don't control all the different ways a user can download/install software. 

> I'm considering using this library in my book, but I'm afraid the readers may not be able to hack stuff to make it work.
Is there a safe way to handle this?

I would recommend looking at https://conda.github.io/conda-lock/ so that you can specify the software requirements for different chapters/the book in a way that is reproducible. ",build setup way keep sync team awesome thing build large matrix different one portion little brittle way shipped see build different hard problem try anticipate change guessing torch exist wheel built could dependency version strict link long change tricky control different way user considering library book afraid may able hack stuff make work safe way handle would recommend looking specify different book way reproducible,issue,positive,positive,neutral,neutral,positive,positive
1696306376,"Cool, I've symlink'ed it. Thanks!

Why is the dependency on PyTorch's version so strict?
I'm considering using this library in my book, but I'm afraid the readers may not be able to hack stuff to make it work.
Is there a safe way to handle this?",cool thanks dependency version strict considering library book afraid may able hack stuff make work safe way handle,issue,positive,positive,positive,positive,positive,positive
1696297193,"So you might be able to fix this bye installing pytorch 2.0.0 so that then the dynamic lib loader works. If there isn't an ABI issue, rename the file:

```
cd /opt/homebrew/Caskroom/miniconda/base/envs/book/lib/python3.10/site-packages/dgl/dgl_sparse/
cp libdgl_sparse_pytorch_2.0.0.dylib libdgl_sparse_pytorch_2.0.1.dylib
```

and that will make things happy, but could cause an issue if the symbols are different. ",might able fix bye dynamic loader work issue rename file make happy could cause issue different,issue,positive,positive,positive,positive,positive,positive
1696289220,"Sorry to be responding on both threads :upside_down_face: 

""better solution"" is a relative term. If you want to play around with `dgl`, I think pulling from conda-forge with some emulation should be fine, and then you can source other packages from conda-forge and everything should be fine ABI wise. 

Emulation will be slower than native, but I image that when performance really matters, you will be running something on a linux HPC or workstation that has a CUDA gpu or something.   ",sorry better solution relative term want play around think emulation fine source everything fine wise emulation native image performance really running something something,issue,positive,positive,positive,positive,positive,positive
1696267291,"I see, thanks! This is the output.
```
$ ls -l /opt/homebrew/Caskroom/miniconda/base/envs/book/lib/python3.10/site-packages/dgl/dgl_sparse/
total 2608
-rwxr-xr-x 1 atcold admin 888543 Aug 28 15:17 libdgl_sparse_pytorch_1.13.0.dylib
-rwxr-xr-x 1 atcold admin 888543 Aug 28 15:17 libdgl_sparse_pytorch_1.13.1.dylib
-rwxr-xr-x 1 atcold admin 890814 Aug 28 15:17 libdgl_sparse_pytorch_2.0.0.dylib

$ python -c 'import torch; print(torch.__version__.split(""+"", maxsplit=1)[0])'
2.0.1
```",see thanks output total python torch print,issue,negative,positive,neutral,neutral,positive,positive
1696265418,"@Atcold That kind of error comes from when the version of pytorch doesn't match the `libdgl_sparse` library that get shipped. Try running `ls -l /opt/homebrew/Caskroom/miniconda/base/envs/book/lib/python3.10/site-packages/dgl/dgl_sparse/` and `python -c 'import torch; print(torch.__version__.split(""+"", maxsplit=1)[0])'` ",kind error come version match library get shipped try running python torch print,issue,negative,positive,positive,positive,positive,positive
1696265242,"Oh, so this would be an even better solution, correct?
Unfortunately it `Cannot find DGL C++ sparse library`.",oh would even better solution correct unfortunately find sparse library,issue,negative,neutral,neutral,neutral,neutral,neutral
1696261627,I believe installing the wheel from the repo like that does not use emulation since there are wheels listed like this [dgl-1.1.2-cp39-cp39-macosx_11_0_arm64.whl](https://data.dgl.ai/wheels/dgl-1.1.2-cp39-cp39-macosx_11_0_arm64.whl) which implies arm64 native builds. ,believe wheel like use emulation since listed like arm native,issue,positive,neutral,neutral,neutral,neutral,neutral
1696259853,"Oh, something went wrong.
```
FileNotFoundError: Cannot find DGL C++ sparse library at /opt/homebrew/Caskroom/miniconda/base/envs/book/lib/python3.10/site-packages/dgl/dgl_sparse/libdgl_sparse_pytorch_2.0.1.dylib
```",oh something went wrong find sparse library,issue,negative,negative,negative,negative,negative,negative
1696247794,"Oh, I see! Thanks!

I followed [these](https://github.com/dmlc/dgl/issues/4344#issuecomment-1696242263) instructions and I got a working environment.
Is my installation using Rosetta 2 emulation as well?",oh see thanks got working environment installation emulation well,issue,positive,positive,positive,positive,positive,positive
1696245326,"@Atcold It looks like you are on `osx-arm64`. It is on my to-do list but since conda-forge doesn't have a way to natively build on `osx-arm64` it has to be cross compiled which I am not sure if the current CMake setup is configured to handle that. 


If you want to give this a spin on a M1/M2 mac, you can do this:

```
CONDA_SUBDIR=osx-64 conda create --name dgl-conda-forge -c conda-forge
conda activate dgl-conda-forge
conda config --env --set subdir osx-64
```

That will create a conda env using apple's Rosetta 2 emulation for x86-64. ",like list since way natively build cross sure current setup handle want give spin mac create name activate set create apple emulation,issue,positive,positive,positive,positive,positive,positive
1696242263,"> Could you try
> 
> ```
> pip install dgl -f https://data.dgl.ai/wheels/repo.html
> ```
> 
> If the above doesn't work, could you try downloading the `macosx_11_0_arm64` wheel with the appropriate Python version from https://data.dgl.ai/wheels/repo.html and install it locally?

This works! Can we have it work automatically through a `conda install`?
Thanks!

Keep in mind that the website says nothing about the default installation being incompatible with Mac.",could try pip install work could try wheel appropriate python version install locally work work automatically install thanks keep mind nothing default installation incompatible mac,issue,negative,positive,positive,positive,positive,positive
1696234090,"I tried to install it. It does not work.
```
$ conda install -c conda-forge dgl
Collecting package metadata (current_repodata.json): done
Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.
Collecting package metadata (repodata.json): done
Solving environment: unsuccessful initial attempt using frozen solve. Retrying with flexible solve.

PackagesNotFoundError: The following packages are not available from current channels:

  - dgl

Current channels:

  - https://conda.anaconda.org/conda-forge/osx-arm64
  - https://conda.anaconda.org/conda-forge/noarch
  - https://repo.anaconda.com/pkgs/main/osx-arm64
  - https://repo.anaconda.com/pkgs/main/noarch
  - https://repo.anaconda.com/pkgs/r/osx-arm64
  - https://repo.anaconda.com/pkgs/r/noarch

To search for alternate channels that may provide the conda package you're
looking for, navigate to

    https://anaconda.org

and use the search bar at the top of the page.
```",tried install work install package done environment unsuccessful initial attempt frozen solve flexible solve package done environment unsuccessful initial attempt frozen solve flexible solve following available current current search alternate may provide package looking navigate use search bar top page,issue,positive,positive,positive,positive,positive,positive
1696014000,"@frozenbugs @Rhett-Ying @peizhou001 Can a significant portion of edge weights be zero? Should I optimize considering this case as well in the future? Will users use edge weights to separate train, validation or test edges etc. by setting a lot of edge weights to 0?",significant portion edge zero optimize considering case well future use edge separate train validation test setting lot edge,issue,positive,positive,positive,positive,positive,positive
1694959449,"> Now we have two API designs, one is row-column-select API, and another is index-range-select API. row-column-select API:
> 
> ```
> def rowwise_select(index or range) # User decides whether index or range by input.
> def columnwise_select(index or range)
> ```
> 
> index-range-select API:
> 
> ```
> def Index_select(dim, index) # User decides whether row or column by 'dim'.
> def Range_select(dim, range) 
> ```
> 
> Or even we can combine them all like:
> 
> ```
> def select(dim, index or range) # User decides dim and index/range.
> ```
> 
> @frozenbugs do you have some comments?

The index/range should just be tensor, right? And it is quite common to use dim in dgl Sparse API to indicate row wise and column wise, see (https://docs.dgl.ai/en/1.1.x/api/python/dgl.sparse_v0.html), so def select(dim, Tensor) should be good.",two one another index range user whether index range input index range dim index user whether row column dim range even combine like select dim index range user dim tensor right quite common use dim sparse indicate row wise column wise see select dim tensor good,issue,positive,positive,positive,positive,positive,positive
1694923828,"@mfbalin Yes, I think we could merge this PR and open a ticket to track the remaining issue.",yes think could merge open ticket track issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1694920695,"@Rhett-Ying https://github.com/dmlc/dgl/blob/master/examples/sampling/node_classification.py#L77

I had meant the example above. So, if you think my changes are good, maybe we can merge this and open an issue?",meant example think good maybe merge open issue,issue,negative,positive,positive,positive,positive,positive
1694869532,"@mfbalin I haven't figured out the root cause yet. But I guess memory allocator went wrong when trying to release no-longer-needed memory blocks/objects.

Which official example you're meaning?",figured root cause yet guess memory allocator went wrong trying release memory official example meaning,issue,negative,negative,negative,negative,negative,negative
1694726239,"When I use this function, the memory out of the limit.. The error said: unable to allocate 538 GiB for an array with shape.... and data type int64


could you solve this? 
",use function memory limit error said unable allocate gib array shape data type could solve,issue,negative,negative,negative,negative,negative,negative
1694588852,"Hi @dxyzx0 , how did you deal with the problem? I have met the same problem as you.",hi deal problem met problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1694582845,@mfbalin I think it's not easy to evaluate. My plan is to extract the sampling logic and run it by a large amount of times then test the sampled distribution.,think easy evaluate plan extract sampling logic run large amount time test distribution,issue,negative,positive,positive,positive,positive,positive
1693609411,"@RamonZhou How is the correctness going to be evaluated? If there is going to be a test, can we evaluate whether Labor works correctly as well?",correctness going going test evaluate whether labor work correctly well,issue,negative,neutral,neutral,neutral,neutral,neutral
1693115907,"I am pretty happy with the current performance of this code. Made a last-minute minor optimization. Feel free to merge anytime.
ogbn-products dataset 20 fanout, 200k nodes, including NS times because these two algorithms perform more or less similar things:
```
{('NS', False, False): 13.961718496284448,
 ('LABOR', False, False): 22.257723700022325,
 ('NS', False, True): 264.3265006976435,
 ('LABOR', False, True): 27.74477390339598,
 ('NS', True, False): 198.85092989716213,
 ('LABOR', True, False): 47.24292550235987,
 ('NS', True, True): 1236.366263902164,
 ('LABOR', True, True): 54.78198000055272}
```
Benchmarked with following code:
```
import torch
import dgl.graphbolt as gb
from ogb.nodeproppred import DglNodePropPredDataset
from dgl.data import RedditDataset
# g = gb.from_dglgraph(RedditDataset()[0])
g = gb.from_dglgraph(DglNodePropPredDataset('ogbn-products')[0][0])
g = gb.from_csc(g.csc_indptr, g.indices, None, None, {'probs': torch.rand([g.num_edges])}, g.metadata)
from timeit import default_timer as timer
from collections import defaultdict
times = defaultdict(float)
trials = 10
for z in range(trials):
    nodes = torch.randperm(g.num_nodes)[:200000]
    # nodes = torch.arange(g.num_nodes)
    for replace in [False, True]:
        for w in [None, 'probs']:
            for f, name in zip([g.sample_neighbors, g.sample_layer_neighbors], [""NS"", ""LABOR""]):
                st = timer()
                out = f(nodes, torch.tensor([20]), replace, probs_name=w)
                t = timer() - st
                times[name, replace, w is not None] += t
print({k: v / trials * 1000 for k, v in times.items()})
```",pretty happy current performance code made minor optimization feel free merge time two perform le similar false false false false false true false true true false true false true true true true following code import torch import import import none none import timer import time float range replace false true none name zip labor st timer replace timer st time name replace none print,issue,positive,positive,neutral,neutral,positive,positive
1693079596,"Now we have two API designs, one is row-column-select API, and another is index-range-select API.
row-column-select API:
```
def rowwise_select(index or range) # User decides whether index or range by input.
def columnwise_select(index or range)
```
index-range-select API:
```
def Index_select(dim, index) # User decides whether row or column by 'dim'.
def Range_select(dim, range) 
```
Or even we can combine them all like:
```
def select(dim, index or range) # User decides dim and index/range.
```
@frozenbugs do you have some comments?

",two one another index range user whether index range input index range dim index user whether row column dim range even combine like select dim index range user dim,issue,negative,positive,neutral,neutral,positive,positive
1692900337,"I feel like that would be hiding LayerNeighbor from users somehow. Anywhere NeighborSampler is used, it is possible to have a `--labor` flag. This way, users can compare the different samplers in each scenario NeighborSampler is used. It would also highlight that Graphbolt supports LayerNeighbor as a first-class citizen. This way if any issues come up, we can address them. We could also create advanced examples to demonstrate the advanced Labor features, here no advanced features are used, simply drop-in replacement.

@frozenbugs What do you think? LayerNeighbor is still Neighbor afterall. I would more than appreciate the gesture if we gave the `--labor` option more visibility. Users don't know about this alternative at all and what they are missing by not using it.

EDIT: I am not asking every example to have such an option, but one primary example where users would be exposed to LayerNeighborSampler usage.",feel like would somehow anywhere used possible labor flag way compare different scenario used would also highlight citizen way come address could also create advanced demonstrate advanced labor advanced used simply replacement think still neighbor would appreciate gesture gave labor option visibility know alternative missing edit every example option one primary example would exposed usage,issue,positive,positive,positive,positive,positive,positive
1692861968,"> After #6214 and #6203 are merged, can we add a `--labor` option to this script so that we can test `gb.LayerNeighborSampler` as well?

How about we create an additional example specifically focusing on the labor sampler? It would be beneficial to have an example demonstrating Labor Sampling with Hetero Node Classification. We could place this example in the ""examples/advanced/labor_sampling/"" directory. This way, if there are more related examples like GPUCache in the future, they can all be organized within the same folder.",add labor option script test well create additional example specifically labor sampler would beneficial example labor sampling hetero node classification could place example directory way related like future organized within folder,issue,positive,neutral,neutral,neutral,neutral,neutral
1692821440,"After #6214 and #6203 are merged, can we add a `--labor` option to this script so that we can test `gb.LayerNeighborSampler` as well?",add labor option script test well,issue,negative,neutral,neutral,neutral,neutral,neutral
1692724489,@Rhett-Ying this is such a strange behavior. What do you think causes it? I thought maybe I made a bug in my inference code but it more or less looks the same as the official example.,strange behavior think thought maybe made bug inference code le official example,issue,negative,negative,neutral,neutral,negative,negative
1692713327,"Add several envs to control CUDA memory management helps. Below works:
`CUDA_LAUNCH_BLOCKING=1  PYTORCH_CUDA_ALLOC_CONF=backend:cudaMallocAsync python3 examples/pytorch/labor/train_lightning.py --dataset ogbn-arxiv --num-epochs 1 --data-cpu`",add several control memory management work python,issue,negative,neutral,neutral,neutral,neutral,neutral
1692688057,"We also could allocate the required memory inside the parallel for section but that seemed like a lot of code change. I didn't want to make the code more complicated so I resorted to using the stack as a quick hack. In most scenarios, fanout < 1024, and num_neighbors < 1024 anyway.",also could allocate memory inside parallel section like lot code change want make code complicated stack quick hack anyway,issue,negative,negative,neutral,neutral,negative,negative
1692671956,"> @Rhett-Ying The MSVC version in CI doesn't seem to play well with modern C++ features. I recommend updating the MSVC version in CI.

it's VS2019 and may not play well with C++17 features.",version seem play well modern recommend version may play well,issue,positive,positive,positive,positive,positive,positive
1692103973,"@frozenbugs My goal is to keep Labor performance at parity with Neighbor as much as possible. Labor actually does a bit more work, always O(num_neighbors) compared to Neighbor possibly doing O(fanout), so it may not be possible for all use cases (high average degree graphs and no weights). Since I am proposing Labor to replace Neighbor, I don't want potential future users to say this is a complicated algorithm so it is bound to be slow. They keep saying this in my paper reviews all the time.

What would be nice is to give this algorithm a bit more visibility in examples etc. As it is, the API and behavior fully match the Neighbor API so one can go ahead and use this instead of Neighbor in some examples. I would love the feedback if somehow the end accuracy or result doesn't match the Neighbor baseline, which I could then investigate, but I don't expect such a thing to happen. When sampling multiple layers, Labor will sample significantly fewer vertices and edges which will speed up convergence.

In the future, Labor will support more advanced features which are already supported by the `dgl.sampling.sample_labors`. I am sure it will all look very fancy when we announce all these supported features to the wider GNN community.",goal keep labor performance parity neighbor much possible labor actually bit work always neighbor possibly may possible use high average degree since labor replace neighbor want potential future say complicated algorithm bound slow keep saying paper time would nice give algorithm bit visibility behavior fully match neighbor one go ahead use instead neighbor would love feedback somehow end accuracy result match neighbor could investigate expect thing happen sampling multiple labor sample significantly vertex speed convergence future labor support advanced already sure look fancy announce community,issue,positive,positive,neutral,neutral,positive,positive
1691801707,"Everything is the same except restart_prob.
I tested ""0.4.3 dgl  random_walk_with_restart"" function with different restart_prob. 
I run it 10 times with for loop. 

walks = dgl.contrib.sampling.random_walk_with_restart(G, seeds=[1], **restart_prob=0.9**,max_nodes_per_seed=256)

#Total number of traces for 10 for loops: 2293

walks = dgl.contrib.sampling.random_walk_with_restart(G, seeds=[1], **restart_prob=0.5**,max_nodes_per_seed=256)

#Total number of traces for 10 for loops: 1307

walks = dgl.contrib.sampling.random_walk_with_restart(G, seeds=[1], **restart_prob=0.1**,max_nodes_per_seed=256)

#Total number of traces for 10 for loops: : 237


",everything except tested function different run time loop total number total number total number,issue,negative,neutral,neutral,neutral,neutral,neutral
1691444859,"Not figured out the root cause yet. Below are several findings that might help.

I tried with smaller dataset `--num-epochs 1 --data-cpu --dataset cora --batch-size 100` and it works well.

If choose `neighbor` sampler, it crashed in train(forward) stage.

According to the callstacks shown below(run with `python3 examples/pytorch/labor/train_lightning.py --dataset ogbn-arxiv --num-epochs 1 --data-cpu`), it crashed when trying to releasing cuda memory blocks. More specifically, I guess system(pytorch/cuda) is trying to releasing some tensors which are still in use.

```
Evaluating model in ./tb_logs/ogbn-arxiv_labor_0_False_1/version_43
  5%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                                                                                                       | 2/42 [00:00<00:03, 12.69it/s]
Traceback (most recent call last):
  File ""/home/ubuntu/workspace/dgl_2/examples/pytorch/labor/train_lightning.py"", line 520, in <module>
    pred = model.module.inference(
  File ""/home/ubuntu/workspace/dgl_2/examples/pytorch/labor/model.py"", line 81, in inference
    h = layer(blocks[0], x)
  File ""/home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/nn/modules/module.py"", line 1501, in _call_impl
    return forward_call(*args, **kwargs)
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/nn/pytorch/conv/sageconv.py"", line 237, in forward
    graph.update_all(msg_fn, fn.mean(""m"", ""neigh""))
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/heterograph.py"", line 5110, in update_all
    ndata = core.message_passing(
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/core.py"", line 398, in message_passing
    ndata = invoke_gspmm(g, mfunc, rfunc)
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/core.py"", line 368, in invoke_gspmm
    z = op(graph, x)
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/ops/spmm.py"", line 215, in func
    return gspmm(g, ""copy_lhs"", reduce_op, x, None)
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/ops/spmm.py"", line 111, in gspmm
    deg = g.in_degrees()
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/heterograph.py"", line 3669, in in_degrees
    v = self.dstnodes(dsttype)
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/view.py"", line 49, in __call__
    ret = F.arange(
  File ""/home/ubuntu/workspace/dgl_2/python/dgl/backend/pytorch/tensor.py"", line 407, in arange
    return th.arange(start, stop, dtype=dtype, device=ctx)
RuntimeError: CUDA error: an illegal memory access was encountered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

terminate called after throwing an instance of 'c10::Error'
  what():  CUDA error: an illegal memory access was encountered
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:44 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7f33ce7904d7 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7f33ce75a36b in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x7f33ce82cb58 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1c36b (0x7f33ce7fd36b in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2b930 (0x7f33ce80c930 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x4d5a16 (0x7f34256e4a16 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x3ee77 (0x7f33ce775e77 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #7: c10::TensorImpl::~TensorImpl() + 0x1be (0x7f33ce76e69e in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x9 (0x7f33ce76e7b9 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x75afc8 (0x7f3425969fc8 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
frame #10: THPVariable_subclass_dealloc(_object*) + 0x305 (0x7f342596a355 in /home/ubuntu/anaconda3/envs/dgl-dev-gpu-dgl-2/lib/python3.10/site-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #20: __libc_start_main + 0xf3 (0x7f3445ac7083 in /lib/x86_64-linux-gnu/libc.so.6)

Aborted (core dumped)
```",figured root cause yet several might help tried smaller cora work well choose neighbor sampler train forward stage according shown run python trying memory specifically guess system trying still use model recent call last file line module file line inference layer file line return file line forward neigh file line file line file line graph file line return none file line deg file line file line ret file line return start stop error illegal memory access compile enable terminate throwing instance error illegal memory access compile enable exception raised recent call first frame frame char char unsigned frame char char bool frame unknown function frame unknown function frame unknown function frame unknown function frame frame frame unknown function frame python frame aborted core,issue,negative,negative,neutral,neutral,negative,negative
1691408714,"> The API makes sense to me, how do you plan to distinguish individual tensor or tensor in dict?

Both of them can be fed into the `ShareMemoryHelper`.",sense plan distinguish individual tensor tensor fed,issue,negative,neutral,neutral,neutral,neutral,neutral
1691247526,"Overall LGTM, @czkkkkkk please give approve if you are good with this PR.",overall please give approve good,issue,positive,positive,positive,positive,positive,positive
1691126459,"I've tested the performance.

- `v0`: The original one.
- `v1`: After #6152 
- `v2`: After this PR.

![L-UF](https://github.com/dmlc/dgl/assets/26337272/9e141eb8-ab7e-470e-bcac-ed4a33ca5438)
![L-NF](https://github.com/dmlc/dgl/assets/26337272/1e61292f-f979-457b-898f-90aea3e10c6c)
![L-UT](https://github.com/dmlc/dgl/assets/26337272/3a595ea6-3150-4fc6-aa0a-a2d8bb91874e)
![L-NT](https://github.com/dmlc/dgl/assets/26337272/527d19cb-23b6-44c9-adb9-bde48545e2a2)

Data:
![data](https://github.com/dmlc/dgl/assets/26337272/053ae81e-e7e7-418f-86b3-e3f8d4314c89)

There is a big boost in G1.
The small drops in other graphs may be fluctuations.",tested performance original one data data big boost small may,issue,positive,positive,neutral,neutral,positive,positive
1691066908,"The API makes sense to me, how do you plan to distinguish individual tensor or tensor in dict?",sense plan distinguish individual tensor tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
1691055360,Feel free to merge this PR if the other error is unrelated.,feel free merge error unrelated,issue,negative,positive,positive,positive,positive,positive
1690986149,"



> how to deal with this problem?? @paoxiaode , looking for your reply, thx.


@leaves520 
This problem is due to the pkl file being dumped under an older version of DGL.

If you want to use the PATTERN, CLUSTER dataset, you can refer to https://github.com/dmlc/dgl/blob/master/python/dgl/data/pattern.py, they are now supported by DGL.

If you want to use the not DGL built-in dataset dataset(CIFAR 10 or MNIST), you can refer to https://github.com/graphdeeplearning/benchmarking-gnns/blob/master/data/superpixels/prepare_superpixels_MNIST.ipynb, use the code like below to re-dump the dataset pkl file
```
import pickle
import time

from data.superpixels import SuperPixDatasetDGL 

from data.data import LoadData
from torch.utils.data import DataLoader
from data.superpixels import SuperPixDataset

DATASET_NAME = 'MNIST'
dataset = SuperPixDatasetDGL(DATASET_NAME) 

with open('data/superpixels/MNIST.pkl','wb') as f:
        pickle.dump([dataset.train,dataset.val,dataset.test],f)
```",deal problem looking reply leaf problem due file older version want use pattern cluster refer want use refer use code like file import pickle import time import import import import open,issue,negative,positive,neutral,neutral,positive,positive
1690924360,got it. Let me try to look into this,got let try look,issue,negative,neutral,neutral,neutral,neutral,neutral
1690919724,"@Rhett-Ying Yes, this PR currently fixes UVA inference. However, I couldn't fix the CPU sampling and GPU inferencing combination. 3rd cell in the colab notebook I linked above runs successfully with this PR (UVA sampling).",yes currently uva inference however could fix sampling combination cell notebook linked successfully uva sampling,issue,positive,positive,positive,positive,positive,positive
1690916910,@mfbalin The issue you pasted above happens with current example no matter whether this PR is merged?,issue pasted current example matter whether,issue,negative,neutral,neutral,neutral,neutral,neutral
1690914140,"`DGLGraph.send` is deprecated. As a replacement, use `DGLGraph.apply_edges` API to compute messages as edge data. Then use `DGLGraph.send_and_recv` and set the message function as `dgl.function.copy_e` to conduct message aggregation.",replacement use compute edge data use set message function conduct message aggregation,issue,negative,neutral,neutral,neutral,neutral,neutral
1690880768,@frozenbugs I see that there is a feature store and a feature now. Feature store can hold multiple features. But there is no feature class to derive from. I need this functionality to add GPUCachedFeature. We also need to have a Generic FeatureStore implementation that can have different kinds of features inside of it so that some of the features can be the cached kind.,see feature store feature feature store hold multiple feature class derive need functionality add also need generic implementation different inside kind,issue,positive,positive,positive,positive,positive,positive
1690876121,It shouldn't affect the number of random walk paths.  That should be always equal to the number of seeds.,affect number random walk always equal number,issue,negative,negative,negative,negative,negative,negative
1690874437,"This issue happens with original DGL benchmark. As we are deprecating it and working with new DGL benchmark framework now, let's close this ticket.",issue original working new framework let close ticket,issue,negative,positive,positive,positive,positive,positive
1690545070,@Rhett-Ying The MSVC version in CI doesn't seem to play well with modern C++ features. I recommend updating the MSVC version in CI.,version seem play well modern recommend version,issue,positive,positive,positive,positive,positive,positive
1689606330,"No CI coverage, merge without CI result.",coverage merge without result,issue,negative,neutral,neutral,neutral,neutral,neutral
1689458700,"something wrong with the base, I think you need to sync master first, and rebase.",something wrong base think need sync master first rebase,issue,negative,negative,negative,negative,negative,negative
1689125440,"This issue happens in DGL benchmark image(ubuntu22.04, gcc 11), works well in DGL CI(ubuntu 18.04, gcc 7)",issue image work well,issue,negative,neutral,neutral,neutral,neutral,neutral
1689065983,"> @mfbalin I've updated the description :)

Are the benchmark scripts going to be available? I am thinking of improving Labor performance in the future.",description going available thinking improving labor performance future,issue,negative,positive,positive,positive,positive,positive
1687984997,"that's weird. could you share the minimum reproducible code for above case? Below is the one for illustration.
```
import dgl
import torch

g = dgl.graph(([0, 1], [1, 0]))
print(g.adjacency_matrix().to_dense())
print(g)
```

```
tensor([[0., 1.],
        [1., 0.]])
Graph(num_nodes=2, num_edges=2,
      ndata_schemes={}
      edata_schemes={})
```",weird could share minimum reproducible code case one illustration import import torch print print tensor graph,issue,negative,negative,negative,negative,negative,negative
1687744441,"I guess there is something wrong with the last dataset, since we find the similar result from current hetero-rgcn implementation: https://github.com/dmlc/dgl/blob/master/examples/pytorch/rgcn-hetero/entity_classify.py",guess something wrong last since find similar result current implementation,issue,negative,negative,negative,negative,negative,negative
1687726485,"> I think it is overfit, can you double check?

It seems not overfit. I test different numbers of epoch, follows are the results of epoch = 5 and 10:
```
python examples/sparse/hetero-rgcn.py -d am
Namespace(dataset='am')
Done loading data from cached files.
[W TensorAdvancedIndexing.cpp:1615] Warning: scatter_reduce() is in beta and the API may change at any time. (function operator())
start training...
Epoch 00000 | Train Acc: 0.0452 | Train Loss: 2.7244 | Valid Acc: 0.0437 | Valid loss: 2.6268 
Epoch 00001 | Train Acc: 0.1308 | Train Loss: 2.3101 | Valid Acc: 0.0813 | Valid loss: 2.4318 
Epoch 00002 | Train Acc: 0.4424 | Train Loss: 1.9616 | Valid Acc: 0.1812 | Valid loss: 2.3291 
Epoch 00003 | Train Acc: 0.4657 | Train Loss: 1.6822 | Valid Acc: 0.1688 | Valid loss: 2.3107 
Epoch 00004 | Train Acc: 0.4595 | Train Loss: 1.4807 | Valid Acc: 0.1750 | Valid loss: 2.3611 

Test Acc: 0.3485 | Test loss: 1.8214
```

```
python examples/sparse/hetero-rgcn.py -d am
Namespace(dataset='am')
Done loading data from cached files.
[W TensorAdvancedIndexing.cpp:1615] Warning: scatter_reduce() is in beta and the API may change at any time. (function operator())
start training...
Epoch 00000 | Train Acc: 0.0592 | Train Loss: 2.4887 | Valid Acc: 0.0813 | Valid loss: 2.5531 
Epoch 00001 | Train Acc: 0.4315 | Train Loss: 2.1208 | Valid Acc: 0.1625 | Valid loss: 2.4388 
Epoch 00002 | Train Acc: 0.4221 | Train Loss: 1.8412 | Valid Acc: 0.1500 | Valid loss: 2.4075 
Epoch 00003 | Train Acc: 0.4470 | Train Loss: 1.6381 | Valid Acc: 0.1750 | Valid loss: 2.4399 
Epoch 00004 | Train Acc: 0.4486 | Train Loss: 1.4952 | Valid Acc: 0.1812 | Valid loss: 2.4964 
Epoch 00005 | Train Acc: 0.4626 | Train Loss: 1.3706 | Valid Acc: 0.1812 | Valid loss: 2.5386 
Epoch 00006 | Train Acc: 0.5109 | Train Loss: 1.2319 | Valid Acc: 0.1812 | Valid loss: 2.5417 
Epoch 00007 | Train Acc: 0.5935 | Train Loss: 1.0780 | Valid Acc: 0.1812 | Valid loss: 2.5101 
Epoch 00008 | Train Acc: 0.6963 | Train Loss: 0.9242 | Valid Acc: 0.2062 | Valid loss: 2.4596 
Epoch 00009 | Train Acc: 0.7866 | Train Loss: 0.7796 | Valid Acc: 0.2313 | Valid loss: 2.4064 

Test Acc: 0.4747 | Test loss: 1.6184
```

However, I observe an intersting phenomenon that the results of other three datasets seem to be normal.
This is the result of 'aifb' dataset:
```
python examples/sparse/hetero-rgcn.py -d aifb
Namespace(dataset='aifb')
Done loading data from cached files.
[W TensorAdvancedIndexing.cpp:1615] Warning: scatter_reduce() is in beta and the API may change at any time. (function operator())
start training...
Epoch 00000 | Train Acc: 0.0982 | Train Loss: 1.6857 | Valid Acc: 0.0357 | Valid loss: 2.0964 
Epoch 00001 | Train Acc: 0.3482 | Train Loss: 1.3300 | Valid Acc: 0.5357 | Valid loss: 1.2303 
Epoch 00002 | Train Acc: 0.6339 | Train Loss: 1.0971 | Valid Acc: 0.6429 | Valid loss: 0.8458 
Epoch 00003 | Train Acc: 0.7857 | Train Loss: 0.9242 | Valid Acc: 0.7500 | Valid loss: 0.6349 
Epoch 00004 | Train Acc: 0.8304 | Train Loss: 0.8019 | Valid Acc: 0.9643 | Valid loss: 0.5227 
Epoch 00005 | Train Acc: 0.8304 | Train Loss: 0.7032 | Valid Acc: 0.9643 | Valid loss: 0.4620 
Epoch 00006 | Train Acc: 0.8304 | Train Loss: 0.6094 | Valid Acc: 0.9286 | Valid loss: 0.3989 
Epoch 00007 | Train Acc: 0.8393 | Train Loss: 0.5206 | Valid Acc: 0.9643 | Valid loss: 0.3272 
Epoch 00008 | Train Acc: 0.8393 | Train Loss: 0.4414 | Valid Acc: 0.9643 | Valid loss: 0.2617 
Epoch 00009 | Train Acc: 0.9107 | Train Loss: 0.3744 | Valid Acc: 0.9643 | Valid loss: 0.2084 

Test Acc: 0.8611 | Test loss: 0.4359
```

And follow is the result of 'mutag' dataset:
```
python examples/sparse/hetero-rgcn.py -d mutag
Namespace(dataset='mutag')
Done loading data from cached files.
[W TensorAdvancedIndexing.cpp:1615] Warning: scatter_reduce() is in beta and the API may change at any time. (function operator())
start training...
Epoch 00000 | Train Acc: 0.5275 | Train Loss: 0.7372 | Valid Acc: 0.5370 | Valid loss: 0.7311 
Epoch 00001 | Train Acc: 0.6239 | Train Loss: 0.7495 | Valid Acc: 0.5556 | Valid loss: 0.9664 
Epoch 00002 | Train Acc: 0.6284 | Train Loss: 0.5782 | Valid Acc: 0.5556 | Valid loss: 0.8043 
Epoch 00003 | Train Acc: 0.9312 | Train Loss: 0.4874 | Valid Acc: 0.5370 | Valid loss: 0.7278 
Epoch 00004 | Train Acc: 0.9587 | Train Loss: 0.4223 | Valid Acc: 0.4259 | Valid loss: 0.7278 
Epoch 00005 | Train Acc: 0.9908 | Train Loss: 0.3206 | Valid Acc: 0.4074 | Valid loss: 0.7154 
Epoch 00006 | Train Acc: 1.0000 | Train Loss: 0.2157 | Valid Acc: 0.4444 | Valid loss: 0.6919 
Epoch 00007 | Train Acc: 1.0000 | Train Loss: 0.1378 | Valid Acc: 0.6667 | Valid loss: 0.6790 
Epoch 00008 | Train Acc: 1.0000 | Train Loss: 0.0861 | Valid Acc: 0.6296 | Valid loss: 0.6775 
Epoch 00009 | Train Acc: 1.0000 | Train Loss: 0.0528 | Valid Acc: 0.5926 | Valid loss: 0.6814 
Epoch 00010 | Train Acc: 1.0000 | Train Loss: 0.0313 | Valid Acc: 0.6296 | Valid loss: 0.6866 
Epoch 00011 | Train Acc: 1.0000 | Train Loss: 0.0176 | Valid Acc: 0.6296 | Valid loss: 0.6884 
Epoch 00012 | Train Acc: 1.0000 | Train Loss: 0.0096 | Valid Acc: 0.6296 | Valid loss: 0.6880 
Epoch 00013 | Train Acc: 1.0000 | Train Loss: 0.0052 | Valid Acc: 0.6296 | Valid loss: 0.6861 
Epoch 00014 | Train Acc: 1.0000 | Train Loss: 0.0028 | Valid Acc: 0.6481 | Valid loss: 0.6833 
Epoch 00015 | Train Acc: 1.0000 | Train Loss: 0.0016 | Valid Acc: 0.6667 | Valid loss: 0.6798 
Epoch 00016 | Train Acc: 1.0000 | Train Loss: 0.0009 | Valid Acc: 0.6667 | Valid loss: 0.6761 
Epoch 00017 | Train Acc: 1.0000 | Train Loss: 0.0005 | Valid Acc: 0.6667 | Valid loss: 0.6718 
Epoch 00018 | Train Acc: 1.0000 | Train Loss: 0.0003 | Valid Acc: 0.6296 | Valid loss: 0.6677 
Epoch 00019 | Train Acc: 1.0000 | Train Loss: 0.0002 | Valid Acc: 0.6481 | Valid loss: 0.6644 

Test Acc: 0.6912 | Test loss: 0.6529
```

The result of 'bgs' dataset.
```
ython examples/sparse/hetero-rgcn.py -d bgs
Namespace(dataset='bgs')
Done loading data from cached files.
[W TensorAdvancedIndexing.cpp:1615] Warning: scatter_reduce() is in beta and the API may change at any time. (function operator())
start training...
Epoch 00000 | Train Acc: 0.6170 | Train Loss: 0.6688 | Valid Acc: 0.5652 | Valid loss: 0.6651 
Epoch 00001 | Train Acc: 0.6489 | Train Loss: 0.6068 | Valid Acc: 0.6087 | Valid loss: 0.6248 
Epoch 00002 | Train Acc: 0.7766 | Train Loss: 0.5307 | Valid Acc: 0.8261 | Valid loss: 0.5307 
Epoch 00003 | Train Acc: 0.8723 | Train Loss: 0.4607 | Valid Acc: 0.8696 | Valid loss: 0.4660 
Epoch 00004 | Train Acc: 0.9149 | Train Loss: 0.3835 | Valid Acc: 0.8261 | Valid loss: 0.4066 
Epoch 00005 | Train Acc: 0.9149 | Train Loss: 0.3190 | Valid Acc: 0.7826 | Valid loss: 0.3613 
Epoch 00006 | Train Acc: 0.9149 | Train Loss: 0.2599 | Valid Acc: 0.8696 | Valid loss: 0.3072 
Epoch 00007 | Train Acc: 0.9149 | Train Loss: 0.2085 | Valid Acc: 0.9130 | Valid loss: 0.2479 
Epoch 00008 | Train Acc: 0.9255 | Train Loss: 0.1694 | Valid Acc: 0.9565 | Valid loss: 0.1955 
Epoch 00009 | Train Acc: 0.9255 | Train Loss: 0.1413 | Valid Acc: 0.9565 | Valid loss: 0.1565 

Test Acc: 0.8621 | Test loss: 0.3641
```




",think overfit double check overfit test different epoch epoch python done loading data warning beta may change time function operator start training epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss test test loss python done loading data warning beta may change time function operator start training epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss test test loss however observe phenomenon three seem normal result python done loading data warning beta may change time function operator start training epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss test test loss follow result python done loading data warning beta may change time function operator start training epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss test test loss result done loading data warning beta may change time function operator start training epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss epoch train train loss valid valid loss test test loss,issue,negative,positive,neutral,neutral,positive,positive
1687695367,"Thank you so much 
But I have another questions
I tried a sample code 
Suppose 
I have a graph with adj matrix as given below 

`graph.adjacency_matrix().to_dense()`

`tensor([[0., 1.],
              [1., 0.]])`

When I just print the properties of variable 'graph', it gives me following 

`Graph(num_nodes=2, num_edges=4,
      ndata_schemes={'h': Scheme(shape=(), dtype=torch.float32)}
      edata_schemes={})`

Why num_edges is 4. Shouldn't it be only two even if the DGL graphs are directed

",thank much another tried sample code suppose graph matrix given tensor print variable following graph scheme two even directed,issue,negative,positive,neutral,neutral,positive,positive
1687679918,"I think it is overfit, can you double check?",think overfit double check,issue,negative,neutral,neutral,neutral,neutral,neutral
1687392303,"```
libdgl.so: undefined reference to `dgemv_'
libdgl.so: undefined reference to `dgemm_'
libdgl.so: undefined reference to `sgemm_'
libdgl.so: undefined reference to `sgemv_'
```

Seems to be the issue in 3/75 of the builds. Are these symbols provided by complied libxsmm perhaps? Something else?

We also observed this making the recipie, resolved by making MKL a dependency for the recipe. 
",undefined reference undefined reference undefined reference undefined reference issue provided perhaps something else also making resolved making dependency recipe,issue,negative,neutral,neutral,neutral,neutral,neutral
1687351735,"@jermainewang @frozenbugs, this is the PR to upstream the conda-forge cmake changes, let me know what you think and I will incorporate as soon as I can. ",upstream let know think incorporate soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1687291466,"`DGLGraph` is always directed. You could use `dgl.add_reverse_edges()` or `dgl.to_bidirected()` to see if any new edges are added. If not, then the DGLGraph is already bi-directed. Or try with `directed=True` in `node_link_graph` of nx.",always directed could use see new added already try,issue,negative,positive,positive,positive,positive,positive
1687288519,The experiment shows PyTorch Tensor (On local disk) provided the best performance compare to other solutions for random accessing fix length features.,experiment tensor local disk provided best performance compare random fix length,issue,positive,positive,positive,positive,positive,positive
1687205226,1.1.1 is live now! Again if you want to loop in the branch its `hmacdope:conda-forge-1.1.1`,live want loop branch,issue,negative,positive,positive,positive,positive,positive
1686854250,"In theory, Neighbor should always be faster than Labor. So, it is possible to keep optimizing neighbor until it is faster than labor.",theory neighbor always faster labor possible keep neighbor faster labor,issue,negative,neutral,neutral,neutral,neutral,neutral
1686114774,"Wow, this is indeed a great amount of work! Please accept my hats off! @hmacdope @mikemhenry .

@frozenbugs Please remember to highlight this in our next release and also follow up with this to see how to incorporate those changes to our cmake.",wow indeed great amount work please accept please remember highlight next release also follow see incorporate,issue,positive,positive,positive,positive,positive,positive
1686080191,"@Rhett-Ying 
The sample code is as follows. I am loading a graph from JSON file. 
`
def load_graph(self, path):
        #Load graph
        with open(path, 'r') as f:
            graph_load = json.loads(f.read())
            return nx.readwrite.json_graph.node_link_graph(graph_load)

graph_nx = load_graph(graphs_path)
print(""Number of Edges with Nx===>\n"",graph_nx.number_of_edges())
dgl_graph = dgl.from_networkx(graph_nx, node_attrs=['features', 'label'])
print(""Number of Edges with DGL===>\n"", dgl_graph.number_of_edges())

`

I think, DGL counts Non-directed edges twice here which is not the case with NetworkX Package

Say if adjacent_matrix[i,j] = 1,  In Non directed Edges adjacent_matrix[j,i] is also 1.


Can you please let me know how to fix this. I tried to dig into the code, but I am yet to figure it out





",sample code loading graph file self path load graph open path return print number print number think twice case package say non directed also please let know fix tried dig code yet figure,issue,negative,neutral,neutral,neutral,neutral,neutral
1686061532,could you share a minimum reproducible code?,could share minimum reproducible code,issue,negative,neutral,neutral,neutral,neutral,neutral
1685782638,It's strange that validation accuracy is much lower than test accuracy.,strange validation accuracy much lower test accuracy,issue,negative,positive,neutral,neutral,positive,positive
1685561093,"> > @czkkkkkk @jermainewang do know whether Test Acc: 0.4091 is reasonable?
> 
> The train loss looks abnormal. What is the loss of the message passing example? https://github.com/dmlc/dgl/blob/master/examples/core/rgcn/hetero_rgcn.py#L285

I find the problem is the missing of matrix normalization, so I add it and new result is updated. The loss now is the same as previous exmaples. However, the accuracy is still a bit lower, we think this is because the Graphconv operator in dgl use more fine-grained optimization.",know whether test reasonable train loss abnormal loss message passing example find problem missing matrix normalization add new result loss previous however accuracy still bit lower think operator use optimization,issue,negative,negative,neutral,neutral,negative,negative
1685551504,"> If you can paste the log here, maybe we can help.

@frozenbugs Can be run here, 2nd cell: https://colab.research.google.com/drive/1gxOOYRdAvr291Q1eBLLEZRQVx0vOzpkZ?usp=sharing

```
Traceback (most recent call last):
  File ""/content/dgl-1/examples/pytorch/labor/train_lightning.py"", line 511, in <module>
    pred = model.module.inference(
  File ""/content/dgl-1/examples/pytorch/labor/model.py"", line 88, in inference
    y[output_nodes[0] : output_nodes[-1] + 1] = h.to(y.device)
RuntimeError: CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

terminate called after throwing an instance of 'c10::Error'
  what():  CUDA error: an illegal memory access was encountered
CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.
For debugging consider passing CUDA_LAUNCH_BLOCKING=1.
Compile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.

Exception raised from c10_cuda_check_implementation at ../c10/cuda/CUDAException.cpp:44 (most recent call first):
frame #0: c10::Error::Error(c10::SourceLocation, std::string) + 0x57 (0x7b5ce21af4d7 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #1: c10::detail::torchCheckFail(char const*, char const*, unsigned int, std::string const&) + 0x64 (0x7b5ce217936b in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #2: c10::cuda::c10_cuda_check_implementation(int, char const*, char const*, int, bool) + 0x118 (0x7b5d0c4adb58 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10_cuda.so)
frame #3: <unknown function> + 0x1c36b (0x7b5d0c47e36b in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10_cuda.so)
frame #4: <unknown function> + 0x2b930 (0x7b5d0c48d930 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10_cuda.so)
frame #5: <unknown function> + 0x4d5a16 (0x7b5cdb778a16 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #6: <unknown function> + 0x3ee77 (0x7b5ce2194e77 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #7: c10::TensorImpl::~TensorImpl() + 0x1be (0x7b5ce218d69e in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #8: c10::TensorImpl::~TensorImpl() + 0x9 (0x7b5ce218d7b9 in /usr/local/lib/python3.10/dist-packages/torch/lib/libc10.so)
frame #9: <unknown function> + 0x75afc8 (0x7b5cdb9fdfc8 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
frame #10: THPVariable_subclass_dealloc(_object*) + 0x305 (0x7b5cdb9fe355 in /usr/local/lib/python3.10/dist-packages/torch/lib/libtorch_python.so)
<omitting python frames>
frame #20: <unknown function> + 0x29d90 (0x7b5d0d023d90 in /lib/x86_64-linux-gnu/libc.so.6)
frame #21: __libc_start_main + 0x80 (0x7b5d0d023e40 in /lib/x86_64-linux-gnu/libc.so.6)
```",paste log maybe help run cell recent call last file line module file line inference error illegal memory access kernel might call might incorrect consider passing compile enable terminate throwing instance error illegal memory access kernel might call might incorrect consider passing compile enable exception raised recent call first frame frame char char unsigned frame char char bool frame unknown function frame unknown function frame unknown function frame unknown function frame frame frame unknown function frame python frame unknown function frame,issue,negative,negative,negative,negative,negative,negative
1685162868,"> @czkkkkkk @jermainewang do know whether Test Acc: 0.4091 is reasonable?

The train loss looks abnormal. What is the loss of the message passing example? https://github.com/dmlc/dgl/blob/master/examples/core/rgcn/hetero_rgcn.py#L285",know whether test reasonable train loss abnormal loss message passing example,issue,negative,positive,positive,positive,positive,positive
1684934362,"In the old version a ""max_nodes_per_seed"" parameter gives the maximum number of traces. But the number of traces is variable. That's why I thought the number of traces depends on the ""restart_prob"" parameter. Because when this parameter gets bigger, the total number of traces also increases, and when it gets smaller, the total number of traces also decreases. Actually, the ""restart_prob"" parameter determines the length of the random walk. I know this. But I am not sure if it affects the total trace count. If it does, how does it affect it?

dgl 0.4.3 random_walk_with_restart function

**def random_walk_with_restart(
        g, seeds, restart_prob, max_nodes_per_seed,
        max_visit_counts=0, max_frequent_visited_nodes=0):
    """"""Batch-generate random walk traces on given graph with restart probability.

    Parameters
    ----------
    g : DGLGraph
        The graph.
    seeds : Tensor
        The node ID tensor from which the random walk traces starts.
    restart_prob : float
        Probability to stop a random walk after each step.
    max_nodes_per_seed : int
        Stop generating traces for a seed if the total number of nodes
        visited exceeds this number. [1]
    max_visit_counts : int, optional
    max_frequent_visited_nodes : int, optional
        Alternatively, stop generating traces for a seed if no less than
        ``max_frequent_visited_nodes`` are visited no less than
        ``max_visit_counts`` times.  [1]**

",old version parameter maximum number number variable thought number parameter parameter bigger total number also smaller total number also actually parameter length random walk know sure total trace count affect function random walk given graph restart probability graph tensor node id tensor random walk float probability stop random walk step stop generating seed total number number optional optional alternatively stop generating seed le le time,issue,negative,negative,negative,negative,negative,negative
1684814094,@czkkkkkk @jermainewang do know whether Test Acc: 0.4091 is reasonable?,know whether test reasonable,issue,negative,positive,positive,positive,positive,positive
1683353361,"Just as a note, this patch https://github.com/conda-forge/dgl-feedstock/blob/main/recipe/fix_libdgl_sparse_pytorch_location_logic.patch was kind of a hack to fix some weird issues I was seeing, with the way conda-forge does the builds, we will only ever build one version of PyTorch against dlg_sparse, so it is safe to just grab the one we built. I don't think we should upstream that one and we should make dgl.sparse it's own conda-forge package if it is meant to be stand alone",note patch kind hack fix weird seeing way ever build one version safe grab one built think upstream one make package meant stand alone,issue,positive,positive,positive,positive,positive,positive
1683352047,"This issue can be closed, we have 1.1.0 on conda forge and will work on the newer versions now.",issue closed forge work,issue,negative,negative,neutral,neutral,negative,negative
1683318850,"> > Overall LGTM, please copy paste the model result to the PR description.
> 
> @frozenbugs I'm not sure what the results include. Is it the performance or the size of the model parameters?

Just the output of the model, e.g. acc loss e.t.c. for example: https://github.com/dmlc/dgl/pull/6163",overall please copy paste model result description sure include performance size model output model loss example,issue,negative,positive,positive,positive,positive,positive
1683292650,"Hi all, particularly (@jermainewang @BarclayII @bgawrych @hadim @mikemhenry)

There is now a conda-forge package for DGL 1.1.0!  :smile: :tada: Try it out with:

```
conda install -c conda-forge dgl
```

Thanks so much to @mikemhenry for doing  most of the heavy lifting. 

There were significant CMake patches required to satisfy the conda setup as well as two additional smaller patches. I have attached them here. 

Going forward, should you be amenable, I think we should upstream as many of these changes as possible. 
so that a complicated patch setup is not required for conda releases and such that there is only one source of truth (the wonderful DGL package!). 

1.[ `conda-build.patch` ](https://github.com/conda-forge/dgl-feedstock/blob/main/recipe/conda-build.patch)-> re-works CMake to allow building from deps in a conda env and changes libxsmm to header only mode
2. [`fix_clang_errors.patch` ](https://github.com/conda-forge/dgl-feedstock/blob/main/recipe/fix_clang_errors.patch)-> small change to deal with some clang casting strictness, backport from current `master`
3. [ `fix_libdgl_sparse_pytorch_location_logic.patch`](https://github.com/conda-forge/dgl-feedstock/blob/main/recipe/fix_libdgl_sparse_pytorch_location_logic.patch) -> Makes the finding dgl_sparse libs more robust. 


My branch `hmacdope/conda-forge-1.1.0-patches` has a clean copy of the code with patches applied  for records sake so that you can bring this in as an upstream back-branch if you want. 

My next steps were going to be:

* Generate equivalent CMake patches for 1.1.1 so we can work on a 1.1.1 build in the feedstock. 
* ~~PR against main with patches 2 and 3, should be simple and easy. ~~ 
* PR against main for an equivalent of patch 1, which is more involved.
* Remove the requirement for patches from the feedstock. 

Let me know if you have feedback on this course of action or would like to approach things differently. 

Cheers, 

Hugo 

",hi particularly package smile try install thanks much heavy lifting significant satisfy setup well two additional smaller attached going forward amenable think upstream many possible complicated patch setup one source truth wonderful package allow building header mode small change deal clang casting strictness current master finding robust branch clean copy code applied sake bring upstream want next going generate equivalent work build main simple easy main equivalent patch involved remove requirement let know feedback course action would like approach differently,issue,positive,positive,positive,positive,positive,positive
1683221330,"> Overall LGTM, please copy paste the model result to the PR description.

@frozenbugs I'm not sure what the results include. Is it the performance or the size of the model parameters?",overall please copy paste model result description sure include performance size model,issue,positive,positive,positive,positive,positive,positive
1682645868,"@frozenbugs: Yes, I still see the namespace-related warning for `tests/python/common/data/test_data.py::test_citation_graph` running with both 23.07 and 23.08 NVidia `dgl` containers.",yes still see warning running,issue,negative,neutral,neutral,neutral,neutral,neutral
1681795176,"I don't see namespace related warning tests/python/common/data/test_data.py::test_citation_graph

tests/python/common/data/test_data.py::test_citation_graph PASSED                                                                                                                                              [100%]

================================================================================================== warnings summary ==================================================================================================
../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:10: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _nlv = LooseVersion(_np_version)

../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:11: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p16 = _nlv < LooseVersion(""1.16"")

../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:12: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p17 = _nlv < LooseVersion(""1.17"")

../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:13: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p18 = _nlv < LooseVersion(""1.18"")

../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:14: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p19 = _nlv < LooseVersion(""1.19"")

../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/__init__.py:15: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    _np_version_under1p20 = _nlv < LooseVersion(""1.20"")

../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/setuptools/_distutils/version.py:346
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/setuptools/_distutils/version.py:346: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    other = LooseVersion(other)

../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/function.py:125
../../../../opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/function.py:125
  /opt/conda/envs/dgl-dev-gpu/lib/python3.7/site-packages/pandas/compat/numpy/function.py:125: DeprecationWarning: distutils Version classes are deprecated. Use packaging.version instead.
    if LooseVersion(_np_version) >= LooseVersion(""1.17.0""):

-- Docs: https://docs.pytest.org/en/stable/how-to/capture-warnings.html
=========================================================================================== 1 passed, 9 warnings in 6.88s ============================================================================================

Can you confirm?",see related warning summary version class use instead version class use instead version class use instead version class use instead version class use instead version class use instead version class use instead version class use instead confirm,issue,negative,neutral,neutral,neutral,neutral,neutral
1681707227,"how to deal with this problem?? @paoxiaode , looking for your reply, thx.",deal problem looking reply,issue,negative,neutral,neutral,neutral,neutral,neutral
1681668379,"> Also remove from the original code?

Yes, I am still editing the code",also remove original code yes still code,issue,positive,positive,positive,positive,positive,positive
1681660807,"If you can paste the log here, maybe we can help.",paste log maybe help,issue,negative,neutral,neutral,neutral,neutral,neutral
1681657989,"@frozenbugs This is hopefully the last fix I am making to this example. There still seems to be a bug when we use CPU sampling with inference, but I couldn't figure out why it happens.",hopefully last fix making example still bug use sampling inference could figure,issue,negative,neutral,neutral,neutral,neutral,neutral
1681629189,Also remove from the original code?,also remove original code,issue,negative,positive,positive,positive,positive,positive
1681626206,"@Rhett-Ying @frozenbugs Please help review, the cmake option has removed now",please help review option removed,issue,positive,neutral,neutral,neutral,neutral,neutral
1681559320,"Overall LGTM, please copy paste the model result to the PR description.",overall please copy paste model result description,issue,negative,neutral,neutral,neutral,neutral,neutral
1681519954,Closing this due to inactivity.  Please feel free to reopen if you have updates or further questions.  Thanks!,due inactivity please feel free reopen thanks,issue,positive,positive,positive,positive,positive,positive
1681483675,"I see, we already have UVA work on our todolist, will kick of the work soon.",see already uva work kick work soon,issue,negative,neutral,neutral,neutral,neutral,neutral
1681074013,I've been looking around but I've been unable to find a way to specify labels in `environment.yml`.,looking around unable find way specify,issue,negative,negative,negative,negative,negative,negative
1680997254,"I will open a PR updating to the new version, we don't have to merge it now. We can merge it when they officially announce the new release of CCCL.",open new version merge merge officially announce new release,issue,negative,positive,neutral,neutral,positive,positive
1680995245,@Rhett-Ying The fix they made at the CCCL repository seems to have solved the issue. I can compile with the new CCCL `branch/2.2.x` branch now.,fix made repository issue compile new branch,issue,negative,positive,positive,positive,positive,positive
1680872049,"I am, but I think we need the UVA functionality for GraphBolt first. Otherwise, this PR won't be very useful.",think need uva functionality first otherwise wo useful,issue,negative,positive,positive,positive,positive,positive
1680611614,"As shown in our [start page](https://www.dgl.ai/pages/start.html), you could install CUDA 11.8 by specifying the label:
```python
conda install -c dglteam/label/cu118 dgl
```
Maybe you could specify labels in the same way in `environment.yml` file?",shown start page could install label python install maybe could specify way file,issue,negative,neutral,neutral,neutral,neutral,neutral
1680492490,I'll close this issue as the discussion is ongoing in the [referred discussion forum post](https://discuss.dgl.ai/t/very-intriguing-trial-graphsage-feature-request-feature-instruction-exploring-the-feasibility-of-implementing-asymmetric-node-feature-masking-slicing/3908),close issue discussion ongoing discussion forum post,issue,negative,neutral,neutral,neutral,neutral,neutral
1680315352,"@Rhett-Ying Comments are fixed, please help to have a review",fixed please help review,issue,positive,positive,neutral,neutral,positive,positive
1680222842,"So the main question is how to enable user to control the build behavior of underlying separate modules such as `tensoradaptor` more freely. For now, DGL passes down several envs/variables such as `TORCH_PYTHON_INTERPS`, `TORCH_CUDA_ARCH_LIST`, `USE_CUDA` and so on.

As we don't see any other required envs/variables or any must-have support for now, I think let's keep it. Even if we needs to add some other controls on downstream module's build, we could follow the existing way: add into top-level `CMakeLists.txt` and update corresponding `build.sh/bat`.",main question enable user control build behavior underlying separate freely several see support think let keep even need add downstream module build could follow way add update corresponding,issue,positive,positive,neutral,neutral,positive,positive
1680150468,"> Hi @initzhang Actually I don't think it's a good idea to always blindly pass c/cxx flags defined at the top level down to tensoradaptor build as it may incur unexpected errors. We already have dedicated build script/makefile which controls the build behavior on its own.

Hi @Rhett-Ying , thanks for reply! maybe blindly passing flags is not desired, but I think there should at least be some warnings/notifications when user setting their C/CXX flags. I think it is not a rare case where users have multiple versions of gcc/g++ installed on their machine. And once user have specified one version, I think they should be reminded that __some part of the build__ does not use the specified version.  

",hi actually think good idea always blindly pas defined top level build may incur unexpected already build build behavior hi thanks reply maybe blindly passing desired think least user setting think rare case multiple machine user one version think part use version,issue,positive,positive,neutral,neutral,positive,positive
1680119381,Hi @initzhang  Actually I don't think it's a good idea to always blindly pass c/cxx flags defined at the top level down to tensoradaptor build as it may incur unexpected errors. We already have dedicated build script/makefile which controls the build behavior on its own.,hi actually think good idea always blindly pas defined top level build may incur unexpected already build build behavior,issue,positive,positive,positive,positive,positive,positive
1678357440,"> Finished the Regression test. Result table is at https://dgl-asv-data.s3-us-west-2.amazonaws.com/74049cc18a369b473c9c17e5066586ecd02f146a_r6i16xlarge/results/result.csv. Jenkins job link is https://dgl-jenkins-eksvpc-2136217999.us-west-2.elb.amazonaws.com/job/dgl/job/PR-6134/8/display/redirect.

LGTM",finished regression test result table job link,issue,negative,neutral,neutral,neutral,neutral,neutral
1676887692,"Users now need to provide the directory path of the dataset:
```py
dataset = gb.OnDiskDataset(dataset_dir)
```

Unlike previously, where data loading happened during initialization, `OnDiskDataset` now allows users to modify certain settings, such as:
```py
dataset.yaml_data[""dataset_name""] = ""new_dataset""
```
Afterwards, data is explicitly loaded with `.load()`. By introducing the `_convert_yaml_path_to_absolute_path` function, relative paths in the YAML are converted to absolute paths during the `.load()` call, making it more convenient for users during various operations.",need provide directory path unlike previously data loading modify certain afterwards data explicitly loaded function relative converted absolute call making convenient various,issue,negative,positive,neutral,neutral,positive,positive
1676826268,"The issue is finished, maybe we can close it.",issue finished maybe close,issue,negative,neutral,neutral,neutral,neutral,neutral
1676674408,Start the Regression test. View at https://dgl-jenkins-eksvpc-2136217999.us-west-2.elb.amazonaws.com/job/dgl/job/PR-6134/8/display/redirect,start regression test view,issue,negative,neutral,neutral,neutral,neutral,neutral
1676585269,"As upgrade to c++17 does not resolve this build issue, let's wait to see if CCCL resolves the build issue. And c++ has already updated to `17` on master branch. Let's close this one.",upgrade resolve build issue let wait see build issue already master branch let close one,issue,negative,neutral,neutral,neutral,neutral,neutral
1676581593,"As discussed above, let's merge this into master and to see if CCCL resolves the build issue on windows+cuda.",let merge master see build issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1676569548,"As a conclusion, let's wait the [CCCL](https://github.com/NVIDIA/cccl) release to see if could resolve this issue. For now CCCL is setting up windows CI: https://github.com/NVIDIA/cccl/issues/248. ",conclusion let wait release see could resolve issue setting,issue,negative,neutral,neutral,neutral,neutral,neutral
1676556967,Let's hold on this PR as we need more discussion about the support for graph classification in GraphBolt.,let hold need discussion support graph classification,issue,negative,neutral,neutral,neutral,neutral,neutral
1676284987,"> @ndbaker1 Hi, are you still working on this PR, what's the status of it?

hi @frozenbugs, I'm still working on these changes but response time may vary as it has been difficult to allocate time for work.

As of now the documentation is updated and sanity checks are running, so it will move out of draft status ðŸ‘ ",hi still working status hi still working response time may vary difficult allocate time work documentation sanity running move draft status,issue,negative,negative,negative,negative,negative,negative
1675889108,"I suggested we revert it because I couldn't find a way to fix the build error on Windows+cuda case. If you think windows+cuda release can simply exclude #5648 , that sounds alright. I think they will add windows CI to the CCCL repository (thrust, cub and libcudacxx now lives there) soon so we can update CCCL when that happens and windows build should start working then.",revert could find way fix build error case think release simply exclude alright think add repository thrust cub soon update build start working,issue,negative,neutral,neutral,neutral,neutral,neutral
1675799804,"> @Rhett-Ying Is it possible to modify the CI to include the windows+cu118 case as well? Then, this kind of issue won't arise as new functionalities are added to DGL.

For now, CI runs on windows+cpu only. We do need to include windows+gpu as well in the near future.",possible modify include case well kind issue wo arise new added need include well near future,issue,positive,positive,positive,positive,positive,positive
1675798492,"> We need to revert #5648 to fix #6135. But this PR will fix the static_assert issue encountered on the Windows build without modifying the labor sampling code. Also, it can still be merged if we want to upgrade to CXX17. @Rhett-Ying

Reverting #5648 is the only way to fix the build issue on windows_cuda? I hit this issue when cutting a new release, and for this release, I think it's ok to not cherry-pick #5648 . 

As for this PR, I tried it on windows+cu118, and it failed due to the #5648 . So if we revert it, this PR should be fine on windows.",need revert fix fix issue build without labor sampling code also still want upgrade way fix build issue hit issue cutting new release release think tried due revert fine,issue,negative,negative,neutral,neutral,negative,negative
1675517399,"I think when `torch::cat` is eliminated, the end code will be more than 10x faster than current code. Excited!",think torch end code faster current code excited,issue,negative,positive,positive,positive,positive,positive
1675463247,"We need to revert #5648 to fix #6135. But this PR will fix the static_assert issue encountered on the Windows build without modifying the labor sampling code. Also, it can still be merged if we want to upgrade to CXX17. @Rhett-Ying ",need revert fix fix issue build without labor sampling code also still want upgrade,issue,negative,neutral,neutral,neutral,neutral,neutral
1675448476,"I guess they don't have a CI for Windows builds yet. https://github.com/NVIDIA/cccl/issues/248.
So, we can possibly revert #5648 for now and wait for the cccl repository to get a Windows CI. Then we can reapply #5648 but this time use the latest tested CCCL version that includes the `DeviceCopy` feature.

We should also consider adding Windows+cuda case to the CI if possible.",guess yet possibly revert wait repository get reapply time use latest tested version feature also consider case possible,issue,negative,positive,positive,positive,positive,positive
1675416808,"I was able to reproduce the problem with windows visual studio 17 2022 + cuda 12.2 build. I am getting the following error:
```
10>C:\Users\Muhammed Fatih Balin\dgl-1\third_party\cccl\libcudacxx\include\cuda\std\detail\libcxx\include\__functional/invoke.h(413):
        error : ""cuda"" is ambiguous [C:\Users\Muhammed Fatih Balin\dgl-1\build\dgl.vcxproj]
             static decltype(cuda::std::__4::__invoke(cuda::std::__4::declval<_XFp>(), cuda::std::__4::declval<_XArgs>()...)) __try_call(
         int);
                             ^
                   detected during:
                     instantiation of class ""cuda::std::__4::__invokable_r<_Ret, _Fp, _Args...> [with _Ret=void, _Fp=dgl::aten::impl::<un
         named>::IndptrFunc<int32_t>, _Args=<signed int>]"" at line 475
                     instantiation of class ""cuda::std::__4::__invoke_of<_Fp, _Args...> [with _Fp=dgl::aten::impl::<unnamed>::IndptrFunc<
         int32_t>, _Args=<signed int>]"" at line 542
                     instantiation of class ""cuda::std::__4::invoke_result<_Fn, _Args...> [with _Fn=dgl::aten::impl::<unnamed>::IndptrFun
         c<int32_t>, _Args=<signed int>]"" at line 547
                     instantiation of type ""cuda::std::__4::invoke_result_t<dgl::aten::impl::<unnamed>::IndptrFunc<int32_t>, signed int>""
          at line 699 of C:/Users/Muhammed Fatih Balin/dgl-1/third_party/cccl/thrust\thrust/detail/type_traits.h
                     instantiation of type ""dgl::thrust::detail::invoke_result_t<dgl::aten::impl::<unnamed>::IndptrFunc<int32_t>, signed
         int>"" at line 41 of C:/Users/Muhammed Fatih Balin/dgl-1/third_party/cccl/thrust\thrust/detail/type_traits/result_of_adaptable_fu
         nction.h
                     [ 2 instantiation contexts not shown ]
                     instantiation of class ""dgl::thrust::detail::eval_if<true, Then, Else> [with Then=dgl::thrust::detail::result_of_ada
         ptable_function<dgl::aten::impl::<unnamed>::IndptrFunc<int32_t> (signed int), void>, Else=dgl::thrust::detail::identity_<dgl::th
         rust::use_default>]"" at line 49 of C:/Users/Muhammed Fatih Balin/dgl-1/third_party/cccl/thrust\thrust/iterator/detail/iterator_a
         daptor_base.h
                     instantiation of class ""dgl::thrust::detail::ia_dflt_help<T, DefaultNullaryFn> [with T=dgl::thrust::use_default, Def
         aultNullaryFn=dgl::thrust::detail::result_of_adaptable_function<dgl::aten::impl::<unnamed>::IndptrFunc<int32_t> (signed int), vo
         id>]"" at line 44 of C:/Users/Muhammed Fatih Balin/dgl-1/third_party/cccl/thrust\thrust/iterator/detail/transform_iterator.inl
                     instantiation of class ""dgl::thrust::detail::transform_iterator_base<UnaryFunc, Iterator, Reference, Value> [with Un
         aryFunc=dgl::aten::impl::<unnamed>::IndptrFunc<int32_t>, Iterator=dgl::thrust::counting_iterator<int32_t, dgl::thrust::use_defau
         lt, dgl::thrust::use_default, dgl::thrust::use_default>, Reference=dgl::thrust::use_default, Value=dgl::thrust::use_default]"" at
          line 190 of C:/Users/Muhammed Fatih Balin/dgl-1/third_party/cccl/thrust\thrust/iterator/transform_iterator.h
                     instantiation of class ""dgl::thrust::transform_iterator<AdaptableUnaryFunction, Iterator, Reference, Value> [with Ad
         aptableUnaryFunction=dgl::aten::impl::<unnamed>::IndptrFunc<int32_t>, Iterator=dgl::thrust::counting_iterator<int32_t, dgl::thru
         st::use_default, dgl::thrust::use_default, dgl::thrust::use_default>, Reference=dgl::thrust::use_default, Value=dgl::thrust::use
         _default]"" at line 564 of C:\Users\Muhammed Fatih Balin\dgl-1\src\array\cuda\labor_sampling.cu
                     instantiation of ""std::pair<dgl::aten::COOMatrix, dgl::IdArray> dgl::aten::impl::CSRLaborSampling<XPU,IdType,FloatTy
         pe>(dgl::aten::CSRMatrix, dgl::IdArray, int64_t, dgl::FloatArray, int, dgl::IdArray, float, dgl::IdArray) [with XPU=kDGLCUDA, Id
         Type=int32_t, FloatType=float]"" at line 819 of C:\Users\Muhammed Fatih Balin\dgl-1\src\array\cuda\labor_sampling.cu
         ```",able reproduce problem visual studio build getting following error error ambiguous static class un line class unnamed line class unnamed line type unnamed line type unnamed line shown class true else unnamed void rust line class unnamed id line class reference value un unnamed line class reference value ad unnamed st line float id line,issue,negative,positive,positive,positive,positive,positive
1675038909,"@Rhett-Ying Is it possible to modify the CI to include the windows+cu118 case as well? Then, this kind of issue won't arise as new functionalities are added to DGL.",possible modify include case well kind issue wo arise new added,issue,positive,positive,positive,positive,positive,positive
1675035475,"Also, are we sure that the changes here enable c++17 compilation for the windows build as well?",also sure enable compilation build well,issue,positive,positive,positive,positive,positive,positive
1675029268,"@Rhett-Ying could you try with the newly added commits also? Also, if there is a chance I can setup the same windows build environment, how can I do that?

EDIT: I tried, it doesn't work. We have to wait for the thrust repository to get their windows CI.",could try newly added also also chance setup build environment edit tried work wait thrust repository get,issue,negative,positive,positive,positive,positive,positive
1675025283,"DeviceCopy was added recently to CUB. To make use of it, we updated the submodule thrust version. However, I don't know why it would break the existing release workflow for windows.",added recently cub make use thrust version however know would break release,issue,negative,neutral,neutral,neutral,neutral,neutral
1674972140,"@Rhett-Ying The latest versions of thrust, cub, etc. are now in the https://github.com/NVIDIA/cccl repository.

Why is there a difference in behavior between the CI and when it comes to compiling for a new release? If I want to help
with the build issue, how can I do so? Also, it looks like the latest versions of thrust and cub, etc. are deprecating c++11 and c++14 support.

The CI in the thrust repository has CUDA 11.1, so the cuda version or the driver shouldn't be the issue.",latest thrust cub repository difference behavior come new release want help build issue also like latest thrust cub support thrust repository version driver issue,issue,positive,positive,positive,positive,positive,positive
1674348965,Failed to build GPU version on CI. So the `thrust` is too up-to-date? or cuda driver should be updated? ,build version thrust driver,issue,negative,neutral,neutral,neutral,neutral,neutral
1674329741,"probably cuda driver needs to be updated as [DeviceCopy](https://github.com/NVIDIA/cub/blame/b2e8bccb8c0cd15279974fe4b9b8d6fcd1842b57/cub/device/device_copy.cuh#L48) was added 4 months ago.

any ideas on this? @mfbalin ",probably driver need added ago,issue,negative,neutral,neutral,neutral,neutral,neutral
1674319162,"after update `thurst` in https://github.com/dmlc/dgl/pull/6139, many errors are gone.

those lines are added in https://github.com/dmlc/dgl/pull/5648

<img width=""1087"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/85214957/fd2e603f-667b-4076-b51e-5ed513111254"">
",update many gone added image,issue,negative,positive,positive,positive,positive,positive
1674276299,let me try to update `thrust`.,let try update thrust,issue,negative,neutral,neutral,neutral,neutral,neutral
1674274671,"Excellent, the test is way cleaner now.",excellent test way cleaner,issue,positive,positive,positive,positive,positive,positive
1674227979,"same issue on windows + vs2019 with this PR's branch
<img width=""647"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/85214957/9a911331-05b9-432b-a3c0-49e437b940a0"">


<img width=""1092"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/85214957/2d007179-12b5-4198-80d8-8ea8bfb4a7fc"">
",issue branch image image,issue,negative,neutral,neutral,neutral,neutral,neutral
1674195858,"@Rhett-Ying I don't know why we still need to pass the `-std=c++17` flag to NVCC manually, but let's see if everything will work with this patch. If CI passes, we can check if #6135 is resolved also.",know still need pas flag manually let see everything work patch check resolved also,issue,negative,neutral,neutral,neutral,neutral,neutral
1674184938,"I agree, it might help. We can attempt to upgrade to c++17 again.",agree might help attempt upgrade,issue,positive,neutral,neutral,neutral,neutral,neutral
1674182420,"@mfbalin errors thrown with `thrust` still exist even resolve the `static_assert`. Maybe build with c++17 works.
<img width=""1093"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/85214957/03b41172-8da2-4b9e-8225-20da233bb4a8"">
",thrown thrust still exist even resolve maybe build work image,issue,negative,neutral,neutral,neutral,neutral,neutral
1674139911,"Hi @Rhett-Ying, that line has a `static_assert`, `static_assert` with no error message in 2nd argument is available only in c++17. We can fix it by adding a second argument such as ""alignment requirement is not met!"".
https://en.cppreference.com/w/cpp/language/static_assert",hi line error message argument available fix second argument alignment requirement met,issue,negative,positive,positive,positive,positive,positive
1674125376,"@mfbalin Hi, have you ever tried to build on windows with cuda? Do you have any ideas on the build error I posted above?",hi ever tried build build error posted,issue,negative,neutral,neutral,neutral,neutral,neutral
1672761956,nit: better to add test.,nit better add test,issue,negative,positive,positive,positive,positive,positive
1672623719,"> Commit ID: [375c315](https://github.com/dmlc/dgl/commit/375c31521c5ce5a3ac60412fdbc22652b9f0eb36)
> 
> Build ID: 1
> 
> Status: âŒ CI test failed in Stage [CPU Build].
> 
> Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6126/1/1/logs/report.html)
> 
> Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6126/1/1/logs/cireport.log)

manually killed ci, since no need to run.",commit id build id status test stage build report path link full path link manually since need run,issue,negative,positive,positive,positive,positive,positive
1672618624,"> `DGLGO` is out of maintain? DGLGO CI has already been disabled.

Yes, I just noticed the empty file, if it is safe to remove, I will remove it in the PR.",maintain already disabled yes empty file safe remove remove,issue,positive,positive,neutral,neutral,positive,positive
1672609262,@BarclayII please check whether dglgo/dglgo/utils/optimizer_config.py is safe to remove.,please check whether safe remove,issue,positive,positive,positive,positive,positive,positive
1672472747,Then I will create more PRs in the future that follow similar conventions to the DGL example you pointed out to better highlight different features. We can merge this PR anytime that works in that case.,create future follow similar example pointed better highlight different merge work case,issue,positive,positive,positive,positive,positive,positive
1672443793,"=========================== short test summary info ============================
FAILED tests/python/pytorch/nn/test_nn.py::test_graph_conv0[1] - dgl._ffi.base.DGLError: Cannot assign node feature ""h"" on device cuda:0 to a graph on device cpu. Call DGLGraph.to() to copy the graph to the same device.
FAILED tests/python/pytorch/nn/test_nn.py::test_graph_conv0[2] - dgl._ffi.base.DGLError: Cannot assign node feature ""h"" on device cuda:0 to a graph on device cpu. Call DGLGraph.to() to copy the graph to the same device.
FAILED tests/python/pytorch/nn/test_nn.py::test_dense_cheb_conv[1] - TypeError: from_scipy() got an unexpected keyword argument 'readonly'
FAILED tests/python/pytorch/nn/test_nn.py::test_dense_cheb_conv[2] - TypeError: from_scipy() got an unexpected keyword argument 'readonly'
FAILED tests/python/pytorch/nn/test_nn.py::test_hgt[1-4-idtype0] - ValueError: num_workers must be 0 if graph and indices are on CUDA.
FAILED tests/python/pytorch/nn/test_nn.py::test_hgt[1-4-idtype1] - ValueError: num_workers must be 0 if graph and indices are on CUDA.
FAILED tests/python/pytorch/nn/test_nn.py::test_group_rev_res[idtype0] - AttributeError: 'Tensor' object has no attribute 'untyped_storage'
FAILED tests/python/pytorch/nn/test_nn.py::test_group_rev_res[idtype1] - AttributeError: 'Tensor' object has no attribute 'untyped_storage'
==== 8 failed, 4538 passed, 272 skipped, 125 warnings in 250.12s (0:04:10) =====",short test summary assign node feature device graph device call copy graph device assign node feature device graph device call copy graph device got unexpected argument got unexpected argument must graph index must graph index object attribute object attribute,issue,negative,positive,neutral,neutral,positive,positive
1672442508,"@ndbaker1 Hi, are you still working on this PR, what's the status of it?",hi still working status,issue,negative,neutral,neutral,neutral,neutral,neutral
1672404260,Thank you for taking you time to review and response my issue!,thank taking time review response issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1670806191,"> I read the original paper(https://arxiv.org/pdf/1511.05493.pdf) and the code here (https://github.com/chingyaoc/ggnn.pytorch/blob/0c7897fe9b05e9b4f9a963ff55bd3ad917ea734e/model.py#L69)
> 
> Generally speaking, in GatedGraphConv, the output dim(state dimension) must be no less than input dimension(annotation dimension)
> 
> We can **raise a ValueError** when input dimension is greater than output dimension @czkkkkkk @frozenbugs

Thanks! Could you make a PR to fix it?",read original paper code generally speaking output dim state dimension must le input dimension annotation dimension raise input dimension greater output dimension thanks could make fix,issue,positive,positive,positive,positive,positive,positive
1670796535,"I read the original paper(https://arxiv.org/pdf/1511.05493.pdf) and the code here (https://github.com/chingyaoc/ggnn.pytorch/blob/0c7897fe9b05e9b4f9a963ff55bd3ad917ea734e/model.py#L69)

Generally speaking, in GatedGraphConv, the output dim(state dimension) must be no less than input dimension(annotation dimension)

We can **raise a ValueError** when input dimension is greater than output dimension
@czkkkkkk @frozenbugs ",read original paper code generally speaking output dim state dimension must le input dimension annotation dimension raise input dimension greater output dimension,issue,positive,positive,positive,positive,positive,positive
1670768582,"I haven't tested the ""Graph Contrastive Coding"" author code. I mean if you want to run DGL with the latest CUDA version, you need to install the latest DGL version and also remove some deprecated DGL interfaces (e.g., dgl.nodeflow) in the your code.",tested graph contrastive author code mean want run latest version need install latest version also remove code,issue,negative,positive,positive,positive,positive,positive
1670629785,"Commit ID: b2fb3b8c4e31a2fec8c39d1ab138ff3fdca323ef

Build ID: 7

Status: âŒ CI test failed in Stage [Distributed].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6112/7/7/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-6112/7/7/logs/cireport.log)",commit id build id status test stage distributed report path link full path link,issue,negative,positive,positive,positive,positive,positive
1670577921,"No, we don't have plan to support Tensorflow in near future.",plan support near future,issue,negative,positive,neutral,neutral,positive,positive
1670565611,Is there a schedule in a short period of time?,schedule short period time,issue,negative,neutral,neutral,neutral,neutral,neutral
1669997582,"@drivanov thanks for your effort! However, for R-GCN, we cannot add any nodes' features into the model. When we use our own dataset, it is too troublesome to change the original message_func and apply_func.

could you give any convenient ways? Or could you add this new function?

thanks and best regards.",thanks effort however add model use troublesome change original could give convenient way could add new function thanks best,issue,positive,positive,positive,positive,positive,positive
1669550525,"I run into the following problem:

cmake -DUSE_OPENMP=off -DCMAKE_C_FLAGS='-DXBYAK_DONT_USE_MAP_JIT' -DCMAKE_CXX_FLAGS='-DXBYAK_DONT_USE_MAP_JIT' -DUSE_AVX=OFF -DUSE_LIBXSMM=OFF ..
-- Start configuring project dgl
-- Disabling LIBXSMM on arm64.
CMake Warning at CMakeLists.txt:197 (message):
  EPOLL is not available on this platform...

CMake Error at CMakeLists.txt:266 (add_subdirectory):
  The source directory
 /Users/haimonti/Research/GraphNeuralNetworks/Code/dgl/third_party/dmlc-core
does not contain a CMakeLists.txt file.

CMake Error at CMakeLists.txt:273 (include):
  include could not find requested file:
/Users/haimonti/Research/GraphNeuralNetworks/Code/dgl/third_party/METIS/GKlib/GKlibSystem.cmake

CMake Error at CMakeLists.txt:276 (add_subdirectory):
  add_subdirectory given source ""third_party/METIS/libmetis/"" which is not an
  existing directory.

Any suggestions? I did install Cython as suggested above, but that did not resolve the problem either.
",run following problem start project arm warning message available platform error source directory contain file error include include could find file error given source directory install resolve problem either,issue,negative,positive,positive,positive,positive,positive
1668983029,"For the examples in example zoo which demonstrates users' research work, I think your current code is good enough.",example zoo research work think current code good enough,issue,negative,positive,positive,positive,positive,positive
1668979988,"> @frozenbugs @peizhou001 could you take a look? Any suggestions on how to improve this example further?

The key to a usage-demonstration example is, to make it as simple as possible and highlight the demonstrated usage.
In the long run, we will start promote the examples in the new example structure as we kicked off in the https://github.com/dmlc/dgl/tree/master/examples. You can see there are various example directories that groups examples for different purpose.

For labor sample, I would suggest you focus on the sampling part without showing off the unrelated coding / modeling skills, and make it an advanced example in examples/advanced/labor/. You can use this [code](https://github.com/dmlc/dgl/blob/master/examples/sampling/node_classification.py), which focuses on highlighting neighbor sampling, as an example for your labor example, to create an similar example but only replace the sampling code with your sampler and GPU cache, and highlight them with consistent format, such that you can attract users' eyes without adding frictions when they read your example.",could take look improve example key example make simple possible highlight usage long run start promote new example structure see various example different purpose labor sample would suggest focus sampling part without showing unrelated modeling make advanced example use code neighbor sampling example labor example create similar example replace sampling code sampler cache highlight consistent format attract without read example,issue,positive,positive,neutral,neutral,positive,positive
1667300630,"I went through the current implementation of `DGLGraph` construction and conversion, it looks good to me except for the format is handled in dictionary object parsed from `YAML` file.

A better implementation could be wrapped with `pydantic` like [OnDiskMetaData](https://github.com/dmlc/dgl/blob/8e86c89c3a8ca62f87574ca6a95b79d0be23d418/python/dgl/graphbolt/impl/ondisk_metadata.py#L74) which help on data validation.",went current implementation construction conversion good except format handled dictionary object file better implementation could wrapped like help data validation,issue,positive,positive,positive,positive,positive,positive
1667299969,"> @caojy1998 for the record, please elaborate the root cause and details of fix here.

OK, I have added the description and fix solution.",record please elaborate root cause fix added description fix solution,issue,positive,positive,positive,positive,positive,positive
1667266725,"No, but make sure report error properly such that user knows what to fix.",make sure report error properly user fix,issue,negative,positive,positive,positive,positive,positive
1667266254,"@caojy1998 for the record, please elaborate the root cause and details of fix here.",record please elaborate root cause fix,issue,negative,positive,positive,positive,positive,positive
1667262897,"This is needed if we support loading from a user provided CSCSamplingGraph, for now we only support user provided COO, so it is ok to skip this work for now.",support loading user provided support user provided coo skip work,issue,positive,neutral,neutral,neutral,neutral,neutral
1667232695,"@frozenbugs  what kinds of validation are supposed to do in this work item? Validations of data members of `CSCSamplingGraph` has already been included in various `TORCH_CHECK` such as https://github.com/dmlc/dgl/blob/cff938c6adbac28fe38ef10079a51fe3f8d97d3e/graphbolt/src/csc_sampling_graph.cc#L32-L34, https://github.com/dmlc/dgl/blob/cff938c6adbac28fe38ef10079a51fe3f8d97d3e/graphbolt/src/csc_sampling_graph.cc#L42-L54 and so on.",validation supposed work item data already included various,issue,negative,neutral,neutral,neutral,neutral,neutral
1667221348,"highly depends on #5808, #5813, #5814. when dependent work items finish, we just need to elaborate such data format in doc page.",highly dependent work finish need elaborate data format doc page,issue,negative,positive,positive,positive,positive,positive
1667218774,"@frozenbugs In current implementation of `OnDiskDataset` and [graph loading](https://github.com/dmlc/dgl/blob/cff938c6adbac28fe38ef10079a51fe3f8d97d3e/python/dgl/graphbolt/impl/ondisk_dataset.py#L68-L131) which have already covered the validation, do we still need a dedicated script to validate COO graph topology? or what is the detailed requirement for this work item?",current implementation graph loading already covered validation still need script validate coo graph topology detailed requirement work item,issue,negative,positive,positive,positive,positive,positive
1667215386,"COO graph topology data format (part of `OnDiskDataset`) is shown below:
```
graph: # graph structure and required attributes.
  nodes:
    - type: author
      num: 1024
    - type: paper
      num: 2048
  edges:
    - type: 'author:writes:paper'
      format: csv
      path: edges/writes.csv
    - type: 'paper:cites:paper'
      format: csv
      path: edges/cites.csv
  feature_data: # edge attributed could be added here as edge feature.
    - domain: edge
      type: 'author:write:paper'
      name: prob
      format: numpy
      in_memory: true
      path: edge_data/write-prob.npy
```

Such graph will be constructed as `DGLGraph` first, then convert `CSCSamplingGraph` via [from_dglgraph()](https://github.com/dmlc/dgl/blob/cff938c6adbac28fe38ef10079a51fe3f8d97d3e/python/dgl/graphbolt/impl/csc_sampling_graph.py#L712).",coo graph topology data format part shown graph graph structure type author type paper type format path type format path edge could added edge feature domain edge type write name prob format true path graph first convert via,issue,negative,positive,positive,positive,positive,positive
1667206139,"TVT for link prediction/classification such as `node pair`, `(src, dst, label)`, `(src, dst, neg_srcs, neg_dsts)` are already supported in [OnDiskDataset](https://github.com/dmlc/dgl/blob/cff938c6adbac28fe38ef10079a51fe3f8d97d3e/python/dgl/graphbolt/impl/ondisk_dataset.py#L213).

`CSCSamplingGraph` is also supported in `OnDiskDataset`.",link node pair label already also,issue,negative,neutral,neutral,neutral,neutral,neutral
1667087698,Thanks for taking time to make DGL example code excellent!,thanks taking time make example code excellent,issue,positive,positive,positive,positive,positive,positive
1666950507,@frozenbugs @peizhou001 could you take a look? Any suggestions on how to improve this example further?,could take look improve example,issue,negative,neutral,neutral,neutral,neutral,neutral
1664918650,"reverted, suspicious since it might break the CI.",suspicious since might break,issue,negative,neutral,neutral,neutral,neutral,neutral
1664903607,"> @keli-wen see the comment above for the CI failure.

get",see comment failure get,issue,negative,negative,negative,negative,negative,negative
1664898806,"_____________________ test_OnDiskDataset_preprocess_path ______________________

    def test_OnDiskDataset_preprocess_path():
        """"""Test if the preprocess function can catch the path error.""""""
        with tempfile.TemporaryDirectory() as test_dir:
            # All metadata fields are specified.
            dataset_name = ""graphbolt_test""
            num_classes = 10
            num_labels = 9
    
            yaml_content = f""""""
                dataset_name: {dataset_name}
                num_classes: {num_classes}
                num_labels: {num_labels}
            """"""
            yaml_file = os.path.join(test_dir, ""metadata.yaml"")
            with open(yaml_file, ""w"") as f:
                f.write(yaml_content)
    
            # Case1. Test the passed in is the yaml file path.
            with pytest.raises(
                RuntimeError,
                match=rf""The dataset must be a directory. But got {yaml_file}"",
            ):
>               _ = gb.OnDiskDataset(yaml_file)

tests\python\pytorch\graphbolt\test_ondisk_dataset.py:1046: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <dgl.graphbolt.impl.ondisk_dataset.OnDiskDataset object at 0x0000005182C4BC08>
path = 'C:\\Users\\Administrator\\AppData\\Local\\Temp\\tmpb1xng_vv\\metadata.yaml'

    def __init__(self, path: str) -> None:
        # Always call the preprocess function first. If already preprocessed,
        # the function will return the original path directly.
>       path = preprocess_ondisk_dataset(path)

python\dgl\graphbolt\impl\ondisk_dataset.py:303: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

dataset_dir = 'C:\\Users\\Administrator\\AppData\\Local\\Temp\\tmpb1xng_vv\\metadata.yaml'

    def preprocess_ondisk_dataset(dataset_dir: str) -> str:
        """"""Preprocess the on-disk dataset. Parse the input config file,
        load the data, and save the data in the format that GraphBolt supports.
    
        Parameters
        ----------
        dataset_dir : str
            The path to the dataset directory.
    
        Returns
        -------
        output_config_path : str
            The path to the output config file.
        """"""
        # Check if the dataset path is valid.
        if not os.path.exists(dataset_dir):
            raise RuntimeError(f""Invalid dataset path: {dataset_dir}"")
    
        # Fix all paths under dataset_dir.
>       with fix_dataset_dir(dataset_dir):

python\dgl\graphbolt\impl\ondisk_dataset.py:68: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

self = <contextlib._GeneratorContextManager object at 0x0000005182C4B3C8>

    def __enter__(self):
        # do not keep args and kwds alive unnecessarily
        # they are only needed for recreation, which is not possible anymore
        del self.args, self.kwds, self.func
        try:
>           return next(self.gen)

c:\users\administrator\appdata\local\programs\python\python37\lib\contextlib.py:112: 
_ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _ _

path = 'C:\\Users\\Administrator\\AppData\\Local\\Temp\\tmpb1xng_vv\\metadata.yaml'

    @contextmanager
    def fix_dataset_dir(path):
        """"""Fix the dataset directory path.""""""
        old_pwd = os.getcwd()
        if not os.path.isdir(path):
>           raise RuntimeError(f""The dataset must be a directory. But got {path}"")
E           RuntimeError: The dataset must be a directory. But got C:\Users\Administrator\AppData\Local\Temp\tmpb1xng_vv\metadata.yaml

python\dgl\graphbolt\impl\ondisk_dataset.py:41: RuntimeError",test function catch path error open case test file path must directory got self object path self path none always call function first already function return original path directly path path parse input file load data save data format path directory path output check path valid raise invalid path fix self object self keep alive unnecessarily recreation possible try return next path path fix directory path path raise must directory got path must directory got,issue,positive,positive,neutral,neutral,positive,positive
1664898710,TVT set has been changed from list of list to list in https://github.com/dmlc/dgl/pull/6080,set list list list,issue,negative,neutral,neutral,neutral,neutral,neutral
1664886205,"As we have changed the TVT format on disk which requires user to pass in `src`, `dst`, `neg_src`, `neg_dst` or any other items in this format and will be further constructed as tuple for `ItemSet` or `ItemSetDict`, the output of `MinibatchSampler` is in tuple then.

We decided to keep this tuple format which is flexible for use instead of combining into `b*2` tensor for `src/dst`.",format disk user pas format output decided keep format flexible use instead combining tensor,issue,negative,neutral,neutral,neutral,neutral,neutral
1663561040,"Thank you for responding. Keeping the original edge numbers is a reasonable approach. To meet my requirement of removing the repeated edges, I can simply utilize the function ""dgl to_simple().""",thank keeping original edge reasonable approach meet requirement removing repeated simply utilize function,issue,positive,positive,positive,positive,positive,positive
1663502403,"Oh, thanks for the reminder, I was waiting for the GPUCache PR's building issue get fix.",oh thanks reminder waiting building issue get fix,issue,negative,positive,positive,positive,positive,positive
1663227173,"What other changes are required to merge this PR? @frozenbugs

This PR includes everything required to reproduce all the results in the Labor paper and also the kappa feature experiments in the cooperative minibatching paper.",merge everything reproduce labor paper also kappa feature paper,issue,negative,neutral,neutral,neutral,neutral,neutral
1663225344,"Hi @czkkkkkk,

Okay, thank you very much for the information. I really appreciate your help. To ensure compatibility, could you please provide more details about the machine you ran the code on? Specifically, I would need information about the operating system, GPU model, and CUDA version you used. This will help me set up my environment with the same configuration and install the correct dependencies accordingly. (And please include more information that is relevant for running a GitHub project like yours.) 

Looking forward to your response. Thanks again for your assistance!",hi thank much information really appreciate help ensure compatibility could please provide machine ran code specifically would need information operating system model version used help set environment configuration install correct accordingly please include information relevant running project like looking forward response thanks assistance,issue,positive,positive,positive,positive,positive,positive
1663190626,"Hi, @jingweio, this is because the original graph have multi-edges between user nodes, so it expected to keep them after conversion. ",hi original graph user keep conversion,issue,negative,positive,positive,positive,positive,positive
1663160525,"Hi @JohnyWaffle, our old DGL version does not support CUDA 11.3. Since some modules used in the algorithm is deprecated in DGL, you may need to modify the author code to run it with latest DGL and CUDA 11.3.",hi old version support since used algorithm may need modify author code run latest,issue,negative,positive,positive,positive,positive,positive
1662014758,@mfbalin Can you take a look at this change and the plan for the optimization in the Description section.,take look change plan optimization description section,issue,negative,neutral,neutral,neutral,neutral,neutral
1661595343,"If you use the new version of DGL, you can dump a new graph pkl file. ",use new version dump new graph file,issue,negative,positive,positive,positive,positive,positive
1661455080,This is a known issue. Please refer to https://github.com/dmlc/dgl/issues/5574.,known issue please refer,issue,negative,neutral,neutral,neutral,neutral,neutral
1661452031,"because i must read some files encoded in the old DGL version,These files cannot be read with the latest
&nbsp;


å­”æ˜Žç¾½
***@***.***



&nbsp;




------------------&nbsp;åŽŸå§‹é‚®ä»¶&nbsp;------------------
å‘ä»¶äºº: ***@***.***&gt;; 
å‘é€æ—¶é—´: 2023å¹´8æœˆ2æ—¥(æ˜ŸæœŸä¸‰) ä¸­åˆ11:44
æ”¶ä»¶äºº: ***@***.***&gt;; 
æŠ„é€: ***@***.***&gt;; ***@***.***&gt;; 
ä¸»é¢˜: Re: [dmlc/dgl] dgl._ffi.base.DGLError: [17:19:38] /opt/dgl/src/runtime/c_runtime_api.cc:88: Check failed: allow_missing: Device API gpu is not enabled. Please install the cuda version of dgl. (Issue #6078)





 
Hi @BEILOP, could you try the latest DGL version?
 
â€”
Reply to this email directly, view it on GitHub, or unsubscribe.
You are receiving this because you were mentioned.Message ID: ***@***.***&gt;",must read old version read latest check device please install version issue hi could try latest version reply directly view id,issue,negative,positive,positive,positive,positive,positive
1661443969,"Hi @BEILOP, could you try the latest DGL version?",hi could try latest version,issue,negative,positive,positive,positive,positive,positive
1661373405,"@TristonC I built with g++ 9.4, CUDA is ON. Compared to build with g++11.3.0, some symbols are missing even the code is same.",built build missing even code,issue,negative,negative,negative,negative,negative,negative
1661106620,@mfbalin I have not tried g++ 9 yet as we have been using g++ 11. I will see if I can test on g++ 9.,tried yet see test,issue,negative,neutral,neutral,neutral,neutral,neutral
1660344483,"CI failed, but it seems that the fail has nothing to do with my PR, as the UT test_gat with GPU succeed, but the UT failed with  CPU. And the UT passed in my local environment.",fail nothing ut succeed ut ut local environment,issue,negative,negative,negative,negative,negative,negative
1659847812,Please also add unit test for this 2 new types.,please also add unit test new,issue,negative,positive,positive,positive,positive,positive
1659836842,"> Thanks for the fixing, can you break 2 unrelated changes to 2 PRs?
> 
> For extract_archive, instead of changing the default value to True, what about change the documentation to False since our customer may already have code that works without setting the overwrite, we don't want to accidentally break them.

OK, I have removed the change of extract_archive().
The reason I set the default value of overwrite to true is that overwrite in the function download() is true also

`
def download(
    url,
    path=None,
    overwrite=True,
    sha1_hash=None,
    retries=5,
    verify_ssl=True,
    log=True,
):
`",thanks fixing break unrelated instead default value true change documentation false since customer may already code work without setting overwrite want accidentally break removed change reason set default value overwrite true overwrite function true also,issue,positive,positive,positive,positive,positive,positive
1659796019,"Thanks for the fixing, can you break 2 unrelated changes to 2 PRs?

For extract_archive, instead of changing the default value to True, what about change the documentation to False since our customer may already have code that works without setting the overwrite, we don't want to accidentally break them.",thanks fixing break unrelated instead default value true change documentation false since customer may already code work without setting overwrite want accidentally break,issue,positive,positive,neutral,neutral,positive,positive
1659628334,"> @caojy1998 could you check if the compilation issue is resolved on your end as well?

Seems work to me, thanks!",could check compilation issue resolved end well work thanks,issue,positive,positive,positive,positive,positive,positive
1659580471,"Below is built with g++ 11.3.0 with c++14 and together with [patch](https://github.com/dmlc/dgl/pull/6072).
```
0000000001977ae6 R _ZN3dgl17DGLDataTypeTraitsI13__nv_bfloat16E5dtypeE
0000000001977aea R _ZN3dgl17DGLDataTypeTraitsI6__halfE5dtypeE
0000000001977b06 R _ZN3dgl17DGLDataTypeTraitsIaE5dtypeE
0000000001977ade R _ZN3dgl17DGLDataTypeTraitsIdE5dtypeE
0000000001977ae2 R _ZN3dgl17DGLDataTypeTraitsIfE5dtypeE
0000000001977b02 R _ZN3dgl17DGLDataTypeTraitsIhE5dtypeE
0000000001977afa R _ZN3dgl17DGLDataTypeTraitsIiE5dtypeE
0000000001977af2 R _ZN3dgl17DGLDataTypeTraitsIjE5dtypeE
0000000001977af6 R _ZN3dgl17DGLDataTypeTraitsIlE5dtypeE
0000000001977aee R _ZN3dgl17DGLDataTypeTraitsImE5dtypeE
0000000001977afe R _ZN3dgl17DGLDataTypeTraitsIsE5dtypeE
```",built together patch ae ade ae,issue,negative,neutral,neutral,neutral,neutral,neutral
1659575519,@caojy1998 could you check if the compilation issue is resolved on your end as well?,could check compilation issue resolved end well,issue,negative,neutral,neutral,neutral,neutral,neutral
1659441936,"@TristonC, do you know why the undefined symbol issue might be arising with this PR and g++-9?",know undefined symbol issue might,issue,negative,neutral,neutral,neutral,neutral,neutral
1659416559,@mfbalin consider rollback this PR and the related PR https://github.com/dmlc/dgl/pull/6033 to avoid continuous CI failure for NV container.,consider rollback related avoid continuous failure container,issue,negative,negative,negative,negative,negative,negative
1658506037,@Rhett-Ying I also failed to build with g++-9 version as well after switching to C++17. There must be a fix we can employ so that it works across different compiler versions.,also build version well switching must fix employ work across different compiler,issue,negative,neutral,neutral,neutral,neutral,neutral
1658267593,"Thank you @czkkkkkk, it indeed works with the latest version.",thank indeed work latest version,issue,negative,positive,positive,positive,positive,positive
1657897242,"> @mfbalin Hi, I tried to build DGL gpu version with c++17 with this PR change(g++ 9.4.0) but failed to import dgl(though build is finished successfully.) with below error. Did you hit it?
> 
> ```
> File ~/workspace/dgl_1/python/dgl/_ffi/base.py:39, in _load_lib()
>      37 """"""Load libary by searching possible path.""""""
>      38 lib_path = libinfo.find_lib_path()
> ---> 39 lib = ctypes.CDLL(lib_path[0])
>      40 dirname = os.path.dirname(lib_path[0])
>      41 basename = os.path.basename(lib_path[0])
> 
> File ~/anaconda3/envs/dgl-dev-gpu-dgl-1/lib/python3.10/ctypes/__init__.py:374, in CDLL.__init__(self, name, mode, handle, use_errno, use_last_error, winmode)
>     371 self._FuncPtr = _FuncPtr
>     373 if handle is None:
> --> 374     self._handle = _dlopen(self._name, mode)
>     375 else:
>     376     self._handle = handle
> 
> OSError: /home/ubuntu/workspace/dgl_1/build/libdgl.so: undefined symbol: _ZN3dgl17DGLDataTypeTraitsI6__halfE5dtypeE
> ```
The undefined symbols could be found if build with `g++ 11.3.0`. So the behavior varies on g++ versions.
",hi tried build version change import though build finished successfully error hit file load searching possible path file self name mode handle handle none mode else handle undefined symbol undefined could found build behavior,issue,negative,positive,positive,positive,positive,positive
1657879097,"@mfbalin Hi, I tried to build DGL gpu version with c++17 with this PR change(g++ 9.4.0) but failed to import dgl(though build is finished successfully.) with below error. Did you hit it?

```
File ~/workspace/dgl_1/python/dgl/_ffi/base.py:39, in _load_lib()
     37 """"""Load libary by searching possible path.""""""
     38 lib_path = libinfo.find_lib_path()
---> 39 lib = ctypes.CDLL(lib_path[0])
     40 dirname = os.path.dirname(lib_path[0])
     41 basename = os.path.basename(lib_path[0])

File ~/anaconda3/envs/dgl-dev-gpu-dgl-1/lib/python3.10/ctypes/__init__.py:374, in CDLL.__init__(self, name, mode, handle, use_errno, use_last_error, winmode)
    371 self._FuncPtr = _FuncPtr
    373 if handle is None:
--> 374     self._handle = _dlopen(self._name, mode)
    375 else:
    376     self._handle = handle

OSError: /home/ubuntu/workspace/dgl_1/build/libdgl.so: undefined symbol: _ZN3dgl17DGLDataTypeTraitsI6__halfE5dtypeE
```",hi tried build version change import though build finished successfully error hit file load searching possible path file self name mode handle handle none mode else handle undefined symbol,issue,negative,positive,positive,positive,positive,positive
1657725716,"meet the same problem when using MNIST dataset at https://data.dgl.ai/dataset/benchmarking-gnns/MNIST.pkl

how to reproduce
``` bash
curl https://data.dgl.ai/dataset/benchmarking-gnns/MNIST.pkl -o MNIST.pkl -J -L -k

with open(""MNIST.pkl"",""rb"") as f:
          f = pickle.load(f)
```

error
```
Traceback (most recent call last):
  File ""test.py"", line 4, in <module>
    f = pickle.load(f)
AttributeError: Can't get attribute 'DGLHeteroGraph' on <module 'dgl.heterograph' from '/home/ubuntu/.local/lib/python3.8/site-packages/dgl/heterograph.py'>
```",meet problem reproduce bash curl open error recent call last file line module ca get attribute module,issue,negative,neutral,neutral,neutral,neutral,neutral
1657388778,"Hi @22842219, could you follow the bug report template to provide more details?",hi could follow bug report template provide,issue,negative,neutral,neutral,neutral,neutral,neutral
1656591444,"Besides, I would suggest split this PR into 2 PRs, first is just the change of `pick_fn`, then add `num_pick_fn`.",besides would suggest split first change add,issue,negative,positive,positive,positive,positive,positive
1655169929,Please also add unit test.,please also add unit test,issue,negative,neutral,neutral,neutral,neutral,neutral
1654907997,"> @songqing what about change it to ${DGL_HOME}/build or ${DGL_HOME}/downloads?
> 
> Both of them are reserved in .[gitingore](https://github.com/dmlc/dgl/blob/master/.gitignore#L14).

OK, I have changed it to ${DGL_HOME}/_download, which is also in .gitignore and maybe used before. 
<img width=""818"" alt=""f1"" src=""https://github.com/dmlc/dgl/assets/9260628/f52e6192-8bc2-4233-bad1-df0641d29570"">
",change reserved also maybe used,issue,negative,neutral,neutral,neutral,neutral,neutral
1653828803,"@caojy1998 seems like g++11 doesn't enable some c++17 features in c++14 mode while g++9 does. Modifying the main CMakeLists.txt file to enable c++17, I was able to compile with g++-12. Is it fine if DGL started using c++17 @frozenbugs @Rhett-Ying @yaox12 ? Pytorch switched to requiring c++17 long ago I think.",like enable mode main file enable able compile fine switched long ago think,issue,positive,positive,positive,positive,positive,positive
1653209799,"I met this error when I try to build dgl with gcc 11 and g++ 11 (build with gcc 9 and g++ 9 is OK). Does the change in this PR supports gcc 11 and g++ 11?
@mfbalin  @yaox12 
```
CMake Error at gpu_cache_generated_nv_gpu_cache.cu.o.cmake:276 (message):
  Error generating file
  /dgl/build/CMakeFiles/gpu_cache.dir/third_party/HugeCTR/gpu_cache/src/./gpu_cache_generated_nv_gpu_cache.cu.o


make[2]: *** [CMakeFiles/gpu_cache.dir/build.make:77: CMakeFiles/gpu_cache.dir/third_party/HugeCTR/gpu_cache/src/gpu_cache_generated_nv_gpu_cache.cu.o] Error 1
make[1]: *** [CMakeFiles/Makefile2:182: CMakeFiles/gpu_cache.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
```",met error try build build change error message error generating file make error make error make waiting unfinished,issue,negative,neutral,neutral,neutral,neutral,neutral
1653166740,"same error

## To Reproduce
1 bash script/create_dev_conda_env.sh -g 11.7
2 conda activate ***
3 bash script/build_dgl.sh -g -e '-DCMAKE_BUILD_TYPE=DEBUG'
4  python setup.py build_ext --inplace

## Error Report
[1/1] Cythonizing dgl/_ffi/_cython/core.pyx

Error compiling Cython file:
...
        """"""
        cdef DLManagedTensor* dltensor
        if self.c_is_view != 0:
            raise ValueError(""to_dlpack do not work with memory views"")
        CALL(DGLArrayToDLPack(self.chandle, &dltensor, alignment))
        return pycapsule.PyCapsule_New(dltensor, _c_str_dltensor, _c_dlpack_deleter)
                                                                  ^

dgl/_ffi/_cython/./ndarray.pxi:80:66: Cannot assign type 'void (object) except *' to 'PyCapsule_Destructor'
Traceback (most recent call last):
  File ""setup.py"", line 240, in <module>
    ext_modules=config_cython(),
  File ""setup.py"", line 141, in config_cython
    return cythonize(
  File ""/home/***/.conda/envs/dgl/lib/python3.8/site-packages/Cython/Build/Dependencies.py"", line 1134, in cythonize
    cythonize_one(*args)
  File ""/home/***/.conda/envs/dgl/lib/python3.8/site-packages/Cython/Build/Dependencies.py"", line 1301, in cythonize_one
    raise CompileError(None, pyx_file)
Cython.Compiler.Errors.CompileError: dgl/_ffi/_cython/core.pyx

## Environment
OS (e.g., Linux): Ubuntu 20.04
DGL Version : master
Backend Library & Version:PyTorch 1.13.0+gpu; Cython 3.0.0
How you installed DGL: source
Build command you used: bash script/build_dgl.sh -g -e '-DCMAKE_BUILD_TYPE=DEBUG'
Python version: 3.8.17",error reproduce bash activate bash python error report error file raise work memory call alignment return assign type object except recent call last file line module file line return file line file line raise none environment o version master library version source build command used bash python version,issue,negative,neutral,neutral,neutral,neutral,neutral
1652964508,"Lint passed, the example is not covered by CI, so merge without waiting for CI complete.",lint example covered merge without waiting complete,issue,negative,positive,neutral,neutral,positive,positive
1652948062,@drivanov Thank you for contributing in improving the code quality!,thank improving code quality,issue,positive,neutral,neutral,neutral,neutral,neutral
1652925015,@drivanov Nice work! Thanks for the contribution!,nice work thanks contribution,issue,positive,positive,positive,positive,positive,positive
1652830296,Hi @candyflower2005. Could you try the latest DGL version (1.1.1)? This bug should have been fixed.,hi could try latest version bug fixed,issue,negative,positive,positive,positive,positive,positive
1652825368,"Hi @sanjayjuneja , this is DGL repo, how does grpc related to DGL? Or maybe you should post the issue to https://github.com/grpc/grpc/issues?",hi related maybe post issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1652806391,"> is this problem fixedï¼Ÿ

Our GPU kernel is implemented non-deterministically so each time the result might be different.  That being said, how much did the resulting metric fluctuate?  If it changes a lot then this is a problem we should look into.  @luolo-cry ",problem kernel time result might different said much resulting metric fluctuate lot problem look,issue,negative,positive,neutral,neutral,positive,positive
1652627664,"https://stackoverflow.com/questions/214852/python-module-dlls/74645015#74645015

Has gave NICE answer that works (at least in my case - windows 11 python 3.9.X pytorch):

```
def add_cuda_to_path():
    if os.name != ""nt"":
        return
    path = os.getenv(""PATH"")
    if not path:
        return
    path_split = path.split("";"")
    for folder in path_split:
        if ""cuda"" in folder.lower() or ""tensorrt"" in folder.lower():
            os.add_dll_directory(folder)

add_cuda_to_path()
import <my_module_that_depends_on_cuda>
```",gave nice answer work least case python return path path path return folder folder import,issue,negative,positive,positive,positive,positive,positive
1652401790,"@jermainewang: As you previously suggested, I 
- reverted my changes to `convert.py`
- refactored the `init_graph` function.

With these changes, I see a 7x (700%) runtime improvement, and with my initial changes, I only saw a 1.1x (10%) runtime improvement.",previously function see improvement initial saw improvement,issue,positive,negative,neutral,neutral,negative,negative
1651119597,"Or I can change the value of DGL_DOWNLOAD_DIR to '${DGL_HOME}/_download', I see '_download' is used in some places.",change value see used,issue,negative,neutral,neutral,neutral,neutral,neutral
1651103266,"Hi @nv-dlasalle , thanks for taking action here. Graphbolt provides a framework for integrating different kinds of implementation of the pre-defined components. Which means, there is no fixed approach for adding GPU support. Here are the patterns that I can foresee would happen in the future:
- CSCSamplingGraph support CUDA code, which means a to-device method would be added to it, and move all related tensor to GPU.
- A brand new SampingGraph structure could be added in Python level for CUDA sampling only.
- Leverage UVA for feature fetching from CPU memory to GPU directly.",hi thanks taking action framework different implementation fixed approach support foresee would happen future support code method would added move related tensor brand new structure could added python level sampling leverage uva feature fetching memory directly,issue,positive,positive,neutral,neutral,positive,positive
1650933757,@frozenbugs updated according to your suggestion. Please check again.,according suggestion please check,issue,negative,neutral,neutral,neutral,neutral,neutral
1650524366,"Sure, I have made a quick pull request fixing this.",sure made quick pull request fixing,issue,negative,positive,positive,positive,positive,positive
1650066322,"In the case of sampling with `probs_or_mask`, how many neighbors will be sampled is not known in advance. To make the weighted case fast too, an efficient parallel cat implementation is necessary. Unless weighted sampling is not important.",case sampling many known advance make weighted case fast efficient parallel cat implementation necessary unless weighted sampling important,issue,positive,positive,positive,positive,positive,positive
1649653495,"@Rhett-Ying is out for this week, if not an emergent PR, let's way for Rhett coming back next Monday, @ me again if we need to get it merged sooner.",week emergent let way coming back next need get sooner,issue,negative,neutral,neutral,neutral,neutral,neutral
1649557911,"@drivanov What I mean is to change the `init_graph` function to something like follows:
```python
def init_graph(in_nodes, out_nodes, f_size, device=""cpu""):
    src, dst = [], []
    in_indx = list(range(in_nodes))
    out_indx = list(range(in_nodes, in_nodes + out_nodes))
    # add edges use edge broadcasting
    for u in in_indx:
        src += [u] * len(out_indx)
        dst += out_indx
    ...   # other logics
    g = dgl.graph((src,dst))  # dgl.graph once;
    ...   # other logics
```

Basically, replace all `add_nodes` and `add_edges` with logics for manipulating the src and dst list directly.",mean change function something like python list range list range add use edge basically replace list directly,issue,negative,negative,negative,negative,negative,negative
1649331275,"Hi @mfbalin, thanks for your suggestion, we will further optimize the performance by allocating the memory first to avoid concatenation. We will merge this PR for now since there are some measurable improvement.",hi thanks suggestion optimize performance memory first avoid concatenation merge since measurable improvement,issue,positive,positive,positive,positive,positive,positive
1649200491,"> 

That's true, and the speedup is not very much as you can see in the diagram. According to our test, it performs better when the data volume is small, maybe because cat huge tensors can leverage bulk copy or vector instruction (just suspect)? so it is a tradeoff to decide whether to merge it. For rollout cat, it could be a backup improvement for future.",true much see diagram according test better data volume small maybe cat huge leverage bulk copy vector instruction suspect decide whether merge cat could backup improvement future,issue,positive,positive,positive,positive,positive,positive
1648847123,So the speedup this PR is achieving over the existing implementation may be due to the possibility that `torch.cat` doesn't have a parallel implementation. Profiling the code would reveal whether this is the case. I think doing two levels of `torch.cat` operations only increases the work. Each edge is concatenated two times.,implementation may due possibility parallel implementation code would reveal whether case think two work edge two time,issue,negative,negative,neutral,neutral,negative,negative
1648759693,"Hi @frozenbugs, we found that the linterror comes from the doc string being too long in `base.py`. We changed that and pushed two extra commits. It would be great help if you can help us on running the tests again. Thank you! We appreciate it. 
",hi found come doc string long two extra would great help help u running thank appreciate,issue,positive,positive,positive,positive,positive,positive
1648542322,@BarclayII Do you want to take a look as well? I will be adding some tests later.,want take look well later,issue,negative,neutral,neutral,neutral,neutral,neutral
1648303979,"Is there any suggestions on why it fails with linterror? 
I tried this with `lintrunner -a python/dgl/dataloading/base.py`, and it gives `ok No lint issues. Successfully applied all patches.`",tried lint successfully applied,issue,negative,positive,positive,positive,positive,positive
1647861718,"I had checked to see what kind of cat implementation torch uses internally. I found this:
https://github.com/pytorch/pytorch/blob/33b855e9069ddc98399c0dfd362f18df9503b66f/aten/src/ATen/native/cpu/CatKernel.cpp#L24
If this code is indeed being used, it is a serial implementation so the parallel sampling code speedup will be limited. If that is the case, it might make sense to rollout a custom parallel cat implementation for DGL.
@keli-wen @peizhou001 @frozenbugs ",checked see kind cat implementation torch internally found code indeed used serial implementation parallel sampling code limited case might make sense custom parallel cat implementation,issue,negative,positive,positive,positive,positive,positive
1647225879,"@yaox12 @mfbalin in the future, let's separate the 3rd-party code merging together with the 1st-party code. Since we just import the 3rd party code, we are create a quick PR to make sure it compiles and merge it, and make a separate PR to merge the 1st-party code.",future let separate code together code since import party code create quick make sure merge make separate merge code,issue,positive,positive,positive,positive,positive,positive
1647222581,"You can just edit this file https://github.com/dmlc/dgl/blob/master/python/dgl/batch.py directly, the html file will be updated automatically.",edit file directly file automatically,issue,negative,positive,neutral,neutral,positive,positive
1647145739,"> @mfbalin The lint check won't block merge. So just ignore it.

Was able to fix it by adding an additional `*` to the exclude_path, like `third_party/**`.",lint check wo block merge ignore able fix additional like,issue,negative,positive,positive,positive,positive,positive
1647140381,@mfbalin The lint check won't block merge. So just ignore it.,lint check wo block merge ignore,issue,negative,neutral,neutral,neutral,neutral,neutral
1647135573,@mfbalin You can add an exclude pattern in https://github.com/dmlc/dgl/blob/7ec78bb6d2ff5c9a54962d0f26befba0716bf71e/.lintrunner.toml#L41. Just like Line 19.,add exclude pattern like line,issue,negative,neutral,neutral,neutral,neutral,neutral
1647127774,"I added only the gpu_cache folder from HugeCTR since recent HugeCTR versions have a lot of dependencies, making `git submodule update --init --recursive` step time-consuming. However, linting needs to be disabled for the `third_party` directory for this to work. @yaox12 do you know how to do that?",added folder since recent lot making git update recursive step however need disabled directory work know,issue,negative,negative,neutral,neutral,negative,negative
1647051691,"> @yaox12 Do you think we should update the HugeCTR version now that DGL doesn't support CUDA 10? I think we can depend on the latest version. But I don't know if there was any change to the gpu_cache code in HugeCTR.

@mfbalin Of course, I think it's reasonable. Not sure of the changes to gpu_cache either. Maybe you can just update it and check if it works as expected.
",think update version support think depend latest version know change code course think reasonable sure either maybe update check work,issue,positive,positive,positive,positive,positive,positive
1646451824,@yaox12 Do you think we should update the HugeCTR version now that DGL doesn't support CUDA 10? I think we can depend on the latest version. But I don't know if there was any change to the gpu_cache code in HugeCTR.,think update version support think depend latest version know change code,issue,negative,positive,positive,positive,positive,positive
1646370722,"First warning
```
DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.
```
was generated because `low_memory=False` was not used in line 81 of  `eeg-gcnn/main.py`:
```
    _DATASET_INDEX = pd.read_csv(""master_metadata_index.csv"", low_memory=False)
```

Second one:
```
UserWarning: The memmapped array [[ -572.13196116  -363.93541683  -739.53754843 ...  -357.44040591   -1722.60122587 -1294.1573575 ]] loaded from the file psd_features_data_X is not not bytes aligned. ...
```
was there because the size of the `psd_features_data_X` file was 86528478 and it doesn't match the memory mapped array.


",first warning mixed specify option import set used line second one array loaded file size file match memory array,issue,negative,positive,neutral,neutral,positive,positive
1646342926,"@frozenbugs can you expand this request a bit more? Looking at the existing graphbolt code, it's not obvious to me how GPU support should be integrated. For example, the `CSCSamplingGraph` does not contain any logic to check that the underlying tensors are CPU accessible. Are we planning to add dispatching logic to that class as part of this issue, where member functions like `SampleNeighborsImpl()` would also be templated by the device type?",expand request bit looking code obvious support example contain logic check underlying accessible add logic class part issue member like would also device type,issue,positive,positive,positive,positive,positive,positive
1646193964,"Hi @jermainewang, In fact, both integer lists **u** and **v** that you talked about in this example must be empty. So the simplest solution to this problem would be to replace the call
```
g = dgl.DGLGraph()
```
in `init_graph` by one of the following calls
```
g = dgl.graph(data=([], []), num_nodes=0)
g = dgl.graph(data=([], []))
g = dgl.graph(data=[])
g = dgl.graph([])
```

Unfortunately, it's not possible to just use
```
g = dgl.graph()
```
because `dgl.graph(...)` requires positional argument `data`.
The changes I made to  `convert.py` remove this limitation and make it easier to remove similar warnings for other examples. As I could see, the `dgl.DGLGraph()` call is used in 49 different places and I think it would be easier to replace
```
g = dgl.DGLGraph()
```
by 
```
g = dgl.graph()
```
in these places.",hi fact integer example must empty solution problem would replace call one following unfortunately possible use positional argument data made remove limitation make easier remove similar could see call used different think would easier replace,issue,negative,negative,neutral,neutral,negative,negative
1644942206,"> What does neighbors_per_etype mean?

According to the generate code:

```py
def random_graph_with_fixed_neighbors(num_nodes,
                                      neighbors_per_etype,
                                      num_ntypes,
                                      num_etypes):
    neighbors_per_node = num_etypes * neighbors_per_etype
    csc_indptr = torch.arange((num_nodes+1)) * neighbors_per_node
    num_edges = num_nodes * neighbors_per_node
    indices = torch.randint(0, num_nodes, (num_edges,))
    type_per_edge = torch.arange(num_etypes).repeat_interleave(
        neighbors_per_etype
    ).repeat(num_nodes)

    node_type_offset = torch.sort(
        torch.randint(0, num_nodes, (num_ntypes + 1,))
    )[0]
    node_type_offset[0] = 0
    node_type_offset[-1] = num_nodes

    # Add the metadata to the graph.
    ntypes = { f""n{i}"" : i for i in range(num_ntypes) }
    etypes = {
        (f""n{(i % num_ntypes) + 1}"", f""e{i}"", f""n{(i // num_etypes) + 1}"") : i
            for i in range(num_etypes)
    }
    metadata = gb.GraphMetadata(ntypes, etypes)

    return gb.from_csc(csc_indptr, indices, node_type_offset, type_per_edge, None, metadata)
```

`neighbors_per_etype` denote the number of neighbors of each edge type of the node.",mean according generate code index add graph range range return index none denote number edge type node,issue,negative,negative,negative,negative,negative,negative
1644924162,"> Thanks! Can we keep the issue open until the package is fixed or is this a `wont-fix`?

I think we would not fix this issue in a short time. Basically we only support one minor version for each Pytorch major version.",thanks keep issue open package fixed think would fix issue short time basically support one minor version major version,issue,positive,positive,neutral,neutral,positive,positive
1644411346,"> > And https://github.com/dmlc/dgl/blob/1cbe0b275e3cf938782f581d3a9589f011b54a6d/README.md?plain=1#L12C114-L12C114 `https://docs.dgl.ai/en/latest/` it is 403 Forbidden
> 
> The link is good from my side. Are you still facing the problem?

It has been fixed now",forbidden link good side still facing problem fixed,issue,negative,positive,positive,positive,positive,positive
1644356812,Also We are really close to getting `dgl` on conda-forge which I'll make sure sets this up correctly.,also really close getting make sure correctly,issue,negative,positive,positive,positive,positive,positive
1644356039,Thanks! Can we keep the issue open until the package is fixed or is this a `wont-fix`? ,thanks keep issue open package fixed,issue,negative,positive,positive,positive,positive,positive
1644175718,"@frozenbugs Hi, I'd like to help. But for now I do not know how to edit the document. I will make a pull request as soon as I figure it out.",hi like help know edit document make pull request soon figure,issue,positive,neutral,neutral,neutral,neutral,neutral
1643276735,Overall LGTM. @mfbalin I suggest putting the Python files under `dgl.cuda` directory since we have deprecated all code under `dgl.contrib`.,overall suggest python directory since code,issue,negative,neutral,neutral,neutral,neutral,neutral
1643160903,"Hi @drivanov , thanks for the contribution. I like your fix to remove those warnings. My suggestion is to keep the changes to the capsule network example and try to avoid modifying the core library code such as `convert.py`. Could you help update the PR as follows:
* Revert the changes to `convert.py`.
* Refactor the `init_graph` function to first generate an edge list (e.g., two integer list `u` and `v`) and then pass them to `dgl.graph` call. This is the intended way of constructing a graph in DGL right now.

Thanks!",hi thanks contribution like fix remove suggestion keep capsule network example try avoid core library code could help update revert function first generate edge list two integer list pas call intended way graph right thanks,issue,positive,positive,positive,positive,positive,positive
1643010513,"Yes, the docker is designed for build dgl source code from scratch. DGL does not provide official docker. 
May I ask how a docker makes it easy for you to run DGL?",yes docker designed build source code scratch provide official docker may ask docker easy run,issue,positive,positive,positive,positive,positive,positive
1643008624,"I think dglke can only run on top of DGL 0.4.3, I am not aware of any active maintenance of dglke. Can you try install the old version of dglke if you want to run the code?",think run top aware active maintenance try install old version want run code,issue,positive,positive,positive,positive,positive,positive
1643006774,"@wzm2256 I think you are right, can you provide a quick fix. If you don't have time to help, we will prioritize the fix in our next cycle.",think right provide quick fix time help fix next cycle,issue,negative,positive,positive,positive,positive,positive
1642975217,"> And https://github.com/dmlc/dgl/blob/1cbe0b275e3cf938782f581d3a9589f011b54a6d/README.md?plain=1#L12C114-L12C114 `https://docs.dgl.ai/en/latest/` it is 403 Forbidden

The link is good from my side. Are you still facing the problem?",forbidden link good side still facing problem,issue,negative,positive,positive,positive,positive,positive
1642392769,"@TristonC Thank you! I did not know that it's not an official container.
I also sent the request for container of NVDIA.",thank know official container also sent request container,issue,negative,neutral,neutral,neutral,neutral,neutral
1642203978,While the code is functionally correct I think it's not as readable.  I made some changes in #6020.,code functionally correct think readable made,issue,negative,neutral,neutral,neutral,neutral,neutral
1641742591,"The [PR: [Graphbolt] Add the preprocess_ondisk_dataset function.](https://github.com/dmlc/dgl/pull/5991) implemented a `preprocess_ondisk_dataset()` function:
- Receive the `input_config_path` (a YAML file), extract the data from the `graph` field, and utilize the original data in `.csv/.npy` format to create a `CSCSamplingGraph`.
- Convert all `torch` format data into `numpy` format.
- Return the processed YAML file path.",add function function receive file extract data graph field utilize original data format create convert torch format data format return file path,issue,positive,positive,positive,positive,positive,positive
1641736922,"We are using numpy on-disk tensor, after benchmarking the result, we may discuss whether there are better solutions.",tensor result may discus whether better,issue,negative,positive,positive,positive,positive,positive
1641654151,"Hello, it seems this issue remains unresolved for a week. Is there someone WIP?",hello issue remains unresolved week someone,issue,negative,neutral,neutral,neutral,neutral,neutral
1641585242,"> This should be the python dictionary pop function as ndata has python dictionary type.

If ndata is inherit from a dict type, then maybe this can be put in the document, because the HeteroNodeDataView type is less clear.",python dictionary pop function python dictionary type inherit type maybe put document type le clear,issue,negative,positive,positive,positive,positive,positive
1641294320,"We can insert the query call to the GPU cache here for the old dataloader: https://github.com/dmlc/dgl/blob/master/python/dgl/storages/pytorch_tensor.py#L38 in a potential future PR.

Since GPU cache is supported on Volta or above, we can query `torch.cuda.get_device_capability()[0] >= 7` to check if everything is compatible before enabling the cache.",insert query call cache old potential future since cache query check everything compatible cache,issue,negative,positive,neutral,neutral,positive,positive
1641279617,Just ran the batch_dependency (kappa) path with #4718 and seems to just work.,ran kappa path work,issue,negative,neutral,neutral,neutral,neutral,neutral
1641122695,This should be the python dictionary pop function as ndata has python dictionary type.,python dictionary pop function python dictionary type,issue,negative,neutral,neutral,neutral,neutral,neutral
1641111178,The contrib package has been deprecated [API Deprecation]Deprecate contrib module](https://github.com/dmlc/dgl/pull/5114) @frozenbugs @peizhou001 Could you help to update dglke to run on DGL 1.0+?,package deprecation deprecate module could help update run,issue,negative,neutral,neutral,neutral,neutral,neutral
1641068170,"@baygaliyev This seems not the officially released DGL container. 
@jermainewang Does DGL team officially release docker containers?
@baygaliyev  For GPU cases, NVIDIA provide docker container release which has updated DGL in it. Check out [here](https://developer.nvidia.com/dgl-container-early-access) ",officially container team officially release docker provide docker container release check,issue,negative,neutral,neutral,neutral,neutral,neutral
1640335329,"> > @frozenbugs Could you take a look? This implements the kappa feature in the Cooperative Minibatching paper. Has the ability to increase GPU cache hit rates, and reduce feature transfer times.
> 
> How did you measure the result? what percentage of increment in GPU cache hit rates and reduction of feature transfer?

The results are in the cooperative minibatching paper. Basically, can reduce feature transfer times by more than 2x. Will include some of the figures from the paper here as well.

EDIT: Updated the top description with the results. Feature transfer times are basically proportional to the cache miss rates reported above.",could take look kappa feature paper ability increase cache hit reduce feature transfer time measure result percentage increment cache hit reduction feature transfer paper basically reduce feature transfer time include paper well edit top description feature transfer time basically proportional cache miss,issue,positive,positive,positive,positive,positive,positive
1640001452,"> @frozenbugs Could you take a look? This implements the kappa feature in the Cooperative Minibatching paper. Has the ability to increase GPU cache hit rates, and reduce feature transfer times.

How did you measure the result? what percentage of increment in GPU cache hit rates and reduction of feature transfer?",could take look kappa feature paper ability increase cache hit reduce feature transfer time measure result percentage increment cache hit reduction feature transfer,issue,positive,neutral,neutral,neutral,neutral,neutral
1637388189,"> > > > How do you think the outer api should look? I want to have a version of labor that is identical to the neigbor sampling api in terms of api and behaviour. But I also want to have a separate api that is more advanced and not identical in behaviour (such as importance sampling, kappa feature, layer_dependency or possibly sampling an expected number of vertices instead of deterministic).
> > > 
> > > 
> > > For the version of labor that is identical to the neighbor sampling api, what's the difference then? Is there any benefit of having a labor version identical to the neighbor sampling?
> > 
> > 
> > Since users are familiar with neighbor sampler and its behavior, I thought this implementation is a true drop-in replacement so the switch would be easy for the users.
> > But I believe that neither sampling with replacement or without replacement are good for weighted sampling. Thus I want to implement Poisson sampling as well. Importance sampling will be supported only for poisson sampling also.
> > That is why, I initially wanted to add a bool layer parameter to sample_neighbors. My plan now is to expose sample_layer_neighbors with same API as a drop-in replacement to sample_neighbors while sample_labors will be similar to dgl.sampling.sample_labors. Does that make sense? Please let me know how best I can present Labor to users.
> 
> It makes sense to introduce multiple APIs if needed, we need to make sure that when we create new API, we make it clear to users in which case / why they should chose the new APIs for sampling. Currently I am a little bit confused here:
> 
> 1. My understand of introduce the labor sampling is to get higher overlap when sampling such that we can leverage cache to reduce the feature fetching speed, if that's the case, why do we need 2 different labor API?
> 2. You mentioned that a version of Labor sampling and neighbor sampling as identical, why do we need an identical version, is it faster?

1. Both APIs of labor will have higher overlap compared to neighbor. What changes is the sampling method. There are 3 different sampling methods you can use, sampling without replacement, with replacement, poisson sampling (flipping coins). Here, I implemented sampling with and without replacement for labor. dgl.sampling.sample_labors implements poisson sampling.
2. By identical, I mean the API, input arguments, output structure. When a user says sample me fanout edges with replacement, they will get exactly that, with or without labor, when the API is identical. However, if they use labor, they will get more overlap. However, dgl.sampling.sample_labors is not identical because it uses poisson sampling (hence get fanout edges in expectation, not deterministic), not sampling with or without replacement that users are more familiar with.

So, what I mean by having two different labor APIs is that one that looks exactly like neighbor (replace parameter etc.). The other one will look like dgl.sampling.sample_labors, exposing more advanced functionalities. By providing an API that looks exactly like the neighbor sampling API, my goal is to get the users to make the switch to labor easier. If they like it, they can dig in more and switch to using the other more advanced API, that will look similar to dgl.sampling.sample_labors.",think outer look want version labor identical sampling behaviour also want separate advanced identical behaviour importance sampling kappa feature possibly sampling number vertex instead deterministic version labor identical neighbor sampling difference benefit labor version identical neighbor sampling since familiar neighbor sampler behavior thought implementation true replacement switch would easy believe neither sampling replacement without replacement good weighted sampling thus want implement sampling well importance sampling sampling also initially add bool layer parameter plan expose replacement similar make sense please let know best present labor sense introduce multiple need make sure create new make clear case chose new sampling currently little bit confused understand introduce labor sampling get higher overlap sampling leverage cache reduce feature fetching speed case need different labor version labor sampling neighbor sampling identical need identical version faster labor higher overlap neighbor sampling method different sampling use sampling without replacement replacement sampling sampling without replacement labor sampling identical mean input output structure user sample replacement get exactly without labor identical however use labor get overlap however identical sampling hence get expectation deterministic sampling without replacement familiar mean two different labor one exactly like neighbor replace parameter one look like advanced providing exactly like neighbor sampling goal get make switch labor easier like dig switch advanced look similar,issue,positive,positive,positive,positive,positive,positive
1637380428,"> > > How do you think the outer api should look? I want to have a version of labor that is identical to the neigbor sampling api in terms of api and behaviour. But I also want to have a separate api that is more advanced and not identical in behaviour (such as importance sampling, kappa feature, layer_dependency or possibly sampling an expected number of vertices instead of deterministic).
> > 
> > 
> > For the version of labor that is identical to the neighbor sampling api, what's the difference then? Is there any benefit of having a labor version identical to the neighbor sampling?
> 
> Since users are familiar with neighbor sampler and its behavior, I thought this implementation is a true drop-in replacement so the switch would be easy for the users.
> 
> But I believe that neither sampling with replacement or without replacement are good for weighted sampling. Thus I want to implement Poisson sampling as well. Importance sampling will be supported only for poisson sampling also.
> 
> That is why, I initially wanted to add a bool layer parameter to sample_neighbors. My plan now is to expose sample_layer_neighbors with same API as a drop-in replacement to sample_neighbors while sample_labors will be similar to dgl.sampling.sample_labors. Does that make sense? Please let me know how best I can present Labor to users.

It makes sense to introduce multiple APIs if needed, we need to make sure that when we create new API, we make it clear to users in which case / why they should chose the new APIs for sampling. Currently I am a little bit confused here:

1. My understand of introduce the labor sampling is to get higher overlap when sampling such that we can leverage cache to reduce the feature fetching speed, if that's the case, why do we need 2 different labor API?

2. You mentioned that a version of Labor sampling and neighbor sampling as identical, why do we need an identical version, is it faster?",think outer look want version labor identical sampling behaviour also want separate advanced identical behaviour importance sampling kappa feature possibly sampling number vertex instead deterministic version labor identical neighbor sampling difference benefit labor version identical neighbor sampling since familiar neighbor sampler behavior thought implementation true replacement switch would easy believe neither sampling replacement without replacement good weighted sampling thus want implement sampling well importance sampling sampling also initially add bool layer parameter plan expose replacement similar make sense please let know best present labor sense introduce multiple need make sure create new make clear case chose new sampling currently little bit confused understand introduce labor sampling get higher overlap sampling leverage cache reduce feature fetching speed case need different labor version labor sampling neighbor sampling identical need identical version faster,issue,positive,positive,positive,positive,positive,positive
1636981463,@frozenbugs The required PRs on which this depends are all open and ready now. This depends on the kappa feature and the core GPU cache.,open ready kappa feature core cache,issue,negative,positive,neutral,neutral,positive,positive
1636981066,"@frozenbugs Could you take a look? This implements the kappa feature in the Cooperative Minibatching paper. Has the ability to increase GPU cache hit rates, and reduce feature transfer times.",could take look kappa feature paper ability increase cache hit reduce feature transfer time,issue,positive,neutral,neutral,neutral,neutral,neutral
1636880117,"I think there is a problem with the CI:
`AttributeError: module 'pydantic_yaml' has no attribute 'YamlModel'`",think problem module attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1636820731,"Tests should pass now, I stripped out the items that don't add the core functionality of the GPU cache so that this PR is smaller. Another PR will add the Graphbolt feature store and another will add an example using the feature store with labor with its kappa feature to show cache miss rates can be reduced.",pas stripped add core functionality cache smaller another add feature store another add example feature store labor kappa feature show cache miss reduced,issue,negative,neutral,neutral,neutral,neutral,neutral
1636779759,"> > How do you think the outer api should look? I want to have a version of labor that is identical to the neigbor sampling api in terms of api and behaviour. But I also want to have a separate api that is more advanced and not identical in behaviour (such as importance sampling, kappa feature, layer_dependency or possibly sampling an expected number of vertices instead of deterministic).
> 
> For the version of labor that is identical to the neighbor sampling api, what's the difference then? Is there any benefit of having a labor version identical to the neighbor sampling?

Since users are familiar with neighbor sampler and its behavior, I thought this implementation is a true drop-in replacement so the switch would be easy for the users.

But I believe that neither sampling with replacement or without replacement are good for weighted sampling. Thus I want to implement Poisson sampling as well. Importance sampling will be supported only for poisson sampling also.

That is why, I initially wanted to add a bool layer parameter to sample_neighbors. My plan now is to expose sample_layer_neighbors with same API as a drop-in replacement to sample_neighbors while sample_labors will be similar to dgl.sampling.sample_labors. Does that make sense? Please let me know how best I can present Labor to users.",think outer look want version labor identical sampling behaviour also want separate advanced identical behaviour importance sampling kappa feature possibly sampling number vertex instead deterministic version labor identical neighbor sampling difference benefit labor version identical neighbor sampling since familiar neighbor sampler behavior thought implementation true replacement switch would easy believe neither sampling replacement without replacement good weighted sampling thus want implement sampling well importance sampling sampling also initially add bool layer parameter plan expose replacement similar make sense please let know best present labor,issue,positive,positive,positive,positive,positive,positive
1636693739,"> How do you think the outer api should look? I want to have a version of labor that is identical to the neigbor sampling api in terms of api and behaviour. But I also want to have a separate api that is more advanced and not identical in behaviour (such as importance sampling, kappa feature, layer_dependency or possibly sampling an expected number of vertices instead of deterministic).

For the version of labor that is identical to the neighbor sampling api, what's the difference then? Is there any benefit of having a labor version identical to the neighbor sampling?",think outer look want version labor identical sampling behaviour also want separate advanced identical behaviour importance sampling kappa feature possibly sampling number vertex instead deterministic version labor identical neighbor sampling difference benefit labor version identical neighbor sampling,issue,positive,positive,positive,positive,positive,positive
1636693412,"> I implemented sampling with replacement as well. Full functionality matching sample_neighbors available now.

Thanks for the quick follow up, the replacement code looks good, but in the future let's avoid extending the scope of a PR while it is being reviewed. Let's get a PR approved and merged before we extending the scope. For the new request, you can check out from the PR and work from there, and git rebase once the PR is merged.",sampling replacement well full functionality matching available thanks quick follow replacement code good future let avoid extending scope let get extending scope new request check work git rebase,issue,positive,positive,positive,positive,positive,positive
1636659093,I implemented sampling with replacement as well. Full functionality matching sample_neighbors available now.,sampling replacement well full functionality matching available,issue,negative,positive,positive,positive,positive,positive
1635920312,"How do you think the outer api should look? I want to have a version of labor that is identical to the neigbor sampling api in terms of api and behaviour. But I also want to have a separate api that is more advanced and not identical in behaviour (such as importance sampling, kappa feature, layer_dependency or possibly sampling an expected number of vertices instead of deterministic).",think outer look want version labor identical sampling behaviour also want separate advanced identical behaviour importance sampling kappa feature possibly sampling number vertex instead deterministic,issue,positive,positive,positive,positive,positive,positive
1635588804,"Per discussion with my team, we prefer to create separated python api instead of fuse them together, here is the example code https://github.com/dmlc/dgl/pull/6002/files that you can copy from. The reason we have internal _sample_neighbor is due to distdgl has a legacy dependency, for sample_labor, we don't need to follow the pattern.",per discussion team prefer create python instead fuse together example code copy reason internal due legacy dependency need follow pattern,issue,negative,negative,neutral,neutral,negative,negative
1635330423,I think we can also merge this PR and add the benchmark later.,think also merge add later,issue,negative,neutral,neutral,neutral,neutral,neutral
1635230271,"The histogram has bins, let's say we are computing a histogram for bins with values 0 to 6 (7 bins in total). Without the fix, the bin boundaries were [0, 8) (8 exclusive) vs [0, 7). Documentation says that CUB evenly distributed the values in the range to bins. But 8 doesn't divide 7. So without the fix, with the new update, 0 and 1 was in the first bin. Without the update 6 and 7 were in the last bin (Which didn't expose the bug). I am speculating that this caused a rounding error and a change in the implementation in CUB might have exposed this bug.",histogram let say histogram total without fix bin exclusive documentation cub evenly distributed range divide without fix new update first bin without update last bin expose bug rounding error change implementation cub might exposed bug,issue,negative,positive,neutral,neutral,positive,positive
1635226407,"> Partition had a minor bug due to the 1 off specification of histogramEven call parameters. Tests should all pass now.

Thanks for fixing, any reason this was not exposed without your optimization?",partition minor bug due specification call pas thanks fixing reason exposed without optimization,issue,negative,positive,neutral,neutral,positive,positive
1635223925,"> Actually, we might want to fix this bug in a separate PR so that if there is any problem with the new thrust version (on the off change), we can take this PR back but the bug fix is still stays.

Solid judgement :)",actually might want fix bug separate problem new thrust version change take back bug fix still stay solid,issue,negative,positive,neutral,neutral,positive,positive
1635221951,"Actually, we might want to fix this bug in a separate PR so that if there is any problem with the new thrust version (on the off change), we can take this PR back but the bug fix is still stays. see: #6001 ",actually might want fix bug separate problem new thrust version change take back bug fix still stay see,issue,negative,positive,neutral,neutral,positive,positive
1635220959,@frozenbugs Partition had a minor bug due to the 1 off specification of histogramEven call parameters. Tests should all pass now.,partition minor bug due specification call pas,issue,negative,negative,neutral,neutral,negative,negative
1635117687,@mfbalin can you help us take a look at the failing test?,help u take look failing test,issue,negative,neutral,neutral,neutral,neutral,neutral
1634651033,"Hi, I'm experiencing the same issue and I've already installed the PyTorch nightly build. Is dgl nightly build necessary too to resolve the error?",hi issue already nightly build nightly build necessary resolve error,issue,negative,neutral,neutral,neutral,neutral,neutral
1633847451,"no, not blocking, let's run the CI, and I will merge it.",blocking let run merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1633712646,Is the lack of a benchmark script blocking the merge of this PR or are we waiting for another reviewer's approval?,lack script blocking merge waiting another reviewer approval,issue,negative,neutral,neutral,neutral,neutral,neutral
1633487491,"I am not sure if this new code path or the existing int32_t specialization is faster. One would need to do a benchmark to see if the cusparse csr2coo or cub is better. However, for the int64_t specialization, CUB should outperform the existing implementation in all cases.
Cusparse code path: https://github.com/dmlc/dgl/blob/078be4369411e72365248409e39a544ed4451e86/src/array/cuda/csr2coo.cu#L44",sure new code path specialization faster one would need see cub better however specialization cub outperform implementation code path,issue,positive,positive,positive,positive,positive,positive
1633471023,"> Previously, how did you trigger these two warnings?

@drivanov Friendly nudge.",previously trigger two friendly nudge,issue,negative,positive,positive,positive,positive,positive
1633427777,"Hi, for distributed training, please check out https://github.com/awslabs/graphstorm which simplifies a lot of errands in DistDGL.",hi distributed training please check lot,issue,negative,neutral,neutral,neutral,neutral,neutral
1632746561,"I needed to move Pick and PickByEtype functions to become members of the Graph class so that they can call LaborPick, which is also a member function. The reason is that LaborPick requires access to the indices_ array. The whole thing is templated on the template parameter labor so there shouldn't be any performance impact.

EDIT: Not needed anymore.",move pick become graph class call also member function reason access array whole thing template parameter labor performance impact edit,issue,negative,positive,positive,positive,positive,positive
1632518367,"Converting this to a feature request. I agree with @Rhett-Ying that we should add a check to bypass `dgl.sparse` when backend is not pytorch. Also, wonder why our CI doesn't catch this error.",converting feature request agree add check bypass also wonder catch error,issue,negative,neutral,neutral,neutral,neutral,neutral
1632501928,@Ericcsr the original contributor of this example and cc the reviewer @sneakerkg . ,original contributor example reviewer,issue,negative,positive,positive,positive,positive,positive
1632498308,Nowadays copy-paste has become the new standard :). This is a reasonable ask but might be of low-priority because we later find that this may not be trivial since the logic could be tightly coupled with the NN module.,nowadays become new standard reasonable ask might later find may trivial since logic could tightly coupled module,issue,negative,positive,neutral,neutral,positive,positive
1632492765,"@kyawlin the original contributor of this module. This indeed looks strange to me because `add_` is an inplace operation which should be avoided usually to prevent breaking autograd.

Also cc the reviewer @BarclayII ",original contributor module indeed strange operation usually prevent breaking also reviewer,issue,negative,positive,neutral,neutral,positive,positive
1632484051,"Could you try the following and see if you get any errors?
```python
import dgl
g = dgl.graph(([0, 1, 2], [1, 2, 3])).to('cuda:0')
```

If the installation is correct, the code above should raise an error.",could try following see get python import installation correct code raise error,issue,negative,neutral,neutral,neutral,neutral,neutral
1632478313,The equivalent concept of nodeflow in newer DGL is message flow graph (mfg). Please check out the tutorial: https://docs.dgl.ai/tutorials/large/index.html,equivalent concept message flow graph please check tutorial,issue,negative,neutral,neutral,neutral,neutral,neutral
1631708664,"@yaox12 It looks like CUDA 10.2 is deprecated now, so we can depend on the latest version of the GPU cache. Also, is the Graphbolt feature store definition mature enough, maybe we can move this PR forward.",like depend latest version cache also feature store definition mature enough maybe move forward,issue,positive,positive,positive,positive,positive,positive
1631684553,@czkkkkkk CUDA 10.2 is not in the CI anymore if I am not mistaken with #5977. Are we going to wait for months before the next release of thrust/cub or is it possible to merge this PR before then? Could we run the CI again to see if the tests pass?,mistaken going wait next release possible merge could run see pas,issue,negative,neutral,neutral,neutral,neutral,neutral
1630212858,Let's revisit this example after graphbolt MVP to see whether the performance will bounce back.,let revisit example see whether performance bounce back,issue,negative,neutral,neutral,neutral,neutral,neutral
1630117205,"> This PR is deprecating pytorch 1.12 in CI and as pytorch 1.13 requires CUDA >=11.6, so cu102/113 are being deprecated as well. And in the next DGL release, the minimum pytorch version is 1.13 and cu116. @BarclayII @frozenbugs please add more comments on this.

Yes, CUDA 10.2 is pretty old now, pytorch is deprecating 11.6, so it is time to catch up.",well next release minimum version please add yes pretty old time catch,issue,positive,positive,positive,positive,positive,positive
1630038327,"This PR is deprecating pytorch 1.12 in CI and as pytorch 1.13 requires CUDA >=11.6, so cu102/113 are being deprecated as well.
And in the next DGL release, the minimum pytorch version is 1.13 and cu116. @BarclayII @frozenbugs please add more comments on this.",well next release minimum version please add,issue,positive,neutral,neutral,neutral,neutral,neutral
1629984837,"> > lintrunner -a python/dgl/dataloading/base.py
> 
> I will add these features.
> 
> Do you have example test functions that I can take a look at. Sorry I haven't written any unit test before and need an example for this.

Sorry for not responding @jwzhi .  An example unit test is https://github.com/dmlc/dgl/blob/master/tests/python/pytorch/dataloading/test_dataloader.py#L727.",add example test take look sorry written unit test need example sorry example unit test,issue,negative,negative,negative,negative,negative,negative
1628466096,"> @caojy1998 FYI. We need to add benchmark for `sample_labor()` into our new benchmark framework.

OK, got it.",need add new framework got,issue,negative,positive,positive,positive,positive,positive
1628095744,@caojy1998 FYI. We need to add benchmark for `sample_labor()` into our new benchmark framework.,need add new framework,issue,negative,positive,positive,positive,positive,positive
1627666098,"> It is indeed very hard to write unit tests to check whether the random pick is uniform or not, worth to use monte carlo simulation to check. can you run the experiment and put the result in this PR?

Finish Monte Carlo Simulation and publish the result in our PR.",indeed hard write unit check whether random pick uniform worth use monte simulation check run experiment put result finish monte simulation publish result,issue,negative,negative,negative,negative,negative,negative
1626946095,"I found that supporting PyTorch 1.12 and TorchData 0.4 needs quite some additional code for compatibility.  Since PyTorch 1.12 is an old version and has security hole anyway, should we drop PyTorch 1.12 support in DGL 1.2?  @frozenbugs ",found supporting need quite additional code compatibility since old version security hole anyway drop support,issue,positive,positive,positive,positive,positive,positive
1625720260,"I would also like to make a PR including the kappa feature I talked about in my presentation. It modifies only the random number generation logic and adds the kappa parameter to the sampler API. However, it won't be useful if #4341 or an alternative dynamic cache is not merged. With the addition of the kappa PR, the official LABOR sampling implementation living inside DGL will be complete.",would also like make kappa feature presentation random number generation logic kappa parameter sampler however wo useful alternative dynamic cache addition kappa official labor sampling implementation living inside complete,issue,positive,negative,neutral,neutral,negative,negative
1624028808,"Yes, seems like I have same issue on Intel i7-9850H.
Regression after #5725

",yes like issue regression,issue,positive,neutral,neutral,neutral,neutral,neutral
1623943613,Thanks @itaraban for looking at it! Can you reproduce this issue?,thanks looking reproduce issue,issue,negative,positive,positive,positive,positive,positive
1623093600,"Let's get this PR merged first, and let's discuss next week to find a path to integrate it in graphbolt. @mfbalin ",let get first let discus next week find path integrate,issue,negative,positive,positive,positive,positive,positive
1623049730,"Hi @itaraban , can you take a look, it seems that this is a pretty deep bug, which only happens on a set of CPU model.",hi take look pretty deep bug set model,issue,negative,positive,positive,positive,positive,positive
1623048952,"> I also suggest using the examples in the doc for the unit tests if you have not done so. If the examples get broken, you will be able to tell that from the CI results.

I have `doctests` setup now and it makes the exp. much better thanks ðŸ‘ ",also suggest doc unit done get broken able tell setup much better thanks,issue,negative,positive,positive,positive,positive,positive
1622820353,"Is your graph `g` on CUDA?  If you installed DGL without CUDA support (i.e. picking `None` in CUDA version in the start page above), then graphs and features on CUDA won't be supported.",graph without support none version start page wo,issue,negative,neutral,neutral,neutral,neutral,neutral
1622815043,"This seems to be submitted by a bot, so I'll respond it with ChatGPT:
> Thank you for bringing this to my attention! I appreciate you identifying an AI-specific code smell in the project. The issue you mentioned, ""Columns and DataType Not Explicitly Set,"" can indeed lead to problems with readability and data consistency. It's important for developers to know what to expect in the downstream data schema, and explicitly setting columns and data types can help achieve that.
>
> I reviewed the paper you provided at https://dl.acm.org/doi/abs/10.1145/3522664.3528620, which describes the problem and provides a solution. It suggests explicitly selecting columns in data processing and setting data types to ensure clarity and avoid potential errors. The paper's example demonstrates how to address the issue using the pandas library in Python.
>
> Additionally, you shared a code snippet related to this smell from the DGL project on GitHub (https://github.com/dmlc/dgl/blob/dce899190e23be2660f7cf3e2e56552ce2e39869/tutorials/blitz/6_load_data.py#L189-L209). This snippet shows how to improve the code by explicitly selecting columns and setting data types during data loading using pandas.
>
> Furthermore, you pointed out several instances of this smell in other files of the DGL project:
>
> File: https://github.com/dmlc/dgl/blob/master/benchmarks/benchmarks/utils.py#L126-L136 (Line: 131)
> File: https://github.com/dmlc/dgl/blob/master/benchmarks/benchmarks/utils.py#L147-L157 (Line: 152)
> File: https://github.com/dmlc/dgl/blob/master/benchmarks/scripts/generate_excel.py#L80-L90 (Line: 85)
> File: https://github.com/dmlc/dgl/blob/master/examples/pytorch/bgnn/run.py#L113-L123 (Line: 118)
> File: https://github.com/dmlc/dgl/blob/master/examples/pytorch/bgnn/run.py#L114-L124 (Line: 119)
> It's great that you provided these examples, as it allows developers to easily locate and address the instances of the code smell.
>
> Overall, your information is indeed helpful in identifying and addressing the ""Columns and DataType Not Explicitly Set"" code smell. Explicitly setting columns and data types enhances code readability and ensures a more predictable data schema. Thank you for your contribution!

Jokes aside, while I don't think the fix should be explicit specification of column names and types, I do think some sort of sanity checks on CSV files is necessary.",bot respond thank attention appreciate code smell project issue explicitly set indeed lead readability data consistency important know expect downstream data schema explicitly setting data help achieve paper provided problem solution explicitly data setting data ensure clarity avoid potential paper example address issue library python additionally code snippet related smell project snippet improve code explicitly setting data data loading furthermore pointed several smell project file line file line file line file line file line great provided easily locate address code smell overall information indeed helpful explicitly set code smell explicitly setting data code readability predictable data schema thank contribution aside think fix explicit specification column think sort sanity necessary,issue,positive,positive,positive,positive,positive,positive
1622797556,The negative samples and positive samples have their losses computed as binary classification loss in https://github.com/dmlc/dgl/blob/master/examples/pytorch/node2vec/model.py#L156-L160.,negative positive binary classification loss,issue,negative,negative,neutral,neutral,negative,negative
1622718592,"Quoted:

Hey!
It will be in the next release. You can find the timing for it here: https://dev-discuss.pytorch.org/t/pytorch-release-2-1-0/1271
You can also use nightly binaries if you need this feature earlier!

https://github.com/pytorch/pytorch/pull/96664#issuecomment-1622478776",hey next release find timing also use nightly need feature,issue,negative,neutral,neutral,neutral,neutral,neutral
1622708930,"Recently we've found distributed tests timeout more and more often, we really need to figure out the root cause. This is being blocking our daily development.",recently found distributed often really need figure root cause blocking daily development,issue,negative,positive,neutral,neutral,positive,positive
1622706673,"> @Rhett-Ying Do you know why this PR failed on CI due to [Distributed Torch CPU Unit test]? It should not relate to distDGL. Can we improve on distDGL CI/unit testing?

DistDGL tests are not stable and sometimes timeout, we haven't figured out the root cause yet. Usually, re-running works.",know due distributed torch unit test relate improve testing stable sometimes figured root cause yet usually work,issue,positive,negative,negative,negative,negative,negative
1622611135,Thanks a lot for creating the PR @mfbalin. I can confirm that I experienced the same benefits as you did by sorting the indices before doing CPU->GPU UVA transfers (GPU TLB misses are considerably reduced).,thanks lot confirm experienced index uva considerably reduced,issue,negative,positive,positive,positive,positive,positive
1622355861,"@Rhett-Ying Do you know why this PR failed on CI due to [Distributed Torch CPU Unit test]? It should not relate to distDGL. Can we improve on distDGL CI/unit testing?
",know due distributed torch unit test relate improve testing,issue,negative,negative,negative,negative,negative,negative
1621465621,"I also suggest using the examples in the doc for the unit tests if you have not done so. If the examples get broken, you will be able to tell that from the CI results.",also suggest doc unit done get broken able tell,issue,negative,positive,neutral,neutral,positive,positive
1621265364,"> Not sure if I have control over either of these failures:
> 
> ```
> tests/python/common/ops/test_ops.py::test_spmm[float32-idtype1-max-div-shp0-g1] script returned exit code 1
> ```
> 
> ```
> tests/distributed/test_rpc.py::test_multi_client_connect Expected error: Failed to build conncetion with peer after 1 retries. Please check network availability or increase max try times via 'DGL_DIST_MAX_TRY_TIMES'.
> ```

I don't think so. @Rhett-Ying any thoughts?",sure control either script returned exit code error build peer please check network availability increase try time via think,issue,negative,positive,positive,positive,positive,positive
1619933902,"```
        # 1-step transition probability

        if scipy.__version__ < ""1.11.0"":

            RW = np.array(A / (A.sum(1) + 1e-30))

        else:

            # sparse matrix divided by a dense array returns a sparse matrix in scipy since 1.11.0

>           RW = (A / (A.sum(1) + 1e-30)).toarray()

E           AttributeError: 'matrix' object has no attribute 'toarray'


python/dgl/transforms/functional.py:3597: AttributeError

```",transition probability else sparse matrix divided dense array sparse matrix since object attribute,issue,negative,neutral,neutral,neutral,neutral,neutral
1619814597,"@frozenbugs @jermainewang 
Hi, I fixed all CI problems and I think this change is ready for review now ",hi fixed think change ready review,issue,negative,positive,positive,positive,positive,positive
1619632518,"It is indeed very hard to write unit tests to check whether the random pick is uniform or not, worth to use monte carlo simulation to check.
can you run the experiment and put the result in this PR?",indeed hard write unit check whether random pick uniform worth use monte simulation check run experiment put result,issue,negative,negative,negative,negative,negative,negative
1619522575,"Not sure if I have control over either of these failures:

```
tests/python/common/ops/test_ops.py::test_spmm[float32-idtype1-max-div-shp0-g1] script returned exit code 1
```
```
tests/distributed/test_rpc.py::test_multi_client_connect Expected error: Failed to build conncetion with peer after 1 retries. Please check network availability or increase max try times via 'DGL_DIST_MAX_TRY_TIMES'.
```",sure control either script returned exit code error build peer please check network availability increase try time via,issue,negative,positive,positive,positive,positive,positive
1617449623,Now we try to use python API for relabel_nodes=True instread of writing kernel function. The latter is much more complicated.,try use python writing kernel function latter much complicated,issue,negative,negative,negative,negative,negative,negative
1617336583,"could we offer a utility API to convert COO(which could be **homogeneous** or **heterogenous**, **unsorted**) to  a **sorted** `CSCSamplingGraph`? could we construct a `DGLGraph` first form coo data and convert via `dgl.to_homogeneous()` to obtain csc matrix?",could offer utility convert coo could homogeneous heterogenous unsorted sorted could construct first form coo data convert via obtain matrix,issue,negative,positive,positive,positive,positive,positive
1617152065,A new layer sampler called Labor Sampler is available now in dgl as dgl.dataloading.LaborSampler and dgl.sampling.sample_labors.,new layer sampler labor sampler available,issue,negative,positive,positive,positive,positive,positive
1616806693,"I pitch this too. I am getting the following error while trying to run the launch script. 

```bash
usage: node_classification.py [-h] [--graph_name GRAPH_NAME]
                              [--ip_config IP_CONFIG]
                              [--part_config PART_CONFIG]
                              [--n_classes N_CLASSES] [--backend BACKEND]
                              [--num_gpus NUM_GPUS] [--num_epochs NUM_EPOCHS]
                              [--num_hidden NUM_HIDDEN]
                              [--num_layers NUM_LAYERS] [--fan_out FAN_OUT]
                              [--batch_size BATCH_SIZE]
                              [--batch_size_eval BATCH_SIZE_EVAL]
                              [--log_every LOG_EVERY]
                              [--eval_every EVAL_EVERY] [--lr LR]
                              [--dropout DROPOUT] [--local_rank LOCAL_RANK]
                              [--pad-data]
node_classification.py: error: unrecognized arguments: --local-rank=2```",pitch getting following error trying run launch script bash usage dropout dropout error unrecognized,issue,negative,neutral,neutral,neutral,neutral,neutral
1615569646,"> The new code is in https://github.com/dmlc/dgl/blob/master/examples/multigpu/node_classification_sage.py. I have made a PR to fix it.

Thank you for your help!
",new code made fix thank help,issue,positive,positive,positive,positive,positive,positive
1615498675,The new code is in https://github.com/dmlc/dgl/blob/master/examples/multigpu/node_classification_sage.py.  I have made a PR to fix it.,new code made fix,issue,negative,positive,positive,positive,positive,positive
1615490504,Closing this issue.  Please feel free to reopen if the issue pops up again.,issue please feel free reopen issue,issue,positive,positive,positive,positive,positive,positive
1615286051,"When I was fetching mag240M edge types, it made an enormous difference (4x). The exact scenario was that the array length is 3.4e9, the dtype is uint8, and I was fetching around 600k of them at a time.",fetching edge made enormous difference exact scenario array length fetching around time,issue,negative,positive,positive,positive,positive,positive
1615277416,"> > @mfbalin Does the below code snippet measure the target performance improvement?
> > ```
> > import torch
> > import dgl
> > 
> > feat_data = torch.rand(1000, 10).pin_memory()
> > idx = torch.randint(0, 1000, (1000,)).to('cuda')
> > 
> > # t0
> > sliced_data = dgl.utils.gather_pinned_tensor_rows(feat_data, idx)
> > # t1
> > ```
> 
> You might want to try larger sizes though. Like if the scenario was ogbn-products, then 2M for feat_data and idx would be of size 200k.

Is ogbn-products big enough to observe a performance improvement on? Or do we need to target even larger so that there are significant TLB misses?",code snippet measure target performance improvement import torch import might want try size though like scenario would size big enough observe performance improvement need target even significant,issue,positive,positive,positive,positive,positive,positive
1615273709,"Commit ID: d0d8efa3266188fcabe0e1349541f3d4e482a0ac

Build ID: 1

Status: âŒ CI test failed in Stage [DGL-Go CPU test].

Report path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-5934/1/1/logs/report.html)

Full logs path: [link](https://dgl-ci-result.s3.us-west-2.amazonaws.com/dgl/PR-5934/1/1/logs/cireport.log)",commit id build id status test stage test report path link full path link,issue,negative,positive,positive,positive,positive,positive
1615244815,"Yes, the issue is still there and we need to fix it. Here is the file diff: https://gist.github.com/chang-l/63aa5beb79ec94bbccbd1aea07ec37b3  to run the example in non-uva mode (cpu sampling and feature fetching). I ran it with command: 
```python multi_gpu_node_classification.py  --gpu 0,1,2,3``` on 4XA100.",yes issue still need fix file run example mode sampling feature fetching ran command python,issue,negative,neutral,neutral,neutral,neutral,neutral
1615125892,"No clue what happened but it seems to work now? 

From the forum discussions it seemed like a general problem with V100. Either way thanks again for you help!",clue work forum like general problem either way thanks help,issue,positive,positive,positive,positive,positive,positive
1614968734,"> lintrunner -a python/dgl/dataloading/base.py

I will add these features. 

Do you have example test functions that I can take a look at. Sorry I haven't written any unit test before and need an example for this. ",add example test take look sorry written unit test need example,issue,negative,negative,negative,negative,negative,negative
1614896960,"Could you try (1) the pip command (maybe with poetry) `pip install --no-cache-dir dgl -f https://data.dgl.ai/wheels/cu117/repo.html` and show us the complete log, and (2) run `python -c ""import dgl; print(dgl); print(dgl.__version__)""` and show us the output?  I'd like to see if the package URL pip downloaded is correct.",could try pip command maybe poetry pip install show u complete log run python import print print show u output like see package pip correct,issue,negative,positive,neutral,neutral,positive,positive
1614893912,"> I have been getting the exact same error too:
> 
> ```
> Traceback (most recent call last):
>   File ""/storage/utk/dgl/examples/pytorch/graphsage/node_classification.py"", line 181, in <module>
>     dataset = AsNodePredDataset(DglNodePropPredDataset(""ogbn-papers100M"", ""./dataset/ogbn_papers100M/""))
>                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
>   File ""/storage/utk/miniconda3/envs/dgl/lib/python3.11/site-packages/ogb/nodeproppred/dataset_dgl.py"", line 69, in __init__
>     self.pre_process()
>   File ""/storage/utk/miniconda3/envs/dgl/lib/python3.11/site-packages/ogb/nodeproppred/dataset_dgl.py"", line 98, in pre_process
>     if decide_download(url):
>        ^^^^^^^^^^^^^^^^^^^^
>   File ""/storage/utk/miniconda3/envs/dgl/lib/python3.11/site-packages/ogb/utils/url.py"", line 13, in decide_download
>     size = int(d.info()[""Content-Length""])/GBFACTOR
>            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
> ```

Maybe because of https://github.com/snap-stanford/ogb/issues/452#issuecomment-1608233455",getting exact error recent call last file line module file line file line file line size argument must string object real number maybe,issue,negative,positive,positive,positive,positive,positive
1614843446,"I have been getting the exact same error too:

```
Traceback (most recent call last):
  File ""/storage/utk/dgl/examples/pytorch/graphsage/node_classification.py"", line 181, in <module>
    dataset = AsNodePredDataset(DglNodePropPredDataset(""ogbn-papers100M"", ""./dataset/ogbn_papers100M/""))
                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File ""/storage/utk/miniconda3/envs/dgl/lib/python3.11/site-packages/ogb/nodeproppred/dataset_dgl.py"", line 69, in __init__
    self.pre_process()
  File ""/storage/utk/miniconda3/envs/dgl/lib/python3.11/site-packages/ogb/nodeproppred/dataset_dgl.py"", line 98, in pre_process
    if decide_download(url):
       ^^^^^^^^^^^^^^^^^^^^
  File ""/storage/utk/miniconda3/envs/dgl/lib/python3.11/site-packages/ogb/utils/url.py"", line 13, in decide_download
    size = int(d.info()[""Content-Length""])/GBFACTOR
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: int() argument must be a string, a bytes-like object or a real number, not 'NoneType'
```",getting exact error recent call last file line module file line file line file line size argument must string object real number,issue,negative,positive,positive,positive,positive,positive
1614699019,"> I tried `pip install dgl -f https://data.dgl.ai/wheels/cu117/repo.html`, it successfully installed 1.1.1+cu117.
> 
> ```
> Looking in links: https://data.dgl.ai/wheels/cu117/repo.html
> Collecting dgl
>   Downloading https://data.dgl.ai/wheels/cu117/dgl-1.1.1%2Bcu117-cp310-cp310-manylinux1_x86_64.whl (87.2 MB)
>      â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 87.2/87.2 MB 7.4 MB/s eta 0:00:00
> Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)
> Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)
> Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)
> Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)
> Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)
> Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)
> Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)
> Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)
> Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)
> Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)
> Installing collected packages: dgl
> Successfully installed dgl-1.1.1+cu117
> DGL backend not selected or invalid.  Assuming PyTorch for now.
> Setting the default backend to ""pytorch"". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)
> 1.1.1+cu117
> ```

I wonder if this has to do with using a V100. Obviously I tried the same command and it did not work. 

It seems like I'm not alone:

- https://stackoverflow.com/questions/76519346/unable-to-install-dgl-cuany-version-in-google-colab/76568205#76568205
- https://discuss.dgl.ai/t/device-api-gpu-is-not-enabled/1112
- https://discuss.dgl.ai/t/dglerror-check-failed-allow-missing-device-api-cuda-is-not-enabled-please-install-the-cuda-version-of-dgl/3654/5

",tried pip install successfully looking link eta requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied collected successfully selected invalid assuming setting default change file export environment variable valid wonder obviously tried command work like alone,issue,positive,positive,positive,positive,positive,positive
1614260699,"> é‰´äºŽæ‚¨æ²¡æœ‰å‘æˆ‘æä¾›ç‰©ç†å†…å­˜çš„å¤§å°ï¼Œæˆ‘å‡è®¾æ‚¨æœ‰ä¸€ä¸ªæ ‡å‡†çš„ 16GB å†…å­˜ã€‚å¦‚ä¸Šæ‰€è¿°ï¼Œåœ¨ä¸€ä¸ªå®žéªŒä¸­å¯¹æ¯ä¸ªçºªå…ƒçš„æ‰€æœ‰å®šä½ç‚¹è¿›è¡Œé‡‡æ ·å¤§çº¦ä¼šæ¶ˆè€— 12-20GB çš„å†…å­˜ã€‚ä»¥ä¸‹æ˜¯æˆ‘å¯ä»¥å»ºè®®çš„ä¸¤ä¸ªè§£å†³æ–¹æ¡ˆï¼š
> 
> 1. æ‚¨å¯ä»¥å°†å®šä½ç‚¹é‡‡æ ·å‡½æ•°ä¿®æ”¹ä¸ºä¸€æ¬¡ä»…å¯¹ N ä¸ªæ—¶æœŸçš„å®šä½ç‚¹è¿›è¡Œé‡‡æ ·ã€‚æ‚¨å¯ä»¥æ¯ N ä¸ªçºªå…ƒè°ƒç”¨ä¸€æ¬¡å®ƒä»¥å‡å°‘å†…å­˜æ¶ˆè€—ã€‚
> 2. æ‚¨å¯ä»¥å°†é”šç‚¹é‡‡æ ·å‡½æ•°é‡å†™ä¸º Pytorch æ•°æ®é›†ï¼Œå¹¶åˆ©ç”¨æ•°æ®åŠ è½½å™¨è¿›è¡Œé¢„å–ã€‚

Thank you for your reply. My memory is 8GB, which is indeed the problem you mentioned! I will try your suggestion!",thank reply memory indeed problem try suggestion,issue,negative,neutral,neutral,neutral,neutral,neutral
1614115274,"I tried `pip install dgl -f https://data.dgl.ai/wheels/cu117/repo.html`, it successfully installed 1.1.1+cu117.
```
Looking in links: https://data.dgl.ai/wheels/cu117/repo.html
Collecting dgl
  Downloading https://data.dgl.ai/wheels/cu117/dgl-1.1.1%2Bcu117-cp310-cp310-manylinux1_x86_64.whl (87.2 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 87.2/87.2 MB 7.4 MB/s eta 0:00:00
Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.22.4)
Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (1.10.1)
Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.10/dist-packages (from dgl) (3.1)
Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (2.27.1)
Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from dgl) (4.65.0)
Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from dgl) (5.9.5)
Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (1.26.16)
Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2023.5.7)
Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (2.0.12)
Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->dgl) (3.4)
Installing collected packages: dgl
Successfully installed dgl-1.1.1+cu117
DGL backend not selected or invalid.  Assuming PyTorch for now.
Setting the default backend to ""pytorch"". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)
1.1.1+cu117
```",tried pip install successfully looking link eta requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied requirement already satisfied collected successfully selected invalid assuming setting default change file export environment variable valid,issue,positive,positive,positive,positive,positive,positive
1612728792,"@frozenbugs `dgl.sampling.sample_labors()` is not covered in existing DGL benchmarks, we need to add it in order to do performance comparison",covered need add order performance comparison,issue,negative,neutral,neutral,neutral,neutral,neutral
1612705287,"> @limaoSure Given that you haven't provided me with the size of your physical memory, I assume you have a standard 16GB of memory. As mentioned above, sampling all the anchor for each epoch in one experiment would roughly consume 12-20GB of memory. Here are two solutions I can suggest:
> 
> 1. You can modify the anchor sampling function to sample anchor for only N epochs at a time. You can call it every N epoch to reduce memory consumption.
> 2. You can rewrite the anchor sampling function as a Pytorch dataset and utilize a data loader for prefetching.

@limaoSure Here is a sample code for solution 2:
```python
class PGNNDataset(Dataset):
    def __init__(self, data, args):
        self.data = data
        self.anchor_set_ids = [get_anchors(self.data[""num_nodes""]) for _ in range(args.epoch_num)]

    def __len__(self):
        return len(self.anchor_set_ids)

    def __getitem__(self, idx):
        anchor_set = self.anchor_set_ids[idx]
        dists_max, dists_argmax = get_dist_max(anchor_set, self.data[""dists""])
        g, anchor_eid, edge_weight = get_a_graph(dists_max, dists_argmax)

        return g, anchor_eid, dists_max, edge_weight

data = get_dataset(args)
dataset = PGNNDataset(data, args)
dataloader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2, prefetch_factor=2,
                        collate_fn=lambda x: x[0])

for epoch, (g, anchor_eid, dist_max, edge_weight) in enumerate(dataloader):
    if epoch == 200:
        for param_group in optimizer.param_groups:
            param_group[""lr""] /= 10

    g = dgl.graph(g)
    g.ndata[""feat""] = torch.FloatTensor(data[""feature""])
    g.edata[""sp_dist""] = torch.FloatTensor(edge_weight)
    g_data = {
        ""graph"": g.to(device),
        ""anchor_eid"": anchor_eid,
        ""dists_max"": dist_max,
    }

    train_model(data, model, loss_func, optimizer, device, g_data)
```",given provided size physical memory assume standard memory sampling anchor epoch one experiment would roughly consume memory two suggest modify anchor sampling function sample anchor time call every epoch reduce memory consumption rewrite anchor sampling function utilize data loader sample code solution python class self data data range self return self return data data epoch enumerate epoch feat data feature graph device data model device,issue,negative,negative,neutral,neutral,negative,negative
1612581599,"> @mufeili Should I submit a pr based on the solution I mentioned to resolve this issue?

@RecLusIve-F Thanks! Let's wait for @limaoSure 's response first.",submit based solution resolve issue thanks let wait response first,issue,positive,positive,positive,positive,positive,positive
1612570886,@mufeili Should I submit a pr based on the solution I mentioned to resolve this issue?,submit based solution resolve issue,issue,positive,neutral,neutral,neutral,neutral,neutral
1612568109,"@limaoSure Given that you haven't provided me with the size of your physical memory, I assume you have a standard 16GB of memory. As mentioned above, sampling all the anchor for each epoch in one experiment would roughly consume 12-20GB of memory. Here are two solutions I can suggest:

1. You can modify the anchor sampling function to sample anchor for only N epochs at a time. You can call it every N epoch to reduce memory consumption.
2. You can rewrite the anchor sampling function as a Pytorch dataset and utilize a data loader for prefetching.",given provided size physical memory assume standard memory sampling anchor epoch one experiment would roughly consume memory two suggest modify anchor sampling function sample anchor time call every epoch reduce memory consumption rewrite anchor sampling function utilize data loader,issue,negative,negative,neutral,neutral,negative,negative
1612540324,"I've noticed that there's a CPU version implementation in `DGL` [Code](https://github.com/dmlc/dgl/blob/master/src/array/cpu/spmat_op_impl_coo.cc#L747-L760). 

I wonder if we need to follow this code? My understanding is that if our only requirement is to convert a **single** `COO` to `CSC`, this might be sufficient.",version implementation code wonder need follow code understanding requirement convert single coo might sufficient,issue,negative,negative,neutral,neutral,negative,negative
1612524152,"> @mfbalin Does the below code snippet measure the target performance improvement?
> 
> ```
> import torch
> import dgl
> 
> feat_data = torch.rand(1000, 10).pin_memory()
> idx = torch.randint(0, 1000, (1000,)).to('cuda')
> 
> # t0
> sliced_data = dgl.utils.gather_pinned_tensor_rows(feat_data, idx)
> # t1
> ```

You might want to try larger sizes though. Like if the scenario was ogbn-products, then 2M for feat_data and idx would be of size 200k. ",code snippet measure target performance improvement import torch import might want try size though like scenario would size,issue,positive,neutral,neutral,neutral,neutral,neutral
1612522114,@peizhou001 I have run the benchmark and pasted the results here.pls take a look,run pasted take look,issue,negative,neutral,neutral,neutral,neutral,neutral
1612503709,"@mfbalin Does the below code snippet measure the target performance improvement?
```
import torch
import dgl

feat_data = torch.rand(1000, 10).pin_memory()
idx = torch.randint(0, 1000, (1000,)).to('cuda')

# t0
sliced_data = dgl.utils.gather_pinned_tensor_rows(feat_data, idx)
# t1
```",code snippet measure target performance improvement import torch import,issue,negative,neutral,neutral,neutral,neutral,neutral
1612397429,"> @mfbalin Hi, how do you measure the performance improvement of this PR? existing [DGL benchmarks ](https://github.com/dmlc/dgl/tree/master/benchmarks/benchmarks)or self-customized ones?

@nv-dlasalle and I are finalizing a paper. The runtime measurements were made with our own training scripts.

If you wanted to test the performance, my suggestion would be to measure the time with different index permutations of the old and new code.",hi measure performance improvement paper made training test performance suggestion would measure time different index old new code,issue,negative,positive,neutral,neutral,positive,positive
1612396471,"@mfbalin Hi, how do you measure the performance improvement of this PR? existing [DGL benchmarks ](https://github.com/dmlc/dgl/tree/master/benchmarks/benchmarks)or self-customized ones?",hi measure performance improvement,issue,negative,neutral,neutral,neutral,neutral,neutral
1612393491,"> If there is already a test for correctness checking of UVA indexing, they should do the job. This patch is to improve the performance and the behavior should be unchanged. I was getting inconsistent performance measurements before this change, sometimes less data transferred was faster than more data transferred, etc.

I see, thanks for the clarification, if this is a performance critical pass, maybe worth to work with @Rhett-Ying to add benchmark test, feel free to make the decision based on your judgement.",already test correctness uva indexing job patch improve performance behavior unchanged getting inconsistent performance change sometimes le data transferred faster data transferred see thanks clarification performance critical pas maybe worth work add test feel free make decision based,issue,positive,positive,positive,positive,positive,positive
1612387696,"If there is already a test for correctness checking of UVA indexing, they should do the job. This patch is to improve the performance and the behavior should be unchanged. I was getting inconsistent performance measurements before this change, sometimes less data transferred was faster than more data transferred, etc.",already test correctness uva indexing job patch improve performance behavior unchanged getting inconsistent performance change sometimes le data transferred faster data transferred,issue,negative,neutral,neutral,neutral,neutral,neutral
1612377839,"> It seems you didn't install the CUDA version of DGL somehow. Can you print the `dgl.__version__` to see the version info?

That seems the case, yes. But I used the command above which on your website says it should install the CUDA version of DGL.

> pip install  dgl -f https://data.dgl.ai/wheels/cu117/repo.html 

As per my post I had to explicitly specify it, as such:

> pip install dgl==1.0.1+cu117 -f https://data.dgl.ai/wheels/cu117/repo.html


",install version somehow print see version case yes used command install version pip install per post explicitly specify pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1612366536,"There isn't a guide, but it might be helpful to read the related part in the GraphSAGE paper.",guide might helpful read related part paper,issue,negative,neutral,neutral,neutral,neutral,neutral
1612363337,It seems you didn't install the CUDA version of DGL somehow. Can you print the `dgl.__version__` to see the version info?,install version somehow print see version,issue,negative,neutral,neutral,neutral,neutral,neutral
1612359495,"Sorry, this issue falls out of my radar... I will give it another try this week with the latest code base and post it here. Thanks @Rhett-Ying ! ",sorry issue radar give another try week latest code base post thanks,issue,negative,negative,negative,negative,negative,negative
1612354126,Is it possible to add some unit test for this change and related code?,possible add unit test change related code,issue,negative,neutral,neutral,neutral,neutral,neutral
1612352204,"@yaox12 Hi Xin, can you take a look, thanks!",hi take look thanks,issue,negative,positive,positive,positive,positive,positive
1612341237,Perhaps it's better to also update the docstring and include an example.,perhaps better also update include example,issue,negative,positive,positive,positive,positive,positive
1612326714,"Hi, thanks for pointing this out. `h_self` refers to the self node embedding before neighbor aggregation.",hi thanks pointing self node neighbor aggregation,issue,negative,positive,positive,positive,positive,positive
1611569364,Is there a problem with the CI again? I don't see how the distributed tests are related to these changes.,problem see distributed related,issue,negative,neutral,neutral,neutral,neutral,neutral
1610993561,CI is aborted as no need to pass except lint check stage.,aborted need pas except lint check stage,issue,negative,neutral,neutral,neutral,neutral,neutral
1610952286,"LGTM, @Rhett-Ying please go head with the approval after your comment is addressed.",please go head approval comment,issue,positive,neutral,neutral,neutral,neutral,neutral
1610668918,"> Can you link the related issue?

OK, I have linked it.",link related issue linked,issue,negative,neutral,neutral,neutral,neutral,neutral
1610616863,"> CI pass in #5912 which includes the same commit as this PR and I'd like to merge this PR directly to `1.0.4` branch. I don't think it's a good idea to cherry-pick the temp fix for ogb which should be reverted once ogb server is back. @frozenbugs

We just need to cherry-pick the PR that fix the performance issue, for the CI related temp fix, keep them in master is enough.",pas commit like merge directly branch think good idea temp fix server back need fix performance issue related temp fix keep master enough,issue,positive,positive,positive,positive,positive,positive
1610605926,CI pass in https://github.com/dmlc/dgl/pull/5912 which includes the same commit as this PR and I'd like to merge this PR directly to `1.0.4` branch. I don't think it's a good idea to cherry-pick the temp fix for ogb which should be reverted once ogb server is back. @frozenbugs ,pas commit like merge directly branch think good idea temp fix server back,issue,positive,positive,positive,positive,positive,positive
1610601273,"@frozenbugs, @yaox12, @nv-dlasalle  I am adding some overdue tests after my initial contribution and also a specialized code path when we detect the sampling is performed over UVA.",overdue initial contribution also specialized code path detect sampling uva,issue,negative,neutral,neutral,neutral,neutral,neutral
1610574852,"> > > > 
> > > 
> > > 
> > > It occur before the first epoch. But my virtual memory is about 50000MB. ![image](https://user-images.githubusercontent.com/75509857/249074819-90e0cbee-6ef0-4ec9-81e6-6d76aacd77a8.png)
> > 
> > 
> > I think it may be related to physical memory, can I ask you about your physical memory size? You can try to modify [num_workers](https://github.com/dmlc/dgl/blob/master/examples/pytorch/P-GNN/utils.py#L303) to reduce memory usage, but the calculation time consumption will increase.
> 
> ![image](https://user-images.githubusercontent.com/75509857/249095267-95e7ecce-a5fb-4b5f-85ff-59a94ec4db91.png) The above are my computer parameters. The num_workers in the code is 4, but spawnpoolworker-5 will appear when I run.

I am asking about your physical memory size and not the storage size. Let me correct my mistake, reducing the num_workers do not reduce memory usage because the number of anchors is fixed.",occur first epoch virtual memory image think may related physical memory ask physical memory size try modify reduce memory usage calculation time consumption increase image computer code appear run physical memory size storage size let correct mistake reducing reduce memory usage number fixed,issue,negative,positive,neutral,neutral,positive,positive
1609086920,"> > > 
> > 
> > 
> > It occur before the first epoch. But my virtual memory is about 50000MB. ![image](https://user-images.githubusercontent.com/75509857/249074819-90e0cbee-6ef0-4ec9-81e6-6d76aacd77a8.png)
> 
> I think it may be related to physical memory, can I ask you about your physical memory size? You can try to modify [num_workers](https://github.com/dmlc/dgl/blob/master/examples/pytorch/P-GNN/utils.py#L303) to reduce memory usage, but the calculation time consumption will increase.

![image](https://github.com/dmlc/dgl/assets/75509857/95e7ecce-a5fb-4b5f-85ff-59a94ec4db91)
The above are my computer parameters.The num_workers in the code is 4, but spawnpoolworker-5 will appear when I run.",occur first epoch virtual memory image think may related physical memory ask physical memory size try modify reduce memory usage calculation time consumption increase image computer code appear run,issue,negative,positive,neutral,neutral,positive,positive
1609079917,"> > 
> 
> It occur before the first epoch. But my virtual memory is about 50000MB. ![image](https://user-images.githubusercontent.com/75509857/249074819-90e0cbee-6ef0-4ec9-81e6-6d76aacd77a8.png)

I think it may be related to physical memory, can I ask you about your physical memory size?
You can try to modify [num_workers](https://github.com/dmlc/dgl/blob/master/examples/pytorch/P-GNN/utils.py#L303) to reduce memory usage, but the calculation time consumption will increase.",occur first epoch virtual memory image think may related physical memory ask physical memory size try modify reduce memory usage calculation time consumption increase,issue,negative,positive,neutral,neutral,positive,positive
1608972079,"> 

It occur before the first epoch. But my virtual memory is about 50000MB.
![image](https://github.com/dmlc/dgl/assets/75509857/90e0cbee-6ef0-4ec9-81e6-6d76aacd77a8)
",occur first epoch virtual memory image,issue,negative,positive,positive,positive,positive,positive
1608965673,"> > 
> 
> After I fixed this, a new error appeared: ![b90f48982169729d90a718a1c1c8357](https://user-images.githubusercontent.com/75509857/248732760-62bc0ff7-4375-47c5-a881-301b2d252521.png) It looks as the same as before.

Did this error occur before the first experiment or after training for several experiments? 
In my env, the memory usage for running one experiment is approximately between 12-20 GB. I am not sure if this memory usage is normal, and I need to further investigate to confirm.",fixed new error error occur first experiment training several memory usage running one experiment approximately sure memory usage normal need investigate confirm,issue,negative,positive,positive,positive,positive,positive
1608878985,"> > > > Could you also provide the installation instruction you used?
> > > 
> > > 
> > > This is my installation list: `(PGNNtest) D:\ä¸‹è½½>pip list Package Version certifi 2023.5.7 charset-normalizer 3.1.0 dgl 0.7.2 idna 3.4 joblib 1.2.0 mkl-fft 1.3.6 mkl-random 1.2.2 mkl-service 2.4.0 networkx 2.6.3 numpy 1.21.2 Pillow 9.4.0 pip 23.1.2 requests 2.31.0 scikit-learn 1.0.2 scipy 1.10.1 setuptools 67.8.0 threadpoolctl 3.1.0 torch 1.10.1 torchaudio 0.10.1 torchvision 0.11.2 typing_extensions 4.6.3 urllib3 2.0.3 wheel 0.38.4`
> > 
> > 
> > What were the exact commands you used for installation? It's also possible that you did not use the correct installation instructions.
> > I download a wheelfor dgl and torch to install.
> > ![image](https://user-images.githubusercontent.com/75509857/249054161-52dcb9d2-806b-4746-88ea-96d7ebee3a24.png)
> > About pytorch,I used a official direction:`conda install pytorch==1.10.1 torchvision==0.11.2 torchaudio==0.10.1 -c pytorch`

@BarclayII Do you have any clues?",could also provide installation instruction used installation list pip list package version pillow pip torch wheel exact used installation also possible use correct installation torch install image used official direction install,issue,negative,positive,positive,positive,positive,positive
1608875599,"> 

In addition,I can import multiprocessing in other file.
![image](https://github.com/dmlc/dgl/assets/75509857/b73d6959-57d2-4d54-adcf-2827e9e54ccf)
",addition import file image,issue,negative,neutral,neutral,neutral,neutral,neutral
1608861849,"> > @RecLusIve-F Could you take a look?
> 
> Sure, I will take a look.

Thanks a lot!",could take look sure take look thanks lot,issue,positive,positive,positive,positive,positive,positive
1608861690,"> > Could you also provide the installation instruction you used?
> 
> This is my installation list: `(PGNNtest) D:\ä¸‹è½½>pip list Package Version
> 
> certifi 2023.5.7 charset-normalizer 3.1.0 dgl 0.7.2 idna 3.4 joblib 1.2.0 mkl-fft 1.3.6 mkl-random 1.2.2 mkl-service 2.4.0 networkx 2.6.3 numpy 1.21.2 Pillow 9.4.0 pip 23.1.2 requests 2.31.0 scikit-learn 1.0.2 scipy 1.10.1 setuptools 67.8.0 threadpoolctl 3.1.0 torch 1.10.1 torchaudio 0.10.1 torchvision 0.11.2 typing_extensions 4.6.3 urllib3 2.0.3 wheel 0.38.4`

What were the exact commands you used for installation? It's also possible that you did not use the correct installation instructions.",could also provide installation instruction used installation list pip list package version pillow pip torch wheel exact used installation also possible use correct installation,issue,negative,positive,positive,positive,positive,positive
1608557063,"> Can you also include the performance diff in this PR description?

The number of tests performed has been added, and the detailed benchmark can only be run once the code has been merged into the main branch.",also include performance description number added detailed run code main branch,issue,negative,positive,positive,positive,positive,positive
1607097111,"> @RecLusIve-F Could you take a look?

Sure, I will take a look.",could take look sure take look,issue,negative,positive,positive,positive,positive,positive
1606960009,"> Could you also provide the installation instruction you used?

This is my installation list:
`(PGNNtest) D:\ä¸‹è½½>pip list
Package            Version
------------------ --------
certifi            2023.5.7
charset-normalizer 3.1.0
dgl                0.7.2
idna               3.4
joblib             1.2.0
mkl-fft            1.3.6
mkl-random         1.2.2
mkl-service        2.4.0
networkx           2.6.3
numpy              1.21.2
Pillow             9.4.0
pip                23.1.2
requests           2.31.0
scikit-learn       1.0.2
scipy              1.10.1
setuptools         67.8.0
threadpoolctl      3.1.0
torch              1.10.1
torchaudio         0.10.1
torchvision        0.11.2
typing_extensions  4.6.3
urllib3            2.0.3
wheel              0.38.4`",could also provide installation instruction used installation list pip list package version pillow pip torch wheel,issue,negative,neutral,neutral,neutral,neutral,neutral
1606956554,Could you also provide the installation instruction you used?,could also provide installation instruction used,issue,negative,neutral,neutral,neutral,neutral,neutral
1606937034,"This is the error after reinstall my environment:
`D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
Using backend: pytorch
Learning Type: Transductive Task: link
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
Using backend: pytorch
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll
D:\ProgramData\Anaconda3\envs\PGNNtest\lib\site-packages\numpy\.libs\libopenblas64__v0.3.21-gcc_10_3_0.dll
  warnings.warn(""loaded more than 1 DLL from .libs:""
Using backend: pytorch
Using backend: pytorch
Using backend: pytorch
 58%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–Š                                                   | 290/500 [00:36<00:25,  8.27it/s]multiprocessing.pool.RemoteTraceback:
""""""
Traceback (most recent call last):
  File ""D:\ProgramData\Anaconda3\envs\PGNNtest\lib\multiprocessing\pool.py"", line 125, in worker
    result = (True, func(*args, **kwds))
  File ""D:\ç ”ä¸€å­¦ä¹ èµ„æ–™\VScode\GNNå¤çŽ°\utils.py"", line 279, in get_graphs
    g, anchor_eid, edge_weight = get_a_graph(dists_max, dists_argmax)
  File ""D:\ç ”ä¸€å­¦ä¹ èµ„æ–™\VScode\GNNå¤çŽ°\utils.py"", line 266, in get_a_graph
    eid_dict = {(u, v): i for i, (u, v) in enumerate(list(zip(dst, src)))}
  File ""D:\ç ”ä¸€å­¦ä¹ èµ„æ–™\VScode\GNNå¤çŽ°\utils.py"", line 266, in <dictcomp>
    eid_dict = {(u, v): i for i, (u, v) in enumerate(list(zip(dst, src)))}
MemoryError
""""""

The above exception was the direct cause of the following exception:

Traceback (most recent call last):
  File ""main.py"", line 211, in <module>
    main(args)
  File ""main.py"", line 119, in main
    ) = preselect_anchor(data, args)
  File ""D:\ç ”ä¸€å­¦ä¹ èµ„æ–™\VScode\GNNå¤çŽ°\utils.py"", line 323, in preselect_anchor
    output = [p.get() for p in results]
  File ""D:\ç ”ä¸€å­¦ä¹ èµ„æ–™\VScode\GNNå¤çŽ°\utils.py"", line 323, in <listcomp>
    output = [p.get() for p in results]
  File ""D:\ProgramData\Anaconda3\envs\PGNNtest\lib\multiprocessing\pool.py"", line 771, in get
    raise self._value
MemoryError`
It looks the same as the previous error.",error reinstall environment loaded loaded learning type task link loaded loaded loaded loaded loaded loaded loaded loaded loaded loaded loaded loaded loaded recent call last file line worker result true file line file line enumerate list zip file line enumerate list zip exception direct cause following exception recent call last file line module main file line main data file line output file line output file line get raise previous error,issue,negative,positive,neutral,neutral,positive,positive
1606924412,Thanks. Let me close this issue for now so that we can have a centralized discussion in 5900. Feel free to reopen it if you find necessary.,thanks let close issue discussion feel free reopen find necessary,issue,positive,positive,positive,positive,positive,positive
1606877789,"Sorry, I did not get your point. Do we still need to keep this issue open? Or maybe we can close the issue and make 5900 the centralized place for discussion?",sorry get point still need keep issue open maybe close issue make place discussion,issue,negative,negative,negative,negative,negative,negative
1606875696,"> 

I later installed the dgl0.7.2 version, and the error returned was the same as before, so it was released in #5900",later version error returned,issue,negative,neutral,neutral,neutral,neutral,neutral
1606694899,Can you also include the performance diff in this PR description?,also include performance description,issue,negative,neutral,neutral,neutral,neutral,neutral
1605927407,"I changed the version of dgl and downloaded dgl0.6.1, but the following errors occurred during operation:
`Exception in thread Thread-6:
Traceback (most recent call last):
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\threading.py"", line 932, in _bootstrap_inner
    self.run()
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\threading.py"", line 870, in run
    self._target(*self._args, **self._kwargs)
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\pool.py"", line 576, in _handle_results
    task = get()
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\connection.py"", line 250, in recv
    buf = self._recv_bytes()
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\connection.py"", line 318, in _recv_bytes
    return self._get_more_data(ov, maxsize)
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\connection.py"", line 340, in _get_more_data
    ov, err = _winapi.ReadFile(self._handle, left, overlapped=True)
MemoryError
Process SpawnPoolWorker-7:
Traceback (most recent call last):
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\pool.py"", line 131, in worker
    put((job, i, result))
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\queues.py"", line 362, in put
    obj = _ForkingPickler.dumps(obj)
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\reduction.py"", line 51, in dumps
    cls(buf, protocol).dump(obj)
MemoryError
During handling of the above exception, another exception occurred:
Traceback (most recent call last):
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\process.py"", line 315, in _bootstrap
    self.run()
  File ""D:\ProgramData\Anaconda3\envs\GNN\lib\multiprocessing\process.py"", line 108, in run
    self._target(*self._args, **self._kwargs)`",version following operation exception thread recent call last file line file line run file line task get file line file line return file line err left process recent call last file line worker put job result file line put file line protocol handling exception another exception recent call last file line file line run,issue,negative,neutral,neutral,neutral,neutral,neutral
1605910199,"> > > Since DGLGraph.adj() is no longer backward compatible, shouldn't this be considered a break change instead of iterating only minor versions?
> > 
> > 
> > In our 1.1.0 release note, we mentioned that `g.adj()` has a breaking change (https://github.com/dmlc/dgl/releases/tag/1.1.0).
> 
> Does it mean that DGL does not follow the protocol of [Semantic Versioning 2.0.0](https://semver.org/)? This may not be what most users expect, since minor releases usually do not contain incompatible changes. ![image](https://user-images.githubusercontent.com/65325063/248536538-95f5c31a-55d0-4917-b69e-58f2871315df.png)

Make sense! We will discuss this issue internally.",since longer backward compatible considered break change instead minor release note breaking change mean follow protocol semantic may expect since minor usually contain incompatible image make sense discus issue internally,issue,negative,negative,negative,negative,negative,negative
1605906741,"> > Since DGLGraph.adj() is no longer backward compatible, shouldn't this be considered a break change instead of iterating only minor versions?
> 
> In our 1.1.0 release note, we mentioned that `g.adj()` has a breaking change (https://github.com/dmlc/dgl/releases/tag/1.1.0).

Does it mean that DGL does not follow the protocol of [Semantic Versioning 2.0.0](https://semver.org/)? This may not be what most users expect, since minor releases usually do not contain incompatible changes.
![image](https://github.com/dmlc/dgl/assets/65325063/95f5c31a-55d0-4917-b69e-58f2871315df)
",since longer backward compatible considered break change instead minor release note breaking change mean follow protocol semantic may expect since minor usually contain incompatible image,issue,negative,negative,negative,negative,negative,negative
1605903343,"> Since DGLGraph.adj() is no longer backward compatible, shouldn't this be considered a break change instead of iterating only minor versions?

In our 1.1.0 release note, we mentioned that `g.adj()` has a breaking change (https://github.com/dmlc/dgl/releases/tag/1.1.0).",since longer backward compatible considered break change instead minor release note breaking change,issue,negative,negative,neutral,neutral,negative,negative
1605897362,"Also, would you mind add a new unit test?  We typically add unit tests of data loading in `tests/python/pytorch/dataloading` so you could add a `test_...` function in a new file like `tests/python/pytorch/dataloading/test_spot_target.py`.

There are also some lint errors in the file.  You could fix it with `lintrunner -a python/dgl/dataloading/base.py`.",also would mind add new unit test typically add unit data loading could add function new file like also lint file could fix,issue,negative,positive,neutral,neutral,positive,positive
1605893615,"> How did you install DGL 0.7.2?

I downloaded ""dgl-0.7-2-py38_0. tar. bz2"", unzipped it, and copied the dgl and dgl-0.7-2-py3.8.egg info folders inside into the site packages folder in the virtual environment.",install tar copied egg inside site folder virtual environment,issue,negative,neutral,neutral,neutral,neutral,neutral
1605838148,"> Finished the Regression test. Result table is at https://dgl-asv-data.s3-us-west-2.amazonaws.com/0216482d957139a82353668a642fb927ad24c8c6_r6i16xlarge/results/result.csv. Jenkins job link is https://dgl-jenkins-eksvpc-2136217999.us-west-2.elb.amazonaws.com/job/dgl/job/PR-5895/7/display/redirect.

LGTM in overall though fluctuation exists for several testcases such as `bench_edge_ids`.",finished regression test result table job link overall though fluctuation several,issue,negative,neutral,neutral,neutral,neutral,neutral
1605829181,"> @peizhou001 I have triggered perf test, please check the results.

Do you mean the `bench_sample_neighbors`? It is for graphbolt sampling.",triggered test please check mean sampling,issue,negative,negative,negative,negative,negative,negative
1604402035,"That still requires creating a PR for security considerations. It's better if you can create a PR for this so that I can approve it. Otherwise, I will need to ask a teammate to approve it. Thanks.",still security better create approve otherwise need ask teammate approve thanks,issue,positive,positive,positive,positive,positive,positive
1604160314,Cannot run the regression test due to unknown command,run regression test due unknown command,issue,negative,negative,negative,negative,negative,negative
1603679455,"> Finished the Regression test. Result table is at https://dgl-asv-data.s3-us-west-2.amazonaws.com/bf925a7e805e5e62e32ccd5b855d8c76466835f6_r6i16xlarge/results/result.csv. Jenkins job link is https://dgl-jenkins-eksvpc-2136217999.us-west-2.elb.amazonaws.com/job/dgl/job/PR-5895/6/display/redirect.

LGTM except api, let me re-run it.",finished regression test result table job link except let,issue,negative,neutral,neutral,neutral,neutral,neutral
1600758481,"> use â€™dgl.utils.gather_pinned_tensor_rowsâ€™ can result this problem.

`pin_memory()` will Copy the tensor to pinned memory. Maybe we need `dgl.utils.pin_memory_inplace`?

Thank you for your issue. How did you solve this problem?",use result problem copy tensor pinned memory maybe need thank issue solve problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1600756474,"> Hi @lzc17 , could you upgrade DGL to the newest version (1.0) to see whether this problem still exists?

DGL 1.0 seems to have removed this API.
https://github.com/dmlc/dgl/issues/4693 ",hi could upgrade version see whether problem still removed,issue,negative,neutral,neutral,neutral,neutral,neutral
1600408385,"> Since `DGLGraph.adj()` is no longer backward compatible, shouldn't this be considered a break change instead of iterating only minor versions?

Sorry for the late reply. I agree with you. Any thoughts? @frozenbugs @BarclayII @jermainewang ",since longer backward compatible considered break change instead minor sorry late reply agree,issue,negative,negative,negative,negative,negative,negative
1600324758,"@peizhou001  I have triggered perf test, please check the results.",triggered test please check,issue,negative,neutral,neutral,neutral,neutral,neutral
1600135651,"


> I am still encountering this problem trying to build 1.0.1 on Ubuntu 22,.04. Any workaround?
> 
> I built with gcc 9.5.0 and still have the same error.

I can either build on Ubuntu 22.04. However, I can build DGL with the source code on Ubuntu 18.04 and 20.04 using gcc-9.5.0.",still problem trying build built still error either build however build source code,issue,negative,neutral,neutral,neutral,neutral,neutral
1599417149,"Hi, I opened a pull request for this, see here https://github.com/dmlc/dgl/pull/5893. 

The issue I am having is, it has a CI test error, as reported by dgl-bot. But I didn't understand which part went wrong, according to the report. It would be great help if you can give me some ideas about this. 

Thanks,
Jing",hi pull request see issue test error understand part went wrong according report would great help give thanks jing,issue,positive,positive,positive,positive,positive,positive
1595929583,"@BarclayII could you take a look? On machines with multiple GPUs where PCI-e bandwidth is highly contested, this PR should improve things by quite a lot.",could take look multiple highly improve quite lot,issue,negative,positive,neutral,neutral,positive,positive
1595704088,"Hi @mufeili , I have updated codes with resolving unit test and lintrunner issue, and removing gcmc example from the current pr.",hi unit test issue removing example current,issue,negative,neutral,neutral,neutral,neutral,neutral
1595684982,"This can be done by converting the whole graph to networkx first, and networkx can do that.",done converting whole graph first,issue,negative,positive,positive,positive,positive,positive
1595593826,"@yaox12, could you take a look? The patch is minimal so should be fairly easy to review.",could take look patch minimal fairly easy review,issue,negative,positive,positive,positive,positive,positive
1594186455,"Overall LGTM, need to clarify the behavior of update method.",overall need clarify behavior update method,issue,negative,neutral,neutral,neutral,neutral,neutral
1594075430,"Unit tests failed due to

```
train_graph, valid_graph, test_graph = movielens[0]
```

Please also check the other part of the unit test.",unit due please also check part unit test,issue,negative,negative,negative,negative,negative,negative
1594002451,"> Hi, @gmsft, a workaround is using `randint` to generate negative samples.For example:
> 
> ```
> src = src.repeat_interleave(num_negative_samples)
> dst = randint(0, g.num_nodes, num_negative_samples)
> ```

@peizhou001 Thank you.",hi generate negative example thank,issue,negative,negative,negative,negative,negative,negative
1593299282,"@LspongebobJH Could you fix the lint issues caught by ""Lint / lintrunner (pull_request)""? Also you may remove the changes for the GCMC example.",could fix lint caught lint also may remove example,issue,negative,neutral,neutral,neutral,neutral,neutral
1593025250,"Hi @mufeili , I have finished the test. Movielens works well with new urls.",hi finished test work well new,issue,negative,positive,positive,positive,positive,positive
1592522272,"Hi, @gmsft, a workaround is using `randint` to generate negative samples.For example:
```
src = src.repeat_interleave(num_negative_samples)
dst = randint(0, g.num_nodes, num_negative_samples)
```",hi generate negative example,issue,negative,negative,negative,negative,negative,negative
1592420749,Add `train_step_node` [here](https://github.com/dmlc/dgl/blob/master/docs/source/_templates/classtemplate.rst) for rendering the doc of this function.,add rendering doc function,issue,negative,neutral,neutral,neutral,neutral,neutral
1591795017,"> Is it possible to break this PR into two PRs? It might be easier to first review the extension for homogeneous graphs and then review the extension for heterogeneous graphs after we merge the first PR.

Ok, seems like it very quickly got longer after the initial set of changes.
I can convert this PR to the homogenous impl. and raise a new for hetero impl. If it works for you",possible break two might easier first review extension homogeneous review extension heterogeneous merge first like quickly got longer initial set convert homogenous raise new hetero work,issue,positive,positive,positive,positive,positive,positive
1591013101,"> Lint check by lintrunner failed. Click ""Details"" to see the suggested fix.

Fixed",lint check click see fix fixed,issue,negative,positive,neutral,neutral,positive,positive
1590937165,"Yes, feel free to make the change in existing dataloader, we can figure out the future work of migrate the work to new design later.",yes feel free make change figure future work migrate work new design later,issue,positive,positive,positive,positive,positive,positive
1590766982,"@zheng-da  with this PR: https://github.com/dmlc/dgl/pull/5872, I think the case you mentioned should be ok as long as `etypes`/`ntypes` are same in train and inference graph. Because ntype/etype list are used at [here](https://github.com/dmlc/dgl/blob/3a0bcc0c15cd0ce445318382887cd977979514df/python/dgl/distributed/dist_graph.py#L410-L414) only. The mapping from etype to etype_id is read from `etypes` fields of part_config json.

If you could share a minimum repro, I will look into it.",think case long train inference graph list used read could share minimum look,issue,negative,negative,neutral,neutral,negative,negative
1590713278,Please also update the title / description of the PR,please also update title description,issue,negative,neutral,neutral,neutral,neutral,neutral
1590627898,Is it possible to break this PR into two PRs? It might be easier to first review the extension for homogeneous graphs and then review the extension for heterogeneous graphs after we merge the first PR.,possible break two might easier first review extension homogeneous review extension heterogeneous merge first,issue,negative,positive,positive,positive,positive,positive
1590609625,"lint checks failed

```
python/dgl/nn/pytorch/explain/pgexplainer.py:611:4: W0221: Parameters differ from overridden 'train_step_node' method (arguments-differ)
python/dgl/nn/pytorch/explain/pgexplainer.py:817:4: W0221: Parameters differ from overridden 'explain_node' method (arguments-differ)
```",lint differ method differ method,issue,negative,neutral,neutral,neutral,neutral,neutral
1590465760,"Lint check by lintrunner failed. Click ""Details"" to see the suggested fix.",lint check click see fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1590437268,"instead updating the stale code, can you copy this to examples/core/graphsage/node_classification.py?",instead stale code copy,issue,negative,negative,negative,negative,negative,negative
1589584923,"@mfbalin  I believe Method 1 is the one that's invariably correct:

**Method 1:**

```python
g = dgl.rand_graph(10, 20)
g = g.formats([""csc"", ""coo""])
g.create_formats_()
g.formats()
# {'created': ['coo', 'csc'], 'not created': []}
```

**Method 2:**

```python
g = dgl.rand_graph(10, 20)
g.create_formats_()
g = g.formats([""csc"", ""coo""])
g.formats()
# {'created': ['coo', 'csc'], 'not created': []}
```

In this case, both methods yield identical results.

- For Method 1, we initially specify `allowed_formats = [""csc"", ""coo""]`, then proceed to create all the `allowed_formats`. This is undeniably correct.

- For Method 2, **in the context of this example**:
    - We first create all `created_formats = [""csc"", ""coo"", ""csr""]`
    - Then specify `allowed_formats = [""csc"", ""coo""]` using `formats([""csc"", ""coo""])`. As per our newly established rule, we retain the intersection of `allowed_formats` and `created_formats` from the original graph, which is `[""csc"", ""coo""]`. 
    - **However, this operates under the assumption that `allowed_formats = [""csc"", ""coo"", ""csr""]` to begin with. If `allowed_formats = [""csc"", ""csr""]` initially, Method 2 fails to deliver the correct result.**


For instance, the following situation would yield an incorrect outcome. Therefore, my recommendation is: **first use `formats()` to define `allowed_formats`, then use `create_formats_()` to create all the `allowed_formats`.**

```python
g = dgl.rand_graph(10, 20)
g = g.formats([""csc"", ""csr""])
g.create_formats_()
g.formats()
# {'created': ['csr', 'csc'], 'not created': []}
######### The above is the pre-process #########
g.create_formats_()
g = g.formats([""csc"", ""coo""])
g.formats()
# {'created': ['csc'], 'not created': ['coo']}
# incorrect 
```",believe method one invariably correct method python coo method python coo case yield identical method initially specify coo proceed create undeniably correct method context example first create coo specify coo coo per newly established rule retain intersection original graph coo however assumption coo begin initially method deliver correct result instance following situation would yield incorrect outcome therefore recommendation first use define use create python coo incorrect,issue,positive,positive,positive,positive,positive,positive
1589468348,"Thanks for looking into it @keli-wen. If I want to create only csc and coo, then do I create all the formats using create_formats_() and then use formats(['csc','coo']) so that the formats only in the intersection remain, which should be csc and coo in this case?",thanks looking want create coo create use intersection remain coo case,issue,positive,positive,positive,positive,positive,positive
1588807282,"Hi @mfbalin , I believe we have now addressed the issues with the current function. We've made two primary changes, corresponding to two separate PRs:

- [x] [[Sparse] Clean formats function docstring.](https://github.com/dmlc/dgl/pull/5851): We optimized the docstring of the `DGLGraph.formats()` function and clarified the difference between `created_formats` and `allowed_formats`.
- [x] [[Sparse] Update code and add unittest for `formats`.](https://github.com/dmlc/dgl/pull/5859): We identified the logic behind creating `created_formats` when the `DGLGraph.formats()` function return the cloned graph.

Perhaps the function's behavior is not exactly what you had anticipated. However, I am confident that our revisions have made the function more comprehensible for users and capable of accommodating all their needs. 

Lastly, thank you for raising the issue; I will now close it as resolved. Please feel free to reach out if you have any further questions. âœ¨
",hi believe current function made two primary corresponding two separate sparse clean function function difference sparse update code add logic behind function return graph perhaps function behavior exactly however confident made function comprehensible capable accommodating need lastly thank raising issue close resolved please feel free reach,issue,positive,positive,positive,positive,positive,positive
1588765260,"Finally, this problem is solved in the following two PR.

#5851
#5859 ",finally problem following two,issue,negative,neutral,neutral,neutral,neutral,neutral
1588623802,"<html xmlns:v=""urn:schemas-microsoft-com:vml""
xmlns:o=""urn:schemas-microsoft-com:office:office""
xmlns:x=""urn:schemas-microsoft-com:office:excel""
xmlns=""http://www.w3.org/TR/REC-html40"">

<head>

<meta name=ProgId content=Excel.Sheet>
<meta name=Generator content=""Microsoft Excel 15"">
<link id=Main-File rel=Main-File
href=""file:////Users/ruying/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip.htm"">
<link rel=File-List
href=""file:////Users/ruying/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_filelist.xml"">
<style>
<!--table
	{mso-displayed-decimal-separator:""\."";
	mso-displayed-thousand-separator:""\,"";}
@page
	{margin:1.0in .75in 1.0in .75in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;}
tr
	{mso-height-source:auto;}
col
	{mso-width-source:auto;}
br
	{mso-data-placement:same-cell;}
td
	{padding-top:1px;
	padding-right:1px;
	padding-left:1px;
	mso-ignore:padding;
	color:black;
	font-size:12.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:Calibri, sans-serif;
	mso-font-charset:0;
	mso-number-format:General;
	text-align:general;
	vertical-align:bottom;
	border:none;
	mso-background-source:auto;
	mso-pattern:auto;
	mso-protection:locked visible;
	white-space:nowrap;
	mso-rotate:0;}
.xl63
	{mso-number-format:0%;}
-->
</style>
</head>

<body link=""#0563C1"" vlink=""#954F72"">



Â  | test_name | params | unit | Â  | number_master | machine | number_5859
-- | -- | -- | -- | -- | -- | -- | --
0 | api.bench_format_conversion.track_time | 'cora', ('coo', 'csc') | s | 0% | 0.00012357 | g4dn.16xlarge-gpu | 0.00012394
1 | api.bench_format_conversion.track_time | 'cora', ('csc', 'coo') | s | -1% | 0.00025006 | g4dn.16xlarge-gpu | 0.00024796
2 | api.bench_format_conversion.track_time | 'cora', ('coo', 'csr') | s | -2% | 0.00012885 | g4dn.16xlarge-gpu | 0.00012603
3 | api.bench_format_conversion.track_time | 'cora', ('csr', 'coo') | s | -1% | 0.00024654 | g4dn.16xlarge-gpu | 0.00024449
4 | api.bench_format_conversion.track_time | 'cora', ('csr', 'csc') | s | -7% | 0.00016098 | g4dn.16xlarge-gpu | 0.00014895
5 | api.bench_format_conversion.track_time | 'cora', ('csc', 'csr') | s | -10% | 0.00016242 | g4dn.16xlarge-gpu | 0.00014696
6 | api.bench_format_conversion.track_time | 'livejournal', ('coo', 'csc') | s | 0% | 0.0772455 | g4dn.16xlarge-gpu | 0.07726824
7 | api.bench_format_conversion.track_time | 'livejournal', ('csc', 'coo') | s | 0% | 0.14903008 | g4dn.16xlarge-gpu | 0.14906498
8 | api.bench_format_conversion.track_time | 'livejournal', ('coo', 'csr') | s | 0% | 0.05643348 | g4dn.16xlarge-gpu | 0.05643428
9 | api.bench_format_conversion.track_time | 'livejournal', ('csr', 'coo') | s | 0% | 0.11302251 | g4dn.16xlarge-gpu | 0.11290552
10 | api.bench_format_conversion.track_time | 'livejournal', ('csr', 'csc') | s | 0% | 0.11632094 | g4dn.16xlarge-gpu | 0.11637903
11 | api.bench_format_conversion.track_time | 'livejournal', ('csc', 'csr') | s | 0% | 0.11524528 | g4dn.16xlarge-gpu | 0.11522761



</body>

</html>
",urn urn office office urn office excel head meta meta excel link file link file style table page margin auto col auto padding color black normal none general general bottom border none auto auto locked visible body unit machine,issue,positive,positive,neutral,neutral,positive,positive
1588576457,@Rhett-Ying please double check the benchmark result looks good to you.,please double check result good,issue,positive,positive,positive,positive,positive,positive
1588554633,"What's the difference between this PR and #5856, if one of them are deprecated, close it or mark it as DO NOT MERGE.",difference one close mark merge,issue,negative,neutral,neutral,neutral,neutral,neutral
1587226784,"> Could you index them in the documentation by updating `dgl.data.rst` and adding corresponding unit tests? You may find it helpful to follow the practice of #5477 .

Done. Let me know if anything else is needed.",could index documentation corresponding unit may find helpful follow practice done let know anything else,issue,negative,neutral,neutral,neutral,neutral,neutral
1586903064,Could you index them in the documentation by updating `dgl.data.rst` and adding corresponding unit tests? You may find it helpful to follow the practice of #5477 .,could index documentation corresponding unit may find helpful follow practice,issue,negative,neutral,neutral,neutral,neutral,neutral
1586806986,@LspongebobJH  I've uploaded the data files to DGL's s3 bucket. Could you try it and update the code if it works? You may want to first rename the old files to avoid overwriting.,data bucket could try update code work may want first rename old avoid,issue,negative,positive,positive,positive,positive,positive
1586487633,Thank you for opening the PR! I'll take a look when I have time.,thank opening take look time,issue,negative,neutral,neutral,neutral,neutral,neutral
1586484188,"You could also directly make a PR.  The relevant code is in `dgl/dataloading/base.py`.

@frozenbugs Did our refactor go to edge exclusion in edge dataloader?  If not, I guess we can still have the change in `dgl/dataloader/base.py`, and do the refactor together?",could also directly make relevant code go edge exclusion edge guess still change together,issue,negative,positive,positive,positive,positive,positive
1586347332,Oh I see. Sounds good! I will update the code and post when I finish. Thanks!,oh see good update code post finish thanks,issue,positive,positive,positive,positive,positive,positive
1586163662,"I think the only difference between naive exclude_edges and your SpotTarget is that your SpotTarget only exclude the seed edges with low-degree incident nodes.  I guess it's better to have it like a callable to avoid overriding `EdgePredictionSampler`.

Namely, I imagine that you could do something like (maybe you need some modifications):
```
class SpotTarget(object):
    def __init__(self, g, degree_threshold=10, ...):
        self.g = g
        self.degree_threshold = degree_threshold

    def __call__(self, edge_minibatch):
        g = self.g
        src, dst = g.find_edges(seed_edges)
        head_degree = g.in_degrees(src)
        tail_degree = g.in_degrees(dst)
        degree = torch.min(head_degree, tail_degree)
        degree_mask = degree < self.degree_threshold
        edges_need_to_exclude = seed_edges[degree_mask]
        return find_exclude_eids(g, edges_need_to_exclude, ...)
```
Then users could call it like:
```
sampler = dgl.dataloading.as_edge_prediction_sampler(
    sampler,
    exclude=dgl.dataloading.edge_exclusion.SpotTarget(g),
)
```",think difference naive exclude seed incident guess better like callable avoid namely imagine could something like maybe need class object self self degree degree return could call like sampler sampler,issue,positive,positive,neutral,neutral,positive,positive
1584137295,"Once you get this to work, could you move the unit test to `tests/python/common/test_convert.py` as practiced in https://github.com/dmlc/dgl/pull/5726?",get work could move unit test practiced,issue,negative,neutral,neutral,neutral,neutral,neutral
1584009136,"I'm fine either way, though you may need extra efforts to deal with the unit tests and regression tests if the behavior gets changed.",fine either way though may need extra deal unit regression behavior,issue,negative,positive,positive,positive,positive,positive
1583944982,"Let's do this: if there are intersection, retain it, otherewise create new one  following the order coo -> csr -> csc.",let intersection retain create new one following order coo,issue,negative,positive,neutral,neutral,positive,positive
1583927193,"I'd like to discuss the behavior definition of the `formats()` function~ 

I hope you can help me. @frozenbugs @mufeili âœ¨",like discus behavior definition hope help,issue,positive,neutral,neutral,neutral,neutral,neutral
1583927114,"@frozenbugs , I made a draft following the code in our design doc. 

There is still one thing to decide: how to handle the heterogeneous information of features. In a graph, a feature array has a feature name and belongs to a specific type of nodes. I'd suggest to use `InMemoryFeatureStore` as a key-value store. When fetching/storing features, `FeatureFetcher` uses `(ntype, feat_name)` as the key to access features.",made draft following code design doc still one thing decide handle heterogeneous information graph feature array feature name specific type suggest use store key access,issue,negative,neutral,neutral,neutral,neutral,neutral
1582164771,"> 
hi,
I am doing research on recommendation. When training the model using BPR Loss(the equation is pasted below), I need positive and negative (user, item) pairs for a specific user. 
<img width=""334"" alt=""image"" src=""https://github.com/dmlc/dgl/assets/6802304/b4f9c915-96e5-4d99-9761-67556f8963e4"">
",hi research recommendation training model loss equation pasted need positive negative user item specific user image,issue,negative,negative,neutral,neutral,negative,negative
1581963719,"According to [pytorch release note](https://pytorch.org/blog/PyTorch-1.13-release/#introduction-of-cuda-116-and-117-and-deprecation-of-cuda-102-and-113), cuda 10.2 which is DGL CI is building on does not support c++17. So it failed in GPU build.

What's more, I'm afraid c++17 is not fully enabled(Below flag is applied to all required third-party libs as well?) in your PR as below line is not changed.
```
  set(CMAKE_CXX_FLAGS ""-O2 -Wall -fPIC -std=c++14 ${CMAKE_CXX_FLAGS}"")
```
https://github.com/dmlc/dgl/blob/5ada3fc94444244973b2ab0f9c23974c586e531d/CMakeLists.txt#LL91C7-L91C22",according release note building support build afraid fully flag applied well line set,issue,positive,negative,negative,negative,negative,negative
1581842500,"make[2]: *** [rpc_client] Error 1
CMakeFiles/Makefile2:283: recipe for target 'CMakeFiles/rpc_client.dir/all' failed
make[1]: *** [CMakeFiles/rpc_client.dir/all] Error 2
make[1]: *** Waiting for unfinished jobs....
libdgl.so: undefined reference to `dgl::DGLDataTypeTraits&lt;signed char&gt;::dtype'
libdgl.so: undefined reference to `dgl::DGLDataTypeTraits&lt;__half&gt;::dtype'
collect2: error: ld returned 1 exit status
CMakeFiles/rpc_server.dir/build.make:95: recipe for target 'rpc_server' failed
make[2]: *** [rpc_server] Error 1
CMakeFiles/Makefile2:319: recipe for target 'CMakeFiles/rpc_server.dir/all' failed
make[1]: *** [CMakeFiles/rpc_server.dir/all] Error 2",make error recipe target make error make waiting unfinished undefined reference char undefined reference collect error returned exit status recipe target make error recipe target make error,issue,negative,neutral,neutral,neutral,neutral,neutral
1581800688,"Hi @gmsft, what is your application scenario of this interface?",hi application scenario interface,issue,negative,neutral,neutral,neutral,neutral,neutral
1581697032,"> Some questions about heterogeneous item set.
> 
>     1. Since the input is a dictionary, how will we decide the order when `shuffle=False`? For example, given `{ 'user' : ..., 'item' : ...}`, which of the ""user"" or ""item"" ids will be iterated first?
> 
>     2. In the above example, if all the ""user"" ids have been consumed, will the returned mini-batch dictionary still contain the key `'user'` or not? If yes, what is shape/dtype of the corresponding tensor?

For 1, A number of items(this is controlled by buffer size) will be iterated and saved into a buffer, then pick one of them from the buffer when `shuffle=True` for each iteration. So in the case you mentioned, `user` will be iterated first if `len('user')` is greater than `buffer_size`(10000 in default). If not greater than `buffer_size`, then `item` may be picked up for each iteration. Here's the implementation which could help understand the shuffle logic: https://github.com/pytorch/pytorch/blob/6ac3352a37ead6bae0de9fe4c45b618f8e82dc78/torch/utils/data/datapipes/iter/combinatorics.py#L122-L135

So an enhancement is to dynamically specify the `buffer_size` to control the iteration order. For example, specify the `buffer_size` as the number of items which results in shuffle across all the items. But this could be infeasible sometimes as `ItemSet` is required to be **iterable** only and `__len__()` may be not available. `stream` is an example.

For 2, it only returns the ones picked up for the current mini-batch, so `No` if `user` has already been ran out.

@jermainewang ",heterogeneous item set since input dictionary decide order example given user item first example user returned dictionary still contain key yes corresponding tensor number buffer size saved buffer pick one buffer iteration case user first greater default greater item may picked iteration implementation could help understand shuffle logic enhancement dynamically specify control iteration order example specify number shuffle across could infeasible sometimes iterable may available stream example picked current user already ran,issue,positive,positive,positive,positive,positive,positive
1581096948,"Some questions about heterogeneous item set.

1. Since the input is a dictionary, how will we decide the order when `shuffle=False`? For example, given `{ 'user' : ..., 'item' : ...}`, which of the ""user"" or ""item"" ids will be iterated first?
2. In the above example, if all the ""user"" ids have been consumed, will the returned mini-batch dictionary still contain the key `'user'` or not? If yes, what is shape/dtype of the corresponding tensor?",heterogeneous item set since input dictionary decide order example given user item first example user returned dictionary still contain key yes corresponding tensor,issue,negative,positive,positive,positive,positive,positive
1579830469,"Hi, sorry for the late response. I was trying to catch up a paper deadline previously.  And I just found that I forgot to attach our code in the RFC request. 

 I prefer codes in Python. 

In our experiments, since all graphs are treated as undirected graph, we add the reverse edges into the graph and only take the in_degree of each node, see low. That's equivalent of taking the in_degree and out_degree for an undirected graph without reverse edges. I didn't do experiments on directed graphs. 

The SpotTarget code for low degree are shown below. Can you also point me towards the subgraph sampling code that you are trying to integrate to? And I can take a look at how to put this into the new implementation. 

```
from dgl.dataloading.base import EdgePredictionSampler, _find_exclude_eids
from collections.abc import Mapping
from dgl.base import EID, NID
from dgl.utils import recursive_apply
import dgl
import torch


def find_exclude_eids(g, seed_edges, exclude, reverse_eids=None, reverse_etypes=None,
                      output_device=None, degree_threshold=10):
    """"""Find all edge IDs to exclude according to :attr:`exclude_mode`.
    Parameters
    ----------
    g : DGLGraph
        The graph.
    exclude_mode : str, optional
        Can be either of the following,
        None (default)
            Does not exclude any edge.
        'self'
            Exclude the given edges themselves but nothing else.
        'reverse_id'
            Exclude all edges specified in ``eids``, as well as their reverse edges
            of the same edge type.
            The mapping from each edge ID to its reverse edge ID is specified in
            the keyword argument ``reverse_eid_map``.
            This mode assumes that the reverse of an edge with ID ``e`` and type
            ``etype`` will have ID ``reverse_eid_map[e]`` and type ``etype``.
        'reverse_types'
            Exclude all edges specified in ``eids``, as well as their reverse
            edges of the corresponding edge types.
            The mapping from each edge type to its reverse edge type is specified
            in the keyword argument ``reverse_etype_map``.
            This mode assumes that the reverse of an edge with ID ``e`` and type ``etype``
            will have ID ``e`` and type ``reverse_etype_map[etype]``.
        callable
            Any function that takes in a single argument :attr:`seed_edges` and returns
            a tensor or dict of tensors.
    eids : Tensor or dict[etype, Tensor]
        The edge IDs.
    reverse_eids : Tensor or dict[etype, Tensor]
        The mapping from edge ID to its reverse edge ID.
    reverse_etypes : dict[etype, etype]
        The mapping from edge etype to its reverse edge type.
    output_device : device
        The device of the output edge IDs.
    """"""
    # edges_need_to_exclude = TODO
    src, dst = g.find_edges(seed_edges)
    head_degree = g.in_degrees(src)
    tail_degree = g.in_degrees(dst)
    degree = torch.min(head_degree, tail_degree)
    degree_mask = degree < degree_threshold
    edges_need_to_exclude = seed_edges[degree_mask]
    exclude_eids = _find_exclude_eids(
        g,
        exclude,
        edges_need_to_exclude,
        reverse_eid_map=reverse_eids,
        reverse_etype_map=reverse_etypes)
    if exclude_eids is not None and output_device is not None:
        exclude_eids = recursive_apply(exclude_eids, lambda x: F.copy_to(x, output_device))
    return exclude_eids


class EdgePredictionSamplerwithDegree(EdgePredictionSampler):
    """"""Sampler class that builds upon EdgePredictionSampler
    The exlucde train target is only done on edges with a degree < 10
    TODO: Change the fixed degree to user-defined args

    ------------------------------
    Need to call this directly in the code instead of calling as_edge_prediction_sampler
    """"""

    def __init__(self, sampler, exclude=None, reverse_eids=None,
                 reverse_etypes=None, negative_sampler=None, prefetch_labels=None, degree_threshold=10):
        super().__init__(sampler, exclude, reverse_eids, reverse_etypes, negative_sampler, prefetch_labels)
        self.degree_threshold = degree_threshold

    def sample(self, g, seed_edges):  # pylint: disable=arguments-differ
        """"""Samples a list of blocks, as well as a subgraph containing the sampled
        edges from the original graph.
        If :attr:`negative_sampler` is given, also returns another graph containing the
        negative pairs as edges.
        """"""
        if isinstance(seed_edges, Mapping):
            seed_edges = {g.to_canonical_etype(k): v for k, v in seed_edges.items()}
        exclude = self.exclude
        pair_graph = g.edge_subgraph(
            seed_edges, relabel_nodes=False, output_device=self.output_device)
        eids = pair_graph.edata[EID]

        if self.negative_sampler is not None:
            neg_graph = self._build_neg_graph(g, seed_edges)
            pair_graph, neg_graph = dgl.compact_graphs([pair_graph, neg_graph])
        else:
            pair_graph = dgl.compact_graphs(pair_graph)

        pair_graph.edata[EID] = eids
        seed_nodes = pair_graph.ndata[NID]

        exclude_eids = find_exclude_eids(
            g, seed_edges, exclude, self.reverse_eids, self.reverse_etypes,
            self.output_device, self.degree_threshold)

        input_nodes, _, blocks = self.sampler.sample(g, seed_nodes, exclude_eids)

        if self.negative_sampler is None:
            return self.assign_lazy_features((input_nodes, pair_graph, blocks))
        else:
            return self.assign_lazy_features((input_nodes, pair_graph, neg_graph, blocks))
```
",hi sorry late response trying catch paper deadline previously found forgot attach code request prefer python since undirected graph add reverse graph take node see low equivalent taking undirected graph without reverse directed code low degree shown also point towards sampling code trying integrate take look put new implementation import import import nid import import import torch exclude find edge exclude according graph optional either following none default exclude edge exclude given nothing else exclude well reverse edge type edge id reverse edge id argument mode reverse edge id type id type exclude well reverse corresponding edge edge type reverse edge type argument mode reverse edge id type id type callable function single argument tensor tensor tensor edge tensor tensor edge id reverse edge id edge reverse edge type device device output edge degree degree exclude none none lambda return class sampler class upon train target done degree change fixed degree need call directly code instead calling self sampler super sampler exclude sample self list well original graph given also another graph negative exclude none else nid exclude none return else return,issue,negative,negative,neutral,neutral,negative,negative
1579776000,@keli-wen Sounds good to me! I also recommend implementing them in separate PRs.,good also recommend separate,issue,positive,positive,positive,positive,positive,positive
1579312624,"Indeed, I believe we need to first clean up the outdated docstrings in `formats()` and `create_formats_()` and add more **examples** to explain common behaviors (especially when the input parameter is of type `List[str]`). Then, we should unify the expected results of `formats` under different scenarios (for instance, when the input `formats` and the `allowed_formats` of the original graph differ). Following this, we need to update the code in `unit_graph.cc` and add sufficient unit tests.

Summing up, here's our action plan:
- [ ] Update docstrings of `formats` and `create_formats_`
- [ ] Unify the working logic of `formats`
- [ ] Modify the code in `unit_graph.cc` and add sufficient unit tests

I will create a new PR to address these issues shortly and close this PR later.",indeed believe need first clean outdated add explain common especially input parameter type list unify different instance input original graph differ following need update code add sufficient unit action plan update unify working logic modify code add sufficient unit create new address shortly close later,issue,positive,positive,neutral,neutral,positive,positive
1578747658,"> why close this PR? you could just add more commits to this PR.

OK, I put new commit in this PR",close could add put new commit,issue,negative,positive,positive,positive,positive,positive
1578332441,@caojy1998 please also take a look with your fresh eyes.,please also take look fresh,issue,positive,positive,positive,positive,positive,positive
1578331210,"Thanks for the great work, overall it is way more readable than before!",thanks great work overall way readable,issue,positive,positive,positive,positive,positive,positive
1578056856,"@mfbalin as we dig deeper into the code, it is actually work as intended, we are thinking about how to improved the docstring and maybe also polish the behavior.

Currently [dgl.DGLGraph.formats](https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.formats.html#dgl.DGLGraph.formats) clones the graph with the specified sparse format, and not guarantee to create all allowed formats.
And [dgl.DGLGraph.create_formats_](https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.create_formats_.html) will kick off the in-place creation.",dig code actually work intended thinking maybe also polish behavior currently graph sparse format guarantee create kick creation,issue,positive,neutral,neutral,neutral,neutral,neutral
1576938013,and you'd better configure author with `git config`.,better configure author git,issue,negative,positive,positive,positive,positive,positive
1576934116,"pls always pay attention on commit message, be meaningful and concise.",always pay attention commit message meaningful concise,issue,negative,positive,positive,positive,positive,positive
1576097958,@LspongebobJH Thank you for the great efforts! Could you send me the data in private? I'll test the API on my side and then upload the data to the s3 bucket if everything works well.,thank great could send data private test side data bucket everything work well,issue,positive,positive,positive,positive,positive,positive
1576082040,"> Yes, we can open a API to support python level UDF for edge filter, such that ppl can hack quickly for experiment.

I think `as_edge_prediction_sampler` already has Python UDF support.",yes open support python level edge filter hack quickly experiment think already python support,issue,positive,positive,positive,positive,positive,positive
1575591893,"@mufeili, this PR is just to make sure that the usage of the two api are as expected, can you take a look.
We will merge this PR first and then work on the implementation and override the existing ones in a upcoming PR.",make sure usage two take look merge first work implementation override upcoming,issue,negative,positive,positive,positive,positive,positive
1573714094,"Hi @mufeili ,
I have used gcmc model to test movielens API. Specifically, gcmc on ml-100k with features has RMSE 0.9473, close to the reported number(0.9448) of original implementations of gcmc example in dgl. I re-implement the gcmc example in a separate folder, with which people can re-produce the result. With the new API, the implementation of gcmc example has been largely simplified. 
For now my gcmc implementation does not follow coding standards(some hyper-parameters are hard-coded). This is because I just want to provide an simple demo to show how movielens API can be utilized and to test how it performs. This implementation(the gcmc folder in this pr) would be deleted upon you finish reviewing.",hi used model test specifically close number original example example separate folder people result new implementation example largely simplified implementation follow want provide simple show test implementation folder would upon finish,issue,negative,positive,positive,positive,positive,positive
1573266818,"> should we remove all traces of `tvm` even comments such as
> 
> https://github.com/dmlc/dgl/blob/ee00729bbeabacee848fc19fe21233b0000e78c8/src/runtime/c_object_api.cc#L3
> 
> ?

I was confused by those comment as well, I don't see it has any relation with tvm dependency but means the code is referred from tvm implementation or something.",remove even confused comment well see relation dependency code implementation something,issue,negative,negative,negative,negative,negative,negative
1573218458,"Instead of mentioning 1st version, be specific about what's implemented in the title of the PR.",instead st version specific title,issue,negative,neutral,neutral,neutral,neutral,neutral
1573191174,"@jermainewang 
> The dependencies on `cub`, `thrust` and `xbyak` have been removed in 1.0 and we are on the way to removing other unnecessary dependencies such as `tvm` and `tensorpipe`. The remaining issue METIS and GKLib which are needed by some DGL APIs. How hard is it to have them on conda forge?

Vendored `cub` and `thrust` seem to still be being used with `-DUSE_CUDA=ON` at least from just looking at `CMakeLists.txt` is this not used in the actual compilation?",cub thrust removed way removing unnecessary issue metis hard forge cub thrust seem still used least looking used actual compilation,issue,negative,negative,negative,negative,negative,negative
1572383906,"I can look into getting those on conda-forge, @hmacdope this would be another argument for building a newer version ",look getting would another argument building version,issue,negative,neutral,neutral,neutral,neutral,neutral
1572023079,"With 4 trainers, 8 omp threads, 1 sampler and 4 servers:

Old example:   14.57 (s/epoch)
New example: 17.02 (s/epoch)

-14.3% performance

Old:
Part 0, Epoch Time(s): 14.5632, sample+data_copy: 0.6239, forward: 3.8990, backward: 8.3901, update: 0.0447, #seeds: 37725, #inputs: 12750204

New:
Part 0, Epoch Time(s): 17.0236, sample+data_copy: 0.5642, forward: 1.9905, backward: 4.8677, update: 0.0422, #seeds: 37725, #inputs: 18168802",sampler old example new example performance old part epoch time forward backward update new part epoch time forward backward update,issue,negative,positive,positive,positive,positive,positive
1571689298,"Why don't we use PyTorch's default macro? E.g., `AT_DISPATCH_FLOATING_TYPES` . See https://pytorch.org/tutorials/advanced/cpp_extension.html",use default macro see,issue,negative,neutral,neutral,neutral,neutral,neutral
1571638474,@nvitucci I think for now it's fine to disable the unit tests for GPU.,think fine disable unit,issue,negative,positive,positive,positive,positive,positive
1571631740,"The dependencies on `cub`, `thrust` and `xbyak` have been removed in 1.0 and we are on the way to removing other unnecessary dependencies such as `tvm` and `tensorpipe`. The remaining issue METIS and GKLib which are needed by some DGL APIs. How hard is it to have them on conda forge?",cub thrust removed way removing unnecessary issue metis hard forge,issue,negative,negative,negative,negative,negative,negative
1571630924,@mufeili I see now it fails on the `if g.device != F.cpu()` check. I am wondering if this method should be supported at all on GPU graphs?,see check wondering method,issue,negative,neutral,neutral,neutral,neutral,neutral
1571629272,"Sorry for the confusion. It seems that `to_networkx` currently does not support GPUs. In that case, you can disable the unit tests by following the example [here](https://github.com/dmlc/dgl/blob/master/tests/python/common/data/test_data.py#L19).",sorry confusion currently support case disable unit following example,issue,negative,negative,negative,negative,negative,negative
1571545382,"> > > ```
> > >     def test_to_networkx():
> > >         # TODO: adapt and move code from the _test_nx_conversion function in
> > >         # tests/python/common/function/test_basics.py to here
> > >         # (pending resolution of https://github.com/dmlc/dgl/issues/5735).
> > >         g = dgl.heterograph(
> > >             {
> > >                 (""user"", ""follows"", ""user""): ([0, 1], [1, 2]),
> > >                 (""user"", ""follows"", ""topic""): ([1, 1], [1, 2]),
> > >                 (""user"", ""plays"", ""game""): ([0, 3], [3, 4]),
> > >             }
> > >         )
> > >     
> > >         n1 = F.randn((5, 3))
> > >         n2 = F.randn((4, 2))
> > >         e1 = F.randn((2, 3))
> > >         e2 = F.randn((2, 2))
> > >     
> > > >       g.ndata[""n""] = {""game"": n1, ""user"": n2}
> > > > FAILED tests/python/common/test_convert.py::test_to_networkx - dgl._ffi.base.DGLError: Cannot assign node feature ""n"" on device /gpu:0 to a graph on device /cpu:0. Call DGLGraph.to() to copy the graph to the same device.
> > > ```
> > 
> > 
> > I am not sure what to do here. What do you recommend?
> 
> The CI involves tests on CPU and GPU. On GPU instances, `F.randn` creates tensors on GPU. However, your graph is always on CPU. For an example of testing on different graph ID types and device, see https://github.com/dmlc/dgl/blob/master/tests/python/pytorch/nn/conv/test_gatedgcnconv.py.

I'm giving it a try with the latest commit.",adapt move code function pending resolution user user user topic user game game user assign node feature device graph device call copy graph device sure recommend however graph always example testing different graph id device see giving try latest commit,issue,positive,positive,neutral,neutral,positive,positive
1571454068,"Lint check failed

```
python/dgl/nn/pytorch/explain/pgexplainer.py:391:4: W0235: Useless super delegation in method '__init__' (useless-super-delegation)
```",lint check useless super delegation method,issue,negative,negative,neutral,neutral,negative,negative
1571447540,"Yes, we can open a API to support python level UDF for edge filter, such that ppl can hack quickly for experiment.
If we believe this is a solid option, it is better to have C++ implementation.

@jwzhi Do you prefer to code in python or c++?

Just to confirm, when you mention high-degree / low-degree edges, are they in-degree or out-degree or sum of both?

For the actual implementation, we are working on refactoring the code for subgraph sampling, we can guide you towards the new implementation instead of just implementing it in existing dgl.dataloading.as_edge_prediction_sampler, which deemed to be deprecated in the future.",yes open support python level edge filter hack quickly experiment believe solid option better implementation prefer code python confirm mention sum actual implementation working code sampling guide towards new implementation instead future,issue,positive,positive,positive,positive,positive,positive
1571332339,Let's suspend this PR until we are crystal clear about the request.,let suspend crystal clear request,issue,negative,positive,positive,positive,positive,positive
1571276479,"> > ```
> >     def test_to_networkx():
> >         # TODO: adapt and move code from the _test_nx_conversion function in
> >         # tests/python/common/function/test_basics.py to here
> >         # (pending resolution of https://github.com/dmlc/dgl/issues/5735).
> >         g = dgl.heterograph(
> >             {
> >                 (""user"", ""follows"", ""user""): ([0, 1], [1, 2]),
> >                 (""user"", ""follows"", ""topic""): ([1, 1], [1, 2]),
> >                 (""user"", ""plays"", ""game""): ([0, 3], [3, 4]),
> >             }
> >         )
> >     
> >         n1 = F.randn((5, 3))
> >         n2 = F.randn((4, 2))
> >         e1 = F.randn((2, 3))
> >         e2 = F.randn((2, 2))
> >     
> > >       g.ndata[""n""] = {""game"": n1, ""user"": n2}
> > > FAILED tests/python/common/test_convert.py::test_to_networkx - dgl._ffi.base.DGLError: Cannot assign node feature ""n"" on device /gpu:0 to a graph on device /cpu:0. Call DGLGraph.to() to copy the graph to the same device.
> > ```
> 
> I am not sure what to do here. What do you recommend?

The CI involves tests on CPU and GPU. On GPU instances, `F.randn` creates tensors on GPU. However, your graph is always on CPU. For an example of testing on different graph ID types and device, see https://github.com/dmlc/dgl/blob/master/tests/python/pytorch/nn/conv/test_gatedgcnconv.py.",adapt move code function pending resolution user user user topic user game game user assign node feature device graph device call copy graph device sure recommend however graph always example testing different graph id device see,issue,positive,negative,neutral,neutral,negative,negative
1571240712,"My feeling towards this RFC is that this could be achieved by specifying a customized edge exclusion strategy in `as_edge_prediction_sampler`: it accepts an `exclude` argument which could be a user-defined function.  Does it achieve your goal?  Or are you proposing to add this functionality into what DGL official supports?

If the latter, I imagine that it's best to have an edge exclusion callable, something like a `dgl.dataloading.edge_exclusion.SpotTarget` class that has a `__call__` method:
```python
class SpotTarget(object):
    def __init__(self, ...):
        ...
    def __call__(self, edge_minibatch):
        # return the edges to exclude given the minibatch
```

Then we can pass an instance into `as_edge_prediction_sampler`:
```python
sampler = dgl.dataloading.as_edge_prediction_sampler(
    sampler,
    exclude=dgl.dataloading.edge_exclusion.SpotTarget(...),
)
```

What do you think?

cc @frozenbugs ",feeling towards could edge exclusion strategy exclude argument could function achieve goal add functionality official latter imagine best edge exclusion callable something like class method python class object self self return exclude given pas instance python sampler sampler think,issue,negative,positive,positive,positive,positive,positive
1571226578,"Hi @yurivict , we don't have much experience on FreeBSD, do you happen to know the root source?",hi much experience happen know root source,issue,negative,positive,positive,positive,positive,positive
1571195843,Thanks for reporting the issue. We've identified it as a bug. It will be resolved by the linked PR.,thanks issue bug resolved linked,issue,positive,positive,positive,positive,positive,positive
1571187397,">The fix is supposed to be ready in latest torch 2.0.1?

Seems not there yet. There is no release tags under that commit (https://github.com/pytorch/pytorch/commit/6ea790c5b600338f848ec240dbb7cfe248e6f2de). ",fix supposed ready latest torch yet release commit,issue,positive,positive,positive,positive,positive,positive
1571179401,The fix is supposed to be ready in latest `torch 2.0.1`?,fix supposed ready latest torch,issue,negative,positive,positive,positive,positive,positive
1571034488,Please check if it is a duplicate issue of https://github.com/dmlc/dgl/issues/5480 due to a bug from PyT's `ForkingPickler` (stack trace may vary due to file/data racing).,please check duplicate issue due bug stack trace may vary due racing,issue,negative,negative,negative,negative,negative,negative
1570171066,"> ```
>     def test_to_networkx():
>         # TODO: adapt and move code from the _test_nx_conversion function in
>         # tests/python/common/function/test_basics.py to here
>         # (pending resolution of https://github.com/dmlc/dgl/issues/5735).
>         g = dgl.heterograph(
>             {
>                 (""user"", ""follows"", ""user""): ([0, 1], [1, 2]),
>                 (""user"", ""follows"", ""topic""): ([1, 1], [1, 2]),
>                 (""user"", ""plays"", ""game""): ([0, 3], [3, 4]),
>             }
>         )
>     
>         n1 = F.randn((5, 3))
>         n2 = F.randn((4, 2))
>         e1 = F.randn((2, 3))
>         e2 = F.randn((2, 2))
>     
> >       g.ndata[""n""] = {""game"": n1, ""user"": n2}
> > FAILED tests/python/common/test_convert.py::test_to_networkx - dgl._ffi.base.DGLError: Cannot assign node feature ""n"" on device /gpu:0 to a graph on device /cpu:0. Call DGLGraph.to() to copy the graph to the same device.
> ```

I am not sure what to do here. What do you recommend?",adapt move code function pending resolution user user user topic user game game user assign node feature device graph device call copy graph device sure recommend,issue,positive,negative,negative,negative,negative,negative
1569967586,"```
    def test_to_networkx():
        # TODO: adapt and move code from the _test_nx_conversion function in
        # tests/python/common/function/test_basics.py to here
        # (pending resolution of https://github.com/dmlc/dgl/issues/5735).
        g = dgl.heterograph(
            {
                (""user"", ""follows"", ""user""): ([0, 1], [1, 2]),
                (""user"", ""follows"", ""topic""): ([1, 1], [1, 2]),
                (""user"", ""plays"", ""game""): ([0, 3], [3, 4]),
            }
        )
    
        n1 = F.randn((5, 3))
        n2 = F.randn((4, 2))
        e1 = F.randn((2, 3))
        e2 = F.randn((2, 2))
    
>       g.ndata[""n""] = {""game"": n1, ""user"": n2}
> FAILED tests/python/common/test_convert.py::test_to_networkx - dgl._ffi.base.DGLError: Cannot assign node feature ""n"" on device /gpu:0 to a graph on device /cpu:0. Call DGLGraph.to() to copy the graph to the same device.
```",adapt move code function pending resolution user user user topic user game game user assign node feature device graph device call copy graph device,issue,negative,negative,negative,negative,negative,negative
1569777982,"> Lint check failed
> 
> ```
> python/dgl/convert.py:1696:0: C0301: Line too long (117/100) (line-too-long)
> python/dgl/convert.py:1716:0: C0301: Line too long (117/100) (line-too-long)
> python/dgl/convert.py:1719:0: C0301: Line too long (111/100) (line-too-long)
> python/dgl/convert.py:1759:0: C0301: Line too long (105/100) (line-too-long)
> python/dgl/convert.py:1761:0: C0301: Line too long (115/100) (line-too-long)
> python/dgl/convert.py:1763:0: C0301: Line too long (108/100) (line-too-long)
> python/dgl/convert.py:1827:0: C0301: Line too long (101/100) (line-too-long)
> python/dgl/convert.py:1831:0: C0301: Line too long (102/100) (line-too-long)
> python/dgl/convert.py:1832:0: C0301: Line too long (101/100) (line-too-long)
> ```

Strange, I didn't catch this with `ufmt`. I'll fix shortly.",lint check line long line long line long line long line long line long line long line long line long strange catch fix shortly,issue,negative,negative,neutral,neutral,negative,negative
1569763620,"Lint check failed

```
python/dgl/convert.py:1696:0: C0301: Line too long (117/100) (line-too-long)
python/dgl/convert.py:1716:0: C0301: Line too long (117/100) (line-too-long)
python/dgl/convert.py:1719:0: C0301: Line too long (111/100) (line-too-long)
python/dgl/convert.py:1759:0: C0301: Line too long (105/100) (line-too-long)
python/dgl/convert.py:1761:0: C0301: Line too long (115/100) (line-too-long)
python/dgl/convert.py:1763:0: C0301: Line too long (108/100) (line-too-long)
python/dgl/convert.py:1827:0: C0301: Line too long (101/100) (line-too-long)
python/dgl/convert.py:1831:0: C0301: Line too long (102/100) (line-too-long)
python/dgl/convert.py:1832:0: C0301: Line too long (101/100) (line-too-long)
```",lint check line long line long line long line long line long line long line long line long line long,issue,negative,negative,neutral,neutral,negative,negative
1569752327,"> I'm good. Thanks for the great efforts!

Thank you very much for the assistance, @mufeili - it was great to pair with you!",good thanks great thank much assistance great pair,issue,positive,positive,positive,positive,positive,positive
1569731576,"When the test is fixed and enabled, consider adding an `eid_attr` optional parameter as discussed with @mufeili in https://github.com/dmlc/dgl/pull/5726#discussion_r1209986934.",test fixed consider optional parameter,issue,negative,positive,neutral,neutral,positive,positive
1567974954,This might be due to sensitivity to some dependency version.,might due sensitivity dependency version,issue,negative,negative,negative,negative,negative,negative
1567950764,I cannot reproduce the issue on Ubuntu. Maybe this is due to FreeBSD.,reproduce issue maybe due,issue,negative,negative,negative,negative,negative,negative
1567874355,"> Why did you make changes related to `libxsmm`? If this was done by accident, could you revert the changes related to it?

It must have happened while updating from master. I've reverted it.",make related done accident could revert related must master,issue,negative,neutral,neutral,neutral,neutral,neutral
1567855800,"Why did you make changes related to `libxsmm`? If this was done by accident, could you revert the changes related to it?",make related done accident could revert related,issue,negative,neutral,neutral,neutral,neutral,neutral
1567777558,"> > HGT proposes that during sampling, as soon as a neighbor without timestamp is accessed from a seed node, we assign the seed node's timestamp to it (Alg. 2, Line 6 in https://arxiv.org/pdf/2003.01332.pdf).
> 
> This is the same to including them during sampling. Should be a easy patch.

Do you want to include this patch in this PR or open up a separate PR?",sampling soon neighbor without seed node assign seed node line sampling easy patch want include patch open separate,issue,negative,positive,positive,positive,positive,positive
1567719067,"> 



> The error likely related to this line.
> 
> https://github.com/dmlc/dgl/blob/53714ca83112f0747061b53b4f1d3e0b5fd80611/tests/distributed/test_distributed_sampling.py#L33
> 
> Since the fix, the formats time will increase, which caused the timeout.

Actually, when I checked the log, I found that the error **might** come from:

`dgl._ffi.base.DGLError: [15:59:30] /root/jenkins/workspace/dgl_PR-5708/src/array/cpu/./rowwise_pick.h:340: Check failed: (j + 1 == len) || (et[et_idx[j]] <= et[et_idx[j + 1]]): Edge type is not sorted. Please sort in advance or specify 'rowwise_etype_sorted' as false.`

Because I noticed that after this error occurred, it started to time out.

Before the repair of the `formats` function, there was actually only one Edge type, so could it be possible that this CHECK has not been functioning before the repair of the `formats` function?
",error likely related line since fix time increase actually checked log found error might come check edge type sorted please sort advance specify error time repair function actually one edge type could possible check repair function,issue,negative,neutral,neutral,neutral,neutral,neutral
1567714440,"The error likely related to this line.

https://github.com/dmlc/dgl/blob/53714ca83112f0747061b53b4f1d3e0b5fd80611/tests/distributed/test_distributed_sampling.py#L33

Since the fix, the formats time will increase, which caused the timeout.",error likely related line since fix time increase,issue,negative,neutral,neutral,neutral,neutral,neutral
1567279600,"It is a perfect PR, thanks for take the effort to improve the quality.",perfect thanks take effort improve quality,issue,positive,positive,positive,positive,positive,positive
1566939614,"> 

I see. That will be a more fundamental change to the existing pipeline.",see fundamental change pipeline,issue,negative,neutral,neutral,neutral,neutral,neutral
1566590187,"Hey @BarclayII  I have been working on getting a build going on here https://github.com/conda-forge/staged-recipes/pull/22691 an extension of the now stale https://github.com/conda-forge/staged-recipes/pull/18620. The build is still quite WIP.  

You can see the CMake changes I have been making to get this to work on my branch https://github.com/hmacdope/dgl/tree/conda-forge3 .  I would appreciate any help / feedback on the recipe as I go.

I have been building the 0.8.2 version due to some CUB/Thrust  versioning issues documented in #1855  but I am guessing we will probably either vendor CUB/Thrust or somehow link against `cuda-cccl-impl ` from CF (https://github.com/conda-forge/cuda-cccl-impl-feedstock, see discussion here https://github.com/conda-forge/thrust-feedstock/issues/19).  We may also need to do some work to push some of the last few dependencies in the fantastic [table](https://github.com/dmlc/dgl/issues/1855#issuecomment-1443916992) by @hadim onto CF. ",hey working getting build going extension stale build still quite see making get work branch would appreciate help feedback recipe go building version due guessing probably either vendor somehow link see discussion may also need work push last fantastic table onto,issue,positive,negative,neutral,neutral,negative,negative
1566572085,"> what if there are multiple seed nodes?

In this case, a seed node should have its own computation graph; the computation graphs will be disjoint.",multiple seed case seed node computation graph computation disjoint,issue,negative,neutral,neutral,neutral,neutral,neutral
1565195185,"> HGT proposes that during sampling, as soon as a neighbor without timestamp is accessed from a seed node, we assign the seed node's timestamp to it (Alg. 2, Line 6 in https://arxiv.org/pdf/2003.01332.pdf).

This is the same to including them during sampling. Should be a easy patch.

> Another possible option is not to require the neighbors on each layer has timestamps earlier than the nodes on the next layer, but instead just require all the sampled nodes with a timestamp in all the layers is no later than the seed nodes at the last layer.

I will suggest to create a new sampling operator so we keep both options open for experiments. Also, what if there are multiple seed nodes? Does this require the sampled nodes to have timestamp smaller than *any* of the seed nodes? or depending on their connectivity?
",sampling soon neighbor without seed node assign seed node line sampling easy patch another possible option require layer next layer instead require later seed last layer suggest create new sampling operator keep open also multiple seed require smaller seed depending connectivity,issue,positive,positive,neutral,neutral,positive,positive
1565150165,"> I have a high-level question. Is it sufficient to call `to_homogeneous` first and then use the previous PGExplainer implementation for homogeneous graphs? If not, what will be the gaps?

I believe the gap in this approach is that the Heterograph classifier will not be usable by existing PGExplainer when performing model evaluations

The approach I've gone with has been to store the edge mask in its homograph format in order to keep the internals of PGExplainer intact, and use the context from the `EIDS` data to reobtain the heterograph edge mask",question sufficient call first use previous implementation homogeneous believe gap approach classifier usable model approach gone store edge mask homograph format order keep internals intact use context data reobtain edge mask,issue,negative,positive,neutral,neutral,positive,positive
1564070509,DGL does support graph classification.  You could see our GIN example.  To do text classification you will probably need to construct a graph yourself.  You could refer [here](https://docs.dgl.ai/guide/data-process.html#processing-graph-classification-datasets) for how to build a graph classification dataset.,support graph classification could see gin example text classification probably need construct graph could refer build graph classification,issue,negative,neutral,neutral,neutral,neutral,neutral
1563958853,"I have a high-level question. Is it sufficient to call `to_homogeneous` first and then use the previous PGExplainer implementation for homogeneous graphs? If not, what will be the gaps?",question sufficient call first use previous implementation homogeneous,issue,negative,positive,neutral,neutral,positive,positive
1563912257,"> > @mufeili Do I always need to tag the dgl-bot manually?
> 
> @nvitucci Sorry for the unpleasant experience. Currently only core developers are granted the permission to trigger it. I'll trigger that for you once I finish a review. I will greatly appreciate it if you can wait till I finish a round of review to save some back-and-forth efforts.

Thanks! No worries - I thought I had to do it myself, but since it's not the case I'll leave you to trigger it whenever it's most convenient.",always need tag manually sorry unpleasant experience currently core permission trigger trigger finish review greatly appreciate wait till finish round review save thanks thought since case leave trigger whenever convenient,issue,positive,negative,neutral,neutral,negative,negative
1563864318,"> @mufeili Do I always need to tag the dgl-bot manually?

@nvitucci Sorry for the unpleasant experience. Currently only core developers are granted the permission to trigger it. I'll trigger that for you once I finish a review. I will greatly appreciate it if you can wait till I finish a round of review to save some back-and-forth efforts.",always need tag manually sorry unpleasant experience currently core permission trigger trigger finish review greatly appreciate wait till finish round review save,issue,negative,negative,negative,negative,negative,negative
1563546202,@mufeili Do I always need to tag the dgl-bot manually?,always need tag manually,issue,negative,neutral,neutral,neutral,neutral,neutral
1562547000,"> Did you test it with real data?

what is real data? like `ogbn-products`? actually current test case test little.",test real data real data like actually current test case test little,issue,negative,positive,neutral,neutral,positive,positive
1562478720,"> > @LspongebobJH Have you tested on the model examples that use MovieLens?
> 
> @mufeili Oh not yet. I think I can try on IGMC model? We just switched from IGMC PR to the work of MovieLens before. I can try to replace implementations of MovieLens in IGMC PR with the API that we implement in the current PR and see how the model perform.

@LspongebobJH Sure. I just want to see if you can get similar accuracy numbers.",tested model use oh yet think try model switched work try replace implement current see model perform sure want see get similar accuracy,issue,negative,positive,positive,positive,positive,positive
1562371176,"when reproducing this issue, I hit an other known issue: https://github.com/dmlc/dgl/issues/5528#issuecomment-1562360361",issue hit known issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1562360361,"this issue is reproduced with below command which runs `//example/pytorch/graphsage/dist/train_dist.py` with `ogbn-products` on 4x`r6i.16xlarge`. DGL: `1.1.0`. Pytorch: `2.0.1`
```
python3 ~/workspace/dgl/tools/launch.py \
        --workspace ~/workspace/dgl/examples/pytorch/graphsage/dist/ \
        --num_trainers 2 \
        --num_samplers 2 \
        --num_servers 2 \
        --part_config data/ogb-product.json \
        --ip_config ip_config.txt \
        ""python3 train_dist.py --graph_name ogb-product --ip_config ip_config.txt --num_epochs 10 --batch_size 1000""
```",issue command python python,issue,negative,neutral,neutral,neutral,neutral,neutral
1562156459,"We found that adding bias would help in our dataset (MovieLens).  They can also be thought of intrinsic properties of the users and items themselves (like a ""baseline rating"" of an item, etc.).  You cannot directly use dot product as item similarity though: you will need to add the bias of items.",found bias would help also thought intrinsic like rating item directly use dot product item similarity though need add bias,issue,positive,positive,neutral,neutral,positive,positive
1562109127,could you add more about how to reproduce this issue? share the key part of `DistDataLoader`?,could add reproduce issue share key part,issue,negative,neutral,neutral,neutral,neutral,neutral
1560764797,"> @nvitucci Lint check failed
> 
> ```
> python/dgl/convert.py:1809:0: C0301: Line too long (103/100) (line-too-long)
> python/dgl/convert.py:1810:0: C0301: Line too long (101/100) (line-too-long)
> python/dgl/convert.py:1813:0: C0301: Line too long (104/100) (line-too-long)
> python/dgl/convert.py:1814:0: C0301: Line too long (103/100) (line-too-long)
> ```

You're right, I couldn't run the linter after the change - will fix later.",lint check line long line long line long line long right could run linter change fix later,issue,negative,positive,neutral,neutral,positive,positive
1560745954,"@nvitucci Lint check failed

```
python/dgl/convert.py:1809:0: C0301: Line too long (103/100) (line-too-long)
python/dgl/convert.py:1810:0: C0301: Line too long (101/100) (line-too-long)
python/dgl/convert.py:1813:0: C0301: Line too long (104/100) (line-too-long)
python/dgl/convert.py:1814:0: C0301: Line too long (103/100) (line-too-long)
```",lint check line long line long line long line long,issue,negative,negative,neutral,neutral,negative,negative
1560675502,"> Thank you for the report. I think this issue is irrelevant to this PR as this PR focuses on `to_networkx`. Could you open a separate issue so that we can take a deeper look later?

Issue created [here](https://github.com/dmlc/dgl/issues/5735).",thank report think issue irrelevant could open separate issue take look later issue,issue,negative,negative,negative,negative,negative,negative
1560645626,"I found that in our datasets not all of the nodes have timestamps.  In this case, we need to think of how to sample to/from nodes without timestamps.

HGT proposes that during sampling, as soon as a neighbor without timestamp is accessed from a seed node, we assign the seed node's timestamp to it (Alg. 2, Line 6 in https://arxiv.org/pdf/2003.01332.pdf).

Another possible option is not to require the neighbors on each layer has timestamps earlier than the nodes on the next layer, but instead just require all the sampled nodes with a timestamp in all the layers is no later than the seed nodes at the last layer.

EDIT: I'll go for the second option and rewrite the code a bit.",found case need think sample without sampling soon neighbor without seed node assign seed node line another possible option require layer next layer instead require later seed last layer edit go second option rewrite code bit,issue,negative,neutral,neutral,neutral,neutral,neutral
1560637174,"> @mufeili I've moved the existing test in the new module and enabled it, but it fails even without my changes with `dgl._ffi.base.DGLError: Expect edge_id_attr_name and edge_attrs to be None when nx_graph is undirected, got None and ['h']`. The offending lines are the following:
> 
> ```
> nxg = nx.cycle_graph(5)
> nxg.remove_nodes_from([0, 4])
> for u in nxg.nodes():
>     nxg.nodes[u][""h""] = F.tensor([u])
> for u, v, d in nxg.edges(data=True):
>     d[""h""] = F.tensor([u, v])
> 
> g = dgl.from_networkx(nxg, node_attrs=[""h""], edge_attrs=[""h""])
> ```
> 
> For the time being I've disabled it again as it is not directly relevant to this PR. Is this a known issue that led to disable it in the first place?

Thank you for the report. I think this issue is irrelevant to this PR as this PR focuses on `to_networkx`. Could you open a separate issue so that we can take a deeper look later?",test new module even without expect none undirected got none following time disabled directly relevant known issue led disable first place thank report think issue irrelevant could open separate issue take look later,issue,negative,positive,neutral,neutral,positive,positive
1560553031,Close the issue for now. Feel free to reopen it if you have any further questions.,close issue feel free reopen,issue,positive,positive,positive,positive,positive,positive
1560537952,"<strike>

```
This issue is breakdown into two PRs.
1. Support shared memory in the C++ side.
2. Provide Python interface to copy/load graph and add unittests.
```
</strike>

This issue is breakdown into three PRs.
1. Provide `SharedMemory` class for read/write on shared memory. (#5737)
2. Read/write CSCSamplingGraph on shared memory on the C++ side. (#5738)
3. Add Python interface and unittests.",strike issue breakdown two support memory side provide python interface graph add issue breakdown three provide class memory memory side add python interface,issue,negative,neutral,neutral,neutral,neutral,neutral
1560379655,"@frozenbugs @anko-intel As shown [here](https://github.com/dmlc/dgl/pull/5725#issuecomment-1560370505), performance result looks good to me.",shown performance result good,issue,negative,positive,positive,positive,positive,positive
1560127057,"Thanks for your comment. We do calculate the loss for the target edges that are not excluded, so these edges still suffer from the overfitting and distribution shift issues. However, since the target edges that we don't exclude are high-degree edges, the negative effects are diluted throughout the message passing process, and thus we found that excluding low-degree edges only achieves the best trade-off between avoiding overfitting and distribution shift issues as well as avoiding mini-batch graph structure corruption. Our paper will be put on Arxiv soon.
Let me know if you have any questions on this. ",thanks comment calculate loss target still suffer distribution shift however since target exclude negative effect diluted throughout message passing process thus found excluding best distribution shift well graph structure corruption paper put soon let know,issue,negative,positive,positive,positive,positive,positive
1560051161,"@mufeili I've moved the existing test in the new module and enabled it, but it fails even without my changes with `dgl._ffi.base.DGLError: Expect edge_id_attr_name and edge_attrs to be None when nx_graph is undirected, got None and ['h']`. The offending lines are the following:

```
nxg = nx.cycle_graph(5)
nxg.remove_nodes_from([0, 4])
for u in nxg.nodes():
    nxg.nodes[u][""h""] = F.tensor([u])
for u, v, d in nxg.edges(data=True):
    d[""h""] = F.tensor([u, v])

g = dgl.from_networkx(nxg, node_attrs=[""h""], edge_attrs=[""h""])
```

For the time being I've disabled it again as it is not directly relevant to this PR. Is this a known issue that led to disable it in the first place?",test new module even without expect none undirected got none following time disabled directly relevant known issue led disable first place,issue,negative,positive,positive,positive,positive,positive
1559878370,"> Could you add unit tests following the steps below?
> 
>     1. Create a file `tests/python/common/test_convert.py`.
> 
>     2. Add a function `test_to_networkx` in this file. You can move the old unit tests [here](https://github.com/dmlc/dgl/blob/master/tests/python/common/function/test_basics.py#L202) to the new file and further augment them.

Of course. I'll do that with the next commits.",could add unit following create file add function file move old unit new file augment course next,issue,negative,positive,neutral,neutral,positive,positive
1559789928,"@Rhett-Ying , you can see below my results for kernel (left  side ""before"" and right side ""after""). There are some differences but when comparing two runs for the same dgl version measurement noise seems to be similar. Maybe you have some advice on how to achieve more stable results.

Â· Running '/home/ubuntu/miniconda3/envs/dgl/bin/python -c import sys; print(str(sys.version_info[0]) + ""."" + str(sys.version_info[1]))' | = | Â· Running '/home/ubuntu/miniconda3/envs/dgl/bin/python -c import sys; print(str(sys.version_info[0]) + ""."" + str(sys.version_info[1]))'
-- | -- | --
OUTPUT --------> | Â  | OUTPUT -------->
3.11 | Â  | 3.11
Â· Discovering benchmarks | Â  | Â· Discovering benchmarks
Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py discover /home/ubuntu/dgl/benchmarks/benchmarks /tmp/tmpafl9_0yp/result.json' in existing-py_home_ubuntu_miniconda3_envs_dgl_bin_python | <> | Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py discover /home/ubuntu/dgl/benchmarks/benchmarks /tmp/tmp4q2u3ppn/result.json' in existing-py_home_ubuntu_miniconda3_envs_dgl_bin_python
Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/bin/python /home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py discover /home/ubuntu/dgl/benchmarks/benchmarks /tmp/tmpafl9_0yp/result.json' | Â  | Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/bin/python /home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py discover /home/ubuntu/dgl/benchmarks/benchmarks /tmp/tmp4q2u3ppn/result.json'
OUTPUT --------> | = | OUTPUT -------->
WARNING:root:No regression test conf file specified | Â  | WARNING:root:No regression test conf file specified
Skip track_time | Â  | Skip track_time
Skip track_time | Â  | Skip track_time
Â· Running 4 total benchmarks (1 commits * 1 environments * 4 benchmarks) | Â  | Â· Running 4 total benchmarks (1 commits * 1 environments * 4 benchmarks)
[Â  0.00%] Â·Â· Benchmarking existing-py_home_ubuntu_miniconda3_envs_dgl_bin_python | Â  | [Â  0.00%] Â·Â· Benchmarking existing-py_home_ubuntu_miniconda3_envs_dgl_bin_python
[Â  0.00%] Â·Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py run_server /home/ubuntu/dgl/benchmarks/benchmarks /tmp/asv-forkserver-89h2x5ax/socket' in existing-py_home_ubuntu_miniconda3_envs_dgl_bin_python | <> | [Â  0.00%] Â·Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py run_server /home/ubuntu/dgl/benchmarks/benchmarks /tmp/asv-forkserver-ww_we49w/socket' in existing-py_home_ubuntu_miniconda3_envs_dgl_bin_python
[Â  0.00%] Â·Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/bin/python /home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py run_server /home/ubuntu/dgl/benchmarks/benchmarks /tmp/asv-forkserver-89h2x5ax/socket' | Â  | [Â  0.00%] Â·Â·Â· Running '/home/ubuntu/miniconda3/envs/dgl/bin/python /home/ubuntu/miniconda3/envs/dgl/lib/python3.11/site-packages/asv/benchmark.py run_server /home/ubuntu/dgl/benchmarks/benchmarks /tmp/asv-forkserver-ww_we49w/socket'
[Â  0.00%] Â·Â·Â· Importing benchmark suite produced output: | = | [Â  0.00%] Â·Â·Â· Importing benchmark suite produced output:
[Â  0.00%] Â·Â·Â·Â· WARNING:root:No regression test conf file specified | Â  | [Â  0.00%] Â·Â·Â·Â· WARNING:root:No regression test conf file specified
Skip track_time | Â  | Skip track_time
Skip track_time | Â  | Skip track_time
Â  | Â  | Â 
[ 25.00%] Â·Â·Â· kernel.bench_edgesoftmax.track_timeÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  ok | Â  | [ 25.00%] Â·Â·Â· kernel.bench_edgesoftmax.track_timeÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  ok
[ 25.00%] Â·Â·Â· ============ =========== ======================== | Â  | [ 25.00%] Â·Â·Â· ============ =========== ========================
graphÂ  Â  Â  num_heads | Â  | graphÂ  Â  Â  num_heads
------------ ----------- ------------------------ | Â  | ------------ ----------- ------------------------
ogbn-arxivÂ  Â  Â Â  1Â  Â  Â Â  0.0011310587500338442 | <> | ogbn-arxivÂ  Â  Â Â  1Â  Â  Â Â  0.0011382399099238683
ogbn-arxivÂ  Â  Â Â  4Â  Â  Â  Â Â 0.004254575899976771 | Â  | ogbn-arxivÂ  Â  Â Â  4Â  Â  Â Â  0.0031023316900245846
ogbn-arxivÂ  Â  Â Â  8Â  Â  Â  Â  0.00875412162997236 | Â  | ogbn-arxivÂ  Â  Â Â  8Â  Â  Â  Â  0.008733313990087482
redditÂ  Â  Â  Â Â  1Â  Â  Â  Â  0.11246175466003479 | Â  | redditÂ  Â  Â  Â Â  1Â  Â  Â  Â  0.11392187857010867
redditÂ  Â  Â  Â Â  4Â  Â  Â  Â Â  0.446870473040035 | Â  | redditÂ  Â  Â  Â Â  4Â  Â  Â  Â Â  0.4465752463199897
redditÂ  Â  Â  Â Â  8Â  Â  Â  Â Â  0.9219349361099012 | Â  | redditÂ  Â  Â  Â Â  8Â  Â  Â  Â Â  0.9194804022800236
coraÂ  Â  Â  Â  Â  1Â  Â  Â Â Â 0.00010186715997406281 | Â  | coraÂ  Â  Â  Â  Â  1Â  Â  Â Â Â 9.789346004254184e-05
coraÂ  Â  Â  Â  Â  4Â  Â  Â Â  0.00011752254999009892 | Â  | coraÂ  Â  Â  Â  Â  4Â  Â  Â Â  0.0001176776499778498
coraÂ  Â  Â  Â  Â  8Â  Â  Â Â  0.00013455052001518197 | Â  | coraÂ  Â  Â  Â  Â  8Â  Â  Â Â  0.00013412340995273554
pubmedÂ  Â  Â  Â Â  1Â  Â  Â Â  0.00017928322005900555 | Â  | pubmedÂ  Â  Â  Â Â  1Â  Â  Â Â  0.00017482308991020545
pubmedÂ  Â  Â  Â Â  4Â  Â  Â Â  0.0002805396598705556 | Â  | pubmedÂ  Â  Â  Â Â  4Â  Â  Â Â  0.0002886389500054065
pubmedÂ  Â  Â  Â Â  8Â  Â  Â Â  0.00044040321008651515 | Â  | pubmedÂ  Â  Â  Â Â  8Â  Â  Â Â  0.00044198404997587205
============ =========== ======================== | = | ============ =========== ========================
Â  | Â  | Â 
[ 50.00%] Â·Â·Â· kernel.bench_gsddmm_u_dot_v.track_flopsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  ok | Â  | [ 50.00%] Â·Â·Â· kernel.bench_gsddmm_u_dot_v.track_flopsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  ok
[ 50.00%] Â·Â·Â· =============== =========== ======= ======= ======= | Â  | [ 50.00%] Â·Â·Â· =============== =========== ======= ======= =======
--Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  num_heads | Â  | --Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  num_heads
--------------------------- ----------------------- | Â  | --------------------------- -----------------------
graphÂ  Â  Â Â  feat_sizeÂ  Â Â  0Â  Â  Â Â  1Â  Â  Â Â  4 | Â  | graphÂ  Â  Â Â  feat_sizeÂ  Â Â  0Â  Â  Â Â  1Â  Â  Â Â  4
=============== =========== ======= ======= ======= | Â  | =============== =========== ======= ======= =======
ogbn-arxivÂ  Â  Â  Â  4Â  Â  Â Â  17.99Â Â  18.81Â  Â  6.5 | <> | ogbn-arxivÂ  Â  Â  Â  4Â  Â  Â Â  18.26Â Â  18.23Â  Â  6.64
ogbn-arxivÂ  Â  Â  Â  32Â  Â  Â  49.27Â Â Â 48.94Â Â  34.04 | Â  | ogbn-arxivÂ  Â  Â  Â  32Â  Â  Â  48.41Â Â Â 32.23Â Â Â 33.56
ogbn-arxivÂ  Â  Â Â  256Â  Â  Â  43.23Â  Â Â 43.3Â  Â Â 45.8 | Â  | ogbn-arxivÂ  Â  Â Â  256Â  Â  Â  44.67Â Â Â 44.73Â Â  47.44
redditÂ  Â  Â  Â  Â  4Â  Â  Â Â  19.56Â Â  19.32Â  Â Â 7.05 | Â  | redditÂ  Â  Â  Â  Â  4Â  Â  Â Â  18.87Â Â  18.84Â  Â Â 6.99
redditÂ  Â  Â  Â  Â  32Â  Â  Â  55.25Â Â  56.53Â Â  39.46 | Â  | redditÂ  Â  Â  Â  Â  32Â  Â  Â  54.68Â Â  54.75Â Â Â  38.3
redditÂ  Â  Â  Â Â  256Â  Â  Â  49.89Â Â  49.45Â Â  56.17 | Â  | redditÂ  Â  Â  Â Â  256Â  Â  Â  49.43Â Â  49.49Â Â Â Â 55.4
ogbn-proteinsÂ  Â  Â Â  4Â  Â  Â Â  21.81Â Â Â  21.8Â  Â  7.17 | Â  | ogbn-proteinsÂ  Â  Â Â  4Â  Â  Â Â  21.64Â Â  21.79Â  Â  7.19
ogbn-proteinsÂ  Â  Â Â  32Â  Â  Â  76.73Â  Â Â 75.9Â Â  46.39 | Â  | ogbn-proteinsÂ  Â  Â Â  32Â  Â  Â  75.47Â Â  76.06Â Â  46.17
ogbn-proteinsÂ  Â  Â  256Â  Â  Â  60.79Â Â  60.57Â Â  75.79 | Â  | ogbn-proteinsÂ  Â  Â  256Â  Â  Â  60.49Â Â Â  60.6Â Â Â  75.5
=============== =========== ======= ======= ======= | = | =============== =========== ======= ======= =======
Â  | Â  | Â 
[ 75.00%] Â·Â·Â· kernel.bench_gspmm_copy_u.track_flopsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  ok | Â  | [ 75.00%] Â·Â·Â· kernel.bench_gspmm_copy_u.track_flopsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  ok
[ 75.00%] Â·Â·Â· =============== =========== ======== ======== | Â  | [ 75.00%] Â·Â·Â· =============== =========== ======== ========
--Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  reducer | Â  | --Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  reducer
--------------------------- ----------------- | Â  | --------------------------- -----------------
graphÂ  Â  Â Â  feat_sizeÂ  Â  sumÂ  Â  Â  max | Â  | graphÂ  Â  Â Â  feat_sizeÂ  Â  sumÂ  Â  Â  max
=============== =========== ======== ======== | Â  | =============== =========== ======== ========
ogbn-arxivÂ  Â  Â  Â  4Â  Â  Â  Â Â 9.77Â  Â Â  6.15 | <> | ogbn-arxivÂ  Â  Â  Â  4Â  Â  Â Â Â 10.28Â  Â Â  6.84
ogbn-arxivÂ  Â  Â  Â  32Â  Â  Â  35.71Â  Â Â Â 5.23 | Â  | ogbn-arxivÂ  Â  Â  Â  32Â  Â  Â  30.96Â  Â Â Â 4.99
ogbn-arxivÂ  Â  Â Â  256Â  Â  Â  13.58Â  Â Â  4.24 | Â  | ogbn-arxivÂ  Â  Â Â  256Â  Â Â  Â Â 13.6Â  Â Â  4.31
redditÂ  Â  Â  Â  Â  4Â  Â  Â Â  28.81Â  Â  22.77 | Â  | redditÂ  Â  Â  Â  Â  4Â  Â  Â Â  28.67Â  Â  22.66
redditÂ  Â  Â  Â  Â  32Â  Â  Â  122.58Â Â  85.87 | Â  | redditÂ  Â  Â  Â  Â  32Â  Â  Â  121.92Â Â  82.71
redditÂ  Â  Â  Â Â  256Â  Â  Â  59.64Â  Â  48.34 | Â  | redditÂ  Â  Â  Â Â  256Â  Â  Â  59.64Â  Â  47.86
ogbn-proteinsÂ  Â  Â Â  4Â  Â  Â Â  45.85Â  Â  39.78 | Â  | ogbn-proteinsÂ  Â  Â Â  4Â  Â  Â Â  44.51Â  Â  38.14
ogbn-proteinsÂ  Â  Â Â  32Â  Â  Â  160.92Â Â Â 107.14 | Â  | ogbn-proteinsÂ  Â  Â Â  32Â  Â  Â  189.27Â Â Â 121.76
ogbn-proteinsÂ  Â  Â  256Â  Â  Â Â Â 86.3Â  Â Â 68.74 | Â  | ogbn-proteinsÂ  Â  Â  256Â  Â  Â Â 95.55Â  Â Â Â 78.0
=============== =========== ======== ======== | = | =============== =========== ======== ========
Â  | Â  | Â 
[100.00%] Â·Â·Â· kernel.bench_gspmm_u_mul_e_sum.track_flopsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ok | Â  | [100.00%] Â·Â·Â· kernel.bench_gspmm_u_mul_e_sum.track_flopsÂ  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  ok
[100.00%] Â·Â·Â· =============== =========== ======= ======= ======= | Â  | [100.00%] Â·Â·Â· =============== =========== ======= ======= =======
--Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  num_heads | Â  | --Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â  Â Â  num_heads
--------------------------- ----------------------- | Â  | --------------------------- -----------------------
graphÂ  Â  Â Â  feat_sizeÂ  Â Â  0Â  Â  Â Â  1Â  Â  Â Â  4 | Â  | graphÂ  Â  Â Â  feat_sizeÂ  Â Â  0Â  Â  Â Â  1Â  Â  Â Â  4
=============== =========== ======= ======= ======= | Â  | =============== =========== ======= ======= =======
ogbn-arxivÂ  Â  Â  Â  4Â  Â  Â  Â Â 9.24Â  Â Â 7.96Â  Â Â 9.32 | <> | ogbn-arxivÂ  Â  Â  Â  4Â  Â  Â Â Â 11.21Â  Â Â 9.22Â Â Â 10.92
ogbn-arxivÂ  Â  Â  Â  32Â  Â  Â  26.38Â Â  16.62Â Â  13.64 | Â  | ogbn-arxivÂ  Â  Â  Â  32Â  Â  Â  27.66Â Â  18.41Â Â  14.59
ogbn-arxivÂ  Â  Â Â  256Â  Â  Â Â 19.86Â Â  14.83Â Â  14.16 | Â  | ogbn-arxivÂ  Â  Â Â  256Â  Â Â  Â Â 20.2Â Â  14.84Â Â  14.61
redditÂ  Â  Â  Â  Â  4Â  Â  Â Â  25.59Â  Â  6.13Â Â  25.66 | Â  | redditÂ  Â  Â  Â  Â  4Â  Â  Â Â  25.57Â  Â  6.08Â Â  25.66
redditÂ  Â  Â  Â  Â  32Â  Â  Â  53.87Â Â Â  10.6Â Â  10.16 | Â  | redditÂ  Â  Â  Â  Â  32Â  Â  Â  53.61Â Â  10.53Â Â  10.02
redditÂ  Â  Â  Â Â  256Â  Â  Â  37.23Â Â  11.85Â Â  11.75 | Â  | redditÂ  Â  Â  Â Â  256Â  Â  Â  37.31Â Â  11.72Â Â  11.68
ogbn-proteinsÂ  Â  Â Â  4Â  Â  Â Â  14.02Â  Â  4.73Â Â  14.01 | Â  | ogbn-proteinsÂ  Â  Â Â  4Â  Â  Â  Â Â 14.3Â  Â  4.86Â Â  14.32
ogbn-proteinsÂ  Â  Â Â  32Â  Â  Â  52.76Â Â  12.27Â  Â Â 9.94 | Â  | ogbn-proteinsÂ  Â  Â Â  32Â  Â  Â  52.82Â Â  12.34Â Â Â 10.12
ogbn-proteinsÂ  Â  Â  256Â  Â  Â Â 48.34Â Â Â 18.11Â Â  18.06 | Â  | ogbn-proteinsÂ  Â  Â  256Â  Â  Â Â 51.27Â Â Â 20.48Â Â  19.22
=============== =========== ======= ======= ======= | = | =============== =========== ======= ======= =======
Â ",see kernel left side right side two version measurement noise similar maybe advice achieve stable running import print running import print output output running discover running discover running discover running discover output output warning root regression test file warning root regression test file skip skip skip skip running total running total running running running running suite produced output suite produced output warning root regression test file warning root regression test file skip skip skip skip graph graph cora cora cora cora cora cora graph graph reducer reducer graph sum graph sum graph graph,issue,negative,positive,neutral,neutral,positive,positive
1559744882,"> @anko-intel Thanks for your detailed benchmark. so you run the benchmark tests(`//benchmarks/bencmarks/model_speed/`) manually 3 times for `before` and `after`? what does the `norm` mean?

Exactly, ""norm"" is the normalized against the average of all measurements, so 
""norm before 1"" =  6 * ""before 1"" / (""before 1"" + ""before 2"" + ""before 3"" + ""after 1"" + ""after 2"" + ""after 3"")",thanks detailed run manually time norm mean exactly norm average norm,issue,negative,positive,neutral,neutral,positive,positive
1559626502,@anko-intel  Thanks for your detailed benchmark. so you run the benchmark tests(`//benchmarks/bencmarks/model_speed/`) manually 3 times for `before` and `after`? what does the `norm` mean?,thanks detailed run manually time norm mean,issue,negative,positive,neutral,neutral,positive,positive
1559592610,"model_speed benchmark results comparison - measured on r6i.16xlarge:

measurement: | before 1 | before 2 | before 3 | after 1 | after 2 | after 3 | average | norm     before 1 | norm     before 2 | norm     before 3 | norm     afterÂ  1 | norm     after 2 | norm     after 3
-- | --:| --:| --:| --:| --:| --:| --:| --:| --:| --:| --:| --:| --:
bench_gat | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
cora | 0.01024 | 0.00998 | 0.01018 | 0.01030 | 0.01025 | 0.01065 | 0.01027 | 1.00 | 0.97 | 0.99 | 1.00 | 1.00 | 1.04
pubmed | 0.02502 | 0.02481 | 0.02481 | 0.02551 | 0.02522 | 0.02544 | 0.02513 | 1.00 | 0.99 | 0.99 | 1.01 | 1.00 | 1.01
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_gat_ns | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
reddit | 0.18059 | 0.19042 | 0.18632 | 0.18783 | 0.18489 | 0.18476 | 0.18580 | 0.97 | 1.02 | 1.00 | 1.01 | 1.00 | 0.99
ogbn-products | 0.14602 | 0.15572 | 0.15408 | 0.14738 | 0.15401 | 0.15504 | 0.15204 | 0.96 | 1.02 | 1.01 | 0.97 | 1.01 | 1.02
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_gcn_udf | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
cora | 0.07316 | 0.07355 | 0.07409 | 0.07673 | 0.07742 | 0.07453 | 0.07491 | 0.98 | 0.98 | 0.99 | 1.02 | 1.03 | 0.99
pubmed | 0.29299 | 0.29790 | 0.29712 | 0.30024 | 0.30462 | 0.29558 | 0.29808 | 0.98 | 1.00 | 1.00 | 1.01 | 1.02 | 0.99
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_rgcn_base | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
aifb | 0.04329 | 0.04359 | 0.04246 | 0.04370 | 0.04420 | 0.04396 | 0.04353 | 0.99 | 1.00 | 0.98 | 1.00 | 1.02 | 1.01
am | 10.37056 | 10.09430 | 10.08628 | 10.22588 | 10.18912 | 10.11450 | 10.18011 | 1.02 | 0.99 | 0.99 | 1.00 | 1.00 | 0.99
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_rgcn_hetero_ns | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
ogbn-mag | 0.05138 | 0.05330 | 0.05449 | 0.05622 | 0.05399 | 0.05393 | 0.05388 | 0.95 | 0.99 | 1.01 | 1.04 | 1.00 | 1.00
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_rgcn_homogeneous_ns | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
am | 0.04285 | 0.04330 | 0.04761 | 0.05277 | 0.04385 | 0.04528 | 0.04594 | 0.93 | 0.94 | 1.04 | 1.15 | 0.95 | 0.99
ogbn-mag | 0.25833 | 0.25994 | 0.26225 | 0.27063 | 0.27175 | 0.26653 | 0.26490 | 0.98 | 0.98 | 0.99 | 1.02 | 1.03 | 1.01
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_sage | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
cora | 0.00587 | 0.00580 | 0.00590 | 0.00544 | 0.00617 | 0.00610 | 0.00588 | 1.00 | 0.99 | 1.00 | 0.93 | 1.05 | 1.04
pubmed | 0.01603 | 0.01557 | 0.01539 | 0.01587 | 0.01563 | 0.01558 | 0.01568 | 1.02 | 0.99 | 0.98 | 1.01 | 1.00 | 0.99
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_sage_ns | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
reddit | 0.06692 | 0.06176 | 0.06148 | 0.06193 | 0.06195 | 0.06421 | 0.06304 | 1.06 | 0.98 | 0.98 | 0.98 | 0.98 | 1.02
ogbn-products | 0.04192 | 0.04435 | 0.03661 | 0.04042 | 0.03592 | 0.04288 | 0.04035 | 1.04 | 1.10 | 0.91 | 1.00 | 0.89 | 1.06
Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
bench_sage_unsupervised_ns | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
data num_negs batch_size | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â  | Â 
reddit 2 1024 | 0.11821 | 0.11685 | 0.11432 | 0.12712 | 0.13065 | 0.12333 | 0.12175 | 0.97 | 0.96 | 0.94 | 1.04 | 1.07 | 1.01
reddit 2 2048 | 0.18127 | 0.18031 | 0.16444 | 0.17690 | 0.18323 | 0.15626 | 0.17373 | 1.04 | 1.04 | 0.95 | 1.02 | 1.05 | 0.90
reddit 2 8192 | 0.30967 | 0.33396 | 0.32851 | 0.31851 | 0.31305 | 0.32724 | 0.32182 | 0.96 | 1.04 | 1.02 | 0.99 | 0.97 | 1.02
reddit 8 1024 | 0.13431 | 0.13038 | 0.12919 | 0.12307 | 0.13011 | 0.11825 | 0.12755 | 1.05 | 1.02 | 1.01 | 0.96 | 1.02 | 0.93
reddit 8 2048 | 0.18101 | 0.18233 | 0.18684 | 0.17120 | 0.18257 | 0.16623 | 0.17836 | 1.01 | 1.02 | 1.05 | 0.96 | 1.02 | 0.93
reddit 8 8192 | 0.32082 | 0.30227 | 0.34359 | 0.33585 | 0.30942 | 0.33261 | 0.32409 | 0.99 | 0.93 | 1.06 | 1.04 | 0.95 | 1.03
reddit 32 1024 | 0.12201 | 0.10646 | 0.12281 | 0.11819 | 0.11648 | 0.12170 | 0.11794 | 1.03 | 0.90 | 1.04 | 1.00 | 0.99 | 1.03
reddit 32 2048 | 0.18263 | 0.17405 | 0.17880 | 0.17810 | 0.17057 | 0.17413 | 0.17638 | 1.04 | 0.99 | 1.01 | 1.01 | 0.97 | 0.99
reddit 32 8192 | 0.30220 | 0.30273 | 0.31293 | 0.30121 | 0.32689 | 0.34095 | 0.31449 | 0.96 | 0.96 | 1.00 | 0.96 | 1.04 | 1.08

",comparison measured measurement average norm norm norm norm norm norm cora cora cora data,issue,negative,negative,negative,negative,negative,negative
1559259429,"@Rhett-Ying do we have any existing regression test related to libxsmm that can be kicked off for this PR?

It is nicer to check the performance if we have a ready regression test case, if not, feel free to merge if you have already manually verified.",regression test related check performance ready regression test case feel free merge already manually,issue,positive,positive,positive,positive,positive,positive
1559057452,I think you can remove `xbyak` sub module as well,think remove sub module well,issue,negative,neutral,neutral,neutral,neutral,neutral
1558851646,"Could you add unit tests following the steps below?

1. Create a file `tests/python/common/test_convert.py`.
2. Add a function `test_to_networkx` in this file. You can move the old unit tests [here](https://github.com/dmlc/dgl/blob/master/tests/python/common/function/test_basics.py#L202) to the new file and further augment them.",could add unit following create file add function file move old unit new file augment,issue,negative,positive,neutral,neutral,positive,positive
1558807659,"> @LspongebobJH Have you tested on the model examples that use MovieLens?

@mufeili Oh not yet. I think I can try on IGMC model? We just switched from IGMC PR to the work of MovieLens before. I can try to replace implementations of MovieLens in IGMC PR with the API that we implement in the current PR and see how the model perform.",tested model use oh yet think try model switched work try replace implement current see model perform,issue,negative,neutral,neutral,neutral,neutral,neutral
1558362760,"Hi @mfbalin, we do not deprecate CUDA 10.2 for now. Let's keep this PR open and merge it after the deprecation.",hi deprecate let keep open merge deprecation,issue,negative,neutral,neutral,neutral,neutral,neutral
1557298190,"> Before constructing a C++ CSCSamplingGraph, is it possible to get the metadata of its tensors, such as their shapes (# nodes and # edges) and dtypes. This is helpful when loading the graph from shared memory. Otherwise the writing process needs to serialize these information to shared memory to share to other reading processes.

This could be added in the `metadata` structure at python side, we can discuss it later to make the descision. ",possible get helpful loading graph memory otherwise writing process need serialize information memory share reading could added structure python side discus later make,issue,positive,neutral,neutral,neutral,neutral,neutral
1557250806,"Before constructing a C++ CSCSamplingGraph, is it possible to get the metadata of its tensors, such as their shapes (# nodes and # edges) and dtypes. This is helpful when loading the graph from shared memory. Otherwise the writing process needs to serialize these information to shared memory to share to other reading processes.",possible get helpful loading graph memory otherwise writing process need serialize information memory share reading,issue,positive,neutral,neutral,neutral,neutral,neutral
1556929737,"@mufeili The MovieLens API has been tested. I put testing codes in a script file `test_movielens.py`. Furthermore, the example codes in the doc of MovieLens have also been tested.",tested put testing script file furthermore example doc also tested,issue,negative,neutral,neutral,neutral,neutral,neutral
1556524670,"If we only exclude a part of the training edges, do we compute losses only on those edges?  If we also compute losses on the edges not excluded during sampling, then would it cause label leakage during training?",exclude part training compute also compute sampling would cause label leakage training,issue,negative,neutral,neutral,neutral,neutral,neutral
1556511709,I'm good other than the minor comment above as the graph can be on a GPU.,good minor comment graph,issue,negative,positive,positive,positive,positive,positive
1555889038,"> @LspongebobJH Have you tried your latest code with an end-to-end example on MovieLens to verify its correctness?

Not yet. I'll let you know after I finish testing.",tried latest code example verify correctness yet let know finish testing,issue,negative,positive,positive,positive,positive,positive
1555282603,"Since data preprocessing pipeline is being restructured, the verification script might change accordingly. If agreed this PR can be merged into the master branch or we can wait until the restructuring of code is completed and then work on the verification script depending on the needs at that time.",since data pipeline verification script might change accordingly agreed master branch wait code work verification script depending need time,issue,negative,neutral,neutral,neutral,neutral,neutral
1554526122,"> > @Rhett-Ying Do you think if we need to trigger a regression test for this change?
> 
> Why we have concern about regression after we update unit test? Does this PR affect performance?

It's possible that the behavior change of ""g.formats"" affects some performance numbers, for better or for worse. I also suspect that this affects some unit tests for distributed training, causing the CI for distributed training to constantly fail.",think need trigger regression test change concern regression update unit test affect performance possible behavior change performance better worse also suspect unit distributed training causing distributed training constantly fail,issue,negative,negative,neutral,neutral,negative,negative
1554299931,"> @Rhett-Ying Do you think if we need to trigger a regression test for this change?

Why we have concern about regression after we update unit test? Does this PR affect performance?",think need trigger regression test change concern regression update unit test affect performance,issue,negative,neutral,neutral,neutral,neutral,neutral
1554235045,"Sure, I'll promptly rename and expand the unit test as you suggested. Expect an updated PR soon.",sure promptly rename expand unit test expect soon,issue,positive,positive,positive,positive,positive,positive
1554220066,@Rhett-Ying Do you think if we need to trigger a regression test for this change?,think need trigger regression test change,issue,negative,neutral,neutral,neutral,neutral,neutral
1554219617,Could you rename the unit test [here](https://github.com/dmlc/dgl/blob/master/tests/python/common/test_heterograph.py#L2527) to `test_formats` and expand it to cover the cases previously DGL failed to handle?,could rename unit test expand cover previously handle,issue,negative,negative,negative,negative,negative,negative
1554177579,Thank you for the report. I confirm the bug. Could you help fix it by opening a PR?,thank report confirm bug could help fix opening,issue,positive,neutral,neutral,neutral,neutral,neutral
1554147235,@LspongebobJH Have you tried your latest code with an end-to-end example on MovieLens to verify its correctness?,tried latest code example verify correctness,issue,negative,positive,positive,positive,positive,positive
1554011367,"In terms of benchmarks, the datasets you selected (ogbn-products and ogbn-papers100M) are good. We'd like to further see the performance under different sampling configurations:

* Different fanout values. Typical cases are: 10, 15, 30
* Different number of hops. Typical cases are: 2, 3
* Getting the entire neighborhood instead of sampling. This is needed by some evaluation task. In the original `dgl.dataloading.NeighborSampler`, this can be configured by passing fanout = -1.
* Larger batch sizes, e.g., 10K, which is possible for some link prediction task.

cc @Rhett-Ying ",selected good like see performance different sampling different typical different number typical getting entire neighborhood instead sampling evaluation task original passing batch size possible link prediction task,issue,positive,positive,neutral,neutral,positive,positive
1554006976,"Thanks for the detailed RFC and explanation. This is in general a great effort to accelerate a critical part of the end-to-end GNN training, so we'd like to see this being integrated into DGL. According to the offline discussion, there are two options moving forward:

**Option.1**: Add this as a new operator to the `dgl.sampling` namespace. Reimplement `dgl.dataloading.NeighborSampler` ([this part](https://github.com/dmlc/dgl/blob/cc5c2379650bfda06bf331ad42d565962032b7af/python/dgl/dataloading/neighbor_sampler.py#L141-L160)) to invoke fused operator. This requires the new fused implementation to be compatible with the existing interface of `dgl.sampling.sample_neighbors` such as supporting `exclude_edges`. This option is more user-friendly because the optimization requires no user-side code changes.

**Option.2**: Add a new sampler object to the `dgl.dataloading` namespace as an alternative to the original `dgl.dataloading.NeighborSampler`. The two samplers may not need to share the same interface. However, the option is less user-friendly since users need to learn the new API.

We should try to target Option.1 first and see if there are any blockers. Option.2 is generally a temporary workaround.

The other conclusion is that this effort can be done independently with the existing effort (called GraphBolt) to refactor `dgl.dataloading` and `dgl.sampling`. Feel free to contribute it directly to current DGL codebase and we will handle the migration later.

cc @frozenbugs ",thanks detailed explanation general great effort accelerate critical part training like see according discussion two moving forward option add new operator part invoke fused operator new fused implementation compatible interface supporting option optimization code option add new sampler object alternative original two may need share interface however option le since need learn new try target option first see option generally temporary conclusion effort done independently effort feel free contribute directly current handle migration later,issue,positive,positive,positive,positive,positive,positive
1553920340,Enable CI lint in another PR because of too many check fails.,enable lint another many check,issue,negative,positive,positive,positive,positive,positive
1553915195,"> Hi @WMX567 , is the problem resolved? Let us know if you have more questions.

No, the problem is still there. I could not reproduce it.",hi problem resolved let u know problem still could reproduce,issue,negative,neutral,neutral,neutral,neutral,neutral
1553119999,"Nightly build should be back online. @paoxiaode please try it. I will close this for now, but feel free to reopen if the issue still exists.",nightly build back please try close feel free reopen issue still,issue,positive,positive,positive,positive,positive,positive
1552736600,"@daniil-sizov As I mentioned [here](https://github.com/dmlc/dgl/issues/5528#issuecomment-1517465927), it crashed even tcmalloc is loaded in my side. could you share how you load tcmalloc?",even loaded side could share load,issue,negative,neutral,neutral,neutral,neutral,neutral
1552366218,"The new CUB and Thrust releases require CUDA 11.0 from my understanding. That is why I was waiting for a reply in #4501 to see if CUDA 10.2 support would be maintained or not. Otherwise, additional effort is required to choose the thrust version according to the CUDA version and maintain multiple versions of the code. I created this PR to show that future thrust/CUB versions have benefits for the DGL code base so that maintainers can decide how to proceed. Even if this PR is not merged now, it could be merged in the future. Bumping the submodule thrust/CUB version breaks the current DGL CI for CUDA 10.2.",new cub thrust require understanding waiting reply see support would otherwise additional effort choose thrust version according version maintain multiple code show future code base decide proceed even could future bumping version current,issue,negative,negative,negative,negative,negative,negative
1552344699,"> Is it possible to add unittests in Python?

I plan to add test when python-level CSCSamplingGraph is added which also includes python bindings. Or these 2 PRs will have much in common.",possible add python plan add test added also python much common,issue,negative,negative,negative,negative,negative,negative
1552331872,"@chang-l  below is what I changed and it crashed with different error from yours.

```
python3 examples/pytorch/multigpu/multi_gpu_node_classification.py --gpu 0
```

```
ValueError: num_workers must be 0 if UVA sampling is enabled.
```

```
--- a/examples/pytorch/multigpu/multi_gpu_node_classification.py
+++ b/examples/pytorch/multigpu/multi_gpu_node_classification.py
@@ -132,7 +132,7 @@ def train(
         batch_size=1024,
         shuffle=True,
         drop_last=False,
-        num_workers=0,
+        num_workers=4,
         use_ddp=True,
         use_uva=use_uva,
     )
@@ -187,8 +187,8 @@ def run(proc_id, nprocs, devices, g, data, mode):
         rank=proc_id,
     )
     num_classes, train_idx, val_idx, test_idx = data
-    train_idx = train_idx.to(device)
-    val_idx = val_idx.to(device)
+    #train_idx = train_idx.to(device)
+    #val_idx = val_idx.to(device)
     g = g.to(device if mode == ""puregpu"" else ""cpu"")
```",different error python must uva sampling train run data mode data device device device device device mode else,issue,negative,neutral,neutral,neutral,neutral,neutral
1552330721,"From the above discussion, this PR may depends on the CUDA version. @mfbalin can you keep the current implementation and use the new code when CUDA version is greater than 11.0?

> Not yet, I just recently contributed DeviceCopy to CUB in this https://github.com/NVIDIA/cub/pull/675, I guess it will be included in the next release. I don't know the timeline of the next release though.

Does it mean this PR depends on a unreleased version of CUB? If so, we cannot merge this PR for now.
",discussion may version keep current implementation use new code version greater yet recently cub guess included next release know next release though mean unreleased version cub merge,issue,negative,positive,neutral,neutral,positive,positive
1552323724,@daniil-sizov Could you resolve the conflict? So we can merge this effort.,could resolve conflict merge effort,issue,negative,neutral,neutral,neutral,neutral,neutral
1552322824,@yaox12  Would you like to review the code?,would like review code,issue,negative,neutral,neutral,neutral,neutral,neutral
1552313681,@hnisonoff could you make sure torch is able to built from source on ppc? or you could file a ticket in torch forum?,could make sure torch able built source could file ticket torch forum,issue,negative,positive,positive,positive,positive,positive
1551065629,"> LGTM. Do you have a follow-up item to add unittest?

I plan to add python-level tests only which will be added in another python PR.",item add plan add added another python,issue,negative,neutral,neutral,neutral,neutral,neutral
1550902515,"Since `DGLGraph.adj()` is no longer backward compatible, shouldn't this be considered a break change instead of iterating only minor versions? ",since longer backward compatible considered break change instead minor,issue,negative,negative,neutral,neutral,negative,negative
1550608023,"@hnisonoff  oh, sorry. for metis issue, I think you have to modify it manually. As for the protobuf issue, it looks like related to torch build. what torch version are you using? could you try to build torch from source to see if it's related to torch only?",oh sorry metis issue think modify manually issue like related torch build torch version could try build torch source see related torch,issue,negative,negative,negative,negative,negative,negative
1550068318,"@Rhett-Ying I wasn't able to build the conda environment using the script on this architecture. However, I do have a conda environment that should have the dependencies. 

It sounds like you were expecting that I shouldn't have to manually edit the `/third-party/METIS/GKlib/GKlibSystem.cmake` file. Is that correct?


I am still getting the protobuf errors that I described above.",able build environment script architecture however environment like manually edit file correct still getting,issue,negative,positive,positive,positive,positive,positive
1549245817,"> ðŸ¤” Quite strange, is it allowed to directly merge a PR without passing CI/CD?

It finally works. I've merged the PR. Thanks for your patience :)",quite strange directly merge without passing finally work thanks patience,issue,negative,positive,neutral,neutral,positive,positive
1549174090,"ðŸ¤” Quite strange, is it allowed to directly merge a PR without passing CI/CD?",quite strange directly merge without passing,issue,negative,positive,neutral,neutral,positive,positive
1549022951,"> could you enable the cpp unit tests for graphbolt? probably it's better to enable in another standalone PR.

As we discussed
1. Python test can cover all scenarios.
2. C test is pretty time consuming and require CMake file change, let's not add this for now.",could enable unit probably better enable another python test cover test pretty time consuming require file change let add,issue,positive,positive,positive,positive,positive,positive
1549007910,I did have to modify that file manually even after removing the directory and re-cloning the master branch. I am now trying to build the dev conda environment and re-build.,modify file manually even removing directory master branch trying build dev environment,issue,negative,neutral,neutral,neutral,neutral,neutral
1549003662,are you modifying manually? How about sync the latest master branch and build from scratch(`rm -rf builds` beforehand)?,manually sync latest master branch build scratch beforehand,issue,negative,positive,positive,positive,positive,positive
1548986379,"I think we are making progress. After modifying `/third-party/METIS/GKlib/GKlibSystem.cmake` the build progressed further until erroring here:

```
-- Build files have been written to: /g/g12/nisonoff/projects/dgl/build
[  2%] Built target dmlc
[ 22%] Built target tensorpipe_uv
[ 32%] Built target metis
[ 49%] Built target tensorpipe
[100%] Built target dgl
-DCUDA_TOOLKIT_ROOT_DIR=/usr/tce/packages/cuda/cuda-11.6.1 -DTORCH_CUDA_ARCH_LIST=6.0;7.0;7.5;8.0;8.6 -DUSE_CUDA=ON -DDGL_INCLUDE_DIRS=/usr/tce/packages/cuda/cuda-11.6.1/include;/g/g12/nisonoff/projects/dgl/include;/g/g12/nisonoff/projects/dgl/third_party/dlpack/include;/g/g12/nisonoff/projects/dgl/third_party/dmlc-core/include;/g/g12/nisonoff/projects/dgl/third_party/phmap/;/g/g12/nisonoff/projects/dgl/third_party/xbyak/;/g/g12/nisonoff/projects/dgl/third_party/METIS/include/;/g/g12/nisonoff/projects/dgl/tensoradapter/include;/g/g12/nisonoff/projects/dgl/third_party/nanoflann/include;/g/g12/nisonoff/projects/dgl/third_party/libxsmm/include;/g/g12/nisonoff/projects/dgl/third_party/pcg/include;/g/g12/nisonoff/projects/dgl/third_party/METIS/GKlib;/g/g12/nisonoff/projects/dgl/third_party/METIS/include;/g/g12/nisonoff/projects/dgl/third_party/tensorpipe -DDGL_BUILD_DIR=/g/g12/nisonoff/projects/dgl/build
-- Using Python interpreter: python3
-- find_cmake.py output: /usr/workspace/nisonoff/anaconda/envs/opence-1.8.0/lib/python3.9/site-packages/torch/share/cmake;1.13.0
-- Configuring for PyTorch 1.13.0
-- Setting directory to /usr/workspace/nisonoff/anaconda/envs/opence-1.8.0/lib/python3.9/site-packages/torch/share/cmake/Torch
CMake Warning at /usr/workspace/nisonoff/anaconda/envs/opence-1.8.0/lib/python3.9/site-packages/torch/share/cmake/Caffe2/public/protobuf.cmake:88 (message):
  Protobuf cannot be found.  Depending on whether you are building Caffe2 or
  a Caffe2 dependent library, the next warning / error will give you more
  info.
Call Stack (most recent call first):
  /usr/workspace/nisonoff/anaconda/envs/opence-1.8.0/lib/python3.9/site-packages/torch/share/cmake/Caffe2/Caffe2Config.cmake:56 (include)
  /usr/workspace/nisonoff/anaconda/envs/opence-1.8.0/lib/python3.9/site-packages/torch/share/cmake/Torch/TorchConfig.cmake:68 (find_package)
  CMakeLists.txt:29 (find_package)

```

I tried installing protobuf with `condo install -c conda-forge protobuf` but this error remained.
",think making progress build build written built target built target built target metis built target built target python interpreter python output setting directory warning message found depending whether building dependent library next warning error give call stack recent call first include tried install error,issue,negative,positive,neutral,neutral,positive,positive
1548748403,@mfbalin We have added this into our special topic and will discuss it this Thursday.,added special topic discus,issue,negative,positive,positive,positive,positive,positive
1548289570,Sorry for the delay will check today. ,sorry delay check today,issue,negative,negative,negative,negative,negative,negative
1546865783,Struggling to follow that example. Is there a guide to using it?,struggling follow example guide,issue,negative,neutral,neutral,neutral,neutral,neutral
1546282610,"@czkkkkkk, @BarclayII and @diogosilva30 is there any update about this.
I have code running torch in mac M1 and it work really fast. It would be great if we can run DGL directly using MPS  ",update code running torch mac work really fast would great run directly,issue,positive,positive,positive,positive,positive,positive
1544591946,"The loss can be negative as it is a difference between positive loss and negative loss. https://github.com/dmlc/dgl/blob/master/examples/pytorch/mvgrl/graph/utils.py#L63-L83

If the positives' scores are lower than negatives' scores, it will become negative.",loss negative difference positive loss negative loss lower become negative,issue,negative,negative,negative,negative,negative,negative
1544587217,"This can happen in self-supervised node/graph representation learning tasks, as there are some studies claiming that an untrained GNN can already perform quite well. If the self-supervised loss function is not consistent with the downstream tasks, pertaining can harm the performance.

There is train/test split in: https://github.com/dmlc/dgl/blob/master/examples/pytorch/mvgrl/graph/utils.py#L12-L26",happen representation learning untrained already perform quite well loss function consistent downstream pertaining harm performance split,issue,negative,positive,positive,positive,positive,positive
1544567294,"I see , thank you.

---------------------------

Also the example prints ```accuracy_mean, 0.8985``` before training, and ```accuracy_mean, 0.8193``` after training. Does this mean that training didn't succeed, since accuracy didn't improve much?

Also the loss function is negative, which is strange.

Also this example doesn't have any test set to evaluate accuracy.",see thank also example training training mean training succeed since accuracy improve much also loss function negative strange also example test set evaluate accuracy,issue,negative,negative,negative,negative,negative,negative
1544505455,This is the paper's design. See Eq.3 in the paper.,paper design see paper,issue,negative,neutral,neutral,neutral,neutral,neutral
1544314468,"Thanks for picking it up @Rhett-Ying. You need to make sure `train_idx` and `val_idx` in cpu, i.e., commenting out the following two lines https://github.com/dmlc/dgl/blob/41baa0e4483b493e74c4dee6dc67abf6d120a1cc/examples/pytorch/multigpu/multi_gpu_node_classification.py#L190-L191
while set `num_workers > 0`. This is cpu-sampling (with num_workers) + multi-gpu training. Please let me know if you can reproduce at current version. ",thanks need make sure following two set training please let know reproduce current version,issue,positive,positive,positive,positive,positive,positive
1543626343,The error occurs may because you are trying to call DGL functions on GPU Pytorch tensors. Could you check whether all the tensors you used are on CPU?,error may trying call could check whether used,issue,negative,neutral,neutral,neutral,neutral,neutral
1543611359,"@czkkkkkk Sorry, I did not understand what you meant by that. I installed the CPU version of DGL and DGLGO using the command:
pip install  dgl -f https://data.dgl.ai/wheels/repo.html
pip install  dglgo -f https://data.dgl.ai/wheels-test/repo.html

Later, I installed dgllife using by: pip install  dgllife

Other dependencies e.g. Pytorch, Apache mxnet, Tensorflow are already there in my system. I didn't get any warning while importing any of these libraries but when I run my GCN model through deepchem:

model = GCNModel(mode='classification', n_tasks=1, batch_size=16, learning_rate=0.001)
loss = model.fit(dataset, nb_epoch=100)

 It throws me the error above I showed you.
",sorry understand meant version command pip install pip install later pip install apache already system get warning run model model loss error,issue,negative,negative,negative,negative,negative,negative
1543413341,"@chang-l I cannot reproduce the error you hit. could you share what you exactly changed in `multi_gpu_node_classification.py`?

```
-- Process 0 terminated with the following error:
Traceback (most recent call last):
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/torch/multiprocessing/spawn.py"", line 69, in _wrap
    fn(i, *args)
  File ""/home/ubuntu/workspace/dgl_0/examples/pytorch/multigpu/multi_gpu_node_classification.py"", line 201, in run
    train(
  File ""/home/ubuntu/workspace/dgl_0/examples/pytorch/multigpu/multi_gpu_node_classification.py"", line 127, in train
    train_dataloader = DataLoader(
  File ""/home/ubuntu/.local/lib/python3.8/site-packages/dgl/dataloading/dataloader.py"", line 940, in __init__
    raise ValueError(
ValueError: Expect graph and indices to be on the same device when use_uva=False. 
```",reproduce error hit could share exactly process following error recent call last file line file line run train file line train file line raise expect graph index device,issue,negative,positive,neutral,neutral,positive,positive
1543316840,"As #5540 is not included in `1.1.0`.  we need to try with latest nightly built DGL. Unfortunately, current DGL nightly build is down, so @paoxiaode you need to build DGL from source(latest master branch), refer to [here](https://docs.dgl.ai/install/index.html#linux). Once latest DGL nightly build is ready, I will get back here.",included need try latest nightly built unfortunately current nightly build need build source latest master branch refer latest nightly build ready get back,issue,negative,positive,positive,positive,positive,positive
1543298425,"> @tingyu66 do I need to build DGL from latest master branch source code?

Yes, as long as your version includes the changes in #5540.",need build latest master branch source code yes long version,issue,negative,positive,positive,positive,positive,positive
1543278196,@tingyu66 do I need to build DGL from latest master branch source code?,need build latest master branch source code,issue,negative,positive,positive,positive,positive,positive
1543269113,I think our GPU kernel is implemented non-deterministically and due to floating point errors the results naturally fluctuate depending on the order of arithmetics.  How much did the resulting metric fluctuate?  Normally this shouldn't be an issue.,think kernel due floating point naturally fluctuate depending order much resulting metric fluctuate normally issue,issue,negative,positive,neutral,neutral,positive,positive
1543262798,@hnisonoff  could you try on the latest master branch?,could try latest master branch,issue,negative,positive,positive,positive,positive,positive
1543251190,Hi @yurivict have you resolved this issue? could you share any fix?,hi resolved issue could share fix,issue,negative,neutral,neutral,neutral,neutral,neutral
1543234453,"@Rhett-Ying I just tried it on my end and it works. I attach the full history for your reference. My clone has the latest commit 2eb3f08c on the master branch as of now.

```bash
âžœ  dgl git:(master) âœ— bash script/create_dev_conda_env.sh -g 11.7 -p 3.10 -t 2.0.0
Confirm the installed CUDA version matches the specified one.
Continue? [yes/no]:
yes
Confirm you are excuting the script from your DGL root directory.
Current working directory: /home/tingyuw/git/dgl
Continue? [yes/no]:
yes
--------------------------------------------------
name: dgl-dev-gpu
dependencies:
  - python=3.10
  - pip
  - graphviz
  - pandoc
  - pygraphviz
  - pip:
    - --find-links https://download.pytorch.org/whl/torch_stable.html
    - cython
    - filelock
    - matplotlib
    - networkx
    - nltk
    - nose
    - numpy
    - ogb
    - pandas
    - psutil
    - pyarrow
    - pydantic
    - pytest
    - pyyaml
    - rdflib
    - requests[security]
    - scikit-learn
    - scipy
    - torch==2.0.0+cu117
    - torchmetrics
    - tqdm
    - boto3 # AWS SDK for python
    - sphinx==4.2.0
    - sphinx-gallery
    - sphinx_rtd_theme
    - sphinx_copybutton
    - sphinxemoji
    - nbsphinx>=0.8.11
    - nbsphinx-link>=1.3.0
    - pillow
    - seaborn
    - jupyter_http_over_ws
variables:
  DGL_HOME: /home/tingyuw/git/dgl
--------------------------------------------------
Create a conda enviroment with the config?
Continue? [yes/no]:
yes
Collecting package metadata (repodata.json): done
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 22.9.0
  latest version: 23.3.1

Please update conda by running

    $ conda update -n base -c defaults conda



Downloading and Extracting Packages
boost-cpp-1.73.0     | 16 KB     | ################################################################################################################### | 100% 
librsvg-2.54.4       | 6.0 MB    | ################################################################################################################### | 100% 
pandoc-2.12          | 10.5 MB   | ################################################################################################################### | 100% 
font-ttf-source-code | 654 KB    | ################################################################################################################### | 100% 
jpeg-9e              | 262 KB    | ################################################################################################################### | 100% 
pango-1.50.7         | 427 KB    | ################################################################################################################### | 100% 
font-ttf-ubuntu-0.83 | 1.5 MB    | ################################################################################################################### | 100% 
libboost-1.73.0      | 13.8 MB   | ################################################################################################################### | 100% 
libdeflate-1.17      | 69 KB     | ################################################################################################################### | 100% 
libxml2-2.10.3       | 755 KB    | ################################################################################################################### | 100% 
gobject-introspectio | 1.6 MB    | ################################################################################################################### | 100% 
fontconfig-2.14.1    | 281 KB    | ################################################################################################################### | 100% 
ninja-1.10.2         | 8 KB      | ################################################################################################################### | 100% 
libwebp-1.2.4        | 86 KB     | ################################################################################################################### | 100% 
openjpeg-2.4.0       | 331 KB    | ################################################################################################################### | 100% 
poppler-22.12.0      | 17.3 MB   | ################################################################################################################### | 100% 
cairo-1.16.0         | 1.4 MB    | ################################################################################################################### | 100% 
font-ttf-inconsolata | 83 KB     | ################################################################################################################### | 100% 
atk-1.0-2.36.0       | 466 KB    | ################################################################################################################### | 100% 
graphviz-2.50.0      | 2.6 MB    | ################################################################################################################### | 100% 
giflib-5.2.1         | 80 KB     | ################################################################################################################### | 100% 
c-ares-1.19.0        | 118 KB    | ################################################################################################################### | 100% 
ninja-base-1.10.2    | 109 KB    | ################################################################################################################### | 100% 
gdk-pixbuf-2.42.10   | 600 KB    | ################################################################################################################### | 100% 
poppler-data-0.4.11  | 2.6 MB    | ################################################################################################################### | 100% 
libcurl-7.88.1       | 383 KB    | ################################################################################################################### | 100% 
harfbuzz-4.3.0       | 1.3 MB    | ################################################################################################################### | 100% 
fribidi-1.0.10       | 103 KB    | ################################################################################################################### | 100% 
pygraphviz-1.9       | 136 KB    | ################################################################################################################### | 100% 
libgd-2.3.3          | 240 KB    | ################################################################################################################### | 100% 
Preparing transaction: done
Verifying transaction: done
Executing transaction: done
Installing pip dependencies: | Ran pip subprocess with arguments:
['/home/tingyuw/miniconda3/envs/dgl-dev-gpu/bin/python', '-m', 'pip', 'install', '-U', '-r', '/tmp/e2222e1ed0dc0c703fca/condaenv.49vomnc9.requirements.txt']
Pip subprocess output:
Looking in links: https://download.pytorch.org/whl/torch_stable.html
Collecting cython
  Using cached Cython-0.29.34-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (1.9 MB)
Collecting filelock
  Downloading filelock-3.12.0-py3-none-any.whl (10 kB)
Collecting matplotlib
  Using cached matplotlib-3.7.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)
Collecting networkx
  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.1/2.1 MB 19.9 MB/s eta 0:00:00
Collecting nltk
  Downloading nltk-3.8.1-py3-none-any.whl (1.5 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.5/1.5 MB 30.3 MB/s eta 0:00:00
Collecting nose
  Downloading nose-1.3.7-py3-none-any.whl (154 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 154.7/154.7 kB 18.5 MB/s eta 0:00:00
Collecting numpy
  Downloading numpy-1.24.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 17.3/17.3 MB 43.2 MB/s eta 0:00:00
Collecting ogb
  Downloading ogb-1.3.6-py3-none-any.whl (78 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 78.8/78.8 kB 9.6 MB/s eta 0:00:00
Collecting pandas
  Downloading pandas-2.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 12.3/12.3 MB 48.9 MB/s eta 0:00:00
Collecting psutil
  Downloading psutil-5.9.5-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (282 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 282.1/282.1 kB 30.9 MB/s eta 0:00:00
Collecting pyarrow
  Downloading pyarrow-12.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 38.9/38.9 MB 36.2 MB/s eta 0:00:00
Collecting pydantic
  Downloading pydantic-1.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.1/3.1 MB 43.2 MB/s eta 0:00:00
Collecting pytest
  Downloading pytest-7.3.1-py3-none-any.whl (320 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 320.5/320.5 kB 35.0 MB/s eta 0:00:00
Collecting pyyaml
  Using cached PyYAML-6.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (682 kB)
Collecting rdflib
  Using cached rdflib-6.3.2-py3-none-any.whl (528 kB)
Collecting requests[security]
  Downloading requests-2.30.0-py3-none-any.whl (62 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 62.5/62.5 kB 7.1 MB/s eta 0:00:00
Collecting scikit-learn
  Using cached scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)
Collecting scipy
  Using cached scipy-1.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.4 MB)
Collecting torch==2.0.0+cu117
  Downloading https://download.pytorch.org/whl/cu117/torch-2.0.0%2Bcu117-cp310-cp310-linux_x86_64.whl (1843.9 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.8/1.8 GB 3.8 MB/s eta 0:00:00
Collecting torchmetrics
  Using cached torchmetrics-0.11.4-py3-none-any.whl (519 kB)
Collecting tqdm
  Using cached tqdm-4.65.0-py3-none-any.whl (77 kB)
Collecting boto3
  Downloading boto3-1.26.132-py3-none-any.whl (135 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 135.6/135.6 kB 12.1 MB/s eta 0:00:00
Collecting sphinx==4.2.0
  Downloading Sphinx-4.2.0-py3-none-any.whl (3.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.1/3.1 MB 45.8 MB/s eta 0:00:00
Collecting sphinx-gallery
  Downloading sphinx_gallery-0.13.0-py3-none-any.whl (147 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 147.4/147.4 kB 17.6 MB/s eta 0:00:00
Collecting sphinx_rtd_theme
  Downloading sphinx_rtd_theme-1.2.0-py2.py3-none-any.whl (2.8 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 2.8/2.8 MB 43.1 MB/s eta 0:00:00
Collecting sphinx_copybutton
  Downloading sphinx_copybutton-0.5.2-py3-none-any.whl (13 kB)
Collecting sphinxemoji
  Using cached sphinxemoji-0.2.0.tar.gz (44 kB)
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting nbsphinx>=0.8.11
  Downloading nbsphinx-0.9.1-py3-none-any.whl (30 kB)
Collecting nbsphinx-link>=1.3.0
  Using cached nbsphinx_link-1.3.0-py2.py3-none-any.whl (5.2 kB)
Collecting pillow
  Downloading Pillow-9.5.0-cp310-cp310-manylinux_2_28_x86_64.whl (3.4 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 3.4/3.4 MB 46.1 MB/s eta 0:00:00
Collecting seaborn
  Downloading seaborn-0.12.2-py3-none-any.whl (293 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 293.3/293.3 kB 33.7 MB/s eta 0:00:00
Collecting jupyter_http_over_ws
  Downloading jupyter_http_over_ws-0.0.8-py2.py3-none-any.whl (18 kB)
Collecting triton==2.0.0
  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 63.3/63.3 MB 36.1 MB/s eta 0:00:00
Collecting sympy
  Downloading sympy-1.12-py3-none-any.whl (5.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 5.7/5.7 MB 54.0 MB/s eta 0:00:00
Collecting typing-extensions
  Using cached typing_extensions-4.5.0-py3-none-any.whl (27 kB)
Collecting jinja2
  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 133.1/133.1 kB 16.6 MB/s eta 0:00:00
Collecting sphinxcontrib-devhelp
  Using cached sphinxcontrib_devhelp-1.0.2-py2.py3-none-any.whl (84 kB)
Collecting babel>=1.3
  Downloading Babel-2.12.1-py3-none-any.whl (10.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.1/10.1 MB 47.4 MB/s eta 0:00:00
Collecting sphinxcontrib-serializinghtml>=1.1.5
  Using cached sphinxcontrib_serializinghtml-1.1.5-py2.py3-none-any.whl (94 kB)
Collecting alabaster<0.8,>=0.7
  Using cached alabaster-0.7.13-py3-none-any.whl (13 kB)
Collecting sphinxcontrib-applehelp
  Using cached sphinxcontrib_applehelp-1.0.4-py3-none-any.whl (120 kB)
Requirement already satisfied: setuptools in /home/tingyuw/miniconda3/envs/dgl-dev-gpu/lib/python3.10/site-packages (from sphinx==4.2.0->-r /tmp/e2222e1ed0dc0c703fca/condaenv.49vomnc9.requirements.txt (line 24)) (66.0.0)
Collecting docutils<0.18,>=0.14
  Using cached docutils-0.17.1-py2.py3-none-any.whl (575 kB)
Collecting packaging
  Downloading packaging-23.1-py3-none-any.whl (48 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 48.9/48.9 kB 5.4 MB/s eta 0:00:00
Collecting sphinxcontrib-htmlhelp>=2.0.0
  Using cached sphinxcontrib_htmlhelp-2.0.1-py3-none-any.whl (99 kB)
Collecting sphinxcontrib-qthelp
  Using cached sphinxcontrib_qthelp-1.0.3-py2.py3-none-any.whl (90 kB)
Collecting snowballstemmer>=1.1
  Using cached snowballstemmer-2.2.0-py2.py3-none-any.whl (93 kB)
Collecting sphinxcontrib-jsmath
  Using cached sphinxcontrib_jsmath-1.0.1-py2.py3-none-any.whl (5.1 kB)
Collecting Pygments>=2.0
  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.1/1.1 MB 43.8 MB/s eta 0:00:00
Collecting imagesize
  Using cached imagesize-1.4.1-py2.py3-none-any.whl (8.8 kB)
Collecting lit
  Downloading lit-16.0.3.tar.gz (138 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 138.0/138.0 kB 16.9 MB/s eta 0:00:00
  Preparing metadata (setup.py): started
  Preparing metadata (setup.py): finished with status 'done'
Collecting cmake
  Downloading cmake-3.26.3-py2.py3-none-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (24.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 24.0/24.0 MB 43.1 MB/s eta 0:00:00
Collecting contourpy>=1.0.1
  Using cached contourpy-1.0.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)
Collecting python-dateutil>=2.7
  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 247.7/247.7 kB 29.0 MB/s eta 0:00:00
Collecting pyparsing>=2.3.1
  Using cached pyparsing-3.0.9-py3-none-any.whl (98 kB)
Collecting kiwisolver>=1.0.1
  Using cached kiwisolver-1.4.4-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.6 MB)
Collecting cycler>=0.10
  Using cached cycler-0.11.0-py3-none-any.whl (6.4 kB)
Collecting fonttools>=4.22.0
  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 1.0/1.0 MB 53.7 MB/s eta 0:00:00
Collecting regex>=2021.8.3
  Downloading regex-2023.5.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (769 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 769.7/769.7 kB 44.7 MB/s eta 0:00:00
Collecting click
  Using cached click-8.1.3-py3-none-any.whl (96 kB)
Collecting joblib
  Using cached joblib-1.2.0-py3-none-any.whl (297 kB)
Collecting outdated>=0.2.0
  Using cached outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)
Collecting urllib3>=1.24.0
  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 123.2/123.2 kB 14.8 MB/s eta 0:00:00
Collecting six>=1.12.0
  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)
Collecting tzdata>=2022.1
  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 341.8/341.8 kB 20.9 MB/s eta 0:00:00
Collecting pytz>=2020.1
  Using cached pytz-2023.3-py2.py3-none-any.whl (502 kB)
Collecting exceptiongroup>=1.0.0rc8
  Using cached exceptiongroup-1.1.1-py3-none-any.whl (14 kB)
Collecting tomli>=1.0.0
  Using cached tomli-2.0.1-py3-none-any.whl (12 kB)
Collecting pluggy<2.0,>=0.12
  Using cached pluggy-1.0.0-py2.py3-none-any.whl (13 kB)
Collecting iniconfig
  Using cached iniconfig-2.0.0-py3-none-any.whl (5.9 kB)
Collecting isodate<0.7.0,>=0.6.0
  Using cached isodate-0.6.1-py2.py3-none-any.whl (41 kB)
Collecting charset-normalizer<4,>=2
  Using cached charset_normalizer-3.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (199 kB)
Collecting certifi>=2017.4.17
  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 157.0/157.0 kB 19.3 MB/s eta 0:00:00
Collecting idna<4,>=2.5
  Using cached idna-3.4-py3-none-any.whl (61 kB)
Collecting threadpoolctl>=2.0.0
  Using cached threadpoolctl-3.1.0-py3-none-any.whl (14 kB)
Collecting jmespath<2.0.0,>=0.7.1
  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)
Collecting s3transfer<0.7.0,>=0.6.0
  Downloading s3transfer-0.6.1-py3-none-any.whl (79 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 79.8/79.8 kB 9.5 MB/s eta 0:00:00
Collecting botocore<1.30.0,>=1.29.132
  Downloading botocore-1.29.132-py3-none-any.whl (10.7 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.7/10.7 MB 50.1 MB/s eta 0:00:00
Collecting sphinxcontrib-jquery!=3.0.0,>=2.0.0
  Downloading sphinxcontrib_jquery-4.1-py2.py3-none-any.whl (121 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 121.1/121.1 kB 14.9 MB/s eta 0:00:00
Collecting nbformat
  Using cached nbformat-5.8.0-py3-none-any.whl (77 kB)
Collecting nbconvert!=5.4
  Downloading nbconvert-7.4.0-py3-none-any.whl (285 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 285.9/285.9 kB 32.8 MB/s eta 0:00:00
Collecting traitlets>=5
  Using cached traitlets-5.9.0-py3-none-any.whl (117 kB)
Collecting notebook>=5.0
  Using cached notebook-6.5.4-py3-none-any.whl (529 kB)
Collecting tornado>=4.5
  Downloading tornado-6.3.1-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 426.8/426.8 kB 43.6 MB/s eta 0:00:00
Collecting urllib3>=1.24.0
  Using cached urllib3-1.26.15-py2.py3-none-any.whl (140 kB)
Collecting MarkupSafe>=2.0
  Downloading MarkupSafe-2.1.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)
Collecting jupyter-core>=4.7
  Using cached jupyter_core-5.3.0-py3-none-any.whl (93 kB)
Collecting jupyterlab-pygments
  Using cached jupyterlab_pygments-0.2.2-py2.py3-none-any.whl (21 kB)
Collecting nbclient>=0.5.0
  Downloading nbclient-0.7.4-py3-none-any.whl (73 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 73.1/73.1 kB 8.7 MB/s eta 0:00:00
Collecting pandocfilters>=1.4.1
  Using cached pandocfilters-1.5.0-py2.py3-none-any.whl (8.7 kB)
Collecting mistune<3,>=2.0.3
  Using cached mistune-2.0.5-py2.py3-none-any.whl (24 kB)
Collecting defusedxml
  Using cached defusedxml-0.7.1-py2.py3-none-any.whl (25 kB)
Collecting tinycss2
  Using cached tinycss2-1.2.1-py3-none-any.whl (21 kB)
Collecting beautifulsoup4
  Using cached beautifulsoup4-4.12.2-py3-none-any.whl (142 kB)
Collecting bleach
  Using cached bleach-6.0.0-py3-none-any.whl (162 kB)
Collecting jsonschema>=2.6
  Using cached jsonschema-4.17.3-py3-none-any.whl (90 kB)
Collecting fastjsonschema
  Using cached fastjsonschema-2.16.3-py3-none-any.whl (23 kB)
Collecting argon2-cffi
  Using cached argon2_cffi-21.3.0-py3-none-any.whl (14 kB)
Collecting prometheus-client
  Using cached prometheus_client-0.16.0-py3-none-any.whl (122 kB)
Collecting terminado>=0.8.3
  Using cached terminado-0.17.1-py3-none-any.whl (17 kB)
Collecting pyzmq>=17
  Using cached pyzmq-25.0.2-cp310-cp310-manylinux_2_28_x86_64.whl (1.1 MB)
Collecting ipython-genutils
  Using cached ipython_genutils-0.2.0-py2.py3-none-any.whl (26 kB)
Collecting Send2Trash>=1.8.0
  Downloading Send2Trash-1.8.2-py3-none-any.whl (18 kB)
Collecting nbclassic>=0.4.7
  Downloading nbclassic-1.0.0-py3-none-any.whl (10.0 MB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 10.0/10.0 MB 57.4 MB/s eta 0:00:00
Collecting ipykernel
  Downloading ipykernel-6.23.0-py3-none-any.whl (150 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 150.6/150.6 kB 18.3 MB/s eta 0:00:00
Collecting jupyter-client>=5.3.4
  Downloading jupyter_client-8.2.0-py3-none-any.whl (103 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 103.2/103.2 kB 12.6 MB/s eta 0:00:00
Collecting nest-asyncio>=1.5
  Using cached nest_asyncio-1.5.6-py3-none-any.whl (5.2 kB)
Collecting littleutils
  Using cached littleutils-0.2.2-py3-none-any.whl
Collecting mpmath>=0.19
  Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 536.2/536.2 kB 46.9 MB/s eta 0:00:00
Collecting attrs>=17.4.0
  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 61.2/61.2 kB 7.2 MB/s eta 0:00:00
Collecting pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0
  Using cached pyrsistent-0.19.3-py3-none-any.whl (57 kB)
Collecting platformdirs>=2.5
  Downloading platformdirs-3.5.0-py3-none-any.whl (15 kB)
Collecting jupyter-server>=1.8
  Using cached jupyter_server-2.5.0-py3-none-any.whl (366 kB)
Collecting notebook-shim>=0.2.3
  Downloading notebook_shim-0.2.3-py3-none-any.whl (13 kB)
Collecting ptyprocess
  Using cached ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)
Collecting argon2-cffi-bindings
  Using cached argon2_cffi_bindings-21.2.0-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (86 kB)
Collecting soupsieve>1.2
  Downloading soupsieve-2.4.1-py3-none-any.whl (36 kB)
Collecting webencodings
  Using cached webencodings-0.5.1-py2.py3-none-any.whl (11 kB)
Collecting ipython>=7.23.1
  Downloading ipython-8.13.2-py3-none-any.whl (797 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 797.7/797.7 kB 44.9 MB/s eta 0:00:00
Collecting matplotlib-inline>=0.1
  Using cached matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)
Collecting comm>=0.1.1
  Using cached comm-0.1.3-py3-none-any.whl (6.6 kB)
Collecting debugpy>=1.6.5
  Using cached debugpy-1.6.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)
Collecting backcall
  Using cached backcall-0.2.0-py2.py3-none-any.whl (11 kB)
Collecting pickleshare
  Using cached pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)
Collecting stack-data
  Using cached stack_data-0.6.2-py3-none-any.whl (24 kB)
Collecting jedi>=0.16
  Using cached jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)
Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30
  Using cached prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)
Collecting decorator
  Using cached decorator-5.1.1-py3-none-any.whl (9.1 kB)
Collecting pexpect>4.3
  Using cached pexpect-4.8.0-py2.py3-none-any.whl (59 kB)
Collecting jupyter-server-terminals
  Using cached jupyter_server_terminals-0.4.4-py3-none-any.whl (13 kB)
Collecting anyio>=3.1.0
  Using cached anyio-3.6.2-py3-none-any.whl (80 kB)
Collecting jupyter-events>=0.4.0
  Using cached jupyter_events-0.6.3-py3-none-any.whl (18 kB)
Collecting websocket-client
  Using cached websocket_client-1.5.1-py3-none-any.whl (55 kB)
Collecting cffi>=1.0.1
  Downloading cffi-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (441 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 441.8/441.8 kB 39.2 MB/s eta 0:00:00
Collecting sniffio>=1.1
  Using cached sniffio-1.3.0-py3-none-any.whl (10 kB)
Collecting pycparser
  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)
     â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â” 118.7/118.7 kB 9.6 MB/s eta 0:00:00
Collecting parso<0.9.0,>=0.8.0
  Using cached parso-0.8.3-py2.py3-none-any.whl (100 kB)
Collecting rfc3986-validator>=0.1.1
  Using cached rfc3986_validator-0.1.1-py2.py3-none-any.whl (4.2 kB)
Collecting python-json-logger>=2.0.4
  Using cached python_json_logger-2.0.7-py3-none-any.whl (8.1 kB)
Collecting rfc3339-validator
  Using cached rfc3339_validator-0.1.4-py2.py3-none-any.whl (3.5 kB)
Collecting wcwidth
  Using cached wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)
Collecting pure-eval
  Using cached pure_eval-0.2.2-py3-none-any.whl (11 kB)
Collecting executing>=1.2.0
  Using cached executing-1.2.0-py2.py3-none-any.whl (24 kB)
Collecting asttokens>=2.1.0
  Using cached asttokens-2.2.1-py2.py3-none-any.whl (26 kB)
Collecting isoduration
  Using cached isoduration-20.11.0-py3-none-any.whl (11 kB)
Collecting uri-template
  Using cached uri_template-1.2.0-py3-none-any.whl (10 kB)
Collecting jsonpointer>1.13
  Using cached jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)
Collecting fqdn
  Using cached fqdn-1.5.1-py3-none-any.whl (9.1 kB)
Collecting webcolors>=1.11
  Using cached webcolors-1.13-py3-none-any.whl (14 kB)
Collecting arrow>=0.15.0
  Using cached arrow-1.2.3-py3-none-any.whl (66 kB)
Building wheels for collected packages: sphinxemoji, lit
  Building wheel for sphinxemoji (setup.py): started
  Building wheel for sphinxemoji (setup.py): finished with status 'done'
  Created wheel for sphinxemoji: filename=sphinxemoji-0.2.0-py3-none-any.whl size=44410 sha256=56bf750ff106555eb3ed88a7ae9a9ddd9f54a9a3c1d92de4f5d9fd2670dee27d
  Stored in directory: /home/tingyuw/.cache/pip/wheels/64/a4/96/10ec59245ae6f2b45d4509261572f3d6a0db4a7c00d7a6d4c6
  Building wheel for lit (setup.py): started
  Building wheel for lit (setup.py): finished with status 'done'
  Created wheel for lit: filename=lit-16.0.3-py3-none-any.whl size=88174 sha256=397cd54dd6e7d8bc282bf5442e1f9a77f1cb0e870944f6b3f050c6443495bac1
  Stored in directory: /home/tingyuw/.cache/pip/wheels/d6/81/1c/a49ba782377339294cc45c9899927b61a92e58d6ad3ac942f7
Successfully built sphinxemoji lit
Installing collected packages: webencodings, wcwidth, snowballstemmer, pytz, pure-eval, ptyprocess, pickleshare, nose, mpmath, mistune, littleutils, lit, ipython-genutils, fastjsonschema, executing, cmake, backcall, websocket-client, webcolors, urllib3, uri-template, tzdata, typing-extensions, traitlets, tqdm, tornado, tomli, tinycss2, threadpoolctl, sympy, sphinxcontrib-serializinghtml, sphinxcontrib-qthelp, sphinxcontrib-jsmath, sphinxcontrib-htmlhelp, sphinxcontrib-devhelp, sphinxcontrib-applehelp, soupsieve, sniffio, six, Send2Trash, rfc3986-validator, regex, pyzmq, pyyaml, python-json-logger, pyrsistent, pyparsing, Pygments, pycparser, psutil, prompt-toolkit, prometheus-client, pluggy, platformdirs, pillow, pexpect, parso, pandocfilters, packaging, numpy, networkx, nest-asyncio, MarkupSafe, kiwisolver, jupyterlab-pygments, jsonpointer, joblib, jmespath, iniconfig, imagesize, idna, fqdn, fonttools, filelock, exceptiongroup, docutils, defusedxml, decorator, debugpy, cython, cycler, click, charset-normalizer, certifi, babel, attrs, alabaster, terminado, scipy, rfc3339-validator, requests, python-dateutil, pytest, pydantic, pyarrow, nltk, matplotlib-inline, jupyter-core, jsonschema, jinja2, jedi, isodate, contourpy, comm, cffi, bleach, beautifulsoup4, asttokens, anyio, stack-data, sphinx, scikit-learn, rdflib, pandas, outdated, nbformat, matplotlib, jupyter-server-terminals, jupyter-client, botocore, arrow, argon2-cffi-bindings, sphinxemoji, sphinxcontrib-jquery, sphinx-gallery, sphinx_copybutton, seaborn, s3transfer, nbclient, isoduration, ipython, argon2-cffi, sphinx_rtd_theme, nbconvert, ipykernel, boto3, nbsphinx, jupyter-events, nbsphinx-link, jupyter-server, notebook-shim, nbclassic, notebook, jupyter_http_over_ws, triton, torch, torchmetrics, ogb
Successfully installed MarkupSafe-2.1.2 Pygments-2.15.1 Send2Trash-1.8.2 alabaster-0.7.13 anyio-3.6.2 argon2-cffi-21.3.0 argon2-cffi-bindings-21.2.0 arrow-1.2.3 asttokens-2.2.1 attrs-23.1.0 babel-2.12.1 backcall-0.2.0 beautifulsoup4-4.12.2 bleach-6.0.0 boto3-1.26.132 botocore-1.29.132 certifi-2023.5.7 cffi-1.15.1 charset-normalizer-3.1.0 click-8.1.3 cmake-3.26.3 comm-0.1.3 contourpy-1.0.7 cycler-0.11.0 cython-0.29.34 debugpy-1.6.7 decorator-5.1.1 defusedxml-0.7.1 docutils-0.17.1 exceptiongroup-1.1.1 executing-1.2.0 fastjsonschema-2.16.3 filelock-3.12.0 fonttools-4.39.4 fqdn-1.5.1 idna-3.4 imagesize-1.4.1 iniconfig-2.0.0 ipykernel-6.23.0 ipython-8.13.2 ipython-genutils-0.2.0 isodate-0.6.1 isoduration-20.11.0 jedi-0.18.2 jinja2-3.1.2 jmespath-1.0.1 joblib-1.2.0 jsonpointer-2.3 jsonschema-4.17.3 jupyter-client-8.2.0 jupyter-core-5.3.0 jupyter-events-0.6.3 jupyter-server-2.5.0 jupyter-server-terminals-0.4.4 jupyter_http_over_ws-0.0.8 jupyterlab-pygments-0.2.2 kiwisolver-1.4.4 lit-16.0.3 littleutils-0.2.2 matplotlib-3.7.1 matplotlib-inline-0.1.6 mistune-2.0.5 mpmath-1.3.0 nbclassic-1.0.0 nbclient-0.7.4 nbconvert-7.4.0 nbformat-5.8.0 nbsphinx-0.9.1 nbsphinx-link-1.3.0 nest-asyncio-1.5.6 networkx-3.1 nltk-3.8.1 nose-1.3.7 notebook-6.5.4 notebook-shim-0.2.3 numpy-1.24.3 ogb-1.3.6 outdated-0.2.2 packaging-23.1 pandas-2.0.1 pandocfilters-1.5.0 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pillow-9.5.0 platformdirs-3.5.0 pluggy-1.0.0 prometheus-client-0.16.0 prompt-toolkit-3.0.38 psutil-5.9.5 ptyprocess-0.7.0 pure-eval-0.2.2 pyarrow-12.0.0 pycparser-2.21 pydantic-1.10.7 pyparsing-3.0.9 pyrsistent-0.19.3 pytest-7.3.1 python-dateutil-2.8.2 python-json-logger-2.0.7 pytz-2023.3 pyyaml-6.0 pyzmq-25.0.2 rdflib-6.3.2 regex-2023.5.5 requests-2.30.0 rfc3339-validator-0.1.4 rfc3986-validator-0.1.1 s3transfer-0.6.1 scikit-learn-1.2.2 scipy-1.10.1 seaborn-0.12.2 six-1.16.0 sniffio-1.3.0 snowballstemmer-2.2.0 soupsieve-2.4.1 sphinx-4.2.0 sphinx-gallery-0.13.0 sphinx_copybutton-0.5.2 sphinx_rtd_theme-1.2.0 sphinxcontrib-applehelp-1.0.4 sphinxcontrib-devhelp-1.0.2 sphinxcontrib-htmlhelp-2.0.1 sphinxcontrib-jquery-4.1 sphinxcontrib-jsmath-1.0.1 sphinxcontrib-qthelp-1.0.3 sphinxcontrib-serializinghtml-1.1.5 sphinxemoji-0.2.0 stack-data-0.6.2 sympy-1.12 terminado-0.17.1 threadpoolctl-3.1.0 tinycss2-1.2.1 tomli-2.0.1 torch-2.0.0+cu117 torchmetrics-0.11.4 tornado-6.3.1 tqdm-4.65.0 traitlets-5.9.0 triton-2.0.0 typing-extensions-4.5.0 tzdata-2023.3 uri-template-1.2.0 urllib3-1.26.15 wcwidth-0.2.6 webcolors-1.13 webencodings-0.5.1 websocket-client-1.5.1

done
#
# To activate this environment, use
#
#     $ conda activate dgl-dev-gpu
#
# To deactivate an active environment, use
#
#     $ conda deactivate

Retrieving notices: ...working... done
âžœ  dgl git:(master) âœ— conda activate dgl-dev-gpu
(dgl-dev-gpu) âžœ  dgl git:(master) âœ— conda install -c nvidia -c conda-forge -c rapidsai pylibcugraphops=23.04
Collecting package metadata (current_repodata.json): done
Solving environment: failed with initial frozen solve. Retrying with flexible solve.
Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.
Collecting package metadata (repodata.json): done
Solving environment: done


==> WARNING: A newer version of conda exists. <==
  current version: 22.9.0
  latest version: 23.3.1

Please update conda by running

    $ conda update -n base -c defaults conda



## Package Plan ##

  environment location: /home/tingyuw/miniconda3/envs/dgl-dev-gpu

  added / updated specs:
    - pylibcugraphops=23.04


The following NEW packages will be INSTALLED:

  cuda-profiler-api  nvidia/linux-64::cuda-profiler-api-11.8.86-0 None
  cudatoolkit        nvidia/linux-64::cudatoolkit-11.7.0-hd8887f6_10 None
  fmt                conda-forge/linux-64::fmt-9.1.0-h924138e_0 None
  libcublas          nvidia/linux-64::libcublas-11.11.3.6-0 None
  libcublas-dev      nvidia/linux-64::libcublas-dev-11.11.3.6-0 None
  libcugraphops      nvidia/linux-64::libcugraphops-23.04.00-cuda11_230412_ga76892e3_0 None
  libcurand          nvidia/linux-64::libcurand-10.3.0.86-0 None
  libcurand-dev      nvidia/linux-64::libcurand-dev-10.3.0.86-0 None
  libcusolver        nvidia/linux-64::libcusolver-11.4.1.48-0 None
  libcusolver-dev    nvidia/linux-64::libcusolver-dev-11.4.1.48-0 None
  libcusparse        nvidia/linux-64::libcusparse-11.7.5.86-0 None
  libcusparse-dev    nvidia/linux-64::libcusparse-dev-11.7.5.86-0 None
  libraft-headers    rapidsai/linux-64::libraft-headers-23.04.01-cuda11_230421_gdc800d6f_0 None
  librmm             rapidsai/linux-64::librmm-23.04.01-cuda11_230421_geab50f46_0 None
  llvm-openmp        conda-forge/linux-64::llvm-openmp-12.0.1-h4bd325d_1 None
  pylibcugraphops    nvidia/linux-64::pylibcugraphops-23.04.00-cuda11_py310_230412_ga76892e3_0 None
  python_abi         conda-forge/linux-64::python_abi-3.10-2_cp310 None
  spdlog             conda-forge/linux-64::spdlog-1.11.0-h9b3ece8_1 None

The following packages will be REMOVED:

  libgomp-11.2.0-h1234567_1

The following packages will be UPDATED:

  ca-certificates    pkgs/main::ca-certificates-2023.01.10~ --> conda-forge::ca-certificates-2023.5.7-hbcca054_0 None
  libgcc-ng          pkgs/main::libgcc-ng-11.2.0-h1234567_1 --> conda-forge::libgcc-ng-12.2.0-h65d4601_19 None
  libstdcxx-ng       pkgs/main::libstdcxx-ng-11.2.0-h12345~ --> conda-forge::libstdcxx-ng-12.2.0-h46fd767_19 None

The following packages will be SUPERSEDED by a higher-priority channel:

  _libgcc_mutex           pkgs/main::_libgcc_mutex-0.1-main --> conda-forge::_libgcc_mutex-0.1-conda_forge None
  _openmp_mutex          pkgs/main::_openmp_mutex-5.1-1_gnu --> conda-forge::_openmp_mutex-4.5-2_kmp_llvm None
  openssl              pkgs/main::openssl-1.1.1t-h7f8727e_0 --> conda-forge::openssl-1.1.1t-h0b41bf4_0 None


Proceed ([y]/n)? y

Preparing transaction: done
Verifying transaction: done
Executing transaction: | By downloading and using the CUDA Toolkit conda packages, you accept the terms and conditions of the CUDA End User License Agreement (EULA): https://docs.nvidia.com/cuda/eula/index.html

done
Retrieving notices: ...working... done


(dgl-dev-gpu) âžœ  python git:(master) âœ— python -c ""import pylibcugraphops;print(pylibcugraphops.__version__)"" 
23.04.00


```

Edit: The example in the docstring also works:
```
(dgl-dev-gpu) âžœ  python git:(master) âœ— ipython
Python 3.10.11 (main, Apr 20 2023, 19:02:41) [GCC 11.2.0]
Type 'copyright', 'credits' or 'license' for more information
IPython 8.13.2 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import dgl
   ...: import torch
   ...: from dgl.nn import CuGraphGATConv
   ...: device = 'cuda'
   ...: g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3])).to(device)
   ...: g = dgl.add_self_loop(g)
   ...: feat = torch.ones(6, 10).to(device)
   ...: conv = CuGraphGATConv(10, 2, num_heads=3).to(device)
   ...: res = conv(g, feat)
   ...: res
Out[1]: 
tensor([[[-1.2516, -1.7357],
         [ 1.4165,  1.1434],
         [-0.6996,  0.3255]],

        [[-1.2516, -1.7357],
         [ 1.4165,  1.1434],
         [-0.6996,  0.3255]],

        [[-1.2516, -1.7357],
         [ 1.4165,  1.1434],
         [-0.6996,  0.3255]],

        [[-1.2516, -1.7357],
         [ 1.4165,  1.1434],
         [-0.6996,  0.3255]],

        [[-1.2516, -1.7357],
         [ 1.4165,  1.1434],
         [-0.6996,  0.3255]],

        [[-1.2516, -1.7357],
         [ 1.4165,  1.1434],
         [-0.6996,  0.3255]]], device='cuda:0', grad_fn=<AddBackward0>)
```

",tried end work attach full history reference clone latest commit master branch bash git master bash confirm version one continue yes confirm script root directory current working directory continue yes name pip pip nose security python pillow create continue yes package done environment done warning version current version latest version please update running update base transaction done transaction done transaction done pip ran pip pip output looking link eta eta nose eta eta eta eta eta eta eta eta security eta eta eta eta eta eta finished status pillow eta eta eta eta jinja eta eta alabaster requirement already satisfied line eta eta lit eta finished status eta eta cycler eta eta click outdated eta six eta pluggy eta eta eta eta eta notebook tornado eta eta bleach eta eta eta eta eta eta decorator eta eta arrow building collected lit building wheel building wheel finished status wheel directory building wheel lit building wheel lit finished status wheel lit directory successfully built lit collected nose lit tornado six pluggy pillow decorator cycler click alabaster jinja bleach sphinx outdated arrow notebook triton torch successfully done activate environment use activate deactivate active environment use deactivate working done git master activate git master install package done environment initial frozen solve flexible solve environment retry next source package done environment done warning version current version latest version please update running update base package plan environment location added spec following new none none none none none none none none none none none none none none none none none none following removed following none none none following channel none none none proceed transaction done transaction done transaction accept end user license agreement done working done python git master python import print edit example also work python git master python main type information enhanced interactive python type help import import torch import device device feat device device feat tensor,issue,positive,positive,neutral,neutral,positive,positive
1542965856,"@tingyu66 `conda install -c nvidia -c conda-forge -c rapidsai pylibcugraphops` does not work for me. I am working on Ubuntu20.04, dgl 1.1.0+cu117, python 3.10, torch 2.0.0+cu117
```
Package ca-certificates conflicts for:
openssl -> ca-certificates
python=3.10 -> openssl[version='>=3.1.0,<4.0a0'] -> ca-certificates
ca-certificatesThe following specifications were found to be incompatible with your system:

  - feature:/linux-64::__glibc==2.31=0
  - feature:|@/linux-64::__glibc==2.31=0
  - pylibcugraphops -> __glibc[version='>=2.17,<3.0.a0']
  - pylibcugraphops -> librmm[version='>=22.12.0,<22.13.0a0'] -> __glibc[version='>=2.17']

Your installed version is: 2.31

Note that strict channel priority may have removed packages required for satisfiability.

(dgl-dev-gpu) ubuntu@ip-172-31-51-7:~/workspace/dgl_0$ ipython3
Python 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:08:06) [GCC 11.3.0]
Type 'copyright', 'credits' or 'license' for more information
IPython 8.13.2 -- An enhanced Interactive Python. Type '?' for help.

In [1]: import dgl
   ...: import torch
   ...: from dgl.nn import CuGraphGATConv
   ...: device = 'cuda'
   ...: g = dgl.graph(([0,1,2,3,2,5], [1,2,3,4,0,3])).to(device)
   ...: g = dgl.add_self_loop(g)
   ...: feat = torch.ones(6, 10).to(device)
   ...: conv = CuGraphGATConv(10, 2, num_heads=3).to(device)
   ...: res = conv(g, feat)
   ...: res
---------------------------------------------------------------------------
ModuleNotFoundError                       Traceback (most recent call last)
Cell In[1], line 8
      6 g = dgl.add_self_loop(g)
      7 feat = torch.ones(6, 10).to(device)
----> 8 conv = CuGraphGATConv(10, 2, num_heads=3).to(device)
      9 res = conv(g, feat)
     10 res

File /opt/conda/envs/dgl-dev-gpu/lib/python3.10/site-packages/dgl/nn/pytorch/conv/cugraph_gatconv.py:95, in CuGraphGATConv.__init__(self, in_feats, out_feats, num_heads, feat_drop, negative_slope, residual, activation, bias)
     83 def __init__(
     84     self,
     85     in_feats,
   (...)
     92     bias=True,
     93 ):
     94     if has_pylibcugraphops is False:
---> 95         raise ModuleNotFoundError(
     96             f""{self.__class__.__name__} requires pylibcugraphops >= 23.02. ""
     97             f""Install via `conda install -c nvidia 'pylibcugraphops>=23.02'`.""
     98         )
     99     super().__init__()
    100     self.in_feats = in_feats

ModuleNotFoundError: CuGraphGATConv requires pylibcugraphops >= 23.02. Install via `conda install -c nvidia 'pylibcugraphops>=23.02'`.

```",install work working python torch package following found incompatible system feature feature version note strict channel priority may removed python main mar type information enhanced interactive python type help import import torch import device device feat device device feat recent call last cell line feat device device feat file self residual activation bias self false raise install via install super install via install,issue,positive,positive,neutral,neutral,positive,positive
1542596789,"@paoxiaode @Rhett-Ying Thank you for catching the installation issue.
Can you try `conda install -c nvidia -c conda-forge -c rapidsai pylibcugraphops`?

We need `conda-forge` channel for `libgcc-ng>=12`, and `rapidsai` channel for other dependencies under NVIDIA's rapids umbrella.",thank catching installation issue try install need channel channel umbrella,issue,negative,positive,positive,positive,positive,positive
1542537095,"> @frozenbugs, I modified the benchmark ([b047751](https://github.com/dmlc/dgl/commit/b047751eb0c47f993a033850064792648233521e)) to have results from all COOToCSR algorithm on CPU.
> 
> dataset	num nodes	num edges	alg on cpu	when number of available threads is >=
> cora	2708	10556	small	14
> pubmed	19717	88651	sparse	18
> ogbn-arxiv	169343	1166243	sparse	28
> livejournal	4847571	68993773	dense	2
> friendster	65608366	1806067135	dense	2
> On r6i.16xlarge (ami-0343fe6cfc8a09c18 - Ubuntu 20.04) the modified benchmark gives the following results: (filtered to COO-> SCR|CSC only as these conversions use COOToCSR during time measurement)
> 
> dataset	sha:	[ea706ca](https://github.com/dmlc/dgl/commit/ea706cae58ef66d772e2ed3f16c67de5370397d6)	[ccd463d](https://github.com/dmlc/dgl/commit/ccd463d02e603ac163c0b9cfb863c1e82e13d774)	before/after	algorithm
> cora	('coo','csc')	0.000464917	0.000107054	4.34	small
> cora	('coo','csr')	0.000449277	0.000108357	4.15	small
> pubmed	('coo','csc')	0.000572143	0.000518983	1.10	sparse
> pubmed	('coo','csr')	0.000416732	0.000460249	0.91	sparse
> ogbn-arxiv	('coo','csc')	0.002656307	0.002500843	1.06	sparse
> ogbn-arxiv	('coo','csr')	0.002499287	0.002125469	1.18	sparse
> livejournal	('coo','csc')	0.368533011	0.370530003	0.99	dense
> livejournal	('coo','csr')	0.222436191	0.21996336	1.01	dense
> friendster	('coo','csc')	13.80159092	13.75633977	1.00	dense
> friendster	('coo','csr')	1.096111846	1.089540845	1.01	sorted
> Is this benchmark ok for you?

Thanks! the result looks great!",algorithm number available cora small sparse sparse dense dense following use time measurement sha algorithm cora small cora small sparse sparse sparse sparse dense dense dense sorted thanks result great,issue,positive,positive,neutral,neutral,positive,positive
1542052105,"@frozenbugs, I modified the benchmark (https://github.com/dmlc/dgl/pull/5508/commits/b047751eb0c47f993a033850064792648233521e) to have results from all COOToCSR algorithm on CPU.
| dataset      | num nodes | num edges  | alg on cpu | when number of available threads is >= |
|--------|--:|--:|---|---:|
| cora          |     2708  |      10556 | small      | 14 |
| pubmed        |     19717 |      88651 | sparse     | 18 |
| ogbn-arxiv    |    169343 |    1166243 | sparse     | 28 |
| livejournal   |   4847571 |   68993773 | dense      |  2 |
| friendster    |  65608366 | 1806067135 | dense      |  2 |
    
  
On r6i.16xlarge (ami-0343fe6cfc8a09c18 - Ubuntu 20.04) the modified benchmark gives the following results: 
(filtered to COO-> SCR|CSC only as these conversions use COOToCSR during time measurement)
dataset | sha: | ea706cae | ccd463d0 | before/after | algorithm
-- | -- | -- | -- | -- | --
cora | ('coo','csc') | 0.000464917 | 0.000107054 | 4.34 | small
cora | ('coo','csr') | 0.000449277 | 0.000108357 | 4.15 | small
pubmed | ('coo','csc') | 0.000572143 | 0.000518983 | 1.10 | sparse
pubmed | ('coo','csr') | 0.000416732 | 0.000460249 | 0.91 | sparse
ogbn-arxiv | ('coo','csc') | 0.002656307 | 0.002500843 | 1.06 | sparse
ogbn-arxiv | ('coo','csr') | 0.002499287 | 0.002125469 | 1.18 | sparse
livejournal | ('coo','csc') | 0.368533011 | 0.370530003 | 0.99 | dense
livejournal | ('coo','csr') | 0.222436191 | 0.21996336 | 1.01 | dense
friendster | ('coo','csc') | 13.80159092 | 13.75633977 | 1.00 | dense
friendster | ('coo','csr') | 1.096111846 | 1.089540845 | 1.01 | sorted

Is this benchmark ok for you?",algorithm number available cora small sparse sparse dense dense following use time measurement sha algorithm cora small cora small sparse sparse sparse sparse dense dense dense sorted,issue,negative,negative,neutral,neutral,negative,negative
1541616103,"remove model file, argparse, change Dataloader to GraphDataloader",remove model file change,issue,negative,neutral,neutral,neutral,neutral,neutral
1541523604,@tingyu66 could you help take a look at this issue?,could help take look issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1541462703,"I'm good with the implementation now. Thanks for being patient. Finally, you also need to update the unit tests.",good implementation thanks patient finally also need update unit,issue,positive,positive,positive,positive,positive,positive
1541443401,"Tracked in #5671 , close this request for now. Feel free to reopen it.",tracked close request feel free reopen,issue,positive,positive,positive,positive,positive,positive
1541198865,@yurivict  confirmed. we need update on this example. could you help work on this?,confirmed need update example could help work,issue,negative,positive,positive,positive,positive,positive
1541190075,"How and why do you install the C++ project manually? After build libdgl.so, we just need to run `setup.py install`.",install project manually build need run install,issue,negative,neutral,neutral,neutral,neutral,neutral
1541187832,DGL links `build/third_party/METIS/libmetis/libmetis.a` statically instead of dynamically.,link statically instead dynamically,issue,negative,neutral,neutral,neutral,neutral,neutral
1541164231,`NodeDataLoader` has been deprecated. please use `DataLoader` instead. refer to [here](https://docs.dgl.ai/generated/dgl.dataloading.DataLoader.html#dgl.dataloading.DataLoader) for more details.,please use instead refer,issue,negative,neutral,neutral,neutral,neutral,neutral
1541000803,"It looks like writing .npy files in the load function can be removed, because that's where the mis-shaping occurs. Subsequent run can just re-parse model's text files and return the same model object.
",like writing load function removed subsequent run model text return model object,issue,negative,neutral,neutral,neutral,neutral,neutral
1540982536,"Besides deprecated numpy.float value, it looks like tensors are mis-shaped.

It appears that numpy-1.23.1 allowed mis-shaped tensors in np.array and np.save, and numpy-1.24 now doesn't allow mis-shaped tensors (variables adj, diff, feat, labels in the function load in dataset.py).
",besides value like allow feat function load,issue,positive,neutral,neutral,neutral,neutral,neutral
1540972428,"Yes, I confirm that this testcase works with numpy-1.23.1

It looks like this testcase is not compatible with numpy-1.24.

I don't think that my Python-3.9 is outdated or incompatible with numpy-1.24 because everything else works.
",yes confirm work like compatible think outdated incompatible everything else work,issue,positive,negative,negative,negative,negative,negative
1540942665,"I guess this is because the numpy version is not compatible with your python version.

The reason might be: in numpy 1.24, the float() option has been replaced with the latest python's built-in float operation. However, your python 3.9 is out of date.

My recommendation is to use numpy 1.23. From my end, it works.

Best",guess version compatible python version reason might float option latest python float operation however python date recommendation use end work best,issue,positive,positive,positive,positive,positive,positive
1540458842,"> what do mean of /usr/local/lib/libdgl.so is installed by the C++ part.? Did you install DGL before build?

First I build and install the C++ project. It installs /usr/local/lib/libdgl.so
Then I build and install the python binding (in python).
After the python binding is installed it leaves the file /usr/local/dgl/libdgl.so which is a copy of /usr/local/lib/libdgl.so

There is no need to copy this file.",mean install build first build install project build install python binding python python binding leaf file copy need copy file,issue,negative,negative,neutral,neutral,negative,negative
1540454438,There is no error. libmetis.so is built but not installed. It remains in the build directory only.,error built remains build directory,issue,negative,neutral,neutral,neutral,neutral,neutral
1539814497,"seems `c++: error: -Wl,--exclude-libs,ALL: 'linker' input unused [-Werror,-Wunused-command-line-argument]` is the cause of build failure. could you try add `-DBUILD_CPP_TEST=OFF` into cmake?",error input unused cause build failure could try add,issue,negative,negative,negative,negative,negative,negative
1539765246,did you fail to build metis? what's the error log?,fail build metis error log,issue,negative,negative,negative,negative,negative,negative
1539758184,`DGLBACKEND` is not used in cmake stage. But actually we could print more clear error or disable dgl_spare build if backend is not torch.,used stage actually could print clear error disable build torch,issue,negative,positive,neutral,neutral,positive,positive
1539280899,Confirmed it is a bug in the release process. Will fix it soon.,confirmed bug release process fix soon,issue,negative,positive,positive,positive,positive,positive
1538854648,"No, I use cmake build with the pytorch backend.

My goal is to create the FreeBSD port for DGL, and conda can't be used in this process.

So far I succeeded with the tensorflow backend, but not with the PyTorch backend.",use build goal create port ca used process far,issue,negative,positive,neutral,neutral,positive,positive
1538790094,"Maybe cmake should automatically disable parts that aren't compatible with the currently selected backend, and let the user know that some parts where disabled  for the reason of incompatibility.

This would prevent confusion like this.",maybe automatically disable compatible currently selected let user know disabled reason incompatibility would prevent confusion like,issue,negative,negative,neutral,neutral,negative,negative
1538661096,"> Thank you for your comments. According to test: @frozenbugs, I don't have access to https://github.com/dglai/DGL_scripts/tree/master/regression/benchmarks Maybe a good starting point for c++ test could be the POC of benchmark made on top of gtest ( see https://gist.github.com/anko-intel/b9c4ab9d0eefd2fd496a8ea38a9a11db ) which I use for measurements. I could try also to modify python [benchmark](https://github.com/dmlc/dgl/blob/master/benchmarks/benchmarks/api/bench_format_conversion.py) to check performance of all algorithm versions.

Yes, please modify python [benchmark](https://github.com/dmlc/dgl/blob/master/benchmarks/benchmarks/api/bench_format_conversion.py) to cover all cases.",thank according test access maybe good starting point test could made top see use could try also modify python check performance algorithm yes please modify python cover,issue,positive,positive,positive,positive,positive,positive
1538448622,"are you build in conda as [this](https://docs.dgl.ai/install/index.html#linux) suggests? If not, could you try with it? If yes, could you share the whole command you used for build?",build could try yes could share whole command used build,issue,positive,positive,positive,positive,positive,positive
1538425576,"Thanks for your reporting this. I think DGL supports python 3.11 but such package is missing for linux(win/osx is available).

@czkkkkkk could you double confirm it? I have checked on https://anaconda.org/dglteam/dgl/files and seems py311 is missing for linux. I also tried with `conda search dgl==1.1.0 -c dglteam` on my ubuntu and only py36~310 are found.",thanks think python package missing available could double confirm checked missing also tried search found,issue,negative,positive,neutral,neutral,positive,positive
1538010649,"> > Hello, could you please check the log? I have no idea why simply fixing typos in comments will result in fail of CI ðŸ˜¢
> 
> I think this is due to another random failure irrelevant to your changes. Let me try re-triggering the CI.

Thanks! I have created another PR and when it was merged, it triggered a failure. I felt sorry at first, and later realized it may due to some randomness (Because the following commits irrelevant to my changes passed tests.). :joy:",hello could please check log idea simply fixing result fail think due another random failure irrelevant let try thanks another triggered failure felt sorry first later may due randomness following irrelevant joy,issue,negative,negative,negative,negative,negative,negative
1538001836,"> Hello, could you please check the log? I have no idea why simply fixing typos in comments will result in fail of CI ðŸ˜¢

I think this is due to another random failure irrelevant to your changes. Let me try re-triggering the CI.",hello could please check log idea simply fixing result fail think due another random failure irrelevant let try,issue,negative,negative,negative,negative,negative,negative
1537443773,"Hello, could you please check the log? I have no idea why simply fixing typos in comments will result in fail of CI ðŸ˜¢",hello could please check log idea simply fixing result fail,issue,negative,negative,negative,negative,negative,negative
1537087021,"@Rhett-Ying It works after I update to conda 22.9.0. Thanks. It's better if this can be compatible with older versions of Conda. Alternatively, we can at least raise a warning based on Conda version.",work update thanks better compatible older alternatively least raise warning based version,issue,positive,positive,positive,positive,positive,positive
1537063863,I cannot find the description of the model with edge features in the original paper. Where did it come from?,find description model edge original paper come,issue,negative,positive,positive,positive,positive,positive
1537037254,"As discussed w/ @Rhett-Ying offline, it is not easy to add the benchmark to our new framework directly, can you refactor the existing [benchmark](https://github.com/dmlc/dgl/blob/master/benchmarks/benchmarks/api/bench_format_conversion.py) to cover all 4 cases, and we will migrate them to the new framework once it is ready. ",easy add new framework directly cover migrate new framework ready,issue,positive,positive,positive,positive,positive,positive
1537037253,"> > > @mufeili Thanks for the review. I have improved the docs to address the only outstanding issue in the PR. Can you take another look today as the deadline for our container team is fast approaching?
> > > CC: @chang-l
> > 
> > 
> > Sorry for the late reply. I just came back from the break. When is the deadline?
> 
> Apologies for not being aware of public holidays ðŸ˜ƒ , and thanks for the speedy reply. The container release should be on schedule.

Sounds great!",thanks review address outstanding issue take another look today deadline container team fast approaching sorry late reply came back break deadline aware public thanks speedy reply container release schedule great,issue,positive,positive,positive,positive,positive,positive
1537035224,"> how to add to new benchmark framwork

just refer to existing benchmark and add it into https://github.com/dglai/DGL_scripts/tree/master/regression/benchmarks.
",add new refer add,issue,negative,positive,positive,positive,positive,positive
1537033213,"> > @Rhett-Ying Do we have benchmark for COOToCSR? If not, can you guide @anko-intel to add a benchmark test?
> 
> No. The best way to measure the performance of this change is add c++-level benchmark but we don't have any such framework. As a workaround, we could add python-level benchmarks as [here](https://github.com/dmlc/dgl/tree/master/benchmarks/benchmarks/api). we could measure within a python-level call which will call `COOToCSR` in the back. `graph.create_formats()` or `graph.formats()` could be an option.

We already have a [benchmark](https://github.com/dmlc/dgl/blob/master/benchmarks/benchmarks/api/bench_format_conversion.py) testing COOToCSR, but it only covers 1 case of the 4 cases (sorted, unsortedSmall, unsortedSparse, unsortedDense). It is better to refactor and add the benchmark to our new framework directly. @Rhett-Ying how to add a new benchmark to our new framework?",guide add test best way measure performance change add framework could add could measure within call call back could option already testing case sorted better add new framework directly add new new framework,issue,positive,positive,positive,positive,positive,positive
1537025460,"> @Rhett-Ying Do we have benchmark for COOToCSR? If not, can you guide @anko-intel to add a benchmark test?

No. The best way to measure the performance of this change is add c++-level benchmark but we don't have any such framework. As a workaround, we could add python-level benchmarks as [here](https://github.com/dmlc/dgl/tree/master/benchmarks/benchmarks/api). we could measure within a python-level call which will call `COOToCSR` in the back. `graph.create_formats()` or `graph.formats()` could be an option.",guide add test best way measure performance change add framework could add could measure within call call back could option,issue,positive,positive,positive,positive,positive,positive
1536168552,"@mufeili oh, in my side, it's `conda 22.11.1`. Seems `env` should be used instead of `variables`. could you try with it?",oh side used instead could try,issue,negative,neutral,neutral,neutral,neutral,neutral
1535977674,Thanks for your info. We'll discuss the deprecation and get back to you as soon as possible.,thanks discus deprecation get back soon possible,issue,negative,positive,neutral,neutral,positive,positive
1535690419,"Hi @Rhett-Ying, #5648 seems to successfully compile on the `nvcr.io/nvidia/pytorch:20.12-py3` container which has CUDA 11.1. I am not sure if that is the lowest CUDA version that will compile though.",hi successfully compile container sure version compile though,issue,positive,positive,positive,positive,positive,positive
1535637480,seems `libxsmm` is being built. @itaraban could you help take a look at this issue: https://github.com/dmlc/dgl/issues/5554#issuecomment-1535632162 ?,built could help take look issue,issue,negative,neutral,neutral,neutral,neutral,neutral
1535634060,seems the new log is not attached yet.,new log attached yet,issue,negative,positive,positive,positive,positive,positive
1535632162,"Thanks for the help! I did this, and it seemed to fix the first error but not the second during the METIS build:

```
In file included from ./src/li
[build_output.txt](https://github.com/dmlc/dgl/files/11402960/build_output.txt)
bxsmm_trace.h:14,
                 from ./src/libxsmm_malloc.c:11:
include/libxsmm_macros.h:65:5: error: #error LIBXSMM requires X86_64, AArch64, or compatible CPUs!
 #   error LIBXSMM requires X86_64, AArch64, or compatible CPUs!

```

I've attached the full log again. 
[build_output.txt](https://github.com/dmlc/dgl/files/11402988/build_output.txt)
",thanks help fix first error second metis build file included error error compatible error compatible attached full log,issue,negative,positive,positive,positive,positive,positive
1535594442,"> > @mufeili Thanks for the review. I have improved the docs to address the only outstanding issue in the PR. Can you take another look today as the deadline for our container team is fast approaching?
> > CC: @chang-l
> 
> Sorry for the late reply. I just came back from the break. When is the deadline?

Apologies for not being aware of public holidays :smiley: , and thanks for the speedy reply. The container release should be on schedule.",thanks review address outstanding issue take another look today deadline container team fast approaching sorry late reply came back break deadline aware public thanks speedy reply container release schedule,issue,positive,positive,neutral,neutral,positive,positive
1535591383,"According to the build log you shared, it failed to build `METIS` which does not take ppc into account:
```
make[2]: *** [third_party/METIS/libmetis/CMakeFiles/metis.dir/build.make:238: third_party/METIS/libmetis/CMakeFiles/metis.dir/__/GKlib/io.c.o] Error 1
cc: error: unrecognized command line option '-march=native'; did you mean '-mcpu=native'?
```

could you try to update below line in `//third-party/METIS/GKlib/GKlibSystem.cmake`:
```
set(GKlib_COPTIONS ""${GKlib_COPTIONS} -march=native"")
```
to
```
set(GKlib_COPTIONS ""${GKlib_COPTIONS} -mcpu=native"")
```",according build log build metis take account make error error unrecognized command line option mean could try update line set set,issue,negative,negative,negative,negative,negative,negative
1535294522,"Are there any plans on deprecating CUDA 10.2 support for DGL? DGL dependencies such as thrust and CUB dropped support for it in their latest releases. For example, #5648 requires updating thrust and CUB.",support thrust cub support latest example thrust cub,issue,positive,positive,positive,positive,positive,positive
1534952827,"It looks like the following header can not be found this time: `fatal error: cuda_bf16.h: No such file or directory`

@yaox12 Isn't this header supposed to come with CUDA? Do you have any insights?

Edit: Looks like `cuda_bf16.h` is available starting from CUDA 11.0",like following header found time fatal error file directory header supposed come edit like available starting,issue,negative,positive,positive,positive,positive,positive
1534804140,I have updated DGL to the latest version (1.0.2) and the above problem still exists. @BarclayII ,latest version problem still,issue,negative,positive,positive,positive,positive,positive
1534738319,"```python
def setup_seed(seed):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False
    dgl.seed(seed)

class GeoGCNLayer(nn.Module):
    def __init__(self,
                g,
                args,
                device='cuda'
                ):
        super(GeoGCNLayer, self).__init__()
        self.g = g
        self.device = device
        self.act = nn.LeakyReLU(0.2)
        self.is_att = args.is_att 
        self.is_sgc = args.is_sgc 
        self.args = args
        self.is_lightgcn = args.is_lightgcn
        if self.is_att:
            self.attn_fuse = SemanticAttention(args.loc_dim, args.loc_dim*4)
        
    def forward(self, feat):
        funcs = {}
        feat_t = feat if self.is_lightgcn else self.feat_tran(feat)
        self.g.ndata['f'] = feat_t
        for srctype, etype, dsttype in self.g.canonical_etypes:
            if etype == 'geo':
                funcs[etype] = (fn.copy_u('f', 'm'), fn.mean('m', 'geo'))
            elif etype == 'cat':
                funcs[etype] = (fn.copy_u('f', 'm'), fn.mean('m', 'cat'))
            else:
                funcs[etype] = (fn.u_mul_e('f', 'w', 'm'), fn.sum('m', 'trans'))
                    
        self.g.multi_update_all(funcs, 'sum')
        if self.is_att: 
            geo = self.g.ndata['geo'].unsqueeze(1)
            trans = self.g.ndata['trans'].unsqueeze(1)
            if not self.args.base and self.args.cp4:
                cat = self.g.ndata['cat'].unsqueeze(1)
                z = torch.cat([geo, trans, cat], 1)
            else:
                z = torch.cat([geo, trans], 1)
            feat = self.attn_fuse(z)
        return feat if self.is_sgc else self.act(feat)

class SemanticAttention(nn.Module):
    def __init__(self, in_size, hidden_size=128):
        super(SemanticAttention, self).__init__()

        self.project = nn.Sequential(
            nn.Linear(in_size, hidden_size),
            nn.Tanh(),
            nn.Linear(hidden_size, 1, bias=False)
        )

    def forward(self, z):
        w = self.project(z).mean(0)                    
        beta = torch.softmax(w, dim=0)                 
        beta = beta.expand((z.shape[0],) + beta.shape) 
        return (beta * z).sum(1)

class GeoGCN(nn.Module):
    def __init__(self,
                g,
                tran_e_w,
                args,
                device='cuda'
                ):
        super(GeoGCN, self).__init__()
        g = g.int()
        g = dgl.remove_self_loop(g, etype='geo')
        g = dgl.add_self_loop(g, etype='geo')
        self.g = g.to(device)
        self.g.edges['trans'].data['w'] = torch.tensor(tran_e_w).float().to(device)
        self.num_layer = args.GeoGCN_layer_num
        self.device = device
        self.act = nn.LeakyReLU(0.2)
            
        self.gcn = nn.ModuleList()
        for i in range(self.num_layer):
            self.gcn.append(
            GeoGCNLayer(self.g, args, device)
        )
            
    def forward(self, feat):
        for i in range(self.num_layer - 1):
            feat = self.gcn[i](feat)
        feat = self.gcn[-1](feat)
        return feat

loc_emb_model = nn.Embedding(data.loc_num, args.loc_dim).to(device)
geogcn_model = GeoGCN(data.loc_g, data.tran_edge_weight, args, device).to(device)
loc_emb_model.train()
geogcn_model.train()
loc_emb = loc_emb_model(torch.tensor(range(data.loc_num)).to(device))
loc_emb = geogcn_model(loc_emb)

loc_emb_model.eval()
geogcn_model.eval()
loc_emb = loc_emb_model(torch.tensor(range(data.loc_num)).to(device))
loc_emb = geogcn_model(loc_emb)
```
The approximate code flow is as shown above. Next,  I try to update DGL to the latest version (1.0.2) and retest the experimental results. @BarclayII ",python seed seed seed seed seed true false seed class self super self device forward self feat feat else feat else geo cat geo cat else geo feat return feat else feat class self super self forward self beta beta return beta class self super self device device device range device forward self feat range feat feat feat feat return feat device device device range device range device approximate code flow shown next try update latest version retest experimental,issue,positive,positive,positive,positive,positive,positive
1534501769,"@czkkkkkk I tried, this is the error I get: 

DGLError: [15:53:54] /opt/dgl/src/runtime/c_runtime_api.cc:82: Check failed: allow_missing: Device API cuda is not enabled. Please install the cuda version of dgl.
Stack trace:
  [bt] (0) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7f9cccf1570f]
  [bt] (1) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::DeviceAPIManager::GetAPI(std::string, bool)+0x37c) [0x7f9ccd1cc28c]
  [bt] (2) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::DeviceAPI::Get(DGLContext, bool)+0x1e3) [0x7f9ccd1c6863]
  [bt] (3) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::Empty(std::vector<long, std::allocator<long> >, DGLDataType, DGLContext)+0x15b) [0x7f9ccd1e8dfb]
  [bt] (4) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dgl::runtime::NDArray::CopyTo(DGLContext const&) const+0xc0) [0x7f9ccd225e80]
  [bt] (5) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dgl::aten::COOMatrix::CopyTo(DGLContext const&) const+0x7d) [0x7f9ccd34a07d]
  [bt] (6) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dgl::UnitGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0x2aa) [0x7f9ccd33942a]
  [bt] (7) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(dgl::HeteroGraph::CopyTo(std::shared_ptr<dgl::BaseHeteroGraph>, DGLContext const&)+0xf5) [0x7f9ccd238025]
  [bt] (8) /home/sumit/.local/lib/python3.10/site-packages/dgl/libdgl.so(+0x446f3b) [0x7f9ccd246f3b]

",tried error get check device please install version stack trace bool bool long long,issue,negative,negative,neutral,neutral,negative,negative
1534396664,"Hi @czkkkkkk,

yes now it seems to work. Thanks for check. Close the issue.",hi yes work thanks check close issue,issue,positive,positive,positive,positive,positive,positive
1534356526,"@Rhett-Ying 

I opened a new instance. After running `bash script/create_dev_conda_env.sh -f -g 11.7 -p 3.10 -s -t 2.0`

```
name: dgl-dev-gpu
dependencies:
  - python=3.10
  - pip
  - graphviz
  - pandoc
  - pygraphviz
  - pip:
    - --find-links https://download.pytorch.org/whl/torch_stable.html
    - cython
    - filelock
    - matplotlib
    - networkx
    - nltk
    - nose
    - numpy
    - ogb
    - pandas
    - psutil
    - pyarrow
    - pydantic
    - pytest
    - pyyaml
    - rdflib
    - requests[security]
    - scikit-learn
    - scipy
    - torch==2.0+cu117
    - torchmetrics
    - tqdm
    - boto3 # AWS SDK for python
    - sphinx==4.2.0
    - sphinx-gallery
    - sphinx_rtd_theme
    - sphinx_copybutton
    - sphinxemoji
    - nbsphinx>=0.8.11
    - nbsphinx-link>=1.3.0
    - pillow
    - seaborn
    - jupyter_http_over_ws
variables:
  DGL_HOME: /home/ubuntu/cugraph_230504/dgl
--------------------------------------------------
Create a conda enviroment with the config?
y

EnvironmentSectionNotValid: The following section on '/tmp/4c66917359cacec64598/dgl_dev.yml' is invalid and will be ignored:
 - variables
```

Did you encounter `EnvironmentSectionNotValid`? I then encountered ""ERROR: Please make sure environment variable DGL_HOME is set correctly."" after running `bash script/build_dgl.sh -g`.",new instance running bash name pip pip nose security python pillow create following section invalid encounter error please make sure environment variable set correctly running bash,issue,positive,positive,positive,positive,positive,positive
1534330778,"> @mufeili Thanks for the review. I have improved the docs to address the only outstanding issue in the PR. Can you take another look today as the deadline for our container team is fast approaching?
> 
> CC: @chang-l

Sorry for the late reply. I just came back from the break. When is the deadline?",thanks review address outstanding issue take another look today deadline container team fast approaching sorry late reply came back break deadline,issue,positive,positive,neutral,neutral,positive,positive
1534137067,">One question: how would the users call DataLoader while avoiding storing the entire ID set on a single machine?

@BarclayII To clairfy, this PR assumes the entire index datasets (e.g., train_idx) are stored/duplicated in each machine when calling the dataloader (people can use shared memory to store the datasets to save memory). So, with this PR, the native DGL (without DistDGL) should work out-of-the-box with `torchrun`/`torch.distributed.launch`, assuming each machine has a copy of graph structure/features/index datasets.

In future, if users have to store id datasets distributedly across nodes, unlike distributed sampling or distributed feature fetching (given index datasets are already distributed, it is reasonable to assume graph/feature must also be stored distributedly), the modification based on this PR should be much more straightforward. We just need to ensure the input `indices` is decomposed to every local process instead of all processes, i.e., just changing the function call `_decompose_one_dimension(length, world_size, rank, drop_last):` --> `_decompose_one_dimension(length, local_world_size, local_rank, drop_last):`.",one question would call entire id set single machine entire index machine calling people use memory store save memory native without work assuming machine copy graph future store id distributedly across unlike distributed sampling distributed feature fetching given index already distributed reasonable assume must also distributedly modification based much straightforward need ensure input index decomposed every local process instead function call length rank length,issue,positive,negative,neutral,neutral,negative,negative
1534090861,"(@jermainewang not sure how to re-open this issue, can you help?) 

I am running `bash script/build_dgl.sh -c` and getting the errors such as:

```
cc: error: unrecognized command line option '-march=native'; did you mean '-mcpu=native'?
make[2]: *** [third_party/tensorpipe/tensorpipe/CMakeFiles/tensorpipe_uv.dir/build.make:82: third_party/tensorpipe/tensorpipe/CMakeFiles/tensorpipe_uv.dir/__/third_party/libuv/src/fs-poll.c.o] Error 1
```

and 


```
include/libxsmm_macros.h:65:5: error: #error LIBXSMM requires X86_64, AArch64, or compatible CPUs!
 #   error LIBXSMM requires X86_64, AArch64, or compatible CPUs!
     ^~~~~
In file included from include/libxsmm_typedefs.h:14,
                 from include/libxsmm_mhd.h:14,
                 from ./src/libxsmm_math.c:11:
```

The full output of the build Is attached. 
[build_output.txt](https://github.com/dmlc/dgl/files/11392023/build_output.txt)
",sure issue help running bash getting error unrecognized command line option mean make error error error compatible error compatible file included full output build attached,issue,negative,positive,positive,positive,positive,positive
1534089180,@jermainewang the fix did not resolve the issue. I will reopen (sorry didn't know I could do that). ,fix resolve issue reopen sorry know could,issue,negative,negative,negative,negative,negative,negative
1534069359,"It looks like the libcudacxx headers can not be found even though I added it to the cuda include directories, what else needs to be done so that those headers can be found?

Error msg: `/root/jenkins/workspace/dgl_PR-5648@2/third_party/thrust/thrust/detail/type_traits.h:27:10: fatal error: cuda/std/type_traits: No such file or directory`

Edit: added `include` to the include path for libcudacxx, I hope it will work now.",like found even though added include else need done found error fatal error file directory edit added include include path hope work,issue,negative,neutral,neutral,neutral,neutral,neutral
1533996716,I try to install DGL on Colab but cannot reproduce the issue. The problem may due to some unstable issues in our webpage.,try install reproduce issue problem may due unstable,issue,negative,negative,negative,negative,negative,negative
1533995602,@xjtubraveheart Could you post your code?  And could you also upgrade DGL to the latest version (1.0.2)?,could post code could also upgrade latest version,issue,negative,positive,positive,positive,positive,positive
1533988290,"@yaox12
1. Not yet, I just recently contributed DeviceCopy to CUB in this [PR](https://github.com/NVIDIA/cub/pull/675), I guess it will be included in the next release. I don't know the timeline of the next release though.
2. It looks like thrust includes cub and libcu++ as submodule dependencies however I don't know if the libcu++ version that comes with thrust is compatible with CUDA 10.2. What I was able to find is that libcu++ was first released for CUDA 10.2. I don't know if they dropped CUDA 10.2 support in later releases.
",yet recently cub guess included next release know next release though like thrust cub however know version come thrust compatible able find first know support later,issue,positive,positive,positive,positive,positive,positive
1533982466,"Hi @yura-hb , 

Could you try `pip install  dgl -f https://data.dgl.ai/wheels/cu118/repo.html` again?",hi could try pip install,issue,negative,neutral,neutral,neutral,neutral,neutral
1533978639,"@mfbalin 
1. Has this feature been included in any CUB release version?
2. CUB 2.x introduced the libcu++ dependency. Do you know if it's compatible with CUDA 10.2, since DGL still supports it?",feature included cub release version cub dependency know compatible since still,issue,negative,neutral,neutral,neutral,neutral,neutral
1533976908,Make sense! Thanks for catching this. Please go ahead and create a PR for this.,make sense thanks catching please go ahead create,issue,positive,positive,positive,positive,positive,positive
1533971694,"Hi @hnisonoff , it looks like a duplicate of #5554 . Does the fix there resolve your issue? If not, please reopen that issue and close this one so we can have one place to discuss.",hi like duplicate fix resolve issue please reopen issue close one one place discus,issue,positive,neutral,neutral,neutral,neutral,neutral
1533952983,"Thanks for reporting this. As mentioned in https://discuss.dgl.ai/t/convert-parmetis-partition-to-dgl-graph/3646/2, we'll work on the update of doc page.",thanks work update doc page,issue,negative,positive,positive,positive,positive,positive
1533806288,One question: how would the users call DataLoader while avoiding storing the entire ID set on a single machine?,one question would call entire id set single machine,issue,negative,negative,neutral,neutral,negative,negative
1533573204,Discussion is in https://discuss.dgl.ai/t/not-able-to-iterate-through-dataloader/3633 so I'll close it.  Let's follow up there.,discussion close let follow,issue,negative,neutral,neutral,neutral,neutral,neutral
1533130385,"> Suppose I don't wish to use GPU (even CPU would be sufficient for me) would DGL still require CUDA? I'm using DeepChem and some of its functions require DGL.

Sure. You can use the CPU version of DGL in the case.",suppose wish use even would sufficient would still require require sure use version case,issue,positive,positive,positive,positive,positive,positive
1532996800,@k-styles I tried but there's some error while importing deepchem in a conda environment. I need DGL for some of the tasks that can only be done from deepchem.,tried error environment need done,issue,negative,neutral,neutral,neutral,neutral,neutral
1532993893,@czkkkkkk Suppose I don't wish to use GPU (even CPU would be sufficient for me) would DGL still require CUDA? I'm using DeepChem and some of its functions require DGL. ,suppose wish use even would sufficient would still require require,issue,negative,neutral,neutral,neutral,neutral,neutral
1532712213,"I encountered the same problem. When the GNN-related code is commented out, the results, whether GPU or CPU, can be reproduced exactly in each case. Once the GNN learning code is added, the results with GPU start to fluctuate and cannot be reproduced. However, the results with CPU can be reproduced. DGL version: 1.0.1+cu113, Torch version: 1.11.0+cu113.
@BarclayII @frozenbugs ",problem code whether exactly case learning code added start fluctuate however version torch version,issue,negative,positive,positive,positive,positive,positive
1532147010,"@BarclayII @yaox12, could you take a look? This PR requires using the latest thrust and cub versions.",could take look latest thrust cub,issue,negative,positive,positive,positive,positive,positive
1530002987,"@mufeili Thanks for the review. I have improved the docs to address the only outstanding issue in the PR. Can you take another look today as the deadline for our container team is fast approaching? 

CC: @chang-l ",thanks review address outstanding issue take another look today deadline container team fast approaching,issue,positive,positive,positive,positive,positive,positive
1527550726,"> > > @tingyu66 Have you pushed the new docker image to re-enable unit tests?
> > 
> > 
> > This PR #5614 updates the docker image.
> 
> Can I trigger CI now? @tingyu66

Yes",new docker image unit docker image trigger yes,issue,negative,positive,positive,positive,positive,positive
1527288979,"> @itaraban could you also fix this one? Thanks!

I forgot to add fix for this one,
@czkkkkkk , please check now.
",could also fix one thanks forgot add fix one please check,issue,positive,positive,positive,positive,positive,positive
1527275734,"@mufeili I tried on my side and it works well. build upon latest master branch(`665c3798716b03fb34dae7045d48e85c34ea1fa9`).

according to below error message, why it's `python3.8` instead of `python3.10`. Did you create the expected conda env successfully? try with `bash script/create_dev_conda_env.sh -f -g 11.7 -p 3.10 -s -t 2.0`? just append `-f`.
```
make[5]: *** No rule to make target '/opt/conda/envs/5540/lib/python3.8/site-packages/torch/lib/libc10.so', needed by 'libdgl_sparse_pytorch_2.0.0.so'.  Stop.
```",tried side work well build upon latest master branch according error message instead create successfully try bash append make rule make target stop,issue,negative,positive,positive,positive,positive,positive
1527257986,"According to above log, `#inputs` in `new example` is much larger than `old example`, I think this is what cause the performance difference.

So the question is why `new example` always samples more input nodes than `old example`. we need to look deep into this.",according log new example much old example think cause performance difference question new example always input old example need look deep,issue,negative,positive,neutral,neutral,positive,positive
1527245583,"I tried to build with this fix, but there was still one error.

![image](https://user-images.githubusercontent.com/17905585/235107129-557431e3-cfc8-4d2e-8a80-70bf4233426f.png)

@itaraban could you also fix this one? Thanks!",tried build fix still one error image could also fix one thanks,issue,negative,positive,positive,positive,positive,positive
1527227799,"> > @tingyu66 Have you pushed the new docker image to re-enable unit tests?
> 
> This PR #5614 updates the docker image.

Can I trigger CI now? @tingyu66 ",new docker image unit docker image trigger,issue,negative,positive,positive,positive,positive,positive
1527137582,closed as benchmark is done. all look good to me.,closed done look good,issue,negative,positive,positive,positive,positive,positive
1526944882,"As this issue is mainly about ASV benchmark framework, let's close this ticket and I will track it on another ticket.",issue mainly framework let close ticket track another ticket,issue,negative,positive,positive,positive,positive,positive
1526943056,"crashed with below error:
```
Traceback (most recent call last):
                 File ""<string>"", line 1, in <module>
                 File ""/asv/dgl/benchmarks/env/06715dc6ea55f2b02b6ebc21bca7e34a/lib/python3.10/multiprocessing/spawn.py"", line 116, in spawn_main
                   exitcode = _main(fd, parent_sentinel)
                 File ""/asv/dgl/benchmarks/env/06715dc6ea55f2b02b6ebc21bca7e34a/lib/python3.10/multiprocessing/spawn.py"", line 126, in _main
                   self = reduction.pickle.load(from_parent)
                 File ""/asv/dgl/benchmarks/env/06715dc6ea55f2b02b6ebc21bca7e34a/lib/python3.10/site-packages/benchmarks/multigpu/bench_multigpu_rgcn.py"", line 28, in <module>
                   from .. import utils
                 File ""/asv/dgl/benchmarks/env/06715dc6ea55f2b02b6ebc21bca7e34a/lib/python3.10/site-packages/benchmarks/utils.py"", line 482, in <module>
                   filter = TestFilter()
                 File ""/asv/dgl/benchmarks/env/06715dc6ea55f2b02b6ebc21bca7e34a/lib/python3.10/site-packages/benchmarks/utils.py"", line 457, in __init__
                   with open(path, ""r"") as f:
               FileNotFoundError: [Errno 2] No such file or directory: '/asv/dgl/benchmarks/env/06715dc6ea55f2b02b6ebc21bca7e34a/lib/python3.10/site-packages/benchmarks/../../benchmarks/task.json'
```",error recent call last file string line module file line file line self file line module import file line module filter file line open path file directory,issue,negative,neutral,neutral,neutral,neutral,neutral
1526917800,"> @czkkkkkk could you please check my changes(https://github.com/dmlc/dgl/pull/5626) on your machine?

Sure! Thanks for the fix.",could please check machine sure thanks fix,issue,positive,positive,positive,positive,positive,positive
1525851971,@czkkkkkk could you please check my changes(https://github.com/dmlc/dgl/pull/5626) on your machine?,could please check machine,issue,negative,neutral,neutral,neutral,neutral,neutral
1524728359,"Got slightly different results this time (measured with tcmalloc):
old example + [5, 10, 15]:
```
Part 7, Epoch Time(s): 20.8654, sample+data_copy: 3.0675, forward: 3.5795, backward: 10.0897, update: 0.1916, #seeds: 150897, #inputs: 62057612
Part 4, Epoch Time(s): 20.8595, sample+data_copy: 3.1304, forward: 3.6686, backward: 10.1512, update: 0.1791, #seeds: 150897, #inputs: 59525249
Part 0, Epoch Time(s): 20.8609, sample+data_copy: 2.9873, forward: 3.9348, backward: 9.9412, update: 0.1899, #seeds: 150898, #inputs: 58755408
Part 3, Epoch Time(s): 20.8730, sample+data_copy: 3.0860, forward: 4.0205, backward: 9.4282, update: 0.1841, #seeds: 150897, #inputs: 64409679
Part 2, Epoch Time(s): 20.8610, sample+data_copy: 3.0541, forward: 3.6028, backward: 10.1379, update: 0.1839, #seeds: 150898, #inputs: 58862690
Part 1, Epoch Time(s): 20.8736, sample+data_copy: 2.9929, forward: 3.7229, backward: 10.2041, update: 0.1859, #seeds: 150898, #inputs: 57445415
Part 6, Epoch Time(s): 20.8611, sample+data_copy: 6.3976, forward: 3.8441, backward: 6.5445, update: 0.1823, #seeds: 150897, #inputs: 59953762
Part 5, Epoch Time(s): 20.8735, sample+data_copy: 3.0874, forward: 3.3330, backward: 11.3153, update: 0.1801, #seeds: 150897, #inputs: 45676915

```
old example + [15, 10, 5]:
```
Part 4, Epoch Time(s): 21.5111, sample+data_copy: 3.0107, forward: 5.7901, backward: 9.0540, update: 0.1788, #seeds: 150897, #inputs: 52678500
Part 3, Epoch Time(s): 21.5113, sample+data_copy: 2.9846, forward: 5.8501, backward: 8.7853, update: 0.1801, #seeds: 150897, #inputs: 56664419
Part 0, Epoch Time(s): 21.5127, sample+data_copy: 2.8420, forward: 5.7194, backward: 9.5180, update: 0.1731, #seeds: 150898, #inputs: 50996196
Part 7, Epoch Time(s): 21.5131, sample+data_copy: 2.8926, forward: 5.7513, backward: 9.2465, update: 0.1752, #seeds: 150897, #inputs: 54997241
Part 2, Epoch Time(s): 21.5120, sample+data_copy: 2.9610, forward: 5.3282, backward: 9.6714, update: 0.1869, #seeds: 150898, #inputs: 50791396
Part 1, Epoch Time(s): 21.5124, sample+data_copy: 3.0756, forward: 5.7185, backward: 8.9031, update: 0.1834, #seeds: 150898, #inputs: 51317819
Part 6, Epoch Time(s): 21.5125, sample+data_copy: 3.0365, forward: 5.9504, backward: 8.8429, update: 0.1902, #seeds: 150897, #inputs: 53531324
Part 5, Epoch Time(s): 21.5127, sample+data_copy: 2.9088, forward: 5.0472, backward: 10.8057, update: 0.1771, #seeds: 150897, #inputs: 39946971

```
new example + [5, 10, 15]:
```
Part 0, Epoch Time(s): 42.3211, sample+data_copy: 2.7940, forward: 6.8885, backward: 11.9620, update: 0.1843, #seeds: 150898, #inputs: 63119022
Part 4, Epoch Time(s): 42.3203, sample+data_copy: 2.7386, forward: 5.6733, backward: 13.1073, update: 0.1619, #seeds: 150897, #inputs: 64937993
Part 7, Epoch Time(s): 42.3212, sample+data_copy: 3.0381, forward: 5.4593, backward: 6.6245, update: 0.1605, #seeds: 150897, #inputs: 67680253
Part 1, Epoch Time(s): 42.3214, sample+data_copy: 2.8848, forward: 7.0577, backward: 13.9058, update: 0.1761, #seeds: 150898, #inputs: 61930449
Part 2, Epoch Time(s): 42.3204, sample+data_copy: 2.7165, forward: 5.2351, backward: 15.1949, update: 0.1590, #seeds: 150898, #inputs: 64145931
Part 3, Epoch Time(s): 42.3213, sample+data_copy: 2.8780, forward: 5.7714, backward: 11.7612, update: 0.1651, #seeds: 150897, #inputs: 71000024
Part 5, Epoch Time(s): 42.3211, sample+data_copy: 2.6361, forward: 4.9186, backward: 19.5322, update: 0.1596, #seeds: 150897, #inputs: 47300518
Part 6, Epoch Time(s): 42.3205, sample+data_copy: 2.7795, forward: 5.6485, backward: 8.3973, update: 0.1603, #seeds: 150897, #inputs: 65587197

```
new example + [15, 10, 5]:
```
Part 4, Epoch Time(s): 36.5431, sample+data_copy: 2.7602, forward: 3.1342, backward: 9.0168, update: 0.1596, #seeds: 150897, #inputs: 73321625
Part 0, Epoch Time(s): 36.5421, sample+data_copy: 2.8829, forward: 3.8618, backward: 14.0018, update: 0.1602, #seeds: 150898, #inputs: 72702212
Part 2, Epoch Time(s): 36.5424, sample+data_copy: 2.9006, forward: 3.3816, backward: 11.1381, update: 0.1699, #seeds: 150898, #inputs: 74278150
Part 7, Epoch Time(s): 36.5432, sample+data_copy: 2.7739, forward: 3.0995, backward: 4.0968, update: 0.1593, #seeds: 150897, #inputs: 76231714
Part 1, Epoch Time(s): 36.5427, sample+data_copy: 2.9140, forward: 3.9607, backward: 8.8463, update: 0.1818, #seeds: 150898, #inputs: 69019196
Part 3, Epoch Time(s): 36.5443, sample+data_copy: 2.9138, forward: 3.3495, backward: 7.4329, update: 0.1650, #seeds: 150897, #inputs: 80251475
Part 5, Epoch Time(s): 36.5424, sample+data_copy: 2.7966, forward: 3.0235, backward: 8.8597, update: 0.1618, #seeds: 150897, #inputs: 54236246

```",got slightly different time measured old example part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update old example part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update new example part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update new example part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update part epoch time forward backward update,issue,negative,positive,neutral,neutral,positive,positive
1524668485,"Hi @sumenties,

Currently DGL does not officially support CUDA 12.0 as Pytorch does not support it. We will support it as soon as Pytorch offers support on it.",hi currently officially support support support soon support,issue,positive,neutral,neutral,neutral,neutral,neutral
1524477056,"I see the problem.  `block` is a directed bipartite graph, and the source nodes (i.e. `us`) only have outgoing edges.  So you should call `blocks[i].out_degrees(us)` and `blocks[i].in_degrees(vs)`.

I guess since there is no incoming edge type for the source nodes and we did not have a sanity check for that, it returned arbitrary content.  We should add a sanity check for `in_degrees` and `out_degrees`.",see problem block directed bipartite graph source u outgoing call u guess since incoming edge type source sanity check returned arbitrary content add sanity check,issue,negative,negative,neutral,neutral,negative,negative
1524433101,"Hi @beew , in 1.1, the original `.adj()` is renamed as `.adj_external()` and `.adj()` will produce DGL sparse matrix. We will public the release note soon.",hi original produce sparse matrix public release note soon,issue,negative,positive,positive,positive,positive,positive
1524347100,"Yes, by setting 'cuda device to 'cuda:6'' I solved the problem.",yes setting device problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1524338105,"I made changes for these multigpu benchmark tests to utilize `spawn` and `nccl`, this does resolve the crash issue. But a new issue is hit which is caused by the benchmark framework(ASV) we're using. I will keep working on it.",made utilize spawn resolve crash issue new issue hit framework keep working,issue,negative,positive,positive,positive,positive,positive
1523836004,"You can install CUDA in conda environment, and then install dgl.
Refer this for CUDA installation: https://anaconda.org/nvidia/cuda
",install environment install refer installation,issue,negative,neutral,neutral,neutral,neutral,neutral
1523758719,@Rhett-Ying  Any idea why distributed torch unit test keeps failing? This PR should not affect distDGL part I think.,idea distributed torch unit test failing affect part think,issue,negative,neutral,neutral,neutral,neutral,neutral
1523120086,"Hi @lzc17, I think it could be a bug of DGL. Could you try 'cuda:0' to see whether this is still a problem? Also you may try to [set cuda device](https://pytorch.org/docs/stable/generated/torch.cuda.set_device.html) to 'cuda:6' to avoid potential device selection problem.",hi think could bug could try see whether still problem also may try set device avoid potential device selection problem,issue,negative,neutral,neutral,neutral,neutral,neutral
1522811062,"Here's the configuration while reproducing in my local machine(reproduced though different from what we use in daily benchmark tests):
PyTorch: `2.0.0+cu117`
cuda + driver: `NVIDIA-SMI 515.65.01    Driver Version: 515.65.01    CUDA Version: 11.7`
ubuntu 22.04",configuration local machine though different use daily driver driver version version,issue,negative,neutral,neutral,neutral,neutral,neutral
1522744726,Can you add the driver version (you can query it via `nvidia-smi`) and what GPU(s) the system has?,add driver version query via system,issue,negative,neutral,neutral,neutral,neutral,neutral
1522732287,"I put the Tensor in locked page memory, but it prompts an error about not putting it in.
Also if I use the 'dgl.utils.pin_memory_inplaceh' function, I don't know how to pass the return result of type dgl.ndarrayl to the 'gather_pinned_tensor_rowsh ' function.",put tensor locked page memory error also use function know pas return result type function,issue,negative,neutral,neutral,neutral,neutral,neutral
1522659934,"Testing on the products dataset shows that the tensor obtained is all 0
```
from ogb.nodeproppred import DglNodePropPredDataset
data = DglNodePropPredDataset(name=name, root=root)
splitted_idx = data.get_idx_split()
graph, labels = data[0]
feat = graph.ndata.pop('feat')
# print(feat.dtype) # torch.float32
feat = feat.pin_memory()
print(feat.is_pinned())
device = torch.device('cuda:6')
index = torch.LongTensor([1, 2, 3, 4, 5, 14, 19]).to(device)
batch_feats = dgl.utils.gather_pinned_tensor_rows(feat, index)
print(batch_feats)
```

resultï¼š
(dgl0.8.0) python test3.py
WARNING:root:The OGB package is out of date. Your version is 1.3.0, while the latest version is 1.3.6.
True
tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0.],
        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
         0., 0., 0., 0.]], device='cuda:6')

",testing tensor import data graph data feat print feat print device index device feat index print python warning root package date version latest version true tensor,issue,negative,positive,positive,positive,positive,positive
1522632802,"I solved this problem with the following codeï¼š
```
feats = torch.rand((128, 128)).pin_memory()
device = torch.device('cuda:6')
index = torch.LongTensor([1, 2, 3, 4, 5]).to(device)
batch_feats = dgl.utils.gather_pinned_tensor_rows(feats, index)
print(batch_feats)
```",problem following device index device index print,issue,negative,neutral,neutral,neutral,neutral,neutral
1522621446,"@itaraban  As shown in https://github.com/dmlc/dgl/pull/5615#issuecomment-1522615424, confirmed. perf issue is resolved. really appreciate your help.",shown confirmed issue resolved really appreciate help,issue,positive,positive,positive,positive,positive,positive
1522609591,Add this code â€™train_g.pin_memory_()â€™ ï¼Œbut the error still exists.,add code error still,issue,negative,neutral,neutral,neutral,neutral,neutral
1522576491,"@chang-l yes, I hit this issue when run on CPU.",yes hit issue run,issue,negative,neutral,neutral,neutral,neutral,neutral
1522431579,"> @tingyu66 Have you pushed the new docker image to re-enable unit tests?

This PR https://github.com/dmlc/dgl/pull/5614 updates the docker image.",new docker image unit docker image,issue,negative,positive,positive,positive,positive,positive
1522266199,@VibhuJawa Can you take a look if I miss something?,take look miss something,issue,negative,neutral,neutral,neutral,neutral,neutral
1522202446,"@Rhett-Ying can you list what the system configuration was and what the driver, cuda, and pytorch versions were?

While it works using `fork` in some cases, if a cuda context gets created prior to the call to `fork`, it leads to undefined behavior as it is not valid to duplicate a cuda context. So in general to be safe, we should always use `spawn`, as it may not always be obvious when a cuda context is created (I think for a while the ogb package was creating a cuda context when imported  if PyTorch Geometric was installed).
An important note here, is in cuda 12 the call `cudaSetDevice()` now initialized the cuda context, where in prior versions it did not (https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#initialization).

When training on GPUs `nccl` should be used as the backend, to avoid doing communication across PCIe and host memory. Even if NVLINK is not present on the system, `nccl` should still be faster.

",list system configuration driver work fork context prior call fork undefined behavior valid duplicate context general safe always use spawn may always obvious context think package context geometric important note call context prior training used avoid communication across host memory even present system still faster,issue,negative,positive,positive,positive,positive,positive
1522098949,"> pytorch: 1.13.1

Thanks @Rhett-Ying . In fact, I was not able to reproduce the [crash ](https://github.com/dmlc/dgl/issues/5592)with latest PyTorch (built/run with cuda) yesterday... I guess you ran it with CPU-only? (of course it is a bug even if it ran through with cuda)
Anyway, glad it fixes the issue. I will finalize this PR later today :)",thanks fact able reproduce crash latest yesterday guess ran course bug even ran anyway glad issue finalize later today,issue,negative,positive,positive,positive,positive,positive
1521696395,"@nv-dlasalle @chang-l @yaox12 
could you help take a look at this issue? It's blocking us cut a new release.

One more question: For GPU training, should we always use `spawn` or `forkserver` instead of `fork` for multiprocessing start method? should we always use `nccl` backend instead of `gloo`?",could help take look issue blocking u cut new release one question training always use spawn instead fork start method always use instead,issue,negative,positive,positive,positive,positive,positive
1521521198,"Hi @lzc17 , you may need to pin the graph to unpagable CPU memory to support UVA. (https://docs.dgl.ai/en/latest/generated/dgl.DGLGraph.pin_memory_.html)",hi may need pin graph memory support uva,issue,negative,neutral,neutral,neutral,neutral,neutral
1521518390,"Hi @lzc17 , could you upgrade DGL to the newest version (1.0) to see whether this problem still exists?",hi could upgrade version see whether problem still,issue,negative,neutral,neutral,neutral,neutral,neutral
1521331190,"Could you move the logic of `GatedGCNConv` to another PR? It might be easier to merge that PR first. Then we can merge this PR for example.

This PR also lacks the unit tests related to this module. Please add a file `dgl/tests/python/pytorch/nn/conv/test_gatedgcnconv.py`. For an example of unit tests, see https://github.com/dmlc/dgl/pull/3934.

You also need to add GatedGCNConv in https://github.com/dmlc/dgl/blob/master/docs/source/api/python/nn-pytorch.rst",could move logic another might easier merge first merge example also unit related module please add file example unit see also need add,issue,positive,positive,positive,positive,positive,positive
1521290564,"LGTM, @mufeili please double check the logic.",please double check logic,issue,negative,neutral,neutral,neutral,neutral,neutral
1521279945,@tingyu66 Have you pushed the new docker image to re-enable unit tests?,new docker image unit,issue,negative,positive,positive,positive,positive,positive
1521225079,@itaraban could you help look into this issue as you're the owner of https://github.com/dmlc/dgl/pull/5497? This is blocking us cutting a new release of DGL.,could help look issue owner blocking u cutting new release,issue,negative,negative,negative,negative,negative,negative
1521148951,"@Rhett-Ying  Can you please try this PR to see if it can fix your crash? Also, what PyTorch version did you use for testing?",please try see fix crash also version use testing,issue,negative,neutral,neutral,neutral,neutral,neutral
1521103953,"> Exception ignored in: <bound method UnifiedTensor.__del__ of tensor([[0.9717, 0.0579, 0.5422,  ..., 0.8766, 0.7010, 0.8137],
        [0.5823, 0.1262, 0.2802,  ..., 0.9846, 0.3340, 0.6062],
        [0.2277, 0.0496, 0.9529,  ..., 0.0415, 0.8323, 0.2445],
        ...,
        [0.6421, 0.8142, 0.7261,  ..., 0.9613, 0.8522, 0.7953],
        [0.5317, 0.2674, 0.8072,  ..., 0.0387, 0.1471, 0.9845],
        [0.7836, 0.9521, 0.6946,  ..., 0.7086, 0.4129, 0.4234]])>
Traceback (most recent call last):
  File ""/home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/site-packages/dgl/contrib/unified_tensor.py"", line 108, in __del__
  File ""/home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/site-packages/dgl/_ffi/ndarray.py"", line 327, in unpin_memory_
  File ""/home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/site-packages/dgl/_ffi/base.py"", line 65, in check_call
dgl._ffi.base.DGLError: [23:20:41] /opt/dgl/src/runtime/cuda/cuda_device_api.cc:187: Check failed: e == cudaSuccess || e == cudaErrorCudartUnloading: CUDA: an illegal memory access was encountered
Stack trace:
  [bt] (0) /home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/site-packages/dgl/libdgl.so(dmlc::LogMessageFatal::~LogMessageFatal()+0x4f) [0x7fe4157f757f]
  [bt] (1) /home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/site-packages/dgl/libdgl.so(dgl::runtime::CUDADeviceAPI::UnpinData(void*)+0xac) [0x7fe415cce93c]
  [bt] (2) /home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/site-packages/dgl/libdgl.so(DGLArrayUnpinData+0x6) [0x7fe415b3d3b6]
  [bt] (3) /home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call_unix64+0x4c) [0x7fe4b99d1630]
  [bt] (4) /home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/lib-dynload/../../libffi.so.6(ffi_call+0x22d) [0x7fe4b99d0fed]
  [bt] (5) /home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(_ctypes_callproc+0x2ce) [0x7fe4b10c9b9e]
  [bt] (6) /home/liuzhencheng/anaconda3/envs/dgl0.8.0/lib/python3.6/lib-dynload/_ctypes.cpython-36m-x86_64-linux-gnu.so(+0x125d5) [0x7fe4b10ca5d5]
  [bt] (7) python(_PyObject_FastCallDict+0x8b) [0x557eb6430a7b]
  [bt] (8) python(+0x19e2ce) [0x557eb64c02ce]
",exception bound method tensor recent call last file line file line file line check illegal memory access stack trace void python python,issue,negative,negative,negative,negative,negative,negative
1520799519,"> any update on this @tingyu66 ?

This is ready for review. It simply updates the model to reflect the breaking changes in cugraph-ops. Thanks!",update ready review simply model reflect breaking thanks,issue,positive,positive,positive,positive,positive,positive
1519404961,"<html xmlns:v=""urn:schemas-microsoft-com:vml""
xmlns:o=""urn:schemas-microsoft-com:office:office""
xmlns:x=""urn:schemas-microsoft-com:office:excel""
xmlns=""http://www.w3.org/TR/REC-html40"">

<head>

<meta name=ProgId content=Excel.Sheet>
<meta name=Generator content=""Microsoft Excel 15"">
<link id=Main-File rel=Main-File
href=""file:////Users/ruying/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip.htm"">
<link rel=File-List
href=""file:////Users/ruying/Library/Group%20Containers/UBF8T346G9.Office/TemporaryItems/msohtmlclip/clip_filelist.xml"">
<style>
<!--table
	{mso-displayed-decimal-separator:""\."";
	mso-displayed-thousand-separator:""\,"";}
@page
	{margin:1.0in .75in 1.0in .75in;
	mso-header-margin:.5in;
	mso-footer-margin:.5in;}
tr
	{mso-height-source:auto;}
col
	{mso-width-source:auto;}
br
	{mso-data-placement:same-cell;}
td
	{padding-top:1px;
	padding-right:1px;
	padding-left:1px;
	mso-ignore:padding;
	color:black;
	font-size:12.0pt;
	font-weight:400;
	font-style:normal;
	text-decoration:none;
	font-family:Calibri, sans-serif;
	mso-font-charset:0;
	mso-number-format:General;
	text-align:general;
	vertical-align:bottom;
	border:none;
	mso-background-source:auto;
	mso-pattern:auto;
	mso-protection:locked visible;
	white-space:nowrap;
	mso-rotate:0;}
.xl63
	{mso-number-format:Scientific;}
.xl64
	{mso-number-format:0%;}
-->
</style>
</head>

<body link=""#0563C1"" vlink=""#954F72"">



Â  | test_name | params | unit | (1.1 - 1.0.2)/1.0.2 | number_5591 | machine | number_tags/1.0.2
-- | -- | -- | -- | -- | -- | -- | --
135 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 256, 'u_mul_e', 'sum' | s | 302% | 8.19365702 | r6i.16xlarge-cpu | 2.03621097
136 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 256, 'u_mul_e', 'mean' | s | 290% | 8.04209072 | r6i.16xlarge-cpu | 2.06068828
117 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 256, 'u_mul_e', 'sum' | s | 289% | 8.13442738 | r6i.16xlarge-cpu | 2.08935334
118 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 256, 'u_mul_e', 'mean' | s | 283% | 8.13007692 | r6i.16xlarge-cpu | 2.12523823
99 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 256, 'u_mul_e', 'sum' | s | 108% | 0.08485952 | r6i.16xlarge-cpu | 0.04086187
93 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 32, 'u_mul_e', 'sum' | s | 104% | 0.00931347 | r6i.16xlarge-cpu | 0.00455891
100 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 256, 'u_mul_e', 'mean' | s | 85% | 0.10064533 | r6i.16xlarge-cpu | 0.05444648
111 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 32, 'u_mul_e', 'sum' | s | 70% | 0.8742621 | r6i.16xlarge-cpu | 0.51339596
112 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 32, 'u_mul_e', 'mean' | s | 70% | 0.87357228 | r6i.16xlarge-cpu | 0.51367033
129 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 32, 'u_mul_e', 'sum' | s | 43% | 0.60297694 | r6i.16xlarge-cpu | 0.42041867
130 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 32, 'u_mul_e', 'mean' | s | 41% | 0.59967492 | r6i.16xlarge-cpu | 0.42419665
94 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 32, 'u_mul_e', 'mean' | s | 39% | 0.00789198 | r6i.16xlarge-cpu | 0.00566138
87 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 4, 'u_mul_e', 'sum' | s | 11% | 0.00142687 | r6i.16xlarge-cpu | 0.00128893
88 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 4, 'u_mul_e', 'mean' | s | 4% | 0.00188696 | r6i.16xlarge-cpu | 0.00181737
89 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 4, 'u_mul_e', 'max' | s | 2% | 0.00275997 | r6i.16xlarge-cpu | 0.00270861
95 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 32, 'u_mul_e', 'max' | s | 2% | 0.02039767 | r6i.16xlarge-cpu | 0.0200372
101 | api.bench_builtin_update_all_csc.track_time | 'ogbn-arxiv', 'csc', 256, 'u_mul_e', 'max' | s | 2% | 0.17094409 | r6i.16xlarge-cpu | 0.16832822
107 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 4, 'u_mul_e', 'max' | s | 1% | 0.23925228 | r6i.16xlarge-cpu | 0.23624785
137 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 256, 'u_mul_e', 'max' | s | 0% | 3.22021435 | r6i.16xlarge-cpu | 3.21584459
131 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 32, 'u_mul_e', 'max' | s | 0% | 0.57619693 | r6i.16xlarge-cpu | 0.57593793
113 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 32, 'u_mul_e', 'max' | s | -1% | 0.63629046 | r6i.16xlarge-cpu | 0.63963108
119 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 256, 'u_mul_e', 'max' | s | -1% | 3.00823113 | r6i.16xlarge-cpu | 3.0394612
125 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 4, 'u_mul_e', 'max' | s | -5% | 0.17288359 | r6i.16xlarge-cpu | 0.18148787
124 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 4, 'u_mul_e', 'mean' | s | -9% | 0.11869686 | r6i.16xlarge-cpu | 0.13034599
123 | api.bench_builtin_update_all_csc.track_time | 'ogbn-proteins', 'csc', 4, 'u_mul_e', 'sum' | s | -16% | 0.11036966 | r6i.16xlarge-cpu | 0.13063302
106 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 4, 'u_mul_e', 'mean' | s | -20% | 0.13794892 | r6i.16xlarge-cpu | 0.1732847
105 | api.bench_builtin_update_all_csc.track_time | 'reddit', 'csc', 4, 'u_mul_e', 'sum' | s | -21% | 0.13687638 | r6i.16xlarge-cpu | 0.17295736



</body>

</html>
",urn urn office office urn office excel head meta meta excel link file link file style table page margin auto col auto padding color black normal none general general bottom border none auto auto locked visible scientific body unit machine,issue,positive,positive,neutral,neutral,positive,positive
1519393512,@chang-l could you help take a look at this? It's blocking our new release.,could help take look blocking new release,issue,negative,positive,positive,positive,positive,positive
1518932262,"Hi @cccusername , actually you don't need to understand these files. You can follow [https://docs.dgl.ai/en/latest/tutorials/blitz/6_load_data.html](url) to create you own dataset.",hi actually need understand follow create,issue,negative,neutral,neutral,neutral,neutral,neutral
1518932017,"Hi @NitishOritro , it seems that you are assigning a GPU tensor to a CPU graph. You can make them on the same device before the assignment.",hi tensor graph make device assignment,issue,negative,neutral,neutral,neutral,neutral,neutral
1518931691,Hi @ZoroSunCT . Sorry that DGL currently does not support loading a large graph that exceeds CPU memory. This is a direction we are actively working on.,hi sorry currently support loading large graph memory direction actively working,issue,positive,negative,negative,negative,negative,negative
1518925397,"DGL regression framework is ready [here](https://github.com/dglai/DGL_scripts/tree/master/regression) which enables to run DGL and DistDGL benchmark tests on specified instance(`AWS batch`) with specific dependencies such as `Python`, `PyTorch`, `CUDA`.
Dummy tests are added for these modules: `api`, `kernel`, `model`, `distributed`, `multi_gpu`, `pyg`.

In short, benchmark tests can be triggered via `python3 run_benchmarks.py --config dgl_benchmarks.json` under `//DGL_scripts/regression`.",regression framework ready run instance batch specific python dummy added kernel model distributed short triggered via python,issue,negative,positive,neutral,neutral,positive,positive
